{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn import preprocessing\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.neural_network import MLPRegressor\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "from sklearn.metrics import r2_score\n",
    "from scipy.stats import pearsonr\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.feature_selection import SelectFromModel\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compiling complete dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_mlp = pd.read_csv(\"df_thc_lsa.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>lsa_0</th>\n",
       "      <th>lsa_1</th>\n",
       "      <th>lsa_2</th>\n",
       "      <th>lsa_3</th>\n",
       "      <th>lsa_4</th>\n",
       "      <th>hybrid</th>\n",
       "      <th>indica</th>\n",
       "      <th>sativa</th>\n",
       "      <th>anxiety</th>\n",
       "      <th>anxious</th>\n",
       "      <th>...</th>\n",
       "      <th>sweet</th>\n",
       "      <th>tar</th>\n",
       "      <th>tea</th>\n",
       "      <th>tobacco</th>\n",
       "      <th>tree</th>\n",
       "      <th>tropical</th>\n",
       "      <th>vanilla</th>\n",
       "      <th>violet</th>\n",
       "      <th>woody</th>\n",
       "      <th>X..Delta9-THC</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.341025</td>\n",
       "      <td>0.182753</td>\n",
       "      <td>0.008214</td>\n",
       "      <td>0.140406</td>\n",
       "      <td>-0.156943</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.259712</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.232158</td>\n",
       "      <td>-0.045496</td>\n",
       "      <td>0.187131</td>\n",
       "      <td>-0.000936</td>\n",
       "      <td>0.018518</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.259712</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.261225</td>\n",
       "      <td>0.100324</td>\n",
       "      <td>-0.043622</td>\n",
       "      <td>0.141860</td>\n",
       "      <td>-0.034786</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.259712</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.243491</td>\n",
       "      <td>0.034313</td>\n",
       "      <td>0.080290</td>\n",
       "      <td>-0.165609</td>\n",
       "      <td>0.019773</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.259712</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.243491</td>\n",
       "      <td>0.034313</td>\n",
       "      <td>0.080290</td>\n",
       "      <td>-0.165609</td>\n",
       "      <td>0.019773</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.259712</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>74995</th>\n",
       "      <td>0.181714</td>\n",
       "      <td>-0.045560</td>\n",
       "      <td>-0.055692</td>\n",
       "      <td>0.015649</td>\n",
       "      <td>-0.045585</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.562557</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>74996</th>\n",
       "      <td>0.055494</td>\n",
       "      <td>0.003622</td>\n",
       "      <td>-0.050252</td>\n",
       "      <td>-0.024795</td>\n",
       "      <td>-0.031141</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.562557</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>74997</th>\n",
       "      <td>0.055494</td>\n",
       "      <td>0.003622</td>\n",
       "      <td>-0.050252</td>\n",
       "      <td>-0.024795</td>\n",
       "      <td>-0.031141</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.562557</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>74998</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.562557</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>74999</th>\n",
       "      <td>0.270141</td>\n",
       "      <td>-0.004631</td>\n",
       "      <td>-0.151272</td>\n",
       "      <td>0.035538</td>\n",
       "      <td>0.083641</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.562557</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>75000 rows × 87 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          lsa_0     lsa_1     lsa_2     lsa_3     lsa_4  hybrid  indica  \\\n",
       "0      0.341025  0.182753  0.008214  0.140406 -0.156943       1       0   \n",
       "1      0.232158 -0.045496  0.187131 -0.000936  0.018518       1       0   \n",
       "2      0.261225  0.100324 -0.043622  0.141860 -0.034786       1       0   \n",
       "3      0.243491  0.034313  0.080290 -0.165609  0.019773       1       0   \n",
       "4      0.243491  0.034313  0.080290 -0.165609  0.019773       1       0   \n",
       "...         ...       ...       ...       ...       ...     ...     ...   \n",
       "74995  0.181714 -0.045560 -0.055692  0.015649 -0.045585       0       1   \n",
       "74996  0.055494  0.003622 -0.050252 -0.024795 -0.031141       0       1   \n",
       "74997  0.055494  0.003622 -0.050252 -0.024795 -0.031141       0       1   \n",
       "74998  0.000000  0.000000  0.000000  0.000000  0.000000       0       1   \n",
       "74999  0.270141 -0.004631 -0.151272  0.035538  0.083641       0       1   \n",
       "\n",
       "       sativa  anxiety  anxious  ...  sweet  tar  tea  tobacco  tree  \\\n",
       "0           0        0        0  ...      0    0    0        0     0   \n",
       "1           0        0        0  ...      0    0    0        0     0   \n",
       "2           0        0        0  ...      1    0    0        0     0   \n",
       "3           0        0        0  ...      0    1    0        0     0   \n",
       "4           0        0        0  ...      0    1    0        0     0   \n",
       "...       ...      ...      ...  ...    ...  ...  ...      ...   ...   \n",
       "74995       0        0        0  ...      0    0    0        0     0   \n",
       "74996       0        0        0  ...      0    0    0        0     0   \n",
       "74997       0        0        0  ...      0    0    0        0     0   \n",
       "74998       0        0        0  ...      0    0    0        0     0   \n",
       "74999       0        0        1  ...      1    1    1        1     1   \n",
       "\n",
       "       tropical  vanilla  violet  woody  X..Delta9-THC  \n",
       "0             0        0       0      0       0.259712  \n",
       "1             0        1       0      0       0.259712  \n",
       "2             0        1       0      0       0.259712  \n",
       "3             0        0       0      0       0.259712  \n",
       "4             0        0       0      0       0.259712  \n",
       "...         ...      ...     ...    ...            ...  \n",
       "74995         0        0       0      0       0.562557  \n",
       "74996         0        0       0      0       0.562557  \n",
       "74997         0        0       0      0       0.562557  \n",
       "74998         0        0       0      0       0.562557  \n",
       "74999         1        1       1      1       0.562557  \n",
       "\n",
       "[75000 rows x 87 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_mlp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['lsa_0',\n",
       " 'lsa_1',\n",
       " 'lsa_2',\n",
       " 'lsa_3',\n",
       " 'lsa_4',\n",
       " 'hybrid',\n",
       " 'indica',\n",
       " 'sativa',\n",
       " 'anxiety',\n",
       " 'anxious',\n",
       " 'aroused',\n",
       " 'arthritis',\n",
       " 'creative',\n",
       " 'depression',\n",
       " 'dizzy',\n",
       " 'dry eyes',\n",
       " 'dry mouth',\n",
       " 'energetic',\n",
       " 'epilepsy',\n",
       " 'euphoric',\n",
       " 'eye pressure',\n",
       " 'fatigue',\n",
       " 'focused',\n",
       " 'giggly',\n",
       " 'happy',\n",
       " 'headache',\n",
       " 'hungry',\n",
       " 'migraines',\n",
       " 'pain',\n",
       " 'paranoid',\n",
       " 'relaxed',\n",
       " 'seizures',\n",
       " 'sleepy',\n",
       " 'spasticity',\n",
       " 'stress',\n",
       " 'talkative',\n",
       " 'tingly',\n",
       " 'uplifted',\n",
       " 'ammonia',\n",
       " 'apple',\n",
       " 'apricot',\n",
       " 'berry',\n",
       " 'blue cheese',\n",
       " 'blueberry',\n",
       " 'butter',\n",
       " 'cheese',\n",
       " 'chemical',\n",
       " 'chestnut',\n",
       " 'citrus',\n",
       " 'coffee',\n",
       " 'diesel',\n",
       " 'earthy',\n",
       " 'flowery',\n",
       " 'fruit',\n",
       " 'grape',\n",
       " 'grapefruit',\n",
       " 'honey',\n",
       " 'lavender',\n",
       " 'lemon',\n",
       " 'lime',\n",
       " 'mango',\n",
       " 'menthol',\n",
       " 'mint',\n",
       " 'nutty',\n",
       " 'orange',\n",
       " 'peach',\n",
       " 'pear',\n",
       " 'pepper',\n",
       " 'pine',\n",
       " 'pineapple',\n",
       " 'plum',\n",
       " 'pungent',\n",
       " 'rose',\n",
       " 'sage',\n",
       " 'skunk',\n",
       " 'spicy/herbal',\n",
       " 'strawberry',\n",
       " 'sweet',\n",
       " 'tar',\n",
       " 'tea',\n",
       " 'tobacco',\n",
       " 'tree',\n",
       " 'tropical',\n",
       " 'vanilla',\n",
       " 'violet',\n",
       " 'woody',\n",
       " 'X..Delta9-THC']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_mlp.columns.to_list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df_mlp.drop(['X..Delta9-THC'], axis = 1)\n",
    "y = df_mlp[['X..Delta9-THC']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:ylabel='Count'>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAZIAAAD4CAYAAADGmmByAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjQuMywgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/MnkTPAAAACXBIWXMAAAsTAAALEwEAmpwYAAAaEElEQVR4nO3de5BV5b3m8e/DTcBbUFuLoRvoRECFQkZaT3sZixyikhwVTfAExxM6GZkuUTMcHUnQU6VViVhaWh4OJmARJWBCiYyXSDKHHBAvmUQup4moXLXHC92RSAcdQx0EBX/zx16N26Yvm16992bTz6dqV6/9rvWu9b427qfX+669liICMzOzzupR7AaYmVlpc5CYmVkqDhIzM0vFQWJmZqk4SMzMLJVexW5AoZ1yyikxdOjQYjfDzKykrF+//i8RUdbaum4XJEOHDqWurq7YzTAzKymS3m1rnYe2zMwsFQeJmZml4iAxM7NUut0ciR09Pv30UxobG9m7d2+xm2Kt6Nu3L+Xl5fTu3bvYTbE8c5BYyWpsbOT4449n6NChSCp2cyxLRLBr1y4aGxuprKwsdnMszzy0ZSVr7969nHzyyQ6RI5AkTj75ZJ8tdhMOEitpDpEjl3833YeDxMzMUnGQ2FGjYvAQJHXZq2LwkHaP19DQQGVlJR988AEAH374IZWVlbz7bpvf2+K73/0ulZWVnH322QwfPpwpU6bwpz/9qcO+jRs37uAXae+5556c/ns88cQTjB49mpEjR/KDH/zgkPVXX301Y8aM4fTTT+fEE09kzJgxjBkzhpdffvkLxwN45513GDVq1MH369at4+KLL2bEiBGcccYZTJ06lT179uTULjv6eLLdjhqNDdt5cMW2LtvfrZeOaHd9RUUF06ZNY+bMmcyfP5+ZM2dSW1vLkCHtB9D999/PpEmTiAhmz57NV7/6VTZu3EifPn1yatc999zDHXfc0e42u3btYsaMGaxfv56ysjJqampYtWoV48ePP7jNM888A8CLL77IAw88wG9+85ucjv/+++9zzTXXsGTJEs4//3wigqeeeordu3fTv3//nPZxJKgYPITGhu0FP255xWAatrf9x0YpcpCYpXDLLbcwduxYZs+eze9//3seeuihnOtK4pZbbuGZZ55h+fLlTJw4kRUrVnDXXXexb98+vvKVr/Dzn/+c44477mCdmTNn8vHHHzNmzBhGjhzJ4sWLueqqq2hoaGDv3r1Mnz6d2tpa3nrrLYYPH05ZWebWSF/72td46qmnvhAknfXTn/6Umpoazj///IP9mDRpUur9FlpX/+GRq47+QClFDhKzFHr37s3999/PhAkTWLFiRc5nFdnOOecctm7dyoUXXsjdd9/Nc889x7HHHst9993Hgw8+yJ133nlw23vvvZef/OQnbNiw4WDZggULOOmkk/j4448599xz+da3vsXpp5/O1q1beeeddygvL+dXv/oVn3zyyWG167rrrqNfv34AfPLJJ/TokRkJ37hxIzU1NYfdTzt6OUjMUlq+fDkDBw5k48aNXHLJJYddPyIAWLNmDZs3b+bCCy8EMh/ezX/1t2fOnDkHh6kaGhp48803qa6uZt68eXz729+mR48eXHDBBbz11luH1a7FixdTVVUFZOZILr/88sOqb92Hg8QshQ0bNrBy5UrWrFnDRRddxOTJkxk4cOBh7eOVV15h/PjxRASXXHIJjz/+eM51X3zxRZ577jlWr15N//79GTdu3MHvblxxxRVcccUVAMyfP5+ePXty4MABxo4dC8CVV17Jj370o8NqK8DIkSNZv349EydOPOy6dnTyVVtmnRQRTJs2jdmzZzN48GBmzJjBbbfddlj158yZw44dO5gwYQLV1dX84Q9/oL6+HoA9e/bwxhtvHFKvd+/efPrppwB89NFHDBgwgP79+7N161bWrFlzcLudO3cCmavJ5s6dy9SpU+nZsycbNmxgw4YNnQoRgJtvvplFixaxdu3ag2W//OUv+fOf/9yp/Vnp8xnJYSjWVR5wdF7p0dXKKwZ36URmecXgdtf/7Gc/Y/DgwQeHs2688UYWLlzISy+9xPTp0w/OY0ydOpUbbrjh4DDRjBkz+PGPf8yePXuorq7mhRdeoE+fPpSVlbFw4UKuvfZa9u3bB8Ddd9/N8OHDv3Dc2tpaRo8ezTnnnMOCBQt4+OGHGT16NCNGjKC6uvrgdtOnT+fVV18F4M477zxkP5112mmnsWTJEm677TZ27txJjx49uPjii/nmN7/ZJfu30qPm8dnuoqqqKjr7YCtJRbnKAzJXenS331VHtmzZwplnnlnsZlg7juTfUbH+fy7V/5clrY+IqtbWeWjLzMxScZCYmVkqDhIraaU4RNBd+HfTfThIrGT17duXXbt2+QPrCNT8PJK+ffsWuylWAL5qy0pWeXk5jY2NNDU1Fbsp1ormJyTa0c9BYiWrd+/efvqe2REgb0NbkhZI2ilpY1bZ/ZK2SnpN0jOSvpS17nZJ9ZK2Sbosq3yspNeTdXOUPC1H0jGSnkjK10oamq++mJlZ2/I5R7IQmNCibCUwKiJGA28AtwNIOguYDIxM6syV1DOpMw+oBYYlr+Z9Xg98GBGnA/8M3Je3npiZWZvyFiQR8TvggxZlKyJif/J2DdA8gDoRWBIR+yLibaAeOE/SQOCEiFgdmRnVx4CrsuosSpafBMY3n62YmVnhFPOqrf8GLE+WBwENWesak7JByXLL8i/UScLpI+Dk1g4kqVZSnaQ6T8yamXWtogSJpH8C9gOLm4ta2SzaKW+vzqGFEfMjoioiqpof9GNmn+vqxxR31eOMrTQU/KotSTXA5cD4+PwLAI1ARdZm5cB7SXl5K+XZdRol9QJOpMVQmpnlxk8LtDQKekYiaQLwQ+DKiNiTtWoZMDm5EquSzKT6uojYAeyWVJ3Mf0wBns2q0/yYtknA8+FvppmZFVzezkgkPQ6MA06R1AjcReYqrWOAlcm8+JqIuCEiNklaCmwmM+R1U0QcSHY1jcwVYP3IzKk0z6s8CvxCUj2ZM5HJ+eqLmZm1LW9BEhHXtlL8aDvbzwJmtVJeB4xqpXwvcE2aNpqZWXq+15aZmaXiIDEzs1QcJGZmloqDxMzMUnGQmJlZKg4SMzNLxUFiZmapOEjMzCwVB4mZmaXiIDEzs1QcJGZmloqDxMzMUnGQmJlZKg4SMzNLxUFiZmapOEjMzCwVB4mZmaXiIDEzs1QcJGZmloqDxMzMUnGQmJlZKg4SMzNLJW9BImmBpJ2SNmaVnSRppaQ3k58DstbdLqle0jZJl2WVj5X0erJujiQl5cdIeiIpXytpaL76YmZmbcvnGclCYEKLspnAqogYBqxK3iPpLGAyMDKpM1dSz6TOPKAWGJa8mvd5PfBhRJwO/DNwX956YmZmbcpbkETE74APWhRPBBYly4uAq7LKl0TEvoh4G6gHzpM0EDghIlZHRACPtajTvK8ngfHNZytmZlY4hZ4jOS0idgAkP09NygcBDVnbNSZlg5LlluVfqBMR+4GPgJPz1nIzM2vVkTLZ3tqZRLRT3l6dQ3cu1Uqqk1TX1NTUySaamVlrCh0k7yfDVSQ/dybljUBF1nblwHtJeXkr5V+oI6kXcCKHDqUBEBHzI6IqIqrKysq6qCtmZgaFD5JlQE2yXAM8m1U+ObkSq5LMpPq6ZPhrt6TqZP5jSos6zfuaBDyfzKOYmVkB9crXjiU9DowDTpHUCNwF3AsslXQ9sB24BiAiNklaCmwG9gM3RcSBZFfTyFwB1g9YnrwAHgV+IamezJnI5Hz1xczM2pa3IImIa9tYNb6N7WcBs1oprwNGtVK+lySIzMyseI6UyXYzMytRDhIzM0vFQWLtqhg8BElFeVUMHlLs7ptZDvI2R2JHh8aG7Ty4YltRjn3rpSOKclwzOzw+IzEzs1QcJGZmloqDxMzMUnGQmJlZKg4SMzNLxUFiZmapOEjMzCwVB4mZmaXiIDEzs1QcJGZmloqDxMzMUnGQmJlZKg4SMzNLxUFiZmapOEjMzCwVB4mZmaXiIDEzs1QcJGZmloqDxMzMUilKkEi6RdImSRslPS6pr6STJK2U9Gbyc0DW9rdLqpe0TdJlWeVjJb2erJsjScXoj5lZd1bwIJE0CPgfQFVEjAJ6ApOBmcCqiBgGrEreI+msZP1IYAIwV1LPZHfzgFpgWPKaUMCumJkZxRva6gX0k9QL6A+8B0wEFiXrFwFXJcsTgSURsS8i3gbqgfMkDQROiIjVERHAY1l1zMysQAoeJBHxJ+ABYDuwA/goIlYAp0XEjmSbHcCpSZVBQEPWLhqTskHJcsvyQ0iqlVQnqa6pqakru2Nm1u0VY2hrAJmzjErgPwHHSvqH9qq0UhbtlB9aGDE/IqoioqqsrOxwm2xmZu0oxtDW14C3I6IpIj4FngYuAN5PhqtIfu5Mtm8EKrLql5MZCmtMlluWm5lZARUjSLYD1ZL6J1dZjQe2AMuAmmSbGuDZZHkZMFnSMZIqyUyqr0uGv3ZLqk72MyWrjlnJqRg8BElFeZml0avQB4yItZKeBP4I7AdeAeYDxwFLJV1PJmyuSbbfJGkpsDnZ/qaIOJDsbhqwEOgHLE9eZiWpsWE7D67YVpRj33rpiKIc144OBQ8SgIi4C7irRfE+MmcnrW0/C5jVSnkdMKrLG2hmZjnLaWhL0oW5lJmZWfeT6xzJQzmWmZlZN9Pu0Jak88lcUVUm6dasVSeQ+Ua6mZl1cx3NkfQhMwneCzg+q/yvwKR8NcrMzEpHu0ESES8BL0laGBHvFqhNZmZWQnK9ausYSfOBodl1IuJv89EoMzMrHbkGyf8CHgYeAQ50sK2ZmXUjuQbJ/oiYl9eWmJlZScr18t9fS7pR0sDkAVQnSTopry0zK5Ji3arErFTlekbSfA+sGVllAXy5a5tjVnzFulWJb1NipSqnIImIynw3xMzMSlNOQSJpSmvlEfFY1zbHzMxKTa5DW+dmLfclc3PFP5J5vK2ZmXVjuQ5tfT/7vaQTgV/kpUVmZlZSOvtgqz1kHjBlZmbdXK5zJL/m8+eh9wTOBJbmq1FmZlY6cp0jeSBreT/wbkQ05qE9ZmZWYnIa2kpu3riVzB2ABwCf5LNRZmZWOnJ9QuLfA+vIPEf974G1knwbeTMzy3lo65+AcyNiJ4CkMuA54Ml8NczMzEpDrldt9WgOkcSuw6hrZmZHsVzPSH4r6d+Ax5P33wb+NT9NMjOzUtLRM9tPB06LiBmSvglcBAhYDSwuQPvMzOwI19Hw1GxgN0BEPB0Rt0bELWTORmZ39qCSviTpSUlbJW2RdH5ya/qVkt5Mfg7I2v52SfWStkm6LKt8rKTXk3Vz5Htxm5kVXEdBMjQiXmtZGBF1ZB6721n/Avw2Is4Azga2ADOBVRExDFiVvEfSWcBkYCQwAZgrqWeyn3lALZlv2Q9L1puZWQF1FCR921nXrzMHlHQCcDHwKEBEfBIR/w+YCCxKNlsEXJUsTwSWRMS+iHgbqAfOkzQQOCEiVkdEkLmBZHMdMzMrkI6C5N8l/feWhZKuB9Z38phfBpqAn0t6RdIjko4lMxezAyD5eWqy/SCgIat+Y1I2KFluWX4ISbWS6iTVNTU1dbLZZmbWmo6u2vpH4BlJ1/F5cFQBfYCrUxzzHOD7EbFW0r+QDGO1obV5j2in/NDCiPnAfICqqqpWtzEzs85pN0gi4n3gAklfBUYlxf87Ip5PccxGoDEi1ibvnyQTJO9LGhgRO5Jhq51Z21dk1S8H3kvKy1spNzOzAsr1XlsvRMRDyStNiBARfwYaJDU/oHo8sBlYxufPhq8Bnk2WlwGTJR0jqZLMpPq6ZPhrt6Tq5GqtKVl1zMysQHL9QmJX+z6wWFIf4C3ge2RCbWky/7KdzH29iIhNkpaSCZv9wE0RcSDZzzRgIZmJ/+XJy8zMCqgoQRIRG8jMtbQ0vo3tZwGzWimv4/MhNzMzKwLfL8vMzFJxkJiZWSrFmiMx65h64LvemB35HCR25IrPeHDFtoIf9tZLR3S8kZkd5KEtMzNLxUFiZmapOEjMzCwVB4mZmaXiIDEzs1QcJGZmloqDxMzMUnGQmJlZKg4SMzNLxUFiZmapOEjMzCwVB4mZmaXiIDEzs1QcJGZmloqDxMzMUnGQmJlZKg4SMzNLxUFiZmapFC1IJPWU9Iqk3yTvT5K0UtKbyc8BWdveLqle0jZJl2WVj5X0erJujvyAbzOzgivmGcl0YEvW+5nAqogYBqxK3iPpLGAyMBKYAMyV1DOpMw+oBYYlrwmFabqZmTUrSpBIKgf+Dngkq3gisChZXgRclVW+JCL2RcTbQD1wnqSBwAkRsToiAngsq46ZmRVIsc5IZgM/AD7LKjstInYAJD9PTcoHAQ1Z2zUmZYOS5Zblh5BUK6lOUl1TU1OXdMDMzDIKHiSSLgd2RsT6XKu0UhbtlB9aGDE/IqoioqqsrCzHw5qZWS56FeGYFwJXSvoG0Bc4QdIvgfclDYyIHcmw1c5k+0agIqt+OfBeUl7eSrmZmRVQwc9IIuL2iCiPiKFkJtGfj4h/AJYBNclmNcCzyfIyYLKkYyRVkplUX5cMf+2WVJ1crTUlq46ZmRVIMc5I2nIvsFTS9cB24BqAiNgkaSmwGdgP3BQRB5I604CFQD9gefIyM7MCKmqQRMSLwIvJ8i5gfBvbzQJmtVJeB4zKXwvNzKwj/ma7mZml4iAxM7NUHCRmZpaKg8TMzFJxkJiZWSoOEjMzS8VBYmZmqThIzMwsFQeJmZml4iAxM7NUjqR7bZlZd6Me+AnZpc9BYmbFE5/x4IptRTn0rZeOKMpxj0Ye2jIzs1QcJGZmloqDxMzMUnGQmJlZKg4SMzNLxUFiZmapOEjMzCwVB4mZmaXiIDEzs1T8zfZS4VtJmNkRykFSKop0KwnfRsLMOlLwoS1JFZJekLRF0iZJ05PykyStlPRm8nNAVp3bJdVL2ibpsqzysZJeT9bNkf9kNzMruGLMkewH/mdEnAlUAzdJOguYCayKiGHAquQ9ybrJwEhgAjBXUs9kX/OAWmBY8ppQyI6YmVkRgiQidkTEH5Pl3cAWYBAwEViUbLYIuCpZnggsiYh9EfE2UA+cJ2kgcEJErI6IAB7LqmNmZgVS1Ku2JA0F/jOwFjgtInZAJmyAU5PNBgENWdUak7JByXLL8taOUyupTlJdU1NTl/bBzKy7K1qQSDoOeAr4x4j4a3ubtlIW7ZQfWhgxPyKqIqKqrKzs8BtrZtZVkiswi/GqGDwkL10qylVbknqTCZHFEfF0Uvy+pIERsSMZttqZlDcCFVnVy4H3kvLyVsrNzI5cR+HDvIpx1ZaAR4EtEfFg1qplQE2yXAM8m1U+WdIxkirJTKqvS4a/dkuqTvY5JauOmZkVSDHOSC4EvgO8LmlDUnYHcC+wVNL1wHbgGoCI2CRpKbCZzBVfN0XEgaTeNGAh0A9YnrzMzKyACh4kEfF7Wp/fABjfRp1ZwKxWyuuAUV3XOjMzO1y+15aZmaXiIDEzs1QcJGZmloqDxMzMUnGQmJlZKg4SMzNLxUFiZmapOEjMzCwVB4mZmaXiIDEzs1QcJGZmloqDxMzMUnGQmJlZKg4SMzNLxUFiZmapOEjMzCwVB4mZmaXiIDEzs1QcJGZmloqDxMzMUnGQmJlZKg4SMzNLxUFiZmaplHyQSJogaZukekkzi90eM7PupqSDRFJP4KfA14GzgGslnVXcVpmZdS8lHSTAeUB9RLwVEZ8AS4CJRW6TmVm3oogodhs6TdIkYEJETE3efwf4m4i4ucV2tUBt8nYEsK2ThzwF+Esn65Yq97l7cJ+7hzR9HhIRZa2t6NX59hwR1ErZIckYEfOB+akPJtVFRFXa/ZQS97l7cJ+7h3z1udSHthqBiqz35cB7RWqLmVm3VOpB8u/AMEmVkvoAk4FlRW6TmVm3UtJDWxGxX9LNwL8BPYEFEbEpj4dMPTxWgtzn7sF97h7y0ueSnmw3M7PiK/WhLTMzKzIHiZmZpeIgaUVHt11Rxpxk/WuSzilGO7tSDn2+Lunra5JelnR2MdrZlXK9vY6kcyUdSL63VNJy6bOkcZI2SNok6aVCt7Er5fDv+kRJv5b0atLf7xWjnV1J0gJJOyVtbGN9139+RYRfWS8yk/b/F/gy0Ad4FTirxTbfAJaT+R5LNbC22O0uQJ8vAAYky1/vDn3O2u554F+BScVudwF+z18CNgODk/enFrvdee7vHcB9yXIZ8AHQp9htT9nvi4FzgI1trO/yzy+fkRwql9uuTAQei4w1wJckDSx0Q7tQh32OiJcj4sPk7Roy39kpZbneXuf7wFPAzkI2Lk9y6fN/BZ6OiO0AEVHK/c6lvwEcL0nAcWSCZH9hm9m1IuJ3ZPrRli7//HKQHGoQ0JD1vjEpO9xtSsnh9ud6Mn/RlLIO+yxpEHA18HAB25VPufyehwMDJL0oab2kKQVrXdfLpb8/Ac4k80Xm14HpEfFZYZpXNF3++VXS3yPJk1xuu5LTrVlKSM79kfRVMkFyUV5blH+59Hk28MOIOJD5g7Xk5dLnXsBYYDzQD1gtaU1EvJHvxuVBLv29DNgA/C3wFWClpP8TEX/Nc9uKqcs/vxwkh8rltitH261ZcuqPpNHAI8DXI2JXgdqWL7n0uQpYkoTIKcA3JO2PiF8VpIVdL9d/23+JiP8A/kPS74CzgVIMklz6+z3g3shMHtRLehs4A1hXmCYWRZd/fnlo61C53HZlGTAlufqhGvgoInYUuqFdqMM+SxoMPA18p0T/Om2pwz5HRGVEDI2IocCTwI0lHCKQ27/tZ4H/IqmXpP7A3wBbCtzOrpJLf7eTOftC0mlk7g7+VkFbWXhd/vnlM5IWoo3brki6IVn/MJkreL4B1AN7yPxVU7Jy7POdwMnA3OQv9P1RwndOzbHPR5Vc+hwRWyT9FngN+Ax4JCJavYz0SJfj7/jHwEJJr5MZ8vlhRJT0reUlPQ6MA06R1AjcBfSG/H1++RYpZmaWioe2zMwsFQeJmZml4iAxM7NUHCRmZpaKg8TMzFJxkJiZWSoOEjMzS+X/Ay3cLAi0orHKAAAAAElFTkSuQmCC",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "sns.histplot(y, bins = 10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train test split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=1, test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train1, X_val, y_train1, y_val = train_test_split(X_train, y_train, random_state=1, test_size=0.25)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "MLP modeling (before Feature selection and Hyperparameter Tuning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/andalanputra/opt/anaconda3/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:1623: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    }
   ],
   "source": [
    "mlpreg = MLPRegressor(random_state=1, early_stopping=True)\n",
    "mlpreg.fit(X_train1, y_train1)\n",
    "y_pred_mlp = mlpreg.predict(X_val)\n",
    "y_pred_mlp_r2 = mlpreg.predict(X_train1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.15526080201271275"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mean_absolute_error(y_val, y_pred_mlp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5844161565199828"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#train\n",
    "r2_score(y_train1, y_pred_mlp_r2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.4604052178585222"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#val\n",
    "r2_score(y_val, y_pred_mlp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Residual plots for each target variable"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Feature Selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "rfreg = RandomForestRegressor()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/andalanputra/opt/anaconda3/lib/python3.9/site-packages/sklearn/feature_selection/_from_model.py:357: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  self.estimator_.fit(X, y, **fit_params)\n"
     ]
    }
   ],
   "source": [
    "selector = SelectFromModel(rfreg).fit(X_train1, y_train1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1.27780618e-01, 1.21647351e-01, 1.27653254e-01, 1.19058813e-01,\n",
       "       1.22422613e-01, 1.17125640e-02, 1.09122152e-02, 2.78361075e-02,\n",
       "       1.30166923e-04, 2.14611135e-03, 8.70394248e-03, 3.96936941e-06,\n",
       "       7.93190494e-03, 1.03871987e-04, 3.99865129e-03, 6.53130129e-03,\n",
       "       8.78205135e-03, 7.63565596e-03, 2.91335241e-06, 1.00187696e-02,\n",
       "       3.51619037e-06, 3.97965093e-06, 7.71750546e-03, 6.73301517e-03,\n",
       "       1.02853392e-02, 2.54721038e-03, 9.64462769e-03, 9.83410599e-05,\n",
       "       2.40165948e-06, 2.12126113e-03, 1.23197289e-02, 5.37144022e-06,\n",
       "       1.12621073e-02, 0.00000000e+00, 8.08670782e-08, 5.66811698e-03,\n",
       "       6.38833798e-03, 9.11309743e-03, 1.59920038e-03, 3.20553108e-04,\n",
       "       7.23518136e-04, 5.38677106e-03, 1.55460787e-04, 5.07636863e-03,\n",
       "       1.27615877e-03, 1.03977068e-02, 1.54212563e-03, 2.83701343e-04,\n",
       "       6.21517838e-03, 1.24007622e-03, 2.78301164e-02, 1.24541056e-02,\n",
       "       3.04673996e-03, 1.22223961e-03, 7.59664464e-03, 1.55363243e-03,\n",
       "       1.10820197e-03, 7.85028330e-04, 1.23340902e-02, 1.53139781e-03,\n",
       "       7.53726820e-04, 2.78509999e-03, 4.15471036e-03, 1.29598151e-03,\n",
       "       1.88895870e-02, 2.40415475e-04, 8.36645403e-04, 2.20991981e-03,\n",
       "       1.07250742e-02, 6.10100500e-04, 4.02028447e-04, 7.97057000e-03,\n",
       "       1.41398655e-03, 6.46517001e-04, 3.29038036e-03, 3.11876058e-03,\n",
       "       1.10651214e-03, 1.24425074e-02, 4.63294573e-04, 7.60117287e-04,\n",
       "       3.27055927e-04, 9.85945333e-04, 2.86851702e-03, 5.30830767e-03,\n",
       "       4.31975965e-04, 3.35636291e-03])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "selector.estimator_.feature_importances_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.011627906976744186"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "selector.threshold_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "mask = selector.get_support()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ True,  True,  True,  True,  True,  True, False,  True, False,\n",
       "       False, False, False, False, False, False, False, False, False,\n",
       "       False, False, False, False, False, False, False, False, False,\n",
       "       False, False, False,  True, False, False, False, False, False,\n",
       "       False, False, False, False, False, False, False, False, False,\n",
       "       False, False, False, False, False,  True,  True, False, False,\n",
       "       False, False, False, False,  True, False, False, False, False,\n",
       "       False,  True, False, False, False, False, False, False, False,\n",
       "       False, False, False, False, False,  True, False, False, False,\n",
       "       False, False, False, False, False])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "selected_features = X.columns[mask]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>lsa_0</th>\n",
       "      <th>lsa_1</th>\n",
       "      <th>lsa_2</th>\n",
       "      <th>lsa_3</th>\n",
       "      <th>lsa_4</th>\n",
       "      <th>hybrid</th>\n",
       "      <th>sativa</th>\n",
       "      <th>relaxed</th>\n",
       "      <th>diesel</th>\n",
       "      <th>earthy</th>\n",
       "      <th>lemon</th>\n",
       "      <th>orange</th>\n",
       "      <th>sweet</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.341025</td>\n",
       "      <td>0.182753</td>\n",
       "      <td>0.008214</td>\n",
       "      <td>0.140406</td>\n",
       "      <td>-0.156943</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.232158</td>\n",
       "      <td>-0.045496</td>\n",
       "      <td>0.187131</td>\n",
       "      <td>-0.000936</td>\n",
       "      <td>0.018518</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.261225</td>\n",
       "      <td>0.100324</td>\n",
       "      <td>-0.043622</td>\n",
       "      <td>0.141860</td>\n",
       "      <td>-0.034786</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.243491</td>\n",
       "      <td>0.034313</td>\n",
       "      <td>0.080290</td>\n",
       "      <td>-0.165609</td>\n",
       "      <td>0.019773</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.243491</td>\n",
       "      <td>0.034313</td>\n",
       "      <td>0.080290</td>\n",
       "      <td>-0.165609</td>\n",
       "      <td>0.019773</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>74995</th>\n",
       "      <td>0.181714</td>\n",
       "      <td>-0.045560</td>\n",
       "      <td>-0.055692</td>\n",
       "      <td>0.015649</td>\n",
       "      <td>-0.045585</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>74996</th>\n",
       "      <td>0.055494</td>\n",
       "      <td>0.003622</td>\n",
       "      <td>-0.050252</td>\n",
       "      <td>-0.024795</td>\n",
       "      <td>-0.031141</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>74997</th>\n",
       "      <td>0.055494</td>\n",
       "      <td>0.003622</td>\n",
       "      <td>-0.050252</td>\n",
       "      <td>-0.024795</td>\n",
       "      <td>-0.031141</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>74998</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>74999</th>\n",
       "      <td>0.270141</td>\n",
       "      <td>-0.004631</td>\n",
       "      <td>-0.151272</td>\n",
       "      <td>0.035538</td>\n",
       "      <td>0.083641</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>75000 rows × 13 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          lsa_0     lsa_1     lsa_2     lsa_3     lsa_4  hybrid  sativa  \\\n",
       "0      0.341025  0.182753  0.008214  0.140406 -0.156943       1       0   \n",
       "1      0.232158 -0.045496  0.187131 -0.000936  0.018518       1       0   \n",
       "2      0.261225  0.100324 -0.043622  0.141860 -0.034786       1       0   \n",
       "3      0.243491  0.034313  0.080290 -0.165609  0.019773       1       0   \n",
       "4      0.243491  0.034313  0.080290 -0.165609  0.019773       1       0   \n",
       "...         ...       ...       ...       ...       ...     ...     ...   \n",
       "74995  0.181714 -0.045560 -0.055692  0.015649 -0.045585       0       0   \n",
       "74996  0.055494  0.003622 -0.050252 -0.024795 -0.031141       0       0   \n",
       "74997  0.055494  0.003622 -0.050252 -0.024795 -0.031141       0       0   \n",
       "74998  0.000000  0.000000  0.000000  0.000000  0.000000       0       0   \n",
       "74999  0.270141 -0.004631 -0.151272  0.035538  0.083641       0       0   \n",
       "\n",
       "       relaxed  diesel  earthy  lemon  orange  sweet  \n",
       "0            1       0       0      0       0      0  \n",
       "1            1       0       0      0       0      0  \n",
       "2            0       0       0      0       0      1  \n",
       "3            1       0       0      0       0      0  \n",
       "4            1       0       0      0       0      0  \n",
       "...        ...     ...     ...    ...     ...    ...  \n",
       "74995        1       0       0      0       0      0  \n",
       "74996        0       0       0      0       0      0  \n",
       "74997        0       0       0      0       0      0  \n",
       "74998        0       0       0      0       0      0  \n",
       "74999        1       1       1      1       1      1  \n",
       "\n",
       "[75000 rows x 13 columns]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "selected_X = df_mlp[selected_features]\n",
    "selected_X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['lsa_0',\n",
       " 'lsa_1',\n",
       " 'lsa_2',\n",
       " 'lsa_3',\n",
       " 'lsa_4',\n",
       " 'hybrid',\n",
       " 'sativa',\n",
       " 'relaxed',\n",
       " 'diesel',\n",
       " 'earthy',\n",
       " 'lemon',\n",
       " 'orange',\n",
       " 'sweet']"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "selected_X.columns.to_list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['selected_X_mlp_lsa_elbow_thc.pkl']"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import joblib\n",
    "\n",
    "joblib.dump(selector, \"selector_mlp_lsa_elbow_thc.pkl\")\n",
    "joblib.dump(selected_X, \"selected_X_mlp_lsa_elbow_thc.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import joblib\n",
    "\n",
    "selected_X = joblib.load(\"selected_X_mlp_lsa_elbow_thc.pkl\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train test split (after Feature Selection)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(selected_X, y, random_state=1, test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train1, X_val, y_train1, y_val = train_test_split(X_train, y_train, random_state=1, test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/andalanputra/opt/anaconda3/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:1623: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    }
   ],
   "source": [
    "mlpreg.fit(X_train1, y_train1)\n",
    "y_pred_mlpreg = mlpreg.predict(X_val)\n",
    "y_pred_mlpreg_r2 = mlpreg.predict(X_train1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.20878224386710084"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mean_absolute_error(y_val, y_pred_mlpreg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.2449061990660909"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#train\n",
    "r2_score(y_train1, y_pred_mlpreg_r2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.226082011254658"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#val\n",
    "r2_score(y_val, y_pred_mlpreg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hyperparameter Tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "parameters = {'hidden_layer_sizes': [(100,), (50, 50, 50), (50, 100, 50)],\n",
    "              'activation': ['tanh', 'relu'], #only tanh and relu\n",
    "              'max_iter': [200, 500, 1000]\n",
    "              }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "rscv = RandomizedSearchCV(mlpreg,  \n",
    "                     parameters,   \n",
    "                     cv=5, \n",
    "                     scoring='neg_mean_absolute_error',\n",
    "                     n_jobs = -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/andalanputra/opt/anaconda3/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:1623: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/Users/andalanputra/opt/anaconda3/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:1623: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/Users/andalanputra/opt/anaconda3/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:1623: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/Users/andalanputra/opt/anaconda3/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:1623: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/Users/andalanputra/opt/anaconda3/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:1623: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/Users/andalanputra/opt/anaconda3/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:1623: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/Users/andalanputra/opt/anaconda3/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:1623: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/Users/andalanputra/opt/anaconda3/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:1623: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/Users/andalanputra/opt/anaconda3/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:1623: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/Users/andalanputra/opt/anaconda3/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/Users/andalanputra/opt/anaconda3/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/Users/andalanputra/opt/anaconda3/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:1623: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/Users/andalanputra/opt/anaconda3/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:1623: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/Users/andalanputra/opt/anaconda3/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/Users/andalanputra/opt/anaconda3/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/Users/andalanputra/opt/anaconda3/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:1623: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/Users/andalanputra/opt/anaconda3/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:1623: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/Users/andalanputra/opt/anaconda3/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/Users/andalanputra/opt/anaconda3/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:1623: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/Users/andalanputra/opt/anaconda3/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:1623: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/Users/andalanputra/opt/anaconda3/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:1623: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/Users/andalanputra/opt/anaconda3/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:1623: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/Users/andalanputra/opt/anaconda3/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:1623: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/Users/andalanputra/opt/anaconda3/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:1623: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/Users/andalanputra/opt/anaconda3/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:1623: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/Users/andalanputra/opt/anaconda3/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:1623: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/Users/andalanputra/opt/anaconda3/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:1623: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/Users/andalanputra/opt/anaconda3/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:1623: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/Users/andalanputra/opt/anaconda3/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:1623: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/Users/andalanputra/opt/anaconda3/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:1623: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/Users/andalanputra/opt/anaconda3/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/Users/andalanputra/opt/anaconda3/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:1623: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/Users/andalanputra/opt/anaconda3/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:1623: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/Users/andalanputra/opt/anaconda3/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:1623: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/Users/andalanputra/opt/anaconda3/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:1623: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/Users/andalanputra/opt/anaconda3/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/Users/andalanputra/opt/anaconda3/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:1623: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/Users/andalanputra/opt/anaconda3/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:1623: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/Users/andalanputra/opt/anaconda3/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:1623: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/Users/andalanputra/opt/anaconda3/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/Users/andalanputra/opt/anaconda3/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:1623: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/Users/andalanputra/opt/anaconda3/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:1623: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/Users/andalanputra/opt/anaconda3/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:1623: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/Users/andalanputra/opt/anaconda3/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/Users/andalanputra/opt/anaconda3/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:1623: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/Users/andalanputra/opt/anaconda3/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:1623: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/Users/andalanputra/opt/anaconda3/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/Users/andalanputra/opt/anaconda3/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:1623: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/Users/andalanputra/opt/anaconda3/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:1623: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/Users/andalanputra/opt/anaconda3/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:1623: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/Users/andalanputra/opt/anaconda3/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:1623: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/Users/andalanputra/opt/anaconda3/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:1623: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/Users/andalanputra/opt/anaconda3/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:1623: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/Users/andalanputra/opt/anaconda3/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:1623: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/Users/andalanputra/opt/anaconda3/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:1623: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/Users/andalanputra/opt/anaconda3/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:1623: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/Users/andalanputra/opt/anaconda3/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:1623: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/Users/andalanputra/opt/anaconda3/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:1623: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/Users/andalanputra/opt/anaconda3/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:1623: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/Users/andalanputra/opt/anaconda3/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:1623: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/Users/andalanputra/opt/anaconda3/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:1623: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;background-color: white;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>RandomizedSearchCV(cv=5,\n",
       "                   estimator=MLPRegressor(early_stopping=True, random_state=1),\n",
       "                   n_jobs=-1,\n",
       "                   param_distributions={&#x27;activation&#x27;: [&#x27;tanh&#x27;, &#x27;relu&#x27;],\n",
       "                                        &#x27;hidden_layer_sizes&#x27;: [(100,),\n",
       "                                                               (50, 50, 50),\n",
       "                                                               (50, 100, 50)],\n",
       "                                        &#x27;max_iter&#x27;: [200, 500, 1000]},\n",
       "                   scoring=&#x27;neg_mean_absolute_error&#x27;)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" ><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">RandomizedSearchCV</label><div class=\"sk-toggleable__content\"><pre>RandomizedSearchCV(cv=5,\n",
       "                   estimator=MLPRegressor(early_stopping=True, random_state=1),\n",
       "                   n_jobs=-1,\n",
       "                   param_distributions={&#x27;activation&#x27;: [&#x27;tanh&#x27;, &#x27;relu&#x27;],\n",
       "                                        &#x27;hidden_layer_sizes&#x27;: [(100,),\n",
       "                                                               (50, 50, 50),\n",
       "                                                               (50, 100, 50)],\n",
       "                                        &#x27;max_iter&#x27;: [200, 500, 1000]},\n",
       "                   scoring=&#x27;neg_mean_absolute_error&#x27;)</pre></div></div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" ><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">estimator: MLPRegressor</label><div class=\"sk-toggleable__content\"><pre>MLPRegressor(early_stopping=True, random_state=1)</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-3\" type=\"checkbox\" ><label for=\"sk-estimator-id-3\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">MLPRegressor</label><div class=\"sk-toggleable__content\"><pre>MLPRegressor(early_stopping=True, random_state=1)</pre></div></div></div></div></div></div></div></div></div></div>"
      ],
      "text/plain": [
       "RandomizedSearchCV(cv=5,\n",
       "                   estimator=MLPRegressor(early_stopping=True, random_state=1),\n",
       "                   n_jobs=-1,\n",
       "                   param_distributions={'activation': ['tanh', 'relu'],\n",
       "                                        'hidden_layer_sizes': [(100,),\n",
       "                                                               (50, 50, 50),\n",
       "                                                               (50, 100, 50)],\n",
       "                                        'max_iter': [200, 500, 1000]},\n",
       "                   scoring='neg_mean_absolute_error')"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rscv.fit(X_train1, y_train1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'max_iter': 1000, 'hidden_layer_sizes': (50, 100, 50), 'activation': 'tanh'}"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rscv.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['rscv_mlp_lsa_elbow_best_params_thc.pkl']"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "joblib.dump(rscv, \"rscv_mlp_lsa_elbow_thc.pkl\")\n",
    "joblib.dump(rscv.best_params_, \"rscv_mlp_lsa_elbow_best_params_thc.pkl\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "MLP fit (after hyperparameter tuning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/andalanputra/opt/anaconda3/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:1623: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    }
   ],
   "source": [
    "mlpreg_ht = MLPRegressor(random_state=1, max_iter=1000, activation = 'tanh', hidden_layer_sizes= (50,100,50), early_stopping=True)\n",
    "mlpreg_ht.fit(X_train1, y_train1)\n",
    "y_pred_mlp_ht = mlpreg_ht.predict(X_val)\n",
    "y_pred_mlp_r2_ht = mlpreg_ht.predict(X_train1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.15754926305232955"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mean_absolute_error(y_val, y_pred_mlp_ht)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5743225906417272"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#train\n",
    "r2_score(y_train1, y_pred_mlp_r2_ht)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.46756888497949334"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#val\n",
    "r2_score(y_val, y_pred_mlp_ht)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Residual plots after Hyperparameter Tuning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Predicting model on the test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_mlpreg_test = mlpreg_ht.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['y_test_mlpreg_lsa_elbow_thc.pkl']"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "joblib.dump(y_pred_mlpreg_test, \"y_pred_mlpreg_test_lsa_elbow_thc.pkl\")\n",
    "joblib.dump(y_test, \"y_test_mlpreg_lsa_elbow_thc.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.15661278273463217"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mean_absolute_error(y_test, y_pred_mlpreg_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.04250522956766585"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mean_squared_error(y_test, y_pred_mlpreg_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.20616796445535823"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mean_squared_error(y_test, y_pred_mlpreg_test, squared = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.483471346784493"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "r2_score(y_test, y_pred_mlpreg_test)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Error analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 576x432 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 432x288 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# assume y_pred is a numpy array and y_true is a pandas dataframe\n",
    "fig, ax = plt.subplots(figsize=(8, 6))\n",
    "\n",
    "column = \"X..Delta9-THC\"  # specify the target variable name\n",
    "ax.hist(y_pred_mlpreg_test, alpha=0.5, label='y_pred', bins=20)\n",
    "ax.hist(y_test[column], alpha=0.5, label='y_true', bins=20)\n",
    "ax.legend(loc='upper right')\n",
    "ax.set_title(column)\n",
    "\n",
    "plt.show()\n",
    "plt.savefig('error_hist_mlp_lsa_elbow_thc.png')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pearson R"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pearson correlation coefficient: 0.697\n",
      "P-value: 0.000\n"
     ]
    }
   ],
   "source": [
    "corr_coef, p_value = pearsonr(y_pred_mlpreg_test.flatten(), y_test.values.ravel())\n",
    "\n",
    "print(f\"Pearson correlation coefficient: {corr_coef:.3f}\")\n",
    "print(f\"P-value: {p_value:.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:>"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "corr_matrix = y_test.corr()\n",
    "sns.heatmap(corr_matrix, annot=True, cmap='coolwarm', center=0)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
