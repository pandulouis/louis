{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn import preprocessing\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.neural_network import MLPRegressor\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "from sklearn.metrics import r2_score\n",
    "from scipy.stats import pearsonr\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.feature_selection import SelectFromModel\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compiling complete dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_rf = pd.read_csv(\"df_isopul_lsa.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>lsa_0</th>\n",
       "      <th>lsa_1</th>\n",
       "      <th>lsa_2</th>\n",
       "      <th>lsa_3</th>\n",
       "      <th>lsa_4</th>\n",
       "      <th>hybrid</th>\n",
       "      <th>indica</th>\n",
       "      <th>sativa</th>\n",
       "      <th>anxiety</th>\n",
       "      <th>...</th>\n",
       "      <th>sweet</th>\n",
       "      <th>tar</th>\n",
       "      <th>tea</th>\n",
       "      <th>tobacco</th>\n",
       "      <th>tree</th>\n",
       "      <th>tropical</th>\n",
       "      <th>vanilla</th>\n",
       "      <th>violet</th>\n",
       "      <th>woody</th>\n",
       "      <th>X..Isopulegol</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3</td>\n",
       "      <td>0.243491</td>\n",
       "      <td>0.034313</td>\n",
       "      <td>0.080290</td>\n",
       "      <td>-0.165609</td>\n",
       "      <td>0.019773</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3</td>\n",
       "      <td>0.243491</td>\n",
       "      <td>0.034313</td>\n",
       "      <td>0.080290</td>\n",
       "      <td>-0.165609</td>\n",
       "      <td>0.019773</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>0.243491</td>\n",
       "      <td>0.034313</td>\n",
       "      <td>0.080290</td>\n",
       "      <td>-0.165609</td>\n",
       "      <td>0.019773</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>6</td>\n",
       "      <td>0.276418</td>\n",
       "      <td>-0.133986</td>\n",
       "      <td>0.116293</td>\n",
       "      <td>0.073694</td>\n",
       "      <td>0.041143</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>7</td>\n",
       "      <td>0.401841</td>\n",
       "      <td>-0.062527</td>\n",
       "      <td>-0.018128</td>\n",
       "      <td>-0.104475</td>\n",
       "      <td>0.009215</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49995</th>\n",
       "      <td>42965</td>\n",
       "      <td>0.360708</td>\n",
       "      <td>-0.269375</td>\n",
       "      <td>0.169135</td>\n",
       "      <td>0.099257</td>\n",
       "      <td>0.141142</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49996</th>\n",
       "      <td>42968</td>\n",
       "      <td>0.107417</td>\n",
       "      <td>-0.105614</td>\n",
       "      <td>-0.117669</td>\n",
       "      <td>-0.047306</td>\n",
       "      <td>0.055133</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49997</th>\n",
       "      <td>42969</td>\n",
       "      <td>0.109738</td>\n",
       "      <td>-0.066611</td>\n",
       "      <td>-0.064934</td>\n",
       "      <td>0.145920</td>\n",
       "      <td>-0.069040</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49998</th>\n",
       "      <td>42970</td>\n",
       "      <td>0.440634</td>\n",
       "      <td>-0.078839</td>\n",
       "      <td>0.085152</td>\n",
       "      <td>0.087878</td>\n",
       "      <td>-0.133604</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49999</th>\n",
       "      <td>42970</td>\n",
       "      <td>0.440634</td>\n",
       "      <td>-0.078839</td>\n",
       "      <td>0.085152</td>\n",
       "      <td>0.087878</td>\n",
       "      <td>-0.133604</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>50000 rows × 88 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       index     lsa_0     lsa_1     lsa_2     lsa_3     lsa_4  hybrid  \\\n",
       "0          3  0.243491  0.034313  0.080290 -0.165609  0.019773       1   \n",
       "1          3  0.243491  0.034313  0.080290 -0.165609  0.019773       1   \n",
       "2          3  0.243491  0.034313  0.080290 -0.165609  0.019773       1   \n",
       "3          6  0.276418 -0.133986  0.116293  0.073694  0.041143       1   \n",
       "4          7  0.401841 -0.062527 -0.018128 -0.104475  0.009215       1   \n",
       "...      ...       ...       ...       ...       ...       ...     ...   \n",
       "49995  42965  0.360708 -0.269375  0.169135  0.099257  0.141142       0   \n",
       "49996  42968  0.107417 -0.105614 -0.117669 -0.047306  0.055133       0   \n",
       "49997  42969  0.109738 -0.066611 -0.064934  0.145920 -0.069040       0   \n",
       "49998  42970  0.440634 -0.078839  0.085152  0.087878 -0.133604       0   \n",
       "49999  42970  0.440634 -0.078839  0.085152  0.087878 -0.133604       0   \n",
       "\n",
       "       indica  sativa  anxiety  ...  sweet  tar  tea  tobacco  tree  tropical  \\\n",
       "0           0       0        0  ...      0    1    0        0     0         0   \n",
       "1           0       0        0  ...      0    1    0        0     0         0   \n",
       "2           0       0        0  ...      0    1    0        0     0         0   \n",
       "3           0       0        0  ...      0    0    0        0     0         0   \n",
       "4           0       0        0  ...      0    1    0        0     0         0   \n",
       "...       ...     ...      ...  ...    ...  ...  ...      ...   ...       ...   \n",
       "49995       1       0        0  ...      0    0    0        0     0         0   \n",
       "49996       1       0        0  ...      0    0    0        0     0         0   \n",
       "49997       1       0        0  ...      0    0    0        0     0         0   \n",
       "49998       1       0        0  ...      0    0    0        0     0         0   \n",
       "49999       1       0        0  ...      0    0    0        0     0         0   \n",
       "\n",
       "       vanilla  violet  woody  X..Isopulegol  \n",
       "0            0       0      0            0.0  \n",
       "1            0       0      0            0.0  \n",
       "2            0       0      0            0.0  \n",
       "3            0       0      0            0.0  \n",
       "4            1       1      1            0.0  \n",
       "...        ...     ...    ...            ...  \n",
       "49995        0       0      0            0.0  \n",
       "49996        0       0      0            0.0  \n",
       "49997        0       0      0            0.0  \n",
       "49998        0       0      0            0.0  \n",
       "49999        0       0      0            0.0  \n",
       "\n",
       "[50000 rows x 88 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_rf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['index',\n",
       " 'lsa_0',\n",
       " 'lsa_1',\n",
       " 'lsa_2',\n",
       " 'lsa_3',\n",
       " 'lsa_4',\n",
       " 'hybrid',\n",
       " 'indica',\n",
       " 'sativa',\n",
       " 'anxiety',\n",
       " 'anxious',\n",
       " 'aroused',\n",
       " 'arthritis',\n",
       " 'creative',\n",
       " 'depression',\n",
       " 'dizzy',\n",
       " 'dry eyes',\n",
       " 'dry mouth',\n",
       " 'energetic',\n",
       " 'epilepsy',\n",
       " 'euphoric',\n",
       " 'eye pressure',\n",
       " 'fatigue',\n",
       " 'focused',\n",
       " 'giggly',\n",
       " 'happy',\n",
       " 'headache',\n",
       " 'hungry',\n",
       " 'migraines',\n",
       " 'pain',\n",
       " 'paranoid',\n",
       " 'relaxed',\n",
       " 'seizures',\n",
       " 'sleepy',\n",
       " 'spasticity',\n",
       " 'stress',\n",
       " 'talkative',\n",
       " 'tingly',\n",
       " 'uplifted',\n",
       " 'ammonia',\n",
       " 'apple',\n",
       " 'apricot',\n",
       " 'berry',\n",
       " 'blue cheese',\n",
       " 'blueberry',\n",
       " 'butter',\n",
       " 'cheese',\n",
       " 'chemical',\n",
       " 'chestnut',\n",
       " 'citrus',\n",
       " 'coffee',\n",
       " 'diesel',\n",
       " 'earthy',\n",
       " 'flowery',\n",
       " 'fruit',\n",
       " 'grape',\n",
       " 'grapefruit',\n",
       " 'honey',\n",
       " 'lavender',\n",
       " 'lemon',\n",
       " 'lime',\n",
       " 'mango',\n",
       " 'menthol',\n",
       " 'mint',\n",
       " 'nutty',\n",
       " 'orange',\n",
       " 'peach',\n",
       " 'pear',\n",
       " 'pepper',\n",
       " 'pine',\n",
       " 'pineapple',\n",
       " 'plum',\n",
       " 'pungent',\n",
       " 'rose',\n",
       " 'sage',\n",
       " 'skunk',\n",
       " 'spicy/herbal',\n",
       " 'strawberry',\n",
       " 'sweet',\n",
       " 'tar',\n",
       " 'tea',\n",
       " 'tobacco',\n",
       " 'tree',\n",
       " 'tropical',\n",
       " 'vanilla',\n",
       " 'violet',\n",
       " 'woody',\n",
       " 'X..Isopulegol']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_rf.columns.to_list()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Splitting dependent and independent variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df_rf.drop(['index', 'X..Isopulegol'], axis = 1)\n",
    "y = df_rf[['X..Isopulegol']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plotting histograms on target variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       ...,\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.]])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_array = y.to_numpy()\n",
    "y_array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Axes: ylabel='Count'>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "sns.histplot(y, bins = 10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train test split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=1, test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train1, X_val, y_train1, y_val = train_test_split(X_train, y_train, random_state=1, test_size=0.25)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "RF modeling (before Feature selection and Hyperparameter Tuning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/ns/m5pnr0211w91v02hpv22958m0000gn/T/ipykernel_3997/119766249.py:2: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  rfreg.fit(X_train1, y_train1)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;background-color: white;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>RandomForestRegressor(n_jobs=-1)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">RandomForestRegressor</label><div class=\"sk-toggleable__content\"><pre>RandomForestRegressor(n_jobs=-1)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "RandomForestRegressor(n_jobs=-1)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rfreg = RandomForestRegressor(n_jobs = -1)\n",
    "rfreg.fit(X_train1, y_train1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_rfreg = rfreg.predict(X_val)\n",
    "y_pred_rfreg_r2 = rfreg.predict(X_train1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.02205743166184277"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mean_absolute_error(y_val, y_pred_rfreg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.005482627738447913"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mean_squared_error(y_val, y_pred_rfreg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.07404476847453785"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mean_squared_error(y_val, y_pred_rfreg, squared = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9918282937303541"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#train\n",
    "r2_score(y_train1, y_pred_rfreg_r2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9780691021851708"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#val\n",
    "r2_score(y_val, y_pred_rfreg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Residual plots for each target variable"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Feature Selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_feat = pd.DataFrame({\n",
    "    \"features\": X_train1.columns,\n",
    "    \"score\": rfreg.feature_importances_\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>features</th>\n",
       "      <th>score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>lsa_0</td>\n",
       "      <td>0.087061</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>lsa_1</td>\n",
       "      <td>0.080814</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>lsa_2</td>\n",
       "      <td>0.100146</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>lsa_3</td>\n",
       "      <td>0.084599</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>lsa_4</td>\n",
       "      <td>0.081989</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>81</th>\n",
       "      <td>tree</td>\n",
       "      <td>0.000964</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>82</th>\n",
       "      <td>tropical</td>\n",
       "      <td>0.002431</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>83</th>\n",
       "      <td>vanilla</td>\n",
       "      <td>0.002033</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>84</th>\n",
       "      <td>violet</td>\n",
       "      <td>0.000162</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>85</th>\n",
       "      <td>woody</td>\n",
       "      <td>0.003010</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>86 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    features     score\n",
       "0      lsa_0  0.087061\n",
       "1      lsa_1  0.080814\n",
       "2      lsa_2  0.100146\n",
       "3      lsa_3  0.084599\n",
       "4      lsa_4  0.081989\n",
       "..       ...       ...\n",
       "81      tree  0.000964\n",
       "82  tropical  0.002431\n",
       "83   vanilla  0.002033\n",
       "84    violet  0.000162\n",
       "85     woody  0.003010\n",
       "\n",
       "[86 rows x 2 columns]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_feat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_feat_ranked = df_feat.sort_values(\"score\", ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>features</th>\n",
       "      <th>score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>hybrid</td>\n",
       "      <td>0.296976</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>lsa_2</td>\n",
       "      <td>0.100146</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>lsa_0</td>\n",
       "      <td>0.087061</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>lsa_3</td>\n",
       "      <td>0.084599</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>lsa_4</td>\n",
       "      <td>0.081989</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>lsa_1</td>\n",
       "      <td>0.080814</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50</th>\n",
       "      <td>diesel</td>\n",
       "      <td>0.019626</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>64</th>\n",
       "      <td>orange</td>\n",
       "      <td>0.015257</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>cheese</td>\n",
       "      <td>0.013125</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>58</th>\n",
       "      <td>lemon</td>\n",
       "      <td>0.012270</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52</th>\n",
       "      <td>flowery</td>\n",
       "      <td>0.011462</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>relaxed</td>\n",
       "      <td>0.011076</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>aroused</td>\n",
       "      <td>0.010247</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>giggly</td>\n",
       "      <td>0.008263</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>happy</td>\n",
       "      <td>0.007401</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>citrus</td>\n",
       "      <td>0.007306</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>energetic</td>\n",
       "      <td>0.007185</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>talkative</td>\n",
       "      <td>0.006748</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>77</th>\n",
       "      <td>sweet</td>\n",
       "      <td>0.006621</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>berry</td>\n",
       "      <td>0.006499</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54</th>\n",
       "      <td>grape</td>\n",
       "      <td>0.006495</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>68</th>\n",
       "      <td>pine</td>\n",
       "      <td>0.006260</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51</th>\n",
       "      <td>earthy</td>\n",
       "      <td>0.006175</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>74</th>\n",
       "      <td>skunk</td>\n",
       "      <td>0.005753</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>euphoric</td>\n",
       "      <td>0.005684</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>62</th>\n",
       "      <td>mint</td>\n",
       "      <td>0.005526</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>sleepy</td>\n",
       "      <td>0.005291</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>uplifted</td>\n",
       "      <td>0.005160</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>dry mouth</td>\n",
       "      <td>0.004921</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>focused</td>\n",
       "      <td>0.004874</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>creative</td>\n",
       "      <td>0.004778</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>tingly</td>\n",
       "      <td>0.004716</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>blueberry</td>\n",
       "      <td>0.004346</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>hungry</td>\n",
       "      <td>0.004288</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>dizzy</td>\n",
       "      <td>0.004148</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>dry eyes</td>\n",
       "      <td>0.004015</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75</th>\n",
       "      <td>spicy/herbal</td>\n",
       "      <td>0.003685</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>71</th>\n",
       "      <td>pungent</td>\n",
       "      <td>0.003301</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>85</th>\n",
       "      <td>woody</td>\n",
       "      <td>0.003010</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>57</th>\n",
       "      <td>lavender</td>\n",
       "      <td>0.002639</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>headache</td>\n",
       "      <td>0.002498</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>82</th>\n",
       "      <td>tropical</td>\n",
       "      <td>0.002431</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>paranoid</td>\n",
       "      <td>0.002393</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>anxious</td>\n",
       "      <td>0.002141</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>83</th>\n",
       "      <td>vanilla</td>\n",
       "      <td>0.002033</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>63</th>\n",
       "      <td>nutty</td>\n",
       "      <td>0.001605</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>55</th>\n",
       "      <td>grapefruit</td>\n",
       "      <td>0.001469</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>chemical</td>\n",
       "      <td>0.001321</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53</th>\n",
       "      <td>fruit</td>\n",
       "      <td>0.001275</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>70</th>\n",
       "      <td>plum</td>\n",
       "      <td>0.001252</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>60</th>\n",
       "      <td>mango</td>\n",
       "      <td>0.001145</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59</th>\n",
       "      <td>lime</td>\n",
       "      <td>0.001071</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>65</th>\n",
       "      <td>peach</td>\n",
       "      <td>0.001021</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>81</th>\n",
       "      <td>tree</td>\n",
       "      <td>0.000964</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>67</th>\n",
       "      <td>pepper</td>\n",
       "      <td>0.000861</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>79</th>\n",
       "      <td>tea</td>\n",
       "      <td>0.000848</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>61</th>\n",
       "      <td>menthol</td>\n",
       "      <td>0.000715</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>69</th>\n",
       "      <td>pineapple</td>\n",
       "      <td>0.000709</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>56</th>\n",
       "      <td>honey</td>\n",
       "      <td>0.000622</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>apricot</td>\n",
       "      <td>0.000587</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>73</th>\n",
       "      <td>sage</td>\n",
       "      <td>0.000554</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>76</th>\n",
       "      <td>strawberry</td>\n",
       "      <td>0.000457</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>butter</td>\n",
       "      <td>0.000324</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>apple</td>\n",
       "      <td>0.000323</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>80</th>\n",
       "      <td>tobacco</td>\n",
       "      <td>0.000311</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>72</th>\n",
       "      <td>rose</td>\n",
       "      <td>0.000259</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>chestnut</td>\n",
       "      <td>0.000252</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>coffee</td>\n",
       "      <td>0.000169</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>84</th>\n",
       "      <td>violet</td>\n",
       "      <td>0.000162</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>blue cheese</td>\n",
       "      <td>0.000155</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>ammonia</td>\n",
       "      <td>0.000117</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>78</th>\n",
       "      <td>tar</td>\n",
       "      <td>0.000065</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>66</th>\n",
       "      <td>pear</td>\n",
       "      <td>0.000058</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>migraines</td>\n",
       "      <td>0.000030</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>depression</td>\n",
       "      <td>0.000028</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>anxiety</td>\n",
       "      <td>0.000027</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>stress</td>\n",
       "      <td>0.000004</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>spasticity</td>\n",
       "      <td>0.000001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>indica</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>sativa</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>eye pressure</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>arthritis</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>pain</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>seizures</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>fatigue</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>epilepsy</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        features     score\n",
       "5         hybrid  0.296976\n",
       "2          lsa_2  0.100146\n",
       "0          lsa_0  0.087061\n",
       "3          lsa_3  0.084599\n",
       "4          lsa_4  0.081989\n",
       "1          lsa_1  0.080814\n",
       "50        diesel  0.019626\n",
       "64        orange  0.015257\n",
       "45        cheese  0.013125\n",
       "58         lemon  0.012270\n",
       "52       flowery  0.011462\n",
       "30       relaxed  0.011076\n",
       "10       aroused  0.010247\n",
       "23        giggly  0.008263\n",
       "24         happy  0.007401\n",
       "48        citrus  0.007306\n",
       "17     energetic  0.007185\n",
       "35     talkative  0.006748\n",
       "77         sweet  0.006621\n",
       "41         berry  0.006499\n",
       "54         grape  0.006495\n",
       "68          pine  0.006260\n",
       "51        earthy  0.006175\n",
       "74         skunk  0.005753\n",
       "19      euphoric  0.005684\n",
       "62          mint  0.005526\n",
       "32        sleepy  0.005291\n",
       "37      uplifted  0.005160\n",
       "16     dry mouth  0.004921\n",
       "22       focused  0.004874\n",
       "12      creative  0.004778\n",
       "36        tingly  0.004716\n",
       "43     blueberry  0.004346\n",
       "26        hungry  0.004288\n",
       "14         dizzy  0.004148\n",
       "15      dry eyes  0.004015\n",
       "75  spicy/herbal  0.003685\n",
       "71       pungent  0.003301\n",
       "85         woody  0.003010\n",
       "57      lavender  0.002639\n",
       "25      headache  0.002498\n",
       "82      tropical  0.002431\n",
       "29      paranoid  0.002393\n",
       "9        anxious  0.002141\n",
       "83       vanilla  0.002033\n",
       "63         nutty  0.001605\n",
       "55    grapefruit  0.001469\n",
       "46      chemical  0.001321\n",
       "53         fruit  0.001275\n",
       "70          plum  0.001252\n",
       "60         mango  0.001145\n",
       "59          lime  0.001071\n",
       "65         peach  0.001021\n",
       "81          tree  0.000964\n",
       "67        pepper  0.000861\n",
       "79           tea  0.000848\n",
       "61       menthol  0.000715\n",
       "69     pineapple  0.000709\n",
       "56         honey  0.000622\n",
       "40       apricot  0.000587\n",
       "73          sage  0.000554\n",
       "76    strawberry  0.000457\n",
       "44        butter  0.000324\n",
       "39         apple  0.000323\n",
       "80       tobacco  0.000311\n",
       "72          rose  0.000259\n",
       "47      chestnut  0.000252\n",
       "49        coffee  0.000169\n",
       "84        violet  0.000162\n",
       "42   blue cheese  0.000155\n",
       "38       ammonia  0.000117\n",
       "78           tar  0.000065\n",
       "66          pear  0.000058\n",
       "27     migraines  0.000030\n",
       "13    depression  0.000028\n",
       "8        anxiety  0.000027\n",
       "34        stress  0.000004\n",
       "33    spasticity  0.000001\n",
       "6         indica  0.000000\n",
       "7         sativa  0.000000\n",
       "20  eye pressure  0.000000\n",
       "11     arthritis  0.000000\n",
       "28          pain  0.000000\n",
       "31      seizures  0.000000\n",
       "21       fatigue  0.000000\n",
       "18      epilepsy  0.000000"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.set_option('display.max_rows', df_feat_ranked.shape[0]+1)\n",
    "df_feat_ranked"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/louispandu/anaconda3/lib/python3.10/site-packages/sklearn/feature_selection/_from_model.py:357: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  self.estimator_.fit(X, y, **fit_params)\n"
     ]
    }
   ],
   "source": [
    "selector = SelectFromModel(rfreg).fit(X_train1, y_train1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([8.83165855e-02, 8.46394890e-02, 1.01812573e-01, 8.16095586e-02,\n",
       "       8.08276349e-02, 2.96812314e-01, 0.00000000e+00, 0.00000000e+00,\n",
       "       2.30033100e-05, 2.18983016e-03, 1.00911231e-02, 0.00000000e+00,\n",
       "       4.59731757e-03, 4.61656189e-05, 4.13617078e-03, 4.52681234e-03,\n",
       "       5.08863401e-03, 7.35580795e-03, 0.00000000e+00, 5.40202710e-03,\n",
       "       0.00000000e+00, 0.00000000e+00, 5.25284189e-03, 7.84555649e-03,\n",
       "       7.12577252e-03, 2.66197011e-03, 4.43515819e-03, 2.71267131e-05,\n",
       "       0.00000000e+00, 2.22861980e-03, 1.04026082e-02, 0.00000000e+00,\n",
       "       4.97968339e-03, 0.00000000e+00, 0.00000000e+00, 6.61903997e-03,\n",
       "       4.37344040e-03, 4.46873491e-03, 1.43465024e-04, 2.59972475e-04,\n",
       "       4.35681061e-04, 6.12129853e-03, 1.29640271e-04, 4.20166283e-03,\n",
       "       2.15981398e-04, 1.31214284e-02, 1.28058314e-03, 2.85612013e-04,\n",
       "       7.20271485e-03, 2.09437331e-04, 1.96433918e-02, 6.28338950e-03,\n",
       "       1.22027703e-02, 1.17280841e-03, 7.29676208e-03, 1.51028013e-03,\n",
       "       7.92067238e-04, 2.61205788e-03, 1.31492483e-02, 1.09149659e-03,\n",
       "       1.04670527e-03, 8.77406685e-04, 6.04012936e-03, 1.15745096e-03,\n",
       "       1.52890721e-02, 7.01875523e-04, 3.89242528e-05, 7.69563806e-04,\n",
       "       6.11680787e-03, 6.23337334e-04, 1.25407192e-03, 3.24892414e-03,\n",
       "       1.86544828e-04, 5.30335154e-04, 5.13917565e-03, 2.96032055e-03,\n",
       "       3.69987714e-04, 6.55740236e-03, 1.41477416e-04, 9.94821926e-04,\n",
       "       2.59871223e-04, 1.09178929e-03, 1.94231088e-03, 1.90628091e-03,\n",
       "       2.19343347e-04, 3.27872022e-03])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "selector.estimator_.feature_importances_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.01162790697674419"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "selector.threshold_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "mask = selector.get_support()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ True,  True,  True,  True,  True,  True, False, False, False,\n",
       "       False, False, False, False, False, False, False, False, False,\n",
       "       False, False, False, False, False, False, False, False, False,\n",
       "       False, False, False, False, False, False, False, False, False,\n",
       "       False, False, False, False, False, False, False, False, False,\n",
       "        True, False, False, False, False,  True, False,  True, False,\n",
       "       False, False, False, False,  True, False, False, False, False,\n",
       "       False,  True, False, False, False, False, False, False, False,\n",
       "       False, False, False, False, False, False, False, False, False,\n",
       "       False, False, False, False, False])"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "selected_features = X.columns[mask]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>lsa_0</th>\n",
       "      <th>lsa_1</th>\n",
       "      <th>lsa_2</th>\n",
       "      <th>lsa_3</th>\n",
       "      <th>lsa_4</th>\n",
       "      <th>hybrid</th>\n",
       "      <th>cheese</th>\n",
       "      <th>diesel</th>\n",
       "      <th>flowery</th>\n",
       "      <th>lemon</th>\n",
       "      <th>orange</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.243491</td>\n",
       "      <td>0.034313</td>\n",
       "      <td>0.080290</td>\n",
       "      <td>-0.165609</td>\n",
       "      <td>0.019773</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.243491</td>\n",
       "      <td>0.034313</td>\n",
       "      <td>0.080290</td>\n",
       "      <td>-0.165609</td>\n",
       "      <td>0.019773</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.243491</td>\n",
       "      <td>0.034313</td>\n",
       "      <td>0.080290</td>\n",
       "      <td>-0.165609</td>\n",
       "      <td>0.019773</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.276418</td>\n",
       "      <td>-0.133986</td>\n",
       "      <td>0.116293</td>\n",
       "      <td>0.073694</td>\n",
       "      <td>0.041143</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.401841</td>\n",
       "      <td>-0.062527</td>\n",
       "      <td>-0.018128</td>\n",
       "      <td>-0.104475</td>\n",
       "      <td>0.009215</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49995</th>\n",
       "      <td>0.360708</td>\n",
       "      <td>-0.269375</td>\n",
       "      <td>0.169135</td>\n",
       "      <td>0.099257</td>\n",
       "      <td>0.141142</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49996</th>\n",
       "      <td>0.107417</td>\n",
       "      <td>-0.105614</td>\n",
       "      <td>-0.117669</td>\n",
       "      <td>-0.047306</td>\n",
       "      <td>0.055133</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49997</th>\n",
       "      <td>0.109738</td>\n",
       "      <td>-0.066611</td>\n",
       "      <td>-0.064934</td>\n",
       "      <td>0.145920</td>\n",
       "      <td>-0.069040</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49998</th>\n",
       "      <td>0.440634</td>\n",
       "      <td>-0.078839</td>\n",
       "      <td>0.085152</td>\n",
       "      <td>0.087878</td>\n",
       "      <td>-0.133604</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49999</th>\n",
       "      <td>0.440634</td>\n",
       "      <td>-0.078839</td>\n",
       "      <td>0.085152</td>\n",
       "      <td>0.087878</td>\n",
       "      <td>-0.133604</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>50000 rows × 11 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          lsa_0     lsa_1     lsa_2     lsa_3     lsa_4  hybrid  cheese  \\\n",
       "0      0.243491  0.034313  0.080290 -0.165609  0.019773       1       1   \n",
       "1      0.243491  0.034313  0.080290 -0.165609  0.019773       1       1   \n",
       "2      0.243491  0.034313  0.080290 -0.165609  0.019773       1       1   \n",
       "3      0.276418 -0.133986  0.116293  0.073694  0.041143       1       0   \n",
       "4      0.401841 -0.062527 -0.018128 -0.104475  0.009215       1       0   \n",
       "...         ...       ...       ...       ...       ...     ...     ...   \n",
       "49995  0.360708 -0.269375  0.169135  0.099257  0.141142       0       0   \n",
       "49996  0.107417 -0.105614 -0.117669 -0.047306  0.055133       0       0   \n",
       "49997  0.109738 -0.066611 -0.064934  0.145920 -0.069040       0       0   \n",
       "49998  0.440634 -0.078839  0.085152  0.087878 -0.133604       0       0   \n",
       "49999  0.440634 -0.078839  0.085152  0.087878 -0.133604       0       0   \n",
       "\n",
       "       diesel  flowery  lemon  orange  \n",
       "0           0        0      0       0  \n",
       "1           0        0      0       0  \n",
       "2           0        0      0       0  \n",
       "3           0        0      0       0  \n",
       "4           0        0      0       0  \n",
       "...       ...      ...    ...     ...  \n",
       "49995       0        0      0       0  \n",
       "49996       0        0      0       0  \n",
       "49997       0        0      0       0  \n",
       "49998       0        0      0       0  \n",
       "49999       0        0      0       0  \n",
       "\n",
       "[50000 rows x 11 columns]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "selected_X = df_rf[selected_features]\n",
    "selected_X"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train test split (after Feature Selection)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['selected_X_rf_lsa_elbow_isopul.pkl']"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import joblib\n",
    "\n",
    "joblib.dump(selector, \"selector_rf_lsa_elbow_isopul.pkl\")\n",
    "joblib.dump(selected_X, \"selected_X_rf_lsa_elbow_isopul.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(selected_X, y, random_state=1, test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train1, X_val, y_train1, y_val = train_test_split(X_train, y_train, random_state=1, test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/ns/m5pnr0211w91v02hpv22958m0000gn/T/ipykernel_3997/3758305.py:1: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  rfreg.fit(X_train1, y_train1)\n"
     ]
    }
   ],
   "source": [
    "rfreg.fit(X_train1, y_train1)\n",
    "y_pred_rfreg = rfreg.predict(X_val)\n",
    "y_pred_rfreg_r2 = rfreg.predict(X_train1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.023026542654295597"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mean_absolute_error(y_val, y_pred_rfreg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0071934514634623276"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mean_squared_error(y_val, y_pred_rfreg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.08481421734274465"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mean_squared_error(y_val, y_pred_rfreg, squared = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9860116161925745"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#train\n",
    "r2_score(y_train1, y_pred_rfreg_r2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9712259765425983"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#val\n",
    "r2_score(y_val, y_pred_rfreg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hyperparameter Tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "parameters = { 'max_depth': [None, 10, 50, 100],\n",
    "              'max_features': ['auto', 'sqrt'],\n",
    "              'min_samples_leaf': [1, 2, 4],\n",
    "              'min_samples_split': [2, 5, 10],\n",
    "              'n_estimators': [100, 300, 500]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "rscv = RandomizedSearchCV(rfreg,  \n",
    "                     parameters,   \n",
    "                     cv=5, \n",
    "                     scoring='neg_mean_absolute_error',\n",
    "                     n_jobs= -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/louispandu/anaconda3/lib/python3.10/site-packages/sklearn/model_selection/_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/Users/louispandu/anaconda3/lib/python3.10/site-packages/sklearn/model_selection/_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/Users/louispandu/anaconda3/lib/python3.10/site-packages/sklearn/model_selection/_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/Users/louispandu/anaconda3/lib/python3.10/site-packages/sklearn/model_selection/_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/Users/louispandu/anaconda3/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
      "  warn(\n",
      "/Users/louispandu/anaconda3/lib/python3.10/site-packages/sklearn/model_selection/_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/Users/louispandu/anaconda3/lib/python3.10/site-packages/sklearn/model_selection/_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/Users/louispandu/anaconda3/lib/python3.10/site-packages/sklearn/model_selection/_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/Users/louispandu/anaconda3/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
      "  warn(\n",
      "/Users/louispandu/anaconda3/lib/python3.10/site-packages/sklearn/model_selection/_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/Users/louispandu/anaconda3/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
      "  warn(\n",
      "/Users/louispandu/anaconda3/lib/python3.10/site-packages/sklearn/model_selection/_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/Users/louispandu/anaconda3/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
      "  warn(\n",
      "/Users/louispandu/anaconda3/lib/python3.10/site-packages/sklearn/model_selection/_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/Users/louispandu/anaconda3/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
      "  warn(\n",
      "/Users/louispandu/anaconda3/lib/python3.10/site-packages/sklearn/model_selection/_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/Users/louispandu/anaconda3/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
      "  warn(\n",
      "/Users/louispandu/anaconda3/lib/python3.10/site-packages/sklearn/model_selection/_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/Users/louispandu/anaconda3/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
      "  warn(\n",
      "/Users/louispandu/anaconda3/lib/python3.10/site-packages/sklearn/model_selection/_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/Users/louispandu/anaconda3/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
      "  warn(\n",
      "/Users/louispandu/anaconda3/lib/python3.10/site-packages/sklearn/model_selection/_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/Users/louispandu/anaconda3/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
      "  warn(\n",
      "/Users/louispandu/anaconda3/lib/python3.10/site-packages/sklearn/model_selection/_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/Users/louispandu/anaconda3/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
      "  warn(\n",
      "/Users/louispandu/anaconda3/lib/python3.10/site-packages/sklearn/model_selection/_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/Users/louispandu/anaconda3/lib/python3.10/site-packages/sklearn/model_selection/_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/Users/louispandu/anaconda3/lib/python3.10/site-packages/sklearn/model_selection/_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/Users/louispandu/anaconda3/lib/python3.10/site-packages/sklearn/model_selection/_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/Users/louispandu/anaconda3/lib/python3.10/site-packages/sklearn/model_selection/_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/Users/louispandu/anaconda3/lib/python3.10/site-packages/sklearn/model_selection/_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/Users/louispandu/anaconda3/lib/python3.10/site-packages/sklearn/model_selection/_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/Users/louispandu/anaconda3/lib/python3.10/site-packages/sklearn/model_selection/_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/Users/louispandu/anaconda3/lib/python3.10/site-packages/sklearn/model_selection/_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/Users/louispandu/anaconda3/lib/python3.10/site-packages/sklearn/model_selection/_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/Users/louispandu/anaconda3/lib/python3.10/site-packages/sklearn/model_selection/_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/Users/louispandu/anaconda3/lib/python3.10/site-packages/sklearn/model_selection/_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/Users/louispandu/anaconda3/lib/python3.10/site-packages/sklearn/model_selection/_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/Users/louispandu/anaconda3/lib/python3.10/site-packages/sklearn/model_selection/_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/Users/louispandu/anaconda3/lib/python3.10/site-packages/sklearn/model_selection/_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/Users/louispandu/anaconda3/lib/python3.10/site-packages/sklearn/model_selection/_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/Users/louispandu/anaconda3/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
      "  warn(\n",
      "/Users/louispandu/anaconda3/lib/python3.10/site-packages/sklearn/model_selection/_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/Users/louispandu/anaconda3/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
      "  warn(\n",
      "/Users/louispandu/anaconda3/lib/python3.10/site-packages/sklearn/model_selection/_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/Users/louispandu/anaconda3/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
      "  warn(\n",
      "/Users/louispandu/anaconda3/lib/python3.10/site-packages/sklearn/model_selection/_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/Users/louispandu/anaconda3/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
      "  warn(\n",
      "/Users/louispandu/anaconda3/lib/python3.10/site-packages/sklearn/model_selection/_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/Users/louispandu/anaconda3/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
      "  warn(\n",
      "/Users/louispandu/anaconda3/lib/python3.10/site-packages/sklearn/model_selection/_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/Users/louispandu/anaconda3/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
      "  warn(\n",
      "/Users/louispandu/anaconda3/lib/python3.10/site-packages/sklearn/model_selection/_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/Users/louispandu/anaconda3/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
      "  warn(\n",
      "/Users/louispandu/anaconda3/lib/python3.10/site-packages/sklearn/model_selection/_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/Users/louispandu/anaconda3/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
      "  warn(\n",
      "/Users/louispandu/anaconda3/lib/python3.10/site-packages/sklearn/model_selection/_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/Users/louispandu/anaconda3/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
      "  warn(\n",
      "/Users/louispandu/anaconda3/lib/python3.10/site-packages/sklearn/model_selection/_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/Users/louispandu/anaconda3/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
      "  warn(\n",
      "/Users/louispandu/anaconda3/lib/python3.10/site-packages/sklearn/model_selection/_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/Users/louispandu/anaconda3/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
      "  warn(\n",
      "/Users/louispandu/anaconda3/lib/python3.10/site-packages/sklearn/model_selection/_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/Users/louispandu/anaconda3/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
      "  warn(\n",
      "/Users/louispandu/anaconda3/lib/python3.10/site-packages/sklearn/model_selection/_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/Users/louispandu/anaconda3/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
      "  warn(\n",
      "/Users/louispandu/anaconda3/lib/python3.10/site-packages/sklearn/model_selection/_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/Users/louispandu/anaconda3/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
      "  warn(\n",
      "/Users/louispandu/anaconda3/lib/python3.10/site-packages/sklearn/model_selection/_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/Users/louispandu/anaconda3/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
      "  warn(\n",
      "/Users/louispandu/anaconda3/lib/python3.10/site-packages/sklearn/model_selection/_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/Users/louispandu/anaconda3/lib/python3.10/site-packages/sklearn/model_selection/_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/Users/louispandu/anaconda3/lib/python3.10/site-packages/sklearn/model_selection/_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/Users/louispandu/anaconda3/lib/python3.10/site-packages/sklearn/model_selection/_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/Users/louispandu/anaconda3/lib/python3.10/site-packages/sklearn/model_selection/_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/Users/louispandu/anaconda3/lib/python3.10/site-packages/sklearn/model_selection/_search.py:909: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  self.best_estimator_.fit(X, y, **fit_params)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-2 {color: black;background-color: white;}#sk-container-id-2 pre{padding: 0;}#sk-container-id-2 div.sk-toggleable {background-color: white;}#sk-container-id-2 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-2 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-2 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-2 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-2 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-2 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-2 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-2 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-2 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-2 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-2 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-2 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-2 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-2 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-2 div.sk-item {position: relative;z-index: 1;}#sk-container-id-2 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-2 div.sk-item::before, #sk-container-id-2 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-2 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-2 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-2 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-2 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-2 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-2 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-2 div.sk-label-container {text-align: center;}#sk-container-id-2 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-2 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-2\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>RandomizedSearchCV(cv=5, estimator=RandomForestRegressor(n_jobs=-1), n_jobs=-1,\n",
       "                   param_distributions={&#x27;max_depth&#x27;: [None, 10, 50, 100],\n",
       "                                        &#x27;max_features&#x27;: [&#x27;auto&#x27;, &#x27;sqrt&#x27;],\n",
       "                                        &#x27;min_samples_leaf&#x27;: [1, 2, 4],\n",
       "                                        &#x27;min_samples_split&#x27;: [2, 5, 10],\n",
       "                                        &#x27;n_estimators&#x27;: [100, 300, 500]},\n",
       "                   scoring=&#x27;neg_mean_absolute_error&#x27;)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" ><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">RandomizedSearchCV</label><div class=\"sk-toggleable__content\"><pre>RandomizedSearchCV(cv=5, estimator=RandomForestRegressor(n_jobs=-1), n_jobs=-1,\n",
       "                   param_distributions={&#x27;max_depth&#x27;: [None, 10, 50, 100],\n",
       "                                        &#x27;max_features&#x27;: [&#x27;auto&#x27;, &#x27;sqrt&#x27;],\n",
       "                                        &#x27;min_samples_leaf&#x27;: [1, 2, 4],\n",
       "                                        &#x27;min_samples_split&#x27;: [2, 5, 10],\n",
       "                                        &#x27;n_estimators&#x27;: [100, 300, 500]},\n",
       "                   scoring=&#x27;neg_mean_absolute_error&#x27;)</pre></div></div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-3\" type=\"checkbox\" ><label for=\"sk-estimator-id-3\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">estimator: RandomForestRegressor</label><div class=\"sk-toggleable__content\"><pre>RandomForestRegressor(n_jobs=-1)</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-4\" type=\"checkbox\" ><label for=\"sk-estimator-id-4\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">RandomForestRegressor</label><div class=\"sk-toggleable__content\"><pre>RandomForestRegressor(n_jobs=-1)</pre></div></div></div></div></div></div></div></div></div></div>"
      ],
      "text/plain": [
       "RandomizedSearchCV(cv=5, estimator=RandomForestRegressor(n_jobs=-1), n_jobs=-1,\n",
       "                   param_distributions={'max_depth': [None, 10, 50, 100],\n",
       "                                        'max_features': ['auto', 'sqrt'],\n",
       "                                        'min_samples_leaf': [1, 2, 4],\n",
       "                                        'min_samples_split': [2, 5, 10],\n",
       "                                        'n_estimators': [100, 300, 500]},\n",
       "                   scoring='neg_mean_absolute_error')"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rscv.fit(X_train1, y_train1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'n_estimators': 500,\n",
       " 'min_samples_split': 2,\n",
       " 'min_samples_leaf': 1,\n",
       " 'max_features': 'sqrt',\n",
       " 'max_depth': 50}"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rscv.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['rscv_rf_lsa_elbow_best_params_isopul.pkl']"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "joblib.dump(rscv, \"rscv_rf_lsa_elbow_isopul.pkl\")\n",
    "joblib.dump(rscv.best_params_, \"rscv_rf_lsa_elbow_best_params_isopul.pkl\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "RF (after Hyperparameter Tuning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/ns/m5pnr0211w91v02hpv22958m0000gn/T/ipykernel_3997/2121118255.py:2: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  rfreg_ht.fit(X_train1, y_train1)\n"
     ]
    }
   ],
   "source": [
    "rfreg_ht = RandomForestRegressor(n_estimators = 500, min_samples_split = 2, max_features = 'sqrt', min_samples_leaf = 1, max_depth = 50)\n",
    "rfreg_ht.fit(X_train1, y_train1)\n",
    "y_pred_rfreg = rfreg_ht.predict(X_val)\n",
    "y_pred_rfreg_r2 = rfreg_ht.predict(X_train1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.02230006946800364"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mean_absolute_error(y_val, y_pred_rfreg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.006053326235755318"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mean_squared_error(y_val, y_pred_rfreg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.07780312484569832"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mean_squared_error(y_val, y_pred_rfreg, squared = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9867216313289273"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#train\n",
    "r2_score(y_train1, y_pred_rfreg_r2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9757865119424753"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#val\n",
    "r2_score(y_val, y_pred_rfreg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Residual plots after Hyperparameter Tuning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Predicting model on the test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_rfreg_test = rfreg_ht.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['y_test_rfreg_lsa_elbow_isopul.pkl']"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "joblib.dump(y_pred_rfreg_test, \"y_pred_rfreg_test_lsa_elbow_isopul.pkl\")\n",
    "joblib.dump(y_test, \"y_test_rfreg_lsa_elbow_isopul.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.020853330053179752"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mean_absolute_error(y_test, y_pred_rfreg_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.005075960986327629"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mean_squared_error(y_test, y_pred_rfreg_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.07124577872637529"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mean_squared_error(y_test, y_pred_rfreg_test, squared = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9796920611619022"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "r2_score(y_test, y_pred_rfreg_test)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Error analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 800x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# assume y_pred is a numpy array and y_true is a pandas dataframe\n",
    "fig, ax = plt.subplots(figsize=(8, 6))\n",
    "\n",
    "column = \"X..Isopulegol\"  # specify the target variable name\n",
    "ax.hist(y_pred_rfreg_test, alpha=0.5, label='y_pred', bins=20)\n",
    "ax.hist(y_test[column], alpha=0.5, label='y_true', bins=20)\n",
    "ax.legend(loc='upper right')\n",
    "ax.set_title(column)\n",
    "\n",
    "plt.show()\n",
    "plt.savefig('error_hist_rf_lsa_elbow_isopul.png')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pearson R"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pearson correlation coefficient: 0.991\n",
      "P-value: 0.000\n"
     ]
    }
   ],
   "source": [
    "corr_coef, p_value = pearsonr(y_pred_rfreg_test.flatten(), y_test.values.ravel())\n",
    "\n",
    "print(f\"Pearson correlation coefficient: {corr_coef:.3f}\")\n",
    "print(f\"P-value: {p_value:.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Axes: >"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "corr_matrix = y_test.corr()\n",
    "sns.heatmap(corr_matrix, annot=True, cmap='coolwarm', center=0)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
