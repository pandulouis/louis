{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn import preprocessing\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.neural_network import MLPRegressor\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "from sklearn.metrics import r2_score\n",
    "from scipy.stats import pearsonr\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.feature_selection import SelectFromModel\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compiling complete dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_mlp = pd.read_csv(\"df_cbc_lsa.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>lsa_0</th>\n",
       "      <th>lsa_1</th>\n",
       "      <th>lsa_2</th>\n",
       "      <th>lsa_3</th>\n",
       "      <th>lsa_4</th>\n",
       "      <th>hybrid</th>\n",
       "      <th>indica</th>\n",
       "      <th>sativa</th>\n",
       "      <th>anxiety</th>\n",
       "      <th>...</th>\n",
       "      <th>sweet</th>\n",
       "      <th>tar</th>\n",
       "      <th>tea</th>\n",
       "      <th>tobacco</th>\n",
       "      <th>tree</th>\n",
       "      <th>tropical</th>\n",
       "      <th>vanilla</th>\n",
       "      <th>violet</th>\n",
       "      <th>woody</th>\n",
       "      <th>X..CBC</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0.341025</td>\n",
       "      <td>0.182753</td>\n",
       "      <td>0.008214</td>\n",
       "      <td>0.140406</td>\n",
       "      <td>-0.156943</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.175439</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0.232158</td>\n",
       "      <td>-0.045496</td>\n",
       "      <td>0.187131</td>\n",
       "      <td>-0.000936</td>\n",
       "      <td>0.018518</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.175439</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>0.243491</td>\n",
       "      <td>0.034313</td>\n",
       "      <td>0.080290</td>\n",
       "      <td>-0.165609</td>\n",
       "      <td>0.019773</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.175439</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>0.243491</td>\n",
       "      <td>0.034313</td>\n",
       "      <td>0.080290</td>\n",
       "      <td>-0.165609</td>\n",
       "      <td>0.019773</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.175439</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>0.238648</td>\n",
       "      <td>-0.048758</td>\n",
       "      <td>-0.107398</td>\n",
       "      <td>-0.067096</td>\n",
       "      <td>-0.006558</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.175439</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>74995</th>\n",
       "      <td>42975</td>\n",
       "      <td>0.324915</td>\n",
       "      <td>0.131823</td>\n",
       "      <td>-0.099424</td>\n",
       "      <td>0.065491</td>\n",
       "      <td>0.038437</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.614035</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>74996</th>\n",
       "      <td>42975</td>\n",
       "      <td>0.324915</td>\n",
       "      <td>0.131823</td>\n",
       "      <td>-0.099424</td>\n",
       "      <td>0.065491</td>\n",
       "      <td>0.038437</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.614035</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>74997</th>\n",
       "      <td>42975</td>\n",
       "      <td>0.324915</td>\n",
       "      <td>0.131823</td>\n",
       "      <td>-0.099424</td>\n",
       "      <td>0.065491</td>\n",
       "      <td>0.038437</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.614035</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>74998</th>\n",
       "      <td>42976</td>\n",
       "      <td>0.270141</td>\n",
       "      <td>-0.004631</td>\n",
       "      <td>-0.151272</td>\n",
       "      <td>0.035538</td>\n",
       "      <td>0.083641</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.614035</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>74999</th>\n",
       "      <td>42976</td>\n",
       "      <td>0.270141</td>\n",
       "      <td>-0.004631</td>\n",
       "      <td>-0.151272</td>\n",
       "      <td>0.035538</td>\n",
       "      <td>0.083641</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.614035</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>75000 rows × 88 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       index     lsa_0     lsa_1     lsa_2     lsa_3     lsa_4  hybrid  \\\n",
       "0          0  0.341025  0.182753  0.008214  0.140406 -0.156943       1   \n",
       "1          1  0.232158 -0.045496  0.187131 -0.000936  0.018518       1   \n",
       "2          3  0.243491  0.034313  0.080290 -0.165609  0.019773       1   \n",
       "3          3  0.243491  0.034313  0.080290 -0.165609  0.019773       1   \n",
       "4          4  0.238648 -0.048758 -0.107398 -0.067096 -0.006558       1   \n",
       "...      ...       ...       ...       ...       ...       ...     ...   \n",
       "74995  42975  0.324915  0.131823 -0.099424  0.065491  0.038437       0   \n",
       "74996  42975  0.324915  0.131823 -0.099424  0.065491  0.038437       0   \n",
       "74997  42975  0.324915  0.131823 -0.099424  0.065491  0.038437       0   \n",
       "74998  42976  0.270141 -0.004631 -0.151272  0.035538  0.083641       0   \n",
       "74999  42976  0.270141 -0.004631 -0.151272  0.035538  0.083641       0   \n",
       "\n",
       "       indica  sativa  anxiety  ...  sweet  tar  tea  tobacco  tree  tropical  \\\n",
       "0           0       0        0  ...      0    0    0        0     0         0   \n",
       "1           0       0        0  ...      0    0    0        0     0         0   \n",
       "2           0       0        0  ...      0    1    0        0     0         0   \n",
       "3           0       0        0  ...      0    1    0        0     0         0   \n",
       "4           0       0        0  ...      0    0    0        0     0         0   \n",
       "...       ...     ...      ...  ...    ...  ...  ...      ...   ...       ...   \n",
       "74995       1       0        0  ...      0    0    0        0     0         0   \n",
       "74996       1       0        0  ...      0    0    0        0     0         0   \n",
       "74997       1       0        0  ...      0    0    0        0     0         0   \n",
       "74998       1       0        0  ...      1    1    1        1     1         1   \n",
       "74999       1       0        0  ...      1    1    1        1     1         1   \n",
       "\n",
       "       vanilla  violet  woody    X..CBC  \n",
       "0            0       0      0  0.175439  \n",
       "1            1       0      0  0.175439  \n",
       "2            0       0      0  0.175439  \n",
       "3            0       0      0  0.175439  \n",
       "4            0       0      0  0.175439  \n",
       "...        ...     ...    ...       ...  \n",
       "74995        0       0      0  0.614035  \n",
       "74996        0       0      0  0.614035  \n",
       "74997        0       0      0  0.614035  \n",
       "74998        1       1      1  0.614035  \n",
       "74999        1       1      1  0.614035  \n",
       "\n",
       "[75000 rows x 88 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_mlp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['index',\n",
       " 'lsa_0',\n",
       " 'lsa_1',\n",
       " 'lsa_2',\n",
       " 'lsa_3',\n",
       " 'lsa_4',\n",
       " 'hybrid',\n",
       " 'indica',\n",
       " 'sativa',\n",
       " 'anxiety',\n",
       " 'anxious',\n",
       " 'aroused',\n",
       " 'arthritis',\n",
       " 'creative',\n",
       " 'depression',\n",
       " 'dizzy',\n",
       " 'dry eyes',\n",
       " 'dry mouth',\n",
       " 'energetic',\n",
       " 'epilepsy',\n",
       " 'euphoric',\n",
       " 'eye pressure',\n",
       " 'fatigue',\n",
       " 'focused',\n",
       " 'giggly',\n",
       " 'happy',\n",
       " 'headache',\n",
       " 'hungry',\n",
       " 'migraines',\n",
       " 'pain',\n",
       " 'paranoid',\n",
       " 'relaxed',\n",
       " 'seizures',\n",
       " 'sleepy',\n",
       " 'spasticity',\n",
       " 'stress',\n",
       " 'talkative',\n",
       " 'tingly',\n",
       " 'uplifted',\n",
       " 'ammonia',\n",
       " 'apple',\n",
       " 'apricot',\n",
       " 'berry',\n",
       " 'blue cheese',\n",
       " 'blueberry',\n",
       " 'butter',\n",
       " 'cheese',\n",
       " 'chemical',\n",
       " 'chestnut',\n",
       " 'citrus',\n",
       " 'coffee',\n",
       " 'diesel',\n",
       " 'earthy',\n",
       " 'flowery',\n",
       " 'fruit',\n",
       " 'grape',\n",
       " 'grapefruit',\n",
       " 'honey',\n",
       " 'lavender',\n",
       " 'lemon',\n",
       " 'lime',\n",
       " 'mango',\n",
       " 'menthol',\n",
       " 'mint',\n",
       " 'nutty',\n",
       " 'orange',\n",
       " 'peach',\n",
       " 'pear',\n",
       " 'pepper',\n",
       " 'pine',\n",
       " 'pineapple',\n",
       " 'plum',\n",
       " 'pungent',\n",
       " 'rose',\n",
       " 'sage',\n",
       " 'skunk',\n",
       " 'spicy/herbal',\n",
       " 'strawberry',\n",
       " 'sweet',\n",
       " 'tar',\n",
       " 'tea',\n",
       " 'tobacco',\n",
       " 'tree',\n",
       " 'tropical',\n",
       " 'vanilla',\n",
       " 'violet',\n",
       " 'woody',\n",
       " 'X..CBC']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_mlp.columns.to_list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df_mlp.drop(['index', 'X..CBC'], axis = 1)\n",
    "y = df_mlp[['X..CBC']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:ylabel='Count'>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "sns.histplot(y, bins = 10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train test split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=1, test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train1, X_val, y_train1, y_val = train_test_split(X_train, y_train, random_state=1, test_size=0.25)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "MLP modeling (before Feature selection and Hyperparameter Tuning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/andalanputra/opt/anaconda3/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:1623: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    }
   ],
   "source": [
    "mlpreg = MLPRegressor(random_state=1, early_stopping=True)\n",
    "mlpreg.fit(X_train1, y_train1)\n",
    "y_pred_mlp = mlpreg.predict(X_val)\n",
    "y_pred_mlp_r2 = mlpreg.predict(X_train1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.14724670674753046"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mean_absolute_error(y_val, y_pred_mlp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5886825314485602"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#train\n",
    "r2_score(y_train1, y_pred_mlp_r2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.4665821154764974"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#val\n",
    "r2_score(y_val, y_pred_mlp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Residual plots for each target variable"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Feature Selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "rfreg = RandomForestRegressor()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/andalanputra/opt/anaconda3/lib/python3.9/site-packages/sklearn/feature_selection/_from_model.py:357: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  self.estimator_.fit(X, y, **fit_params)\n"
     ]
    }
   ],
   "source": [
    "selector = SelectFromModel(rfreg).fit(X_train1, y_train1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1.12234529e-01, 1.09464919e-01, 1.12456571e-01, 1.19202903e-01,\n",
       "       1.11761612e-01, 1.99489548e-02, 3.45261356e-03, 2.89547794e-02,\n",
       "       7.12259235e-05, 2.37857057e-03, 5.87742739e-03, 1.16744515e-04,\n",
       "       8.43398290e-03, 8.01832919e-05, 4.32222935e-03, 6.06042831e-03,\n",
       "       8.30670445e-03, 9.36614377e-03, 1.08582052e-04, 9.60939444e-03,\n",
       "       1.32897546e-04, 1.00133350e-04, 8.18358899e-03, 6.99515179e-03,\n",
       "       1.02158448e-02, 2.41525501e-03, 8.80455196e-03, 7.72610496e-05,\n",
       "       1.02439568e-04, 3.39752820e-03, 1.26187687e-02, 1.99390309e-04,\n",
       "       7.85746695e-03, 0.00000000e+00, 3.28396743e-07, 7.30680688e-03,\n",
       "       6.30523084e-03, 9.42220205e-03, 1.04915712e-03, 3.36217930e-04,\n",
       "       2.01087217e-04, 9.85392202e-03, 2.51665496e-04, 1.30348981e-02,\n",
       "       4.09679312e-03, 7.68013028e-03, 1.49834615e-03, 7.88400887e-04,\n",
       "       5.38529543e-03, 9.42356354e-04, 4.62337109e-02, 1.01733500e-02,\n",
       "       4.75565092e-03, 1.32466205e-03, 7.55283407e-03, 8.09144357e-03,\n",
       "       1.70650862e-03, 7.06317989e-04, 1.43324065e-02, 1.48092017e-03,\n",
       "       1.47757320e-03, 5.52930181e-04, 7.00382429e-03, 3.34300806e-03,\n",
       "       1.83113506e-02, 3.27372715e-04, 3.83159629e-04, 8.03245319e-04,\n",
       "       1.10622868e-02, 3.27900847e-04, 5.06992369e-04, 6.59223640e-03,\n",
       "       2.99882005e-03, 2.22436099e-03, 4.74716185e-03, 3.02727194e-03,\n",
       "       6.22894158e-04, 6.79525407e-03, 9.75201057e-04, 9.61346840e-04,\n",
       "       7.80979630e-04, 1.38887582e-03, 1.75530693e-03, 1.75650047e-02,\n",
       "       7.20488060e-04, 6.92573337e-03])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "selector.estimator_.feature_importances_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.011627906976744186"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "selector.threshold_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "mask = selector.get_support()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ True,  True,  True,  True,  True,  True, False,  True, False,\n",
       "       False, False, False, False, False, False, False, False, False,\n",
       "       False, False, False, False, False, False, False, False, False,\n",
       "       False, False, False,  True, False, False, False, False, False,\n",
       "       False, False, False, False, False, False, False,  True, False,\n",
       "       False, False, False, False, False,  True, False, False, False,\n",
       "       False, False, False, False,  True, False, False, False, False,\n",
       "       False,  True, False, False, False, False, False, False, False,\n",
       "       False, False, False, False, False, False, False, False, False,\n",
       "       False, False,  True, False, False])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "selected_features = X.columns[mask]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>lsa_0</th>\n",
       "      <th>lsa_1</th>\n",
       "      <th>lsa_2</th>\n",
       "      <th>lsa_3</th>\n",
       "      <th>lsa_4</th>\n",
       "      <th>hybrid</th>\n",
       "      <th>sativa</th>\n",
       "      <th>relaxed</th>\n",
       "      <th>blueberry</th>\n",
       "      <th>diesel</th>\n",
       "      <th>lemon</th>\n",
       "      <th>orange</th>\n",
       "      <th>vanilla</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.341025</td>\n",
       "      <td>0.182753</td>\n",
       "      <td>0.008214</td>\n",
       "      <td>0.140406</td>\n",
       "      <td>-0.156943</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.232158</td>\n",
       "      <td>-0.045496</td>\n",
       "      <td>0.187131</td>\n",
       "      <td>-0.000936</td>\n",
       "      <td>0.018518</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.243491</td>\n",
       "      <td>0.034313</td>\n",
       "      <td>0.080290</td>\n",
       "      <td>-0.165609</td>\n",
       "      <td>0.019773</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.243491</td>\n",
       "      <td>0.034313</td>\n",
       "      <td>0.080290</td>\n",
       "      <td>-0.165609</td>\n",
       "      <td>0.019773</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.238648</td>\n",
       "      <td>-0.048758</td>\n",
       "      <td>-0.107398</td>\n",
       "      <td>-0.067096</td>\n",
       "      <td>-0.006558</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>74995</th>\n",
       "      <td>0.324915</td>\n",
       "      <td>0.131823</td>\n",
       "      <td>-0.099424</td>\n",
       "      <td>0.065491</td>\n",
       "      <td>0.038437</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>74996</th>\n",
       "      <td>0.324915</td>\n",
       "      <td>0.131823</td>\n",
       "      <td>-0.099424</td>\n",
       "      <td>0.065491</td>\n",
       "      <td>0.038437</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>74997</th>\n",
       "      <td>0.324915</td>\n",
       "      <td>0.131823</td>\n",
       "      <td>-0.099424</td>\n",
       "      <td>0.065491</td>\n",
       "      <td>0.038437</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>74998</th>\n",
       "      <td>0.270141</td>\n",
       "      <td>-0.004631</td>\n",
       "      <td>-0.151272</td>\n",
       "      <td>0.035538</td>\n",
       "      <td>0.083641</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>74999</th>\n",
       "      <td>0.270141</td>\n",
       "      <td>-0.004631</td>\n",
       "      <td>-0.151272</td>\n",
       "      <td>0.035538</td>\n",
       "      <td>0.083641</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>75000 rows × 13 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          lsa_0     lsa_1     lsa_2     lsa_3     lsa_4  hybrid  sativa  \\\n",
       "0      0.341025  0.182753  0.008214  0.140406 -0.156943       1       0   \n",
       "1      0.232158 -0.045496  0.187131 -0.000936  0.018518       1       0   \n",
       "2      0.243491  0.034313  0.080290 -0.165609  0.019773       1       0   \n",
       "3      0.243491  0.034313  0.080290 -0.165609  0.019773       1       0   \n",
       "4      0.238648 -0.048758 -0.107398 -0.067096 -0.006558       1       0   \n",
       "...         ...       ...       ...       ...       ...     ...     ...   \n",
       "74995  0.324915  0.131823 -0.099424  0.065491  0.038437       0       0   \n",
       "74996  0.324915  0.131823 -0.099424  0.065491  0.038437       0       0   \n",
       "74997  0.324915  0.131823 -0.099424  0.065491  0.038437       0       0   \n",
       "74998  0.270141 -0.004631 -0.151272  0.035538  0.083641       0       0   \n",
       "74999  0.270141 -0.004631 -0.151272  0.035538  0.083641       0       0   \n",
       "\n",
       "       relaxed  blueberry  diesel  lemon  orange  vanilla  \n",
       "0            1          0       0      0       0        0  \n",
       "1            1          0       0      0       0        1  \n",
       "2            1          0       0      0       0        0  \n",
       "3            1          0       0      0       0        0  \n",
       "4            0          0       0      0       0        0  \n",
       "...        ...        ...     ...    ...     ...      ...  \n",
       "74995        1          0       0      0       0        0  \n",
       "74996        1          0       0      0       0        0  \n",
       "74997        1          0       0      0       0        0  \n",
       "74998        1          1       1      1       1        1  \n",
       "74999        1          1       1      1       1        1  \n",
       "\n",
       "[75000 rows x 13 columns]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "selected_X = df_mlp[selected_features]\n",
    "selected_X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['lsa_0',\n",
       " 'lsa_1',\n",
       " 'lsa_2',\n",
       " 'lsa_3',\n",
       " 'lsa_4',\n",
       " 'hybrid',\n",
       " 'sativa',\n",
       " 'relaxed',\n",
       " 'blueberry',\n",
       " 'diesel',\n",
       " 'lemon',\n",
       " 'orange',\n",
       " 'vanilla']"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "selected_X.columns.to_list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['selected_X_mlp_lsa_elbow_cbc.pkl']"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import joblib\n",
    "\n",
    "joblib.dump(selector, \"selector_mlp_lsa_elbow_cbc.pkl\")\n",
    "joblib.dump(selected_X, \"selected_X_mlp_lsa_elbow_cbc.pkl\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train test split (after Feature Selection)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(selected_X, y, random_state=1, test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train1, X_val, y_train1, y_val = train_test_split(X_train, y_train, random_state=1, test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/andalanputra/opt/anaconda3/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:1623: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    }
   ],
   "source": [
    "mlpreg.fit(X_train1, y_train1)\n",
    "y_pred_mlpreg = mlpreg.predict(X_val)\n",
    "y_pred_mlpreg_r2 = mlpreg.predict(X_train1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.19674406268072722"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mean_absolute_error(y_val, y_pred_mlpreg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.24334433647679654"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#train\n",
    "r2_score(y_train1, y_pred_mlpreg_r2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.2290019319776775"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#val\n",
    "r2_score(y_val, y_pred_mlpreg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hyperparameter Tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "parameters = {'hidden_layer_sizes': [(100,), (50, 50, 50), (50, 100, 50)],\n",
    "              'activation': ['tanh', 'relu'], #only tanh and relu\n",
    "              'max_iter': [200, 500, 1000]\n",
    "              }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "rscv = RandomizedSearchCV(mlpreg,  \n",
    "                     parameters,   \n",
    "                     cv=5, \n",
    "                     scoring='neg_mean_absolute_error',\n",
    "                     n_jobs=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/andalanputra/opt/anaconda3/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:1623: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/Users/andalanputra/opt/anaconda3/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:1623: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/Users/andalanputra/opt/anaconda3/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:1623: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/Users/andalanputra/opt/anaconda3/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:1623: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/Users/andalanputra/opt/anaconda3/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:1623: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/Users/andalanputra/opt/anaconda3/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:1623: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/Users/andalanputra/opt/anaconda3/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:1623: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/Users/andalanputra/opt/anaconda3/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:1623: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/Users/andalanputra/opt/anaconda3/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:1623: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/Users/andalanputra/opt/anaconda3/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:1623: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/Users/andalanputra/opt/anaconda3/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:1623: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/Users/andalanputra/opt/anaconda3/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:1623: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/Users/andalanputra/opt/anaconda3/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:1623: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/Users/andalanputra/opt/anaconda3/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:1623: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/Users/andalanputra/opt/anaconda3/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:1623: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/Users/andalanputra/opt/anaconda3/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:1623: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/Users/andalanputra/opt/anaconda3/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:1623: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/Users/andalanputra/opt/anaconda3/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:1623: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/Users/andalanputra/opt/anaconda3/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:1623: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/Users/andalanputra/opt/anaconda3/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:1623: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/Users/andalanputra/opt/anaconda3/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:1623: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/Users/andalanputra/opt/anaconda3/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/Users/andalanputra/opt/anaconda3/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:1623: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/Users/andalanputra/opt/anaconda3/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:1623: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/Users/andalanputra/opt/anaconda3/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:1623: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/Users/andalanputra/opt/anaconda3/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:1623: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/Users/andalanputra/opt/anaconda3/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:1623: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/Users/andalanputra/opt/anaconda3/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:1623: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/Users/andalanputra/opt/anaconda3/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:1623: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/Users/andalanputra/opt/anaconda3/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:1623: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/Users/andalanputra/opt/anaconda3/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:1623: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/Users/andalanputra/opt/anaconda3/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:1623: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/Users/andalanputra/opt/anaconda3/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:1623: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/Users/andalanputra/opt/anaconda3/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:1623: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/Users/andalanputra/opt/anaconda3/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:1623: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/Users/andalanputra/opt/anaconda3/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:1623: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/Users/andalanputra/opt/anaconda3/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:1623: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/Users/andalanputra/opt/anaconda3/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:1623: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/Users/andalanputra/opt/anaconda3/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:1623: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/Users/andalanputra/opt/anaconda3/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:1623: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/Users/andalanputra/opt/anaconda3/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:1623: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/Users/andalanputra/opt/anaconda3/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:1623: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/Users/andalanputra/opt/anaconda3/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:1623: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/Users/andalanputra/opt/anaconda3/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:1623: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/Users/andalanputra/opt/anaconda3/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:1623: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/Users/andalanputra/opt/anaconda3/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:1623: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/Users/andalanputra/opt/anaconda3/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:1623: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/Users/andalanputra/opt/anaconda3/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:1623: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/Users/andalanputra/opt/anaconda3/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:1623: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/Users/andalanputra/opt/anaconda3/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:1623: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/Users/andalanputra/opt/anaconda3/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:1623: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/Users/andalanputra/opt/anaconda3/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:1623: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;background-color: white;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>RandomizedSearchCV(cv=5,\n",
       "                   estimator=MLPRegressor(early_stopping=True, random_state=1),\n",
       "                   n_jobs=-1,\n",
       "                   param_distributions={&#x27;activation&#x27;: [&#x27;tanh&#x27;, &#x27;relu&#x27;],\n",
       "                                        &#x27;hidden_layer_sizes&#x27;: [(100,),\n",
       "                                                               (50, 50, 50),\n",
       "                                                               (50, 100, 50)],\n",
       "                                        &#x27;max_iter&#x27;: [200, 500, 1000]},\n",
       "                   scoring=&#x27;neg_mean_absolute_error&#x27;)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" ><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">RandomizedSearchCV</label><div class=\"sk-toggleable__content\"><pre>RandomizedSearchCV(cv=5,\n",
       "                   estimator=MLPRegressor(early_stopping=True, random_state=1),\n",
       "                   n_jobs=-1,\n",
       "                   param_distributions={&#x27;activation&#x27;: [&#x27;tanh&#x27;, &#x27;relu&#x27;],\n",
       "                                        &#x27;hidden_layer_sizes&#x27;: [(100,),\n",
       "                                                               (50, 50, 50),\n",
       "                                                               (50, 100, 50)],\n",
       "                                        &#x27;max_iter&#x27;: [200, 500, 1000]},\n",
       "                   scoring=&#x27;neg_mean_absolute_error&#x27;)</pre></div></div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" ><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">estimator: MLPRegressor</label><div class=\"sk-toggleable__content\"><pre>MLPRegressor(early_stopping=True, random_state=1)</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-3\" type=\"checkbox\" ><label for=\"sk-estimator-id-3\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">MLPRegressor</label><div class=\"sk-toggleable__content\"><pre>MLPRegressor(early_stopping=True, random_state=1)</pre></div></div></div></div></div></div></div></div></div></div>"
      ],
      "text/plain": [
       "RandomizedSearchCV(cv=5,\n",
       "                   estimator=MLPRegressor(early_stopping=True, random_state=1),\n",
       "                   n_jobs=-1,\n",
       "                   param_distributions={'activation': ['tanh', 'relu'],\n",
       "                                        'hidden_layer_sizes': [(100,),\n",
       "                                                               (50, 50, 50),\n",
       "                                                               (50, 100, 50)],\n",
       "                                        'max_iter': [200, 500, 1000]},\n",
       "                   scoring='neg_mean_absolute_error')"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rscv.fit(X_train1, y_train1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'max_iter': 1000, 'hidden_layer_sizes': (50, 100, 50), 'activation': 'tanh'}"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rscv.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['rscv_mlp_lsa_elbow_best_params_cbc.pkl']"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "joblib.dump(rscv, \"rscv_mlp_lsa_elbow_cbc.pkl\")\n",
    "joblib.dump(rscv.best_params_, \"rscv_mlp_lsa_elbow_best_params_cbc.pkl\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "MLP fit (after hyperparameter tuning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/andalanputra/opt/anaconda3/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:1623: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    }
   ],
   "source": [
    "mlpreg_ht = MLPRegressor(random_state=1, max_iter=1000, activation = 'tanh', hidden_layer_sizes= (50,100,50), early_stopping=True)\n",
    "mlpreg_ht.fit(X_train1, y_train1)\n",
    "y_pred_mlp_ht = mlpreg_ht.predict(X_val)\n",
    "y_pred_mlp_r2_ht = mlpreg_ht.predict(X_train1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.20105545030599917"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mean_absolute_error(y_val, y_pred_mlp_ht)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.20570052585728593"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#train\n",
    "r2_score(y_train1, y_pred_mlp_r2_ht)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.19887018137530255"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#val\n",
    "r2_score(y_val, y_pred_mlp_ht)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Residual plots after Hyperparameter Tuning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Predicting model on the test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_mlpreg_test = mlpreg_ht.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['y_test_mlpreg_lsa_elbow_cbc.pkl']"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "joblib.dump(y_pred_mlpreg_test, \"y_pred_mlpreg_test_lsa_elbow_cbc.pkl\")\n",
    "joblib.dump(y_test, \"y_test_mlpreg_lsa_elbow_cbc.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.20229085909806307"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mean_absolute_error(y_test, y_pred_mlpreg_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.06149170448191905"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mean_squared_error(y_test, y_pred_mlpreg_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.24797520940997117"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mean_squared_error(y_test, y_pred_mlpreg_test, squared = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.191981228906127"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "r2_score(y_test, y_pred_mlpreg_test)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Error analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 576x432 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 432x288 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# assume y_pred is a numpy array and y_true is a pandas dataframe\n",
    "fig, ax = plt.subplots(figsize=(8, 6))\n",
    "\n",
    "column = \"X..CBC\"  # specify the target variable name\n",
    "ax.hist(y_pred_mlpreg_test, alpha=0.5, label='y_pred', bins=20)\n",
    "ax.hist(y_test[column], alpha=0.5, label='y_true', bins=20)\n",
    "ax.legend(loc='upper right')\n",
    "ax.set_title(column)\n",
    "\n",
    "plt.show()\n",
    "plt.savefig('error_hist_mlp_lsa_elbow_cbc.png')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pearson R"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pearson correlation coefficient: 0.438\n",
      "P-value: 0.000\n"
     ]
    }
   ],
   "source": [
    "corr_coef, p_value = pearsonr(y_pred_mlpreg_test.flatten(), y_test.values.ravel())\n",
    "\n",
    "print(f\"Pearson correlation coefficient: {corr_coef:.3f}\")\n",
    "print(f\"P-value: {p_value:.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:>"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "corr_matrix = y_test.corr()\n",
    "sns.heatmap(corr_matrix, annot=True, cmap='coolwarm', center=0)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
