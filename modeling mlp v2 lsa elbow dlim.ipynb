{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn import preprocessing\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.neural_network import MLPRegressor\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "from sklearn.metrics import r2_score\n",
    "from scipy.stats import pearsonr\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.feature_selection import SelectFromModel\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compiling complete dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_mlp = pd.read_csv(\"df_dlim_lsa.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>lsa_0</th>\n",
       "      <th>lsa_1</th>\n",
       "      <th>lsa_2</th>\n",
       "      <th>lsa_3</th>\n",
       "      <th>lsa_4</th>\n",
       "      <th>hybrid</th>\n",
       "      <th>indica</th>\n",
       "      <th>sativa</th>\n",
       "      <th>anxiety</th>\n",
       "      <th>...</th>\n",
       "      <th>sweet</th>\n",
       "      <th>tar</th>\n",
       "      <th>tea</th>\n",
       "      <th>tobacco</th>\n",
       "      <th>tree</th>\n",
       "      <th>tropical</th>\n",
       "      <th>vanilla</th>\n",
       "      <th>violet</th>\n",
       "      <th>woody</th>\n",
       "      <th>X..D-Limonene</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0.341025</td>\n",
       "      <td>0.182753</td>\n",
       "      <td>0.008214</td>\n",
       "      <td>0.140406</td>\n",
       "      <td>-0.156943</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.341772</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0.232158</td>\n",
       "      <td>-0.045496</td>\n",
       "      <td>0.187131</td>\n",
       "      <td>-0.000936</td>\n",
       "      <td>0.018518</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.341772</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>0.261225</td>\n",
       "      <td>0.100324</td>\n",
       "      <td>-0.043622</td>\n",
       "      <td>0.141860</td>\n",
       "      <td>-0.034786</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.341772</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2</td>\n",
       "      <td>0.261225</td>\n",
       "      <td>0.100324</td>\n",
       "      <td>-0.043622</td>\n",
       "      <td>0.141860</td>\n",
       "      <td>-0.034786</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.341772</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3</td>\n",
       "      <td>0.243491</td>\n",
       "      <td>0.034313</td>\n",
       "      <td>0.080290</td>\n",
       "      <td>-0.165609</td>\n",
       "      <td>0.019773</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.341772</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>74995</th>\n",
       "      <td>42974</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.240506</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>74996</th>\n",
       "      <td>42975</td>\n",
       "      <td>0.324915</td>\n",
       "      <td>0.131823</td>\n",
       "      <td>-0.099424</td>\n",
       "      <td>0.065491</td>\n",
       "      <td>0.038437</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.240506</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>74997</th>\n",
       "      <td>42976</td>\n",
       "      <td>0.270141</td>\n",
       "      <td>-0.004631</td>\n",
       "      <td>-0.151272</td>\n",
       "      <td>0.035538</td>\n",
       "      <td>0.083641</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.240506</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>74998</th>\n",
       "      <td>42976</td>\n",
       "      <td>0.270141</td>\n",
       "      <td>-0.004631</td>\n",
       "      <td>-0.151272</td>\n",
       "      <td>0.035538</td>\n",
       "      <td>0.083641</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.240506</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>74999</th>\n",
       "      <td>42976</td>\n",
       "      <td>0.270141</td>\n",
       "      <td>-0.004631</td>\n",
       "      <td>-0.151272</td>\n",
       "      <td>0.035538</td>\n",
       "      <td>0.083641</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.240506</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>75000 rows × 88 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       index     lsa_0     lsa_1     lsa_2     lsa_3     lsa_4  hybrid  \\\n",
       "0          0  0.341025  0.182753  0.008214  0.140406 -0.156943       1   \n",
       "1          1  0.232158 -0.045496  0.187131 -0.000936  0.018518       1   \n",
       "2          2  0.261225  0.100324 -0.043622  0.141860 -0.034786       1   \n",
       "3          2  0.261225  0.100324 -0.043622  0.141860 -0.034786       1   \n",
       "4          3  0.243491  0.034313  0.080290 -0.165609  0.019773       1   \n",
       "...      ...       ...       ...       ...       ...       ...     ...   \n",
       "74995  42974  0.000000  0.000000  0.000000  0.000000  0.000000       0   \n",
       "74996  42975  0.324915  0.131823 -0.099424  0.065491  0.038437       0   \n",
       "74997  42976  0.270141 -0.004631 -0.151272  0.035538  0.083641       0   \n",
       "74998  42976  0.270141 -0.004631 -0.151272  0.035538  0.083641       0   \n",
       "74999  42976  0.270141 -0.004631 -0.151272  0.035538  0.083641       0   \n",
       "\n",
       "       indica  sativa  anxiety  ...  sweet  tar  tea  tobacco  tree  tropical  \\\n",
       "0           0       0        0  ...      0    0    0        0     0         0   \n",
       "1           0       0        0  ...      0    0    0        0     0         0   \n",
       "2           0       0        0  ...      1    0    0        0     0         0   \n",
       "3           0       0        0  ...      1    0    0        0     0         0   \n",
       "4           0       0        0  ...      0    1    0        0     0         0   \n",
       "...       ...     ...      ...  ...    ...  ...  ...      ...   ...       ...   \n",
       "74995       1       0        0  ...      0    0    0        0     0         0   \n",
       "74996       1       0        0  ...      0    0    0        0     0         0   \n",
       "74997       1       0        0  ...      1    1    1        1     1         1   \n",
       "74998       1       0        0  ...      1    1    1        1     1         1   \n",
       "74999       1       0        0  ...      1    1    1        1     1         1   \n",
       "\n",
       "       vanilla  violet  woody  X..D-Limonene  \n",
       "0            0       0      0       0.341772  \n",
       "1            1       0      0       0.341772  \n",
       "2            1       0      0       0.341772  \n",
       "3            1       0      0       0.341772  \n",
       "4            0       0      0       0.341772  \n",
       "...        ...     ...    ...            ...  \n",
       "74995        0       0      0       0.240506  \n",
       "74996        0       0      0       0.240506  \n",
       "74997        1       1      1       0.240506  \n",
       "74998        1       1      1       0.240506  \n",
       "74999        1       1      1       0.240506  \n",
       "\n",
       "[75000 rows x 88 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_mlp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['index',\n",
       " 'lsa_0',\n",
       " 'lsa_1',\n",
       " 'lsa_2',\n",
       " 'lsa_3',\n",
       " 'lsa_4',\n",
       " 'hybrid',\n",
       " 'indica',\n",
       " 'sativa',\n",
       " 'anxiety',\n",
       " 'anxious',\n",
       " 'aroused',\n",
       " 'arthritis',\n",
       " 'creative',\n",
       " 'depression',\n",
       " 'dizzy',\n",
       " 'dry eyes',\n",
       " 'dry mouth',\n",
       " 'energetic',\n",
       " 'epilepsy',\n",
       " 'euphoric',\n",
       " 'eye pressure',\n",
       " 'fatigue',\n",
       " 'focused',\n",
       " 'giggly',\n",
       " 'happy',\n",
       " 'headache',\n",
       " 'hungry',\n",
       " 'migraines',\n",
       " 'pain',\n",
       " 'paranoid',\n",
       " 'relaxed',\n",
       " 'seizures',\n",
       " 'sleepy',\n",
       " 'spasticity',\n",
       " 'stress',\n",
       " 'talkative',\n",
       " 'tingly',\n",
       " 'uplifted',\n",
       " 'ammonia',\n",
       " 'apple',\n",
       " 'apricot',\n",
       " 'berry',\n",
       " 'blue cheese',\n",
       " 'blueberry',\n",
       " 'butter',\n",
       " 'cheese',\n",
       " 'chemical',\n",
       " 'chestnut',\n",
       " 'citrus',\n",
       " 'coffee',\n",
       " 'diesel',\n",
       " 'earthy',\n",
       " 'flowery',\n",
       " 'fruit',\n",
       " 'grape',\n",
       " 'grapefruit',\n",
       " 'honey',\n",
       " 'lavender',\n",
       " 'lemon',\n",
       " 'lime',\n",
       " 'mango',\n",
       " 'menthol',\n",
       " 'mint',\n",
       " 'nutty',\n",
       " 'orange',\n",
       " 'peach',\n",
       " 'pear',\n",
       " 'pepper',\n",
       " 'pine',\n",
       " 'pineapple',\n",
       " 'plum',\n",
       " 'pungent',\n",
       " 'rose',\n",
       " 'sage',\n",
       " 'skunk',\n",
       " 'spicy/herbal',\n",
       " 'strawberry',\n",
       " 'sweet',\n",
       " 'tar',\n",
       " 'tea',\n",
       " 'tobacco',\n",
       " 'tree',\n",
       " 'tropical',\n",
       " 'vanilla',\n",
       " 'violet',\n",
       " 'woody',\n",
       " 'X..D-Limonene']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_mlp.columns.to_list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df_mlp.drop(['index', 'X..D-Limonene'], axis = 1)\n",
    "y = df_mlp[['X..D-Limonene']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:ylabel='Count'>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "sns.histplot(y, bins = 10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train test split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=1, test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train1, X_val, y_train1, y_val = train_test_split(X_train, y_train, random_state=1, test_size=0.25)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "MLP modeling (before Feature selection and Hyperparameter Tuning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/andalanputra/opt/anaconda3/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:1623: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    }
   ],
   "source": [
    "mlpreg = MLPRegressor(random_state=1, early_stopping=True)\n",
    "mlpreg.fit(X_train1, y_train1)\n",
    "y_pred_mlp = mlpreg.predict(X_val)\n",
    "y_pred_mlp_r2 = mlpreg.predict(X_train1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.14736417941795255"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mean_absolute_error(y_val, y_pred_mlp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6545273276431369"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#train\n",
    "r2_score(y_train1, y_pred_mlp_r2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5262302470231929"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#val\n",
    "r2_score(y_val, y_pred_mlp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Residual plots for each target variable"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Feature Selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "rfreg = RandomForestRegressor()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/andalanputra/opt/anaconda3/lib/python3.9/site-packages/sklearn/feature_selection/_from_model.py:357: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  self.estimator_.fit(X, y, **fit_params)\n"
     ]
    }
   ],
   "source": [
    "selector = SelectFromModel(rfreg).fit(X_train1, y_train1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1.05536882e-01, 9.10285777e-02, 9.77851847e-02, 9.78090953e-02,\n",
       "       9.91895630e-02, 4.22190231e-02, 2.40016329e-02, 9.93037520e-03,\n",
       "       4.13890973e-04, 2.99046642e-03, 5.35444048e-03, 3.02260906e-07,\n",
       "       7.62116986e-03, 3.41770990e-04, 3.95872252e-03, 5.34363138e-03,\n",
       "       8.16702745e-03, 6.65763110e-03, 6.66909919e-08, 9.13936336e-03,\n",
       "       8.91285678e-08, 3.35862351e-10, 8.14812772e-03, 6.16979026e-03,\n",
       "       8.44585279e-03, 2.70409367e-03, 8.16090947e-03, 5.40755301e-04,\n",
       "       5.02669032e-09, 3.24037067e-03, 9.44198638e-03, 5.15931262e-08,\n",
       "       5.92560897e-03, 1.14172052e-08, 5.46359668e-07, 5.91001310e-03,\n",
       "       7.88568684e-03, 7.98992262e-03, 4.01757904e-04, 1.80967595e-04,\n",
       "       1.73788655e-04, 5.92296831e-03, 7.15172100e-05, 9.80040814e-03,\n",
       "       3.50307405e-03, 3.71140357e-03, 1.69126321e-03, 1.49967556e-04,\n",
       "       1.27476993e-02, 2.29148876e-03, 1.48589141e-01, 1.00468314e-02,\n",
       "       2.82790320e-03, 2.34956518e-03, 7.23408104e-03, 1.35161447e-03,\n",
       "       8.81227736e-04, 1.54859295e-03, 1.12499304e-02, 3.59524117e-03,\n",
       "       7.02685528e-04, 3.24468496e-04, 3.86818293e-03, 9.52937255e-04,\n",
       "       9.53872107e-03, 1.93553338e-04, 1.55357529e-04, 2.00538865e-03,\n",
       "       6.27583238e-03, 5.53913729e-04, 1.67146968e-04, 6.94909042e-03,\n",
       "       8.69594523e-04, 1.70075687e-03, 7.77306940e-03, 3.82528820e-03,\n",
       "       7.66981315e-03, 6.95261433e-03, 4.45285626e-04, 1.39013293e-03,\n",
       "       3.62410539e-04, 2.26801101e-03, 4.61894096e-03, 3.12762814e-03,\n",
       "       1.70069069e-04, 4.76603509e-03])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "selector.estimator_.feature_importances_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.011627906976744184"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "selector.threshold_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "mask = selector.get_support()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ True,  True,  True,  True,  True,  True,  True, False, False,\n",
       "       False, False, False, False, False, False, False, False, False,\n",
       "       False, False, False, False, False, False, False, False, False,\n",
       "       False, False, False, False, False, False, False, False, False,\n",
       "       False, False, False, False, False, False, False, False, False,\n",
       "       False, False, False,  True, False,  True, False, False, False,\n",
       "       False, False, False, False, False, False, False, False, False,\n",
       "       False, False, False, False, False, False, False, False, False,\n",
       "       False, False, False, False, False, False, False, False, False,\n",
       "       False, False, False, False, False])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "selected_features = X.columns[mask]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>lsa_0</th>\n",
       "      <th>lsa_1</th>\n",
       "      <th>lsa_2</th>\n",
       "      <th>lsa_3</th>\n",
       "      <th>lsa_4</th>\n",
       "      <th>hybrid</th>\n",
       "      <th>indica</th>\n",
       "      <th>citrus</th>\n",
       "      <th>diesel</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.341025</td>\n",
       "      <td>0.182753</td>\n",
       "      <td>0.008214</td>\n",
       "      <td>0.140406</td>\n",
       "      <td>-0.156943</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.232158</td>\n",
       "      <td>-0.045496</td>\n",
       "      <td>0.187131</td>\n",
       "      <td>-0.000936</td>\n",
       "      <td>0.018518</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.261225</td>\n",
       "      <td>0.100324</td>\n",
       "      <td>-0.043622</td>\n",
       "      <td>0.141860</td>\n",
       "      <td>-0.034786</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.261225</td>\n",
       "      <td>0.100324</td>\n",
       "      <td>-0.043622</td>\n",
       "      <td>0.141860</td>\n",
       "      <td>-0.034786</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.243491</td>\n",
       "      <td>0.034313</td>\n",
       "      <td>0.080290</td>\n",
       "      <td>-0.165609</td>\n",
       "      <td>0.019773</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>74995</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>74996</th>\n",
       "      <td>0.324915</td>\n",
       "      <td>0.131823</td>\n",
       "      <td>-0.099424</td>\n",
       "      <td>0.065491</td>\n",
       "      <td>0.038437</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>74997</th>\n",
       "      <td>0.270141</td>\n",
       "      <td>-0.004631</td>\n",
       "      <td>-0.151272</td>\n",
       "      <td>0.035538</td>\n",
       "      <td>0.083641</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>74998</th>\n",
       "      <td>0.270141</td>\n",
       "      <td>-0.004631</td>\n",
       "      <td>-0.151272</td>\n",
       "      <td>0.035538</td>\n",
       "      <td>0.083641</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>74999</th>\n",
       "      <td>0.270141</td>\n",
       "      <td>-0.004631</td>\n",
       "      <td>-0.151272</td>\n",
       "      <td>0.035538</td>\n",
       "      <td>0.083641</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>75000 rows × 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          lsa_0     lsa_1     lsa_2     lsa_3     lsa_4  hybrid  indica  \\\n",
       "0      0.341025  0.182753  0.008214  0.140406 -0.156943       1       0   \n",
       "1      0.232158 -0.045496  0.187131 -0.000936  0.018518       1       0   \n",
       "2      0.261225  0.100324 -0.043622  0.141860 -0.034786       1       0   \n",
       "3      0.261225  0.100324 -0.043622  0.141860 -0.034786       1       0   \n",
       "4      0.243491  0.034313  0.080290 -0.165609  0.019773       1       0   \n",
       "...         ...       ...       ...       ...       ...     ...     ...   \n",
       "74995  0.000000  0.000000  0.000000  0.000000  0.000000       0       1   \n",
       "74996  0.324915  0.131823 -0.099424  0.065491  0.038437       0       1   \n",
       "74997  0.270141 -0.004631 -0.151272  0.035538  0.083641       0       1   \n",
       "74998  0.270141 -0.004631 -0.151272  0.035538  0.083641       0       1   \n",
       "74999  0.270141 -0.004631 -0.151272  0.035538  0.083641       0       1   \n",
       "\n",
       "       citrus  diesel  \n",
       "0           0       0  \n",
       "1           0       0  \n",
       "2           0       0  \n",
       "3           0       0  \n",
       "4           0       0  \n",
       "...       ...     ...  \n",
       "74995       0       0  \n",
       "74996       0       0  \n",
       "74997       1       1  \n",
       "74998       1       1  \n",
       "74999       1       1  \n",
       "\n",
       "[75000 rows x 9 columns]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "selected_X = df_mlp[selected_features]\n",
    "selected_X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['lsa_0',\n",
       " 'lsa_1',\n",
       " 'lsa_2',\n",
       " 'lsa_3',\n",
       " 'lsa_4',\n",
       " 'hybrid',\n",
       " 'indica',\n",
       " 'citrus',\n",
       " 'diesel']"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "selected_X.columns.to_list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['selected_X_mlp_lsa_elbow_dlim.pkl']"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import joblib\n",
    "\n",
    "joblib.dump(selector, \"selector_mlp_lsa_elbow_dlim.pkl\")\n",
    "joblib.dump(selected_X, \"selected_X_mlp_lsa_elbow_dlim.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import joblib\n",
    "\n",
    "# selected_X = joblib.load(\"selected_X_mlp_lsa_elbow_dlim.pkl\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train test split (after Feature Selection)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(selected_X, y, random_state=1, test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train1, X_val, y_train1, y_val = train_test_split(X_train, y_train, random_state=1, test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/andalanputra/opt/anaconda3/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:1623: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    }
   ],
   "source": [
    "mlpreg.fit(X_train1, y_train1)\n",
    "y_pred_mlpreg = mlpreg.predict(X_val)\n",
    "y_pred_mlpreg_r2 = mlpreg.predict(X_train1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.21261878737456558"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mean_absolute_error(y_val, y_pred_mlpreg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.24588815161779576"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#train\n",
    "r2_score(y_train1, y_pred_mlpreg_r2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.2224313758141886"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#val\n",
    "r2_score(y_val, y_pred_mlpreg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hyperparameter Tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "parameters = {'hidden_layer_sizes': [(100,), (50, 50, 50), (50, 100, 50)],\n",
    "              'activation': ['tanh', 'relu'], #only tanh and relu\n",
    "              'max_iter': [200, 500, 1000]\n",
    "              }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "rscv = RandomizedSearchCV(mlpreg,  \n",
    "                     parameters,   \n",
    "                     cv=5, \n",
    "                     scoring='neg_mean_absolute_error',\n",
    "                     n_jobs=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/andalanputra/opt/anaconda3/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:1623: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/Users/andalanputra/opt/anaconda3/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:1623: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/Users/andalanputra/opt/anaconda3/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:1623: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/Users/andalanputra/opt/anaconda3/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:1623: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/Users/andalanputra/opt/anaconda3/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:1623: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/Users/andalanputra/opt/anaconda3/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:1623: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/Users/andalanputra/opt/anaconda3/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:1623: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/Users/andalanputra/opt/anaconda3/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:1623: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/Users/andalanputra/opt/anaconda3/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:1623: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/Users/andalanputra/opt/anaconda3/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:1623: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/Users/andalanputra/opt/anaconda3/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:1623: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/Users/andalanputra/opt/anaconda3/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:1623: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/Users/andalanputra/opt/anaconda3/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:1623: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/Users/andalanputra/opt/anaconda3/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:1623: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/Users/andalanputra/opt/anaconda3/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:1623: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/Users/andalanputra/opt/anaconda3/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:1623: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/Users/andalanputra/opt/anaconda3/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:1623: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/Users/andalanputra/opt/anaconda3/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:1623: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/Users/andalanputra/opt/anaconda3/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:1623: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/Users/andalanputra/opt/anaconda3/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:1623: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/Users/andalanputra/opt/anaconda3/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:1623: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/Users/andalanputra/opt/anaconda3/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:1623: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/Users/andalanputra/opt/anaconda3/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:1623: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/Users/andalanputra/opt/anaconda3/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:1623: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/Users/andalanputra/opt/anaconda3/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:1623: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/Users/andalanputra/opt/anaconda3/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:1623: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/Users/andalanputra/opt/anaconda3/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:1623: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/Users/andalanputra/opt/anaconda3/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:1623: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/Users/andalanputra/opt/anaconda3/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:1623: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/Users/andalanputra/opt/anaconda3/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:1623: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/Users/andalanputra/opt/anaconda3/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:1623: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/Users/andalanputra/opt/anaconda3/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:1623: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/Users/andalanputra/opt/anaconda3/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:1623: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/Users/andalanputra/opt/anaconda3/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:1623: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/Users/andalanputra/opt/anaconda3/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/Users/andalanputra/opt/anaconda3/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:1623: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/Users/andalanputra/opt/anaconda3/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:1623: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/Users/andalanputra/opt/anaconda3/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:1623: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/Users/andalanputra/opt/anaconda3/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:1623: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/Users/andalanputra/opt/anaconda3/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:1623: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/Users/andalanputra/opt/anaconda3/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:1623: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/Users/andalanputra/opt/anaconda3/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:1623: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/Users/andalanputra/opt/anaconda3/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:1623: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/Users/andalanputra/opt/anaconda3/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:1623: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/Users/andalanputra/opt/anaconda3/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:1623: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/Users/andalanputra/opt/anaconda3/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:1623: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/Users/andalanputra/opt/anaconda3/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:1623: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/Users/andalanputra/opt/anaconda3/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:1623: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/Users/andalanputra/opt/anaconda3/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:1623: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/Users/andalanputra/opt/anaconda3/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:1623: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/Users/andalanputra/opt/anaconda3/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:1623: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/Users/andalanputra/opt/anaconda3/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:1623: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;background-color: white;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>RandomizedSearchCV(cv=5,\n",
       "                   estimator=MLPRegressor(early_stopping=True, random_state=1),\n",
       "                   n_jobs=-1,\n",
       "                   param_distributions={&#x27;activation&#x27;: [&#x27;tanh&#x27;, &#x27;relu&#x27;],\n",
       "                                        &#x27;hidden_layer_sizes&#x27;: [(100,),\n",
       "                                                               (50, 50, 50),\n",
       "                                                               (50, 100, 50)],\n",
       "                                        &#x27;max_iter&#x27;: [200, 500, 1000]},\n",
       "                   scoring=&#x27;neg_mean_absolute_error&#x27;)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" ><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">RandomizedSearchCV</label><div class=\"sk-toggleable__content\"><pre>RandomizedSearchCV(cv=5,\n",
       "                   estimator=MLPRegressor(early_stopping=True, random_state=1),\n",
       "                   n_jobs=-1,\n",
       "                   param_distributions={&#x27;activation&#x27;: [&#x27;tanh&#x27;, &#x27;relu&#x27;],\n",
       "                                        &#x27;hidden_layer_sizes&#x27;: [(100,),\n",
       "                                                               (50, 50, 50),\n",
       "                                                               (50, 100, 50)],\n",
       "                                        &#x27;max_iter&#x27;: [200, 500, 1000]},\n",
       "                   scoring=&#x27;neg_mean_absolute_error&#x27;)</pre></div></div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" ><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">estimator: MLPRegressor</label><div class=\"sk-toggleable__content\"><pre>MLPRegressor(early_stopping=True, random_state=1)</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-3\" type=\"checkbox\" ><label for=\"sk-estimator-id-3\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">MLPRegressor</label><div class=\"sk-toggleable__content\"><pre>MLPRegressor(early_stopping=True, random_state=1)</pre></div></div></div></div></div></div></div></div></div></div>"
      ],
      "text/plain": [
       "RandomizedSearchCV(cv=5,\n",
       "                   estimator=MLPRegressor(early_stopping=True, random_state=1),\n",
       "                   n_jobs=-1,\n",
       "                   param_distributions={'activation': ['tanh', 'relu'],\n",
       "                                        'hidden_layer_sizes': [(100,),\n",
       "                                                               (50, 50, 50),\n",
       "                                                               (50, 100, 50)],\n",
       "                                        'max_iter': [200, 500, 1000]},\n",
       "                   scoring='neg_mean_absolute_error')"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rscv.fit(X_train1, y_train1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'max_iter': 1000, 'hidden_layer_sizes': (50, 100, 50), 'activation': 'relu'}"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rscv.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['rscv_mlp_lsa_elbow_best_params_dlim.pkl']"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "joblib.dump(rscv, \"rscv_mlp_lsa_elbow_dlim.pkl\")\n",
    "joblib.dump(rscv.best_params_, \"rscv_mlp_lsa_elbow_best_params_dlim.pkl\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "MLP fit (after hyperparameter tuning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/andalanputra/opt/anaconda3/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:1623: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    }
   ],
   "source": [
    "mlpreg_ht = MLPRegressor(random_state=1, max_iter=1000, activation = 'relu', hidden_layer_sizes= (50,100,50), early_stopping=True)\n",
    "mlpreg_ht.fit(X_train1, y_train1)\n",
    "y_pred_mlp_ht = mlpreg_ht.predict(X_val)\n",
    "y_pred_mlp_r2_ht = mlpreg_ht.predict(X_train1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.17999609281970153"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mean_absolute_error(y_val, y_pred_mlp_ht)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.47557445646203267"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#train\n",
    "r2_score(y_train1, y_pred_mlp_r2_ht)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.3914490792930384"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#val\n",
    "r2_score(y_val, y_pred_mlp_ht)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Residual plots after Hyperparameter Tuning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Predicting model on the test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_mlpreg_test = mlpreg_ht.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['y_test_mlpreg_lsa_elbow_dlim.pkl']"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "joblib.dump(y_pred_mlpreg_test, \"y_pred_mlpreg_test_lsa_elbow_dlim.pkl\")\n",
    "joblib.dump(y_test, \"y_test_mlpreg_lsa_elbow_dlim.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.18013632329147675"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mean_absolute_error(y_test, y_pred_mlpreg_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.05089172543453676"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mean_squared_error(y_test, y_pred_mlpreg_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.22559194452492481"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mean_squared_error(y_test, y_pred_mlpreg_test, squared = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.4038737815485155"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "r2_score(y_test, y_pred_mlpreg_test)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Error analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 576x432 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 432x288 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# assume y_pred is a numpy array and y_true is a pandas dataframe\n",
    "fig, ax = plt.subplots(figsize=(8, 6))\n",
    "\n",
    "column = \"X..D-Limonene\"  # specify the target variable name\n",
    "ax.hist(y_pred_mlpreg_test, alpha=0.5, label='y_pred', bins=20)\n",
    "ax.hist(y_test[column], alpha=0.5, label='y_true', bins=20)\n",
    "ax.legend(loc='upper right')\n",
    "ax.set_title(column)\n",
    "\n",
    "plt.show()\n",
    "plt.savefig('error_hist_mlp_lsa_elbow_dlim.png')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pearson R"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pearson correlation coefficient: 0.637\n",
      "P-value: 0.000\n"
     ]
    }
   ],
   "source": [
    "corr_coef, p_value = pearsonr(y_pred_mlpreg_test.flatten(), y_test.values.ravel())\n",
    "\n",
    "print(f\"Pearson correlation coefficient: {corr_coef:.3f}\")\n",
    "print(f\"P-value: {p_value:.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:>"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "corr_matrix = y_test.corr()\n",
    "sns.heatmap(corr_matrix, annot=True, cmap='coolwarm', center=0)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
