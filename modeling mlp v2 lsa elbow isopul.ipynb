{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn import preprocessing\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.neural_network import MLPRegressor\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "from sklearn.metrics import r2_score\n",
    "from scipy.stats import pearsonr\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.feature_selection import SelectFromModel\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compiling complete dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_mlp = pd.read_csv(\"df_isopul_lsa.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>lsa_0</th>\n",
       "      <th>lsa_1</th>\n",
       "      <th>lsa_2</th>\n",
       "      <th>lsa_3</th>\n",
       "      <th>lsa_4</th>\n",
       "      <th>hybrid</th>\n",
       "      <th>indica</th>\n",
       "      <th>sativa</th>\n",
       "      <th>anxiety</th>\n",
       "      <th>...</th>\n",
       "      <th>sweet</th>\n",
       "      <th>tar</th>\n",
       "      <th>tea</th>\n",
       "      <th>tobacco</th>\n",
       "      <th>tree</th>\n",
       "      <th>tropical</th>\n",
       "      <th>vanilla</th>\n",
       "      <th>violet</th>\n",
       "      <th>woody</th>\n",
       "      <th>X..Isopulegol</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3</td>\n",
       "      <td>0.243491</td>\n",
       "      <td>0.034313</td>\n",
       "      <td>0.080290</td>\n",
       "      <td>-0.165609</td>\n",
       "      <td>0.019773</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3</td>\n",
       "      <td>0.243491</td>\n",
       "      <td>0.034313</td>\n",
       "      <td>0.080290</td>\n",
       "      <td>-0.165609</td>\n",
       "      <td>0.019773</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>0.243491</td>\n",
       "      <td>0.034313</td>\n",
       "      <td>0.080290</td>\n",
       "      <td>-0.165609</td>\n",
       "      <td>0.019773</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>6</td>\n",
       "      <td>0.276418</td>\n",
       "      <td>-0.133986</td>\n",
       "      <td>0.116293</td>\n",
       "      <td>0.073694</td>\n",
       "      <td>0.041143</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>7</td>\n",
       "      <td>0.401841</td>\n",
       "      <td>-0.062527</td>\n",
       "      <td>-0.018128</td>\n",
       "      <td>-0.104475</td>\n",
       "      <td>0.009215</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49995</th>\n",
       "      <td>42965</td>\n",
       "      <td>0.360708</td>\n",
       "      <td>-0.269375</td>\n",
       "      <td>0.169135</td>\n",
       "      <td>0.099257</td>\n",
       "      <td>0.141142</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49996</th>\n",
       "      <td>42968</td>\n",
       "      <td>0.107417</td>\n",
       "      <td>-0.105614</td>\n",
       "      <td>-0.117669</td>\n",
       "      <td>-0.047306</td>\n",
       "      <td>0.055133</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49997</th>\n",
       "      <td>42969</td>\n",
       "      <td>0.109738</td>\n",
       "      <td>-0.066611</td>\n",
       "      <td>-0.064934</td>\n",
       "      <td>0.145920</td>\n",
       "      <td>-0.069040</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49998</th>\n",
       "      <td>42970</td>\n",
       "      <td>0.440634</td>\n",
       "      <td>-0.078839</td>\n",
       "      <td>0.085152</td>\n",
       "      <td>0.087878</td>\n",
       "      <td>-0.133604</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49999</th>\n",
       "      <td>42970</td>\n",
       "      <td>0.440634</td>\n",
       "      <td>-0.078839</td>\n",
       "      <td>0.085152</td>\n",
       "      <td>0.087878</td>\n",
       "      <td>-0.133604</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>50000 rows × 88 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       index     lsa_0     lsa_1     lsa_2     lsa_3     lsa_4  hybrid  \\\n",
       "0          3  0.243491  0.034313  0.080290 -0.165609  0.019773       1   \n",
       "1          3  0.243491  0.034313  0.080290 -0.165609  0.019773       1   \n",
       "2          3  0.243491  0.034313  0.080290 -0.165609  0.019773       1   \n",
       "3          6  0.276418 -0.133986  0.116293  0.073694  0.041143       1   \n",
       "4          7  0.401841 -0.062527 -0.018128 -0.104475  0.009215       1   \n",
       "...      ...       ...       ...       ...       ...       ...     ...   \n",
       "49995  42965  0.360708 -0.269375  0.169135  0.099257  0.141142       0   \n",
       "49996  42968  0.107417 -0.105614 -0.117669 -0.047306  0.055133       0   \n",
       "49997  42969  0.109738 -0.066611 -0.064934  0.145920 -0.069040       0   \n",
       "49998  42970  0.440634 -0.078839  0.085152  0.087878 -0.133604       0   \n",
       "49999  42970  0.440634 -0.078839  0.085152  0.087878 -0.133604       0   \n",
       "\n",
       "       indica  sativa  anxiety  ...  sweet  tar  tea  tobacco  tree  tropical  \\\n",
       "0           0       0        0  ...      0    1    0        0     0         0   \n",
       "1           0       0        0  ...      0    1    0        0     0         0   \n",
       "2           0       0        0  ...      0    1    0        0     0         0   \n",
       "3           0       0        0  ...      0    0    0        0     0         0   \n",
       "4           0       0        0  ...      0    1    0        0     0         0   \n",
       "...       ...     ...      ...  ...    ...  ...  ...      ...   ...       ...   \n",
       "49995       1       0        0  ...      0    0    0        0     0         0   \n",
       "49996       1       0        0  ...      0    0    0        0     0         0   \n",
       "49997       1       0        0  ...      0    0    0        0     0         0   \n",
       "49998       1       0        0  ...      0    0    0        0     0         0   \n",
       "49999       1       0        0  ...      0    0    0        0     0         0   \n",
       "\n",
       "       vanilla  violet  woody  X..Isopulegol  \n",
       "0            0       0      0            0.0  \n",
       "1            0       0      0            0.0  \n",
       "2            0       0      0            0.0  \n",
       "3            0       0      0            0.0  \n",
       "4            1       1      1            0.0  \n",
       "...        ...     ...    ...            ...  \n",
       "49995        0       0      0            0.0  \n",
       "49996        0       0      0            0.0  \n",
       "49997        0       0      0            0.0  \n",
       "49998        0       0      0            0.0  \n",
       "49999        0       0      0            0.0  \n",
       "\n",
       "[50000 rows x 88 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_mlp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['index',\n",
       " 'lsa_0',\n",
       " 'lsa_1',\n",
       " 'lsa_2',\n",
       " 'lsa_3',\n",
       " 'lsa_4',\n",
       " 'hybrid',\n",
       " 'indica',\n",
       " 'sativa',\n",
       " 'anxiety',\n",
       " 'anxious',\n",
       " 'aroused',\n",
       " 'arthritis',\n",
       " 'creative',\n",
       " 'depression',\n",
       " 'dizzy',\n",
       " 'dry eyes',\n",
       " 'dry mouth',\n",
       " 'energetic',\n",
       " 'epilepsy',\n",
       " 'euphoric',\n",
       " 'eye pressure',\n",
       " 'fatigue',\n",
       " 'focused',\n",
       " 'giggly',\n",
       " 'happy',\n",
       " 'headache',\n",
       " 'hungry',\n",
       " 'migraines',\n",
       " 'pain',\n",
       " 'paranoid',\n",
       " 'relaxed',\n",
       " 'seizures',\n",
       " 'sleepy',\n",
       " 'spasticity',\n",
       " 'stress',\n",
       " 'talkative',\n",
       " 'tingly',\n",
       " 'uplifted',\n",
       " 'ammonia',\n",
       " 'apple',\n",
       " 'apricot',\n",
       " 'berry',\n",
       " 'blue cheese',\n",
       " 'blueberry',\n",
       " 'butter',\n",
       " 'cheese',\n",
       " 'chemical',\n",
       " 'chestnut',\n",
       " 'citrus',\n",
       " 'coffee',\n",
       " 'diesel',\n",
       " 'earthy',\n",
       " 'flowery',\n",
       " 'fruit',\n",
       " 'grape',\n",
       " 'grapefruit',\n",
       " 'honey',\n",
       " 'lavender',\n",
       " 'lemon',\n",
       " 'lime',\n",
       " 'mango',\n",
       " 'menthol',\n",
       " 'mint',\n",
       " 'nutty',\n",
       " 'orange',\n",
       " 'peach',\n",
       " 'pear',\n",
       " 'pepper',\n",
       " 'pine',\n",
       " 'pineapple',\n",
       " 'plum',\n",
       " 'pungent',\n",
       " 'rose',\n",
       " 'sage',\n",
       " 'skunk',\n",
       " 'spicy/herbal',\n",
       " 'strawberry',\n",
       " 'sweet',\n",
       " 'tar',\n",
       " 'tea',\n",
       " 'tobacco',\n",
       " 'tree',\n",
       " 'tropical',\n",
       " 'vanilla',\n",
       " 'violet',\n",
       " 'woody',\n",
       " 'X..Isopulegol']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_mlp.columns.to_list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df_mlp.drop(['index', 'X..Isopulegol'], axis = 1)\n",
    "y = df_mlp[['X..Isopulegol']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:ylabel='Count'>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "sns.histplot(y, bins = 10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train test split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=1, test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train1, X_val, y_train1, y_val = train_test_split(X_train, y_train, random_state=1, test_size=0.25)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "MLP modeling (before Feature selection and Hyperparameter Tuning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/andalanputra/opt/anaconda3/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:1623: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    }
   ],
   "source": [
    "mlpreg = MLPRegressor(random_state=1, early_stopping=True)\n",
    "mlpreg.fit(X_train1, y_train1)\n",
    "y_pred_mlp = mlpreg.predict(X_val)\n",
    "y_pred_mlp_r2 = mlpreg.predict(X_train1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.14967683035834098"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mean_absolute_error(y_val, y_pred_mlp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8232945324105705"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#train\n",
    "r2_score(y_train1, y_pred_mlp_r2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7604362116683282"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#val\n",
    "r2_score(y_val, y_pred_mlp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Residual plots for each target variable"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Feature Selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "rfreg = RandomForestRegressor()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/andalanputra/opt/anaconda3/lib/python3.9/site-packages/sklearn/feature_selection/_from_model.py:357: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  self.estimator_.fit(X, y, **fit_params)\n"
     ]
    }
   ],
   "source": [
    "selector = SelectFromModel(rfreg).fit(X_train1, y_train1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([8.83126513e-02, 8.41618189e-02, 9.87934288e-02, 8.38077672e-02,\n",
       "       8.25987699e-02, 2.96779647e-01, 0.00000000e+00, 0.00000000e+00,\n",
       "       2.09893762e-05, 2.06144683e-03, 9.80290447e-03, 0.00000000e+00,\n",
       "       4.75217607e-03, 5.04454205e-05, 4.06101310e-03, 4.56748116e-03,\n",
       "       5.31584698e-03, 7.09823365e-03, 0.00000000e+00, 5.81022863e-03,\n",
       "       0.00000000e+00, 0.00000000e+00, 4.80308531e-03, 8.32839070e-03,\n",
       "       7.66679347e-03, 2.75592308e-03, 4.03977649e-03, 1.56970075e-05,\n",
       "       0.00000000e+00, 2.39902049e-03, 1.17453083e-02, 0.00000000e+00,\n",
       "       5.08561480e-03, 0.00000000e+00, 0.00000000e+00, 6.71174547e-03,\n",
       "       3.98043328e-03, 4.52693474e-03, 1.13545906e-04, 1.66428894e-04,\n",
       "       3.76114951e-04, 5.76931893e-03, 7.54884872e-05, 4.08084018e-03,\n",
       "       3.31281310e-04, 1.27364058e-02, 1.10509213e-03, 2.71475208e-04,\n",
       "       7.76126316e-03, 4.30315968e-04, 1.96726849e-02, 5.82564214e-03,\n",
       "       1.25302143e-02, 1.27009023e-03, 6.98902146e-03, 1.36432513e-03,\n",
       "       6.08653297e-04, 2.46531939e-03, 1.28894156e-02, 1.06270961e-03,\n",
       "       9.79160835e-04, 7.37528312e-04, 6.12180764e-03, 1.13900537e-03,\n",
       "       1.49657965e-02, 7.85619887e-04, 4.14398213e-05, 7.77543082e-04,\n",
       "       6.22922093e-03, 5.54263491e-04, 1.30932268e-03, 3.30214491e-03,\n",
       "       3.39348316e-04, 5.61484510e-04, 5.62624573e-03, 3.01997275e-03,\n",
       "       3.55117964e-04, 5.88180264e-03, 1.35024567e-04, 7.63132148e-04,\n",
       "       2.16258871e-04, 1.06461045e-03, 1.75290815e-03, 1.93594442e-03,\n",
       "       2.95344955e-04, 3.16073225e-03])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "selector.estimator_.feature_importances_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.01162790697674419"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "selector.threshold_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "mask = selector.get_support()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ True,  True,  True,  True,  True,  True, False, False, False,\n",
       "       False, False, False, False, False, False, False, False, False,\n",
       "       False, False, False, False, False, False, False, False, False,\n",
       "       False, False, False,  True, False, False, False, False, False,\n",
       "       False, False, False, False, False, False, False, False, False,\n",
       "        True, False, False, False, False,  True, False,  True, False,\n",
       "       False, False, False, False,  True, False, False, False, False,\n",
       "       False,  True, False, False, False, False, False, False, False,\n",
       "       False, False, False, False, False, False, False, False, False,\n",
       "       False, False, False, False, False])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "selected_features = X.columns[mask]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>lsa_0</th>\n",
       "      <th>lsa_1</th>\n",
       "      <th>lsa_2</th>\n",
       "      <th>lsa_3</th>\n",
       "      <th>lsa_4</th>\n",
       "      <th>hybrid</th>\n",
       "      <th>relaxed</th>\n",
       "      <th>cheese</th>\n",
       "      <th>diesel</th>\n",
       "      <th>flowery</th>\n",
       "      <th>lemon</th>\n",
       "      <th>orange</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.243491</td>\n",
       "      <td>0.034313</td>\n",
       "      <td>0.080290</td>\n",
       "      <td>-0.165609</td>\n",
       "      <td>0.019773</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.243491</td>\n",
       "      <td>0.034313</td>\n",
       "      <td>0.080290</td>\n",
       "      <td>-0.165609</td>\n",
       "      <td>0.019773</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.243491</td>\n",
       "      <td>0.034313</td>\n",
       "      <td>0.080290</td>\n",
       "      <td>-0.165609</td>\n",
       "      <td>0.019773</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.276418</td>\n",
       "      <td>-0.133986</td>\n",
       "      <td>0.116293</td>\n",
       "      <td>0.073694</td>\n",
       "      <td>0.041143</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.401841</td>\n",
       "      <td>-0.062527</td>\n",
       "      <td>-0.018128</td>\n",
       "      <td>-0.104475</td>\n",
       "      <td>0.009215</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49995</th>\n",
       "      <td>0.360708</td>\n",
       "      <td>-0.269375</td>\n",
       "      <td>0.169135</td>\n",
       "      <td>0.099257</td>\n",
       "      <td>0.141142</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49996</th>\n",
       "      <td>0.107417</td>\n",
       "      <td>-0.105614</td>\n",
       "      <td>-0.117669</td>\n",
       "      <td>-0.047306</td>\n",
       "      <td>0.055133</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49997</th>\n",
       "      <td>0.109738</td>\n",
       "      <td>-0.066611</td>\n",
       "      <td>-0.064934</td>\n",
       "      <td>0.145920</td>\n",
       "      <td>-0.069040</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49998</th>\n",
       "      <td>0.440634</td>\n",
       "      <td>-0.078839</td>\n",
       "      <td>0.085152</td>\n",
       "      <td>0.087878</td>\n",
       "      <td>-0.133604</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49999</th>\n",
       "      <td>0.440634</td>\n",
       "      <td>-0.078839</td>\n",
       "      <td>0.085152</td>\n",
       "      <td>0.087878</td>\n",
       "      <td>-0.133604</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>50000 rows × 12 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          lsa_0     lsa_1     lsa_2     lsa_3     lsa_4  hybrid  relaxed  \\\n",
       "0      0.243491  0.034313  0.080290 -0.165609  0.019773       1        1   \n",
       "1      0.243491  0.034313  0.080290 -0.165609  0.019773       1        1   \n",
       "2      0.243491  0.034313  0.080290 -0.165609  0.019773       1        1   \n",
       "3      0.276418 -0.133986  0.116293  0.073694  0.041143       1        0   \n",
       "4      0.401841 -0.062527 -0.018128 -0.104475  0.009215       1        1   \n",
       "...         ...       ...       ...       ...       ...     ...      ...   \n",
       "49995  0.360708 -0.269375  0.169135  0.099257  0.141142       0        0   \n",
       "49996  0.107417 -0.105614 -0.117669 -0.047306  0.055133       0        0   \n",
       "49997  0.109738 -0.066611 -0.064934  0.145920 -0.069040       0        1   \n",
       "49998  0.440634 -0.078839  0.085152  0.087878 -0.133604       0        0   \n",
       "49999  0.440634 -0.078839  0.085152  0.087878 -0.133604       0        0   \n",
       "\n",
       "       cheese  diesel  flowery  lemon  orange  \n",
       "0           1       0        0      0       0  \n",
       "1           1       0        0      0       0  \n",
       "2           1       0        0      0       0  \n",
       "3           0       0        0      0       0  \n",
       "4           0       0        0      0       0  \n",
       "...       ...     ...      ...    ...     ...  \n",
       "49995       0       0        0      0       0  \n",
       "49996       0       0        0      0       0  \n",
       "49997       0       0        0      0       0  \n",
       "49998       0       0        0      0       0  \n",
       "49999       0       0        0      0       0  \n",
       "\n",
       "[50000 rows x 12 columns]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "selected_X = df_mlp[selected_features]\n",
    "selected_X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['lsa_0',\n",
       " 'lsa_1',\n",
       " 'lsa_2',\n",
       " 'lsa_3',\n",
       " 'lsa_4',\n",
       " 'hybrid',\n",
       " 'relaxed',\n",
       " 'cheese',\n",
       " 'diesel',\n",
       " 'flowery',\n",
       " 'lemon',\n",
       " 'orange']"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "selected_X.columns.to_list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['selected_X_mlp_lsa_elbow_isopul.pkl']"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import joblib\n",
    "\n",
    "joblib.dump(selector, \"selector_mlp_lsa_elbow_isopul.pkl\")\n",
    "joblib.dump(selected_X, \"selected_X_mlp_lsa_elbow_isopul.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import joblib\n",
    "\n",
    "# selected_X = joblib.load(\"selected_X_mlp_lsa_elbow_isopul.pkl\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train test split (after Feature Selection)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(selected_X, y, random_state=1, test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train1, X_val, y_train1, y_val = train_test_split(X_train, y_train, random_state=1, test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/andalanputra/opt/anaconda3/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:1623: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    }
   ],
   "source": [
    "mlpreg.fit(X_train1, y_train1)\n",
    "y_pred_mlpreg = mlpreg.predict(X_val)\n",
    "y_pred_mlpreg_r2 = mlpreg.predict(X_train1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.2681737479077702"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mean_absolute_error(y_val, y_pred_mlpreg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5268376130274264"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#train\n",
    "r2_score(y_train1, y_pred_mlpreg_r2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5076464632385909"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#val\n",
    "r2_score(y_val, y_pred_mlpreg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hyperparameter Tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "parameters = {'hidden_layer_sizes': [(100,), (50, 50, 50), (50, 100, 50)],\n",
    "              'activation': ['tanh', 'relu'], #only tanh and relu\n",
    "              'max_iter': [200, 500, 1000]\n",
    "              }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "rscv = RandomizedSearchCV(mlpreg,  \n",
    "                     parameters,   \n",
    "                     cv=5, \n",
    "                     scoring='neg_mean_absolute_error',\n",
    "                     n_jobs=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/andalanputra/opt/anaconda3/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:1623: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/Users/andalanputra/opt/anaconda3/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:1623: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/Users/andalanputra/opt/anaconda3/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:1623: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/Users/andalanputra/opt/anaconda3/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:1623: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/Users/andalanputra/opt/anaconda3/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:1623: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/Users/andalanputra/opt/anaconda3/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:1623: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/Users/andalanputra/opt/anaconda3/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:1623: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/Users/andalanputra/opt/anaconda3/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:1623: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/Users/andalanputra/opt/anaconda3/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:1623: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/Users/andalanputra/opt/anaconda3/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:1623: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/Users/andalanputra/opt/anaconda3/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:1623: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/Users/andalanputra/opt/anaconda3/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:1623: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/Users/andalanputra/opt/anaconda3/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:1623: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/Users/andalanputra/opt/anaconda3/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:1623: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/Users/andalanputra/opt/anaconda3/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:1623: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/Users/andalanputra/opt/anaconda3/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/Users/andalanputra/opt/anaconda3/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:1623: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/Users/andalanputra/opt/anaconda3/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:1623: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/Users/andalanputra/opt/anaconda3/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:1623: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/Users/andalanputra/opt/anaconda3/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:1623: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/Users/andalanputra/opt/anaconda3/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:1623: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/Users/andalanputra/opt/anaconda3/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:1623: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/Users/andalanputra/opt/anaconda3/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:1623: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/Users/andalanputra/opt/anaconda3/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:1623: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/Users/andalanputra/opt/anaconda3/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:1623: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/Users/andalanputra/opt/anaconda3/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:1623: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/Users/andalanputra/opt/anaconda3/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:1623: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/Users/andalanputra/opt/anaconda3/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:1623: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/Users/andalanputra/opt/anaconda3/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:1623: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/Users/andalanputra/opt/anaconda3/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:1623: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/Users/andalanputra/opt/anaconda3/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:1623: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/Users/andalanputra/opt/anaconda3/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:1623: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/Users/andalanputra/opt/anaconda3/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:1623: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/Users/andalanputra/opt/anaconda3/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:1623: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/Users/andalanputra/opt/anaconda3/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/Users/andalanputra/opt/anaconda3/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:1623: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/Users/andalanputra/opt/anaconda3/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:1623: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/Users/andalanputra/opt/anaconda3/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:1623: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/Users/andalanputra/opt/anaconda3/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:1623: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/Users/andalanputra/opt/anaconda3/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:1623: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/Users/andalanputra/opt/anaconda3/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:1623: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/Users/andalanputra/opt/anaconda3/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:1623: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/Users/andalanputra/opt/anaconda3/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:1623: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/Users/andalanputra/opt/anaconda3/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:1623: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/Users/andalanputra/opt/anaconda3/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:1623: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/Users/andalanputra/opt/anaconda3/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:1623: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/Users/andalanputra/opt/anaconda3/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:1623: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/Users/andalanputra/opt/anaconda3/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:1623: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/Users/andalanputra/opt/anaconda3/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:1623: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/Users/andalanputra/opt/anaconda3/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:1623: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/Users/andalanputra/opt/anaconda3/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:1623: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/Users/andalanputra/opt/anaconda3/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:1623: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/Users/andalanputra/opt/anaconda3/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:1623: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;background-color: white;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>RandomizedSearchCV(cv=5,\n",
       "                   estimator=MLPRegressor(early_stopping=True, random_state=1),\n",
       "                   n_jobs=-1,\n",
       "                   param_distributions={&#x27;activation&#x27;: [&#x27;tanh&#x27;, &#x27;relu&#x27;],\n",
       "                                        &#x27;hidden_layer_sizes&#x27;: [(100,),\n",
       "                                                               (50, 50, 50),\n",
       "                                                               (50, 100, 50)],\n",
       "                                        &#x27;max_iter&#x27;: [200, 500, 1000]},\n",
       "                   scoring=&#x27;neg_mean_absolute_error&#x27;)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" ><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">RandomizedSearchCV</label><div class=\"sk-toggleable__content\"><pre>RandomizedSearchCV(cv=5,\n",
       "                   estimator=MLPRegressor(early_stopping=True, random_state=1),\n",
       "                   n_jobs=-1,\n",
       "                   param_distributions={&#x27;activation&#x27;: [&#x27;tanh&#x27;, &#x27;relu&#x27;],\n",
       "                                        &#x27;hidden_layer_sizes&#x27;: [(100,),\n",
       "                                                               (50, 50, 50),\n",
       "                                                               (50, 100, 50)],\n",
       "                                        &#x27;max_iter&#x27;: [200, 500, 1000]},\n",
       "                   scoring=&#x27;neg_mean_absolute_error&#x27;)</pre></div></div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" ><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">estimator: MLPRegressor</label><div class=\"sk-toggleable__content\"><pre>MLPRegressor(early_stopping=True, random_state=1)</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-3\" type=\"checkbox\" ><label for=\"sk-estimator-id-3\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">MLPRegressor</label><div class=\"sk-toggleable__content\"><pre>MLPRegressor(early_stopping=True, random_state=1)</pre></div></div></div></div></div></div></div></div></div></div>"
      ],
      "text/plain": [
       "RandomizedSearchCV(cv=5,\n",
       "                   estimator=MLPRegressor(early_stopping=True, random_state=1),\n",
       "                   n_jobs=-1,\n",
       "                   param_distributions={'activation': ['tanh', 'relu'],\n",
       "                                        'hidden_layer_sizes': [(100,),\n",
       "                                                               (50, 50, 50),\n",
       "                                                               (50, 100, 50)],\n",
       "                                        'max_iter': [200, 500, 1000]},\n",
       "                   scoring='neg_mean_absolute_error')"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rscv.fit(X_train1, y_train1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'max_iter': 500, 'hidden_layer_sizes': (50, 50, 50), 'activation': 'tanh'}"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rscv.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['rscv_mlp_lsa_elbow_best_params_isopul.pkl']"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "joblib.dump(rscv, \"rscv_mlp_lsa_elbow_isopul.pkl\")\n",
    "joblib.dump(rscv.best_params_, \"rscv_mlp_lsa_elbow_best_params_isopul.pkl\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "MLP fit (after hyperparameter tuning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/andalanputra/opt/anaconda3/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:1623: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    }
   ],
   "source": [
    "mlpreg_ht = MLPRegressor(random_state=1, max_iter=500, activation = 'tanh', hidden_layer_sizes= (50,50,50), early_stopping=True)\n",
    "mlpreg_ht.fit(X_train1, y_train1)\n",
    "y_pred_mlp_ht = mlpreg_ht.predict(X_val)\n",
    "y_pred_mlp_r2_ht = mlpreg_ht.predict(X_train1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.1071778944911262"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mean_absolute_error(y_val, y_pred_mlp_ht)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9092315537875264"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#train\n",
    "r2_score(y_train1, y_pred_mlp_r2_ht)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8409484319924984"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#val\n",
    "r2_score(y_val, y_pred_mlp_ht)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Residual plots after Hyperparameter Tuning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Predicting model on the test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_mlpreg_test = mlpreg_ht.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['y_test_mlpreg_lsa_elbow_isopul.pkl']"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "joblib.dump(y_pred_mlpreg_test, \"y_pred_mlpreg_test_lsa_elbow_isopul.pkl\")\n",
    "joblib.dump(y_test, \"y_test_mlpreg_lsa_elbow_isopul.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.10846424841177871"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mean_absolute_error(y_test, y_pred_mlpreg_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.040041009561429294"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mean_squared_error(y_test, y_pred_mlpreg_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.20010249763915816"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mean_squared_error(y_test, y_pred_mlpreg_test, squared = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8398036597642378"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "r2_score(y_test, y_pred_mlpreg_test)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Error analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 576x432 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 432x288 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# assume y_pred is a numpy array and y_true is a pandas dataframe\n",
    "fig, ax = plt.subplots(figsize=(8, 6))\n",
    "\n",
    "column = \"X..Isopulegol\"  # specify the target variable name\n",
    "ax.hist(y_pred_mlpreg_test, alpha=0.5, label='y_pred', bins=20)\n",
    "ax.hist(y_test[column], alpha=0.5, label='y_true', bins=20)\n",
    "ax.legend(loc='upper right')\n",
    "ax.set_title(column)\n",
    "\n",
    "plt.show()\n",
    "plt.savefig('error_hist_mlp_lsa_elbow_isopul.png')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pearson R"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pearson correlation coefficient: 0.918\n",
      "P-value: 0.000\n"
     ]
    }
   ],
   "source": [
    "corr_coef, p_value = pearsonr(y_pred_mlpreg_test.flatten(), y_test.values.ravel())\n",
    "\n",
    "print(f\"Pearson correlation coefficient: {corr_coef:.3f}\")\n",
    "print(f\"P-value: {p_value:.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:>"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "corr_matrix = y_test.corr()\n",
    "sns.heatmap(corr_matrix, annot=True, cmap='coolwarm', center=0)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
