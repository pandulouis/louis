{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn import preprocessing\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.neural_network import MLPRegressor\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "from sklearn.metrics import r2_score\n",
    "from scipy.stats import pearsonr\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.feature_selection import SelectFromModel\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compiling complete dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_mlp = pd.read_csv(\"df_euca_lsa.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>lsa_0</th>\n",
       "      <th>lsa_1</th>\n",
       "      <th>lsa_2</th>\n",
       "      <th>lsa_3</th>\n",
       "      <th>lsa_4</th>\n",
       "      <th>hybrid</th>\n",
       "      <th>indica</th>\n",
       "      <th>sativa</th>\n",
       "      <th>anxiety</th>\n",
       "      <th>...</th>\n",
       "      <th>sweet</th>\n",
       "      <th>tar</th>\n",
       "      <th>tea</th>\n",
       "      <th>tobacco</th>\n",
       "      <th>tree</th>\n",
       "      <th>tropical</th>\n",
       "      <th>vanilla</th>\n",
       "      <th>violet</th>\n",
       "      <th>woody</th>\n",
       "      <th>X..Eucalyptol</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2</td>\n",
       "      <td>0.261225</td>\n",
       "      <td>0.100324</td>\n",
       "      <td>-0.043622</td>\n",
       "      <td>0.141860</td>\n",
       "      <td>-0.034786</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3</td>\n",
       "      <td>0.243491</td>\n",
       "      <td>0.034313</td>\n",
       "      <td>0.080290</td>\n",
       "      <td>-0.165609</td>\n",
       "      <td>0.019773</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>6</td>\n",
       "      <td>0.276418</td>\n",
       "      <td>-0.133986</td>\n",
       "      <td>0.116293</td>\n",
       "      <td>0.073694</td>\n",
       "      <td>0.041143</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>6</td>\n",
       "      <td>0.276418</td>\n",
       "      <td>-0.133986</td>\n",
       "      <td>0.116293</td>\n",
       "      <td>0.073694</td>\n",
       "      <td>0.041143</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>8</td>\n",
       "      <td>0.158467</td>\n",
       "      <td>0.230093</td>\n",
       "      <td>0.240255</td>\n",
       "      <td>-0.230257</td>\n",
       "      <td>-0.280443</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>74995</th>\n",
       "      <td>42956</td>\n",
       "      <td>0.038338</td>\n",
       "      <td>0.015059</td>\n",
       "      <td>-0.011836</td>\n",
       "      <td>-0.010530</td>\n",
       "      <td>-0.029754</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>74996</th>\n",
       "      <td>42956</td>\n",
       "      <td>0.038338</td>\n",
       "      <td>0.015059</td>\n",
       "      <td>-0.011836</td>\n",
       "      <td>-0.010530</td>\n",
       "      <td>-0.029754</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>74997</th>\n",
       "      <td>42970</td>\n",
       "      <td>0.440634</td>\n",
       "      <td>-0.078839</td>\n",
       "      <td>0.085152</td>\n",
       "      <td>0.087878</td>\n",
       "      <td>-0.133604</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>74998</th>\n",
       "      <td>42972</td>\n",
       "      <td>0.181714</td>\n",
       "      <td>-0.045560</td>\n",
       "      <td>-0.055692</td>\n",
       "      <td>0.015649</td>\n",
       "      <td>-0.045585</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>74999</th>\n",
       "      <td>42973</td>\n",
       "      <td>0.055494</td>\n",
       "      <td>0.003622</td>\n",
       "      <td>-0.050252</td>\n",
       "      <td>-0.024795</td>\n",
       "      <td>-0.031141</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>75000 rows × 88 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       index     lsa_0     lsa_1     lsa_2     lsa_3     lsa_4  hybrid  \\\n",
       "0          2  0.261225  0.100324 -0.043622  0.141860 -0.034786       1   \n",
       "1          3  0.243491  0.034313  0.080290 -0.165609  0.019773       1   \n",
       "2          6  0.276418 -0.133986  0.116293  0.073694  0.041143       1   \n",
       "3          6  0.276418 -0.133986  0.116293  0.073694  0.041143       1   \n",
       "4          8  0.158467  0.230093  0.240255 -0.230257 -0.280443       1   \n",
       "...      ...       ...       ...       ...       ...       ...     ...   \n",
       "74995  42956  0.038338  0.015059 -0.011836 -0.010530 -0.029754       0   \n",
       "74996  42956  0.038338  0.015059 -0.011836 -0.010530 -0.029754       0   \n",
       "74997  42970  0.440634 -0.078839  0.085152  0.087878 -0.133604       0   \n",
       "74998  42972  0.181714 -0.045560 -0.055692  0.015649 -0.045585       0   \n",
       "74999  42973  0.055494  0.003622 -0.050252 -0.024795 -0.031141       0   \n",
       "\n",
       "       indica  sativa  anxiety  ...  sweet  tar  tea  tobacco  tree  tropical  \\\n",
       "0           0       0        0  ...      1    0    0        0     0         0   \n",
       "1           0       0        0  ...      0    1    0        0     0         0   \n",
       "2           0       0        0  ...      0    0    0        0     0         0   \n",
       "3           0       0        0  ...      0    0    0        0     0         0   \n",
       "4           0       0        0  ...      0    0    0        0     0         0   \n",
       "...       ...     ...      ...  ...    ...  ...  ...      ...   ...       ...   \n",
       "74995       1       0        0  ...      0    0    0        0     0         0   \n",
       "74996       1       0        0  ...      0    0    0        0     0         0   \n",
       "74997       1       0        0  ...      0    0    0        0     0         0   \n",
       "74998       1       0        0  ...      0    0    0        0     0         0   \n",
       "74999       1       0        0  ...      0    0    0        0     0         0   \n",
       "\n",
       "       vanilla  violet  woody  X..Eucalyptol  \n",
       "0            1       0      0            0.0  \n",
       "1            0       0      0            0.0  \n",
       "2            0       0      0            0.0  \n",
       "3            0       0      0            0.0  \n",
       "4            0       0      0            0.0  \n",
       "...        ...     ...    ...            ...  \n",
       "74995        0       0      0            0.0  \n",
       "74996        0       0      0            0.0  \n",
       "74997        0       0      0            0.0  \n",
       "74998        0       0      0            0.0  \n",
       "74999        0       0      0            0.0  \n",
       "\n",
       "[75000 rows x 88 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_mlp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['index',\n",
       " 'lsa_0',\n",
       " 'lsa_1',\n",
       " 'lsa_2',\n",
       " 'lsa_3',\n",
       " 'lsa_4',\n",
       " 'hybrid',\n",
       " 'indica',\n",
       " 'sativa',\n",
       " 'anxiety',\n",
       " 'anxious',\n",
       " 'aroused',\n",
       " 'arthritis',\n",
       " 'creative',\n",
       " 'depression',\n",
       " 'dizzy',\n",
       " 'dry eyes',\n",
       " 'dry mouth',\n",
       " 'energetic',\n",
       " 'epilepsy',\n",
       " 'euphoric',\n",
       " 'eye pressure',\n",
       " 'fatigue',\n",
       " 'focused',\n",
       " 'giggly',\n",
       " 'happy',\n",
       " 'headache',\n",
       " 'hungry',\n",
       " 'migraines',\n",
       " 'pain',\n",
       " 'paranoid',\n",
       " 'relaxed',\n",
       " 'seizures',\n",
       " 'sleepy',\n",
       " 'spasticity',\n",
       " 'stress',\n",
       " 'talkative',\n",
       " 'tingly',\n",
       " 'uplifted',\n",
       " 'ammonia',\n",
       " 'apple',\n",
       " 'apricot',\n",
       " 'berry',\n",
       " 'blue cheese',\n",
       " 'blueberry',\n",
       " 'butter',\n",
       " 'cheese',\n",
       " 'chemical',\n",
       " 'chestnut',\n",
       " 'citrus',\n",
       " 'coffee',\n",
       " 'diesel',\n",
       " 'earthy',\n",
       " 'flowery',\n",
       " 'fruit',\n",
       " 'grape',\n",
       " 'grapefruit',\n",
       " 'honey',\n",
       " 'lavender',\n",
       " 'lemon',\n",
       " 'lime',\n",
       " 'mango',\n",
       " 'menthol',\n",
       " 'mint',\n",
       " 'nutty',\n",
       " 'orange',\n",
       " 'peach',\n",
       " 'pear',\n",
       " 'pepper',\n",
       " 'pine',\n",
       " 'pineapple',\n",
       " 'plum',\n",
       " 'pungent',\n",
       " 'rose',\n",
       " 'sage',\n",
       " 'skunk',\n",
       " 'spicy/herbal',\n",
       " 'strawberry',\n",
       " 'sweet',\n",
       " 'tar',\n",
       " 'tea',\n",
       " 'tobacco',\n",
       " 'tree',\n",
       " 'tropical',\n",
       " 'vanilla',\n",
       " 'violet',\n",
       " 'woody',\n",
       " 'X..Eucalyptol']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_mlp.columns.to_list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df_mlp.drop(['index', 'X..Eucalyptol'], axis = 1)\n",
    "y = df_mlp[['X..Eucalyptol']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:ylabel='Count'>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "sns.histplot(y, bins = 10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train test split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=1, test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train1, X_val, y_train1, y_val = train_test_split(X_train, y_train, random_state=1, test_size=0.25)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "MLP modeling (before Feature selection and Hyperparameter Tuning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/andalanputra/opt/anaconda3/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:1623: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    }
   ],
   "source": [
    "mlpreg = MLPRegressor(random_state=1, early_stopping=True)\n",
    "mlpreg.fit(X_train1, y_train1)\n",
    "y_pred_mlp = mlpreg.predict(X_val)\n",
    "y_pred_mlp_r2 = mlpreg.predict(X_train1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.11488540908262425"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mean_absolute_error(y_val, y_pred_mlp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7971256521899894"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#train\n",
    "r2_score(y_train1, y_pred_mlp_r2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7059203840533808"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#val\n",
    "r2_score(y_val, y_pred_mlp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Residual plots for each target variable"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Feature Selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "rfreg = RandomForestRegressor()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/andalanputra/opt/anaconda3/lib/python3.9/site-packages/sklearn/feature_selection/_from_model.py:357: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  self.estimator_.fit(X, y, **fit_params)\n"
     ]
    }
   ],
   "source": [
    "selector = SelectFromModel(rfreg).fit(X_train1, y_train1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([8.52191944e-02, 7.31984774e-02, 7.94502655e-02, 1.03018272e-01,\n",
       "       8.86952384e-02, 3.65372199e-02, 6.71278088e-02, 1.00795846e-02,\n",
       "       1.60792873e-04, 2.46634545e-03, 3.60368116e-03, 0.00000000e+00,\n",
       "       8.07230574e-03, 1.39352455e-04, 3.25905100e-03, 5.05901790e-03,\n",
       "       7.64493239e-03, 6.77282319e-03, 0.00000000e+00, 9.70623227e-03,\n",
       "       0.00000000e+00, 0.00000000e+00, 5.67200015e-03, 7.76022641e-03,\n",
       "       8.67346044e-03, 2.56211317e-03, 5.94856179e-03, 1.44434201e-04,\n",
       "       0.00000000e+00, 2.19187041e-03, 1.09729459e-02, 0.00000000e+00,\n",
       "       5.42503566e-03, 0.00000000e+00, 0.00000000e+00, 4.96487679e-03,\n",
       "       4.28945748e-03, 7.92897381e-03, 1.79167191e-03, 1.36150070e-03,\n",
       "       7.38273153e-04, 7.35109669e-03, 1.95493757e-03, 8.61876204e-03,\n",
       "       2.79774437e-04, 4.59741329e-03, 1.91346299e-03, 2.99375872e-04,\n",
       "       7.44889191e-03, 1.58772804e-03, 1.42071067e-01, 1.31348107e-02,\n",
       "       4.24941650e-03, 1.01328988e-03, 4.35811803e-03, 9.82904627e-04,\n",
       "       7.21072587e-04, 2.34982937e-03, 7.07907425e-02, 2.16085989e-03,\n",
       "       4.36496862e-04, 4.21558683e-04, 1.79644280e-03, 1.32615046e-03,\n",
       "       7.00702225e-03, 2.70415802e-04, 3.23084641e-04, 1.76914993e-03,\n",
       "       4.83351453e-03, 1.91978692e-03, 4.16455742e-04, 5.40763066e-03,\n",
       "       7.85644626e-04, 2.10416202e-03, 4.11895083e-03, 4.64650901e-03,\n",
       "       7.08108328e-03, 7.36553287e-03, 5.05946363e-04, 1.45061803e-03,\n",
       "       1.03409387e-03, 5.51002902e-04, 2.96621412e-03, 4.71945176e-04,\n",
       "       4.12456306e-04, 4.05858002e-03])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "selector.estimator_.feature_importances_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.011627906976744186"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "selector.threshold_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "mask = selector.get_support()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ True,  True,  True,  True,  True,  True,  True, False, False,\n",
       "       False, False, False, False, False, False, False, False, False,\n",
       "       False, False, False, False, False, False, False, False, False,\n",
       "       False, False, False, False, False, False, False, False, False,\n",
       "       False, False, False, False, False, False, False, False, False,\n",
       "       False, False, False, False, False,  True,  True, False, False,\n",
       "       False, False, False, False,  True, False, False, False, False,\n",
       "       False, False, False, False, False, False, False, False, False,\n",
       "       False, False, False, False, False, False, False, False, False,\n",
       "       False, False, False, False, False])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "selected_features = X.columns[mask]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>lsa_0</th>\n",
       "      <th>lsa_1</th>\n",
       "      <th>lsa_2</th>\n",
       "      <th>lsa_3</th>\n",
       "      <th>lsa_4</th>\n",
       "      <th>hybrid</th>\n",
       "      <th>indica</th>\n",
       "      <th>diesel</th>\n",
       "      <th>earthy</th>\n",
       "      <th>lemon</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.261225</td>\n",
       "      <td>0.100324</td>\n",
       "      <td>-0.043622</td>\n",
       "      <td>0.141860</td>\n",
       "      <td>-0.034786</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.243491</td>\n",
       "      <td>0.034313</td>\n",
       "      <td>0.080290</td>\n",
       "      <td>-0.165609</td>\n",
       "      <td>0.019773</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.276418</td>\n",
       "      <td>-0.133986</td>\n",
       "      <td>0.116293</td>\n",
       "      <td>0.073694</td>\n",
       "      <td>0.041143</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.276418</td>\n",
       "      <td>-0.133986</td>\n",
       "      <td>0.116293</td>\n",
       "      <td>0.073694</td>\n",
       "      <td>0.041143</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.158467</td>\n",
       "      <td>0.230093</td>\n",
       "      <td>0.240255</td>\n",
       "      <td>-0.230257</td>\n",
       "      <td>-0.280443</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>74995</th>\n",
       "      <td>0.038338</td>\n",
       "      <td>0.015059</td>\n",
       "      <td>-0.011836</td>\n",
       "      <td>-0.010530</td>\n",
       "      <td>-0.029754</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>74996</th>\n",
       "      <td>0.038338</td>\n",
       "      <td>0.015059</td>\n",
       "      <td>-0.011836</td>\n",
       "      <td>-0.010530</td>\n",
       "      <td>-0.029754</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>74997</th>\n",
       "      <td>0.440634</td>\n",
       "      <td>-0.078839</td>\n",
       "      <td>0.085152</td>\n",
       "      <td>0.087878</td>\n",
       "      <td>-0.133604</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>74998</th>\n",
       "      <td>0.181714</td>\n",
       "      <td>-0.045560</td>\n",
       "      <td>-0.055692</td>\n",
       "      <td>0.015649</td>\n",
       "      <td>-0.045585</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>74999</th>\n",
       "      <td>0.055494</td>\n",
       "      <td>0.003622</td>\n",
       "      <td>-0.050252</td>\n",
       "      <td>-0.024795</td>\n",
       "      <td>-0.031141</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>75000 rows × 10 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          lsa_0     lsa_1     lsa_2     lsa_3     lsa_4  hybrid  indica  \\\n",
       "0      0.261225  0.100324 -0.043622  0.141860 -0.034786       1       0   \n",
       "1      0.243491  0.034313  0.080290 -0.165609  0.019773       1       0   \n",
       "2      0.276418 -0.133986  0.116293  0.073694  0.041143       1       0   \n",
       "3      0.276418 -0.133986  0.116293  0.073694  0.041143       1       0   \n",
       "4      0.158467  0.230093  0.240255 -0.230257 -0.280443       1       0   \n",
       "...         ...       ...       ...       ...       ...     ...     ...   \n",
       "74995  0.038338  0.015059 -0.011836 -0.010530 -0.029754       0       1   \n",
       "74996  0.038338  0.015059 -0.011836 -0.010530 -0.029754       0       1   \n",
       "74997  0.440634 -0.078839  0.085152  0.087878 -0.133604       0       1   \n",
       "74998  0.181714 -0.045560 -0.055692  0.015649 -0.045585       0       1   \n",
       "74999  0.055494  0.003622 -0.050252 -0.024795 -0.031141       0       1   \n",
       "\n",
       "       diesel  earthy  lemon  \n",
       "0           0       0      0  \n",
       "1           0       0      0  \n",
       "2           0       0      0  \n",
       "3           0       0      0  \n",
       "4           0       0      0  \n",
       "...       ...     ...    ...  \n",
       "74995       0       0      0  \n",
       "74996       0       0      0  \n",
       "74997       0       0      0  \n",
       "74998       0       0      0  \n",
       "74999       0       0      0  \n",
       "\n",
       "[75000 rows x 10 columns]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "selected_X = df_mlp[selected_features]\n",
    "selected_X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['lsa_0',\n",
       " 'lsa_1',\n",
       " 'lsa_2',\n",
       " 'lsa_3',\n",
       " 'lsa_4',\n",
       " 'hybrid',\n",
       " 'indica',\n",
       " 'diesel',\n",
       " 'earthy',\n",
       " 'lemon']"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "selected_X.columns.to_list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['selected_X_mlp_lsa_elbow_euca.pkl']"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import joblib\n",
    "\n",
    "joblib.dump(selector, \"selector_mlp_lsa_elbow_euca.pkl\")\n",
    "joblib.dump(selected_X, \"selected_X_mlp_lsa_elbow_euca.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import joblib\n",
    "\n",
    "# selected_X = joblib.load(\"selected_X_mlp_lsa_elbow_euca.pkl\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train test split (after Feature Selection)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(selected_X, y, random_state=1, test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train1, X_val, y_train1, y_val = train_test_split(X_train, y_train, random_state=1, test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/andalanputra/opt/anaconda3/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:1623: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    }
   ],
   "source": [
    "mlpreg.fit(X_train1, y_train1)\n",
    "y_pred_mlpreg = mlpreg.predict(X_val)\n",
    "y_pred_mlpreg_r2 = mlpreg.predict(X_train1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.19779320759943889"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mean_absolute_error(y_val, y_pred_mlpreg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.4361735338644239"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#train\n",
    "r2_score(y_train1, y_pred_mlpreg_r2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.43362797458672175"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#val\n",
    "r2_score(y_val, y_pred_mlpreg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hyperparameter Tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "parameters = {'hidden_layer_sizes': [(100,), (50, 50, 50), (50, 100, 50)],\n",
    "              'activation': ['tanh', 'relu'], #only tanh and relu\n",
    "              'max_iter': [200, 500, 1000]\n",
    "              }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "rscv = RandomizedSearchCV(mlpreg,  \n",
    "                     parameters,   \n",
    "                     cv=5, \n",
    "                     scoring='neg_mean_absolute_error',\n",
    "                     n_jobs=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/andalanputra/opt/anaconda3/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:1623: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/Users/andalanputra/opt/anaconda3/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:1623: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/Users/andalanputra/opt/anaconda3/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:1623: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/Users/andalanputra/opt/anaconda3/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:1623: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/Users/andalanputra/opt/anaconda3/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:1623: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/Users/andalanputra/opt/anaconda3/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:1623: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/Users/andalanputra/opt/anaconda3/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:1623: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/Users/andalanputra/opt/anaconda3/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:1623: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/Users/andalanputra/opt/anaconda3/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:1623: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/Users/andalanputra/opt/anaconda3/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:1623: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/Users/andalanputra/opt/anaconda3/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:1623: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/Users/andalanputra/opt/anaconda3/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:1623: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/Users/andalanputra/opt/anaconda3/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:1623: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/Users/andalanputra/opt/anaconda3/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:1623: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/Users/andalanputra/opt/anaconda3/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:1623: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/Users/andalanputra/opt/anaconda3/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:1623: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/Users/andalanputra/opt/anaconda3/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:1623: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/Users/andalanputra/opt/anaconda3/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:1623: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/Users/andalanputra/opt/anaconda3/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:1623: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/Users/andalanputra/opt/anaconda3/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:1623: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/Users/andalanputra/opt/anaconda3/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:1623: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/Users/andalanputra/opt/anaconda3/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:1623: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/Users/andalanputra/opt/anaconda3/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:1623: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/Users/andalanputra/opt/anaconda3/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:1623: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/Users/andalanputra/opt/anaconda3/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:1623: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/Users/andalanputra/opt/anaconda3/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:1623: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/Users/andalanputra/opt/anaconda3/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:1623: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/Users/andalanputra/opt/anaconda3/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:1623: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/Users/andalanputra/opt/anaconda3/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:1623: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/Users/andalanputra/opt/anaconda3/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:1623: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/Users/andalanputra/opt/anaconda3/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:1623: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/Users/andalanputra/opt/anaconda3/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:1623: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/Users/andalanputra/opt/anaconda3/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:1623: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/Users/andalanputra/opt/anaconda3/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:1623: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/Users/andalanputra/opt/anaconda3/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:1623: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/Users/andalanputra/opt/anaconda3/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:1623: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/Users/andalanputra/opt/anaconda3/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:1623: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/Users/andalanputra/opt/anaconda3/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:1623: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/Users/andalanputra/opt/anaconda3/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:1623: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/Users/andalanputra/opt/anaconda3/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:1623: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/Users/andalanputra/opt/anaconda3/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/Users/andalanputra/opt/anaconda3/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:1623: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/Users/andalanputra/opt/anaconda3/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:1623: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/Users/andalanputra/opt/anaconda3/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:1623: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/Users/andalanputra/opt/anaconda3/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/Users/andalanputra/opt/anaconda3/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:1623: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/Users/andalanputra/opt/anaconda3/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:1623: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/Users/andalanputra/opt/anaconda3/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:1623: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/Users/andalanputra/opt/anaconda3/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:1623: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/Users/andalanputra/opt/anaconda3/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:1623: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/Users/andalanputra/opt/anaconda3/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:1623: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/Users/andalanputra/opt/anaconda3/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:1623: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/Users/andalanputra/opt/anaconda3/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/Users/andalanputra/opt/anaconda3/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/Users/andalanputra/opt/anaconda3/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/Users/andalanputra/opt/anaconda3/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:1623: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;background-color: white;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>RandomizedSearchCV(cv=5,\n",
       "                   estimator=MLPRegressor(early_stopping=True, random_state=1),\n",
       "                   n_jobs=-1,\n",
       "                   param_distributions={&#x27;activation&#x27;: [&#x27;tanh&#x27;, &#x27;relu&#x27;],\n",
       "                                        &#x27;hidden_layer_sizes&#x27;: [(100,),\n",
       "                                                               (50, 50, 50),\n",
       "                                                               (50, 100, 50)],\n",
       "                                        &#x27;max_iter&#x27;: [200, 500, 1000]},\n",
       "                   scoring=&#x27;neg_mean_absolute_error&#x27;)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" ><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">RandomizedSearchCV</label><div class=\"sk-toggleable__content\"><pre>RandomizedSearchCV(cv=5,\n",
       "                   estimator=MLPRegressor(early_stopping=True, random_state=1),\n",
       "                   n_jobs=-1,\n",
       "                   param_distributions={&#x27;activation&#x27;: [&#x27;tanh&#x27;, &#x27;relu&#x27;],\n",
       "                                        &#x27;hidden_layer_sizes&#x27;: [(100,),\n",
       "                                                               (50, 50, 50),\n",
       "                                                               (50, 100, 50)],\n",
       "                                        &#x27;max_iter&#x27;: [200, 500, 1000]},\n",
       "                   scoring=&#x27;neg_mean_absolute_error&#x27;)</pre></div></div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" ><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">estimator: MLPRegressor</label><div class=\"sk-toggleable__content\"><pre>MLPRegressor(early_stopping=True, random_state=1)</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-3\" type=\"checkbox\" ><label for=\"sk-estimator-id-3\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">MLPRegressor</label><div class=\"sk-toggleable__content\"><pre>MLPRegressor(early_stopping=True, random_state=1)</pre></div></div></div></div></div></div></div></div></div></div>"
      ],
      "text/plain": [
       "RandomizedSearchCV(cv=5,\n",
       "                   estimator=MLPRegressor(early_stopping=True, random_state=1),\n",
       "                   n_jobs=-1,\n",
       "                   param_distributions={'activation': ['tanh', 'relu'],\n",
       "                                        'hidden_layer_sizes': [(100,),\n",
       "                                                               (50, 50, 50),\n",
       "                                                               (50, 100, 50)],\n",
       "                                        'max_iter': [200, 500, 1000]},\n",
       "                   scoring='neg_mean_absolute_error')"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rscv.fit(X_train1, y_train1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'max_iter': 1000, 'hidden_layer_sizes': (50, 100, 50), 'activation': 'relu'}"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rscv.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['rscv_mlp_lsa_elbow_best_params_euca.pkl']"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "joblib.dump(rscv, \"rscv_mlp_lsa_elbow_euca.pkl\")\n",
    "joblib.dump(rscv.best_params_, \"rscv_mlp_lsa_elbow_best_params_euca.pkl\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "MLP fit (after hyperparameter tuning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/andalanputra/opt/anaconda3/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:1623: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    }
   ],
   "source": [
    "mlpreg_ht = MLPRegressor(random_state=1, max_iter=1000, activation = 'relu', hidden_layer_sizes= (50,100,50), early_stopping=True)\n",
    "mlpreg_ht.fit(X_train1, y_train1)\n",
    "y_pred_mlp_ht = mlpreg_ht.predict(X_val)\n",
    "y_pred_mlp_r2_ht = mlpreg_ht.predict(X_train1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.1402474333575579"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mean_absolute_error(y_val, y_pred_mlp_ht)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6994346529957536"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#train\n",
    "r2_score(y_train1, y_pred_mlp_r2_ht)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6334005033224402"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#val\n",
    "r2_score(y_val, y_pred_mlp_ht)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Residual plots after Hyperparameter Tuning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Predicting model on the test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_mlpreg_test = mlpreg_ht.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['y_test_mlpreg_lsa_elbow_euca.pkl']"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "joblib.dump(y_pred_mlpreg_test, \"y_pred_mlpreg_test_lsa_elbow_euca.pkl\")\n",
    "joblib.dump(y_test, \"y_test_mlpreg_lsa_elbow_euca.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.13737078999764615"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mean_absolute_error(y_test, y_pred_mlpreg_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.04457228090820358"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mean_squared_error(y_test, y_pred_mlpreg_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.21112148376753034"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mean_squared_error(y_test, y_pred_mlpreg_test, squared = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6451174077063779"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "r2_score(y_test, y_pred_mlpreg_test)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Error analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 576x432 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 432x288 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# assume y_pred is a numpy array and y_true is a pandas dataframe\n",
    "fig, ax = plt.subplots(figsize=(8, 6))\n",
    "\n",
    "column = \"X..Eucalyptol\"  # specify the target variable name\n",
    "ax.hist(y_pred_mlpreg_test, alpha=0.5, label='y_pred', bins=20)\n",
    "ax.hist(y_test[column], alpha=0.5, label='y_true', bins=20)\n",
    "ax.legend(loc='upper right')\n",
    "ax.set_title(column)\n",
    "\n",
    "plt.show()\n",
    "plt.savefig('error_hist_mlp_lsa_elbow_euca.png')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pearson R"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pearson correlation coefficient: 0.803\n",
      "P-value: 0.000\n"
     ]
    }
   ],
   "source": [
    "corr_coef, p_value = pearsonr(y_pred_mlpreg_test.flatten(), y_test.values.ravel())\n",
    "\n",
    "print(f\"Pearson correlation coefficient: {corr_coef:.3f}\")\n",
    "print(f\"P-value: {p_value:.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:>"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "corr_matrix = y_test.corr()\n",
    "sns.heatmap(corr_matrix, annot=True, cmap='coolwarm', center=0)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
