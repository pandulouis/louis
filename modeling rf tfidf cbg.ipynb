{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn import preprocessing\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.neural_network import MLPRegressor\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "from sklearn.metrics import r2_score\n",
    "from scipy.stats import pearsonr\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.feature_selection import SelectFromModel\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compiling complete dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_rf = pd.read_csv(\"df_cbg_tfidf.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['index',\n",
       " 'tfidf_0',\n",
       " 'tfidf_1',\n",
       " 'tfidf_2',\n",
       " 'tfidf_3',\n",
       " 'tfidf_4',\n",
       " 'tfidf_5',\n",
       " 'tfidf_6',\n",
       " 'tfidf_7',\n",
       " 'tfidf_8',\n",
       " 'tfidf_9',\n",
       " 'tfidf_10',\n",
       " 'tfidf_11',\n",
       " 'tfidf_12',\n",
       " 'tfidf_13',\n",
       " 'tfidf_14',\n",
       " 'tfidf_15',\n",
       " 'tfidf_16',\n",
       " 'tfidf_17',\n",
       " 'tfidf_18',\n",
       " 'tfidf_19',\n",
       " 'tfidf_20',\n",
       " 'tfidf_21',\n",
       " 'tfidf_22',\n",
       " 'tfidf_23',\n",
       " 'tfidf_24',\n",
       " 'tfidf_25',\n",
       " 'tfidf_26',\n",
       " 'tfidf_27',\n",
       " 'tfidf_28',\n",
       " 'tfidf_29',\n",
       " 'tfidf_30',\n",
       " 'tfidf_31',\n",
       " 'tfidf_32',\n",
       " 'tfidf_33',\n",
       " 'tfidf_34',\n",
       " 'tfidf_35',\n",
       " 'tfidf_36',\n",
       " 'tfidf_37',\n",
       " 'tfidf_38',\n",
       " 'tfidf_39',\n",
       " 'tfidf_40',\n",
       " 'tfidf_41',\n",
       " 'tfidf_42',\n",
       " 'tfidf_43',\n",
       " 'tfidf_44',\n",
       " 'tfidf_45',\n",
       " 'tfidf_46',\n",
       " 'tfidf_47',\n",
       " 'tfidf_48',\n",
       " 'tfidf_49',\n",
       " 'tfidf_50',\n",
       " 'tfidf_51',\n",
       " 'tfidf_52',\n",
       " 'tfidf_53',\n",
       " 'tfidf_54',\n",
       " 'tfidf_55',\n",
       " 'tfidf_56',\n",
       " 'tfidf_57',\n",
       " 'tfidf_58',\n",
       " 'tfidf_59',\n",
       " 'tfidf_60',\n",
       " 'tfidf_61',\n",
       " 'tfidf_62',\n",
       " 'tfidf_63',\n",
       " 'tfidf_64',\n",
       " 'tfidf_65',\n",
       " 'tfidf_66',\n",
       " 'tfidf_67',\n",
       " 'tfidf_68',\n",
       " 'tfidf_69',\n",
       " 'tfidf_70',\n",
       " 'tfidf_71',\n",
       " 'tfidf_72',\n",
       " 'tfidf_73',\n",
       " 'tfidf_74',\n",
       " 'tfidf_75',\n",
       " 'tfidf_76',\n",
       " 'tfidf_77',\n",
       " 'tfidf_78',\n",
       " 'tfidf_79',\n",
       " 'tfidf_80',\n",
       " 'tfidf_81',\n",
       " 'tfidf_82',\n",
       " 'tfidf_83',\n",
       " 'tfidf_84',\n",
       " 'tfidf_85',\n",
       " 'tfidf_86',\n",
       " 'tfidf_87',\n",
       " 'tfidf_88',\n",
       " 'tfidf_89',\n",
       " 'tfidf_90',\n",
       " 'tfidf_91',\n",
       " 'tfidf_92',\n",
       " 'tfidf_93',\n",
       " 'tfidf_94',\n",
       " 'tfidf_95',\n",
       " 'tfidf_96',\n",
       " 'tfidf_97',\n",
       " 'tfidf_98',\n",
       " 'tfidf_99',\n",
       " 'tfidf_100',\n",
       " 'tfidf_101',\n",
       " 'tfidf_102',\n",
       " 'tfidf_103',\n",
       " 'tfidf_104',\n",
       " 'tfidf_105',\n",
       " 'tfidf_106',\n",
       " 'tfidf_107',\n",
       " 'tfidf_108',\n",
       " 'tfidf_109',\n",
       " 'tfidf_110',\n",
       " 'tfidf_111',\n",
       " 'tfidf_112',\n",
       " 'tfidf_113',\n",
       " 'tfidf_114',\n",
       " 'tfidf_115',\n",
       " 'tfidf_116',\n",
       " 'tfidf_117',\n",
       " 'tfidf_118',\n",
       " 'tfidf_119',\n",
       " 'tfidf_120',\n",
       " 'tfidf_121',\n",
       " 'tfidf_122',\n",
       " 'tfidf_123',\n",
       " 'tfidf_124',\n",
       " 'tfidf_125',\n",
       " 'tfidf_126',\n",
       " 'tfidf_127',\n",
       " 'tfidf_128',\n",
       " 'tfidf_129',\n",
       " 'tfidf_130',\n",
       " 'tfidf_131',\n",
       " 'tfidf_132',\n",
       " 'tfidf_133',\n",
       " 'tfidf_134',\n",
       " 'tfidf_135',\n",
       " 'tfidf_136',\n",
       " 'tfidf_137',\n",
       " 'tfidf_138',\n",
       " 'tfidf_139',\n",
       " 'tfidf_140',\n",
       " 'tfidf_141',\n",
       " 'tfidf_142',\n",
       " 'tfidf_143',\n",
       " 'tfidf_144',\n",
       " 'tfidf_145',\n",
       " 'tfidf_146',\n",
       " 'tfidf_147',\n",
       " 'tfidf_148',\n",
       " 'tfidf_149',\n",
       " 'tfidf_150',\n",
       " 'tfidf_151',\n",
       " 'tfidf_152',\n",
       " 'tfidf_153',\n",
       " 'tfidf_154',\n",
       " 'tfidf_155',\n",
       " 'tfidf_156',\n",
       " 'tfidf_157',\n",
       " 'tfidf_158',\n",
       " 'tfidf_159',\n",
       " 'tfidf_160',\n",
       " 'tfidf_161',\n",
       " 'tfidf_162',\n",
       " 'tfidf_163',\n",
       " 'tfidf_164',\n",
       " 'tfidf_165',\n",
       " 'tfidf_166',\n",
       " 'tfidf_167',\n",
       " 'tfidf_168',\n",
       " 'tfidf_169',\n",
       " 'tfidf_170',\n",
       " 'tfidf_171',\n",
       " 'tfidf_172',\n",
       " 'tfidf_173',\n",
       " 'tfidf_174',\n",
       " 'tfidf_175',\n",
       " 'tfidf_176',\n",
       " 'tfidf_177',\n",
       " 'tfidf_178',\n",
       " 'tfidf_179',\n",
       " 'tfidf_180',\n",
       " 'tfidf_181',\n",
       " 'tfidf_182',\n",
       " 'tfidf_183',\n",
       " 'tfidf_184',\n",
       " 'tfidf_185',\n",
       " 'tfidf_186',\n",
       " 'tfidf_187',\n",
       " 'tfidf_188',\n",
       " 'tfidf_189',\n",
       " 'tfidf_190',\n",
       " 'tfidf_191',\n",
       " 'tfidf_192',\n",
       " 'tfidf_193',\n",
       " 'tfidf_194',\n",
       " 'tfidf_195',\n",
       " 'tfidf_196',\n",
       " 'tfidf_197',\n",
       " 'tfidf_198',\n",
       " 'tfidf_199',\n",
       " 'tfidf_200',\n",
       " 'tfidf_201',\n",
       " 'tfidf_202',\n",
       " 'tfidf_203',\n",
       " 'tfidf_204',\n",
       " 'tfidf_205',\n",
       " 'tfidf_206',\n",
       " 'tfidf_207',\n",
       " 'tfidf_208',\n",
       " 'tfidf_209',\n",
       " 'tfidf_210',\n",
       " 'tfidf_211',\n",
       " 'tfidf_212',\n",
       " 'tfidf_213',\n",
       " 'tfidf_214',\n",
       " 'tfidf_215',\n",
       " 'tfidf_216',\n",
       " 'tfidf_217',\n",
       " 'tfidf_218',\n",
       " 'tfidf_219',\n",
       " 'tfidf_220',\n",
       " 'tfidf_221',\n",
       " 'tfidf_222',\n",
       " 'tfidf_223',\n",
       " 'tfidf_224',\n",
       " 'tfidf_225',\n",
       " 'tfidf_226',\n",
       " 'tfidf_227',\n",
       " 'tfidf_228',\n",
       " 'tfidf_229',\n",
       " 'tfidf_230',\n",
       " 'tfidf_231',\n",
       " 'tfidf_232',\n",
       " 'tfidf_233',\n",
       " 'tfidf_234',\n",
       " 'tfidf_235',\n",
       " 'tfidf_236',\n",
       " 'tfidf_237',\n",
       " 'tfidf_238',\n",
       " 'tfidf_239',\n",
       " 'tfidf_240',\n",
       " 'tfidf_241',\n",
       " 'tfidf_242',\n",
       " 'tfidf_243',\n",
       " 'tfidf_244',\n",
       " 'tfidf_245',\n",
       " 'tfidf_246',\n",
       " 'tfidf_247',\n",
       " 'tfidf_248',\n",
       " 'tfidf_249',\n",
       " 'tfidf_250',\n",
       " 'tfidf_251',\n",
       " 'tfidf_252',\n",
       " 'tfidf_253',\n",
       " 'tfidf_254',\n",
       " 'tfidf_255',\n",
       " 'tfidf_256',\n",
       " 'tfidf_257',\n",
       " 'tfidf_258',\n",
       " 'tfidf_259',\n",
       " 'tfidf_260',\n",
       " 'tfidf_261',\n",
       " 'tfidf_262',\n",
       " 'tfidf_263',\n",
       " 'tfidf_264',\n",
       " 'tfidf_265',\n",
       " 'tfidf_266',\n",
       " 'tfidf_267',\n",
       " 'tfidf_268',\n",
       " 'tfidf_269',\n",
       " 'tfidf_270',\n",
       " 'tfidf_271',\n",
       " 'tfidf_272',\n",
       " 'tfidf_273',\n",
       " 'tfidf_274',\n",
       " 'tfidf_275',\n",
       " 'tfidf_276',\n",
       " 'tfidf_277',\n",
       " 'tfidf_278',\n",
       " 'tfidf_279',\n",
       " 'tfidf_280',\n",
       " 'tfidf_281',\n",
       " 'tfidf_282',\n",
       " 'tfidf_283',\n",
       " 'tfidf_284',\n",
       " 'tfidf_285',\n",
       " 'tfidf_286',\n",
       " 'tfidf_287',\n",
       " 'tfidf_288',\n",
       " 'tfidf_289',\n",
       " 'tfidf_290',\n",
       " 'tfidf_291',\n",
       " 'tfidf_292',\n",
       " 'tfidf_293',\n",
       " 'tfidf_294',\n",
       " 'tfidf_295',\n",
       " 'tfidf_296',\n",
       " 'tfidf_297',\n",
       " 'tfidf_298',\n",
       " 'tfidf_299',\n",
       " 'tfidf_300',\n",
       " 'tfidf_301',\n",
       " 'tfidf_302',\n",
       " 'tfidf_303',\n",
       " 'tfidf_304',\n",
       " 'tfidf_305',\n",
       " 'tfidf_306',\n",
       " 'tfidf_307',\n",
       " 'tfidf_308',\n",
       " 'tfidf_309',\n",
       " 'tfidf_310',\n",
       " 'tfidf_311',\n",
       " 'tfidf_312',\n",
       " 'tfidf_313',\n",
       " 'tfidf_314',\n",
       " 'tfidf_315',\n",
       " 'tfidf_316',\n",
       " 'tfidf_317',\n",
       " 'tfidf_318',\n",
       " 'tfidf_319',\n",
       " 'tfidf_320',\n",
       " 'tfidf_321',\n",
       " 'tfidf_322',\n",
       " 'tfidf_323',\n",
       " 'tfidf_324',\n",
       " 'tfidf_325',\n",
       " 'tfidf_326',\n",
       " 'tfidf_327',\n",
       " 'tfidf_328',\n",
       " 'tfidf_329',\n",
       " 'tfidf_330',\n",
       " 'tfidf_331',\n",
       " 'tfidf_332',\n",
       " 'tfidf_333',\n",
       " 'tfidf_334',\n",
       " 'tfidf_335',\n",
       " 'tfidf_336',\n",
       " 'tfidf_337',\n",
       " 'tfidf_338',\n",
       " 'tfidf_339',\n",
       " 'tfidf_340',\n",
       " 'tfidf_341',\n",
       " 'tfidf_342',\n",
       " 'tfidf_343',\n",
       " 'tfidf_344',\n",
       " 'tfidf_345',\n",
       " 'tfidf_346',\n",
       " 'tfidf_347',\n",
       " 'tfidf_348',\n",
       " 'tfidf_349',\n",
       " 'tfidf_350',\n",
       " 'tfidf_351',\n",
       " 'tfidf_352',\n",
       " 'tfidf_353',\n",
       " 'tfidf_354',\n",
       " 'tfidf_355',\n",
       " 'tfidf_356',\n",
       " 'tfidf_357',\n",
       " 'tfidf_358',\n",
       " 'tfidf_359',\n",
       " 'tfidf_360',\n",
       " 'tfidf_361',\n",
       " 'tfidf_362',\n",
       " 'tfidf_363',\n",
       " 'tfidf_364',\n",
       " 'tfidf_365',\n",
       " 'tfidf_366',\n",
       " 'tfidf_367',\n",
       " 'tfidf_368',\n",
       " 'tfidf_369',\n",
       " 'tfidf_370',\n",
       " 'tfidf_371',\n",
       " 'tfidf_372',\n",
       " 'tfidf_373',\n",
       " 'tfidf_374',\n",
       " 'tfidf_375',\n",
       " 'tfidf_376',\n",
       " 'tfidf_377',\n",
       " 'tfidf_378',\n",
       " 'tfidf_379',\n",
       " 'tfidf_380',\n",
       " 'tfidf_381',\n",
       " 'tfidf_382',\n",
       " 'tfidf_383',\n",
       " 'tfidf_384',\n",
       " 'tfidf_385',\n",
       " 'tfidf_386',\n",
       " 'tfidf_387',\n",
       " 'hybrid',\n",
       " 'indica',\n",
       " 'sativa',\n",
       " 'anxiety',\n",
       " 'anxious',\n",
       " 'aroused',\n",
       " 'arthritis',\n",
       " 'creative',\n",
       " 'depression',\n",
       " 'dizzy',\n",
       " 'dry eyes',\n",
       " 'dry mouth',\n",
       " 'energetic',\n",
       " 'epilepsy',\n",
       " 'euphoric',\n",
       " 'eye pressure',\n",
       " 'fatigue',\n",
       " 'focused',\n",
       " 'giggly',\n",
       " 'happy',\n",
       " 'headache',\n",
       " 'hungry',\n",
       " 'migraines',\n",
       " 'pain',\n",
       " 'paranoid',\n",
       " 'relaxed',\n",
       " 'seizures',\n",
       " 'sleepy',\n",
       " 'spasticity',\n",
       " 'stress',\n",
       " 'talkative',\n",
       " 'tingly',\n",
       " 'uplifted',\n",
       " 'ammonia',\n",
       " 'apple',\n",
       " 'apricot',\n",
       " 'berry',\n",
       " 'blue cheese',\n",
       " 'blueberry',\n",
       " 'butter',\n",
       " 'cheese',\n",
       " 'chemical',\n",
       " 'chestnut',\n",
       " 'citrus',\n",
       " 'coffee',\n",
       " 'diesel',\n",
       " 'earthy',\n",
       " 'flowery',\n",
       " 'fruit',\n",
       " 'grape',\n",
       " 'grapefruit',\n",
       " 'honey',\n",
       " 'lavender',\n",
       " 'lemon',\n",
       " 'lime',\n",
       " 'mango',\n",
       " 'menthol',\n",
       " 'mint',\n",
       " 'nutty',\n",
       " 'orange',\n",
       " 'peach',\n",
       " 'pear',\n",
       " 'pepper',\n",
       " 'pine',\n",
       " 'pineapple',\n",
       " 'plum',\n",
       " 'pungent',\n",
       " 'rose',\n",
       " 'sage',\n",
       " 'skunk',\n",
       " 'spicy/herbal',\n",
       " 'strawberry',\n",
       " 'sweet',\n",
       " 'tar',\n",
       " 'tea',\n",
       " 'tobacco',\n",
       " 'tree',\n",
       " 'tropical',\n",
       " 'vanilla',\n",
       " 'violet',\n",
       " 'woody',\n",
       " 'X..CBG']"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_rf.columns.to_list()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Splitting dependent and independent variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df_rf.drop(['index', 'X..CBG'], axis = 1)\n",
    "y = df_rf[['X..CBG']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plotting histograms on target variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.04247104],\n",
       "       [0.04247104],\n",
       "       [0.04247104],\n",
       "       ...,\n",
       "       [0.33590734],\n",
       "       [0.33590734],\n",
       "       [0.33590734]])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_array = y.to_numpy()\n",
    "y_array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:ylabel='Count'>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "sns.histplot(y, bins = 10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train test split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=1, test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train1, X_val, y_train1, y_val = train_test_split(X_train, y_train, random_state=1, test_size=0.25)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "RF modeling (before Feature selection and Hyperparameter Tuning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/y1/pjvjlkjn5gl846rnyzr53p340000gn/T/ipykernel_9167/350139188.py:2: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  rfreg.fit(X_train1, y_train1)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;background-color: white;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>RandomForestRegressor()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">RandomForestRegressor</label><div class=\"sk-toggleable__content\"><pre>RandomForestRegressor()</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "RandomForestRegressor()"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rfreg = RandomForestRegressor()\n",
    "rfreg.fit(X_train1, y_train1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_rfreg = rfreg.predict(X_val)\n",
    "y_pred_rfreg_r2 = rfreg.predict(X_train1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.026523216330939046"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mean_absolute_error(y_val, y_pred_rfreg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.004639029576824657"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mean_squared_error(y_val, y_pred_rfreg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.06811042193985188"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mean_squared_error(y_val, y_pred_rfreg, squared = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9889671361538536"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#train\n",
    "r2_score(y_train1, y_pred_rfreg_r2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9357643772892066"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#val\n",
    "r2_score(y_val, y_pred_rfreg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Residual plots for each target variable"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Feature Selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_feat = pd.DataFrame({\n",
    "    \"features\": X_train1.columns,\n",
    "    \"score\": rfreg.feature_importances_\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>features</th>\n",
       "      <th>score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>tfidf_0</td>\n",
       "      <td>0.000273</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>tfidf_1</td>\n",
       "      <td>0.001225</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>tfidf_2</td>\n",
       "      <td>0.000178</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>tfidf_3</td>\n",
       "      <td>0.000171</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>tfidf_4</td>\n",
       "      <td>0.001481</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>464</th>\n",
       "      <td>tree</td>\n",
       "      <td>0.000200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>465</th>\n",
       "      <td>tropical</td>\n",
       "      <td>0.010486</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>466</th>\n",
       "      <td>vanilla</td>\n",
       "      <td>0.003261</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>467</th>\n",
       "      <td>violet</td>\n",
       "      <td>0.000107</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>468</th>\n",
       "      <td>woody</td>\n",
       "      <td>0.002020</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>469 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     features     score\n",
       "0     tfidf_0  0.000273\n",
       "1     tfidf_1  0.001225\n",
       "2     tfidf_2  0.000178\n",
       "3     tfidf_3  0.000171\n",
       "4     tfidf_4  0.001481\n",
       "..        ...       ...\n",
       "464      tree  0.000200\n",
       "465  tropical  0.010486\n",
       "466   vanilla  0.003261\n",
       "467    violet  0.000107\n",
       "468     woody  0.002020\n",
       "\n",
       "[469 rows x 2 columns]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_feat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_feat_ranked = df_feat.sort_values(\"score\", ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>features</th>\n",
       "      <th>score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>424</th>\n",
       "      <td>berry</td>\n",
       "      <td>2.083860e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>459</th>\n",
       "      <td>strawberry</td>\n",
       "      <td>1.041198e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>389</th>\n",
       "      <td>indica</td>\n",
       "      <td>9.072023e-02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>390</th>\n",
       "      <td>sativa</td>\n",
       "      <td>4.050349e-02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>329</th>\n",
       "      <td>tfidf_329</td>\n",
       "      <td>1.929160e-02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>154</th>\n",
       "      <td>tfidf_154</td>\n",
       "      <td>1.712360e-02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>tfidf_29</td>\n",
       "      <td>1.596217e-02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>176</th>\n",
       "      <td>tfidf_176</td>\n",
       "      <td>1.417043e-02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>437</th>\n",
       "      <td>grape</td>\n",
       "      <td>1.268792e-02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>433</th>\n",
       "      <td>diesel</td>\n",
       "      <td>1.097112e-02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>441</th>\n",
       "      <td>lemon</td>\n",
       "      <td>1.082084e-02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>447</th>\n",
       "      <td>orange</td>\n",
       "      <td>1.080657e-02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>465</th>\n",
       "      <td>tropical</td>\n",
       "      <td>1.048560e-02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>388</th>\n",
       "      <td>hybrid</td>\n",
       "      <td>9.876639e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>426</th>\n",
       "      <td>blueberry</td>\n",
       "      <td>9.534352e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>442</th>\n",
       "      <td>lime</td>\n",
       "      <td>7.038352e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>345</th>\n",
       "      <td>tfidf_345</td>\n",
       "      <td>6.820654e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>405</th>\n",
       "      <td>focused</td>\n",
       "      <td>6.819044e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>409</th>\n",
       "      <td>hungry</td>\n",
       "      <td>6.794576e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>428</th>\n",
       "      <td>cheese</td>\n",
       "      <td>6.474180e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>168</th>\n",
       "      <td>tfidf_168</td>\n",
       "      <td>6.443989e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>149</th>\n",
       "      <td>tfidf_149</td>\n",
       "      <td>6.316261e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>362</th>\n",
       "      <td>tfidf_362</td>\n",
       "      <td>6.163958e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>144</th>\n",
       "      <td>tfidf_144</td>\n",
       "      <td>5.890867e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>281</th>\n",
       "      <td>tfidf_281</td>\n",
       "      <td>5.593252e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>359</th>\n",
       "      <td>tfidf_359</td>\n",
       "      <td>5.467979e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>199</th>\n",
       "      <td>tfidf_199</td>\n",
       "      <td>5.466289e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>457</th>\n",
       "      <td>skunk</td>\n",
       "      <td>5.234045e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>210</th>\n",
       "      <td>tfidf_210</td>\n",
       "      <td>4.933543e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>121</th>\n",
       "      <td>tfidf_121</td>\n",
       "      <td>4.904386e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>239</th>\n",
       "      <td>tfidf_239</td>\n",
       "      <td>4.548537e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>141</th>\n",
       "      <td>tfidf_141</td>\n",
       "      <td>4.521365e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>285</th>\n",
       "      <td>tfidf_285</td>\n",
       "      <td>4.346664e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>431</th>\n",
       "      <td>citrus</td>\n",
       "      <td>4.295961e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>342</th>\n",
       "      <td>tfidf_342</td>\n",
       "      <td>4.122935e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>406</th>\n",
       "      <td>giggly</td>\n",
       "      <td>4.111664e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>145</th>\n",
       "      <td>tfidf_145</td>\n",
       "      <td>4.084216e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>283</th>\n",
       "      <td>tfidf_283</td>\n",
       "      <td>3.730994e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>125</th>\n",
       "      <td>tfidf_125</td>\n",
       "      <td>3.576370e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>312</th>\n",
       "      <td>tfidf_312</td>\n",
       "      <td>3.551120e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>56</th>\n",
       "      <td>tfidf_56</td>\n",
       "      <td>3.514786e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>245</th>\n",
       "      <td>tfidf_245</td>\n",
       "      <td>3.372188e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>466</th>\n",
       "      <td>vanilla</td>\n",
       "      <td>3.261299e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>253</th>\n",
       "      <td>tfidf_253</td>\n",
       "      <td>3.253353e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>438</th>\n",
       "      <td>grapefruit</td>\n",
       "      <td>3.086923e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>103</th>\n",
       "      <td>tfidf_103</td>\n",
       "      <td>3.030447e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>337</th>\n",
       "      <td>tfidf_337</td>\n",
       "      <td>2.969368e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>tfidf_7</td>\n",
       "      <td>2.952772e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>tfidf_98</td>\n",
       "      <td>2.934850e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>117</th>\n",
       "      <td>tfidf_117</td>\n",
       "      <td>2.845277e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>420</th>\n",
       "      <td>uplifted</td>\n",
       "      <td>2.825395e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>309</th>\n",
       "      <td>tfidf_309</td>\n",
       "      <td>2.809949e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>407</th>\n",
       "      <td>happy</td>\n",
       "      <td>2.743736e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>178</th>\n",
       "      <td>tfidf_178</td>\n",
       "      <td>2.743276e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>413</th>\n",
       "      <td>relaxed</td>\n",
       "      <td>2.710652e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>207</th>\n",
       "      <td>tfidf_207</td>\n",
       "      <td>2.701431e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>343</th>\n",
       "      <td>tfidf_343</td>\n",
       "      <td>2.559599e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>194</th>\n",
       "      <td>tfidf_194</td>\n",
       "      <td>2.556433e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>395</th>\n",
       "      <td>creative</td>\n",
       "      <td>2.536693e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>tfidf_96</td>\n",
       "      <td>2.507319e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>393</th>\n",
       "      <td>aroused</td>\n",
       "      <td>2.490285e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>60</th>\n",
       "      <td>tfidf_60</td>\n",
       "      <td>2.466622e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>tfidf_36</td>\n",
       "      <td>2.331195e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>158</th>\n",
       "      <td>tfidf_158</td>\n",
       "      <td>2.209411e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>78</th>\n",
       "      <td>tfidf_78</td>\n",
       "      <td>2.204143e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>434</th>\n",
       "      <td>earthy</td>\n",
       "      <td>2.150516e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>tfidf_30</td>\n",
       "      <td>2.088187e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>tfidf_43</td>\n",
       "      <td>2.039179e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>468</th>\n",
       "      <td>woody</td>\n",
       "      <td>2.020307e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>tfidf_37</td>\n",
       "      <td>1.994665e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>265</th>\n",
       "      <td>tfidf_265</td>\n",
       "      <td>1.976182e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>320</th>\n",
       "      <td>tfidf_320</td>\n",
       "      <td>1.947519e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>162</th>\n",
       "      <td>tfidf_162</td>\n",
       "      <td>1.938871e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52</th>\n",
       "      <td>tfidf_52</td>\n",
       "      <td>1.931689e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>451</th>\n",
       "      <td>pine</td>\n",
       "      <td>1.926411e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>73</th>\n",
       "      <td>tfidf_73</td>\n",
       "      <td>1.917489e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>267</th>\n",
       "      <td>tfidf_267</td>\n",
       "      <td>1.898174e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>270</th>\n",
       "      <td>tfidf_270</td>\n",
       "      <td>1.868768e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>402</th>\n",
       "      <td>euphoric</td>\n",
       "      <td>1.847675e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>379</th>\n",
       "      <td>tfidf_379</td>\n",
       "      <td>1.756159e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>303</th>\n",
       "      <td>tfidf_303</td>\n",
       "      <td>1.730593e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>230</th>\n",
       "      <td>tfidf_230</td>\n",
       "      <td>1.675406e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>399</th>\n",
       "      <td>dry mouth</td>\n",
       "      <td>1.658647e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>186</th>\n",
       "      <td>tfidf_186</td>\n",
       "      <td>1.639691e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>415</th>\n",
       "      <td>sleepy</td>\n",
       "      <td>1.602634e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>314</th>\n",
       "      <td>tfidf_314</td>\n",
       "      <td>1.587776e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>353</th>\n",
       "      <td>tfidf_353</td>\n",
       "      <td>1.574015e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53</th>\n",
       "      <td>tfidf_53</td>\n",
       "      <td>1.573407e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>381</th>\n",
       "      <td>tfidf_381</td>\n",
       "      <td>1.548876e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>418</th>\n",
       "      <td>talkative</td>\n",
       "      <td>1.546143e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>374</th>\n",
       "      <td>tfidf_374</td>\n",
       "      <td>1.508763e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>tfidf_4</td>\n",
       "      <td>1.480666e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>333</th>\n",
       "      <td>tfidf_333</td>\n",
       "      <td>1.467116e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>119</th>\n",
       "      <td>tfidf_119</td>\n",
       "      <td>1.465048e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>79</th>\n",
       "      <td>tfidf_79</td>\n",
       "      <td>1.451461e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>163</th>\n",
       "      <td>tfidf_163</td>\n",
       "      <td>1.445960e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>217</th>\n",
       "      <td>tfidf_217</td>\n",
       "      <td>1.440278e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>247</th>\n",
       "      <td>tfidf_247</td>\n",
       "      <td>1.416653e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>325</th>\n",
       "      <td>tfidf_325</td>\n",
       "      <td>1.415437e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>tfidf_11</td>\n",
       "      <td>1.359864e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>357</th>\n",
       "      <td>tfidf_357</td>\n",
       "      <td>1.358516e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>205</th>\n",
       "      <td>tfidf_205</td>\n",
       "      <td>1.332881e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>445</th>\n",
       "      <td>mint</td>\n",
       "      <td>1.327885e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54</th>\n",
       "      <td>tfidf_54</td>\n",
       "      <td>1.307369e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>316</th>\n",
       "      <td>tfidf_316</td>\n",
       "      <td>1.292890e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>173</th>\n",
       "      <td>tfidf_173</td>\n",
       "      <td>1.267275e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>tfidf_28</td>\n",
       "      <td>1.252049e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>tfidf_1</td>\n",
       "      <td>1.224635e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>400</th>\n",
       "      <td>energetic</td>\n",
       "      <td>1.219131e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>tfidf_46</td>\n",
       "      <td>1.200758e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>206</th>\n",
       "      <td>tfidf_206</td>\n",
       "      <td>1.190274e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>398</th>\n",
       "      <td>dry eyes</td>\n",
       "      <td>1.156079e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>310</th>\n",
       "      <td>tfidf_310</td>\n",
       "      <td>1.152559e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>181</th>\n",
       "      <td>tfidf_181</td>\n",
       "      <td>1.150228e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>258</th>\n",
       "      <td>tfidf_258</td>\n",
       "      <td>1.146739e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>282</th>\n",
       "      <td>tfidf_282</td>\n",
       "      <td>1.132257e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>352</th>\n",
       "      <td>tfidf_352</td>\n",
       "      <td>1.131787e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>460</th>\n",
       "      <td>sweet</td>\n",
       "      <td>1.129588e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50</th>\n",
       "      <td>tfidf_50</td>\n",
       "      <td>1.126583e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>104</th>\n",
       "      <td>tfidf_104</td>\n",
       "      <td>1.108673e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>tfidf_17</td>\n",
       "      <td>1.103124e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>366</th>\n",
       "      <td>tfidf_366</td>\n",
       "      <td>1.073522e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>167</th>\n",
       "      <td>tfidf_167</td>\n",
       "      <td>1.058326e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>367</th>\n",
       "      <td>tfidf_367</td>\n",
       "      <td>1.004354e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>454</th>\n",
       "      <td>pungent</td>\n",
       "      <td>1.002668e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>373</th>\n",
       "      <td>tfidf_373</td>\n",
       "      <td>9.963744e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>tfidf_26</td>\n",
       "      <td>9.919778e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>272</th>\n",
       "      <td>tfidf_272</td>\n",
       "      <td>9.894289e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>193</th>\n",
       "      <td>tfidf_193</td>\n",
       "      <td>9.881121e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>93</th>\n",
       "      <td>tfidf_93</td>\n",
       "      <td>9.771665e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>126</th>\n",
       "      <td>tfidf_126</td>\n",
       "      <td>9.737833e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>128</th>\n",
       "      <td>tfidf_128</td>\n",
       "      <td>9.731861e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>419</th>\n",
       "      <td>tingly</td>\n",
       "      <td>9.683837e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>332</th>\n",
       "      <td>tfidf_332</td>\n",
       "      <td>9.641649e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>155</th>\n",
       "      <td>tfidf_155</td>\n",
       "      <td>9.459294e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>tfidf_41</td>\n",
       "      <td>9.379366e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>387</th>\n",
       "      <td>tfidf_387</td>\n",
       "      <td>9.233332e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>340</th>\n",
       "      <td>tfidf_340</td>\n",
       "      <td>9.177159e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>323</th>\n",
       "      <td>tfidf_323</td>\n",
       "      <td>9.115538e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>77</th>\n",
       "      <td>tfidf_77</td>\n",
       "      <td>9.080967e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>61</th>\n",
       "      <td>tfidf_61</td>\n",
       "      <td>8.981346e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>tfidf_42</td>\n",
       "      <td>8.915000e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>450</th>\n",
       "      <td>pepper</td>\n",
       "      <td>8.907272e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>112</th>\n",
       "      <td>tfidf_112</td>\n",
       "      <td>8.754140e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>278</th>\n",
       "      <td>tfidf_278</td>\n",
       "      <td>8.689144e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>264</th>\n",
       "      <td>tfidf_264</td>\n",
       "      <td>8.680196e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>286</th>\n",
       "      <td>tfidf_286</td>\n",
       "      <td>8.677068e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>192</th>\n",
       "      <td>tfidf_192</td>\n",
       "      <td>8.645311e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>380</th>\n",
       "      <td>tfidf_380</td>\n",
       "      <td>8.474752e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>191</th>\n",
       "      <td>tfidf_191</td>\n",
       "      <td>8.301324e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>382</th>\n",
       "      <td>tfidf_382</td>\n",
       "      <td>8.254125e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>175</th>\n",
       "      <td>tfidf_175</td>\n",
       "      <td>8.094230e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>tfidf_19</td>\n",
       "      <td>7.954296e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>341</th>\n",
       "      <td>tfidf_341</td>\n",
       "      <td>7.941834e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>148</th>\n",
       "      <td>tfidf_148</td>\n",
       "      <td>7.939658e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>354</th>\n",
       "      <td>tfidf_354</td>\n",
       "      <td>7.915073e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>304</th>\n",
       "      <td>tfidf_304</td>\n",
       "      <td>7.914682e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>tfidf_20</td>\n",
       "      <td>7.913338e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>129</th>\n",
       "      <td>tfidf_129</td>\n",
       "      <td>7.690605e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>324</th>\n",
       "      <td>tfidf_324</td>\n",
       "      <td>7.607831e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>435</th>\n",
       "      <td>flowery</td>\n",
       "      <td>7.588766e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>137</th>\n",
       "      <td>tfidf_137</td>\n",
       "      <td>7.363608e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>240</th>\n",
       "      <td>tfidf_240</td>\n",
       "      <td>7.335379e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>164</th>\n",
       "      <td>tfidf_164</td>\n",
       "      <td>7.275024e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>287</th>\n",
       "      <td>tfidf_287</td>\n",
       "      <td>7.272072e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>130</th>\n",
       "      <td>tfidf_130</td>\n",
       "      <td>7.240471e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>222</th>\n",
       "      <td>tfidf_222</td>\n",
       "      <td>7.182662e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>458</th>\n",
       "      <td>spicy/herbal</td>\n",
       "      <td>7.144774e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>355</th>\n",
       "      <td>tfidf_355</td>\n",
       "      <td>7.111146e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>107</th>\n",
       "      <td>tfidf_107</td>\n",
       "      <td>6.974529e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>338</th>\n",
       "      <td>tfidf_338</td>\n",
       "      <td>6.915301e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>143</th>\n",
       "      <td>tfidf_143</td>\n",
       "      <td>6.868802e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>221</th>\n",
       "      <td>tfidf_221</td>\n",
       "      <td>6.866757e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>385</th>\n",
       "      <td>tfidf_385</td>\n",
       "      <td>6.845672e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>58</th>\n",
       "      <td>tfidf_58</td>\n",
       "      <td>6.809550e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>tfidf_40</td>\n",
       "      <td>6.796159e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>251</th>\n",
       "      <td>tfidf_251</td>\n",
       "      <td>6.731441e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>235</th>\n",
       "      <td>tfidf_235</td>\n",
       "      <td>6.656337e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>101</th>\n",
       "      <td>tfidf_101</td>\n",
       "      <td>6.644434e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>tfidf_45</td>\n",
       "      <td>6.637107e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>190</th>\n",
       "      <td>tfidf_190</td>\n",
       "      <td>6.558911e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>153</th>\n",
       "      <td>tfidf_153</td>\n",
       "      <td>6.444722e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>215</th>\n",
       "      <td>tfidf_215</td>\n",
       "      <td>6.296751e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>170</th>\n",
       "      <td>tfidf_170</td>\n",
       "      <td>6.241225e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>64</th>\n",
       "      <td>tfidf_64</td>\n",
       "      <td>6.093113e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>136</th>\n",
       "      <td>tfidf_136</td>\n",
       "      <td>6.082070e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>440</th>\n",
       "      <td>lavender</td>\n",
       "      <td>6.031455e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>tfidf_9</td>\n",
       "      <td>6.031374e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>tfidf_14</td>\n",
       "      <td>6.004979e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>291</th>\n",
       "      <td>tfidf_291</td>\n",
       "      <td>5.996773e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>177</th>\n",
       "      <td>tfidf_177</td>\n",
       "      <td>5.849922e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>tfidf_5</td>\n",
       "      <td>5.846530e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>294</th>\n",
       "      <td>tfidf_294</td>\n",
       "      <td>5.796814e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>151</th>\n",
       "      <td>tfidf_151</td>\n",
       "      <td>5.700284e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>166</th>\n",
       "      <td>tfidf_166</td>\n",
       "      <td>5.692424e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>346</th>\n",
       "      <td>tfidf_346</td>\n",
       "      <td>5.673802e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>453</th>\n",
       "      <td>plum</td>\n",
       "      <td>5.562222e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>371</th>\n",
       "      <td>tfidf_371</td>\n",
       "      <td>5.546849e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>tfidf_21</td>\n",
       "      <td>5.405854e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>123</th>\n",
       "      <td>tfidf_123</td>\n",
       "      <td>5.405580e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>376</th>\n",
       "      <td>tfidf_376</td>\n",
       "      <td>5.398049e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>tfidf_32</td>\n",
       "      <td>5.374086e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>69</th>\n",
       "      <td>tfidf_69</td>\n",
       "      <td>5.365406e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>289</th>\n",
       "      <td>tfidf_289</td>\n",
       "      <td>5.361937e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>349</th>\n",
       "      <td>tfidf_349</td>\n",
       "      <td>5.351624e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>274</th>\n",
       "      <td>tfidf_274</td>\n",
       "      <td>5.315659e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>298</th>\n",
       "      <td>tfidf_298</td>\n",
       "      <td>5.299383e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>200</th>\n",
       "      <td>tfidf_200</td>\n",
       "      <td>5.285554e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>350</th>\n",
       "      <td>tfidf_350</td>\n",
       "      <td>5.269274e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>184</th>\n",
       "      <td>tfidf_184</td>\n",
       "      <td>5.210236e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>124</th>\n",
       "      <td>tfidf_124</td>\n",
       "      <td>5.158071e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>83</th>\n",
       "      <td>tfidf_83</td>\n",
       "      <td>5.154621e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>122</th>\n",
       "      <td>tfidf_122</td>\n",
       "      <td>5.101143e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>198</th>\n",
       "      <td>tfidf_198</td>\n",
       "      <td>5.058213e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>tfidf_39</td>\n",
       "      <td>4.992195e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>71</th>\n",
       "      <td>tfidf_71</td>\n",
       "      <td>4.975072e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>tfidf_34</td>\n",
       "      <td>4.967655e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>208</th>\n",
       "      <td>tfidf_208</td>\n",
       "      <td>4.955627e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>tfidf_48</td>\n",
       "      <td>4.922532e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>213</th>\n",
       "      <td>tfidf_213</td>\n",
       "      <td>4.891762e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>tfidf_35</td>\n",
       "      <td>4.871410e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>90</th>\n",
       "      <td>tfidf_90</td>\n",
       "      <td>4.845454e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>273</th>\n",
       "      <td>tfidf_273</td>\n",
       "      <td>4.838933e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>tfidf_99</td>\n",
       "      <td>4.808695e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>231</th>\n",
       "      <td>tfidf_231</td>\n",
       "      <td>4.763450e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>tfidf_16</td>\n",
       "      <td>4.753402e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>146</th>\n",
       "      <td>tfidf_146</td>\n",
       "      <td>4.743898e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>336</th>\n",
       "      <td>tfidf_336</td>\n",
       "      <td>4.709847e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>277</th>\n",
       "      <td>tfidf_277</td>\n",
       "      <td>4.704279e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>370</th>\n",
       "      <td>tfidf_370</td>\n",
       "      <td>4.654300e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>412</th>\n",
       "      <td>paranoid</td>\n",
       "      <td>4.638548e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>368</th>\n",
       "      <td>tfidf_368</td>\n",
       "      <td>4.614009e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>238</th>\n",
       "      <td>tfidf_238</td>\n",
       "      <td>4.605882e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>455</th>\n",
       "      <td>rose</td>\n",
       "      <td>4.591590e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>204</th>\n",
       "      <td>tfidf_204</td>\n",
       "      <td>4.570185e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>319</th>\n",
       "      <td>tfidf_319</td>\n",
       "      <td>4.520447e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75</th>\n",
       "      <td>tfidf_75</td>\n",
       "      <td>4.481814e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>172</th>\n",
       "      <td>tfidf_172</td>\n",
       "      <td>4.476791e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>260</th>\n",
       "      <td>tfidf_260</td>\n",
       "      <td>4.463547e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>203</th>\n",
       "      <td>tfidf_203</td>\n",
       "      <td>4.444912e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>224</th>\n",
       "      <td>tfidf_224</td>\n",
       "      <td>4.435195e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>159</th>\n",
       "      <td>tfidf_159</td>\n",
       "      <td>4.431738e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>315</th>\n",
       "      <td>tfidf_315</td>\n",
       "      <td>4.419200e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>288</th>\n",
       "      <td>tfidf_288</td>\n",
       "      <td>4.368430e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>161</th>\n",
       "      <td>tfidf_161</td>\n",
       "      <td>4.363754e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>269</th>\n",
       "      <td>tfidf_269</td>\n",
       "      <td>4.341859e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>456</th>\n",
       "      <td>sage</td>\n",
       "      <td>4.315040e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>321</th>\n",
       "      <td>tfidf_321</td>\n",
       "      <td>4.301648e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>120</th>\n",
       "      <td>tfidf_120</td>\n",
       "      <td>4.259196e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>140</th>\n",
       "      <td>tfidf_140</td>\n",
       "      <td>4.201033e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>360</th>\n",
       "      <td>tfidf_360</td>\n",
       "      <td>4.170120e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>152</th>\n",
       "      <td>tfidf_152</td>\n",
       "      <td>4.154722e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>211</th>\n",
       "      <td>tfidf_211</td>\n",
       "      <td>4.132923e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>68</th>\n",
       "      <td>tfidf_68</td>\n",
       "      <td>4.125494e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>118</th>\n",
       "      <td>tfidf_118</td>\n",
       "      <td>4.062546e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>139</th>\n",
       "      <td>tfidf_139</td>\n",
       "      <td>4.049785e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>80</th>\n",
       "      <td>tfidf_80</td>\n",
       "      <td>4.046555e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>311</th>\n",
       "      <td>tfidf_311</td>\n",
       "      <td>4.001797e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>202</th>\n",
       "      <td>tfidf_202</td>\n",
       "      <td>3.997683e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>344</th>\n",
       "      <td>tfidf_344</td>\n",
       "      <td>3.920032e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>223</th>\n",
       "      <td>tfidf_223</td>\n",
       "      <td>3.872713e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>237</th>\n",
       "      <td>tfidf_237</td>\n",
       "      <td>3.870141e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>268</th>\n",
       "      <td>tfidf_268</td>\n",
       "      <td>3.819050e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>tfidf_22</td>\n",
       "      <td>3.806642e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>tfidf_49</td>\n",
       "      <td>3.790713e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>358</th>\n",
       "      <td>tfidf_358</td>\n",
       "      <td>3.750047e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>275</th>\n",
       "      <td>tfidf_275</td>\n",
       "      <td>3.735192e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>85</th>\n",
       "      <td>tfidf_85</td>\n",
       "      <td>3.724133e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>246</th>\n",
       "      <td>tfidf_246</td>\n",
       "      <td>3.694199e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>91</th>\n",
       "      <td>tfidf_91</td>\n",
       "      <td>3.666436e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>189</th>\n",
       "      <td>tfidf_189</td>\n",
       "      <td>3.609121e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>108</th>\n",
       "      <td>tfidf_108</td>\n",
       "      <td>3.593512e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>174</th>\n",
       "      <td>tfidf_174</td>\n",
       "      <td>3.578801e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>135</th>\n",
       "      <td>tfidf_135</td>\n",
       "      <td>3.577441e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>92</th>\n",
       "      <td>tfidf_92</td>\n",
       "      <td>3.521333e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>84</th>\n",
       "      <td>tfidf_84</td>\n",
       "      <td>3.514744e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>94</th>\n",
       "      <td>tfidf_94</td>\n",
       "      <td>3.514637e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>tfidf_6</td>\n",
       "      <td>3.499155e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>297</th>\n",
       "      <td>tfidf_297</td>\n",
       "      <td>3.498618e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>179</th>\n",
       "      <td>tfidf_179</td>\n",
       "      <td>3.422553e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>243</th>\n",
       "      <td>tfidf_243</td>\n",
       "      <td>3.354112e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>188</th>\n",
       "      <td>tfidf_188</td>\n",
       "      <td>3.328407e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>317</th>\n",
       "      <td>tfidf_317</td>\n",
       "      <td>3.279750e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>88</th>\n",
       "      <td>tfidf_88</td>\n",
       "      <td>3.273348e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>276</th>\n",
       "      <td>tfidf_276</td>\n",
       "      <td>3.269017e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>234</th>\n",
       "      <td>tfidf_234</td>\n",
       "      <td>3.267800e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>67</th>\n",
       "      <td>tfidf_67</td>\n",
       "      <td>3.256799e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>259</th>\n",
       "      <td>tfidf_259</td>\n",
       "      <td>3.246654e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>250</th>\n",
       "      <td>tfidf_250</td>\n",
       "      <td>3.232469e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>347</th>\n",
       "      <td>tfidf_347</td>\n",
       "      <td>3.204599e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>111</th>\n",
       "      <td>tfidf_111</td>\n",
       "      <td>3.183801e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>220</th>\n",
       "      <td>tfidf_220</td>\n",
       "      <td>3.179442e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>86</th>\n",
       "      <td>tfidf_86</td>\n",
       "      <td>3.136128e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>142</th>\n",
       "      <td>tfidf_142</td>\n",
       "      <td>3.135264e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>397</th>\n",
       "      <td>dizzy</td>\n",
       "      <td>3.092156e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>tfidf_23</td>\n",
       "      <td>3.081104e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>214</th>\n",
       "      <td>tfidf_214</td>\n",
       "      <td>3.019637e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>378</th>\n",
       "      <td>tfidf_378</td>\n",
       "      <td>2.984698e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>106</th>\n",
       "      <td>tfidf_106</td>\n",
       "      <td>2.970134e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>255</th>\n",
       "      <td>tfidf_255</td>\n",
       "      <td>2.870469e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>386</th>\n",
       "      <td>tfidf_386</td>\n",
       "      <td>2.809778e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>134</th>\n",
       "      <td>tfidf_134</td>\n",
       "      <td>2.782544e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>110</th>\n",
       "      <td>tfidf_110</td>\n",
       "      <td>2.771115e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>tfidf_97</td>\n",
       "      <td>2.759427e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>257</th>\n",
       "      <td>tfidf_257</td>\n",
       "      <td>2.753204e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>182</th>\n",
       "      <td>tfidf_182</td>\n",
       "      <td>2.744944e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>tfidf_0</td>\n",
       "      <td>2.732238e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>443</th>\n",
       "      <td>mango</td>\n",
       "      <td>2.730936e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>57</th>\n",
       "      <td>tfidf_57</td>\n",
       "      <td>2.730408e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>436</th>\n",
       "      <td>fruit</td>\n",
       "      <td>2.718786e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>116</th>\n",
       "      <td>tfidf_116</td>\n",
       "      <td>2.715547e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>105</th>\n",
       "      <td>tfidf_105</td>\n",
       "      <td>2.708039e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>306</th>\n",
       "      <td>tfidf_306</td>\n",
       "      <td>2.685525e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>318</th>\n",
       "      <td>tfidf_318</td>\n",
       "      <td>2.657245e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>195</th>\n",
       "      <td>tfidf_195</td>\n",
       "      <td>2.614581e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>131</th>\n",
       "      <td>tfidf_131</td>\n",
       "      <td>2.611699e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>tfidf_31</td>\n",
       "      <td>2.564896e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>248</th>\n",
       "      <td>tfidf_248</td>\n",
       "      <td>2.531551e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>452</th>\n",
       "      <td>pineapple</td>\n",
       "      <td>2.529270e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>81</th>\n",
       "      <td>tfidf_81</td>\n",
       "      <td>2.498866e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>157</th>\n",
       "      <td>tfidf_157</td>\n",
       "      <td>2.489923e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>348</th>\n",
       "      <td>tfidf_348</td>\n",
       "      <td>2.478725e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>82</th>\n",
       "      <td>tfidf_82</td>\n",
       "      <td>2.474570e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>261</th>\n",
       "      <td>tfidf_261</td>\n",
       "      <td>2.466305e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>408</th>\n",
       "      <td>headache</td>\n",
       "      <td>2.417612e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>326</th>\n",
       "      <td>tfidf_326</td>\n",
       "      <td>2.409835e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>279</th>\n",
       "      <td>tfidf_279</td>\n",
       "      <td>2.347820e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>tfidf_13</td>\n",
       "      <td>2.342824e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>271</th>\n",
       "      <td>tfidf_271</td>\n",
       "      <td>2.336481e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>290</th>\n",
       "      <td>tfidf_290</td>\n",
       "      <td>2.310792e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>tfidf_33</td>\n",
       "      <td>2.306285e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>201</th>\n",
       "      <td>tfidf_201</td>\n",
       "      <td>2.277629e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>225</th>\n",
       "      <td>tfidf_225</td>\n",
       "      <td>2.260666e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>295</th>\n",
       "      <td>tfidf_295</td>\n",
       "      <td>2.247766e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>249</th>\n",
       "      <td>tfidf_249</td>\n",
       "      <td>2.244920e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>183</th>\n",
       "      <td>tfidf_183</td>\n",
       "      <td>2.233081e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>365</th>\n",
       "      <td>tfidf_365</td>\n",
       "      <td>2.225019e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>280</th>\n",
       "      <td>tfidf_280</td>\n",
       "      <td>2.212428e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>87</th>\n",
       "      <td>tfidf_87</td>\n",
       "      <td>2.174179e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>tfidf_47</td>\n",
       "      <td>2.156443e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>262</th>\n",
       "      <td>tfidf_262</td>\n",
       "      <td>2.099714e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>432</th>\n",
       "      <td>coffee</td>\n",
       "      <td>2.098231e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>263</th>\n",
       "      <td>tfidf_263</td>\n",
       "      <td>2.084609e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>361</th>\n",
       "      <td>tfidf_361</td>\n",
       "      <td>2.083023e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>392</th>\n",
       "      <td>anxious</td>\n",
       "      <td>2.052144e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>301</th>\n",
       "      <td>tfidf_301</td>\n",
       "      <td>2.039431e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51</th>\n",
       "      <td>tfidf_51</td>\n",
       "      <td>2.015397e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>138</th>\n",
       "      <td>tfidf_138</td>\n",
       "      <td>2.006631e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>102</th>\n",
       "      <td>tfidf_102</td>\n",
       "      <td>2.006084e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>185</th>\n",
       "      <td>tfidf_185</td>\n",
       "      <td>2.005578e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>464</th>\n",
       "      <td>tree</td>\n",
       "      <td>2.004219e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>252</th>\n",
       "      <td>tfidf_252</td>\n",
       "      <td>1.980353e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>308</th>\n",
       "      <td>tfidf_308</td>\n",
       "      <td>1.946741e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>65</th>\n",
       "      <td>tfidf_65</td>\n",
       "      <td>1.931304e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>tfidf_44</td>\n",
       "      <td>1.911770e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>109</th>\n",
       "      <td>tfidf_109</td>\n",
       "      <td>1.908230e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>216</th>\n",
       "      <td>tfidf_216</td>\n",
       "      <td>1.899877e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>377</th>\n",
       "      <td>tfidf_377</td>\n",
       "      <td>1.897975e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>187</th>\n",
       "      <td>tfidf_187</td>\n",
       "      <td>1.861579e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>tfidf_18</td>\n",
       "      <td>1.860180e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>446</th>\n",
       "      <td>nutty</td>\n",
       "      <td>1.854655e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>227</th>\n",
       "      <td>tfidf_227</td>\n",
       "      <td>1.847563e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>369</th>\n",
       "      <td>tfidf_369</td>\n",
       "      <td>1.845916e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>62</th>\n",
       "      <td>tfidf_62</td>\n",
       "      <td>1.833539e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>232</th>\n",
       "      <td>tfidf_232</td>\n",
       "      <td>1.826234e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>241</th>\n",
       "      <td>tfidf_241</td>\n",
       "      <td>1.821638e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>244</th>\n",
       "      <td>tfidf_244</td>\n",
       "      <td>1.811371e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>171</th>\n",
       "      <td>tfidf_171</td>\n",
       "      <td>1.801813e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>372</th>\n",
       "      <td>tfidf_372</td>\n",
       "      <td>1.795597e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>tfidf_2</td>\n",
       "      <td>1.782475e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>197</th>\n",
       "      <td>tfidf_197</td>\n",
       "      <td>1.768938e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>74</th>\n",
       "      <td>tfidf_74</td>\n",
       "      <td>1.740738e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>tfidf_3</td>\n",
       "      <td>1.712923e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>284</th>\n",
       "      <td>tfidf_284</td>\n",
       "      <td>1.661963e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>150</th>\n",
       "      <td>tfidf_150</td>\n",
       "      <td>1.624032e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>tfidf_10</td>\n",
       "      <td>1.622606e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>76</th>\n",
       "      <td>tfidf_76</td>\n",
       "      <td>1.599903e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>70</th>\n",
       "      <td>tfidf_70</td>\n",
       "      <td>1.571799e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>212</th>\n",
       "      <td>tfidf_212</td>\n",
       "      <td>1.571191e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>132</th>\n",
       "      <td>tfidf_132</td>\n",
       "      <td>1.568660e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>256</th>\n",
       "      <td>tfidf_256</td>\n",
       "      <td>1.556518e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>429</th>\n",
       "      <td>chemical</td>\n",
       "      <td>1.551594e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>383</th>\n",
       "      <td>tfidf_383</td>\n",
       "      <td>1.550427e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>tfidf_27</td>\n",
       "      <td>1.547214e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>363</th>\n",
       "      <td>tfidf_363</td>\n",
       "      <td>1.538648e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>113</th>\n",
       "      <td>tfidf_113</td>\n",
       "      <td>1.522638e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>296</th>\n",
       "      <td>tfidf_296</td>\n",
       "      <td>1.514303e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>180</th>\n",
       "      <td>tfidf_180</td>\n",
       "      <td>1.505020e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59</th>\n",
       "      <td>tfidf_59</td>\n",
       "      <td>1.497079e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>165</th>\n",
       "      <td>tfidf_165</td>\n",
       "      <td>1.492692e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>160</th>\n",
       "      <td>tfidf_160</td>\n",
       "      <td>1.472156e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>tfidf_24</td>\n",
       "      <td>1.468715e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>100</th>\n",
       "      <td>tfidf_100</td>\n",
       "      <td>1.466482e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>228</th>\n",
       "      <td>tfidf_228</td>\n",
       "      <td>1.458919e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>384</th>\n",
       "      <td>tfidf_384</td>\n",
       "      <td>1.457859e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>242</th>\n",
       "      <td>tfidf_242</td>\n",
       "      <td>1.448015e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>233</th>\n",
       "      <td>tfidf_233</td>\n",
       "      <td>1.446113e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>313</th>\n",
       "      <td>tfidf_313</td>\n",
       "      <td>1.430042e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>302</th>\n",
       "      <td>tfidf_302</td>\n",
       "      <td>1.417809e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>89</th>\n",
       "      <td>tfidf_89</td>\n",
       "      <td>1.383462e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>196</th>\n",
       "      <td>tfidf_196</td>\n",
       "      <td>1.344832e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>307</th>\n",
       "      <td>tfidf_307</td>\n",
       "      <td>1.325017e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>331</th>\n",
       "      <td>tfidf_331</td>\n",
       "      <td>1.310859e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>364</th>\n",
       "      <td>tfidf_364</td>\n",
       "      <td>1.305829e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>tfidf_38</td>\n",
       "      <td>1.299921e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>330</th>\n",
       "      <td>tfidf_330</td>\n",
       "      <td>1.290297e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>375</th>\n",
       "      <td>tfidf_375</td>\n",
       "      <td>1.263697e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>219</th>\n",
       "      <td>tfidf_219</td>\n",
       "      <td>1.253738e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>114</th>\n",
       "      <td>tfidf_114</td>\n",
       "      <td>1.250297e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>254</th>\n",
       "      <td>tfidf_254</td>\n",
       "      <td>1.249128e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>305</th>\n",
       "      <td>tfidf_305</td>\n",
       "      <td>1.229992e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>tfidf_15</td>\n",
       "      <td>1.199940e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>299</th>\n",
       "      <td>tfidf_299</td>\n",
       "      <td>1.193209e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>328</th>\n",
       "      <td>tfidf_328</td>\n",
       "      <td>1.148886e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>236</th>\n",
       "      <td>tfidf_236</td>\n",
       "      <td>1.128733e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>226</th>\n",
       "      <td>tfidf_226</td>\n",
       "      <td>1.126807e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>156</th>\n",
       "      <td>tfidf_156</td>\n",
       "      <td>1.125502e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>127</th>\n",
       "      <td>tfidf_127</td>\n",
       "      <td>1.121386e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>334</th>\n",
       "      <td>tfidf_334</td>\n",
       "      <td>1.118385e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>351</th>\n",
       "      <td>tfidf_351</td>\n",
       "      <td>1.111751e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>292</th>\n",
       "      <td>tfidf_292</td>\n",
       "      <td>1.110315e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>335</th>\n",
       "      <td>tfidf_335</td>\n",
       "      <td>1.103233e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>439</th>\n",
       "      <td>honey</td>\n",
       "      <td>1.072190e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>467</th>\n",
       "      <td>violet</td>\n",
       "      <td>1.067914e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>55</th>\n",
       "      <td>tfidf_55</td>\n",
       "      <td>1.059832e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>tfidf_12</td>\n",
       "      <td>1.052914e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>266</th>\n",
       "      <td>tfidf_266</td>\n",
       "      <td>1.034256e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>tfidf_25</td>\n",
       "      <td>1.027900e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>147</th>\n",
       "      <td>tfidf_147</td>\n",
       "      <td>1.002173e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>63</th>\n",
       "      <td>tfidf_63</td>\n",
       "      <td>9.810363e-05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>422</th>\n",
       "      <td>apple</td>\n",
       "      <td>9.673573e-05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>229</th>\n",
       "      <td>tfidf_229</td>\n",
       "      <td>9.587321e-05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>tfidf_95</td>\n",
       "      <td>9.510612e-05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>327</th>\n",
       "      <td>tfidf_327</td>\n",
       "      <td>9.266331e-05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>356</th>\n",
       "      <td>tfidf_356</td>\n",
       "      <td>9.180252e-05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>115</th>\n",
       "      <td>tfidf_115</td>\n",
       "      <td>8.820037e-05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>421</th>\n",
       "      <td>ammonia</td>\n",
       "      <td>8.813033e-05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>tfidf_8</td>\n",
       "      <td>8.721951e-05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>169</th>\n",
       "      <td>tfidf_169</td>\n",
       "      <td>8.703661e-05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>449</th>\n",
       "      <td>pear</td>\n",
       "      <td>8.695613e-05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>218</th>\n",
       "      <td>tfidf_218</td>\n",
       "      <td>8.233290e-05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>339</th>\n",
       "      <td>tfidf_339</td>\n",
       "      <td>8.038310e-05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>66</th>\n",
       "      <td>tfidf_66</td>\n",
       "      <td>7.657517e-05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>133</th>\n",
       "      <td>tfidf_133</td>\n",
       "      <td>6.649471e-05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>462</th>\n",
       "      <td>tea</td>\n",
       "      <td>6.302904e-05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>209</th>\n",
       "      <td>tfidf_209</td>\n",
       "      <td>6.208766e-05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>300</th>\n",
       "      <td>tfidf_300</td>\n",
       "      <td>6.004479e-05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>72</th>\n",
       "      <td>tfidf_72</td>\n",
       "      <td>5.846898e-05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>322</th>\n",
       "      <td>tfidf_322</td>\n",
       "      <td>5.384517e-05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>293</th>\n",
       "      <td>tfidf_293</td>\n",
       "      <td>5.259565e-05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>463</th>\n",
       "      <td>tobacco</td>\n",
       "      <td>4.935378e-05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>430</th>\n",
       "      <td>chestnut</td>\n",
       "      <td>3.961101e-05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>448</th>\n",
       "      <td>peach</td>\n",
       "      <td>3.732900e-05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>410</th>\n",
       "      <td>migraines</td>\n",
       "      <td>3.241150e-05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>461</th>\n",
       "      <td>tar</td>\n",
       "      <td>3.200238e-05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>396</th>\n",
       "      <td>depression</td>\n",
       "      <td>3.050181e-05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>425</th>\n",
       "      <td>blue cheese</td>\n",
       "      <td>2.635743e-05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>427</th>\n",
       "      <td>butter</td>\n",
       "      <td>2.357558e-05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>391</th>\n",
       "      <td>anxiety</td>\n",
       "      <td>2.197024e-05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>444</th>\n",
       "      <td>menthol</td>\n",
       "      <td>1.309199e-05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>423</th>\n",
       "      <td>apricot</td>\n",
       "      <td>5.582577e-06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>416</th>\n",
       "      <td>spasticity</td>\n",
       "      <td>2.635995e-09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>414</th>\n",
       "      <td>seizures</td>\n",
       "      <td>0.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>401</th>\n",
       "      <td>epilepsy</td>\n",
       "      <td>0.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>403</th>\n",
       "      <td>eye pressure</td>\n",
       "      <td>0.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>404</th>\n",
       "      <td>fatigue</td>\n",
       "      <td>0.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>411</th>\n",
       "      <td>pain</td>\n",
       "      <td>0.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>417</th>\n",
       "      <td>stress</td>\n",
       "      <td>0.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>394</th>\n",
       "      <td>arthritis</td>\n",
       "      <td>0.000000e+00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         features         score\n",
       "424         berry  2.083860e-01\n",
       "459    strawberry  1.041198e-01\n",
       "389        indica  9.072023e-02\n",
       "390        sativa  4.050349e-02\n",
       "329     tfidf_329  1.929160e-02\n",
       "154     tfidf_154  1.712360e-02\n",
       "29       tfidf_29  1.596217e-02\n",
       "176     tfidf_176  1.417043e-02\n",
       "437         grape  1.268792e-02\n",
       "433        diesel  1.097112e-02\n",
       "441         lemon  1.082084e-02\n",
       "447        orange  1.080657e-02\n",
       "465      tropical  1.048560e-02\n",
       "388        hybrid  9.876639e-03\n",
       "426     blueberry  9.534352e-03\n",
       "442          lime  7.038352e-03\n",
       "345     tfidf_345  6.820654e-03\n",
       "405       focused  6.819044e-03\n",
       "409        hungry  6.794576e-03\n",
       "428        cheese  6.474180e-03\n",
       "168     tfidf_168  6.443989e-03\n",
       "149     tfidf_149  6.316261e-03\n",
       "362     tfidf_362  6.163958e-03\n",
       "144     tfidf_144  5.890867e-03\n",
       "281     tfidf_281  5.593252e-03\n",
       "359     tfidf_359  5.467979e-03\n",
       "199     tfidf_199  5.466289e-03\n",
       "457         skunk  5.234045e-03\n",
       "210     tfidf_210  4.933543e-03\n",
       "121     tfidf_121  4.904386e-03\n",
       "239     tfidf_239  4.548537e-03\n",
       "141     tfidf_141  4.521365e-03\n",
       "285     tfidf_285  4.346664e-03\n",
       "431        citrus  4.295961e-03\n",
       "342     tfidf_342  4.122935e-03\n",
       "406        giggly  4.111664e-03\n",
       "145     tfidf_145  4.084216e-03\n",
       "283     tfidf_283  3.730994e-03\n",
       "125     tfidf_125  3.576370e-03\n",
       "312     tfidf_312  3.551120e-03\n",
       "56       tfidf_56  3.514786e-03\n",
       "245     tfidf_245  3.372188e-03\n",
       "466       vanilla  3.261299e-03\n",
       "253     tfidf_253  3.253353e-03\n",
       "438    grapefruit  3.086923e-03\n",
       "103     tfidf_103  3.030447e-03\n",
       "337     tfidf_337  2.969368e-03\n",
       "7         tfidf_7  2.952772e-03\n",
       "98       tfidf_98  2.934850e-03\n",
       "117     tfidf_117  2.845277e-03\n",
       "420      uplifted  2.825395e-03\n",
       "309     tfidf_309  2.809949e-03\n",
       "407         happy  2.743736e-03\n",
       "178     tfidf_178  2.743276e-03\n",
       "413       relaxed  2.710652e-03\n",
       "207     tfidf_207  2.701431e-03\n",
       "343     tfidf_343  2.559599e-03\n",
       "194     tfidf_194  2.556433e-03\n",
       "395      creative  2.536693e-03\n",
       "96       tfidf_96  2.507319e-03\n",
       "393       aroused  2.490285e-03\n",
       "60       tfidf_60  2.466622e-03\n",
       "36       tfidf_36  2.331195e-03\n",
       "158     tfidf_158  2.209411e-03\n",
       "78       tfidf_78  2.204143e-03\n",
       "434        earthy  2.150516e-03\n",
       "30       tfidf_30  2.088187e-03\n",
       "43       tfidf_43  2.039179e-03\n",
       "468         woody  2.020307e-03\n",
       "37       tfidf_37  1.994665e-03\n",
       "265     tfidf_265  1.976182e-03\n",
       "320     tfidf_320  1.947519e-03\n",
       "162     tfidf_162  1.938871e-03\n",
       "52       tfidf_52  1.931689e-03\n",
       "451          pine  1.926411e-03\n",
       "73       tfidf_73  1.917489e-03\n",
       "267     tfidf_267  1.898174e-03\n",
       "270     tfidf_270  1.868768e-03\n",
       "402      euphoric  1.847675e-03\n",
       "379     tfidf_379  1.756159e-03\n",
       "303     tfidf_303  1.730593e-03\n",
       "230     tfidf_230  1.675406e-03\n",
       "399     dry mouth  1.658647e-03\n",
       "186     tfidf_186  1.639691e-03\n",
       "415        sleepy  1.602634e-03\n",
       "314     tfidf_314  1.587776e-03\n",
       "353     tfidf_353  1.574015e-03\n",
       "53       tfidf_53  1.573407e-03\n",
       "381     tfidf_381  1.548876e-03\n",
       "418     talkative  1.546143e-03\n",
       "374     tfidf_374  1.508763e-03\n",
       "4         tfidf_4  1.480666e-03\n",
       "333     tfidf_333  1.467116e-03\n",
       "119     tfidf_119  1.465048e-03\n",
       "79       tfidf_79  1.451461e-03\n",
       "163     tfidf_163  1.445960e-03\n",
       "217     tfidf_217  1.440278e-03\n",
       "247     tfidf_247  1.416653e-03\n",
       "325     tfidf_325  1.415437e-03\n",
       "11       tfidf_11  1.359864e-03\n",
       "357     tfidf_357  1.358516e-03\n",
       "205     tfidf_205  1.332881e-03\n",
       "445          mint  1.327885e-03\n",
       "54       tfidf_54  1.307369e-03\n",
       "316     tfidf_316  1.292890e-03\n",
       "173     tfidf_173  1.267275e-03\n",
       "28       tfidf_28  1.252049e-03\n",
       "1         tfidf_1  1.224635e-03\n",
       "400     energetic  1.219131e-03\n",
       "46       tfidf_46  1.200758e-03\n",
       "206     tfidf_206  1.190274e-03\n",
       "398      dry eyes  1.156079e-03\n",
       "310     tfidf_310  1.152559e-03\n",
       "181     tfidf_181  1.150228e-03\n",
       "258     tfidf_258  1.146739e-03\n",
       "282     tfidf_282  1.132257e-03\n",
       "352     tfidf_352  1.131787e-03\n",
       "460         sweet  1.129588e-03\n",
       "50       tfidf_50  1.126583e-03\n",
       "104     tfidf_104  1.108673e-03\n",
       "17       tfidf_17  1.103124e-03\n",
       "366     tfidf_366  1.073522e-03\n",
       "167     tfidf_167  1.058326e-03\n",
       "367     tfidf_367  1.004354e-03\n",
       "454       pungent  1.002668e-03\n",
       "373     tfidf_373  9.963744e-04\n",
       "26       tfidf_26  9.919778e-04\n",
       "272     tfidf_272  9.894289e-04\n",
       "193     tfidf_193  9.881121e-04\n",
       "93       tfidf_93  9.771665e-04\n",
       "126     tfidf_126  9.737833e-04\n",
       "128     tfidf_128  9.731861e-04\n",
       "419        tingly  9.683837e-04\n",
       "332     tfidf_332  9.641649e-04\n",
       "155     tfidf_155  9.459294e-04\n",
       "41       tfidf_41  9.379366e-04\n",
       "387     tfidf_387  9.233332e-04\n",
       "340     tfidf_340  9.177159e-04\n",
       "323     tfidf_323  9.115538e-04\n",
       "77       tfidf_77  9.080967e-04\n",
       "61       tfidf_61  8.981346e-04\n",
       "42       tfidf_42  8.915000e-04\n",
       "450        pepper  8.907272e-04\n",
       "112     tfidf_112  8.754140e-04\n",
       "278     tfidf_278  8.689144e-04\n",
       "264     tfidf_264  8.680196e-04\n",
       "286     tfidf_286  8.677068e-04\n",
       "192     tfidf_192  8.645311e-04\n",
       "380     tfidf_380  8.474752e-04\n",
       "191     tfidf_191  8.301324e-04\n",
       "382     tfidf_382  8.254125e-04\n",
       "175     tfidf_175  8.094230e-04\n",
       "19       tfidf_19  7.954296e-04\n",
       "341     tfidf_341  7.941834e-04\n",
       "148     tfidf_148  7.939658e-04\n",
       "354     tfidf_354  7.915073e-04\n",
       "304     tfidf_304  7.914682e-04\n",
       "20       tfidf_20  7.913338e-04\n",
       "129     tfidf_129  7.690605e-04\n",
       "324     tfidf_324  7.607831e-04\n",
       "435       flowery  7.588766e-04\n",
       "137     tfidf_137  7.363608e-04\n",
       "240     tfidf_240  7.335379e-04\n",
       "164     tfidf_164  7.275024e-04\n",
       "287     tfidf_287  7.272072e-04\n",
       "130     tfidf_130  7.240471e-04\n",
       "222     tfidf_222  7.182662e-04\n",
       "458  spicy/herbal  7.144774e-04\n",
       "355     tfidf_355  7.111146e-04\n",
       "107     tfidf_107  6.974529e-04\n",
       "338     tfidf_338  6.915301e-04\n",
       "143     tfidf_143  6.868802e-04\n",
       "221     tfidf_221  6.866757e-04\n",
       "385     tfidf_385  6.845672e-04\n",
       "58       tfidf_58  6.809550e-04\n",
       "40       tfidf_40  6.796159e-04\n",
       "251     tfidf_251  6.731441e-04\n",
       "235     tfidf_235  6.656337e-04\n",
       "101     tfidf_101  6.644434e-04\n",
       "45       tfidf_45  6.637107e-04\n",
       "190     tfidf_190  6.558911e-04\n",
       "153     tfidf_153  6.444722e-04\n",
       "215     tfidf_215  6.296751e-04\n",
       "170     tfidf_170  6.241225e-04\n",
       "64       tfidf_64  6.093113e-04\n",
       "136     tfidf_136  6.082070e-04\n",
       "440      lavender  6.031455e-04\n",
       "9         tfidf_9  6.031374e-04\n",
       "14       tfidf_14  6.004979e-04\n",
       "291     tfidf_291  5.996773e-04\n",
       "177     tfidf_177  5.849922e-04\n",
       "5         tfidf_5  5.846530e-04\n",
       "294     tfidf_294  5.796814e-04\n",
       "151     tfidf_151  5.700284e-04\n",
       "166     tfidf_166  5.692424e-04\n",
       "346     tfidf_346  5.673802e-04\n",
       "453          plum  5.562222e-04\n",
       "371     tfidf_371  5.546849e-04\n",
       "21       tfidf_21  5.405854e-04\n",
       "123     tfidf_123  5.405580e-04\n",
       "376     tfidf_376  5.398049e-04\n",
       "32       tfidf_32  5.374086e-04\n",
       "69       tfidf_69  5.365406e-04\n",
       "289     tfidf_289  5.361937e-04\n",
       "349     tfidf_349  5.351624e-04\n",
       "274     tfidf_274  5.315659e-04\n",
       "298     tfidf_298  5.299383e-04\n",
       "200     tfidf_200  5.285554e-04\n",
       "350     tfidf_350  5.269274e-04\n",
       "184     tfidf_184  5.210236e-04\n",
       "124     tfidf_124  5.158071e-04\n",
       "83       tfidf_83  5.154621e-04\n",
       "122     tfidf_122  5.101143e-04\n",
       "198     tfidf_198  5.058213e-04\n",
       "39       tfidf_39  4.992195e-04\n",
       "71       tfidf_71  4.975072e-04\n",
       "34       tfidf_34  4.967655e-04\n",
       "208     tfidf_208  4.955627e-04\n",
       "48       tfidf_48  4.922532e-04\n",
       "213     tfidf_213  4.891762e-04\n",
       "35       tfidf_35  4.871410e-04\n",
       "90       tfidf_90  4.845454e-04\n",
       "273     tfidf_273  4.838933e-04\n",
       "99       tfidf_99  4.808695e-04\n",
       "231     tfidf_231  4.763450e-04\n",
       "16       tfidf_16  4.753402e-04\n",
       "146     tfidf_146  4.743898e-04\n",
       "336     tfidf_336  4.709847e-04\n",
       "277     tfidf_277  4.704279e-04\n",
       "370     tfidf_370  4.654300e-04\n",
       "412      paranoid  4.638548e-04\n",
       "368     tfidf_368  4.614009e-04\n",
       "238     tfidf_238  4.605882e-04\n",
       "455          rose  4.591590e-04\n",
       "204     tfidf_204  4.570185e-04\n",
       "319     tfidf_319  4.520447e-04\n",
       "75       tfidf_75  4.481814e-04\n",
       "172     tfidf_172  4.476791e-04\n",
       "260     tfidf_260  4.463547e-04\n",
       "203     tfidf_203  4.444912e-04\n",
       "224     tfidf_224  4.435195e-04\n",
       "159     tfidf_159  4.431738e-04\n",
       "315     tfidf_315  4.419200e-04\n",
       "288     tfidf_288  4.368430e-04\n",
       "161     tfidf_161  4.363754e-04\n",
       "269     tfidf_269  4.341859e-04\n",
       "456          sage  4.315040e-04\n",
       "321     tfidf_321  4.301648e-04\n",
       "120     tfidf_120  4.259196e-04\n",
       "140     tfidf_140  4.201033e-04\n",
       "360     tfidf_360  4.170120e-04\n",
       "152     tfidf_152  4.154722e-04\n",
       "211     tfidf_211  4.132923e-04\n",
       "68       tfidf_68  4.125494e-04\n",
       "118     tfidf_118  4.062546e-04\n",
       "139     tfidf_139  4.049785e-04\n",
       "80       tfidf_80  4.046555e-04\n",
       "311     tfidf_311  4.001797e-04\n",
       "202     tfidf_202  3.997683e-04\n",
       "344     tfidf_344  3.920032e-04\n",
       "223     tfidf_223  3.872713e-04\n",
       "237     tfidf_237  3.870141e-04\n",
       "268     tfidf_268  3.819050e-04\n",
       "22       tfidf_22  3.806642e-04\n",
       "49       tfidf_49  3.790713e-04\n",
       "358     tfidf_358  3.750047e-04\n",
       "275     tfidf_275  3.735192e-04\n",
       "85       tfidf_85  3.724133e-04\n",
       "246     tfidf_246  3.694199e-04\n",
       "91       tfidf_91  3.666436e-04\n",
       "189     tfidf_189  3.609121e-04\n",
       "108     tfidf_108  3.593512e-04\n",
       "174     tfidf_174  3.578801e-04\n",
       "135     tfidf_135  3.577441e-04\n",
       "92       tfidf_92  3.521333e-04\n",
       "84       tfidf_84  3.514744e-04\n",
       "94       tfidf_94  3.514637e-04\n",
       "6         tfidf_6  3.499155e-04\n",
       "297     tfidf_297  3.498618e-04\n",
       "179     tfidf_179  3.422553e-04\n",
       "243     tfidf_243  3.354112e-04\n",
       "188     tfidf_188  3.328407e-04\n",
       "317     tfidf_317  3.279750e-04\n",
       "88       tfidf_88  3.273348e-04\n",
       "276     tfidf_276  3.269017e-04\n",
       "234     tfidf_234  3.267800e-04\n",
       "67       tfidf_67  3.256799e-04\n",
       "259     tfidf_259  3.246654e-04\n",
       "250     tfidf_250  3.232469e-04\n",
       "347     tfidf_347  3.204599e-04\n",
       "111     tfidf_111  3.183801e-04\n",
       "220     tfidf_220  3.179442e-04\n",
       "86       tfidf_86  3.136128e-04\n",
       "142     tfidf_142  3.135264e-04\n",
       "397         dizzy  3.092156e-04\n",
       "23       tfidf_23  3.081104e-04\n",
       "214     tfidf_214  3.019637e-04\n",
       "378     tfidf_378  2.984698e-04\n",
       "106     tfidf_106  2.970134e-04\n",
       "255     tfidf_255  2.870469e-04\n",
       "386     tfidf_386  2.809778e-04\n",
       "134     tfidf_134  2.782544e-04\n",
       "110     tfidf_110  2.771115e-04\n",
       "97       tfidf_97  2.759427e-04\n",
       "257     tfidf_257  2.753204e-04\n",
       "182     tfidf_182  2.744944e-04\n",
       "0         tfidf_0  2.732238e-04\n",
       "443         mango  2.730936e-04\n",
       "57       tfidf_57  2.730408e-04\n",
       "436         fruit  2.718786e-04\n",
       "116     tfidf_116  2.715547e-04\n",
       "105     tfidf_105  2.708039e-04\n",
       "306     tfidf_306  2.685525e-04\n",
       "318     tfidf_318  2.657245e-04\n",
       "195     tfidf_195  2.614581e-04\n",
       "131     tfidf_131  2.611699e-04\n",
       "31       tfidf_31  2.564896e-04\n",
       "248     tfidf_248  2.531551e-04\n",
       "452     pineapple  2.529270e-04\n",
       "81       tfidf_81  2.498866e-04\n",
       "157     tfidf_157  2.489923e-04\n",
       "348     tfidf_348  2.478725e-04\n",
       "82       tfidf_82  2.474570e-04\n",
       "261     tfidf_261  2.466305e-04\n",
       "408      headache  2.417612e-04\n",
       "326     tfidf_326  2.409835e-04\n",
       "279     tfidf_279  2.347820e-04\n",
       "13       tfidf_13  2.342824e-04\n",
       "271     tfidf_271  2.336481e-04\n",
       "290     tfidf_290  2.310792e-04\n",
       "33       tfidf_33  2.306285e-04\n",
       "201     tfidf_201  2.277629e-04\n",
       "225     tfidf_225  2.260666e-04\n",
       "295     tfidf_295  2.247766e-04\n",
       "249     tfidf_249  2.244920e-04\n",
       "183     tfidf_183  2.233081e-04\n",
       "365     tfidf_365  2.225019e-04\n",
       "280     tfidf_280  2.212428e-04\n",
       "87       tfidf_87  2.174179e-04\n",
       "47       tfidf_47  2.156443e-04\n",
       "262     tfidf_262  2.099714e-04\n",
       "432        coffee  2.098231e-04\n",
       "263     tfidf_263  2.084609e-04\n",
       "361     tfidf_361  2.083023e-04\n",
       "392       anxious  2.052144e-04\n",
       "301     tfidf_301  2.039431e-04\n",
       "51       tfidf_51  2.015397e-04\n",
       "138     tfidf_138  2.006631e-04\n",
       "102     tfidf_102  2.006084e-04\n",
       "185     tfidf_185  2.005578e-04\n",
       "464          tree  2.004219e-04\n",
       "252     tfidf_252  1.980353e-04\n",
       "308     tfidf_308  1.946741e-04\n",
       "65       tfidf_65  1.931304e-04\n",
       "44       tfidf_44  1.911770e-04\n",
       "109     tfidf_109  1.908230e-04\n",
       "216     tfidf_216  1.899877e-04\n",
       "377     tfidf_377  1.897975e-04\n",
       "187     tfidf_187  1.861579e-04\n",
       "18       tfidf_18  1.860180e-04\n",
       "446         nutty  1.854655e-04\n",
       "227     tfidf_227  1.847563e-04\n",
       "369     tfidf_369  1.845916e-04\n",
       "62       tfidf_62  1.833539e-04\n",
       "232     tfidf_232  1.826234e-04\n",
       "241     tfidf_241  1.821638e-04\n",
       "244     tfidf_244  1.811371e-04\n",
       "171     tfidf_171  1.801813e-04\n",
       "372     tfidf_372  1.795597e-04\n",
       "2         tfidf_2  1.782475e-04\n",
       "197     tfidf_197  1.768938e-04\n",
       "74       tfidf_74  1.740738e-04\n",
       "3         tfidf_3  1.712923e-04\n",
       "284     tfidf_284  1.661963e-04\n",
       "150     tfidf_150  1.624032e-04\n",
       "10       tfidf_10  1.622606e-04\n",
       "76       tfidf_76  1.599903e-04\n",
       "70       tfidf_70  1.571799e-04\n",
       "212     tfidf_212  1.571191e-04\n",
       "132     tfidf_132  1.568660e-04\n",
       "256     tfidf_256  1.556518e-04\n",
       "429      chemical  1.551594e-04\n",
       "383     tfidf_383  1.550427e-04\n",
       "27       tfidf_27  1.547214e-04\n",
       "363     tfidf_363  1.538648e-04\n",
       "113     tfidf_113  1.522638e-04\n",
       "296     tfidf_296  1.514303e-04\n",
       "180     tfidf_180  1.505020e-04\n",
       "59       tfidf_59  1.497079e-04\n",
       "165     tfidf_165  1.492692e-04\n",
       "160     tfidf_160  1.472156e-04\n",
       "24       tfidf_24  1.468715e-04\n",
       "100     tfidf_100  1.466482e-04\n",
       "228     tfidf_228  1.458919e-04\n",
       "384     tfidf_384  1.457859e-04\n",
       "242     tfidf_242  1.448015e-04\n",
       "233     tfidf_233  1.446113e-04\n",
       "313     tfidf_313  1.430042e-04\n",
       "302     tfidf_302  1.417809e-04\n",
       "89       tfidf_89  1.383462e-04\n",
       "196     tfidf_196  1.344832e-04\n",
       "307     tfidf_307  1.325017e-04\n",
       "331     tfidf_331  1.310859e-04\n",
       "364     tfidf_364  1.305829e-04\n",
       "38       tfidf_38  1.299921e-04\n",
       "330     tfidf_330  1.290297e-04\n",
       "375     tfidf_375  1.263697e-04\n",
       "219     tfidf_219  1.253738e-04\n",
       "114     tfidf_114  1.250297e-04\n",
       "254     tfidf_254  1.249128e-04\n",
       "305     tfidf_305  1.229992e-04\n",
       "15       tfidf_15  1.199940e-04\n",
       "299     tfidf_299  1.193209e-04\n",
       "328     tfidf_328  1.148886e-04\n",
       "236     tfidf_236  1.128733e-04\n",
       "226     tfidf_226  1.126807e-04\n",
       "156     tfidf_156  1.125502e-04\n",
       "127     tfidf_127  1.121386e-04\n",
       "334     tfidf_334  1.118385e-04\n",
       "351     tfidf_351  1.111751e-04\n",
       "292     tfidf_292  1.110315e-04\n",
       "335     tfidf_335  1.103233e-04\n",
       "439         honey  1.072190e-04\n",
       "467        violet  1.067914e-04\n",
       "55       tfidf_55  1.059832e-04\n",
       "12       tfidf_12  1.052914e-04\n",
       "266     tfidf_266  1.034256e-04\n",
       "25       tfidf_25  1.027900e-04\n",
       "147     tfidf_147  1.002173e-04\n",
       "63       tfidf_63  9.810363e-05\n",
       "422         apple  9.673573e-05\n",
       "229     tfidf_229  9.587321e-05\n",
       "95       tfidf_95  9.510612e-05\n",
       "327     tfidf_327  9.266331e-05\n",
       "356     tfidf_356  9.180252e-05\n",
       "115     tfidf_115  8.820037e-05\n",
       "421       ammonia  8.813033e-05\n",
       "8         tfidf_8  8.721951e-05\n",
       "169     tfidf_169  8.703661e-05\n",
       "449          pear  8.695613e-05\n",
       "218     tfidf_218  8.233290e-05\n",
       "339     tfidf_339  8.038310e-05\n",
       "66       tfidf_66  7.657517e-05\n",
       "133     tfidf_133  6.649471e-05\n",
       "462           tea  6.302904e-05\n",
       "209     tfidf_209  6.208766e-05\n",
       "300     tfidf_300  6.004479e-05\n",
       "72       tfidf_72  5.846898e-05\n",
       "322     tfidf_322  5.384517e-05\n",
       "293     tfidf_293  5.259565e-05\n",
       "463       tobacco  4.935378e-05\n",
       "430      chestnut  3.961101e-05\n",
       "448         peach  3.732900e-05\n",
       "410     migraines  3.241150e-05\n",
       "461           tar  3.200238e-05\n",
       "396    depression  3.050181e-05\n",
       "425   blue cheese  2.635743e-05\n",
       "427        butter  2.357558e-05\n",
       "391       anxiety  2.197024e-05\n",
       "444       menthol  1.309199e-05\n",
       "423       apricot  5.582577e-06\n",
       "416    spasticity  2.635995e-09\n",
       "414      seizures  0.000000e+00\n",
       "401      epilepsy  0.000000e+00\n",
       "403  eye pressure  0.000000e+00\n",
       "404       fatigue  0.000000e+00\n",
       "411          pain  0.000000e+00\n",
       "417        stress  0.000000e+00\n",
       "394     arthritis  0.000000e+00"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.set_option('display.max_rows', df_feat_ranked.shape[0]+1)\n",
    "df_feat_ranked"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/andalanputra/opt/anaconda3/lib/python3.9/site-packages/sklearn/feature_selection/_from_model.py:357: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  self.estimator_.fit(X, y, **fit_params)\n"
     ]
    }
   ],
   "source": [
    "selector = SelectFromModel(rfreg).fit(X_train1, y_train1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([2.94431882e-04, 1.14045844e-03, 1.40448984e-04, 1.48747260e-04,\n",
       "       1.35249612e-03, 6.04001550e-04, 4.12338415e-04, 2.72980227e-03,\n",
       "       1.05273826e-04, 6.77432795e-04, 1.49570962e-04, 1.36850328e-03,\n",
       "       8.26238089e-05, 3.00656798e-04, 5.66314072e-04, 9.77219316e-05,\n",
       "       5.20014541e-04, 1.16383259e-03, 2.60555374e-04, 7.05146799e-04,\n",
       "       8.03900584e-04, 5.94181863e-04, 4.45411220e-04, 3.23567068e-04,\n",
       "       1.51879710e-04, 1.09441165e-04, 1.09189606e-03, 1.51586389e-04,\n",
       "       1.13453449e-03, 1.59824441e-02, 2.11782066e-03, 2.49824655e-04,\n",
       "       5.75816121e-04, 1.63832133e-04, 4.48860920e-04, 4.08976747e-04,\n",
       "       2.35932640e-03, 1.90840860e-03, 1.74067041e-04, 5.20776657e-04,\n",
       "       5.74752519e-04, 8.91420569e-04, 7.82594931e-04, 2.02099681e-03,\n",
       "       1.73652946e-04, 6.99949246e-04, 1.22187558e-03, 1.63851567e-04,\n",
       "       5.46580687e-04, 3.70149051e-04, 9.02428769e-04, 2.10947223e-04,\n",
       "       1.76601596e-03, 1.50496613e-03, 1.56853998e-03, 1.07990823e-04,\n",
       "       3.64219758e-03, 3.09195826e-04, 6.63604674e-04, 1.27694267e-04,\n",
       "       1.87735650e-03, 9.93633628e-04, 1.75569531e-04, 8.24678958e-05,\n",
       "       5.50727356e-04, 2.18705667e-04, 9.24367530e-05, 6.06486609e-04,\n",
       "       3.32168549e-04, 5.51845831e-04, 1.30772932e-04, 5.30588718e-04,\n",
       "       6.25906921e-05, 1.90624939e-03, 2.44771096e-04, 4.20476078e-04,\n",
       "       1.75188547e-04, 8.99750250e-04, 2.34755676e-03, 1.70570130e-03,\n",
       "       4.81788741e-04, 2.60010240e-04, 2.24529152e-04, 2.98582032e-04,\n",
       "       3.24657149e-04, 4.16946081e-04, 2.91853808e-04, 2.74068870e-04,\n",
       "       3.83082253e-04, 1.20270125e-04, 5.78746075e-04, 3.61803970e-04,\n",
       "       3.12474982e-04, 9.70348391e-04, 3.28371050e-04, 8.52710485e-05,\n",
       "       2.36460020e-03, 2.72867225e-04, 3.05654634e-03, 7.04211984e-04,\n",
       "       1.18500083e-04, 6.90611974e-04, 2.26746289e-04, 3.00429458e-03,\n",
       "       1.12818337e-03, 2.77679168e-04, 3.01231459e-04, 7.04605973e-04,\n",
       "       4.73048623e-04, 1.88765229e-04, 2.74259018e-04, 3.01731613e-04,\n",
       "       1.03183105e-03, 1.36538230e-04, 7.30717264e-05, 8.43147640e-05,\n",
       "       3.08103919e-04, 2.77458080e-03, 3.41092738e-04, 1.43495362e-03,\n",
       "       4.36423246e-04, 4.73909377e-03, 4.59619827e-04, 6.11387584e-04,\n",
       "       5.62961352e-04, 3.49867790e-03, 1.01215124e-03, 1.26819737e-04,\n",
       "       1.04337652e-03, 7.83478602e-04, 7.49276065e-04, 2.64058212e-04,\n",
       "       1.63990868e-04, 5.45574615e-05, 2.53336108e-04, 3.50929900e-04,\n",
       "       8.21878066e-04, 7.69843753e-04, 1.61903006e-04, 3.90496676e-04,\n",
       "       4.91659341e-04, 4.18473313e-03, 3.42215271e-04, 7.94105564e-04,\n",
       "       6.30934625e-03, 4.37916121e-03, 4.71422481e-04, 9.41292918e-05,\n",
       "       7.50970840e-04, 6.07778526e-03, 1.64237411e-04, 5.88723761e-04,\n",
       "       4.58775898e-04, 6.05628848e-04, 1.80937437e-02, 9.35332141e-04,\n",
       "       1.27736894e-04, 2.44033951e-04, 2.51558119e-03, 5.18131058e-04,\n",
       "       1.23267720e-04, 4.51820245e-04, 1.94141291e-03, 1.34670169e-03,\n",
       "       8.26237830e-04, 1.93012090e-04, 5.68489543e-04, 1.15259373e-03,\n",
       "       6.24894681e-03, 7.83114510e-05, 6.52669482e-04, 1.97394766e-04,\n",
       "       4.42555826e-04, 1.16331562e-03, 5.17491191e-04, 7.95391967e-04,\n",
       "       1.37897748e-02, 7.13144509e-04, 3.07272202e-03, 3.77405196e-04,\n",
       "       1.31084624e-04, 1.02982151e-03, 2.71085261e-04, 2.34711280e-04,\n",
       "       4.89019214e-04, 2.29440920e-04, 1.77943424e-03, 2.15050085e-04,\n",
       "       3.80102564e-04, 3.22934904e-04, 6.80557378e-04, 1.01781662e-03,\n",
       "       7.83771928e-04, 9.78415191e-04, 2.72382053e-03, 2.81867162e-04,\n",
       "       1.42211474e-04, 1.48500871e-04, 5.66301225e-04, 5.93274984e-03,\n",
       "       5.06892160e-04, 2.15445889e-04, 4.99137021e-04, 5.15603268e-04,\n",
       "       4.60359891e-04, 1.28802308e-03, 1.27466734e-03, 2.59173555e-03,\n",
       "       5.16041258e-04, 5.98701994e-05, 4.58323672e-03, 3.92415973e-04,\n",
       "       1.72145729e-04, 5.04926517e-04, 1.93988574e-04, 5.41948869e-04,\n",
       "       2.91698337e-04, 1.56960516e-03, 8.67212832e-05, 1.07944252e-04,\n",
       "       3.30888241e-04, 7.61850864e-04, 6.91470469e-04, 3.55046274e-04,\n",
       "       3.82634362e-04, 2.29708821e-04, 9.21181556e-05, 1.58326041e-04,\n",
       "       1.31234582e-04, 1.16640699e-04, 1.53671921e-03, 3.47026329e-04,\n",
       "       2.46700023e-04, 1.39441573e-04, 2.89936468e-04, 4.92268947e-04,\n",
       "       1.28872696e-04, 3.50798448e-04, 3.34245288e-04, 4.54487002e-03,\n",
       "       7.74124359e-04, 1.80678814e-04, 1.42560649e-04, 3.53820506e-04,\n",
       "       2.21449810e-04, 3.16457785e-03, 2.86123802e-04, 1.36883241e-03,\n",
       "       3.03815421e-04, 2.42442472e-04, 1.86045321e-04, 8.33030054e-04,\n",
       "       2.11791766e-04, 3.20993694e-03, 2.49506363e-04, 2.83489367e-04,\n",
       "       1.55970534e-04, 1.92337683e-04, 1.15076368e-03, 2.81569852e-04,\n",
       "       3.98139244e-04, 2.38753706e-04, 2.11317124e-04, 1.77646123e-04,\n",
       "       8.85210888e-04, 2.03545691e-03, 1.07687065e-04, 2.20553474e-03,\n",
       "       3.37198859e-04, 3.77817309e-04, 1.67207911e-03, 2.72651228e-04,\n",
       "       1.07672466e-03, 5.12846165e-04, 4.63936805e-04, 3.62566211e-04,\n",
       "       3.42565103e-04, 5.24035998e-04, 8.64642375e-04, 1.77996834e-04,\n",
       "       2.15274858e-04, 6.32981474e-03, 1.34419567e-03, 3.74577850e-03,\n",
       "       1.55953362e-04, 4.27229641e-03, 8.19636687e-04, 6.95556060e-04,\n",
       "       4.51194086e-04, 5.49116608e-04, 2.10064116e-04, 5.43575342e-04,\n",
       "       1.28717578e-04, 8.29456428e-05, 5.26277570e-04, 2.31371030e-04,\n",
       "       1.24091463e-04, 3.52818528e-04, 4.49628529e-04, 1.14341154e-04,\n",
       "       4.79990585e-05, 1.97451174e-04, 1.59171842e-04, 1.50479779e-03,\n",
       "       6.63834480e-04, 1.29852872e-04, 2.51345241e-04, 1.47315217e-04,\n",
       "       1.79987704e-04, 2.65563735e-03, 1.02835095e-03, 3.25353905e-04,\n",
       "       3.51148837e-03, 9.96600556e-05, 1.64684715e-03, 3.84285160e-04,\n",
       "       1.33531489e-03, 2.74177653e-04, 2.45752271e-04, 4.59308376e-04,\n",
       "       2.03241386e-03, 4.06198841e-04, 6.21978309e-05, 1.37561288e-03,\n",
       "       7.53634599e-04, 1.30328720e-03, 2.49017918e-04, 3.83116431e-05,\n",
       "       1.35827300e-04, 1.88670512e-02, 1.37774826e-04, 1.56091243e-04,\n",
       "       1.03926106e-03, 1.40540466e-03, 1.25693166e-04, 1.19084716e-04,\n",
       "       5.51235343e-04, 2.71454568e-03, 7.84882763e-04, 8.79056234e-05,\n",
       "       9.91640698e-04, 1.00930950e-03, 3.77354583e-03, 2.48326767e-03,\n",
       "       4.16354652e-04, 6.99462420e-03, 4.71300983e-04, 3.64289573e-04,\n",
       "       2.00663788e-04, 6.27003454e-04, 4.98192651e-04, 9.10273024e-05,\n",
       "       1.02858103e-03, 1.34652601e-03, 8.54786226e-04, 4.89256601e-04,\n",
       "       1.17456055e-04, 1.34219145e-03, 3.70622447e-04, 5.05632006e-03,\n",
       "       4.39255819e-04, 1.79134551e-04, 6.48526690e-03, 1.78885346e-04,\n",
       "       1.03146586e-04, 1.46957976e-04, 1.18397844e-03, 1.13037612e-03,\n",
       "       4.83038104e-04, 1.92938861e-04, 4.32881154e-04, 6.34005660e-04,\n",
       "       1.74765285e-04, 1.00797445e-03, 1.39201197e-03, 1.10327252e-04,\n",
       "       5.85984351e-04, 2.01435796e-04, 2.61727271e-04, 1.89008969e-03,\n",
       "       7.43645762e-04, 1.68355365e-03, 8.01723840e-04, 1.14695728e-04,\n",
       "       2.14351123e-04, 7.07478914e-04, 3.10367723e-04, 9.42092677e-04,\n",
       "       1.13705979e-02, 8.98957321e-02, 3.94415924e-02, 2.00331619e-05,\n",
       "       2.70020487e-04, 2.36194888e-03, 0.00000000e+00, 2.18558498e-03,\n",
       "       2.66754078e-05, 2.80961287e-04, 1.26646689e-03, 1.57501776e-03,\n",
       "       1.13976486e-03, 0.00000000e+00, 1.98592339e-03, 0.00000000e+00,\n",
       "       0.00000000e+00, 6.62331854e-03, 4.08815053e-03, 2.88982362e-03,\n",
       "       2.06352939e-04, 6.84775531e-03, 1.93909362e-05, 0.00000000e+00,\n",
       "       3.65036261e-04, 2.84709029e-03, 0.00000000e+00, 1.50308461e-03,\n",
       "       0.00000000e+00, 0.00000000e+00, 1.72415465e-03, 9.65680919e-04,\n",
       "       2.43509690e-03, 8.28185103e-05, 7.06664258e-05, 2.27564779e-05,\n",
       "       2.08123868e-01, 5.22167908e-05, 9.67077347e-03, 3.09410185e-05,\n",
       "       5.43889412e-03, 2.14870153e-04, 3.14648568e-05, 4.49850139e-03,\n",
       "       2.12635024e-04, 1.13567556e-02, 2.39734465e-03, 8.07590110e-04,\n",
       "       3.10150478e-04, 1.19259133e-02, 3.20614634e-03, 9.80128768e-05,\n",
       "       4.74622785e-04, 1.03829035e-02, 7.39365156e-03, 3.30563503e-04,\n",
       "       2.98208791e-05, 1.36131006e-03, 1.98237350e-04, 1.05211359e-02,\n",
       "       2.12674561e-05, 9.57501390e-05, 9.50457980e-04, 1.86094567e-03,\n",
       "       2.85518480e-04, 4.75170148e-04, 9.84408299e-04, 4.30660824e-04,\n",
       "       4.08556947e-04, 5.29180228e-03, 5.78150374e-04, 1.04716066e-01,\n",
       "       1.24887721e-03, 3.64324658e-05, 5.53296310e-05, 5.02980186e-05,\n",
       "       1.06079068e-04, 1.11755041e-02, 3.21245606e-03, 9.86741394e-05,\n",
       "       2.00221618e-03])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "selector.estimator_.feature_importances_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0021321961620469083"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "selector.threshold_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "mask = selector.get_support()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([False, False, False, False, False, False, False,  True, False,\n",
       "       False, False, False, False, False, False, False, False, False,\n",
       "       False, False, False, False, False, False, False, False, False,\n",
       "       False, False,  True, False, False, False, False, False, False,\n",
       "        True, False, False, False, False, False, False, False, False,\n",
       "       False, False, False, False, False, False, False, False, False,\n",
       "       False, False,  True, False, False, False, False, False, False,\n",
       "       False, False, False, False, False, False, False, False, False,\n",
       "       False, False, False, False, False, False,  True, False, False,\n",
       "       False, False, False, False, False, False, False, False, False,\n",
       "       False, False, False, False, False, False,  True, False,  True,\n",
       "       False, False, False, False,  True, False, False, False, False,\n",
       "       False, False, False, False, False, False, False, False, False,\n",
       "        True, False, False, False,  True, False, False, False,  True,\n",
       "       False, False, False, False, False, False, False, False, False,\n",
       "       False, False, False, False, False, False,  True, False, False,\n",
       "        True,  True, False, False, False,  True, False, False, False,\n",
       "       False,  True, False, False, False,  True, False, False, False,\n",
       "       False, False, False, False, False, False,  True, False, False,\n",
       "       False, False, False, False, False,  True, False,  True, False,\n",
       "       False, False, False, False, False, False, False, False, False,\n",
       "       False, False, False, False, False,  True, False, False, False,\n",
       "       False,  True, False, False, False, False, False, False, False,\n",
       "        True, False, False,  True, False, False, False, False, False,\n",
       "       False, False, False, False, False, False, False, False, False,\n",
       "       False, False, False, False, False, False, False, False, False,\n",
       "       False, False, False, False, False,  True, False, False, False,\n",
       "       False, False,  True, False, False, False, False, False, False,\n",
       "       False,  True, False, False, False, False, False, False, False,\n",
       "       False, False, False, False, False, False,  True, False, False,\n",
       "       False, False, False, False, False, False, False, False, False,\n",
       "       False, False,  True, False,  True, False,  True, False, False,\n",
       "       False, False, False, False, False, False, False, False, False,\n",
       "       False, False, False, False, False, False, False, False, False,\n",
       "       False, False, False,  True, False, False,  True, False, False,\n",
       "       False, False, False, False, False, False, False, False, False,\n",
       "       False, False, False, False, False,  True, False, False, False,\n",
       "       False, False, False, False,  True, False, False, False, False,\n",
       "        True,  True, False,  True, False, False, False, False, False,\n",
       "       False, False, False, False, False, False, False, False,  True,\n",
       "       False, False,  True, False, False, False, False, False, False,\n",
       "       False, False, False, False, False, False, False, False, False,\n",
       "       False, False, False, False, False, False, False, False, False,\n",
       "       False,  True,  True,  True, False, False,  True, False,  True,\n",
       "       False, False, False, False, False, False, False, False, False,\n",
       "        True,  True,  True, False,  True, False, False, False,  True,\n",
       "       False, False, False, False, False, False,  True, False, False,\n",
       "       False,  True, False,  True, False,  True, False, False,  True,\n",
       "       False,  True,  True, False, False,  True,  True, False, False,\n",
       "        True,  True, False, False, False, False,  True, False, False,\n",
       "       False, False, False, False, False, False, False,  True, False,\n",
       "        True, False, False, False, False, False,  True,  True, False,\n",
       "       False])"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "selected_features = X.columns[mask]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tfidf_7</th>\n",
       "      <th>tfidf_29</th>\n",
       "      <th>tfidf_36</th>\n",
       "      <th>tfidf_56</th>\n",
       "      <th>tfidf_78</th>\n",
       "      <th>tfidf_96</th>\n",
       "      <th>tfidf_98</th>\n",
       "      <th>tfidf_103</th>\n",
       "      <th>tfidf_117</th>\n",
       "      <th>tfidf_121</th>\n",
       "      <th>...</th>\n",
       "      <th>earthy</th>\n",
       "      <th>grape</th>\n",
       "      <th>grapefruit</th>\n",
       "      <th>lemon</th>\n",
       "      <th>lime</th>\n",
       "      <th>orange</th>\n",
       "      <th>skunk</th>\n",
       "      <th>strawberry</th>\n",
       "      <th>tropical</th>\n",
       "      <th>vanilla</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.151083</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.151083</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.122034</td>\n",
       "      <td>0.140663</td>\n",
       "      <td>0.170755</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.247899</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>74995</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>74996</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>74997</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>74998</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>74999</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>75000 rows × 66 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       tfidf_7  tfidf_29  tfidf_36  tfidf_56  tfidf_78  tfidf_96  tfidf_98  \\\n",
       "0          0.0       0.0       0.0       0.0       0.0       0.0  0.000000   \n",
       "1          0.0       0.0       0.0       0.0       0.0       0.0  0.000000   \n",
       "2          0.0       0.0       0.0       0.0       0.0       0.0  0.000000   \n",
       "3          0.0       0.0       0.0       0.0       0.0       0.0  0.000000   \n",
       "4          0.0       0.0       0.0       0.0       0.0       0.0  0.247899   \n",
       "...        ...       ...       ...       ...       ...       ...       ...   \n",
       "74995      0.0       0.0       0.0       0.0       0.0       0.0  0.000000   \n",
       "74996      0.0       0.0       0.0       0.0       0.0       0.0  0.000000   \n",
       "74997      0.0       0.0       0.0       0.0       0.0       0.0  0.000000   \n",
       "74998      0.0       0.0       0.0       0.0       0.0       0.0  0.000000   \n",
       "74999      0.0       0.0       0.0       0.0       0.0       0.0  0.000000   \n",
       "\n",
       "       tfidf_103  tfidf_117  tfidf_121  ...  earthy  grape  grapefruit  lemon  \\\n",
       "0       0.151083   0.000000   0.000000  ...       0      1           0      0   \n",
       "1       0.151083   0.000000   0.000000  ...       0      1           0      0   \n",
       "2       0.122034   0.140663   0.170755  ...       0      0           0      0   \n",
       "3       0.000000   0.000000   0.000000  ...       0      0           0      0   \n",
       "4       0.000000   0.000000   0.000000  ...       0      0           0      0   \n",
       "...          ...        ...        ...  ...     ...    ...         ...    ...   \n",
       "74995   0.000000   0.000000   0.000000  ...       0      0           0      0   \n",
       "74996   0.000000   0.000000   0.000000  ...       0      0           0      0   \n",
       "74997   0.000000   0.000000   0.000000  ...       0      0           0      0   \n",
       "74998   0.000000   0.000000   0.000000  ...       0      0           0      0   \n",
       "74999   0.000000   0.000000   0.000000  ...       1      1           1      1   \n",
       "\n",
       "       lime  orange  skunk  strawberry  tropical  vanilla  \n",
       "0         1       0      0           0         0        0  \n",
       "1         1       0      0           0         0        0  \n",
       "2         0       0      0           0         0        1  \n",
       "3         0       0      1           0         0        0  \n",
       "4         0       0      0           0         0        0  \n",
       "...     ...     ...    ...         ...       ...      ...  \n",
       "74995     0       0      0           0         0        0  \n",
       "74996     0       0      0           0         0        0  \n",
       "74997     0       0      0           0         0        0  \n",
       "74998     0       0      0           0         0        0  \n",
       "74999     1       1      1           1         1        1  \n",
       "\n",
       "[75000 rows x 66 columns]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "selected_X = df_rf[selected_features]\n",
    "selected_X"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train test split (after Feature Selection)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['selected_X_rf_tfidf_cbg.pkl']"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import joblib\n",
    "\n",
    "joblib.dump(selector, \"selector_rf_tfidf_cbg.pkl\")\n",
    "joblib.dump(selected_X, \"selected_X_rf_tfidf_cbg.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(selected_X, y, random_state=1, test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train1, X_val, y_train1, y_val = train_test_split(X_train, y_train, random_state=1, test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/y1/pjvjlkjn5gl846rnyzr53p340000gn/T/ipykernel_9167/3758305.py:1: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  rfreg.fit(X_train1, y_train1)\n"
     ]
    }
   ],
   "source": [
    "rfreg.fit(X_train1, y_train1)\n",
    "y_pred_rfreg = rfreg.predict(X_val)\n",
    "y_pred_rfreg_r2 = rfreg.predict(X_train1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.027227070019288674"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mean_absolute_error(y_val, y_pred_rfreg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0047601180514211415"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mean_squared_error(y_val, y_pred_rfreg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.06899360877227065"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mean_squared_error(y_val, y_pred_rfreg, squared = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.982832935294932"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#train\n",
    "r2_score(y_train1, y_pred_rfreg_r2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9339101343470937"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#val\n",
    "r2_score(y_val, y_pred_rfreg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hyperparameter Tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "parameters = {'max_depth': [None, 10, 50, 100],\n",
    "              'max_features': ['auto', 'sqrt'],\n",
    "              'min_samples_leaf': [1, 2, 4],\n",
    "              'min_samples_split': [2, 5, 10],\n",
    "              'n_estimators': [100, 300, 500]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "rscv = RandomizedSearchCV(rfreg,  \n",
    "                     parameters,   \n",
    "                     cv=5, \n",
    "                     scoring='neg_mean_absolute_error',\n",
    "                     n_jobs = -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/andalanputra/opt/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/Users/andalanputra/opt/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/Users/andalanputra/opt/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/Users/andalanputra/opt/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/Users/andalanputra/opt/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/Users/andalanputra/opt/anaconda3/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
      "  warn(\n",
      "/Users/andalanputra/opt/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/Users/andalanputra/opt/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/Users/andalanputra/opt/anaconda3/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
      "  warn(\n",
      "/Users/andalanputra/opt/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/Users/andalanputra/opt/anaconda3/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
      "  warn(\n",
      "/Users/andalanputra/opt/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/Users/andalanputra/opt/anaconda3/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
      "  warn(\n",
      "/Users/andalanputra/opt/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/Users/andalanputra/opt/anaconda3/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
      "  warn(\n",
      "/Users/andalanputra/opt/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/Users/andalanputra/opt/anaconda3/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
      "  warn(\n",
      "/Users/andalanputra/opt/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/Users/andalanputra/opt/anaconda3/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
      "  warn(\n",
      "/Users/andalanputra/opt/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/Users/andalanputra/opt/anaconda3/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
      "  warn(\n",
      "/Users/andalanputra/opt/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/Users/andalanputra/opt/anaconda3/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
      "  warn(\n",
      "/Users/andalanputra/opt/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/Users/andalanputra/opt/anaconda3/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
      "  warn(\n",
      "/Users/andalanputra/opt/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/Users/andalanputra/opt/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/Users/andalanputra/opt/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/Users/andalanputra/opt/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/Users/andalanputra/opt/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/Users/andalanputra/opt/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/Users/andalanputra/opt/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/Users/andalanputra/opt/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/Users/andalanputra/opt/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/Users/andalanputra/opt/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/Users/andalanputra/opt/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/Users/andalanputra/opt/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/Users/andalanputra/opt/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/Users/andalanputra/opt/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/Users/andalanputra/opt/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/Users/andalanputra/opt/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/Users/andalanputra/opt/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/Users/andalanputra/opt/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/Users/andalanputra/opt/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/Users/andalanputra/opt/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/Users/andalanputra/opt/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/Users/andalanputra/opt/anaconda3/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
      "  warn(\n",
      "/Users/andalanputra/opt/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/Users/andalanputra/opt/anaconda3/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
      "  warn(\n",
      "/Users/andalanputra/opt/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/Users/andalanputra/opt/anaconda3/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
      "  warn(\n",
      "/Users/andalanputra/opt/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/Users/andalanputra/opt/anaconda3/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
      "  warn(\n",
      "/Users/andalanputra/opt/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/Users/andalanputra/opt/anaconda3/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
      "  warn(\n",
      "/Users/andalanputra/opt/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/Users/andalanputra/opt/anaconda3/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
      "  warn(\n",
      "/Users/andalanputra/opt/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/Users/andalanputra/opt/anaconda3/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
      "  warn(\n",
      "/Users/andalanputra/opt/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/Users/andalanputra/opt/anaconda3/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
      "  warn(\n",
      "/Users/andalanputra/opt/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/Users/andalanputra/opt/anaconda3/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
      "  warn(\n",
      "/Users/andalanputra/opt/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/Users/andalanputra/opt/anaconda3/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
      "  warn(\n",
      "/Users/andalanputra/opt/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/Users/andalanputra/opt/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/Users/andalanputra/opt/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/Users/andalanputra/opt/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/Users/andalanputra/opt/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/Users/andalanputra/opt/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_search.py:909: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  self.best_estimator_.fit(X, y, **fit_params)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-2 {color: black;background-color: white;}#sk-container-id-2 pre{padding: 0;}#sk-container-id-2 div.sk-toggleable {background-color: white;}#sk-container-id-2 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-2 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-2 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-2 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-2 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-2 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-2 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-2 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-2 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-2 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-2 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-2 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-2 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-2 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-2 div.sk-item {position: relative;z-index: 1;}#sk-container-id-2 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-2 div.sk-item::before, #sk-container-id-2 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-2 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-2 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-2 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-2 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-2 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-2 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-2 div.sk-label-container {text-align: center;}#sk-container-id-2 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-2 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-2\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>RandomizedSearchCV(cv=5, estimator=RandomForestRegressor(), n_jobs=-1,\n",
       "                   param_distributions={&#x27;max_depth&#x27;: [None, 10, 50, 100],\n",
       "                                        &#x27;max_features&#x27;: [&#x27;auto&#x27;, &#x27;sqrt&#x27;],\n",
       "                                        &#x27;min_samples_leaf&#x27;: [1, 2, 4],\n",
       "                                        &#x27;min_samples_split&#x27;: [2, 5, 10],\n",
       "                                        &#x27;n_estimators&#x27;: [100, 300, 500]},\n",
       "                   scoring=&#x27;neg_mean_absolute_error&#x27;)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" ><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">RandomizedSearchCV</label><div class=\"sk-toggleable__content\"><pre>RandomizedSearchCV(cv=5, estimator=RandomForestRegressor(), n_jobs=-1,\n",
       "                   param_distributions={&#x27;max_depth&#x27;: [None, 10, 50, 100],\n",
       "                                        &#x27;max_features&#x27;: [&#x27;auto&#x27;, &#x27;sqrt&#x27;],\n",
       "                                        &#x27;min_samples_leaf&#x27;: [1, 2, 4],\n",
       "                                        &#x27;min_samples_split&#x27;: [2, 5, 10],\n",
       "                                        &#x27;n_estimators&#x27;: [100, 300, 500]},\n",
       "                   scoring=&#x27;neg_mean_absolute_error&#x27;)</pre></div></div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-3\" type=\"checkbox\" ><label for=\"sk-estimator-id-3\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">estimator: RandomForestRegressor</label><div class=\"sk-toggleable__content\"><pre>RandomForestRegressor()</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-4\" type=\"checkbox\" ><label for=\"sk-estimator-id-4\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">RandomForestRegressor</label><div class=\"sk-toggleable__content\"><pre>RandomForestRegressor()</pre></div></div></div></div></div></div></div></div></div></div>"
      ],
      "text/plain": [
       "RandomizedSearchCV(cv=5, estimator=RandomForestRegressor(), n_jobs=-1,\n",
       "                   param_distributions={'max_depth': [None, 10, 50, 100],\n",
       "                                        'max_features': ['auto', 'sqrt'],\n",
       "                                        'min_samples_leaf': [1, 2, 4],\n",
       "                                        'min_samples_split': [2, 5, 10],\n",
       "                                        'n_estimators': [100, 300, 500]},\n",
       "                   scoring='neg_mean_absolute_error')"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rscv.fit(X_train1, y_train1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'n_estimators': 500,\n",
       " 'min_samples_split': 10,\n",
       " 'min_samples_leaf': 1,\n",
       " 'max_features': 'sqrt',\n",
       " 'max_depth': None}"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rscv.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['rscv_rf_tfidf_best_params_cbg.pkl']"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "joblib.dump(rscv, \"rscv_rf_tfidf_cbg.pkl\")\n",
    "joblib.dump(rscv.best_params_, \"rscv_rf_tfidf_best_params_cbg.pkl\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "RF (after Hyperparameter Tuning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/y1/pjvjlkjn5gl846rnyzr53p340000gn/T/ipykernel_9167/2401359886.py:2: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  rfreg_ht.fit(X_train1, y_train1)\n"
     ]
    }
   ],
   "source": [
    "rfreg_ht = RandomForestRegressor(n_estimators = 500, min_samples_split = 10, min_samples_leaf = 1, max_features = 'sqrt', max_depth = None)\n",
    "rfreg_ht.fit(X_train1, y_train1)\n",
    "y_pred_rfreg = rfreg_ht.predict(X_val)\n",
    "y_pred_rfreg_r2 = rfreg_ht.predict(X_train1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.03797218205013828"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mean_absolute_error(y_val, y_pred_rfreg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.005550677283696649"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mean_squared_error(y_val, y_pred_rfreg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.07450286762062686"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mean_squared_error(y_val, y_pred_rfreg, squared = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9631461358890151"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#train\n",
    "r2_score(y_train1, y_pred_rfreg_r2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9229339457552678"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#val\n",
    "r2_score(y_val, y_pred_rfreg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Residual plots after Hyperparameter Tuning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Predicting model on the test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_rfreg_test = rfreg_ht.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['y_test_rfreg_tfidf_cbg.pkl']"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "joblib.dump(y_pred_rfreg_test, \"y_pred_rfreg_test_tfidf_cbg.pkl\")\n",
    "joblib.dump(y_test, \"y_test_rfreg_tfidf_cbg.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.03758084572025641"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mean_absolute_error(y_test, y_pred_rfreg_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.00546742906859753"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mean_squared_error(y_test, y_pred_rfreg_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.07394206562301009"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mean_squared_error(y_test, y_pred_rfreg_test, squared = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9247885709221614"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "r2_score(y_test, y_pred_rfreg_test)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Error analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 576x432 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 432x288 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# assume y_pred is a numpy array and y_true is a pandas dataframe\n",
    "fig, ax = plt.subplots(figsize=(8, 6))\n",
    "\n",
    "column = \"X..CBG\"  # specify the target variable name\n",
    "ax.hist(y_pred_rfreg_test, alpha=0.5, label='y_pred', bins=20)\n",
    "ax.hist(y_test[column], alpha=0.5, label='y_true', bins=20)\n",
    "ax.legend(loc='upper right')\n",
    "ax.set_title(column)\n",
    "\n",
    "plt.show()\n",
    "plt.savefig('error_hist_knn_tfidf_cbg.png')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pearson R"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pearson correlation coefficient: 0.963\n",
      "P-value: 0.000\n"
     ]
    }
   ],
   "source": [
    "corr_coef, p_value = pearsonr(y_pred_rfreg_test.flatten(), y_test.values.ravel())\n",
    "\n",
    "print(f\"Pearson correlation coefficient: {corr_coef:.3f}\")\n",
    "print(f\"P-value: {p_value:.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:>"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "corr_matrix = y_test.corr()\n",
    "sns.heatmap(corr_matrix, annot=True, cmap='coolwarm', center=0)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
