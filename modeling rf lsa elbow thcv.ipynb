{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn import preprocessing\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.neural_network import MLPRegressor\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "from sklearn.metrics import r2_score\n",
    "from scipy.stats import pearsonr\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.feature_selection import SelectFromModel\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compiling complete dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_rf = pd.read_csv(\"df_thcv_lsa.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>lsa_0</th>\n",
       "      <th>lsa_1</th>\n",
       "      <th>lsa_2</th>\n",
       "      <th>lsa_3</th>\n",
       "      <th>lsa_4</th>\n",
       "      <th>hybrid</th>\n",
       "      <th>indica</th>\n",
       "      <th>sativa</th>\n",
       "      <th>anxiety</th>\n",
       "      <th>...</th>\n",
       "      <th>sweet</th>\n",
       "      <th>tar</th>\n",
       "      <th>tea</th>\n",
       "      <th>tobacco</th>\n",
       "      <th>tree</th>\n",
       "      <th>tropical</th>\n",
       "      <th>vanilla</th>\n",
       "      <th>violet</th>\n",
       "      <th>woody</th>\n",
       "      <th>X..THCV</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0.341025</td>\n",
       "      <td>0.182753</td>\n",
       "      <td>0.008214</td>\n",
       "      <td>0.140406</td>\n",
       "      <td>-0.156943</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.030928</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0.232158</td>\n",
       "      <td>-0.045496</td>\n",
       "      <td>0.187131</td>\n",
       "      <td>-0.000936</td>\n",
       "      <td>0.018518</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.030928</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4</td>\n",
       "      <td>0.238648</td>\n",
       "      <td>-0.048758</td>\n",
       "      <td>-0.107398</td>\n",
       "      <td>-0.067096</td>\n",
       "      <td>-0.006558</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.030928</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>7</td>\n",
       "      <td>0.401841</td>\n",
       "      <td>-0.062527</td>\n",
       "      <td>-0.018128</td>\n",
       "      <td>-0.104475</td>\n",
       "      <td>0.009215</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.030928</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>11</td>\n",
       "      <td>0.260672</td>\n",
       "      <td>-0.019644</td>\n",
       "      <td>0.215790</td>\n",
       "      <td>-0.106098</td>\n",
       "      <td>0.058930</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.030928</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>74995</th>\n",
       "      <td>42976</td>\n",
       "      <td>0.270141</td>\n",
       "      <td>-0.004631</td>\n",
       "      <td>-0.151272</td>\n",
       "      <td>0.035538</td>\n",
       "      <td>0.083641</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.154639</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>74996</th>\n",
       "      <td>42976</td>\n",
       "      <td>0.270141</td>\n",
       "      <td>-0.004631</td>\n",
       "      <td>-0.151272</td>\n",
       "      <td>0.035538</td>\n",
       "      <td>0.083641</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.154639</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>74997</th>\n",
       "      <td>42976</td>\n",
       "      <td>0.270141</td>\n",
       "      <td>-0.004631</td>\n",
       "      <td>-0.151272</td>\n",
       "      <td>0.035538</td>\n",
       "      <td>0.083641</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.154639</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>74998</th>\n",
       "      <td>42976</td>\n",
       "      <td>0.270141</td>\n",
       "      <td>-0.004631</td>\n",
       "      <td>-0.151272</td>\n",
       "      <td>0.035538</td>\n",
       "      <td>0.083641</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.154639</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>74999</th>\n",
       "      <td>42976</td>\n",
       "      <td>0.270141</td>\n",
       "      <td>-0.004631</td>\n",
       "      <td>-0.151272</td>\n",
       "      <td>0.035538</td>\n",
       "      <td>0.083641</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.154639</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>75000 rows × 88 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       index     lsa_0     lsa_1     lsa_2     lsa_3     lsa_4  hybrid  \\\n",
       "0          0  0.341025  0.182753  0.008214  0.140406 -0.156943       1   \n",
       "1          1  0.232158 -0.045496  0.187131 -0.000936  0.018518       1   \n",
       "2          4  0.238648 -0.048758 -0.107398 -0.067096 -0.006558       1   \n",
       "3          7  0.401841 -0.062527 -0.018128 -0.104475  0.009215       1   \n",
       "4         11  0.260672 -0.019644  0.215790 -0.106098  0.058930       1   \n",
       "...      ...       ...       ...       ...       ...       ...     ...   \n",
       "74995  42976  0.270141 -0.004631 -0.151272  0.035538  0.083641       0   \n",
       "74996  42976  0.270141 -0.004631 -0.151272  0.035538  0.083641       0   \n",
       "74997  42976  0.270141 -0.004631 -0.151272  0.035538  0.083641       0   \n",
       "74998  42976  0.270141 -0.004631 -0.151272  0.035538  0.083641       0   \n",
       "74999  42976  0.270141 -0.004631 -0.151272  0.035538  0.083641       0   \n",
       "\n",
       "       indica  sativa  anxiety  ...  sweet  tar  tea  tobacco  tree  tropical  \\\n",
       "0           0       0        0  ...      0    0    0        0     0         0   \n",
       "1           0       0        0  ...      0    0    0        0     0         0   \n",
       "2           0       0        0  ...      0    0    0        0     0         0   \n",
       "3           0       0        0  ...      0    1    0        0     0         0   \n",
       "4           0       0        0  ...      1    0    0        0     0         0   \n",
       "...       ...     ...      ...  ...    ...  ...  ...      ...   ...       ...   \n",
       "74995       1       0        0  ...      1    1    1        1     1         1   \n",
       "74996       1       0        0  ...      1    1    1        1     1         1   \n",
       "74997       1       0        0  ...      1    1    1        1     1         1   \n",
       "74998       1       0        0  ...      1    1    1        1     1         1   \n",
       "74999       1       0        0  ...      1    1    1        1     1         1   \n",
       "\n",
       "       vanilla  violet  woody   X..THCV  \n",
       "0            0       0      0  0.030928  \n",
       "1            1       0      0  0.030928  \n",
       "2            0       0      0  0.030928  \n",
       "3            1       1      1  0.030928  \n",
       "4            0       0      0  0.030928  \n",
       "...        ...     ...    ...       ...  \n",
       "74995        1       1      1  0.154639  \n",
       "74996        1       1      1  0.154639  \n",
       "74997        1       1      1  0.154639  \n",
       "74998        1       1      1  0.154639  \n",
       "74999        1       1      1  0.154639  \n",
       "\n",
       "[75000 rows x 88 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_rf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['index',\n",
       " 'lsa_0',\n",
       " 'lsa_1',\n",
       " 'lsa_2',\n",
       " 'lsa_3',\n",
       " 'lsa_4',\n",
       " 'hybrid',\n",
       " 'indica',\n",
       " 'sativa',\n",
       " 'anxiety',\n",
       " 'anxious',\n",
       " 'aroused',\n",
       " 'arthritis',\n",
       " 'creative',\n",
       " 'depression',\n",
       " 'dizzy',\n",
       " 'dry eyes',\n",
       " 'dry mouth',\n",
       " 'energetic',\n",
       " 'epilepsy',\n",
       " 'euphoric',\n",
       " 'eye pressure',\n",
       " 'fatigue',\n",
       " 'focused',\n",
       " 'giggly',\n",
       " 'happy',\n",
       " 'headache',\n",
       " 'hungry',\n",
       " 'migraines',\n",
       " 'pain',\n",
       " 'paranoid',\n",
       " 'relaxed',\n",
       " 'seizures',\n",
       " 'sleepy',\n",
       " 'spasticity',\n",
       " 'stress',\n",
       " 'talkative',\n",
       " 'tingly',\n",
       " 'uplifted',\n",
       " 'ammonia',\n",
       " 'apple',\n",
       " 'apricot',\n",
       " 'berry',\n",
       " 'blue cheese',\n",
       " 'blueberry',\n",
       " 'butter',\n",
       " 'cheese',\n",
       " 'chemical',\n",
       " 'chestnut',\n",
       " 'citrus',\n",
       " 'coffee',\n",
       " 'diesel',\n",
       " 'earthy',\n",
       " 'flowery',\n",
       " 'fruit',\n",
       " 'grape',\n",
       " 'grapefruit',\n",
       " 'honey',\n",
       " 'lavender',\n",
       " 'lemon',\n",
       " 'lime',\n",
       " 'mango',\n",
       " 'menthol',\n",
       " 'mint',\n",
       " 'nutty',\n",
       " 'orange',\n",
       " 'peach',\n",
       " 'pear',\n",
       " 'pepper',\n",
       " 'pine',\n",
       " 'pineapple',\n",
       " 'plum',\n",
       " 'pungent',\n",
       " 'rose',\n",
       " 'sage',\n",
       " 'skunk',\n",
       " 'spicy/herbal',\n",
       " 'strawberry',\n",
       " 'sweet',\n",
       " 'tar',\n",
       " 'tea',\n",
       " 'tobacco',\n",
       " 'tree',\n",
       " 'tropical',\n",
       " 'vanilla',\n",
       " 'violet',\n",
       " 'woody',\n",
       " 'X..THCV']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_rf.columns.to_list()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Splitting dependent and independent variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df_rf.drop(['index', 'X..THCV'], axis = 1)\n",
    "y = df_rf[['X..THCV']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plotting histograms on target variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.03092784],\n",
       "       [0.03092784],\n",
       "       [0.03092784],\n",
       "       ...,\n",
       "       [0.15463918],\n",
       "       [0.15463918],\n",
       "       [0.15463918]])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_array = y.to_numpy()\n",
    "y_array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Axes: ylabel='Count'>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "sns.histplot(y, bins = 10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train test split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=1, test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train1, X_val, y_train1, y_val = train_test_split(X_train, y_train, random_state=1, test_size=0.25)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "RF modeling (before Feature selection and Hyperparameter Tuning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/ns/m5pnr0211w91v02hpv22958m0000gn/T/ipykernel_3199/119766249.py:2: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  rfreg.fit(X_train1, y_train1)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;background-color: white;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>RandomForestRegressor(n_jobs=-1)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">RandomForestRegressor</label><div class=\"sk-toggleable__content\"><pre>RandomForestRegressor(n_jobs=-1)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "RandomForestRegressor(n_jobs=-1)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rfreg = RandomForestRegressor(n_jobs = -1)\n",
    "rfreg.fit(X_train1, y_train1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_rfreg = rfreg.predict(X_val)\n",
    "y_pred_rfreg_r2 = rfreg.predict(X_train1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.01131442706822162"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mean_absolute_error(y_val, y_pred_rfreg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0016804668450637631"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mean_squared_error(y_val, y_pred_rfreg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.04099349759490843"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mean_squared_error(y_val, y_pred_rfreg, squared = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9912958421624637"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#train\n",
    "r2_score(y_train1, y_pred_rfreg_r2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9862662343389453"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#val\n",
    "r2_score(y_val, y_pred_rfreg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Residual plots for each target variable"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Feature Selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_feat = pd.DataFrame({\n",
    "    \"features\": X_train1.columns,\n",
    "    \"score\": rfreg.feature_importances_\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>features</th>\n",
       "      <th>score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>lsa_0</td>\n",
       "      <td>0.108502</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>lsa_1</td>\n",
       "      <td>0.057349</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>lsa_2</td>\n",
       "      <td>0.103441</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>lsa_3</td>\n",
       "      <td>0.069180</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>lsa_4</td>\n",
       "      <td>0.072582</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>81</th>\n",
       "      <td>tree</td>\n",
       "      <td>0.000147</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>82</th>\n",
       "      <td>tropical</td>\n",
       "      <td>0.001629</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>83</th>\n",
       "      <td>vanilla</td>\n",
       "      <td>0.000250</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>84</th>\n",
       "      <td>violet</td>\n",
       "      <td>0.000030</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>85</th>\n",
       "      <td>woody</td>\n",
       "      <td>0.000790</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>86 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    features     score\n",
       "0      lsa_0  0.108502\n",
       "1      lsa_1  0.057349\n",
       "2      lsa_2  0.103441\n",
       "3      lsa_3  0.069180\n",
       "4      lsa_4  0.072582\n",
       "..       ...       ...\n",
       "81      tree  0.000147\n",
       "82  tropical  0.001629\n",
       "83   vanilla  0.000250\n",
       "84    violet  0.000030\n",
       "85     woody  0.000790\n",
       "\n",
       "[86 rows x 2 columns]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_feat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_feat_ranked = df_feat.sort_values(\"score\", ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>features</th>\n",
       "      <th>score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>hybrid</td>\n",
       "      <td>0.264681</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>lsa_0</td>\n",
       "      <td>0.108502</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59</th>\n",
       "      <td>lime</td>\n",
       "      <td>0.104602</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>lsa_2</td>\n",
       "      <td>0.103441</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>lsa_4</td>\n",
       "      <td>0.072582</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>lsa_3</td>\n",
       "      <td>0.069180</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>citrus</td>\n",
       "      <td>0.068155</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>lsa_1</td>\n",
       "      <td>0.057349</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>cheese</td>\n",
       "      <td>0.025364</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50</th>\n",
       "      <td>diesel</td>\n",
       "      <td>0.009589</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>hungry</td>\n",
       "      <td>0.008675</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51</th>\n",
       "      <td>earthy</td>\n",
       "      <td>0.007836</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>happy</td>\n",
       "      <td>0.006316</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>64</th>\n",
       "      <td>orange</td>\n",
       "      <td>0.005406</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>tingly</td>\n",
       "      <td>0.005087</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>uplifted</td>\n",
       "      <td>0.005047</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>euphoric</td>\n",
       "      <td>0.005021</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>71</th>\n",
       "      <td>pungent</td>\n",
       "      <td>0.004890</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>giggly</td>\n",
       "      <td>0.004603</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54</th>\n",
       "      <td>grape</td>\n",
       "      <td>0.004496</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>dry mouth</td>\n",
       "      <td>0.004289</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>sleepy</td>\n",
       "      <td>0.004022</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>dry eyes</td>\n",
       "      <td>0.003925</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>creative</td>\n",
       "      <td>0.003666</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>74</th>\n",
       "      <td>skunk</td>\n",
       "      <td>0.003589</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>58</th>\n",
       "      <td>lemon</td>\n",
       "      <td>0.003453</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>relaxed</td>\n",
       "      <td>0.002917</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>focused</td>\n",
       "      <td>0.002786</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>68</th>\n",
       "      <td>pine</td>\n",
       "      <td>0.002765</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>berry</td>\n",
       "      <td>0.002744</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>77</th>\n",
       "      <td>sweet</td>\n",
       "      <td>0.002073</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>talkative</td>\n",
       "      <td>0.001963</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>60</th>\n",
       "      <td>mango</td>\n",
       "      <td>0.001947</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>indica</td>\n",
       "      <td>0.001850</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>82</th>\n",
       "      <td>tropical</td>\n",
       "      <td>0.001629</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>energetic</td>\n",
       "      <td>0.001596</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>aroused</td>\n",
       "      <td>0.001326</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>blueberry</td>\n",
       "      <td>0.001136</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>55</th>\n",
       "      <td>grapefruit</td>\n",
       "      <td>0.001033</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>67</th>\n",
       "      <td>pepper</td>\n",
       "      <td>0.000974</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52</th>\n",
       "      <td>flowery</td>\n",
       "      <td>0.000926</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>62</th>\n",
       "      <td>mint</td>\n",
       "      <td>0.000874</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>85</th>\n",
       "      <td>woody</td>\n",
       "      <td>0.000790</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>sativa</td>\n",
       "      <td>0.000777</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>paranoid</td>\n",
       "      <td>0.000741</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75</th>\n",
       "      <td>spicy/herbal</td>\n",
       "      <td>0.000731</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>migraines</td>\n",
       "      <td>0.000567</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>anxiety</td>\n",
       "      <td>0.000524</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>anxious</td>\n",
       "      <td>0.000517</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>depression</td>\n",
       "      <td>0.000451</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>headache</td>\n",
       "      <td>0.000344</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>dizzy</td>\n",
       "      <td>0.000287</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>83</th>\n",
       "      <td>vanilla</td>\n",
       "      <td>0.000250</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>73</th>\n",
       "      <td>sage</td>\n",
       "      <td>0.000248</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53</th>\n",
       "      <td>fruit</td>\n",
       "      <td>0.000192</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>63</th>\n",
       "      <td>nutty</td>\n",
       "      <td>0.000177</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>chemical</td>\n",
       "      <td>0.000163</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>81</th>\n",
       "      <td>tree</td>\n",
       "      <td>0.000147</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>56</th>\n",
       "      <td>honey</td>\n",
       "      <td>0.000142</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>70</th>\n",
       "      <td>plum</td>\n",
       "      <td>0.000072</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>76</th>\n",
       "      <td>strawberry</td>\n",
       "      <td>0.000065</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>78</th>\n",
       "      <td>tar</td>\n",
       "      <td>0.000060</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>61</th>\n",
       "      <td>menthol</td>\n",
       "      <td>0.000057</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>69</th>\n",
       "      <td>pineapple</td>\n",
       "      <td>0.000054</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>ammonia</td>\n",
       "      <td>0.000053</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>79</th>\n",
       "      <td>tea</td>\n",
       "      <td>0.000052</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>72</th>\n",
       "      <td>rose</td>\n",
       "      <td>0.000050</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>coffee</td>\n",
       "      <td>0.000037</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>57</th>\n",
       "      <td>lavender</td>\n",
       "      <td>0.000033</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>84</th>\n",
       "      <td>violet</td>\n",
       "      <td>0.000030</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>butter</td>\n",
       "      <td>0.000022</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>apple</td>\n",
       "      <td>0.000021</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>apricot</td>\n",
       "      <td>0.000018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>chestnut</td>\n",
       "      <td>0.000008</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>80</th>\n",
       "      <td>tobacco</td>\n",
       "      <td>0.000006</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>blue cheese</td>\n",
       "      <td>0.000004</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>66</th>\n",
       "      <td>pear</td>\n",
       "      <td>0.000003</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>65</th>\n",
       "      <td>peach</td>\n",
       "      <td>0.000001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>pain</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>stress</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>fatigue</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>eye pressure</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>arthritis</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>seizures</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>epilepsy</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>spasticity</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        features     score\n",
       "5         hybrid  0.264681\n",
       "0          lsa_0  0.108502\n",
       "59          lime  0.104602\n",
       "2          lsa_2  0.103441\n",
       "4          lsa_4  0.072582\n",
       "3          lsa_3  0.069180\n",
       "48        citrus  0.068155\n",
       "1          lsa_1  0.057349\n",
       "45        cheese  0.025364\n",
       "50        diesel  0.009589\n",
       "26        hungry  0.008675\n",
       "51        earthy  0.007836\n",
       "24         happy  0.006316\n",
       "64        orange  0.005406\n",
       "36        tingly  0.005087\n",
       "37      uplifted  0.005047\n",
       "19      euphoric  0.005021\n",
       "71       pungent  0.004890\n",
       "23        giggly  0.004603\n",
       "54         grape  0.004496\n",
       "16     dry mouth  0.004289\n",
       "32        sleepy  0.004022\n",
       "15      dry eyes  0.003925\n",
       "12      creative  0.003666\n",
       "74         skunk  0.003589\n",
       "58         lemon  0.003453\n",
       "30       relaxed  0.002917\n",
       "22       focused  0.002786\n",
       "68          pine  0.002765\n",
       "41         berry  0.002744\n",
       "77         sweet  0.002073\n",
       "35     talkative  0.001963\n",
       "60         mango  0.001947\n",
       "6         indica  0.001850\n",
       "82      tropical  0.001629\n",
       "17     energetic  0.001596\n",
       "10       aroused  0.001326\n",
       "43     blueberry  0.001136\n",
       "55    grapefruit  0.001033\n",
       "67        pepper  0.000974\n",
       "52       flowery  0.000926\n",
       "62          mint  0.000874\n",
       "85         woody  0.000790\n",
       "7         sativa  0.000777\n",
       "29      paranoid  0.000741\n",
       "75  spicy/herbal  0.000731\n",
       "27     migraines  0.000567\n",
       "8        anxiety  0.000524\n",
       "9        anxious  0.000517\n",
       "13    depression  0.000451\n",
       "25      headache  0.000344\n",
       "14         dizzy  0.000287\n",
       "83       vanilla  0.000250\n",
       "73          sage  0.000248\n",
       "53         fruit  0.000192\n",
       "63         nutty  0.000177\n",
       "46      chemical  0.000163\n",
       "81          tree  0.000147\n",
       "56         honey  0.000142\n",
       "70          plum  0.000072\n",
       "76    strawberry  0.000065\n",
       "78           tar  0.000060\n",
       "61       menthol  0.000057\n",
       "69     pineapple  0.000054\n",
       "38       ammonia  0.000053\n",
       "79           tea  0.000052\n",
       "72          rose  0.000050\n",
       "49        coffee  0.000037\n",
       "57      lavender  0.000033\n",
       "84        violet  0.000030\n",
       "44        butter  0.000022\n",
       "39         apple  0.000021\n",
       "40       apricot  0.000018\n",
       "47      chestnut  0.000008\n",
       "80       tobacco  0.000006\n",
       "42   blue cheese  0.000004\n",
       "66          pear  0.000003\n",
       "65         peach  0.000001\n",
       "28          pain  0.000000\n",
       "34        stress  0.000000\n",
       "21       fatigue  0.000000\n",
       "20  eye pressure  0.000000\n",
       "11     arthritis  0.000000\n",
       "31      seizures  0.000000\n",
       "18      epilepsy  0.000000\n",
       "33    spasticity  0.000000"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.set_option('display.max_rows', df_feat_ranked.shape[0]+1)\n",
    "df_feat_ranked"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/louispandu/anaconda3/lib/python3.10/site-packages/sklearn/feature_selection/_from_model.py:357: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  self.estimator_.fit(X, y, **fit_params)\n"
     ]
    }
   ],
   "source": [
    "selector = SelectFromModel(rfreg).fit(X_train1, y_train1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1.08021700e-01, 6.14358962e-02, 1.05799928e-01, 6.35802612e-02,\n",
       "       7.21500456e-02, 2.65068417e-01, 1.85869543e-03, 7.17812528e-04,\n",
       "       2.03000390e-04, 4.51363541e-04, 1.40625070e-03, 0.00000000e+00,\n",
       "       3.17013019e-03, 2.52746028e-04, 2.75137036e-04, 3.88199774e-03,\n",
       "       4.97150327e-03, 1.80925687e-03, 0.00000000e+00, 5.45351006e-03,\n",
       "       0.00000000e+00, 0.00000000e+00, 2.31102319e-03, 3.98299998e-03,\n",
       "       5.83015517e-03, 4.17573128e-04, 8.38263221e-03, 5.23119690e-04,\n",
       "       0.00000000e+00, 5.79753695e-04, 3.67874475e-03, 0.00000000e+00,\n",
       "       4.52755972e-03, 0.00000000e+00, 0.00000000e+00, 1.76968049e-03,\n",
       "       4.81986496e-03, 4.96164713e-03, 1.09329686e-04, 2.73818457e-05,\n",
       "       1.59081087e-05, 3.06673960e-03, 2.86389508e-06, 1.02081569e-03,\n",
       "       2.32188663e-05, 2.51836777e-02, 1.28844816e-04, 1.58027224e-05,\n",
       "       6.79136960e-02, 3.85688906e-05, 9.76822847e-03, 6.98176918e-03,\n",
       "       1.00753032e-03, 2.81959254e-04, 4.02790309e-03, 1.13544716e-03,\n",
       "       1.77338172e-04, 3.52568893e-05, 3.47802407e-03, 1.04671273e-01,\n",
       "       2.95647435e-03, 6.07277042e-05, 9.34935221e-04, 2.29402260e-04,\n",
       "       5.08090624e-03, 1.56616799e-06, 2.82344728e-06, 1.27615142e-03,\n",
       "       2.92400265e-03, 7.40879190e-05, 1.00027903e-04, 5.15875787e-03,\n",
       "       4.99419486e-05, 2.78208866e-04, 3.65181216e-03, 6.60103017e-04,\n",
       "       6.69648266e-05, 1.99668636e-03, 6.65100125e-05, 4.58859597e-05,\n",
       "       5.78909830e-06, 1.68567688e-04, 1.65780792e-03, 2.19887387e-04,\n",
       "       2.27025290e-05, 9.05286158e-04])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "selector.estimator_.feature_importances_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.011627906976744186"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "selector.threshold_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "mask = selector.get_support()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ True,  True,  True,  True,  True,  True, False, False, False,\n",
       "       False, False, False, False, False, False, False, False, False,\n",
       "       False, False, False, False, False, False, False, False, False,\n",
       "       False, False, False, False, False, False, False, False, False,\n",
       "       False, False, False, False, False, False, False, False, False,\n",
       "        True, False, False,  True, False, False, False, False, False,\n",
       "       False, False, False, False, False,  True, False, False, False,\n",
       "       False, False, False, False, False, False, False, False, False,\n",
       "       False, False, False, False, False, False, False, False, False,\n",
       "       False, False, False, False, False])"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "selected_features = X.columns[mask]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>lsa_0</th>\n",
       "      <th>lsa_1</th>\n",
       "      <th>lsa_2</th>\n",
       "      <th>lsa_3</th>\n",
       "      <th>lsa_4</th>\n",
       "      <th>hybrid</th>\n",
       "      <th>cheese</th>\n",
       "      <th>citrus</th>\n",
       "      <th>lime</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.341025</td>\n",
       "      <td>0.182753</td>\n",
       "      <td>0.008214</td>\n",
       "      <td>0.140406</td>\n",
       "      <td>-0.156943</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.232158</td>\n",
       "      <td>-0.045496</td>\n",
       "      <td>0.187131</td>\n",
       "      <td>-0.000936</td>\n",
       "      <td>0.018518</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.238648</td>\n",
       "      <td>-0.048758</td>\n",
       "      <td>-0.107398</td>\n",
       "      <td>-0.067096</td>\n",
       "      <td>-0.006558</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.401841</td>\n",
       "      <td>-0.062527</td>\n",
       "      <td>-0.018128</td>\n",
       "      <td>-0.104475</td>\n",
       "      <td>0.009215</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.260672</td>\n",
       "      <td>-0.019644</td>\n",
       "      <td>0.215790</td>\n",
       "      <td>-0.106098</td>\n",
       "      <td>0.058930</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>74995</th>\n",
       "      <td>0.270141</td>\n",
       "      <td>-0.004631</td>\n",
       "      <td>-0.151272</td>\n",
       "      <td>0.035538</td>\n",
       "      <td>0.083641</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>74996</th>\n",
       "      <td>0.270141</td>\n",
       "      <td>-0.004631</td>\n",
       "      <td>-0.151272</td>\n",
       "      <td>0.035538</td>\n",
       "      <td>0.083641</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>74997</th>\n",
       "      <td>0.270141</td>\n",
       "      <td>-0.004631</td>\n",
       "      <td>-0.151272</td>\n",
       "      <td>0.035538</td>\n",
       "      <td>0.083641</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>74998</th>\n",
       "      <td>0.270141</td>\n",
       "      <td>-0.004631</td>\n",
       "      <td>-0.151272</td>\n",
       "      <td>0.035538</td>\n",
       "      <td>0.083641</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>74999</th>\n",
       "      <td>0.270141</td>\n",
       "      <td>-0.004631</td>\n",
       "      <td>-0.151272</td>\n",
       "      <td>0.035538</td>\n",
       "      <td>0.083641</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>75000 rows × 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          lsa_0     lsa_1     lsa_2     lsa_3     lsa_4  hybrid  cheese  \\\n",
       "0      0.341025  0.182753  0.008214  0.140406 -0.156943       1       0   \n",
       "1      0.232158 -0.045496  0.187131 -0.000936  0.018518       1       1   \n",
       "2      0.238648 -0.048758 -0.107398 -0.067096 -0.006558       1       0   \n",
       "3      0.401841 -0.062527 -0.018128 -0.104475  0.009215       1       0   \n",
       "4      0.260672 -0.019644  0.215790 -0.106098  0.058930       1       0   \n",
       "...         ...       ...       ...       ...       ...     ...     ...   \n",
       "74995  0.270141 -0.004631 -0.151272  0.035538  0.083641       0       1   \n",
       "74996  0.270141 -0.004631 -0.151272  0.035538  0.083641       0       1   \n",
       "74997  0.270141 -0.004631 -0.151272  0.035538  0.083641       0       1   \n",
       "74998  0.270141 -0.004631 -0.151272  0.035538  0.083641       0       1   \n",
       "74999  0.270141 -0.004631 -0.151272  0.035538  0.083641       0       1   \n",
       "\n",
       "       citrus  lime  \n",
       "0           0     0  \n",
       "1           0     0  \n",
       "2           0     0  \n",
       "3           0     0  \n",
       "4           0     0  \n",
       "...       ...   ...  \n",
       "74995       1     1  \n",
       "74996       1     1  \n",
       "74997       1     1  \n",
       "74998       1     1  \n",
       "74999       1     1  \n",
       "\n",
       "[75000 rows x 9 columns]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "selected_X = df_rf[selected_features]\n",
    "selected_X"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train test split (after Feature Selection)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['selected_X_rf_lsa_elbow_thcv.pkl']"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import joblib\n",
    "\n",
    "joblib.dump(selector, \"selector_rf_lsa_elbow_thcv.pkl\")\n",
    "joblib.dump(selected_X, \"selected_X_rf_lsa_elbow_thcv.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(selected_X, y, random_state=1, test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train1, X_val, y_train1, y_val = train_test_split(X_train, y_train, random_state=1, test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/ns/m5pnr0211w91v02hpv22958m0000gn/T/ipykernel_3199/3758305.py:1: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  rfreg.fit(X_train1, y_train1)\n"
     ]
    }
   ],
   "source": [
    "rfreg.fit(X_train1, y_train1)\n",
    "y_pred_rfreg = rfreg.predict(X_val)\n",
    "y_pred_rfreg_r2 = rfreg.predict(X_train1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.013138237782703385"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mean_absolute_error(y_val, y_pred_rfreg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0023324836100977755"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mean_squared_error(y_val, y_pred_rfreg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.048295792881966185"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mean_squared_error(y_val, y_pred_rfreg, squared = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9873896427729143"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#train\n",
    "r2_score(y_train1, y_pred_rfreg_r2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9810266834473702"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#val\n",
    "r2_score(y_val, y_pred_rfreg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hyperparameter Tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "parameters = { 'max_depth': [None, 10, 50, 100],\n",
    "              'max_features': ['auto', 'sqrt'],\n",
    "              'min_samples_leaf': [1, 2, 4],\n",
    "              'min_samples_split': [2, 5, 10],\n",
    "              'n_estimators': [100, 300, 500]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "rscv = RandomizedSearchCV(rfreg,  \n",
    "                     parameters,   \n",
    "                     cv=5, \n",
    "                     scoring='neg_mean_absolute_error',\n",
    "                     n_jobs= -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/louispandu/anaconda3/lib/python3.10/site-packages/sklearn/model_selection/_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/Users/louispandu/anaconda3/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
      "  warn(\n",
      "/Users/louispandu/anaconda3/lib/python3.10/site-packages/sklearn/model_selection/_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/Users/louispandu/anaconda3/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
      "  warn(\n",
      "/Users/louispandu/anaconda3/lib/python3.10/site-packages/sklearn/model_selection/_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/Users/louispandu/anaconda3/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
      "  warn(\n",
      "/Users/louispandu/anaconda3/lib/python3.10/site-packages/sklearn/model_selection/_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/Users/louispandu/anaconda3/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
      "  warn(\n",
      "/Users/louispandu/anaconda3/lib/python3.10/site-packages/sklearn/model_selection/_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/Users/louispandu/anaconda3/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
      "  warn(\n",
      "/Users/louispandu/anaconda3/lib/python3.10/site-packages/sklearn/model_selection/_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/Users/louispandu/anaconda3/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
      "  warn(\n",
      "/Users/louispandu/anaconda3/lib/python3.10/site-packages/sklearn/model_selection/_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/Users/louispandu/anaconda3/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
      "  warn(\n",
      "/Users/louispandu/anaconda3/lib/python3.10/site-packages/sklearn/model_selection/_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/Users/louispandu/anaconda3/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
      "  warn(\n",
      "/Users/louispandu/anaconda3/lib/python3.10/site-packages/sklearn/model_selection/_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/Users/louispandu/anaconda3/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
      "  warn(\n",
      "/Users/louispandu/anaconda3/lib/python3.10/site-packages/sklearn/model_selection/_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/Users/louispandu/anaconda3/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
      "  warn(\n",
      "/Users/louispandu/anaconda3/lib/python3.10/site-packages/sklearn/model_selection/_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/Users/louispandu/anaconda3/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
      "  warn(\n",
      "/Users/louispandu/anaconda3/lib/python3.10/site-packages/sklearn/model_selection/_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/Users/louispandu/anaconda3/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
      "  warn(\n",
      "/Users/louispandu/anaconda3/lib/python3.10/site-packages/sklearn/model_selection/_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/Users/louispandu/anaconda3/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
      "  warn(\n",
      "/Users/louispandu/anaconda3/lib/python3.10/site-packages/sklearn/model_selection/_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/Users/louispandu/anaconda3/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
      "  warn(\n",
      "/Users/louispandu/anaconda3/lib/python3.10/site-packages/sklearn/model_selection/_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/Users/louispandu/anaconda3/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
      "  warn(\n",
      "/Users/louispandu/anaconda3/lib/python3.10/site-packages/sklearn/model_selection/_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/Users/louispandu/anaconda3/lib/python3.10/site-packages/sklearn/model_selection/_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/Users/louispandu/anaconda3/lib/python3.10/site-packages/sklearn/model_selection/_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/Users/louispandu/anaconda3/lib/python3.10/site-packages/sklearn/model_selection/_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/Users/louispandu/anaconda3/lib/python3.10/site-packages/sklearn/model_selection/_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/Users/louispandu/anaconda3/lib/python3.10/site-packages/sklearn/model_selection/_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/Users/louispandu/anaconda3/lib/python3.10/site-packages/sklearn/model_selection/_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/Users/louispandu/anaconda3/lib/python3.10/site-packages/sklearn/model_selection/_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/Users/louispandu/anaconda3/lib/python3.10/site-packages/sklearn/model_selection/_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/Users/louispandu/anaconda3/lib/python3.10/site-packages/sklearn/model_selection/_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/Users/louispandu/anaconda3/lib/python3.10/site-packages/sklearn/model_selection/_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/Users/louispandu/anaconda3/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
      "  warn(\n",
      "/Users/louispandu/anaconda3/lib/python3.10/site-packages/sklearn/model_selection/_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/Users/louispandu/anaconda3/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
      "  warn(\n",
      "/Users/louispandu/anaconda3/lib/python3.10/site-packages/sklearn/model_selection/_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/Users/louispandu/anaconda3/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
      "  warn(\n",
      "/Users/louispandu/anaconda3/lib/python3.10/site-packages/sklearn/model_selection/_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/Users/louispandu/anaconda3/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
      "  warn(\n",
      "/Users/louispandu/anaconda3/lib/python3.10/site-packages/sklearn/model_selection/_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/Users/louispandu/anaconda3/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
      "  warn(\n",
      "/Users/louispandu/anaconda3/lib/python3.10/site-packages/sklearn/model_selection/_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/Users/louispandu/anaconda3/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
      "  warn(\n",
      "/Users/louispandu/anaconda3/lib/python3.10/site-packages/sklearn/model_selection/_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/Users/louispandu/anaconda3/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
      "  warn(\n",
      "/Users/louispandu/anaconda3/lib/python3.10/site-packages/sklearn/model_selection/_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/Users/louispandu/anaconda3/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
      "  warn(\n",
      "/Users/louispandu/anaconda3/lib/python3.10/site-packages/sklearn/model_selection/_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/Users/louispandu/anaconda3/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
      "  warn(\n",
      "/Users/louispandu/anaconda3/lib/python3.10/site-packages/sklearn/model_selection/_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/Users/louispandu/anaconda3/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
      "  warn(\n",
      "/Users/louispandu/anaconda3/lib/python3.10/site-packages/sklearn/model_selection/_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/Users/louispandu/anaconda3/lib/python3.10/site-packages/sklearn/model_selection/_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/Users/louispandu/anaconda3/lib/python3.10/site-packages/sklearn/model_selection/_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/Users/louispandu/anaconda3/lib/python3.10/site-packages/sklearn/model_selection/_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/Users/louispandu/anaconda3/lib/python3.10/site-packages/sklearn/model_selection/_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/Users/louispandu/anaconda3/lib/python3.10/site-packages/sklearn/model_selection/_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/Users/louispandu/anaconda3/lib/python3.10/site-packages/sklearn/model_selection/_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/Users/louispandu/anaconda3/lib/python3.10/site-packages/sklearn/model_selection/_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/Users/louispandu/anaconda3/lib/python3.10/site-packages/sklearn/model_selection/_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/Users/louispandu/anaconda3/lib/python3.10/site-packages/sklearn/model_selection/_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/Users/louispandu/anaconda3/lib/python3.10/site-packages/sklearn/model_selection/_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/Users/louispandu/anaconda3/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
      "  warn(\n",
      "/Users/louispandu/anaconda3/lib/python3.10/site-packages/sklearn/model_selection/_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/Users/louispandu/anaconda3/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
      "  warn(\n",
      "/Users/louispandu/anaconda3/lib/python3.10/site-packages/sklearn/model_selection/_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/Users/louispandu/anaconda3/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
      "  warn(\n",
      "/Users/louispandu/anaconda3/lib/python3.10/site-packages/sklearn/model_selection/_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/Users/louispandu/anaconda3/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
      "  warn(\n",
      "/Users/louispandu/anaconda3/lib/python3.10/site-packages/sklearn/model_selection/_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/Users/louispandu/anaconda3/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
      "  warn(\n",
      "/Users/louispandu/anaconda3/lib/python3.10/site-packages/sklearn/model_selection/_search.py:909: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  self.best_estimator_.fit(X, y, **fit_params)\n",
      "/Users/louispandu/anaconda3/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
      "  warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-2 {color: black;background-color: white;}#sk-container-id-2 pre{padding: 0;}#sk-container-id-2 div.sk-toggleable {background-color: white;}#sk-container-id-2 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-2 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-2 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-2 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-2 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-2 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-2 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-2 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-2 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-2 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-2 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-2 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-2 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-2 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-2 div.sk-item {position: relative;z-index: 1;}#sk-container-id-2 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-2 div.sk-item::before, #sk-container-id-2 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-2 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-2 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-2 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-2 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-2 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-2 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-2 div.sk-label-container {text-align: center;}#sk-container-id-2 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-2 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-2\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>RandomizedSearchCV(cv=5, estimator=RandomForestRegressor(n_jobs=-1), n_jobs=-1,\n",
       "                   param_distributions={&#x27;max_depth&#x27;: [None, 10, 50, 100],\n",
       "                                        &#x27;max_features&#x27;: [&#x27;auto&#x27;, &#x27;sqrt&#x27;],\n",
       "                                        &#x27;min_samples_leaf&#x27;: [1, 2, 4],\n",
       "                                        &#x27;min_samples_split&#x27;: [2, 5, 10],\n",
       "                                        &#x27;n_estimators&#x27;: [100, 300, 500]},\n",
       "                   scoring=&#x27;neg_mean_absolute_error&#x27;)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" ><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">RandomizedSearchCV</label><div class=\"sk-toggleable__content\"><pre>RandomizedSearchCV(cv=5, estimator=RandomForestRegressor(n_jobs=-1), n_jobs=-1,\n",
       "                   param_distributions={&#x27;max_depth&#x27;: [None, 10, 50, 100],\n",
       "                                        &#x27;max_features&#x27;: [&#x27;auto&#x27;, &#x27;sqrt&#x27;],\n",
       "                                        &#x27;min_samples_leaf&#x27;: [1, 2, 4],\n",
       "                                        &#x27;min_samples_split&#x27;: [2, 5, 10],\n",
       "                                        &#x27;n_estimators&#x27;: [100, 300, 500]},\n",
       "                   scoring=&#x27;neg_mean_absolute_error&#x27;)</pre></div></div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-3\" type=\"checkbox\" ><label for=\"sk-estimator-id-3\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">estimator: RandomForestRegressor</label><div class=\"sk-toggleable__content\"><pre>RandomForestRegressor(n_jobs=-1)</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-4\" type=\"checkbox\" ><label for=\"sk-estimator-id-4\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">RandomForestRegressor</label><div class=\"sk-toggleable__content\"><pre>RandomForestRegressor(n_jobs=-1)</pre></div></div></div></div></div></div></div></div></div></div>"
      ],
      "text/plain": [
       "RandomizedSearchCV(cv=5, estimator=RandomForestRegressor(n_jobs=-1), n_jobs=-1,\n",
       "                   param_distributions={'max_depth': [None, 10, 50, 100],\n",
       "                                        'max_features': ['auto', 'sqrt'],\n",
       "                                        'min_samples_leaf': [1, 2, 4],\n",
       "                                        'min_samples_split': [2, 5, 10],\n",
       "                                        'n_estimators': [100, 300, 500]},\n",
       "                   scoring='neg_mean_absolute_error')"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rscv.fit(X_train1, y_train1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'n_estimators': 100,\n",
       " 'min_samples_split': 10,\n",
       " 'min_samples_leaf': 1,\n",
       " 'max_features': 'auto',\n",
       " 'max_depth': None}"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rscv.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['rscv_rf_lsa_elbow_best_params_thcv.pkl']"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "joblib.dump(rscv, \"rscv_rf_lsa_elbow_thcv.pkl\")\n",
    "joblib.dump(rscv.best_params_, \"rscv_rf_lsa_elbow_best_params_thcv.pkl\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "RF (after Hyperparameter Tuning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/ns/m5pnr0211w91v02hpv22958m0000gn/T/ipykernel_3199/1145761103.py:2: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  rfreg_ht.fit(X_train1, y_train1)\n",
      "/Users/louispandu/anaconda3/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
      "  warn(\n"
     ]
    }
   ],
   "source": [
    "rfreg_ht = RandomForestRegressor(n_estimators = 100, min_samples_split = 10, max_features = 'auto', min_samples_leaf = 1, max_depth = None)\n",
    "rfreg_ht.fit(X_train1, y_train1)\n",
    "y_pred_rfreg = rfreg_ht.predict(X_val)\n",
    "y_pred_rfreg_r2 = rfreg_ht.predict(X_train1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.014888978415889901"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mean_absolute_error(y_val, y_pred_rfreg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0023903205527583847"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mean_squared_error(y_val, y_pred_rfreg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.04889090460155533"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mean_squared_error(y_val, y_pred_rfreg, squared = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9864095951399218"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#train\n",
    "r2_score(y_train1, y_pred_rfreg_r2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.980556215566359"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#val\n",
    "r2_score(y_val, y_pred_rfreg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Residual plots after Hyperparameter Tuning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Predicting model on the test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_rfreg_test = rfreg_ht.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['y_test_rfreg_lsa_elbow_thcv.pkl']"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "joblib.dump(y_pred_rfreg_test, \"y_pred_rfreg_test_lsa_elbow_thcv.pkl\")\n",
    "joblib.dump(y_test, \"y_test_rfreg_lsa_elbow_thcv.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.015543215330813272"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mean_absolute_error(y_test, y_pred_rfreg_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.002669253424522633"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mean_squared_error(y_test, y_pred_rfreg_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.051664818053706846"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mean_squared_error(y_test, y_pred_rfreg_test, squared = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9779847843445233"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "r2_score(y_test, y_pred_rfreg_test)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Error analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 800x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# assume y_pred is a numpy array and y_true is a pandas dataframe\n",
    "fig, ax = plt.subplots(figsize=(8, 6))\n",
    "\n",
    "column = \"X..THCV\"  # specify the target variable name\n",
    "ax.hist(y_pred_rfreg_test, alpha=0.5, label='y_pred', bins=20)\n",
    "ax.hist(y_test[column], alpha=0.5, label='y_true', bins=20)\n",
    "ax.legend(loc='upper right')\n",
    "ax.set_title(column)\n",
    "\n",
    "plt.show()\n",
    "plt.savefig('error_hist_rf_lsa_elbow_thcv.png')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pearson R"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pearson correlation coefficient: 0.989\n",
      "P-value: 0.000\n"
     ]
    }
   ],
   "source": [
    "corr_coef, p_value = pearsonr(y_pred_rfreg_test.flatten(), y_test.values.ravel())\n",
    "\n",
    "print(f\"Pearson correlation coefficient: {corr_coef:.3f}\")\n",
    "print(f\"P-value: {p_value:.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Axes: >"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "corr_matrix = y_test.corr()\n",
    "sns.heatmap(corr_matrix, annot=True, cmap='coolwarm', center=0)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
