{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn import preprocessing\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.neural_network import MLPRegressor\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "from sklearn.metrics import r2_score\n",
    "from scipy.stats import pearsonr\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.feature_selection import SelectFromModel\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compiling complete dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_rf = pd.read_csv(\"df_terpi_tfidf.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['index',\n",
       " 'tfidf_0',\n",
       " 'tfidf_1',\n",
       " 'tfidf_2',\n",
       " 'tfidf_3',\n",
       " 'tfidf_4',\n",
       " 'tfidf_5',\n",
       " 'tfidf_6',\n",
       " 'tfidf_7',\n",
       " 'tfidf_8',\n",
       " 'tfidf_9',\n",
       " 'tfidf_10',\n",
       " 'tfidf_11',\n",
       " 'tfidf_12',\n",
       " 'tfidf_13',\n",
       " 'tfidf_14',\n",
       " 'tfidf_15',\n",
       " 'tfidf_16',\n",
       " 'tfidf_17',\n",
       " 'tfidf_18',\n",
       " 'tfidf_19',\n",
       " 'tfidf_20',\n",
       " 'tfidf_21',\n",
       " 'tfidf_22',\n",
       " 'tfidf_23',\n",
       " 'tfidf_24',\n",
       " 'tfidf_25',\n",
       " 'tfidf_26',\n",
       " 'tfidf_27',\n",
       " 'tfidf_28',\n",
       " 'tfidf_29',\n",
       " 'tfidf_30',\n",
       " 'tfidf_31',\n",
       " 'tfidf_32',\n",
       " 'tfidf_33',\n",
       " 'tfidf_34',\n",
       " 'tfidf_35',\n",
       " 'tfidf_36',\n",
       " 'tfidf_37',\n",
       " 'tfidf_38',\n",
       " 'tfidf_39',\n",
       " 'tfidf_40',\n",
       " 'tfidf_41',\n",
       " 'tfidf_42',\n",
       " 'tfidf_43',\n",
       " 'tfidf_44',\n",
       " 'tfidf_45',\n",
       " 'tfidf_46',\n",
       " 'tfidf_47',\n",
       " 'tfidf_48',\n",
       " 'tfidf_49',\n",
       " 'tfidf_50',\n",
       " 'tfidf_51',\n",
       " 'tfidf_52',\n",
       " 'tfidf_53',\n",
       " 'tfidf_54',\n",
       " 'tfidf_55',\n",
       " 'tfidf_56',\n",
       " 'tfidf_57',\n",
       " 'tfidf_58',\n",
       " 'tfidf_59',\n",
       " 'tfidf_60',\n",
       " 'tfidf_61',\n",
       " 'tfidf_62',\n",
       " 'tfidf_63',\n",
       " 'tfidf_64',\n",
       " 'tfidf_65',\n",
       " 'tfidf_66',\n",
       " 'tfidf_67',\n",
       " 'tfidf_68',\n",
       " 'tfidf_69',\n",
       " 'tfidf_70',\n",
       " 'tfidf_71',\n",
       " 'tfidf_72',\n",
       " 'tfidf_73',\n",
       " 'tfidf_74',\n",
       " 'tfidf_75',\n",
       " 'tfidf_76',\n",
       " 'tfidf_77',\n",
       " 'tfidf_78',\n",
       " 'tfidf_79',\n",
       " 'tfidf_80',\n",
       " 'tfidf_81',\n",
       " 'tfidf_82',\n",
       " 'tfidf_83',\n",
       " 'tfidf_84',\n",
       " 'tfidf_85',\n",
       " 'tfidf_86',\n",
       " 'tfidf_87',\n",
       " 'tfidf_88',\n",
       " 'tfidf_89',\n",
       " 'tfidf_90',\n",
       " 'tfidf_91',\n",
       " 'tfidf_92',\n",
       " 'tfidf_93',\n",
       " 'tfidf_94',\n",
       " 'tfidf_95',\n",
       " 'tfidf_96',\n",
       " 'tfidf_97',\n",
       " 'tfidf_98',\n",
       " 'tfidf_99',\n",
       " 'tfidf_100',\n",
       " 'tfidf_101',\n",
       " 'tfidf_102',\n",
       " 'tfidf_103',\n",
       " 'tfidf_104',\n",
       " 'tfidf_105',\n",
       " 'tfidf_106',\n",
       " 'tfidf_107',\n",
       " 'tfidf_108',\n",
       " 'tfidf_109',\n",
       " 'tfidf_110',\n",
       " 'tfidf_111',\n",
       " 'tfidf_112',\n",
       " 'tfidf_113',\n",
       " 'tfidf_114',\n",
       " 'tfidf_115',\n",
       " 'tfidf_116',\n",
       " 'tfidf_117',\n",
       " 'tfidf_118',\n",
       " 'tfidf_119',\n",
       " 'tfidf_120',\n",
       " 'tfidf_121',\n",
       " 'tfidf_122',\n",
       " 'tfidf_123',\n",
       " 'tfidf_124',\n",
       " 'tfidf_125',\n",
       " 'tfidf_126',\n",
       " 'tfidf_127',\n",
       " 'tfidf_128',\n",
       " 'tfidf_129',\n",
       " 'tfidf_130',\n",
       " 'tfidf_131',\n",
       " 'tfidf_132',\n",
       " 'tfidf_133',\n",
       " 'tfidf_134',\n",
       " 'tfidf_135',\n",
       " 'tfidf_136',\n",
       " 'tfidf_137',\n",
       " 'tfidf_138',\n",
       " 'tfidf_139',\n",
       " 'tfidf_140',\n",
       " 'tfidf_141',\n",
       " 'tfidf_142',\n",
       " 'tfidf_143',\n",
       " 'tfidf_144',\n",
       " 'tfidf_145',\n",
       " 'tfidf_146',\n",
       " 'tfidf_147',\n",
       " 'tfidf_148',\n",
       " 'tfidf_149',\n",
       " 'tfidf_150',\n",
       " 'tfidf_151',\n",
       " 'tfidf_152',\n",
       " 'tfidf_153',\n",
       " 'tfidf_154',\n",
       " 'tfidf_155',\n",
       " 'tfidf_156',\n",
       " 'tfidf_157',\n",
       " 'tfidf_158',\n",
       " 'tfidf_159',\n",
       " 'tfidf_160',\n",
       " 'tfidf_161',\n",
       " 'tfidf_162',\n",
       " 'tfidf_163',\n",
       " 'tfidf_164',\n",
       " 'tfidf_165',\n",
       " 'tfidf_166',\n",
       " 'tfidf_167',\n",
       " 'tfidf_168',\n",
       " 'tfidf_169',\n",
       " 'tfidf_170',\n",
       " 'tfidf_171',\n",
       " 'tfidf_172',\n",
       " 'tfidf_173',\n",
       " 'tfidf_174',\n",
       " 'tfidf_175',\n",
       " 'tfidf_176',\n",
       " 'tfidf_177',\n",
       " 'tfidf_178',\n",
       " 'tfidf_179',\n",
       " 'tfidf_180',\n",
       " 'tfidf_181',\n",
       " 'tfidf_182',\n",
       " 'tfidf_183',\n",
       " 'tfidf_184',\n",
       " 'tfidf_185',\n",
       " 'tfidf_186',\n",
       " 'tfidf_187',\n",
       " 'tfidf_188',\n",
       " 'tfidf_189',\n",
       " 'tfidf_190',\n",
       " 'tfidf_191',\n",
       " 'tfidf_192',\n",
       " 'tfidf_193',\n",
       " 'tfidf_194',\n",
       " 'tfidf_195',\n",
       " 'tfidf_196',\n",
       " 'tfidf_197',\n",
       " 'tfidf_198',\n",
       " 'tfidf_199',\n",
       " 'tfidf_200',\n",
       " 'tfidf_201',\n",
       " 'tfidf_202',\n",
       " 'tfidf_203',\n",
       " 'tfidf_204',\n",
       " 'tfidf_205',\n",
       " 'tfidf_206',\n",
       " 'tfidf_207',\n",
       " 'tfidf_208',\n",
       " 'tfidf_209',\n",
       " 'tfidf_210',\n",
       " 'tfidf_211',\n",
       " 'tfidf_212',\n",
       " 'tfidf_213',\n",
       " 'tfidf_214',\n",
       " 'tfidf_215',\n",
       " 'tfidf_216',\n",
       " 'tfidf_217',\n",
       " 'tfidf_218',\n",
       " 'tfidf_219',\n",
       " 'tfidf_220',\n",
       " 'tfidf_221',\n",
       " 'tfidf_222',\n",
       " 'tfidf_223',\n",
       " 'tfidf_224',\n",
       " 'tfidf_225',\n",
       " 'tfidf_226',\n",
       " 'tfidf_227',\n",
       " 'tfidf_228',\n",
       " 'tfidf_229',\n",
       " 'tfidf_230',\n",
       " 'tfidf_231',\n",
       " 'tfidf_232',\n",
       " 'tfidf_233',\n",
       " 'tfidf_234',\n",
       " 'tfidf_235',\n",
       " 'tfidf_236',\n",
       " 'tfidf_237',\n",
       " 'tfidf_238',\n",
       " 'tfidf_239',\n",
       " 'tfidf_240',\n",
       " 'tfidf_241',\n",
       " 'tfidf_242',\n",
       " 'tfidf_243',\n",
       " 'tfidf_244',\n",
       " 'tfidf_245',\n",
       " 'tfidf_246',\n",
       " 'tfidf_247',\n",
       " 'tfidf_248',\n",
       " 'tfidf_249',\n",
       " 'tfidf_250',\n",
       " 'tfidf_251',\n",
       " 'tfidf_252',\n",
       " 'tfidf_253',\n",
       " 'tfidf_254',\n",
       " 'tfidf_255',\n",
       " 'tfidf_256',\n",
       " 'tfidf_257',\n",
       " 'tfidf_258',\n",
       " 'tfidf_259',\n",
       " 'tfidf_260',\n",
       " 'tfidf_261',\n",
       " 'tfidf_262',\n",
       " 'tfidf_263',\n",
       " 'tfidf_264',\n",
       " 'tfidf_265',\n",
       " 'tfidf_266',\n",
       " 'tfidf_267',\n",
       " 'tfidf_268',\n",
       " 'tfidf_269',\n",
       " 'tfidf_270',\n",
       " 'tfidf_271',\n",
       " 'tfidf_272',\n",
       " 'tfidf_273',\n",
       " 'tfidf_274',\n",
       " 'tfidf_275',\n",
       " 'tfidf_276',\n",
       " 'tfidf_277',\n",
       " 'tfidf_278',\n",
       " 'tfidf_279',\n",
       " 'tfidf_280',\n",
       " 'tfidf_281',\n",
       " 'tfidf_282',\n",
       " 'tfidf_283',\n",
       " 'tfidf_284',\n",
       " 'tfidf_285',\n",
       " 'tfidf_286',\n",
       " 'tfidf_287',\n",
       " 'tfidf_288',\n",
       " 'tfidf_289',\n",
       " 'tfidf_290',\n",
       " 'tfidf_291',\n",
       " 'tfidf_292',\n",
       " 'tfidf_293',\n",
       " 'tfidf_294',\n",
       " 'tfidf_295',\n",
       " 'tfidf_296',\n",
       " 'tfidf_297',\n",
       " 'tfidf_298',\n",
       " 'tfidf_299',\n",
       " 'tfidf_300',\n",
       " 'tfidf_301',\n",
       " 'tfidf_302',\n",
       " 'tfidf_303',\n",
       " 'tfidf_304',\n",
       " 'tfidf_305',\n",
       " 'tfidf_306',\n",
       " 'tfidf_307',\n",
       " 'tfidf_308',\n",
       " 'tfidf_309',\n",
       " 'tfidf_310',\n",
       " 'tfidf_311',\n",
       " 'tfidf_312',\n",
       " 'tfidf_313',\n",
       " 'tfidf_314',\n",
       " 'tfidf_315',\n",
       " 'tfidf_316',\n",
       " 'tfidf_317',\n",
       " 'tfidf_318',\n",
       " 'tfidf_319',\n",
       " 'tfidf_320',\n",
       " 'tfidf_321',\n",
       " 'tfidf_322',\n",
       " 'tfidf_323',\n",
       " 'tfidf_324',\n",
       " 'tfidf_325',\n",
       " 'tfidf_326',\n",
       " 'tfidf_327',\n",
       " 'tfidf_328',\n",
       " 'tfidf_329',\n",
       " 'tfidf_330',\n",
       " 'tfidf_331',\n",
       " 'tfidf_332',\n",
       " 'tfidf_333',\n",
       " 'tfidf_334',\n",
       " 'tfidf_335',\n",
       " 'tfidf_336',\n",
       " 'tfidf_337',\n",
       " 'tfidf_338',\n",
       " 'tfidf_339',\n",
       " 'tfidf_340',\n",
       " 'tfidf_341',\n",
       " 'tfidf_342',\n",
       " 'tfidf_343',\n",
       " 'tfidf_344',\n",
       " 'tfidf_345',\n",
       " 'tfidf_346',\n",
       " 'tfidf_347',\n",
       " 'tfidf_348',\n",
       " 'tfidf_349',\n",
       " 'tfidf_350',\n",
       " 'tfidf_351',\n",
       " 'tfidf_352',\n",
       " 'tfidf_353',\n",
       " 'tfidf_354',\n",
       " 'tfidf_355',\n",
       " 'tfidf_356',\n",
       " 'tfidf_357',\n",
       " 'tfidf_358',\n",
       " 'tfidf_359',\n",
       " 'tfidf_360',\n",
       " 'tfidf_361',\n",
       " 'tfidf_362',\n",
       " 'tfidf_363',\n",
       " 'tfidf_364',\n",
       " 'tfidf_365',\n",
       " 'tfidf_366',\n",
       " 'tfidf_367',\n",
       " 'tfidf_368',\n",
       " 'tfidf_369',\n",
       " 'tfidf_370',\n",
       " 'tfidf_371',\n",
       " 'tfidf_372',\n",
       " 'tfidf_373',\n",
       " 'tfidf_374',\n",
       " 'tfidf_375',\n",
       " 'tfidf_376',\n",
       " 'tfidf_377',\n",
       " 'tfidf_378',\n",
       " 'tfidf_379',\n",
       " 'tfidf_380',\n",
       " 'tfidf_381',\n",
       " 'tfidf_382',\n",
       " 'tfidf_383',\n",
       " 'tfidf_384',\n",
       " 'tfidf_385',\n",
       " 'tfidf_386',\n",
       " 'tfidf_387',\n",
       " 'hybrid',\n",
       " 'indica',\n",
       " 'sativa',\n",
       " 'anxiety',\n",
       " 'anxious',\n",
       " 'aroused',\n",
       " 'arthritis',\n",
       " 'creative',\n",
       " 'depression',\n",
       " 'dizzy',\n",
       " 'dry eyes',\n",
       " 'dry mouth',\n",
       " 'energetic',\n",
       " 'epilepsy',\n",
       " 'euphoric',\n",
       " 'eye pressure',\n",
       " 'fatigue',\n",
       " 'focused',\n",
       " 'giggly',\n",
       " 'happy',\n",
       " 'headache',\n",
       " 'hungry',\n",
       " 'migraines',\n",
       " 'pain',\n",
       " 'paranoid',\n",
       " 'relaxed',\n",
       " 'seizures',\n",
       " 'sleepy',\n",
       " 'spasticity',\n",
       " 'stress',\n",
       " 'talkative',\n",
       " 'tingly',\n",
       " 'uplifted',\n",
       " 'ammonia',\n",
       " 'apple',\n",
       " 'apricot',\n",
       " 'berry',\n",
       " 'blue cheese',\n",
       " 'blueberry',\n",
       " 'butter',\n",
       " 'cheese',\n",
       " 'chemical',\n",
       " 'chestnut',\n",
       " 'citrus',\n",
       " 'coffee',\n",
       " 'diesel',\n",
       " 'earthy',\n",
       " 'flowery',\n",
       " 'fruit',\n",
       " 'grape',\n",
       " 'grapefruit',\n",
       " 'honey',\n",
       " 'lavender',\n",
       " 'lemon',\n",
       " 'lime',\n",
       " 'mango',\n",
       " 'menthol',\n",
       " 'mint',\n",
       " 'nutty',\n",
       " 'orange',\n",
       " 'peach',\n",
       " 'pear',\n",
       " 'pepper',\n",
       " 'pine',\n",
       " 'pineapple',\n",
       " 'plum',\n",
       " 'pungent',\n",
       " 'rose',\n",
       " 'sage',\n",
       " 'skunk',\n",
       " 'spicy/herbal',\n",
       " 'strawberry',\n",
       " 'sweet',\n",
       " 'tar',\n",
       " 'tea',\n",
       " 'tobacco',\n",
       " 'tree',\n",
       " 'tropical',\n",
       " 'vanilla',\n",
       " 'violet',\n",
       " 'woody',\n",
       " 'X..Terpinolene']"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_rf.columns.to_list()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Splitting dependent and independent variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df_rf.drop(['index', 'X..Terpinolene'], axis = 1)\n",
    "y = df_rf[['X..Terpinolene']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plotting histograms on target variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       ...,\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.]])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_array = y.to_numpy()\n",
    "y_array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Axes: ylabel='Count'>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "sns.histplot(y, bins = 10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train test split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=1, test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train1, X_val, y_train1, y_val = train_test_split(X_train, y_train, random_state=1, test_size=0.25)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "RF modeling (before Feature selection and Hyperparameter Tuning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/ns/m5pnr0211w91v02hpv22958m0000gn/T/ipykernel_88675/350139188.py:2: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  rfreg.fit(X_train1, y_train1)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;background-color: white;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>RandomForestRegressor()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">RandomForestRegressor</label><div class=\"sk-toggleable__content\"><pre>RandomForestRegressor()</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "RandomForestRegressor()"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rfreg = RandomForestRegressor()\n",
    "rfreg.fit(X_train1, y_train1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_rfreg = rfreg.predict(X_val)\n",
    "y_pred_rfreg_r2 = rfreg.predict(X_train1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.02706776860735762"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mean_absolute_error(y_val, y_pred_rfreg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.006243786774765489"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mean_squared_error(y_val, y_pred_rfreg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.07901763584647094"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mean_squared_error(y_val, y_pred_rfreg, squared = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9899007446980245"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#train\n",
    "r2_score(y_train1, y_pred_rfreg_r2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9475210224473682"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#val\n",
    "r2_score(y_val, y_pred_rfreg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Residual plots for each target variable"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Feature Selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_feat = pd.DataFrame({\n",
    "    \"features\": X_train1.columns,\n",
    "    \"score\": rfreg.feature_importances_\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>features</th>\n",
       "      <th>score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>tfidf_0</td>\n",
       "      <td>0.001721</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>tfidf_1</td>\n",
       "      <td>0.001742</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>tfidf_2</td>\n",
       "      <td>0.000850</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>tfidf_3</td>\n",
       "      <td>0.001196</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>tfidf_4</td>\n",
       "      <td>0.001961</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>464</th>\n",
       "      <td>tree</td>\n",
       "      <td>0.000158</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>465</th>\n",
       "      <td>tropical</td>\n",
       "      <td>0.000476</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>466</th>\n",
       "      <td>vanilla</td>\n",
       "      <td>0.037302</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>467</th>\n",
       "      <td>violet</td>\n",
       "      <td>0.000015</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>468</th>\n",
       "      <td>woody</td>\n",
       "      <td>0.000405</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>469 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     features     score\n",
       "0     tfidf_0  0.001721\n",
       "1     tfidf_1  0.001742\n",
       "2     tfidf_2  0.000850\n",
       "3     tfidf_3  0.001196\n",
       "4     tfidf_4  0.001961\n",
       "..        ...       ...\n",
       "464      tree  0.000158\n",
       "465  tropical  0.000476\n",
       "466   vanilla  0.037302\n",
       "467    violet  0.000015\n",
       "468     woody  0.000405\n",
       "\n",
       "[469 rows x 2 columns]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_feat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_feat_ranked = df_feat.sort_values(\"score\", ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>features</th>\n",
       "      <th>score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>428</th>\n",
       "      <td>cheese</td>\n",
       "      <td>1.114134e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>389</th>\n",
       "      <td>indica</td>\n",
       "      <td>8.013183e-02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>466</th>\n",
       "      <td>vanilla</td>\n",
       "      <td>3.730248e-02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>388</th>\n",
       "      <td>hybrid</td>\n",
       "      <td>2.841362e-02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>168</th>\n",
       "      <td>tfidf_168</td>\n",
       "      <td>2.005386e-02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>433</th>\n",
       "      <td>diesel</td>\n",
       "      <td>1.730051e-02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>424</th>\n",
       "      <td>berry</td>\n",
       "      <td>1.681100e-02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>329</th>\n",
       "      <td>tfidf_329</td>\n",
       "      <td>1.597831e-02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>390</th>\n",
       "      <td>sativa</td>\n",
       "      <td>1.392520e-02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>253</th>\n",
       "      <td>tfidf_253</td>\n",
       "      <td>1.387822e-02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>441</th>\n",
       "      <td>lemon</td>\n",
       "      <td>1.356640e-02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>447</th>\n",
       "      <td>orange</td>\n",
       "      <td>1.355734e-02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>345</th>\n",
       "      <td>tfidf_345</td>\n",
       "      <td>1.333219e-02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>367</th>\n",
       "      <td>tfidf_367</td>\n",
       "      <td>1.322552e-02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>239</th>\n",
       "      <td>tfidf_239</td>\n",
       "      <td>1.267174e-02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>149</th>\n",
       "      <td>tfidf_149</td>\n",
       "      <td>1.199917e-02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>145</th>\n",
       "      <td>tfidf_145</td>\n",
       "      <td>1.148689e-02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>314</th>\n",
       "      <td>tfidf_314</td>\n",
       "      <td>1.028157e-02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>381</th>\n",
       "      <td>tfidf_381</td>\n",
       "      <td>9.192358e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>189</th>\n",
       "      <td>tfidf_189</td>\n",
       "      <td>9.161902e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>121</th>\n",
       "      <td>tfidf_121</td>\n",
       "      <td>8.764601e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>340</th>\n",
       "      <td>tfidf_340</td>\n",
       "      <td>8.742274e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>366</th>\n",
       "      <td>tfidf_366</td>\n",
       "      <td>8.322461e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>tfidf_22</td>\n",
       "      <td>8.108129e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>117</th>\n",
       "      <td>tfidf_117</td>\n",
       "      <td>7.924130e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>210</th>\n",
       "      <td>tfidf_210</td>\n",
       "      <td>7.782156e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>187</th>\n",
       "      <td>tfidf_187</td>\n",
       "      <td>7.407093e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>362</th>\n",
       "      <td>tfidf_362</td>\n",
       "      <td>7.214589e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>258</th>\n",
       "      <td>tfidf_258</td>\n",
       "      <td>7.189907e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>69</th>\n",
       "      <td>tfidf_69</td>\n",
       "      <td>7.134854e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>407</th>\n",
       "      <td>happy</td>\n",
       "      <td>6.860127e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>178</th>\n",
       "      <td>tfidf_178</td>\n",
       "      <td>6.801907e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>tfidf_30</td>\n",
       "      <td>6.689989e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>312</th>\n",
       "      <td>tfidf_312</td>\n",
       "      <td>6.436598e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>413</th>\n",
       "      <td>relaxed</td>\n",
       "      <td>6.172982e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>402</th>\n",
       "      <td>euphoric</td>\n",
       "      <td>6.123404e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>309</th>\n",
       "      <td>tfidf_309</td>\n",
       "      <td>6.016004e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>207</th>\n",
       "      <td>tfidf_207</td>\n",
       "      <td>5.675458e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>442</th>\n",
       "      <td>lime</td>\n",
       "      <td>5.554589e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>245</th>\n",
       "      <td>tfidf_245</td>\n",
       "      <td>5.535883e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>tfidf_95</td>\n",
       "      <td>5.305555e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>420</th>\n",
       "      <td>uplifted</td>\n",
       "      <td>5.095768e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>tfidf_17</td>\n",
       "      <td>5.062537e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>398</th>\n",
       "      <td>dry eyes</td>\n",
       "      <td>5.033288e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>144</th>\n",
       "      <td>tfidf_144</td>\n",
       "      <td>4.859450e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>93</th>\n",
       "      <td>tfidf_93</td>\n",
       "      <td>4.808655e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>399</th>\n",
       "      <td>dry mouth</td>\n",
       "      <td>4.570102e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>281</th>\n",
       "      <td>tfidf_281</td>\n",
       "      <td>4.473888e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>285</th>\n",
       "      <td>tfidf_285</td>\n",
       "      <td>4.459955e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>161</th>\n",
       "      <td>tfidf_161</td>\n",
       "      <td>4.294198e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>199</th>\n",
       "      <td>tfidf_199</td>\n",
       "      <td>4.269398e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>434</th>\n",
       "      <td>earthy</td>\n",
       "      <td>4.268308e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>353</th>\n",
       "      <td>tfidf_353</td>\n",
       "      <td>4.199673e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>141</th>\n",
       "      <td>tfidf_141</td>\n",
       "      <td>4.046926e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>337</th>\n",
       "      <td>tfidf_337</td>\n",
       "      <td>3.935143e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>361</th>\n",
       "      <td>tfidf_361</td>\n",
       "      <td>3.828350e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>385</th>\n",
       "      <td>tfidf_385</td>\n",
       "      <td>3.792418e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>355</th>\n",
       "      <td>tfidf_355</td>\n",
       "      <td>3.764891e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>193</th>\n",
       "      <td>tfidf_193</td>\n",
       "      <td>3.744637e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>128</th>\n",
       "      <td>tfidf_128</td>\n",
       "      <td>3.668805e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>89</th>\n",
       "      <td>tfidf_89</td>\n",
       "      <td>3.613498e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>211</th>\n",
       "      <td>tfidf_211</td>\n",
       "      <td>3.518970e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>155</th>\n",
       "      <td>tfidf_155</td>\n",
       "      <td>3.345871e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>382</th>\n",
       "      <td>tfidf_382</td>\n",
       "      <td>3.319899e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>195</th>\n",
       "      <td>tfidf_195</td>\n",
       "      <td>3.088286e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>tfidf_43</td>\n",
       "      <td>2.961775e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>357</th>\n",
       "      <td>tfidf_357</td>\n",
       "      <td>2.865662e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>460</th>\n",
       "      <td>sweet</td>\n",
       "      <td>2.838064e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>65</th>\n",
       "      <td>tfidf_65</td>\n",
       "      <td>2.786792e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>348</th>\n",
       "      <td>tfidf_348</td>\n",
       "      <td>2.735768e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>282</th>\n",
       "      <td>tfidf_282</td>\n",
       "      <td>2.689469e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>405</th>\n",
       "      <td>focused</td>\n",
       "      <td>2.630549e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>283</th>\n",
       "      <td>tfidf_283</td>\n",
       "      <td>2.623520e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>175</th>\n",
       "      <td>tfidf_175</td>\n",
       "      <td>2.536245e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>400</th>\n",
       "      <td>energetic</td>\n",
       "      <td>2.441341e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>342</th>\n",
       "      <td>tfidf_342</td>\n",
       "      <td>2.355169e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>418</th>\n",
       "      <td>talkative</td>\n",
       "      <td>2.305499e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>tfidf_48</td>\n",
       "      <td>2.263182e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>260</th>\n",
       "      <td>tfidf_260</td>\n",
       "      <td>2.262997e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>tfidf_7</td>\n",
       "      <td>2.245283e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>73</th>\n",
       "      <td>tfidf_73</td>\n",
       "      <td>2.213686e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>205</th>\n",
       "      <td>tfidf_205</td>\n",
       "      <td>2.187445e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>104</th>\n",
       "      <td>tfidf_104</td>\n",
       "      <td>2.137587e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>129</th>\n",
       "      <td>tfidf_129</td>\n",
       "      <td>2.111105e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>431</th>\n",
       "      <td>citrus</td>\n",
       "      <td>2.082916e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>107</th>\n",
       "      <td>tfidf_107</td>\n",
       "      <td>2.001196e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>248</th>\n",
       "      <td>tfidf_248</td>\n",
       "      <td>1.981235e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>tfidf_37</td>\n",
       "      <td>1.975268e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>tfidf_4</td>\n",
       "      <td>1.961041e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>426</th>\n",
       "      <td>blueberry</td>\n",
       "      <td>1.954092e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>343</th>\n",
       "      <td>tfidf_343</td>\n",
       "      <td>1.937460e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>tfidf_46</td>\n",
       "      <td>1.933347e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>247</th>\n",
       "      <td>tfidf_247</td>\n",
       "      <td>1.921839e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>221</th>\n",
       "      <td>tfidf_221</td>\n",
       "      <td>1.905006e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>tfidf_32</td>\n",
       "      <td>1.868229e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>tfidf_5</td>\n",
       "      <td>1.838823e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>119</th>\n",
       "      <td>tfidf_119</td>\n",
       "      <td>1.831264e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>88</th>\n",
       "      <td>tfidf_88</td>\n",
       "      <td>1.824238e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>395</th>\n",
       "      <td>creative</td>\n",
       "      <td>1.792952e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>122</th>\n",
       "      <td>tfidf_122</td>\n",
       "      <td>1.786763e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>437</th>\n",
       "      <td>grape</td>\n",
       "      <td>1.783061e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>tfidf_1</td>\n",
       "      <td>1.742171e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>173</th>\n",
       "      <td>tfidf_173</td>\n",
       "      <td>1.738646e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>78</th>\n",
       "      <td>tfidf_78</td>\n",
       "      <td>1.729943e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>tfidf_0</td>\n",
       "      <td>1.720920e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>tfidf_98</td>\n",
       "      <td>1.713339e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>374</th>\n",
       "      <td>tfidf_374</td>\n",
       "      <td>1.690904e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>371</th>\n",
       "      <td>tfidf_371</td>\n",
       "      <td>1.667464e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>158</th>\n",
       "      <td>tfidf_158</td>\n",
       "      <td>1.663489e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>194</th>\n",
       "      <td>tfidf_194</td>\n",
       "      <td>1.654439e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53</th>\n",
       "      <td>tfidf_53</td>\n",
       "      <td>1.649324e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>tfidf_15</td>\n",
       "      <td>1.631483e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>354</th>\n",
       "      <td>tfidf_354</td>\n",
       "      <td>1.616815e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>tfidf_16</td>\n",
       "      <td>1.615804e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>61</th>\n",
       "      <td>tfidf_61</td>\n",
       "      <td>1.613580e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>tfidf_29</td>\n",
       "      <td>1.585885e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>58</th>\n",
       "      <td>tfidf_58</td>\n",
       "      <td>1.584292e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>415</th>\n",
       "      <td>sleepy</td>\n",
       "      <td>1.523554e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>tfidf_6</td>\n",
       "      <td>1.514152e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>406</th>\n",
       "      <td>giggly</td>\n",
       "      <td>1.485904e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>217</th>\n",
       "      <td>tfidf_217</td>\n",
       "      <td>1.446897e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>409</th>\n",
       "      <td>hungry</td>\n",
       "      <td>1.427778e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>376</th>\n",
       "      <td>tfidf_376</td>\n",
       "      <td>1.410504e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>tfidf_21</td>\n",
       "      <td>1.403046e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>71</th>\n",
       "      <td>tfidf_71</td>\n",
       "      <td>1.400429e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>162</th>\n",
       "      <td>tfidf_162</td>\n",
       "      <td>1.397198e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>227</th>\n",
       "      <td>tfidf_227</td>\n",
       "      <td>1.374969e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>265</th>\n",
       "      <td>tfidf_265</td>\n",
       "      <td>1.329950e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>419</th>\n",
       "      <td>tingly</td>\n",
       "      <td>1.327370e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>57</th>\n",
       "      <td>tfidf_57</td>\n",
       "      <td>1.323520e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>234</th>\n",
       "      <td>tfidf_234</td>\n",
       "      <td>1.309868e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>167</th>\n",
       "      <td>tfidf_167</td>\n",
       "      <td>1.306869e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>tfidf_49</td>\n",
       "      <td>1.306326e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>320</th>\n",
       "      <td>tfidf_320</td>\n",
       "      <td>1.292062e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>278</th>\n",
       "      <td>tfidf_278</td>\n",
       "      <td>1.272552e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>350</th>\n",
       "      <td>tfidf_350</td>\n",
       "      <td>1.270619e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>tfidf_20</td>\n",
       "      <td>1.267817e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>457</th>\n",
       "      <td>skunk</td>\n",
       "      <td>1.254392e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>126</th>\n",
       "      <td>tfidf_126</td>\n",
       "      <td>1.218467e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>237</th>\n",
       "      <td>tfidf_237</td>\n",
       "      <td>1.210333e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>206</th>\n",
       "      <td>tfidf_206</td>\n",
       "      <td>1.207508e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>tfidf_39</td>\n",
       "      <td>1.202331e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>tfidf_3</td>\n",
       "      <td>1.195768e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>325</th>\n",
       "      <td>tfidf_325</td>\n",
       "      <td>1.187023e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>347</th>\n",
       "      <td>tfidf_347</td>\n",
       "      <td>1.180877e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>80</th>\n",
       "      <td>tfidf_80</td>\n",
       "      <td>1.173987e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>341</th>\n",
       "      <td>tfidf_341</td>\n",
       "      <td>1.134735e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>383</th>\n",
       "      <td>tfidf_383</td>\n",
       "      <td>1.132320e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>166</th>\n",
       "      <td>tfidf_166</td>\n",
       "      <td>1.122191e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>tfidf_44</td>\n",
       "      <td>1.119208e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>179</th>\n",
       "      <td>tfidf_179</td>\n",
       "      <td>1.111050e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>259</th>\n",
       "      <td>tfidf_259</td>\n",
       "      <td>1.107685e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>303</th>\n",
       "      <td>tfidf_303</td>\n",
       "      <td>1.080162e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>151</th>\n",
       "      <td>tfidf_151</td>\n",
       "      <td>1.078539e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>454</th>\n",
       "      <td>pungent</td>\n",
       "      <td>1.072397e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>267</th>\n",
       "      <td>tfidf_267</td>\n",
       "      <td>1.052844e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>tfidf_11</td>\n",
       "      <td>1.047088e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>456</th>\n",
       "      <td>sage</td>\n",
       "      <td>1.047077e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>338</th>\n",
       "      <td>tfidf_338</td>\n",
       "      <td>1.041636e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>304</th>\n",
       "      <td>tfidf_304</td>\n",
       "      <td>1.026833e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>297</th>\n",
       "      <td>tfidf_297</td>\n",
       "      <td>1.009363e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>90</th>\n",
       "      <td>tfidf_90</td>\n",
       "      <td>1.009343e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>123</th>\n",
       "      <td>tfidf_123</td>\n",
       "      <td>9.962606e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54</th>\n",
       "      <td>tfidf_54</td>\n",
       "      <td>9.937367e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>tfidf_45</td>\n",
       "      <td>9.891690e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>323</th>\n",
       "      <td>tfidf_323</td>\n",
       "      <td>9.769382e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>101</th>\n",
       "      <td>tfidf_101</td>\n",
       "      <td>9.415302e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>263</th>\n",
       "      <td>tfidf_263</td>\n",
       "      <td>9.391364e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>tfidf_9</td>\n",
       "      <td>9.388953e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>112</th>\n",
       "      <td>tfidf_112</td>\n",
       "      <td>9.346887e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>319</th>\n",
       "      <td>tfidf_319</td>\n",
       "      <td>9.227898e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>244</th>\n",
       "      <td>tfidf_244</td>\n",
       "      <td>9.211511e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>252</th>\n",
       "      <td>tfidf_252</td>\n",
       "      <td>9.136273e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>270</th>\n",
       "      <td>tfidf_270</td>\n",
       "      <td>9.063170e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>tfidf_14</td>\n",
       "      <td>9.057699e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>208</th>\n",
       "      <td>tfidf_208</td>\n",
       "      <td>8.997923e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>64</th>\n",
       "      <td>tfidf_64</td>\n",
       "      <td>8.961477e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>159</th>\n",
       "      <td>tfidf_159</td>\n",
       "      <td>8.952374e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>316</th>\n",
       "      <td>tfidf_316</td>\n",
       "      <td>8.938014e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>181</th>\n",
       "      <td>tfidf_181</td>\n",
       "      <td>8.882987e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>94</th>\n",
       "      <td>tfidf_94</td>\n",
       "      <td>8.867632e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>336</th>\n",
       "      <td>tfidf_336</td>\n",
       "      <td>8.810851e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>106</th>\n",
       "      <td>tfidf_106</td>\n",
       "      <td>8.774737e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>264</th>\n",
       "      <td>tfidf_264</td>\n",
       "      <td>8.749998e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>103</th>\n",
       "      <td>tfidf_103</td>\n",
       "      <td>8.726677e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>256</th>\n",
       "      <td>tfidf_256</td>\n",
       "      <td>8.629232e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>tfidf_2</td>\n",
       "      <td>8.501774e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>328</th>\n",
       "      <td>tfidf_328</td>\n",
       "      <td>8.372551e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>201</th>\n",
       "      <td>tfidf_201</td>\n",
       "      <td>8.355758e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>tfidf_96</td>\n",
       "      <td>8.332790e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>116</th>\n",
       "      <td>tfidf_116</td>\n",
       "      <td>8.207012e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>298</th>\n",
       "      <td>tfidf_298</td>\n",
       "      <td>8.129564e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>393</th>\n",
       "      <td>aroused</td>\n",
       "      <td>8.126325e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>289</th>\n",
       "      <td>tfidf_289</td>\n",
       "      <td>8.099055e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>171</th>\n",
       "      <td>tfidf_171</td>\n",
       "      <td>8.013515e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>160</th>\n",
       "      <td>tfidf_160</td>\n",
       "      <td>7.974807e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>451</th>\n",
       "      <td>pine</td>\n",
       "      <td>7.957194e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>291</th>\n",
       "      <td>tfidf_291</td>\n",
       "      <td>7.931826e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>70</th>\n",
       "      <td>tfidf_70</td>\n",
       "      <td>7.889898e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>200</th>\n",
       "      <td>tfidf_200</td>\n",
       "      <td>7.859596e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>397</th>\n",
       "      <td>dizzy</td>\n",
       "      <td>7.812679e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>231</th>\n",
       "      <td>tfidf_231</td>\n",
       "      <td>7.762614e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>tfidf_36</td>\n",
       "      <td>7.705441e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>tfidf_41</td>\n",
       "      <td>7.673262e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>435</th>\n",
       "      <td>flowery</td>\n",
       "      <td>7.588287e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>275</th>\n",
       "      <td>tfidf_275</td>\n",
       "      <td>7.502085e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>277</th>\n",
       "      <td>tfidf_277</td>\n",
       "      <td>7.481944e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>170</th>\n",
       "      <td>tfidf_170</td>\n",
       "      <td>7.464593e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>tfidf_28</td>\n",
       "      <td>7.451622e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>311</th>\n",
       "      <td>tfidf_311</td>\n",
       "      <td>7.424145e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>184</th>\n",
       "      <td>tfidf_184</td>\n",
       "      <td>7.376750e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>190</th>\n",
       "      <td>tfidf_190</td>\n",
       "      <td>7.268608e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>203</th>\n",
       "      <td>tfidf_203</td>\n",
       "      <td>7.241687e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>280</th>\n",
       "      <td>tfidf_280</td>\n",
       "      <td>7.239544e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>tfidf_26</td>\n",
       "      <td>7.098760e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>360</th>\n",
       "      <td>tfidf_360</td>\n",
       "      <td>6.941960e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>271</th>\n",
       "      <td>tfidf_271</td>\n",
       "      <td>6.873726e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>60</th>\n",
       "      <td>tfidf_60</td>\n",
       "      <td>6.806431e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>125</th>\n",
       "      <td>tfidf_125</td>\n",
       "      <td>6.766809e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>79</th>\n",
       "      <td>tfidf_79</td>\n",
       "      <td>6.739500e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>230</th>\n",
       "      <td>tfidf_230</td>\n",
       "      <td>6.685358e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>214</th>\n",
       "      <td>tfidf_214</td>\n",
       "      <td>6.494643e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>164</th>\n",
       "      <td>tfidf_164</td>\n",
       "      <td>6.468648e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>358</th>\n",
       "      <td>tfidf_358</td>\n",
       "      <td>6.459098e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>146</th>\n",
       "      <td>tfidf_146</td>\n",
       "      <td>6.416550e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>124</th>\n",
       "      <td>tfidf_124</td>\n",
       "      <td>6.382146e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>130</th>\n",
       "      <td>tfidf_130</td>\n",
       "      <td>6.357090e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>tfidf_35</td>\n",
       "      <td>6.353180e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>tfidf_19</td>\n",
       "      <td>6.212282e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>373</th>\n",
       "      <td>tfidf_373</td>\n",
       "      <td>6.202031e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>370</th>\n",
       "      <td>tfidf_370</td>\n",
       "      <td>6.110784e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>215</th>\n",
       "      <td>tfidf_215</td>\n",
       "      <td>6.046999e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>233</th>\n",
       "      <td>tfidf_233</td>\n",
       "      <td>6.031140e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>240</th>\n",
       "      <td>tfidf_240</td>\n",
       "      <td>6.018718e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>67</th>\n",
       "      <td>tfidf_67</td>\n",
       "      <td>5.981169e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>137</th>\n",
       "      <td>tfidf_137</td>\n",
       "      <td>5.971611e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>110</th>\n",
       "      <td>tfidf_110</td>\n",
       "      <td>5.922934e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>235</th>\n",
       "      <td>tfidf_235</td>\n",
       "      <td>5.922739e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>111</th>\n",
       "      <td>tfidf_111</td>\n",
       "      <td>5.893961e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>tfidf_47</td>\n",
       "      <td>5.805694e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>257</th>\n",
       "      <td>tfidf_257</td>\n",
       "      <td>5.761793e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>153</th>\n",
       "      <td>tfidf_153</td>\n",
       "      <td>5.741397e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>198</th>\n",
       "      <td>tfidf_198</td>\n",
       "      <td>5.683317e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>273</th>\n",
       "      <td>tfidf_273</td>\n",
       "      <td>5.571511e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>81</th>\n",
       "      <td>tfidf_81</td>\n",
       "      <td>5.561522e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>224</th>\n",
       "      <td>tfidf_224</td>\n",
       "      <td>5.512165e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>262</th>\n",
       "      <td>tfidf_262</td>\n",
       "      <td>5.431126e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>372</th>\n",
       "      <td>tfidf_372</td>\n",
       "      <td>5.387793e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>131</th>\n",
       "      <td>tfidf_131</td>\n",
       "      <td>5.356974e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>459</th>\n",
       "      <td>strawberry</td>\n",
       "      <td>5.349964e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>251</th>\n",
       "      <td>tfidf_251</td>\n",
       "      <td>5.323161e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>322</th>\n",
       "      <td>tfidf_322</td>\n",
       "      <td>5.320235e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>445</th>\n",
       "      <td>mint</td>\n",
       "      <td>5.270593e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>108</th>\n",
       "      <td>tfidf_108</td>\n",
       "      <td>5.241289e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>tfidf_23</td>\n",
       "      <td>5.184233e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>85</th>\n",
       "      <td>tfidf_85</td>\n",
       "      <td>5.167162e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>295</th>\n",
       "      <td>tfidf_295</td>\n",
       "      <td>5.102617e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>387</th>\n",
       "      <td>tfidf_387</td>\n",
       "      <td>5.062962e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>276</th>\n",
       "      <td>tfidf_276</td>\n",
       "      <td>5.048794e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>183</th>\n",
       "      <td>tfidf_183</td>\n",
       "      <td>4.977184e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>439</th>\n",
       "      <td>honey</td>\n",
       "      <td>4.916890e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>432</th>\n",
       "      <td>coffee</td>\n",
       "      <td>4.915536e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>152</th>\n",
       "      <td>tfidf_152</td>\n",
       "      <td>4.895532e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>tfidf_34</td>\n",
       "      <td>4.882663e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>351</th>\n",
       "      <td>tfidf_351</td>\n",
       "      <td>4.875925e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>136</th>\n",
       "      <td>tfidf_136</td>\n",
       "      <td>4.824327e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>458</th>\n",
       "      <td>spicy/herbal</td>\n",
       "      <td>4.810913e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>138</th>\n",
       "      <td>tfidf_138</td>\n",
       "      <td>4.774911e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>465</th>\n",
       "      <td>tropical</td>\n",
       "      <td>4.758970e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>tfidf_38</td>\n",
       "      <td>4.739867e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>344</th>\n",
       "      <td>tfidf_344</td>\n",
       "      <td>4.691804e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>148</th>\n",
       "      <td>tfidf_148</td>\n",
       "      <td>4.680109e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>118</th>\n",
       "      <td>tfidf_118</td>\n",
       "      <td>4.669889e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>154</th>\n",
       "      <td>tfidf_154</td>\n",
       "      <td>4.645613e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>188</th>\n",
       "      <td>tfidf_188</td>\n",
       "      <td>4.404268e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>140</th>\n",
       "      <td>tfidf_140</td>\n",
       "      <td>4.394600e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>346</th>\n",
       "      <td>tfidf_346</td>\n",
       "      <td>4.328386e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>202</th>\n",
       "      <td>tfidf_202</td>\n",
       "      <td>4.296194e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>307</th>\n",
       "      <td>tfidf_307</td>\n",
       "      <td>4.286460e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>176</th>\n",
       "      <td>tfidf_176</td>\n",
       "      <td>4.283623e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>446</th>\n",
       "      <td>nutty</td>\n",
       "      <td>4.282440e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>324</th>\n",
       "      <td>tfidf_324</td>\n",
       "      <td>4.269896e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>429</th>\n",
       "      <td>chemical</td>\n",
       "      <td>4.249747e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>250</th>\n",
       "      <td>tfidf_250</td>\n",
       "      <td>4.244818e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>139</th>\n",
       "      <td>tfidf_139</td>\n",
       "      <td>4.181302e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>76</th>\n",
       "      <td>tfidf_76</td>\n",
       "      <td>4.136827e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>318</th>\n",
       "      <td>tfidf_318</td>\n",
       "      <td>4.136020e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>452</th>\n",
       "      <td>pineapple</td>\n",
       "      <td>4.132366e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>333</th>\n",
       "      <td>tfidf_333</td>\n",
       "      <td>4.111515e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>172</th>\n",
       "      <td>tfidf_172</td>\n",
       "      <td>4.085369e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>352</th>\n",
       "      <td>tfidf_352</td>\n",
       "      <td>4.068301e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>468</th>\n",
       "      <td>woody</td>\n",
       "      <td>4.047003e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>246</th>\n",
       "      <td>tfidf_246</td>\n",
       "      <td>4.043562e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>287</th>\n",
       "      <td>tfidf_287</td>\n",
       "      <td>4.018444e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>300</th>\n",
       "      <td>tfidf_300</td>\n",
       "      <td>4.011521e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>369</th>\n",
       "      <td>tfidf_369</td>\n",
       "      <td>3.998142e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>286</th>\n",
       "      <td>tfidf_286</td>\n",
       "      <td>3.994207e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>331</th>\n",
       "      <td>tfidf_331</td>\n",
       "      <td>3.985976e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>91</th>\n",
       "      <td>tfidf_91</td>\n",
       "      <td>3.967347e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>380</th>\n",
       "      <td>tfidf_380</td>\n",
       "      <td>3.959573e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>68</th>\n",
       "      <td>tfidf_68</td>\n",
       "      <td>3.927282e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>87</th>\n",
       "      <td>tfidf_87</td>\n",
       "      <td>3.926979e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>tfidf_25</td>\n",
       "      <td>3.877245e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>tfidf_99</td>\n",
       "      <td>3.814785e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>220</th>\n",
       "      <td>tfidf_220</td>\n",
       "      <td>3.765645e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>213</th>\n",
       "      <td>tfidf_213</td>\n",
       "      <td>3.675786e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>120</th>\n",
       "      <td>tfidf_120</td>\n",
       "      <td>3.590062e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>163</th>\n",
       "      <td>tfidf_163</td>\n",
       "      <td>3.532811e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>443</th>\n",
       "      <td>mango</td>\n",
       "      <td>3.493032e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>tfidf_13</td>\n",
       "      <td>3.480004e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>133</th>\n",
       "      <td>tfidf_133</td>\n",
       "      <td>3.424657e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>272</th>\n",
       "      <td>tfidf_272</td>\n",
       "      <td>3.387797e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>274</th>\n",
       "      <td>tfidf_274</td>\n",
       "      <td>3.387179e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>tfidf_97</td>\n",
       "      <td>3.334303e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>tfidf_40</td>\n",
       "      <td>3.328668e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>294</th>\n",
       "      <td>tfidf_294</td>\n",
       "      <td>3.324656e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>334</th>\n",
       "      <td>tfidf_334</td>\n",
       "      <td>3.318281e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>186</th>\n",
       "      <td>tfidf_186</td>\n",
       "      <td>3.313026e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>269</th>\n",
       "      <td>tfidf_269</td>\n",
       "      <td>3.219545e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>102</th>\n",
       "      <td>tfidf_102</td>\n",
       "      <td>3.204834e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>450</th>\n",
       "      <td>pepper</td>\n",
       "      <td>3.161179e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>tfidf_24</td>\n",
       "      <td>3.123561e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>222</th>\n",
       "      <td>tfidf_222</td>\n",
       "      <td>3.109275e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>363</th>\n",
       "      <td>tfidf_363</td>\n",
       "      <td>3.081548e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>375</th>\n",
       "      <td>tfidf_375</td>\n",
       "      <td>3.042371e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>132</th>\n",
       "      <td>tfidf_132</td>\n",
       "      <td>3.040833e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>143</th>\n",
       "      <td>tfidf_143</td>\n",
       "      <td>3.024207e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>254</th>\n",
       "      <td>tfidf_254</td>\n",
       "      <td>2.988672e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>384</th>\n",
       "      <td>tfidf_384</td>\n",
       "      <td>2.948894e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>tfidf_10</td>\n",
       "      <td>2.944404e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>192</th>\n",
       "      <td>tfidf_192</td>\n",
       "      <td>2.937443e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>232</th>\n",
       "      <td>tfidf_232</td>\n",
       "      <td>2.919468e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>157</th>\n",
       "      <td>tfidf_157</td>\n",
       "      <td>2.907179e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>197</th>\n",
       "      <td>tfidf_197</td>\n",
       "      <td>2.906180e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>134</th>\n",
       "      <td>tfidf_134</td>\n",
       "      <td>2.901530e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>379</th>\n",
       "      <td>tfidf_379</td>\n",
       "      <td>2.869822e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>142</th>\n",
       "      <td>tfidf_142</td>\n",
       "      <td>2.846110e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>321</th>\n",
       "      <td>tfidf_321</td>\n",
       "      <td>2.840672e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>368</th>\n",
       "      <td>tfidf_368</td>\n",
       "      <td>2.825204e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>109</th>\n",
       "      <td>tfidf_109</td>\n",
       "      <td>2.786221e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>135</th>\n",
       "      <td>tfidf_135</td>\n",
       "      <td>2.773447e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>225</th>\n",
       "      <td>tfidf_225</td>\n",
       "      <td>2.753878e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>56</th>\n",
       "      <td>tfidf_56</td>\n",
       "      <td>2.690108e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>238</th>\n",
       "      <td>tfidf_238</td>\n",
       "      <td>2.683698e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>105</th>\n",
       "      <td>tfidf_105</td>\n",
       "      <td>2.655457e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>349</th>\n",
       "      <td>tfidf_349</td>\n",
       "      <td>2.645861e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>408</th>\n",
       "      <td>headache</td>\n",
       "      <td>2.624802e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>tfidf_27</td>\n",
       "      <td>2.582527e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>83</th>\n",
       "      <td>tfidf_83</td>\n",
       "      <td>2.575705e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>249</th>\n",
       "      <td>tfidf_249</td>\n",
       "      <td>2.551906e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>tfidf_42</td>\n",
       "      <td>2.550805e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>301</th>\n",
       "      <td>tfidf_301</td>\n",
       "      <td>2.525231e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>212</th>\n",
       "      <td>tfidf_212</td>\n",
       "      <td>2.524487e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>156</th>\n",
       "      <td>tfidf_156</td>\n",
       "      <td>2.507050e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>315</th>\n",
       "      <td>tfidf_315</td>\n",
       "      <td>2.504785e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>84</th>\n",
       "      <td>tfidf_84</td>\n",
       "      <td>2.499774e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>392</th>\n",
       "      <td>anxious</td>\n",
       "      <td>2.491529e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>86</th>\n",
       "      <td>tfidf_86</td>\n",
       "      <td>2.443064e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52</th>\n",
       "      <td>tfidf_52</td>\n",
       "      <td>2.404076e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>165</th>\n",
       "      <td>tfidf_165</td>\n",
       "      <td>2.394581e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>229</th>\n",
       "      <td>tfidf_229</td>\n",
       "      <td>2.388180e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>290</th>\n",
       "      <td>tfidf_290</td>\n",
       "      <td>2.312942e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>412</th>\n",
       "      <td>paranoid</td>\n",
       "      <td>2.295150e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>310</th>\n",
       "      <td>tfidf_310</td>\n",
       "      <td>2.275509e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>218</th>\n",
       "      <td>tfidf_218</td>\n",
       "      <td>2.251383e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>tfidf_12</td>\n",
       "      <td>2.240218e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>422</th>\n",
       "      <td>apple</td>\n",
       "      <td>2.202757e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>62</th>\n",
       "      <td>tfidf_62</td>\n",
       "      <td>2.183465e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>tfidf_33</td>\n",
       "      <td>2.158266e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75</th>\n",
       "      <td>tfidf_75</td>\n",
       "      <td>2.155714e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>313</th>\n",
       "      <td>tfidf_313</td>\n",
       "      <td>2.143188e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>302</th>\n",
       "      <td>tfidf_302</td>\n",
       "      <td>2.135991e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>115</th>\n",
       "      <td>tfidf_115</td>\n",
       "      <td>2.135905e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>tfidf_31</td>\n",
       "      <td>2.130852e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>288</th>\n",
       "      <td>tfidf_288</td>\n",
       "      <td>2.129532e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>127</th>\n",
       "      <td>tfidf_127</td>\n",
       "      <td>2.124902e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>308</th>\n",
       "      <td>tfidf_308</td>\n",
       "      <td>2.101537e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>365</th>\n",
       "      <td>tfidf_365</td>\n",
       "      <td>2.083552e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>423</th>\n",
       "      <td>apricot</td>\n",
       "      <td>2.049043e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>326</th>\n",
       "      <td>tfidf_326</td>\n",
       "      <td>2.047271e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>219</th>\n",
       "      <td>tfidf_219</td>\n",
       "      <td>2.046453e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>169</th>\n",
       "      <td>tfidf_169</td>\n",
       "      <td>2.030914e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>177</th>\n",
       "      <td>tfidf_177</td>\n",
       "      <td>1.993749e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>82</th>\n",
       "      <td>tfidf_82</td>\n",
       "      <td>1.976653e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>436</th>\n",
       "      <td>fruit</td>\n",
       "      <td>1.927144e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>332</th>\n",
       "      <td>tfidf_332</td>\n",
       "      <td>1.850956e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>284</th>\n",
       "      <td>tfidf_284</td>\n",
       "      <td>1.780000e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>223</th>\n",
       "      <td>tfidf_223</td>\n",
       "      <td>1.746962e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>204</th>\n",
       "      <td>tfidf_204</td>\n",
       "      <td>1.745986e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>74</th>\n",
       "      <td>tfidf_74</td>\n",
       "      <td>1.695443e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59</th>\n",
       "      <td>tfidf_59</td>\n",
       "      <td>1.693556e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>tfidf_8</td>\n",
       "      <td>1.645294e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>421</th>\n",
       "      <td>ammonia</td>\n",
       "      <td>1.641431e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>359</th>\n",
       "      <td>tfidf_359</td>\n",
       "      <td>1.639583e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>185</th>\n",
       "      <td>tfidf_185</td>\n",
       "      <td>1.624554e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>255</th>\n",
       "      <td>tfidf_255</td>\n",
       "      <td>1.622624e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>216</th>\n",
       "      <td>tfidf_216</td>\n",
       "      <td>1.619164e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>236</th>\n",
       "      <td>tfidf_236</td>\n",
       "      <td>1.617591e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>228</th>\n",
       "      <td>tfidf_228</td>\n",
       "      <td>1.613820e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>464</th>\n",
       "      <td>tree</td>\n",
       "      <td>1.583777e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>100</th>\n",
       "      <td>tfidf_100</td>\n",
       "      <td>1.565164e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>243</th>\n",
       "      <td>tfidf_243</td>\n",
       "      <td>1.563617e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>226</th>\n",
       "      <td>tfidf_226</td>\n",
       "      <td>1.557064e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>327</th>\n",
       "      <td>tfidf_327</td>\n",
       "      <td>1.549318e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>196</th>\n",
       "      <td>tfidf_196</td>\n",
       "      <td>1.546602e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>317</th>\n",
       "      <td>tfidf_317</td>\n",
       "      <td>1.506873e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>356</th>\n",
       "      <td>tfidf_356</td>\n",
       "      <td>1.475036e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>tfidf_18</td>\n",
       "      <td>1.453571e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>77</th>\n",
       "      <td>tfidf_77</td>\n",
       "      <td>1.443775e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>268</th>\n",
       "      <td>tfidf_268</td>\n",
       "      <td>1.438411e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>63</th>\n",
       "      <td>tfidf_63</td>\n",
       "      <td>1.396174e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>440</th>\n",
       "      <td>lavender</td>\n",
       "      <td>1.378801e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>305</th>\n",
       "      <td>tfidf_305</td>\n",
       "      <td>1.375231e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>279</th>\n",
       "      <td>tfidf_279</td>\n",
       "      <td>1.283970e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>306</th>\n",
       "      <td>tfidf_306</td>\n",
       "      <td>1.272154e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>266</th>\n",
       "      <td>tfidf_266</td>\n",
       "      <td>1.245771e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>180</th>\n",
       "      <td>tfidf_180</td>\n",
       "      <td>1.230920e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>55</th>\n",
       "      <td>tfidf_55</td>\n",
       "      <td>1.196112e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>92</th>\n",
       "      <td>tfidf_92</td>\n",
       "      <td>1.188015e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>299</th>\n",
       "      <td>tfidf_299</td>\n",
       "      <td>1.132286e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>191</th>\n",
       "      <td>tfidf_191</td>\n",
       "      <td>1.106892e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>72</th>\n",
       "      <td>tfidf_72</td>\n",
       "      <td>1.104230e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>174</th>\n",
       "      <td>tfidf_174</td>\n",
       "      <td>1.073140e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>292</th>\n",
       "      <td>tfidf_292</td>\n",
       "      <td>1.034924e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>378</th>\n",
       "      <td>tfidf_378</td>\n",
       "      <td>1.012591e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>339</th>\n",
       "      <td>tfidf_339</td>\n",
       "      <td>9.899493e-05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>66</th>\n",
       "      <td>tfidf_66</td>\n",
       "      <td>9.780627e-05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>330</th>\n",
       "      <td>tfidf_330</td>\n",
       "      <td>9.696685e-05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>242</th>\n",
       "      <td>tfidf_242</td>\n",
       "      <td>9.469317e-05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>461</th>\n",
       "      <td>tar</td>\n",
       "      <td>9.406651e-05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>114</th>\n",
       "      <td>tfidf_114</td>\n",
       "      <td>8.555617e-05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>335</th>\n",
       "      <td>tfidf_335</td>\n",
       "      <td>8.392827e-05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>147</th>\n",
       "      <td>tfidf_147</td>\n",
       "      <td>8.340948e-05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>182</th>\n",
       "      <td>tfidf_182</td>\n",
       "      <td>8.245169e-05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>386</th>\n",
       "      <td>tfidf_386</td>\n",
       "      <td>7.696653e-05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>150</th>\n",
       "      <td>tfidf_150</td>\n",
       "      <td>7.514844e-05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>462</th>\n",
       "      <td>tea</td>\n",
       "      <td>7.331578e-05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>113</th>\n",
       "      <td>tfidf_113</td>\n",
       "      <td>7.194635e-05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>438</th>\n",
       "      <td>grapefruit</td>\n",
       "      <td>6.512872e-05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>377</th>\n",
       "      <td>tfidf_377</td>\n",
       "      <td>6.182848e-05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>296</th>\n",
       "      <td>tfidf_296</td>\n",
       "      <td>5.757491e-05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>449</th>\n",
       "      <td>pear</td>\n",
       "      <td>5.744845e-05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>425</th>\n",
       "      <td>blue cheese</td>\n",
       "      <td>5.511503e-05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>448</th>\n",
       "      <td>peach</td>\n",
       "      <td>5.351249e-05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>391</th>\n",
       "      <td>anxiety</td>\n",
       "      <td>5.280380e-05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>364</th>\n",
       "      <td>tfidf_364</td>\n",
       "      <td>5.155945e-05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50</th>\n",
       "      <td>tfidf_50</td>\n",
       "      <td>5.103802e-05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>209</th>\n",
       "      <td>tfidf_209</td>\n",
       "      <td>5.032478e-05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>261</th>\n",
       "      <td>tfidf_261</td>\n",
       "      <td>4.375440e-05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51</th>\n",
       "      <td>tfidf_51</td>\n",
       "      <td>4.080484e-05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>430</th>\n",
       "      <td>chestnut</td>\n",
       "      <td>3.895310e-05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>293</th>\n",
       "      <td>tfidf_293</td>\n",
       "      <td>3.826159e-05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>427</th>\n",
       "      <td>butter</td>\n",
       "      <td>3.609594e-05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>396</th>\n",
       "      <td>depression</td>\n",
       "      <td>3.171211e-05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>241</th>\n",
       "      <td>tfidf_241</td>\n",
       "      <td>2.911594e-05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>455</th>\n",
       "      <td>rose</td>\n",
       "      <td>2.879680e-05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>444</th>\n",
       "      <td>menthol</td>\n",
       "      <td>1.755792e-05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>410</th>\n",
       "      <td>migraines</td>\n",
       "      <td>1.626353e-05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>463</th>\n",
       "      <td>tobacco</td>\n",
       "      <td>1.573209e-05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>467</th>\n",
       "      <td>violet</td>\n",
       "      <td>1.468041e-05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>453</th>\n",
       "      <td>plum</td>\n",
       "      <td>1.000273e-05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>416</th>\n",
       "      <td>spasticity</td>\n",
       "      <td>3.051550e-07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>401</th>\n",
       "      <td>epilepsy</td>\n",
       "      <td>3.325426e-10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>403</th>\n",
       "      <td>eye pressure</td>\n",
       "      <td>6.410554e-11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>394</th>\n",
       "      <td>arthritis</td>\n",
       "      <td>2.698316e-11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>404</th>\n",
       "      <td>fatigue</td>\n",
       "      <td>1.122879e-11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>411</th>\n",
       "      <td>pain</td>\n",
       "      <td>0.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>414</th>\n",
       "      <td>seizures</td>\n",
       "      <td>0.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>417</th>\n",
       "      <td>stress</td>\n",
       "      <td>0.000000e+00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         features         score\n",
       "428        cheese  1.114134e-01\n",
       "389        indica  8.013183e-02\n",
       "466       vanilla  3.730248e-02\n",
       "388        hybrid  2.841362e-02\n",
       "168     tfidf_168  2.005386e-02\n",
       "433        diesel  1.730051e-02\n",
       "424         berry  1.681100e-02\n",
       "329     tfidf_329  1.597831e-02\n",
       "390        sativa  1.392520e-02\n",
       "253     tfidf_253  1.387822e-02\n",
       "441         lemon  1.356640e-02\n",
       "447        orange  1.355734e-02\n",
       "345     tfidf_345  1.333219e-02\n",
       "367     tfidf_367  1.322552e-02\n",
       "239     tfidf_239  1.267174e-02\n",
       "149     tfidf_149  1.199917e-02\n",
       "145     tfidf_145  1.148689e-02\n",
       "314     tfidf_314  1.028157e-02\n",
       "381     tfidf_381  9.192358e-03\n",
       "189     tfidf_189  9.161902e-03\n",
       "121     tfidf_121  8.764601e-03\n",
       "340     tfidf_340  8.742274e-03\n",
       "366     tfidf_366  8.322461e-03\n",
       "22       tfidf_22  8.108129e-03\n",
       "117     tfidf_117  7.924130e-03\n",
       "210     tfidf_210  7.782156e-03\n",
       "187     tfidf_187  7.407093e-03\n",
       "362     tfidf_362  7.214589e-03\n",
       "258     tfidf_258  7.189907e-03\n",
       "69       tfidf_69  7.134854e-03\n",
       "407         happy  6.860127e-03\n",
       "178     tfidf_178  6.801907e-03\n",
       "30       tfidf_30  6.689989e-03\n",
       "312     tfidf_312  6.436598e-03\n",
       "413       relaxed  6.172982e-03\n",
       "402      euphoric  6.123404e-03\n",
       "309     tfidf_309  6.016004e-03\n",
       "207     tfidf_207  5.675458e-03\n",
       "442          lime  5.554589e-03\n",
       "245     tfidf_245  5.535883e-03\n",
       "95       tfidf_95  5.305555e-03\n",
       "420      uplifted  5.095768e-03\n",
       "17       tfidf_17  5.062537e-03\n",
       "398      dry eyes  5.033288e-03\n",
       "144     tfidf_144  4.859450e-03\n",
       "93       tfidf_93  4.808655e-03\n",
       "399     dry mouth  4.570102e-03\n",
       "281     tfidf_281  4.473888e-03\n",
       "285     tfidf_285  4.459955e-03\n",
       "161     tfidf_161  4.294198e-03\n",
       "199     tfidf_199  4.269398e-03\n",
       "434        earthy  4.268308e-03\n",
       "353     tfidf_353  4.199673e-03\n",
       "141     tfidf_141  4.046926e-03\n",
       "337     tfidf_337  3.935143e-03\n",
       "361     tfidf_361  3.828350e-03\n",
       "385     tfidf_385  3.792418e-03\n",
       "355     tfidf_355  3.764891e-03\n",
       "193     tfidf_193  3.744637e-03\n",
       "128     tfidf_128  3.668805e-03\n",
       "89       tfidf_89  3.613498e-03\n",
       "211     tfidf_211  3.518970e-03\n",
       "155     tfidf_155  3.345871e-03\n",
       "382     tfidf_382  3.319899e-03\n",
       "195     tfidf_195  3.088286e-03\n",
       "43       tfidf_43  2.961775e-03\n",
       "357     tfidf_357  2.865662e-03\n",
       "460         sweet  2.838064e-03\n",
       "65       tfidf_65  2.786792e-03\n",
       "348     tfidf_348  2.735768e-03\n",
       "282     tfidf_282  2.689469e-03\n",
       "405       focused  2.630549e-03\n",
       "283     tfidf_283  2.623520e-03\n",
       "175     tfidf_175  2.536245e-03\n",
       "400     energetic  2.441341e-03\n",
       "342     tfidf_342  2.355169e-03\n",
       "418     talkative  2.305499e-03\n",
       "48       tfidf_48  2.263182e-03\n",
       "260     tfidf_260  2.262997e-03\n",
       "7         tfidf_7  2.245283e-03\n",
       "73       tfidf_73  2.213686e-03\n",
       "205     tfidf_205  2.187445e-03\n",
       "104     tfidf_104  2.137587e-03\n",
       "129     tfidf_129  2.111105e-03\n",
       "431        citrus  2.082916e-03\n",
       "107     tfidf_107  2.001196e-03\n",
       "248     tfidf_248  1.981235e-03\n",
       "37       tfidf_37  1.975268e-03\n",
       "4         tfidf_4  1.961041e-03\n",
       "426     blueberry  1.954092e-03\n",
       "343     tfidf_343  1.937460e-03\n",
       "46       tfidf_46  1.933347e-03\n",
       "247     tfidf_247  1.921839e-03\n",
       "221     tfidf_221  1.905006e-03\n",
       "32       tfidf_32  1.868229e-03\n",
       "5         tfidf_5  1.838823e-03\n",
       "119     tfidf_119  1.831264e-03\n",
       "88       tfidf_88  1.824238e-03\n",
       "395      creative  1.792952e-03\n",
       "122     tfidf_122  1.786763e-03\n",
       "437         grape  1.783061e-03\n",
       "1         tfidf_1  1.742171e-03\n",
       "173     tfidf_173  1.738646e-03\n",
       "78       tfidf_78  1.729943e-03\n",
       "0         tfidf_0  1.720920e-03\n",
       "98       tfidf_98  1.713339e-03\n",
       "374     tfidf_374  1.690904e-03\n",
       "371     tfidf_371  1.667464e-03\n",
       "158     tfidf_158  1.663489e-03\n",
       "194     tfidf_194  1.654439e-03\n",
       "53       tfidf_53  1.649324e-03\n",
       "15       tfidf_15  1.631483e-03\n",
       "354     tfidf_354  1.616815e-03\n",
       "16       tfidf_16  1.615804e-03\n",
       "61       tfidf_61  1.613580e-03\n",
       "29       tfidf_29  1.585885e-03\n",
       "58       tfidf_58  1.584292e-03\n",
       "415        sleepy  1.523554e-03\n",
       "6         tfidf_6  1.514152e-03\n",
       "406        giggly  1.485904e-03\n",
       "217     tfidf_217  1.446897e-03\n",
       "409        hungry  1.427778e-03\n",
       "376     tfidf_376  1.410504e-03\n",
       "21       tfidf_21  1.403046e-03\n",
       "71       tfidf_71  1.400429e-03\n",
       "162     tfidf_162  1.397198e-03\n",
       "227     tfidf_227  1.374969e-03\n",
       "265     tfidf_265  1.329950e-03\n",
       "419        tingly  1.327370e-03\n",
       "57       tfidf_57  1.323520e-03\n",
       "234     tfidf_234  1.309868e-03\n",
       "167     tfidf_167  1.306869e-03\n",
       "49       tfidf_49  1.306326e-03\n",
       "320     tfidf_320  1.292062e-03\n",
       "278     tfidf_278  1.272552e-03\n",
       "350     tfidf_350  1.270619e-03\n",
       "20       tfidf_20  1.267817e-03\n",
       "457         skunk  1.254392e-03\n",
       "126     tfidf_126  1.218467e-03\n",
       "237     tfidf_237  1.210333e-03\n",
       "206     tfidf_206  1.207508e-03\n",
       "39       tfidf_39  1.202331e-03\n",
       "3         tfidf_3  1.195768e-03\n",
       "325     tfidf_325  1.187023e-03\n",
       "347     tfidf_347  1.180877e-03\n",
       "80       tfidf_80  1.173987e-03\n",
       "341     tfidf_341  1.134735e-03\n",
       "383     tfidf_383  1.132320e-03\n",
       "166     tfidf_166  1.122191e-03\n",
       "44       tfidf_44  1.119208e-03\n",
       "179     tfidf_179  1.111050e-03\n",
       "259     tfidf_259  1.107685e-03\n",
       "303     tfidf_303  1.080162e-03\n",
       "151     tfidf_151  1.078539e-03\n",
       "454       pungent  1.072397e-03\n",
       "267     tfidf_267  1.052844e-03\n",
       "11       tfidf_11  1.047088e-03\n",
       "456          sage  1.047077e-03\n",
       "338     tfidf_338  1.041636e-03\n",
       "304     tfidf_304  1.026833e-03\n",
       "297     tfidf_297  1.009363e-03\n",
       "90       tfidf_90  1.009343e-03\n",
       "123     tfidf_123  9.962606e-04\n",
       "54       tfidf_54  9.937367e-04\n",
       "45       tfidf_45  9.891690e-04\n",
       "323     tfidf_323  9.769382e-04\n",
       "101     tfidf_101  9.415302e-04\n",
       "263     tfidf_263  9.391364e-04\n",
       "9         tfidf_9  9.388953e-04\n",
       "112     tfidf_112  9.346887e-04\n",
       "319     tfidf_319  9.227898e-04\n",
       "244     tfidf_244  9.211511e-04\n",
       "252     tfidf_252  9.136273e-04\n",
       "270     tfidf_270  9.063170e-04\n",
       "14       tfidf_14  9.057699e-04\n",
       "208     tfidf_208  8.997923e-04\n",
       "64       tfidf_64  8.961477e-04\n",
       "159     tfidf_159  8.952374e-04\n",
       "316     tfidf_316  8.938014e-04\n",
       "181     tfidf_181  8.882987e-04\n",
       "94       tfidf_94  8.867632e-04\n",
       "336     tfidf_336  8.810851e-04\n",
       "106     tfidf_106  8.774737e-04\n",
       "264     tfidf_264  8.749998e-04\n",
       "103     tfidf_103  8.726677e-04\n",
       "256     tfidf_256  8.629232e-04\n",
       "2         tfidf_2  8.501774e-04\n",
       "328     tfidf_328  8.372551e-04\n",
       "201     tfidf_201  8.355758e-04\n",
       "96       tfidf_96  8.332790e-04\n",
       "116     tfidf_116  8.207012e-04\n",
       "298     tfidf_298  8.129564e-04\n",
       "393       aroused  8.126325e-04\n",
       "289     tfidf_289  8.099055e-04\n",
       "171     tfidf_171  8.013515e-04\n",
       "160     tfidf_160  7.974807e-04\n",
       "451          pine  7.957194e-04\n",
       "291     tfidf_291  7.931826e-04\n",
       "70       tfidf_70  7.889898e-04\n",
       "200     tfidf_200  7.859596e-04\n",
       "397         dizzy  7.812679e-04\n",
       "231     tfidf_231  7.762614e-04\n",
       "36       tfidf_36  7.705441e-04\n",
       "41       tfidf_41  7.673262e-04\n",
       "435       flowery  7.588287e-04\n",
       "275     tfidf_275  7.502085e-04\n",
       "277     tfidf_277  7.481944e-04\n",
       "170     tfidf_170  7.464593e-04\n",
       "28       tfidf_28  7.451622e-04\n",
       "311     tfidf_311  7.424145e-04\n",
       "184     tfidf_184  7.376750e-04\n",
       "190     tfidf_190  7.268608e-04\n",
       "203     tfidf_203  7.241687e-04\n",
       "280     tfidf_280  7.239544e-04\n",
       "26       tfidf_26  7.098760e-04\n",
       "360     tfidf_360  6.941960e-04\n",
       "271     tfidf_271  6.873726e-04\n",
       "60       tfidf_60  6.806431e-04\n",
       "125     tfidf_125  6.766809e-04\n",
       "79       tfidf_79  6.739500e-04\n",
       "230     tfidf_230  6.685358e-04\n",
       "214     tfidf_214  6.494643e-04\n",
       "164     tfidf_164  6.468648e-04\n",
       "358     tfidf_358  6.459098e-04\n",
       "146     tfidf_146  6.416550e-04\n",
       "124     tfidf_124  6.382146e-04\n",
       "130     tfidf_130  6.357090e-04\n",
       "35       tfidf_35  6.353180e-04\n",
       "19       tfidf_19  6.212282e-04\n",
       "373     tfidf_373  6.202031e-04\n",
       "370     tfidf_370  6.110784e-04\n",
       "215     tfidf_215  6.046999e-04\n",
       "233     tfidf_233  6.031140e-04\n",
       "240     tfidf_240  6.018718e-04\n",
       "67       tfidf_67  5.981169e-04\n",
       "137     tfidf_137  5.971611e-04\n",
       "110     tfidf_110  5.922934e-04\n",
       "235     tfidf_235  5.922739e-04\n",
       "111     tfidf_111  5.893961e-04\n",
       "47       tfidf_47  5.805694e-04\n",
       "257     tfidf_257  5.761793e-04\n",
       "153     tfidf_153  5.741397e-04\n",
       "198     tfidf_198  5.683317e-04\n",
       "273     tfidf_273  5.571511e-04\n",
       "81       tfidf_81  5.561522e-04\n",
       "224     tfidf_224  5.512165e-04\n",
       "262     tfidf_262  5.431126e-04\n",
       "372     tfidf_372  5.387793e-04\n",
       "131     tfidf_131  5.356974e-04\n",
       "459    strawberry  5.349964e-04\n",
       "251     tfidf_251  5.323161e-04\n",
       "322     tfidf_322  5.320235e-04\n",
       "445          mint  5.270593e-04\n",
       "108     tfidf_108  5.241289e-04\n",
       "23       tfidf_23  5.184233e-04\n",
       "85       tfidf_85  5.167162e-04\n",
       "295     tfidf_295  5.102617e-04\n",
       "387     tfidf_387  5.062962e-04\n",
       "276     tfidf_276  5.048794e-04\n",
       "183     tfidf_183  4.977184e-04\n",
       "439         honey  4.916890e-04\n",
       "432        coffee  4.915536e-04\n",
       "152     tfidf_152  4.895532e-04\n",
       "34       tfidf_34  4.882663e-04\n",
       "351     tfidf_351  4.875925e-04\n",
       "136     tfidf_136  4.824327e-04\n",
       "458  spicy/herbal  4.810913e-04\n",
       "138     tfidf_138  4.774911e-04\n",
       "465      tropical  4.758970e-04\n",
       "38       tfidf_38  4.739867e-04\n",
       "344     tfidf_344  4.691804e-04\n",
       "148     tfidf_148  4.680109e-04\n",
       "118     tfidf_118  4.669889e-04\n",
       "154     tfidf_154  4.645613e-04\n",
       "188     tfidf_188  4.404268e-04\n",
       "140     tfidf_140  4.394600e-04\n",
       "346     tfidf_346  4.328386e-04\n",
       "202     tfidf_202  4.296194e-04\n",
       "307     tfidf_307  4.286460e-04\n",
       "176     tfidf_176  4.283623e-04\n",
       "446         nutty  4.282440e-04\n",
       "324     tfidf_324  4.269896e-04\n",
       "429      chemical  4.249747e-04\n",
       "250     tfidf_250  4.244818e-04\n",
       "139     tfidf_139  4.181302e-04\n",
       "76       tfidf_76  4.136827e-04\n",
       "318     tfidf_318  4.136020e-04\n",
       "452     pineapple  4.132366e-04\n",
       "333     tfidf_333  4.111515e-04\n",
       "172     tfidf_172  4.085369e-04\n",
       "352     tfidf_352  4.068301e-04\n",
       "468         woody  4.047003e-04\n",
       "246     tfidf_246  4.043562e-04\n",
       "287     tfidf_287  4.018444e-04\n",
       "300     tfidf_300  4.011521e-04\n",
       "369     tfidf_369  3.998142e-04\n",
       "286     tfidf_286  3.994207e-04\n",
       "331     tfidf_331  3.985976e-04\n",
       "91       tfidf_91  3.967347e-04\n",
       "380     tfidf_380  3.959573e-04\n",
       "68       tfidf_68  3.927282e-04\n",
       "87       tfidf_87  3.926979e-04\n",
       "25       tfidf_25  3.877245e-04\n",
       "99       tfidf_99  3.814785e-04\n",
       "220     tfidf_220  3.765645e-04\n",
       "213     tfidf_213  3.675786e-04\n",
       "120     tfidf_120  3.590062e-04\n",
       "163     tfidf_163  3.532811e-04\n",
       "443         mango  3.493032e-04\n",
       "13       tfidf_13  3.480004e-04\n",
       "133     tfidf_133  3.424657e-04\n",
       "272     tfidf_272  3.387797e-04\n",
       "274     tfidf_274  3.387179e-04\n",
       "97       tfidf_97  3.334303e-04\n",
       "40       tfidf_40  3.328668e-04\n",
       "294     tfidf_294  3.324656e-04\n",
       "334     tfidf_334  3.318281e-04\n",
       "186     tfidf_186  3.313026e-04\n",
       "269     tfidf_269  3.219545e-04\n",
       "102     tfidf_102  3.204834e-04\n",
       "450        pepper  3.161179e-04\n",
       "24       tfidf_24  3.123561e-04\n",
       "222     tfidf_222  3.109275e-04\n",
       "363     tfidf_363  3.081548e-04\n",
       "375     tfidf_375  3.042371e-04\n",
       "132     tfidf_132  3.040833e-04\n",
       "143     tfidf_143  3.024207e-04\n",
       "254     tfidf_254  2.988672e-04\n",
       "384     tfidf_384  2.948894e-04\n",
       "10       tfidf_10  2.944404e-04\n",
       "192     tfidf_192  2.937443e-04\n",
       "232     tfidf_232  2.919468e-04\n",
       "157     tfidf_157  2.907179e-04\n",
       "197     tfidf_197  2.906180e-04\n",
       "134     tfidf_134  2.901530e-04\n",
       "379     tfidf_379  2.869822e-04\n",
       "142     tfidf_142  2.846110e-04\n",
       "321     tfidf_321  2.840672e-04\n",
       "368     tfidf_368  2.825204e-04\n",
       "109     tfidf_109  2.786221e-04\n",
       "135     tfidf_135  2.773447e-04\n",
       "225     tfidf_225  2.753878e-04\n",
       "56       tfidf_56  2.690108e-04\n",
       "238     tfidf_238  2.683698e-04\n",
       "105     tfidf_105  2.655457e-04\n",
       "349     tfidf_349  2.645861e-04\n",
       "408      headache  2.624802e-04\n",
       "27       tfidf_27  2.582527e-04\n",
       "83       tfidf_83  2.575705e-04\n",
       "249     tfidf_249  2.551906e-04\n",
       "42       tfidf_42  2.550805e-04\n",
       "301     tfidf_301  2.525231e-04\n",
       "212     tfidf_212  2.524487e-04\n",
       "156     tfidf_156  2.507050e-04\n",
       "315     tfidf_315  2.504785e-04\n",
       "84       tfidf_84  2.499774e-04\n",
       "392       anxious  2.491529e-04\n",
       "86       tfidf_86  2.443064e-04\n",
       "52       tfidf_52  2.404076e-04\n",
       "165     tfidf_165  2.394581e-04\n",
       "229     tfidf_229  2.388180e-04\n",
       "290     tfidf_290  2.312942e-04\n",
       "412      paranoid  2.295150e-04\n",
       "310     tfidf_310  2.275509e-04\n",
       "218     tfidf_218  2.251383e-04\n",
       "12       tfidf_12  2.240218e-04\n",
       "422         apple  2.202757e-04\n",
       "62       tfidf_62  2.183465e-04\n",
       "33       tfidf_33  2.158266e-04\n",
       "75       tfidf_75  2.155714e-04\n",
       "313     tfidf_313  2.143188e-04\n",
       "302     tfidf_302  2.135991e-04\n",
       "115     tfidf_115  2.135905e-04\n",
       "31       tfidf_31  2.130852e-04\n",
       "288     tfidf_288  2.129532e-04\n",
       "127     tfidf_127  2.124902e-04\n",
       "308     tfidf_308  2.101537e-04\n",
       "365     tfidf_365  2.083552e-04\n",
       "423       apricot  2.049043e-04\n",
       "326     tfidf_326  2.047271e-04\n",
       "219     tfidf_219  2.046453e-04\n",
       "169     tfidf_169  2.030914e-04\n",
       "177     tfidf_177  1.993749e-04\n",
       "82       tfidf_82  1.976653e-04\n",
       "436         fruit  1.927144e-04\n",
       "332     tfidf_332  1.850956e-04\n",
       "284     tfidf_284  1.780000e-04\n",
       "223     tfidf_223  1.746962e-04\n",
       "204     tfidf_204  1.745986e-04\n",
       "74       tfidf_74  1.695443e-04\n",
       "59       tfidf_59  1.693556e-04\n",
       "8         tfidf_8  1.645294e-04\n",
       "421       ammonia  1.641431e-04\n",
       "359     tfidf_359  1.639583e-04\n",
       "185     tfidf_185  1.624554e-04\n",
       "255     tfidf_255  1.622624e-04\n",
       "216     tfidf_216  1.619164e-04\n",
       "236     tfidf_236  1.617591e-04\n",
       "228     tfidf_228  1.613820e-04\n",
       "464          tree  1.583777e-04\n",
       "100     tfidf_100  1.565164e-04\n",
       "243     tfidf_243  1.563617e-04\n",
       "226     tfidf_226  1.557064e-04\n",
       "327     tfidf_327  1.549318e-04\n",
       "196     tfidf_196  1.546602e-04\n",
       "317     tfidf_317  1.506873e-04\n",
       "356     tfidf_356  1.475036e-04\n",
       "18       tfidf_18  1.453571e-04\n",
       "77       tfidf_77  1.443775e-04\n",
       "268     tfidf_268  1.438411e-04\n",
       "63       tfidf_63  1.396174e-04\n",
       "440      lavender  1.378801e-04\n",
       "305     tfidf_305  1.375231e-04\n",
       "279     tfidf_279  1.283970e-04\n",
       "306     tfidf_306  1.272154e-04\n",
       "266     tfidf_266  1.245771e-04\n",
       "180     tfidf_180  1.230920e-04\n",
       "55       tfidf_55  1.196112e-04\n",
       "92       tfidf_92  1.188015e-04\n",
       "299     tfidf_299  1.132286e-04\n",
       "191     tfidf_191  1.106892e-04\n",
       "72       tfidf_72  1.104230e-04\n",
       "174     tfidf_174  1.073140e-04\n",
       "292     tfidf_292  1.034924e-04\n",
       "378     tfidf_378  1.012591e-04\n",
       "339     tfidf_339  9.899493e-05\n",
       "66       tfidf_66  9.780627e-05\n",
       "330     tfidf_330  9.696685e-05\n",
       "242     tfidf_242  9.469317e-05\n",
       "461           tar  9.406651e-05\n",
       "114     tfidf_114  8.555617e-05\n",
       "335     tfidf_335  8.392827e-05\n",
       "147     tfidf_147  8.340948e-05\n",
       "182     tfidf_182  8.245169e-05\n",
       "386     tfidf_386  7.696653e-05\n",
       "150     tfidf_150  7.514844e-05\n",
       "462           tea  7.331578e-05\n",
       "113     tfidf_113  7.194635e-05\n",
       "438    grapefruit  6.512872e-05\n",
       "377     tfidf_377  6.182848e-05\n",
       "296     tfidf_296  5.757491e-05\n",
       "449          pear  5.744845e-05\n",
       "425   blue cheese  5.511503e-05\n",
       "448         peach  5.351249e-05\n",
       "391       anxiety  5.280380e-05\n",
       "364     tfidf_364  5.155945e-05\n",
       "50       tfidf_50  5.103802e-05\n",
       "209     tfidf_209  5.032478e-05\n",
       "261     tfidf_261  4.375440e-05\n",
       "51       tfidf_51  4.080484e-05\n",
       "430      chestnut  3.895310e-05\n",
       "293     tfidf_293  3.826159e-05\n",
       "427        butter  3.609594e-05\n",
       "396    depression  3.171211e-05\n",
       "241     tfidf_241  2.911594e-05\n",
       "455          rose  2.879680e-05\n",
       "444       menthol  1.755792e-05\n",
       "410     migraines  1.626353e-05\n",
       "463       tobacco  1.573209e-05\n",
       "467        violet  1.468041e-05\n",
       "453          plum  1.000273e-05\n",
       "416    spasticity  3.051550e-07\n",
       "401      epilepsy  3.325426e-10\n",
       "403  eye pressure  6.410554e-11\n",
       "394     arthritis  2.698316e-11\n",
       "404       fatigue  1.122879e-11\n",
       "411          pain  0.000000e+00\n",
       "414      seizures  0.000000e+00\n",
       "417        stress  0.000000e+00"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.set_option('display.max_rows', df_feat_ranked.shape[0]+1)\n",
    "df_feat_ranked"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/louispandu/anaconda3/lib/python3.10/site-packages/sklearn/feature_selection/_from_model.py:357: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  self.estimator_.fit(X, y, **fit_params)\n"
     ]
    }
   ],
   "source": [
    "selector = SelectFromModel(rfreg).fit(X_train1, y_train1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1.66244762e-03, 1.73178923e-03, 8.05650321e-04, 8.00737360e-04,\n",
       "       1.93284289e-03, 1.57949373e-03, 1.73342926e-03, 2.29645664e-03,\n",
       "       1.30645195e-04, 8.30030903e-04, 3.46459833e-04, 1.06446480e-03,\n",
       "       3.10134872e-04, 4.28724288e-04, 9.15189010e-04, 1.51933729e-03,\n",
       "       1.52502099e-03, 4.22243751e-03, 1.91468765e-04, 6.90930136e-04,\n",
       "       1.28408496e-03, 1.49283495e-03, 9.08053583e-03, 3.55993613e-04,\n",
       "       3.48011824e-04, 4.21089516e-04, 5.82985927e-04, 2.32454857e-04,\n",
       "       7.87256687e-04, 1.73778864e-03, 6.90932709e-03, 1.74058387e-04,\n",
       "       1.73572776e-03, 2.21437423e-04, 4.89305190e-04, 5.62891353e-04,\n",
       "       6.57111922e-04, 1.64188520e-03, 6.28404032e-04, 1.34094409e-03,\n",
       "       2.70662214e-04, 8.91569453e-04, 2.15990285e-04, 2.86607763e-03,\n",
       "       1.55928591e-03, 9.68556385e-04, 1.66447905e-03, 6.35219596e-04,\n",
       "       1.89552982e-03, 2.08999192e-03, 9.97866751e-05, 3.83066497e-05,\n",
       "       1.98417227e-04, 1.22666815e-03, 1.09072205e-03, 1.03465476e-04,\n",
       "       2.63748657e-04, 1.19730657e-03, 1.50107383e-03, 1.27050513e-04,\n",
       "       6.80312464e-04, 1.41268625e-03, 2.17569866e-04, 1.23787002e-04,\n",
       "       9.48558591e-04, 2.53023187e-03, 1.13867867e-04, 4.32424813e-04,\n",
       "       2.56327600e-04, 6.91466288e-03, 5.98292747e-04, 1.48415381e-03,\n",
       "       1.28534106e-04, 2.25989386e-03, 1.24956936e-04, 2.02826007e-04,\n",
       "       4.30154643e-04, 1.91450972e-04, 1.73135532e-03, 6.14362839e-04,\n",
       "       1.02226659e-03, 3.74282088e-04, 2.18318529e-04, 2.31266818e-04,\n",
       "       2.78759148e-04, 5.76211181e-04, 3.06195776e-04, 5.36058189e-04,\n",
       "       1.66994692e-03, 3.46214920e-03, 1.03135531e-03, 4.49144339e-04,\n",
       "       9.34670823e-05, 4.81054648e-03, 8.19304580e-04, 5.38386878e-03,\n",
       "       9.33788571e-04, 2.92536179e-04, 1.57033678e-03, 2.81511639e-04,\n",
       "       1.71771217e-04, 8.89558241e-04, 3.68869970e-04, 9.25316328e-04,\n",
       "       2.21272413e-03, 2.29485482e-04, 8.61277408e-04, 1.58515787e-03,\n",
       "       5.93493609e-04, 2.68047624e-04, 6.10064143e-04, 3.08988487e-04,\n",
       "       9.20704392e-04, 8.38312696e-05, 7.49708848e-05, 2.21965810e-04,\n",
       "       6.99433550e-04, 8.41168619e-03, 4.60566138e-04, 2.29558907e-03,\n",
       "       3.03489984e-04, 8.55069327e-03, 2.06526717e-03, 9.33608138e-04,\n",
       "       6.61640270e-04, 6.88960255e-04, 1.55239816e-03, 1.63539927e-04,\n",
       "       3.57522483e-03, 2.08256613e-03, 5.56208128e-04, 5.90412575e-04,\n",
       "       2.86432002e-04, 3.15546309e-04, 2.86962056e-04, 2.28936979e-04,\n",
       "       5.11376501e-04, 6.92433050e-04, 5.04156014e-04, 4.40339482e-04,\n",
       "       4.83942206e-04, 4.31529652e-03, 2.92202294e-04, 2.92913289e-04,\n",
       "       5.08727365e-03, 1.23904709e-02, 4.99832188e-04, 8.36035437e-05,\n",
       "       4.45215509e-04, 1.21002566e-02, 7.79608766e-05, 1.17908859e-03,\n",
       "       5.07742766e-04, 5.39670582e-04, 4.56322502e-04, 3.48431022e-03,\n",
       "       2.18731152e-04, 2.81786738e-04, 1.57146617e-03, 8.32430363e-04,\n",
       "       9.38537081e-04, 4.40876435e-03, 1.44814222e-03, 3.29915811e-04,\n",
       "       6.09505429e-04, 2.65492350e-04, 1.04420725e-03, 1.37586916e-03,\n",
       "       2.02739000e-02, 1.78604953e-04, 7.13405497e-04, 4.62994407e-04,\n",
       "       4.69715022e-04, 1.80643178e-03, 1.23385661e-04, 2.83562248e-03,\n",
       "       4.43916350e-04, 1.56154928e-04, 6.11220242e-03, 1.03484980e-03,\n",
       "       1.55766808e-04, 6.78191051e-04, 1.57125974e-04, 7.17724667e-04,\n",
       "       6.09933188e-04, 1.43566590e-04, 3.61246209e-04, 7.64129417e-03,\n",
       "       4.04988390e-04, 8.85500598e-03, 4.69950629e-04, 7.07068261e-05,\n",
       "       3.19732531e-04, 3.90057971e-03, 1.65306593e-03, 2.68611973e-03,\n",
       "       1.64520036e-04, 3.13556375e-04, 5.69765610e-04, 4.77219274e-03,\n",
       "       8.14180147e-04, 9.10685688e-04, 4.70465863e-04, 7.88230894e-04,\n",
       "       1.75704137e-04, 2.26452326e-03, 1.39074580e-03, 5.39808743e-03,\n",
       "       8.36872555e-04, 4.53547362e-05, 7.95700966e-03, 3.54127174e-03,\n",
       "       3.67518523e-04, 4.18637864e-04, 7.34679768e-04, 4.62495945e-04,\n",
       "       1.33113030e-04, 1.40504425e-03, 2.06121727e-04, 2.25085095e-04,\n",
       "       4.57374014e-04, 1.89496486e-03, 3.38181561e-04, 1.39350282e-04,\n",
       "       6.75746227e-04, 3.17713099e-04, 2.20653615e-04, 1.61511181e-03,\n",
       "       1.06328290e-04, 2.70225973e-04, 7.18771521e-04, 8.09959434e-04,\n",
       "       1.70432881e-04, 6.04220312e-04, 1.28596042e-03, 5.96006901e-04,\n",
       "       1.38536096e-04, 1.14998310e-03, 2.05052452e-04, 1.29307903e-02,\n",
       "       5.25986983e-04, 5.04292188e-05, 1.05046182e-04, 1.64933004e-04,\n",
       "       1.20290889e-03, 5.83982027e-03, 3.96659128e-04, 1.94817910e-03,\n",
       "       2.10917882e-03, 2.23020826e-04, 2.49565120e-04, 4.88634403e-04,\n",
       "       9.18985325e-04, 1.31791057e-02, 3.45439728e-04, 1.82436665e-04,\n",
       "       9.51537649e-04, 8.74739498e-04, 7.02524907e-03, 1.03976873e-03,\n",
       "       2.28019942e-03, 1.04560759e-04, 5.14171443e-04, 9.50906324e-04,\n",
       "       7.55040328e-04, 1.30504343e-03, 1.45223240e-04, 8.66830173e-04,\n",
       "       1.29565790e-04, 3.33349964e-04, 9.76043754e-04, 6.65806071e-04,\n",
       "       2.97126583e-04, 5.03665771e-04, 3.28726368e-04, 7.48664310e-04,\n",
       "       5.23929563e-04, 6.52954962e-04, 1.31701404e-03, 1.20526765e-04,\n",
       "       6.39202694e-04, 4.53636739e-03, 2.17612823e-03, 2.54949744e-03,\n",
       "       1.84299087e-04, 4.47088213e-03, 3.86777255e-04, 3.56644047e-04,\n",
       "       2.28960399e-04, 8.02871763e-04, 1.80268071e-04, 9.34838941e-04,\n",
       "       1.03973737e-04, 4.44067883e-05, 3.33563441e-04, 5.26203864e-04,\n",
       "       2.56683921e-05, 1.00927542e-03, 6.55989347e-04, 3.02703532e-04,\n",
       "       6.31800096e-04, 2.67308093e-04, 1.68149801e-04, 1.07559108e-03,\n",
       "       1.46371151e-03, 9.51235785e-05, 1.60753048e-04, 4.48990653e-04,\n",
       "       1.74775879e-04, 6.51911184e-03, 1.78596092e-04, 6.91200636e-04,\n",
       "       6.99985235e-03, 2.03137569e-04, 9.83598819e-03, 2.81958869e-04,\n",
       "       9.81019875e-04, 1.41600183e-04, 5.61657419e-04, 8.47330439e-04,\n",
       "       1.04107947e-03, 3.00471226e-04, 5.17379104e-04, 7.09375789e-04,\n",
       "       4.28220217e-04, 1.09669877e-03, 2.11822113e-04, 1.87859905e-04,\n",
       "       8.81381418e-04, 1.62712331e-02, 1.64660642e-04, 3.88079031e-04,\n",
       "       2.13527937e-04, 4.32160140e-04, 4.41953300e-04, 7.24352772e-05,\n",
       "       7.78770312e-04, 4.16908668e-03, 1.02751608e-03, 1.01286942e-04,\n",
       "       9.26152420e-03, 1.59969075e-03, 1.66758252e-03, 1.89883294e-03,\n",
       "       3.74748158e-04, 1.42587651e-02, 4.50090670e-04, 1.08298733e-03,\n",
       "       2.18977634e-03, 2.38889428e-04, 1.51543140e-03, 4.99449047e-04,\n",
       "       3.97477990e-04, 4.13575334e-03, 1.57736120e-03, 3.61629369e-03,\n",
       "       1.22636992e-04, 2.94331896e-03, 5.11719909e-04, 2.01894161e-04,\n",
       "       6.62334798e-04, 4.15794066e-03, 6.70155058e-03, 2.73637592e-04,\n",
       "       6.22827517e-05, 1.52623617e-04, 8.26686139e-03, 1.31864637e-02,\n",
       "       2.21668064e-04, 4.62632686e-04, 5.89075462e-04, 1.82342531e-03,\n",
       "       4.81986177e-04, 6.36106931e-04, 1.71330749e-03, 3.19062300e-04,\n",
       "       1.91143259e-03, 6.06858858e-05, 1.39610189e-04, 2.57361675e-04,\n",
       "       4.56956837e-04, 9.32375042e-03, 3.52085141e-03, 7.06388235e-04,\n",
       "       3.09730295e-04, 3.90263892e-03, 7.65057060e-05, 4.79082534e-04,\n",
       "       2.74377022e-02, 8.03710064e-02, 1.35532962e-02, 3.79668131e-05,\n",
       "       2.51026776e-04, 9.55255388e-04, 0.00000000e+00, 1.61994040e-03,\n",
       "       3.51632185e-05, 7.22924748e-04, 4.95643879e-03, 3.73118871e-03,\n",
       "       2.37044543e-03, 2.34876290e-10, 6.34956445e-03, 7.56541979e-11,\n",
       "       7.67764644e-11, 2.82190054e-03, 1.40782815e-03, 7.68071461e-03,\n",
       "       1.52957932e-04, 1.56392589e-03, 2.43107674e-05, 1.12266182e-11,\n",
       "       2.09323918e-04, 6.05304868e-03, 2.00281060e-10, 1.62546823e-03,\n",
       "       0.00000000e+00, 0.00000000e+00, 2.18833831e-03, 1.37524818e-03,\n",
       "       5.44798240e-03, 1.22837699e-04, 2.18118255e-04, 1.72555015e-04,\n",
       "       1.69351491e-02, 4.42592560e-05, 2.00823805e-03, 3.62313707e-05,\n",
       "       1.10337880e-01, 1.51753097e-04, 5.95335639e-05, 1.99458199e-03,\n",
       "       4.99698859e-04, 1.76799950e-02, 3.83418221e-03, 7.53639161e-04,\n",
       "       1.50672399e-04, 1.81195394e-03, 6.65227693e-05, 5.58445166e-04,\n",
       "       1.44517158e-04, 1.35559322e-02, 5.66819048e-03, 3.72696448e-04,\n",
       "       2.03684310e-05, 3.52919078e-04, 3.97449969e-04, 1.35126369e-02,\n",
       "       4.09029196e-05, 3.05833430e-05, 3.38440569e-04, 7.85160170e-04,\n",
       "       5.09361678e-04, 1.49619814e-05, 1.21884348e-03, 4.49557487e-05,\n",
       "       1.06112421e-03, 1.30038893e-03, 4.63884742e-04, 4.64127901e-04,\n",
       "       2.95315130e-03, 7.58128145e-05, 5.52979695e-05, 3.38616995e-05,\n",
       "       1.49159010e-04, 5.46021630e-04, 3.75479875e-02, 9.02957143e-06,\n",
       "       3.65185462e-04])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "selector.estimator_.feature_importances_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0021321961620469083"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "selector.threshold_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "mask = selector.get_support()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([False, False, False, False, False, False, False,  True, False,\n",
       "       False, False, False, False, False, False, False, False,  True,\n",
       "       False, False, False, False,  True, False, False, False, False,\n",
       "       False, False, False,  True, False, False, False, False, False,\n",
       "       False, False, False, False, False, False, False,  True, False,\n",
       "       False, False, False, False, False, False, False, False, False,\n",
       "       False, False, False, False, False, False, False, False, False,\n",
       "       False, False,  True, False, False, False,  True, False, False,\n",
       "       False,  True, False, False, False, False, False, False, False,\n",
       "       False, False, False, False, False, False, False, False,  True,\n",
       "       False, False, False,  True, False,  True, False, False, False,\n",
       "       False, False, False, False, False,  True, False, False, False,\n",
       "       False, False, False, False, False, False, False, False, False,\n",
       "        True, False,  True, False,  True, False, False, False, False,\n",
       "       False, False,  True, False, False, False, False, False, False,\n",
       "       False, False, False, False, False, False,  True, False, False,\n",
       "        True,  True, False, False, False,  True, False, False, False,\n",
       "       False, False,  True, False, False, False, False, False,  True,\n",
       "       False, False, False, False, False, False,  True, False, False,\n",
       "       False, False, False, False,  True, False, False,  True, False,\n",
       "       False, False, False, False, False, False, False,  True, False,\n",
       "        True, False, False, False,  True, False,  True, False, False,\n",
       "       False,  True, False, False, False, False, False,  True, False,\n",
       "        True, False, False,  True,  True, False, False, False, False,\n",
       "       False, False, False, False, False, False, False, False, False,\n",
       "       False, False, False, False, False, False, False, False, False,\n",
       "       False, False, False, False, False,  True, False, False, False,\n",
       "       False, False,  True, False, False, False, False, False, False,\n",
       "       False,  True, False, False, False, False,  True, False,  True,\n",
       "       False, False, False, False, False, False, False, False, False,\n",
       "       False, False, False, False, False, False, False, False, False,\n",
       "       False, False,  True,  True,  True, False,  True, False, False,\n",
       "       False, False, False, False, False, False, False, False, False,\n",
       "       False, False, False, False, False, False, False, False, False,\n",
       "       False, False, False,  True, False, False,  True, False,  True,\n",
       "       False, False, False, False, False, False, False, False, False,\n",
       "       False, False, False, False, False,  True, False, False, False,\n",
       "       False, False, False, False,  True, False, False,  True, False,\n",
       "       False, False, False,  True, False, False,  True, False, False,\n",
       "       False, False,  True, False,  True, False,  True, False, False,\n",
       "       False,  True,  True, False, False, False,  True,  True, False,\n",
       "       False, False, False, False, False, False, False, False, False,\n",
       "       False, False, False,  True,  True, False, False,  True, False,\n",
       "       False,  True,  True,  True, False, False, False, False, False,\n",
       "       False, False,  True,  True,  True, False,  True, False, False,\n",
       "        True, False,  True, False, False, False, False, False,  True,\n",
       "       False, False, False, False,  True, False,  True, False, False,\n",
       "       False,  True, False, False, False,  True, False, False, False,\n",
       "       False,  True,  True, False, False, False, False, False, False,\n",
       "        True,  True, False, False, False, False,  True, False, False,\n",
       "       False, False, False, False, False, False, False, False, False,\n",
       "       False,  True, False, False, False, False, False,  True, False,\n",
       "       False])"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "selected_features = X.columns[mask]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tfidf_7</th>\n",
       "      <th>tfidf_17</th>\n",
       "      <th>tfidf_22</th>\n",
       "      <th>tfidf_30</th>\n",
       "      <th>tfidf_43</th>\n",
       "      <th>tfidf_65</th>\n",
       "      <th>tfidf_69</th>\n",
       "      <th>tfidf_73</th>\n",
       "      <th>tfidf_89</th>\n",
       "      <th>tfidf_93</th>\n",
       "      <th>...</th>\n",
       "      <th>uplifted</th>\n",
       "      <th>berry</th>\n",
       "      <th>cheese</th>\n",
       "      <th>diesel</th>\n",
       "      <th>earthy</th>\n",
       "      <th>lemon</th>\n",
       "      <th>lime</th>\n",
       "      <th>orange</th>\n",
       "      <th>sweet</th>\n",
       "      <th>vanilla</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.206994</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.206994</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.206994</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.206994</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.206994</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>74995</th>\n",
       "      <td>0.261458</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.256018</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.238134</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>74996</th>\n",
       "      <td>0.261458</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.256018</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.238134</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>74997</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.108601</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>74998</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>74999</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>75000 rows × 82 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        tfidf_7  tfidf_17  tfidf_22  tfidf_30  tfidf_43  tfidf_65  tfidf_69  \\\n",
       "0      0.000000       0.0       0.0  0.000000       0.0  0.206994       0.0   \n",
       "1      0.000000       0.0       0.0  0.000000       0.0  0.206994       0.0   \n",
       "2      0.000000       0.0       0.0  0.000000       0.0  0.206994       0.0   \n",
       "3      0.000000       0.0       0.0  0.000000       0.0  0.206994       0.0   \n",
       "4      0.000000       0.0       0.0  0.000000       0.0  0.206994       0.0   \n",
       "...         ...       ...       ...       ...       ...       ...       ...   \n",
       "74995  0.261458       0.0       0.0  0.256018       0.0  0.000000       0.0   \n",
       "74996  0.261458       0.0       0.0  0.256018       0.0  0.000000       0.0   \n",
       "74997  0.000000       0.0       0.0  0.000000       0.0  0.000000       0.0   \n",
       "74998  0.000000       0.0       0.0  0.000000       0.0  0.000000       0.0   \n",
       "74999  0.000000       0.0       0.0  0.000000       0.0  0.000000       0.0   \n",
       "\n",
       "       tfidf_73  tfidf_89  tfidf_93  ...  uplifted  berry  cheese  diesel  \\\n",
       "0      0.000000       0.0  0.000000  ...         0      0       0       0   \n",
       "1      0.000000       0.0  0.000000  ...         0      0       0       0   \n",
       "2      0.000000       0.0  0.000000  ...         0      0       0       0   \n",
       "3      0.000000       0.0  0.000000  ...         0      0       0       0   \n",
       "4      0.000000       0.0  0.000000  ...         0      0       0       0   \n",
       "...         ...       ...       ...  ...       ...    ...     ...     ...   \n",
       "74995  0.238134       0.0  0.000000  ...         0      0       0       0   \n",
       "74996  0.238134       0.0  0.000000  ...         0      0       0       0   \n",
       "74997  0.000000       0.0  0.108601  ...         0      0       0       0   \n",
       "74998  0.000000       0.0  0.000000  ...         0      0       0       0   \n",
       "74999  0.000000       0.0  0.000000  ...         0      0       0       0   \n",
       "\n",
       "       earthy  lemon  lime  orange  sweet  vanilla  \n",
       "0           0      0     0       0      0        0  \n",
       "1           0      0     0       0      0        0  \n",
       "2           0      0     0       0      0        0  \n",
       "3           0      0     0       0      0        0  \n",
       "4           0      0     0       0      0        0  \n",
       "...       ...    ...   ...     ...    ...      ...  \n",
       "74995       0      0     0       0      0        0  \n",
       "74996       0      0     0       0      0        0  \n",
       "74997       0      0     0       0      0        0  \n",
       "74998       0      0     0       0      0        0  \n",
       "74999       0      0     0       0      0        0  \n",
       "\n",
       "[75000 rows x 82 columns]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "selected_X = df_rf[selected_features]\n",
    "selected_X"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train test split (after Feature Selection)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['selected_X_rf_tfidf_terpi.pkl']"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import joblib\n",
    "\n",
    "joblib.dump(selector, \"selector_rf_tfidf_terpi.pkl\")\n",
    "joblib.dump(selected_X, \"selected_X_rf_tfidf_terpi.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(selected_X, y, random_state=1, test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train1, X_val, y_train1, y_val = train_test_split(X_train, y_train, random_state=1, test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/ns/m5pnr0211w91v02hpv22958m0000gn/T/ipykernel_88675/3758305.py:1: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  rfreg.fit(X_train1, y_train1)\n"
     ]
    }
   ],
   "source": [
    "rfreg.fit(X_train1, y_train1)\n",
    "y_pred_rfreg = rfreg.predict(X_val)\n",
    "y_pred_rfreg_r2 = rfreg.predict(X_train1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.030178528590660326"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mean_absolute_error(y_val, y_pred_rfreg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.006543560637149343"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mean_squared_error(y_val, y_pred_rfreg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.08089227798219892"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mean_squared_error(y_val, y_pred_rfreg, squared = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9854215709237236"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#train\n",
    "r2_score(y_train1, y_pred_rfreg_r2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.944790849376006"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#val\n",
    "r2_score(y_val, y_pred_rfreg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hyperparameter Tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "parameters = {'max_depth': [None, 10, 50, 100],\n",
    "              'max_features': ['auto', 'sqrt'],\n",
    "              'min_samples_leaf': [1, 2, 4],\n",
    "              'min_samples_split': [2, 5, 10],\n",
    "              'n_estimators': [100, 300, 500]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "rscv = RandomizedSearchCV(rfreg,  \n",
    "                     parameters,   \n",
    "                     cv=5, \n",
    "                     scoring='neg_mean_absolute_error',\n",
    "                     n_jobs = -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/louispandu/anaconda3/lib/python3.10/site-packages/sklearn/model_selection/_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/Users/louispandu/anaconda3/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
      "  warn(\n",
      "/Users/louispandu/anaconda3/lib/python3.10/site-packages/sklearn/model_selection/_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/Users/louispandu/anaconda3/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
      "  warn(\n",
      "/Users/louispandu/anaconda3/lib/python3.10/site-packages/sklearn/model_selection/_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/Users/louispandu/anaconda3/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
      "  warn(\n",
      "/Users/louispandu/anaconda3/lib/python3.10/site-packages/sklearn/model_selection/_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/Users/louispandu/anaconda3/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
      "  warn(\n",
      "/Users/louispandu/anaconda3/lib/python3.10/site-packages/sklearn/model_selection/_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/Users/louispandu/anaconda3/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
      "  warn(\n",
      "/Users/louispandu/anaconda3/lib/python3.10/site-packages/sklearn/model_selection/_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/Users/louispandu/anaconda3/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
      "  warn(\n",
      "/Users/louispandu/anaconda3/lib/python3.10/site-packages/sklearn/model_selection/_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/Users/louispandu/anaconda3/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
      "  warn(\n",
      "/Users/louispandu/anaconda3/lib/python3.10/site-packages/sklearn/model_selection/_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/Users/louispandu/anaconda3/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
      "  warn(\n",
      "/Users/louispandu/anaconda3/lib/python3.10/site-packages/sklearn/model_selection/_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/Users/louispandu/anaconda3/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
      "  warn(\n",
      "/Users/louispandu/anaconda3/lib/python3.10/site-packages/sklearn/model_selection/_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/Users/louispandu/anaconda3/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
      "  warn(\n",
      "/Users/louispandu/anaconda3/lib/python3.10/site-packages/sklearn/model_selection/_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/Users/louispandu/anaconda3/lib/python3.10/site-packages/sklearn/model_selection/_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/Users/louispandu/anaconda3/lib/python3.10/site-packages/sklearn/model_selection/_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/Users/louispandu/anaconda3/lib/python3.10/site-packages/sklearn/model_selection/_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/Users/louispandu/anaconda3/lib/python3.10/site-packages/sklearn/model_selection/_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/Users/louispandu/anaconda3/lib/python3.10/site-packages/sklearn/model_selection/_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/Users/louispandu/anaconda3/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
      "  warn(\n",
      "/Users/louispandu/anaconda3/lib/python3.10/site-packages/joblib/externals/loky/process_executor.py:702: UserWarning: A worker stopped while some jobs were given to the executor. This can be caused by a too short worker timeout or by a memory leak.\n",
      "  warnings.warn(\n",
      "/Users/louispandu/anaconda3/lib/python3.10/site-packages/sklearn/model_selection/_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/Users/louispandu/anaconda3/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
      "  warn(\n",
      "/Users/louispandu/anaconda3/lib/python3.10/site-packages/sklearn/model_selection/_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/Users/louispandu/anaconda3/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
      "  warn(\n",
      "/Users/louispandu/anaconda3/lib/python3.10/site-packages/sklearn/model_selection/_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/Users/louispandu/anaconda3/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
      "  warn(\n",
      "/Users/louispandu/anaconda3/lib/python3.10/site-packages/sklearn/model_selection/_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/Users/louispandu/anaconda3/lib/python3.10/site-packages/sklearn/model_selection/_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/Users/louispandu/anaconda3/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
      "  warn(\n",
      "/Users/louispandu/anaconda3/lib/python3.10/site-packages/sklearn/model_selection/_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/Users/louispandu/anaconda3/lib/python3.10/site-packages/sklearn/model_selection/_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/Users/louispandu/anaconda3/lib/python3.10/site-packages/sklearn/model_selection/_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/Users/louispandu/anaconda3/lib/python3.10/site-packages/sklearn/model_selection/_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/Users/louispandu/anaconda3/lib/python3.10/site-packages/sklearn/model_selection/_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/Users/louispandu/anaconda3/lib/python3.10/site-packages/sklearn/model_selection/_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/Users/louispandu/anaconda3/lib/python3.10/site-packages/sklearn/model_selection/_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/Users/louispandu/anaconda3/lib/python3.10/site-packages/sklearn/model_selection/_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/Users/louispandu/anaconda3/lib/python3.10/site-packages/sklearn/model_selection/_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/Users/louispandu/anaconda3/lib/python3.10/site-packages/sklearn/model_selection/_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/Users/louispandu/anaconda3/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
      "  warn(\n",
      "/Users/louispandu/anaconda3/lib/python3.10/site-packages/sklearn/model_selection/_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/Users/louispandu/anaconda3/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
      "  warn(\n",
      "/Users/louispandu/anaconda3/lib/python3.10/site-packages/sklearn/model_selection/_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/Users/louispandu/anaconda3/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
      "  warn(\n",
      "/Users/louispandu/anaconda3/lib/python3.10/site-packages/sklearn/model_selection/_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/Users/louispandu/anaconda3/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
      "  warn(\n",
      "/Users/louispandu/anaconda3/lib/python3.10/site-packages/sklearn/model_selection/_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/Users/louispandu/anaconda3/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
      "  warn(\n",
      "/Users/louispandu/anaconda3/lib/python3.10/site-packages/sklearn/model_selection/_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/Users/louispandu/anaconda3/lib/python3.10/site-packages/sklearn/model_selection/_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/Users/louispandu/anaconda3/lib/python3.10/site-packages/sklearn/model_selection/_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/Users/louispandu/anaconda3/lib/python3.10/site-packages/sklearn/model_selection/_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/Users/louispandu/anaconda3/lib/python3.10/site-packages/sklearn/model_selection/_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/Users/louispandu/anaconda3/lib/python3.10/site-packages/sklearn/model_selection/_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/Users/louispandu/anaconda3/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
      "  warn(\n",
      "/Users/louispandu/anaconda3/lib/python3.10/site-packages/sklearn/model_selection/_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/Users/louispandu/anaconda3/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
      "  warn(\n",
      "/Users/louispandu/anaconda3/lib/python3.10/site-packages/sklearn/model_selection/_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/Users/louispandu/anaconda3/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
      "  warn(\n",
      "/Users/louispandu/anaconda3/lib/python3.10/site-packages/sklearn/model_selection/_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/Users/louispandu/anaconda3/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
      "  warn(\n",
      "/Users/louispandu/anaconda3/lib/python3.10/site-packages/sklearn/model_selection/_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/Users/louispandu/anaconda3/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
      "  warn(\n",
      "/Users/louispandu/anaconda3/lib/python3.10/site-packages/sklearn/model_selection/_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/Users/louispandu/anaconda3/lib/python3.10/site-packages/sklearn/model_selection/_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/Users/louispandu/anaconda3/lib/python3.10/site-packages/sklearn/model_selection/_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/Users/louispandu/anaconda3/lib/python3.10/site-packages/sklearn/model_selection/_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/Users/louispandu/anaconda3/lib/python3.10/site-packages/sklearn/model_selection/_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/Users/louispandu/anaconda3/lib/python3.10/site-packages/sklearn/model_selection/_search.py:909: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  self.best_estimator_.fit(X, y, **fit_params)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-2 {color: black;background-color: white;}#sk-container-id-2 pre{padding: 0;}#sk-container-id-2 div.sk-toggleable {background-color: white;}#sk-container-id-2 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-2 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-2 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-2 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-2 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-2 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-2 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-2 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-2 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-2 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-2 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-2 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-2 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-2 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-2 div.sk-item {position: relative;z-index: 1;}#sk-container-id-2 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-2 div.sk-item::before, #sk-container-id-2 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-2 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-2 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-2 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-2 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-2 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-2 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-2 div.sk-label-container {text-align: center;}#sk-container-id-2 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-2 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-2\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>RandomizedSearchCV(cv=5, estimator=RandomForestRegressor(), n_jobs=-1,\n",
       "                   param_distributions={&#x27;max_depth&#x27;: [None, 10, 50, 100],\n",
       "                                        &#x27;max_features&#x27;: [&#x27;auto&#x27;, &#x27;sqrt&#x27;],\n",
       "                                        &#x27;min_samples_leaf&#x27;: [1, 2, 4],\n",
       "                                        &#x27;min_samples_split&#x27;: [2, 5, 10],\n",
       "                                        &#x27;n_estimators&#x27;: [100, 300, 500]},\n",
       "                   scoring=&#x27;neg_mean_absolute_error&#x27;)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" ><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">RandomizedSearchCV</label><div class=\"sk-toggleable__content\"><pre>RandomizedSearchCV(cv=5, estimator=RandomForestRegressor(), n_jobs=-1,\n",
       "                   param_distributions={&#x27;max_depth&#x27;: [None, 10, 50, 100],\n",
       "                                        &#x27;max_features&#x27;: [&#x27;auto&#x27;, &#x27;sqrt&#x27;],\n",
       "                                        &#x27;min_samples_leaf&#x27;: [1, 2, 4],\n",
       "                                        &#x27;min_samples_split&#x27;: [2, 5, 10],\n",
       "                                        &#x27;n_estimators&#x27;: [100, 300, 500]},\n",
       "                   scoring=&#x27;neg_mean_absolute_error&#x27;)</pre></div></div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-3\" type=\"checkbox\" ><label for=\"sk-estimator-id-3\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">estimator: RandomForestRegressor</label><div class=\"sk-toggleable__content\"><pre>RandomForestRegressor()</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-4\" type=\"checkbox\" ><label for=\"sk-estimator-id-4\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">RandomForestRegressor</label><div class=\"sk-toggleable__content\"><pre>RandomForestRegressor()</pre></div></div></div></div></div></div></div></div></div></div>"
      ],
      "text/plain": [
       "RandomizedSearchCV(cv=5, estimator=RandomForestRegressor(), n_jobs=-1,\n",
       "                   param_distributions={'max_depth': [None, 10, 50, 100],\n",
       "                                        'max_features': ['auto', 'sqrt'],\n",
       "                                        'min_samples_leaf': [1, 2, 4],\n",
       "                                        'min_samples_split': [2, 5, 10],\n",
       "                                        'n_estimators': [100, 300, 500]},\n",
       "                   scoring='neg_mean_absolute_error')"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rscv.fit(X_train1, y_train1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'n_estimators': 500,\n",
       " 'min_samples_split': 2,\n",
       " 'min_samples_leaf': 1,\n",
       " 'max_features': 'sqrt',\n",
       " 'max_depth': None}"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rscv.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['rscv_rf_tfidf_best_params_terpi.pkl']"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "joblib.dump(rscv, \"rscv_rf_tfidf_terpi.pkl\")\n",
    "joblib.dump(rscv.best_params_, \"rscv_rf_tfidf_best_params_terpi.pkl\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "RF (after Hyperparameter Tuning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/ns/m5pnr0211w91v02hpv22958m0000gn/T/ipykernel_88675/3191280092.py:2: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  rfreg_ht.fit(X_train1, y_train1)\n"
     ]
    }
   ],
   "source": [
    "rfreg_ht = RandomForestRegressor(n_estimators = 500, min_samples_split = 2, min_samples_leaf = 1, max_features = 'sqrt', max_depth = None)\n",
    "rfreg_ht.fit(X_train1, y_train1)\n",
    "y_pred_rfreg = rfreg_ht.predict(X_val)\n",
    "y_pred_rfreg_r2 = rfreg_ht.predict(X_train1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.02865563115606618"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mean_absolute_error(y_val, y_pred_rfreg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.005060003629655643"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mean_squared_error(y_val, y_pred_rfreg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.07113370248803054"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mean_squared_error(y_val, y_pred_rfreg, squared = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9873120604830801"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#train\n",
    "r2_score(y_train1, y_pred_rfreg_r2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9573078759350635"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#val\n",
    "r2_score(y_val, y_pred_rfreg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Residual plots after Hyperparameter Tuning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Predicting model on the test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_rfreg_test = rfreg_ht.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['y_test_rfreg_tfidf_terpi.pkl']"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "joblib.dump(y_pred_rfreg_test, \"y_pred_rfreg_test_tfidf_terpi.pkl\")\n",
    "joblib.dump(y_test, \"y_test_rfreg_tfidf_terpi.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.028078788276081363"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mean_absolute_error(y_test, y_pred_rfreg_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.00488252599781248"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mean_squared_error(y_test, y_pred_rfreg_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.06987507422402126"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mean_squared_error(y_test, y_pred_rfreg_test, squared = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9591954036247992"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "r2_score(y_test, y_pred_rfreg_test)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Error analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 800x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# assume y_pred is a numpy array and y_true is a pandas dataframe\n",
    "fig, ax = plt.subplots(figsize=(8, 6))\n",
    "\n",
    "column = \"X..Terpinolene\"  # specify the target variable name\n",
    "ax.hist(y_pred_rfreg_test, alpha=0.5, label='y_pred', bins=20)\n",
    "ax.hist(y_test[column], alpha=0.5, label='y_true', bins=20)\n",
    "ax.legend(loc='upper right')\n",
    "ax.set_title(column)\n",
    "\n",
    "plt.show()\n",
    "plt.savefig('error_hist_knn_tfidf_terpi.png')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pearson R"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pearson correlation coefficient: 0.981\n",
      "P-value: 0.000\n"
     ]
    }
   ],
   "source": [
    "corr_coef, p_value = pearsonr(y_pred_rfreg_test.flatten(), y_test.values.ravel())\n",
    "\n",
    "print(f\"Pearson correlation coefficient: {corr_coef:.3f}\")\n",
    "print(f\"P-value: {p_value:.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Axes: >"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "corr_matrix = y_test.corr()\n",
    "sns.heatmap(corr_matrix, annot=True, cmap='coolwarm', center=0)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
