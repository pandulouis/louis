{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn import preprocessing\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.neural_network import MLPRegressor\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "from sklearn.metrics import r2_score\n",
    "from scipy.stats import pearsonr\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.feature_selection import SelectFromModel\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compiling complete dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_rf = pd.read_csv(\"df_geran_tfidf.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['index',\n",
       " 'tfidf_0',\n",
       " 'tfidf_1',\n",
       " 'tfidf_2',\n",
       " 'tfidf_3',\n",
       " 'tfidf_4',\n",
       " 'tfidf_5',\n",
       " 'tfidf_6',\n",
       " 'tfidf_7',\n",
       " 'tfidf_8',\n",
       " 'tfidf_9',\n",
       " 'tfidf_10',\n",
       " 'tfidf_11',\n",
       " 'tfidf_12',\n",
       " 'tfidf_13',\n",
       " 'tfidf_14',\n",
       " 'tfidf_15',\n",
       " 'tfidf_16',\n",
       " 'tfidf_17',\n",
       " 'tfidf_18',\n",
       " 'tfidf_19',\n",
       " 'tfidf_20',\n",
       " 'tfidf_21',\n",
       " 'tfidf_22',\n",
       " 'tfidf_23',\n",
       " 'tfidf_24',\n",
       " 'tfidf_25',\n",
       " 'tfidf_26',\n",
       " 'tfidf_27',\n",
       " 'tfidf_28',\n",
       " 'tfidf_29',\n",
       " 'tfidf_30',\n",
       " 'tfidf_31',\n",
       " 'tfidf_32',\n",
       " 'tfidf_33',\n",
       " 'tfidf_34',\n",
       " 'tfidf_35',\n",
       " 'tfidf_36',\n",
       " 'tfidf_37',\n",
       " 'tfidf_38',\n",
       " 'tfidf_39',\n",
       " 'tfidf_40',\n",
       " 'tfidf_41',\n",
       " 'tfidf_42',\n",
       " 'tfidf_43',\n",
       " 'tfidf_44',\n",
       " 'tfidf_45',\n",
       " 'tfidf_46',\n",
       " 'tfidf_47',\n",
       " 'tfidf_48',\n",
       " 'tfidf_49',\n",
       " 'tfidf_50',\n",
       " 'tfidf_51',\n",
       " 'tfidf_52',\n",
       " 'tfidf_53',\n",
       " 'tfidf_54',\n",
       " 'tfidf_55',\n",
       " 'tfidf_56',\n",
       " 'tfidf_57',\n",
       " 'tfidf_58',\n",
       " 'tfidf_59',\n",
       " 'tfidf_60',\n",
       " 'tfidf_61',\n",
       " 'tfidf_62',\n",
       " 'tfidf_63',\n",
       " 'tfidf_64',\n",
       " 'tfidf_65',\n",
       " 'tfidf_66',\n",
       " 'tfidf_67',\n",
       " 'tfidf_68',\n",
       " 'tfidf_69',\n",
       " 'tfidf_70',\n",
       " 'tfidf_71',\n",
       " 'tfidf_72',\n",
       " 'tfidf_73',\n",
       " 'tfidf_74',\n",
       " 'tfidf_75',\n",
       " 'tfidf_76',\n",
       " 'tfidf_77',\n",
       " 'tfidf_78',\n",
       " 'tfidf_79',\n",
       " 'tfidf_80',\n",
       " 'tfidf_81',\n",
       " 'tfidf_82',\n",
       " 'tfidf_83',\n",
       " 'tfidf_84',\n",
       " 'tfidf_85',\n",
       " 'tfidf_86',\n",
       " 'tfidf_87',\n",
       " 'tfidf_88',\n",
       " 'tfidf_89',\n",
       " 'tfidf_90',\n",
       " 'tfidf_91',\n",
       " 'tfidf_92',\n",
       " 'tfidf_93',\n",
       " 'tfidf_94',\n",
       " 'tfidf_95',\n",
       " 'tfidf_96',\n",
       " 'tfidf_97',\n",
       " 'tfidf_98',\n",
       " 'tfidf_99',\n",
       " 'tfidf_100',\n",
       " 'tfidf_101',\n",
       " 'tfidf_102',\n",
       " 'tfidf_103',\n",
       " 'tfidf_104',\n",
       " 'tfidf_105',\n",
       " 'tfidf_106',\n",
       " 'tfidf_107',\n",
       " 'tfidf_108',\n",
       " 'tfidf_109',\n",
       " 'tfidf_110',\n",
       " 'tfidf_111',\n",
       " 'tfidf_112',\n",
       " 'tfidf_113',\n",
       " 'tfidf_114',\n",
       " 'tfidf_115',\n",
       " 'tfidf_116',\n",
       " 'tfidf_117',\n",
       " 'tfidf_118',\n",
       " 'tfidf_119',\n",
       " 'tfidf_120',\n",
       " 'tfidf_121',\n",
       " 'tfidf_122',\n",
       " 'tfidf_123',\n",
       " 'tfidf_124',\n",
       " 'tfidf_125',\n",
       " 'tfidf_126',\n",
       " 'tfidf_127',\n",
       " 'tfidf_128',\n",
       " 'tfidf_129',\n",
       " 'tfidf_130',\n",
       " 'tfidf_131',\n",
       " 'tfidf_132',\n",
       " 'tfidf_133',\n",
       " 'tfidf_134',\n",
       " 'tfidf_135',\n",
       " 'tfidf_136',\n",
       " 'tfidf_137',\n",
       " 'tfidf_138',\n",
       " 'tfidf_139',\n",
       " 'tfidf_140',\n",
       " 'tfidf_141',\n",
       " 'tfidf_142',\n",
       " 'tfidf_143',\n",
       " 'tfidf_144',\n",
       " 'tfidf_145',\n",
       " 'tfidf_146',\n",
       " 'tfidf_147',\n",
       " 'tfidf_148',\n",
       " 'tfidf_149',\n",
       " 'tfidf_150',\n",
       " 'tfidf_151',\n",
       " 'tfidf_152',\n",
       " 'tfidf_153',\n",
       " 'tfidf_154',\n",
       " 'tfidf_155',\n",
       " 'tfidf_156',\n",
       " 'tfidf_157',\n",
       " 'tfidf_158',\n",
       " 'tfidf_159',\n",
       " 'tfidf_160',\n",
       " 'tfidf_161',\n",
       " 'tfidf_162',\n",
       " 'tfidf_163',\n",
       " 'tfidf_164',\n",
       " 'tfidf_165',\n",
       " 'tfidf_166',\n",
       " 'tfidf_167',\n",
       " 'tfidf_168',\n",
       " 'tfidf_169',\n",
       " 'tfidf_170',\n",
       " 'tfidf_171',\n",
       " 'tfidf_172',\n",
       " 'tfidf_173',\n",
       " 'tfidf_174',\n",
       " 'tfidf_175',\n",
       " 'tfidf_176',\n",
       " 'tfidf_177',\n",
       " 'tfidf_178',\n",
       " 'tfidf_179',\n",
       " 'tfidf_180',\n",
       " 'tfidf_181',\n",
       " 'tfidf_182',\n",
       " 'tfidf_183',\n",
       " 'tfidf_184',\n",
       " 'tfidf_185',\n",
       " 'tfidf_186',\n",
       " 'tfidf_187',\n",
       " 'tfidf_188',\n",
       " 'tfidf_189',\n",
       " 'tfidf_190',\n",
       " 'tfidf_191',\n",
       " 'tfidf_192',\n",
       " 'tfidf_193',\n",
       " 'tfidf_194',\n",
       " 'tfidf_195',\n",
       " 'tfidf_196',\n",
       " 'tfidf_197',\n",
       " 'tfidf_198',\n",
       " 'tfidf_199',\n",
       " 'tfidf_200',\n",
       " 'tfidf_201',\n",
       " 'tfidf_202',\n",
       " 'tfidf_203',\n",
       " 'tfidf_204',\n",
       " 'tfidf_205',\n",
       " 'tfidf_206',\n",
       " 'tfidf_207',\n",
       " 'tfidf_208',\n",
       " 'tfidf_209',\n",
       " 'tfidf_210',\n",
       " 'tfidf_211',\n",
       " 'tfidf_212',\n",
       " 'tfidf_213',\n",
       " 'tfidf_214',\n",
       " 'tfidf_215',\n",
       " 'tfidf_216',\n",
       " 'tfidf_217',\n",
       " 'tfidf_218',\n",
       " 'tfidf_219',\n",
       " 'tfidf_220',\n",
       " 'tfidf_221',\n",
       " 'tfidf_222',\n",
       " 'tfidf_223',\n",
       " 'tfidf_224',\n",
       " 'tfidf_225',\n",
       " 'tfidf_226',\n",
       " 'tfidf_227',\n",
       " 'tfidf_228',\n",
       " 'tfidf_229',\n",
       " 'tfidf_230',\n",
       " 'tfidf_231',\n",
       " 'tfidf_232',\n",
       " 'tfidf_233',\n",
       " 'tfidf_234',\n",
       " 'tfidf_235',\n",
       " 'tfidf_236',\n",
       " 'tfidf_237',\n",
       " 'tfidf_238',\n",
       " 'tfidf_239',\n",
       " 'tfidf_240',\n",
       " 'tfidf_241',\n",
       " 'tfidf_242',\n",
       " 'tfidf_243',\n",
       " 'tfidf_244',\n",
       " 'tfidf_245',\n",
       " 'tfidf_246',\n",
       " 'tfidf_247',\n",
       " 'tfidf_248',\n",
       " 'tfidf_249',\n",
       " 'tfidf_250',\n",
       " 'tfidf_251',\n",
       " 'tfidf_252',\n",
       " 'tfidf_253',\n",
       " 'tfidf_254',\n",
       " 'tfidf_255',\n",
       " 'tfidf_256',\n",
       " 'tfidf_257',\n",
       " 'tfidf_258',\n",
       " 'tfidf_259',\n",
       " 'tfidf_260',\n",
       " 'tfidf_261',\n",
       " 'tfidf_262',\n",
       " 'tfidf_263',\n",
       " 'tfidf_264',\n",
       " 'tfidf_265',\n",
       " 'tfidf_266',\n",
       " 'tfidf_267',\n",
       " 'tfidf_268',\n",
       " 'tfidf_269',\n",
       " 'tfidf_270',\n",
       " 'tfidf_271',\n",
       " 'tfidf_272',\n",
       " 'tfidf_273',\n",
       " 'tfidf_274',\n",
       " 'tfidf_275',\n",
       " 'tfidf_276',\n",
       " 'tfidf_277',\n",
       " 'tfidf_278',\n",
       " 'tfidf_279',\n",
       " 'tfidf_280',\n",
       " 'tfidf_281',\n",
       " 'tfidf_282',\n",
       " 'tfidf_283',\n",
       " 'tfidf_284',\n",
       " 'tfidf_285',\n",
       " 'tfidf_286',\n",
       " 'tfidf_287',\n",
       " 'tfidf_288',\n",
       " 'tfidf_289',\n",
       " 'tfidf_290',\n",
       " 'tfidf_291',\n",
       " 'tfidf_292',\n",
       " 'tfidf_293',\n",
       " 'tfidf_294',\n",
       " 'tfidf_295',\n",
       " 'tfidf_296',\n",
       " 'tfidf_297',\n",
       " 'tfidf_298',\n",
       " 'tfidf_299',\n",
       " 'tfidf_300',\n",
       " 'tfidf_301',\n",
       " 'tfidf_302',\n",
       " 'tfidf_303',\n",
       " 'tfidf_304',\n",
       " 'tfidf_305',\n",
       " 'tfidf_306',\n",
       " 'tfidf_307',\n",
       " 'tfidf_308',\n",
       " 'tfidf_309',\n",
       " 'tfidf_310',\n",
       " 'tfidf_311',\n",
       " 'tfidf_312',\n",
       " 'tfidf_313',\n",
       " 'tfidf_314',\n",
       " 'tfidf_315',\n",
       " 'tfidf_316',\n",
       " 'tfidf_317',\n",
       " 'tfidf_318',\n",
       " 'tfidf_319',\n",
       " 'tfidf_320',\n",
       " 'tfidf_321',\n",
       " 'tfidf_322',\n",
       " 'tfidf_323',\n",
       " 'tfidf_324',\n",
       " 'tfidf_325',\n",
       " 'tfidf_326',\n",
       " 'tfidf_327',\n",
       " 'tfidf_328',\n",
       " 'tfidf_329',\n",
       " 'tfidf_330',\n",
       " 'tfidf_331',\n",
       " 'tfidf_332',\n",
       " 'tfidf_333',\n",
       " 'tfidf_334',\n",
       " 'tfidf_335',\n",
       " 'tfidf_336',\n",
       " 'tfidf_337',\n",
       " 'tfidf_338',\n",
       " 'tfidf_339',\n",
       " 'tfidf_340',\n",
       " 'tfidf_341',\n",
       " 'tfidf_342',\n",
       " 'tfidf_343',\n",
       " 'tfidf_344',\n",
       " 'tfidf_345',\n",
       " 'tfidf_346',\n",
       " 'tfidf_347',\n",
       " 'tfidf_348',\n",
       " 'tfidf_349',\n",
       " 'tfidf_350',\n",
       " 'tfidf_351',\n",
       " 'tfidf_352',\n",
       " 'tfidf_353',\n",
       " 'tfidf_354',\n",
       " 'tfidf_355',\n",
       " 'tfidf_356',\n",
       " 'tfidf_357',\n",
       " 'tfidf_358',\n",
       " 'tfidf_359',\n",
       " 'tfidf_360',\n",
       " 'tfidf_361',\n",
       " 'tfidf_362',\n",
       " 'tfidf_363',\n",
       " 'tfidf_364',\n",
       " 'tfidf_365',\n",
       " 'tfidf_366',\n",
       " 'tfidf_367',\n",
       " 'tfidf_368',\n",
       " 'tfidf_369',\n",
       " 'tfidf_370',\n",
       " 'tfidf_371',\n",
       " 'tfidf_372',\n",
       " 'tfidf_373',\n",
       " 'tfidf_374',\n",
       " 'tfidf_375',\n",
       " 'tfidf_376',\n",
       " 'tfidf_377',\n",
       " 'tfidf_378',\n",
       " 'tfidf_379',\n",
       " 'tfidf_380',\n",
       " 'tfidf_381',\n",
       " 'tfidf_382',\n",
       " 'tfidf_383',\n",
       " 'tfidf_384',\n",
       " 'tfidf_385',\n",
       " 'tfidf_386',\n",
       " 'tfidf_387',\n",
       " 'hybrid',\n",
       " 'indica',\n",
       " 'sativa',\n",
       " 'anxiety',\n",
       " 'anxious',\n",
       " 'aroused',\n",
       " 'arthritis',\n",
       " 'creative',\n",
       " 'depression',\n",
       " 'dizzy',\n",
       " 'dry eyes',\n",
       " 'dry mouth',\n",
       " 'energetic',\n",
       " 'epilepsy',\n",
       " 'euphoric',\n",
       " 'eye pressure',\n",
       " 'fatigue',\n",
       " 'focused',\n",
       " 'giggly',\n",
       " 'happy',\n",
       " 'headache',\n",
       " 'hungry',\n",
       " 'migraines',\n",
       " 'pain',\n",
       " 'paranoid',\n",
       " 'relaxed',\n",
       " 'seizures',\n",
       " 'sleepy',\n",
       " 'spasticity',\n",
       " 'stress',\n",
       " 'talkative',\n",
       " 'tingly',\n",
       " 'uplifted',\n",
       " 'ammonia',\n",
       " 'apple',\n",
       " 'apricot',\n",
       " 'berry',\n",
       " 'blue cheese',\n",
       " 'blueberry',\n",
       " 'butter',\n",
       " 'cheese',\n",
       " 'chemical',\n",
       " 'chestnut',\n",
       " 'citrus',\n",
       " 'coffee',\n",
       " 'diesel',\n",
       " 'earthy',\n",
       " 'flowery',\n",
       " 'fruit',\n",
       " 'grape',\n",
       " 'grapefruit',\n",
       " 'honey',\n",
       " 'lavender',\n",
       " 'lemon',\n",
       " 'lime',\n",
       " 'mango',\n",
       " 'menthol',\n",
       " 'mint',\n",
       " 'nutty',\n",
       " 'orange',\n",
       " 'peach',\n",
       " 'pear',\n",
       " 'pepper',\n",
       " 'pine',\n",
       " 'pineapple',\n",
       " 'plum',\n",
       " 'pungent',\n",
       " 'rose',\n",
       " 'sage',\n",
       " 'skunk',\n",
       " 'spicy/herbal',\n",
       " 'strawberry',\n",
       " 'sweet',\n",
       " 'tar',\n",
       " 'tea',\n",
       " 'tobacco',\n",
       " 'tree',\n",
       " 'tropical',\n",
       " 'vanilla',\n",
       " 'violet',\n",
       " 'woody',\n",
       " 'X..Geraniol']"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_rf.columns.to_list()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Splitting dependent and independent variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df_rf.drop(['index', 'X..Geraniol'], axis = 1)\n",
    "y = df_rf[['X..Geraniol']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plotting histograms on target variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       ...,\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.]])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_array = y.to_numpy()\n",
    "y_array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:ylabel='Count'>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "sns.histplot(y, bins = 10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train test split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=1, test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train1, X_val, y_train1, y_val = train_test_split(X_train, y_train, random_state=1, test_size=0.25)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "RF modeling (before Feature selection and Hyperparameter Tuning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/y1/pjvjlkjn5gl846rnyzr53p340000gn/T/ipykernel_9787/350139188.py:2: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  rfreg.fit(X_train1, y_train1)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;background-color: white;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>RandomForestRegressor()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">RandomForestRegressor</label><div class=\"sk-toggleable__content\"><pre>RandomForestRegressor()</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "RandomForestRegressor()"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rfreg = RandomForestRegressor()\n",
    "rfreg.fit(X_train1, y_train1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_rfreg = rfreg.predict(X_val)\n",
    "y_pred_rfreg_r2 = rfreg.predict(X_train1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.03170916372709689"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mean_absolute_error(y_val, y_pred_rfreg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.010083969597479661"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mean_squared_error(y_val, y_pred_rfreg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.10041897030680837"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mean_squared_error(y_val, y_pred_rfreg, squared = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9835650389433528"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#train\n",
    "r2_score(y_train1, y_pred_rfreg_r2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9455048223135305"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#val\n",
    "r2_score(y_val, y_pred_rfreg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Residual plots for each target variable"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Feature Selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_feat = pd.DataFrame({\n",
    "    \"features\": X_train1.columns,\n",
    "    \"score\": rfreg.feature_importances_\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>features</th>\n",
       "      <th>score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>tfidf_0</td>\n",
       "      <td>0.000327</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>tfidf_1</td>\n",
       "      <td>0.001356</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>tfidf_2</td>\n",
       "      <td>0.000696</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>tfidf_3</td>\n",
       "      <td>0.000123</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>tfidf_4</td>\n",
       "      <td>0.001062</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>464</th>\n",
       "      <td>tree</td>\n",
       "      <td>0.000587</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>465</th>\n",
       "      <td>tropical</td>\n",
       "      <td>0.000536</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>466</th>\n",
       "      <td>vanilla</td>\n",
       "      <td>0.001937</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>467</th>\n",
       "      <td>violet</td>\n",
       "      <td>0.000010</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>468</th>\n",
       "      <td>woody</td>\n",
       "      <td>0.000941</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>469 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     features     score\n",
       "0     tfidf_0  0.000327\n",
       "1     tfidf_1  0.001356\n",
       "2     tfidf_2  0.000696\n",
       "3     tfidf_3  0.000123\n",
       "4     tfidf_4  0.001062\n",
       "..        ...       ...\n",
       "464      tree  0.000587\n",
       "465  tropical  0.000536\n",
       "466   vanilla  0.001937\n",
       "467    violet  0.000010\n",
       "468     woody  0.000941\n",
       "\n",
       "[469 rows x 2 columns]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_feat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_feat_ranked = df_feat.sort_values(\"score\", ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>features</th>\n",
       "      <th>score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>388</th>\n",
       "      <td>hybrid</td>\n",
       "      <td>1.670229e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>345</th>\n",
       "      <td>tfidf_345</td>\n",
       "      <td>2.635097e-02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>433</th>\n",
       "      <td>diesel</td>\n",
       "      <td>2.551401e-02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>329</th>\n",
       "      <td>tfidf_329</td>\n",
       "      <td>2.517208e-02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>342</th>\n",
       "      <td>tfidf_342</td>\n",
       "      <td>1.673504e-02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>447</th>\n",
       "      <td>orange</td>\n",
       "      <td>1.371383e-02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>149</th>\n",
       "      <td>tfidf_149</td>\n",
       "      <td>1.361106e-02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>441</th>\n",
       "      <td>lemon</td>\n",
       "      <td>1.349075e-02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>168</th>\n",
       "      <td>tfidf_168</td>\n",
       "      <td>1.313941e-02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>78</th>\n",
       "      <td>tfidf_78</td>\n",
       "      <td>1.193064e-02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>199</th>\n",
       "      <td>tfidf_199</td>\n",
       "      <td>9.802088e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>145</th>\n",
       "      <td>tfidf_145</td>\n",
       "      <td>9.582460e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>253</th>\n",
       "      <td>tfidf_253</td>\n",
       "      <td>9.383704e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>239</th>\n",
       "      <td>tfidf_239</td>\n",
       "      <td>9.093943e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>312</th>\n",
       "      <td>tfidf_312</td>\n",
       "      <td>8.810159e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>309</th>\n",
       "      <td>tfidf_309</td>\n",
       "      <td>8.452206e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>431</th>\n",
       "      <td>citrus</td>\n",
       "      <td>8.281149e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>285</th>\n",
       "      <td>tfidf_285</td>\n",
       "      <td>8.050332e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>141</th>\n",
       "      <td>tfidf_141</td>\n",
       "      <td>7.860344e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>210</th>\n",
       "      <td>tfidf_210</td>\n",
       "      <td>7.632988e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>128</th>\n",
       "      <td>tfidf_128</td>\n",
       "      <td>7.527622e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>tfidf_37</td>\n",
       "      <td>7.486344e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>245</th>\n",
       "      <td>tfidf_245</td>\n",
       "      <td>7.270762e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>428</th>\n",
       "      <td>cheese</td>\n",
       "      <td>7.075953e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>151</th>\n",
       "      <td>tfidf_151</td>\n",
       "      <td>6.834003e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>167</th>\n",
       "      <td>tfidf_167</td>\n",
       "      <td>6.803480e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>460</th>\n",
       "      <td>sweet</td>\n",
       "      <td>6.457233e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>207</th>\n",
       "      <td>tfidf_207</td>\n",
       "      <td>6.101430e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>190</th>\n",
       "      <td>tfidf_190</td>\n",
       "      <td>5.985979e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>176</th>\n",
       "      <td>tfidf_176</td>\n",
       "      <td>5.909709e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>272</th>\n",
       "      <td>tfidf_272</td>\n",
       "      <td>5.737141e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>413</th>\n",
       "      <td>relaxed</td>\n",
       "      <td>5.692206e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>382</th>\n",
       "      <td>tfidf_382</td>\n",
       "      <td>5.565253e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>64</th>\n",
       "      <td>tfidf_64</td>\n",
       "      <td>5.370436e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>tfidf_30</td>\n",
       "      <td>5.213673e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>162</th>\n",
       "      <td>tfidf_162</td>\n",
       "      <td>5.191297e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>144</th>\n",
       "      <td>tfidf_144</td>\n",
       "      <td>5.131775e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>357</th>\n",
       "      <td>tfidf_357</td>\n",
       "      <td>5.011426e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>104</th>\n",
       "      <td>tfidf_104</td>\n",
       "      <td>4.955599e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>173</th>\n",
       "      <td>tfidf_173</td>\n",
       "      <td>4.659404e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>140</th>\n",
       "      <td>tfidf_140</td>\n",
       "      <td>4.577337e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>tfidf_7</td>\n",
       "      <td>4.554783e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>121</th>\n",
       "      <td>tfidf_121</td>\n",
       "      <td>4.542546e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>343</th>\n",
       "      <td>tfidf_343</td>\n",
       "      <td>4.539871e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>258</th>\n",
       "      <td>tfidf_258</td>\n",
       "      <td>4.487186e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>395</th>\n",
       "      <td>creative</td>\n",
       "      <td>4.453748e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>434</th>\n",
       "      <td>earthy</td>\n",
       "      <td>4.369043e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>107</th>\n",
       "      <td>tfidf_107</td>\n",
       "      <td>4.290507e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>281</th>\n",
       "      <td>tfidf_281</td>\n",
       "      <td>4.227785e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>337</th>\n",
       "      <td>tfidf_337</td>\n",
       "      <td>4.080245e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>158</th>\n",
       "      <td>tfidf_158</td>\n",
       "      <td>4.050726e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>tfidf_43</td>\n",
       "      <td>4.015433e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>400</th>\n",
       "      <td>energetic</td>\n",
       "      <td>4.006776e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>362</th>\n",
       "      <td>tfidf_362</td>\n",
       "      <td>3.944219e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>73</th>\n",
       "      <td>tfidf_73</td>\n",
       "      <td>3.855694e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>93</th>\n",
       "      <td>tfidf_93</td>\n",
       "      <td>3.819345e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>71</th>\n",
       "      <td>tfidf_71</td>\n",
       "      <td>3.803627e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>407</th>\n",
       "      <td>happy</td>\n",
       "      <td>3.785066e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>247</th>\n",
       "      <td>tfidf_247</td>\n",
       "      <td>3.742178e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>260</th>\n",
       "      <td>tfidf_260</td>\n",
       "      <td>3.727948e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>178</th>\n",
       "      <td>tfidf_178</td>\n",
       "      <td>3.725534e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>418</th>\n",
       "      <td>talkative</td>\n",
       "      <td>3.722702e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>420</th>\n",
       "      <td>uplifted</td>\n",
       "      <td>3.658490e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>203</th>\n",
       "      <td>tfidf_203</td>\n",
       "      <td>3.619739e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>405</th>\n",
       "      <td>focused</td>\n",
       "      <td>3.603567e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>376</th>\n",
       "      <td>tfidf_376</td>\n",
       "      <td>3.529886e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>tfidf_11</td>\n",
       "      <td>3.405696e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>283</th>\n",
       "      <td>tfidf_283</td>\n",
       "      <td>3.402405e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>402</th>\n",
       "      <td>euphoric</td>\n",
       "      <td>3.339514e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>tfidf_98</td>\n",
       "      <td>3.332615e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>415</th>\n",
       "      <td>sleepy</td>\n",
       "      <td>3.315023e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>119</th>\n",
       "      <td>tfidf_119</td>\n",
       "      <td>3.260370e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>399</th>\n",
       "      <td>dry mouth</td>\n",
       "      <td>3.244144e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>340</th>\n",
       "      <td>tfidf_340</td>\n",
       "      <td>3.148157e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>311</th>\n",
       "      <td>tfidf_311</td>\n",
       "      <td>3.141454e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>371</th>\n",
       "      <td>tfidf_371</td>\n",
       "      <td>3.123861e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>101</th>\n",
       "      <td>tfidf_101</td>\n",
       "      <td>3.102761e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>328</th>\n",
       "      <td>tfidf_328</td>\n",
       "      <td>3.099224e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>205</th>\n",
       "      <td>tfidf_205</td>\n",
       "      <td>3.084667e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>tfidf_46</td>\n",
       "      <td>3.082663e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>69</th>\n",
       "      <td>tfidf_69</td>\n",
       "      <td>3.037645e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>314</th>\n",
       "      <td>tfidf_314</td>\n",
       "      <td>3.024834e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>122</th>\n",
       "      <td>tfidf_122</td>\n",
       "      <td>3.016877e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>135</th>\n",
       "      <td>tfidf_135</td>\n",
       "      <td>2.983065e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>tfidf_5</td>\n",
       "      <td>2.891474e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>130</th>\n",
       "      <td>tfidf_130</td>\n",
       "      <td>2.798961e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>398</th>\n",
       "      <td>dry eyes</td>\n",
       "      <td>2.762605e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>354</th>\n",
       "      <td>tfidf_354</td>\n",
       "      <td>2.749907e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>457</th>\n",
       "      <td>skunk</td>\n",
       "      <td>2.732236e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>278</th>\n",
       "      <td>tfidf_278</td>\n",
       "      <td>2.694322e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>367</th>\n",
       "      <td>tfidf_367</td>\n",
       "      <td>2.577083e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>126</th>\n",
       "      <td>tfidf_126</td>\n",
       "      <td>2.568570e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>454</th>\n",
       "      <td>pungent</td>\n",
       "      <td>2.567409e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>336</th>\n",
       "      <td>tfidf_336</td>\n",
       "      <td>2.549554e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>344</th>\n",
       "      <td>tfidf_344</td>\n",
       "      <td>2.474482e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>360</th>\n",
       "      <td>tfidf_360</td>\n",
       "      <td>2.399743e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>90</th>\n",
       "      <td>tfidf_90</td>\n",
       "      <td>2.349786e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>212</th>\n",
       "      <td>tfidf_212</td>\n",
       "      <td>2.336576e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>308</th>\n",
       "      <td>tfidf_308</td>\n",
       "      <td>2.259514e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>129</th>\n",
       "      <td>tfidf_129</td>\n",
       "      <td>2.232793e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>tfidf_20</td>\n",
       "      <td>2.213665e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>224</th>\n",
       "      <td>tfidf_224</td>\n",
       "      <td>2.176944e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>289</th>\n",
       "      <td>tfidf_289</td>\n",
       "      <td>2.152466e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>445</th>\n",
       "      <td>mint</td>\n",
       "      <td>2.152417e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>79</th>\n",
       "      <td>tfidf_79</td>\n",
       "      <td>2.132252e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>tfidf_16</td>\n",
       "      <td>2.125842e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>222</th>\n",
       "      <td>tfidf_222</td>\n",
       "      <td>2.118084e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>103</th>\n",
       "      <td>tfidf_103</td>\n",
       "      <td>2.071466e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>409</th>\n",
       "      <td>hungry</td>\n",
       "      <td>2.061842e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>127</th>\n",
       "      <td>tfidf_127</td>\n",
       "      <td>2.047180e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>217</th>\n",
       "      <td>tfidf_217</td>\n",
       "      <td>2.034108e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>tfidf_44</td>\n",
       "      <td>1.996804e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>234</th>\n",
       "      <td>tfidf_234</td>\n",
       "      <td>1.968920e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>381</th>\n",
       "      <td>tfidf_381</td>\n",
       "      <td>1.966390e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>80</th>\n",
       "      <td>tfidf_80</td>\n",
       "      <td>1.950200e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>117</th>\n",
       "      <td>tfidf_117</td>\n",
       "      <td>1.944957e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>466</th>\n",
       "      <td>vanilla</td>\n",
       "      <td>1.937176e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>tfidf_9</td>\n",
       "      <td>1.928824e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>406</th>\n",
       "      <td>giggly</td>\n",
       "      <td>1.907554e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>179</th>\n",
       "      <td>tfidf_179</td>\n",
       "      <td>1.902438e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>tfidf_96</td>\n",
       "      <td>1.879175e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>154</th>\n",
       "      <td>tfidf_154</td>\n",
       "      <td>1.866167e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>277</th>\n",
       "      <td>tfidf_277</td>\n",
       "      <td>1.857346e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>267</th>\n",
       "      <td>tfidf_267</td>\n",
       "      <td>1.827139e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>124</th>\n",
       "      <td>tfidf_124</td>\n",
       "      <td>1.814390e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>385</th>\n",
       "      <td>tfidf_385</td>\n",
       "      <td>1.811566e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>325</th>\n",
       "      <td>tfidf_325</td>\n",
       "      <td>1.808420e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>419</th>\n",
       "      <td>tingly</td>\n",
       "      <td>1.762323e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>365</th>\n",
       "      <td>tfidf_365</td>\n",
       "      <td>1.757291e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>61</th>\n",
       "      <td>tfidf_61</td>\n",
       "      <td>1.740993e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>tfidf_26</td>\n",
       "      <td>1.692216e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75</th>\n",
       "      <td>tfidf_75</td>\n",
       "      <td>1.689254e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>63</th>\n",
       "      <td>tfidf_63</td>\n",
       "      <td>1.677423e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>231</th>\n",
       "      <td>tfidf_231</td>\n",
       "      <td>1.674412e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>271</th>\n",
       "      <td>tfidf_271</td>\n",
       "      <td>1.654288e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>142</th>\n",
       "      <td>tfidf_142</td>\n",
       "      <td>1.640927e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>348</th>\n",
       "      <td>tfidf_348</td>\n",
       "      <td>1.640413e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>150</th>\n",
       "      <td>tfidf_150</td>\n",
       "      <td>1.632231e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>338</th>\n",
       "      <td>tfidf_338</td>\n",
       "      <td>1.621439e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>291</th>\n",
       "      <td>tfidf_291</td>\n",
       "      <td>1.609008e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>366</th>\n",
       "      <td>tfidf_366</td>\n",
       "      <td>1.606323e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>237</th>\n",
       "      <td>tfidf_237</td>\n",
       "      <td>1.599878e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>256</th>\n",
       "      <td>tfidf_256</td>\n",
       "      <td>1.593141e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>426</th>\n",
       "      <td>blueberry</td>\n",
       "      <td>1.592541e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>123</th>\n",
       "      <td>tfidf_123</td>\n",
       "      <td>1.568013e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>tfidf_99</td>\n",
       "      <td>1.559081e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>374</th>\n",
       "      <td>tfidf_374</td>\n",
       "      <td>1.546061e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>tfidf_32</td>\n",
       "      <td>1.521307e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53</th>\n",
       "      <td>tfidf_53</td>\n",
       "      <td>1.507005e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>223</th>\n",
       "      <td>tfidf_223</td>\n",
       "      <td>1.504604e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>tfidf_22</td>\n",
       "      <td>1.469388e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>387</th>\n",
       "      <td>tfidf_387</td>\n",
       "      <td>1.454518e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>412</th>\n",
       "      <td>paranoid</td>\n",
       "      <td>1.453588e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>355</th>\n",
       "      <td>tfidf_355</td>\n",
       "      <td>1.440973e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>240</th>\n",
       "      <td>tfidf_240</td>\n",
       "      <td>1.440961e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>102</th>\n",
       "      <td>tfidf_102</td>\n",
       "      <td>1.435396e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>324</th>\n",
       "      <td>tfidf_324</td>\n",
       "      <td>1.426919e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>318</th>\n",
       "      <td>tfidf_318</td>\n",
       "      <td>1.384763e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>437</th>\n",
       "      <td>grape</td>\n",
       "      <td>1.368317e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>tfidf_21</td>\n",
       "      <td>1.363255e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>303</th>\n",
       "      <td>tfidf_303</td>\n",
       "      <td>1.362014e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>tfidf_1</td>\n",
       "      <td>1.355783e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>236</th>\n",
       "      <td>tfidf_236</td>\n",
       "      <td>1.354087e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>397</th>\n",
       "      <td>dizzy</td>\n",
       "      <td>1.345581e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>83</th>\n",
       "      <td>tfidf_83</td>\n",
       "      <td>1.340278e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>tfidf_34</td>\n",
       "      <td>1.336212e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>166</th>\n",
       "      <td>tfidf_166</td>\n",
       "      <td>1.329424e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>200</th>\n",
       "      <td>tfidf_200</td>\n",
       "      <td>1.321130e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>350</th>\n",
       "      <td>tfidf_350</td>\n",
       "      <td>1.311586e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>435</th>\n",
       "      <td>flowery</td>\n",
       "      <td>1.305491e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>255</th>\n",
       "      <td>tfidf_255</td>\n",
       "      <td>1.296271e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>451</th>\n",
       "      <td>pine</td>\n",
       "      <td>1.272407e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>393</th>\n",
       "      <td>aroused</td>\n",
       "      <td>1.264425e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>251</th>\n",
       "      <td>tfidf_251</td>\n",
       "      <td>1.244379e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>92</th>\n",
       "      <td>tfidf_92</td>\n",
       "      <td>1.243379e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>175</th>\n",
       "      <td>tfidf_175</td>\n",
       "      <td>1.223149e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>424</th>\n",
       "      <td>berry</td>\n",
       "      <td>1.223089e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54</th>\n",
       "      <td>tfidf_54</td>\n",
       "      <td>1.211702e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>tfidf_47</td>\n",
       "      <td>1.207562e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>257</th>\n",
       "      <td>tfidf_257</td>\n",
       "      <td>1.207092e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>241</th>\n",
       "      <td>tfidf_241</td>\n",
       "      <td>1.206773e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>tfidf_31</td>\n",
       "      <td>1.197435e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>269</th>\n",
       "      <td>tfidf_269</td>\n",
       "      <td>1.191565e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>tfidf_38</td>\n",
       "      <td>1.185535e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>163</th>\n",
       "      <td>tfidf_163</td>\n",
       "      <td>1.177905e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>136</th>\n",
       "      <td>tfidf_136</td>\n",
       "      <td>1.174053e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>186</th>\n",
       "      <td>tfidf_186</td>\n",
       "      <td>1.168070e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51</th>\n",
       "      <td>tfidf_51</td>\n",
       "      <td>1.125944e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>280</th>\n",
       "      <td>tfidf_280</td>\n",
       "      <td>1.116100e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>tfidf_12</td>\n",
       "      <td>1.115396e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>392</th>\n",
       "      <td>anxious</td>\n",
       "      <td>1.107570e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>tfidf_45</td>\n",
       "      <td>1.091021e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>169</th>\n",
       "      <td>tfidf_169</td>\n",
       "      <td>1.083065e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>230</th>\n",
       "      <td>tfidf_230</td>\n",
       "      <td>1.082644e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>202</th>\n",
       "      <td>tfidf_202</td>\n",
       "      <td>1.077915e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>319</th>\n",
       "      <td>tfidf_319</td>\n",
       "      <td>1.070168e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>274</th>\n",
       "      <td>tfidf_274</td>\n",
       "      <td>1.063242e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>tfidf_4</td>\n",
       "      <td>1.062434e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>310</th>\n",
       "      <td>tfidf_310</td>\n",
       "      <td>1.060829e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>331</th>\n",
       "      <td>tfidf_331</td>\n",
       "      <td>1.036807e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>220</th>\n",
       "      <td>tfidf_220</td>\n",
       "      <td>1.029196e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>204</th>\n",
       "      <td>tfidf_204</td>\n",
       "      <td>1.019535e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>359</th>\n",
       "      <td>tfidf_359</td>\n",
       "      <td>1.018877e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>84</th>\n",
       "      <td>tfidf_84</td>\n",
       "      <td>1.016301e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>86</th>\n",
       "      <td>tfidf_86</td>\n",
       "      <td>1.014938e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>372</th>\n",
       "      <td>tfidf_372</td>\n",
       "      <td>1.009128e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>tfidf_17</td>\n",
       "      <td>1.003683e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>353</th>\n",
       "      <td>tfidf_353</td>\n",
       "      <td>1.000586e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>120</th>\n",
       "      <td>tfidf_120</td>\n",
       "      <td>9.839242e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>458</th>\n",
       "      <td>spicy/herbal</td>\n",
       "      <td>9.804836e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>tfidf_41</td>\n",
       "      <td>9.694549e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>300</th>\n",
       "      <td>tfidf_300</td>\n",
       "      <td>9.608471e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>221</th>\n",
       "      <td>tfidf_221</td>\n",
       "      <td>9.606649e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>373</th>\n",
       "      <td>tfidf_373</td>\n",
       "      <td>9.519649e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>183</th>\n",
       "      <td>tfidf_183</td>\n",
       "      <td>9.478262e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>tfidf_97</td>\n",
       "      <td>9.471854e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>273</th>\n",
       "      <td>tfidf_273</td>\n",
       "      <td>9.438605e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>468</th>\n",
       "      <td>woody</td>\n",
       "      <td>9.409699e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>tfidf_48</td>\n",
       "      <td>9.393664e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>386</th>\n",
       "      <td>tfidf_386</td>\n",
       "      <td>9.267061e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>116</th>\n",
       "      <td>tfidf_116</td>\n",
       "      <td>9.173571e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>264</th>\n",
       "      <td>tfidf_264</td>\n",
       "      <td>9.152394e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>81</th>\n",
       "      <td>tfidf_81</td>\n",
       "      <td>9.125659e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>198</th>\n",
       "      <td>tfidf_198</td>\n",
       "      <td>9.083828e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>206</th>\n",
       "      <td>tfidf_206</td>\n",
       "      <td>8.873886e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>tfidf_23</td>\n",
       "      <td>8.702368e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>341</th>\n",
       "      <td>tfidf_341</td>\n",
       "      <td>8.678053e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>189</th>\n",
       "      <td>tfidf_189</td>\n",
       "      <td>8.567813e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>358</th>\n",
       "      <td>tfidf_358</td>\n",
       "      <td>8.555331e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>321</th>\n",
       "      <td>tfidf_321</td>\n",
       "      <td>8.517521e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>288</th>\n",
       "      <td>tfidf_288</td>\n",
       "      <td>8.514314e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>184</th>\n",
       "      <td>tfidf_184</td>\n",
       "      <td>8.447087e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>316</th>\n",
       "      <td>tfidf_316</td>\n",
       "      <td>8.297523e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>361</th>\n",
       "      <td>tfidf_361</td>\n",
       "      <td>8.271028e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>77</th>\n",
       "      <td>tfidf_77</td>\n",
       "      <td>7.965072e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>330</th>\n",
       "      <td>tfidf_330</td>\n",
       "      <td>7.955431e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>164</th>\n",
       "      <td>tfidf_164</td>\n",
       "      <td>7.837800e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>275</th>\n",
       "      <td>tfidf_275</td>\n",
       "      <td>7.780470e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>106</th>\n",
       "      <td>tfidf_106</td>\n",
       "      <td>7.554682e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>159</th>\n",
       "      <td>tfidf_159</td>\n",
       "      <td>7.475849e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>tfidf_19</td>\n",
       "      <td>7.414178e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>tfidf_28</td>\n",
       "      <td>7.366272e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>363</th>\n",
       "      <td>tfidf_363</td>\n",
       "      <td>7.306331e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>440</th>\n",
       "      <td>lavender</td>\n",
       "      <td>7.255115e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>216</th>\n",
       "      <td>tfidf_216</td>\n",
       "      <td>7.240539e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>297</th>\n",
       "      <td>tfidf_297</td>\n",
       "      <td>7.078844e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>152</th>\n",
       "      <td>tfidf_152</td>\n",
       "      <td>7.072109e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>375</th>\n",
       "      <td>tfidf_375</td>\n",
       "      <td>7.047448e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>295</th>\n",
       "      <td>tfidf_295</td>\n",
       "      <td>7.023482e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>76</th>\n",
       "      <td>tfidf_76</td>\n",
       "      <td>7.019337e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>tfidf_24</td>\n",
       "      <td>7.016713e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>326</th>\n",
       "      <td>tfidf_326</td>\n",
       "      <td>7.011253e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>333</th>\n",
       "      <td>tfidf_333</td>\n",
       "      <td>6.988227e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>105</th>\n",
       "      <td>tfidf_105</td>\n",
       "      <td>6.985632e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>380</th>\n",
       "      <td>tfidf_380</td>\n",
       "      <td>6.963774e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>tfidf_2</td>\n",
       "      <td>6.957745e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>232</th>\n",
       "      <td>tfidf_232</td>\n",
       "      <td>6.912700e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>369</th>\n",
       "      <td>tfidf_369</td>\n",
       "      <td>6.870769e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>286</th>\n",
       "      <td>tfidf_286</td>\n",
       "      <td>6.660035e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>282</th>\n",
       "      <td>tfidf_282</td>\n",
       "      <td>6.628915e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>153</th>\n",
       "      <td>tfidf_153</td>\n",
       "      <td>6.468217e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>110</th>\n",
       "      <td>tfidf_110</td>\n",
       "      <td>6.235542e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>276</th>\n",
       "      <td>tfidf_276</td>\n",
       "      <td>6.234449e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>302</th>\n",
       "      <td>tfidf_302</td>\n",
       "      <td>6.203101e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>211</th>\n",
       "      <td>tfidf_211</td>\n",
       "      <td>6.176079e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>56</th>\n",
       "      <td>tfidf_56</td>\n",
       "      <td>6.160845e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>85</th>\n",
       "      <td>tfidf_85</td>\n",
       "      <td>6.106519e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>261</th>\n",
       "      <td>tfidf_261</td>\n",
       "      <td>6.079287e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>tfidf_49</td>\n",
       "      <td>6.047226e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>tfidf_13</td>\n",
       "      <td>6.043709e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>305</th>\n",
       "      <td>tfidf_305</td>\n",
       "      <td>6.002526e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>tfidf_40</td>\n",
       "      <td>5.964425e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>265</th>\n",
       "      <td>tfidf_265</td>\n",
       "      <td>5.944665e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>tfidf_6</td>\n",
       "      <td>5.874833e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>464</th>\n",
       "      <td>tree</td>\n",
       "      <td>5.872815e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>193</th>\n",
       "      <td>tfidf_193</td>\n",
       "      <td>5.853621e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>334</th>\n",
       "      <td>tfidf_334</td>\n",
       "      <td>5.852084e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>436</th>\n",
       "      <td>fruit</td>\n",
       "      <td>5.831760e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>192</th>\n",
       "      <td>tfidf_192</td>\n",
       "      <td>5.700858e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>384</th>\n",
       "      <td>tfidf_384</td>\n",
       "      <td>5.666742e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>408</th>\n",
       "      <td>headache</td>\n",
       "      <td>5.615301e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>172</th>\n",
       "      <td>tfidf_172</td>\n",
       "      <td>5.605595e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>351</th>\n",
       "      <td>tfidf_351</td>\n",
       "      <td>5.547272e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>226</th>\n",
       "      <td>tfidf_226</td>\n",
       "      <td>5.530457e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>tfidf_29</td>\n",
       "      <td>5.502920e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>tfidf_10</td>\n",
       "      <td>5.476794e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>346</th>\n",
       "      <td>tfidf_346</td>\n",
       "      <td>5.473556e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>306</th>\n",
       "      <td>tfidf_306</td>\n",
       "      <td>5.459477e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>171</th>\n",
       "      <td>tfidf_171</td>\n",
       "      <td>5.425062e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>465</th>\n",
       "      <td>tropical</td>\n",
       "      <td>5.364246e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>tfidf_14</td>\n",
       "      <td>5.316600e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>118</th>\n",
       "      <td>tfidf_118</td>\n",
       "      <td>5.290767e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>268</th>\n",
       "      <td>tfidf_268</td>\n",
       "      <td>5.222687e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>170</th>\n",
       "      <td>tfidf_170</td>\n",
       "      <td>5.135911e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>227</th>\n",
       "      <td>tfidf_227</td>\n",
       "      <td>5.127186e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>tfidf_39</td>\n",
       "      <td>5.100999e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>131</th>\n",
       "      <td>tfidf_131</td>\n",
       "      <td>5.058514e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>182</th>\n",
       "      <td>tfidf_182</td>\n",
       "      <td>5.054375e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>58</th>\n",
       "      <td>tfidf_58</td>\n",
       "      <td>5.031594e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>195</th>\n",
       "      <td>tfidf_195</td>\n",
       "      <td>5.016341e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>347</th>\n",
       "      <td>tfidf_347</td>\n",
       "      <td>5.004204e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>304</th>\n",
       "      <td>tfidf_304</td>\n",
       "      <td>4.963792e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59</th>\n",
       "      <td>tfidf_59</td>\n",
       "      <td>4.957546e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>146</th>\n",
       "      <td>tfidf_146</td>\n",
       "      <td>4.935182e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>356</th>\n",
       "      <td>tfidf_356</td>\n",
       "      <td>4.896305e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>108</th>\n",
       "      <td>tfidf_108</td>\n",
       "      <td>4.861927e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>112</th>\n",
       "      <td>tfidf_112</td>\n",
       "      <td>4.843679e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>263</th>\n",
       "      <td>tfidf_263</td>\n",
       "      <td>4.787812e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>290</th>\n",
       "      <td>tfidf_290</td>\n",
       "      <td>4.769917e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>100</th>\n",
       "      <td>tfidf_100</td>\n",
       "      <td>4.725026e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>320</th>\n",
       "      <td>tfidf_320</td>\n",
       "      <td>4.671089e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>215</th>\n",
       "      <td>tfidf_215</td>\n",
       "      <td>4.612564e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>88</th>\n",
       "      <td>tfidf_88</td>\n",
       "      <td>4.581701e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>91</th>\n",
       "      <td>tfidf_91</td>\n",
       "      <td>4.553514e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>197</th>\n",
       "      <td>tfidf_197</td>\n",
       "      <td>4.486015e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>188</th>\n",
       "      <td>tfidf_188</td>\n",
       "      <td>4.459960e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>157</th>\n",
       "      <td>tfidf_157</td>\n",
       "      <td>4.416749e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>177</th>\n",
       "      <td>tfidf_177</td>\n",
       "      <td>4.401556e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>214</th>\n",
       "      <td>tfidf_214</td>\n",
       "      <td>4.332589e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>160</th>\n",
       "      <td>tfidf_160</td>\n",
       "      <td>4.299952e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>298</th>\n",
       "      <td>tfidf_298</td>\n",
       "      <td>4.291315e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>254</th>\n",
       "      <td>tfidf_254</td>\n",
       "      <td>4.277271e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>134</th>\n",
       "      <td>tfidf_134</td>\n",
       "      <td>4.219513e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>tfidf_33</td>\n",
       "      <td>4.118554e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>185</th>\n",
       "      <td>tfidf_185</td>\n",
       "      <td>4.002230e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>323</th>\n",
       "      <td>tfidf_323</td>\n",
       "      <td>3.989425e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>208</th>\n",
       "      <td>tfidf_208</td>\n",
       "      <td>3.968747e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>133</th>\n",
       "      <td>tfidf_133</td>\n",
       "      <td>3.898685e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>125</th>\n",
       "      <td>tfidf_125</td>\n",
       "      <td>3.879433e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>349</th>\n",
       "      <td>tfidf_349</td>\n",
       "      <td>3.866992e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>294</th>\n",
       "      <td>tfidf_294</td>\n",
       "      <td>3.800840e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>370</th>\n",
       "      <td>tfidf_370</td>\n",
       "      <td>3.793312e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>66</th>\n",
       "      <td>tfidf_66</td>\n",
       "      <td>3.790093e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>293</th>\n",
       "      <td>tfidf_293</td>\n",
       "      <td>3.744790e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>243</th>\n",
       "      <td>tfidf_243</td>\n",
       "      <td>3.659703e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>213</th>\n",
       "      <td>tfidf_213</td>\n",
       "      <td>3.568670e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>317</th>\n",
       "      <td>tfidf_317</td>\n",
       "      <td>3.541018e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>364</th>\n",
       "      <td>tfidf_364</td>\n",
       "      <td>3.525627e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>249</th>\n",
       "      <td>tfidf_249</td>\n",
       "      <td>3.445452e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>187</th>\n",
       "      <td>tfidf_187</td>\n",
       "      <td>3.388551e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>315</th>\n",
       "      <td>tfidf_315</td>\n",
       "      <td>3.375957e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>62</th>\n",
       "      <td>tfidf_62</td>\n",
       "      <td>3.346418e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>109</th>\n",
       "      <td>tfidf_109</td>\n",
       "      <td>3.326963e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>156</th>\n",
       "      <td>tfidf_156</td>\n",
       "      <td>3.294101e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>tfidf_0</td>\n",
       "      <td>3.270714e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>229</th>\n",
       "      <td>tfidf_229</td>\n",
       "      <td>3.249599e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>378</th>\n",
       "      <td>tfidf_378</td>\n",
       "      <td>3.217024e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>165</th>\n",
       "      <td>tfidf_165</td>\n",
       "      <td>3.189871e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52</th>\n",
       "      <td>tfidf_52</td>\n",
       "      <td>3.177664e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>248</th>\n",
       "      <td>tfidf_248</td>\n",
       "      <td>3.164836e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>244</th>\n",
       "      <td>tfidf_244</td>\n",
       "      <td>3.159290e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>296</th>\n",
       "      <td>tfidf_296</td>\n",
       "      <td>3.113221e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>137</th>\n",
       "      <td>tfidf_137</td>\n",
       "      <td>3.104193e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>113</th>\n",
       "      <td>tfidf_113</td>\n",
       "      <td>3.103535e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>60</th>\n",
       "      <td>tfidf_60</td>\n",
       "      <td>3.091106e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>139</th>\n",
       "      <td>tfidf_139</td>\n",
       "      <td>3.069687e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>246</th>\n",
       "      <td>tfidf_246</td>\n",
       "      <td>3.061032e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>252</th>\n",
       "      <td>tfidf_252</td>\n",
       "      <td>3.055740e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>148</th>\n",
       "      <td>tfidf_148</td>\n",
       "      <td>3.036563e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>tfidf_8</td>\n",
       "      <td>3.003589e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>209</th>\n",
       "      <td>tfidf_209</td>\n",
       "      <td>2.979136e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>72</th>\n",
       "      <td>tfidf_72</td>\n",
       "      <td>2.974473e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>299</th>\n",
       "      <td>tfidf_299</td>\n",
       "      <td>2.952563e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>111</th>\n",
       "      <td>tfidf_111</td>\n",
       "      <td>2.951825e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>327</th>\n",
       "      <td>tfidf_327</td>\n",
       "      <td>2.948605e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>442</th>\n",
       "      <td>lime</td>\n",
       "      <td>2.944530e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>tfidf_35</td>\n",
       "      <td>2.941008e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>180</th>\n",
       "      <td>tfidf_180</td>\n",
       "      <td>2.922584e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>tfidf_15</td>\n",
       "      <td>2.797344e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>301</th>\n",
       "      <td>tfidf_301</td>\n",
       "      <td>2.745941e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>181</th>\n",
       "      <td>tfidf_181</td>\n",
       "      <td>2.725236e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50</th>\n",
       "      <td>tfidf_50</td>\n",
       "      <td>2.674619e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>377</th>\n",
       "      <td>tfidf_377</td>\n",
       "      <td>2.627162e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>155</th>\n",
       "      <td>tfidf_155</td>\n",
       "      <td>2.593912e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>322</th>\n",
       "      <td>tfidf_322</td>\n",
       "      <td>2.551091e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>65</th>\n",
       "      <td>tfidf_65</td>\n",
       "      <td>2.531372e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>307</th>\n",
       "      <td>tfidf_307</td>\n",
       "      <td>2.313141e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>115</th>\n",
       "      <td>tfidf_115</td>\n",
       "      <td>2.224085e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>201</th>\n",
       "      <td>tfidf_201</td>\n",
       "      <td>2.220232e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>379</th>\n",
       "      <td>tfidf_379</td>\n",
       "      <td>2.184576e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>196</th>\n",
       "      <td>tfidf_196</td>\n",
       "      <td>2.129042e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>446</th>\n",
       "      <td>nutty</td>\n",
       "      <td>2.102846e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>332</th>\n",
       "      <td>tfidf_332</td>\n",
       "      <td>2.052314e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>262</th>\n",
       "      <td>tfidf_262</td>\n",
       "      <td>2.029048e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>67</th>\n",
       "      <td>tfidf_67</td>\n",
       "      <td>1.948302e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>138</th>\n",
       "      <td>tfidf_138</td>\n",
       "      <td>1.929984e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>279</th>\n",
       "      <td>tfidf_279</td>\n",
       "      <td>1.916030e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>tfidf_25</td>\n",
       "      <td>1.891735e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>143</th>\n",
       "      <td>tfidf_143</td>\n",
       "      <td>1.886627e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>259</th>\n",
       "      <td>tfidf_259</td>\n",
       "      <td>1.878589e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>tfidf_27</td>\n",
       "      <td>1.828812e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>352</th>\n",
       "      <td>tfidf_352</td>\n",
       "      <td>1.818243e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>270</th>\n",
       "      <td>tfidf_270</td>\n",
       "      <td>1.816817e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>455</th>\n",
       "      <td>rose</td>\n",
       "      <td>1.773688e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>339</th>\n",
       "      <td>tfidf_339</td>\n",
       "      <td>1.717248e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>87</th>\n",
       "      <td>tfidf_87</td>\n",
       "      <td>1.673642e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>453</th>\n",
       "      <td>plum</td>\n",
       "      <td>1.670633e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>tfidf_36</td>\n",
       "      <td>1.666470e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>tfidf_42</td>\n",
       "      <td>1.633482e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>94</th>\n",
       "      <td>tfidf_94</td>\n",
       "      <td>1.628894e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>219</th>\n",
       "      <td>tfidf_219</td>\n",
       "      <td>1.612695e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>383</th>\n",
       "      <td>tfidf_383</td>\n",
       "      <td>1.611491e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>57</th>\n",
       "      <td>tfidf_57</td>\n",
       "      <td>1.521988e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>238</th>\n",
       "      <td>tfidf_238</td>\n",
       "      <td>1.514572e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>218</th>\n",
       "      <td>tfidf_218</td>\n",
       "      <td>1.466954e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>194</th>\n",
       "      <td>tfidf_194</td>\n",
       "      <td>1.440777e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>242</th>\n",
       "      <td>tfidf_242</td>\n",
       "      <td>1.412748e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>443</th>\n",
       "      <td>mango</td>\n",
       "      <td>1.371981e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>287</th>\n",
       "      <td>tfidf_287</td>\n",
       "      <td>1.352720e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>161</th>\n",
       "      <td>tfidf_161</td>\n",
       "      <td>1.305794e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>459</th>\n",
       "      <td>strawberry</td>\n",
       "      <td>1.293152e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>313</th>\n",
       "      <td>tfidf_313</td>\n",
       "      <td>1.254718e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>452</th>\n",
       "      <td>pineapple</td>\n",
       "      <td>1.240564e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>tfidf_3</td>\n",
       "      <td>1.229383e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>55</th>\n",
       "      <td>tfidf_55</td>\n",
       "      <td>1.208707e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>233</th>\n",
       "      <td>tfidf_233</td>\n",
       "      <td>1.198290e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>82</th>\n",
       "      <td>tfidf_82</td>\n",
       "      <td>1.139379e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>174</th>\n",
       "      <td>tfidf_174</td>\n",
       "      <td>1.105410e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>438</th>\n",
       "      <td>grapefruit</td>\n",
       "      <td>1.097581e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>225</th>\n",
       "      <td>tfidf_225</td>\n",
       "      <td>1.090495e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>147</th>\n",
       "      <td>tfidf_147</td>\n",
       "      <td>1.088952e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>429</th>\n",
       "      <td>chemical</td>\n",
       "      <td>1.054196e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>439</th>\n",
       "      <td>honey</td>\n",
       "      <td>1.022695e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>335</th>\n",
       "      <td>tfidf_335</td>\n",
       "      <td>9.838115e-05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>74</th>\n",
       "      <td>tfidf_74</td>\n",
       "      <td>9.444652e-05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>462</th>\n",
       "      <td>tea</td>\n",
       "      <td>9.374237e-05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>235</th>\n",
       "      <td>tfidf_235</td>\n",
       "      <td>8.863570e-05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>423</th>\n",
       "      <td>apricot</td>\n",
       "      <td>8.437947e-05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>450</th>\n",
       "      <td>pepper</td>\n",
       "      <td>8.249663e-05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>114</th>\n",
       "      <td>tfidf_114</td>\n",
       "      <td>7.376723e-05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>89</th>\n",
       "      <td>tfidf_89</td>\n",
       "      <td>7.056637e-05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>68</th>\n",
       "      <td>tfidf_68</td>\n",
       "      <td>6.617381e-05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>228</th>\n",
       "      <td>tfidf_228</td>\n",
       "      <td>6.356324e-05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>132</th>\n",
       "      <td>tfidf_132</td>\n",
       "      <td>6.098402e-05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>284</th>\n",
       "      <td>tfidf_284</td>\n",
       "      <td>5.720382e-05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>456</th>\n",
       "      <td>sage</td>\n",
       "      <td>5.661543e-05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>292</th>\n",
       "      <td>tfidf_292</td>\n",
       "      <td>5.054074e-05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>70</th>\n",
       "      <td>tfidf_70</td>\n",
       "      <td>4.920778e-05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>461</th>\n",
       "      <td>tar</td>\n",
       "      <td>4.767122e-05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>432</th>\n",
       "      <td>coffee</td>\n",
       "      <td>4.713226e-05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>368</th>\n",
       "      <td>tfidf_368</td>\n",
       "      <td>4.605883e-05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>tfidf_18</td>\n",
       "      <td>4.471904e-05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>427</th>\n",
       "      <td>butter</td>\n",
       "      <td>3.603295e-05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>448</th>\n",
       "      <td>peach</td>\n",
       "      <td>3.238420e-05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>191</th>\n",
       "      <td>tfidf_191</td>\n",
       "      <td>2.838294e-05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>444</th>\n",
       "      <td>menthol</td>\n",
       "      <td>2.324054e-05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>266</th>\n",
       "      <td>tfidf_266</td>\n",
       "      <td>2.181287e-05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>396</th>\n",
       "      <td>depression</td>\n",
       "      <td>2.139883e-05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>422</th>\n",
       "      <td>apple</td>\n",
       "      <td>1.907960e-05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>250</th>\n",
       "      <td>tfidf_250</td>\n",
       "      <td>1.835410e-05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>430</th>\n",
       "      <td>chestnut</td>\n",
       "      <td>1.826769e-05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>425</th>\n",
       "      <td>blue cheese</td>\n",
       "      <td>1.601830e-05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>467</th>\n",
       "      <td>violet</td>\n",
       "      <td>9.971046e-06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>421</th>\n",
       "      <td>ammonia</td>\n",
       "      <td>9.915319e-06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>tfidf_95</td>\n",
       "      <td>8.004983e-06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>463</th>\n",
       "      <td>tobacco</td>\n",
       "      <td>5.825062e-06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>449</th>\n",
       "      <td>pear</td>\n",
       "      <td>2.202018e-06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>391</th>\n",
       "      <td>anxiety</td>\n",
       "      <td>9.491970e-07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>389</th>\n",
       "      <td>indica</td>\n",
       "      <td>2.197864e-07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>390</th>\n",
       "      <td>sativa</td>\n",
       "      <td>1.436944e-07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>410</th>\n",
       "      <td>migraines</td>\n",
       "      <td>7.279284e-09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>404</th>\n",
       "      <td>fatigue</td>\n",
       "      <td>0.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>403</th>\n",
       "      <td>eye pressure</td>\n",
       "      <td>0.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>416</th>\n",
       "      <td>spasticity</td>\n",
       "      <td>0.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>394</th>\n",
       "      <td>arthritis</td>\n",
       "      <td>0.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>414</th>\n",
       "      <td>seizures</td>\n",
       "      <td>0.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>417</th>\n",
       "      <td>stress</td>\n",
       "      <td>0.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>401</th>\n",
       "      <td>epilepsy</td>\n",
       "      <td>0.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>411</th>\n",
       "      <td>pain</td>\n",
       "      <td>0.000000e+00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         features         score\n",
       "388        hybrid  1.670229e-01\n",
       "345     tfidf_345  2.635097e-02\n",
       "433        diesel  2.551401e-02\n",
       "329     tfidf_329  2.517208e-02\n",
       "342     tfidf_342  1.673504e-02\n",
       "447        orange  1.371383e-02\n",
       "149     tfidf_149  1.361106e-02\n",
       "441         lemon  1.349075e-02\n",
       "168     tfidf_168  1.313941e-02\n",
       "78       tfidf_78  1.193064e-02\n",
       "199     tfidf_199  9.802088e-03\n",
       "145     tfidf_145  9.582460e-03\n",
       "253     tfidf_253  9.383704e-03\n",
       "239     tfidf_239  9.093943e-03\n",
       "312     tfidf_312  8.810159e-03\n",
       "309     tfidf_309  8.452206e-03\n",
       "431        citrus  8.281149e-03\n",
       "285     tfidf_285  8.050332e-03\n",
       "141     tfidf_141  7.860344e-03\n",
       "210     tfidf_210  7.632988e-03\n",
       "128     tfidf_128  7.527622e-03\n",
       "37       tfidf_37  7.486344e-03\n",
       "245     tfidf_245  7.270762e-03\n",
       "428        cheese  7.075953e-03\n",
       "151     tfidf_151  6.834003e-03\n",
       "167     tfidf_167  6.803480e-03\n",
       "460         sweet  6.457233e-03\n",
       "207     tfidf_207  6.101430e-03\n",
       "190     tfidf_190  5.985979e-03\n",
       "176     tfidf_176  5.909709e-03\n",
       "272     tfidf_272  5.737141e-03\n",
       "413       relaxed  5.692206e-03\n",
       "382     tfidf_382  5.565253e-03\n",
       "64       tfidf_64  5.370436e-03\n",
       "30       tfidf_30  5.213673e-03\n",
       "162     tfidf_162  5.191297e-03\n",
       "144     tfidf_144  5.131775e-03\n",
       "357     tfidf_357  5.011426e-03\n",
       "104     tfidf_104  4.955599e-03\n",
       "173     tfidf_173  4.659404e-03\n",
       "140     tfidf_140  4.577337e-03\n",
       "7         tfidf_7  4.554783e-03\n",
       "121     tfidf_121  4.542546e-03\n",
       "343     tfidf_343  4.539871e-03\n",
       "258     tfidf_258  4.487186e-03\n",
       "395      creative  4.453748e-03\n",
       "434        earthy  4.369043e-03\n",
       "107     tfidf_107  4.290507e-03\n",
       "281     tfidf_281  4.227785e-03\n",
       "337     tfidf_337  4.080245e-03\n",
       "158     tfidf_158  4.050726e-03\n",
       "43       tfidf_43  4.015433e-03\n",
       "400     energetic  4.006776e-03\n",
       "362     tfidf_362  3.944219e-03\n",
       "73       tfidf_73  3.855694e-03\n",
       "93       tfidf_93  3.819345e-03\n",
       "71       tfidf_71  3.803627e-03\n",
       "407         happy  3.785066e-03\n",
       "247     tfidf_247  3.742178e-03\n",
       "260     tfidf_260  3.727948e-03\n",
       "178     tfidf_178  3.725534e-03\n",
       "418     talkative  3.722702e-03\n",
       "420      uplifted  3.658490e-03\n",
       "203     tfidf_203  3.619739e-03\n",
       "405       focused  3.603567e-03\n",
       "376     tfidf_376  3.529886e-03\n",
       "11       tfidf_11  3.405696e-03\n",
       "283     tfidf_283  3.402405e-03\n",
       "402      euphoric  3.339514e-03\n",
       "98       tfidf_98  3.332615e-03\n",
       "415        sleepy  3.315023e-03\n",
       "119     tfidf_119  3.260370e-03\n",
       "399     dry mouth  3.244144e-03\n",
       "340     tfidf_340  3.148157e-03\n",
       "311     tfidf_311  3.141454e-03\n",
       "371     tfidf_371  3.123861e-03\n",
       "101     tfidf_101  3.102761e-03\n",
       "328     tfidf_328  3.099224e-03\n",
       "205     tfidf_205  3.084667e-03\n",
       "46       tfidf_46  3.082663e-03\n",
       "69       tfidf_69  3.037645e-03\n",
       "314     tfidf_314  3.024834e-03\n",
       "122     tfidf_122  3.016877e-03\n",
       "135     tfidf_135  2.983065e-03\n",
       "5         tfidf_5  2.891474e-03\n",
       "130     tfidf_130  2.798961e-03\n",
       "398      dry eyes  2.762605e-03\n",
       "354     tfidf_354  2.749907e-03\n",
       "457         skunk  2.732236e-03\n",
       "278     tfidf_278  2.694322e-03\n",
       "367     tfidf_367  2.577083e-03\n",
       "126     tfidf_126  2.568570e-03\n",
       "454       pungent  2.567409e-03\n",
       "336     tfidf_336  2.549554e-03\n",
       "344     tfidf_344  2.474482e-03\n",
       "360     tfidf_360  2.399743e-03\n",
       "90       tfidf_90  2.349786e-03\n",
       "212     tfidf_212  2.336576e-03\n",
       "308     tfidf_308  2.259514e-03\n",
       "129     tfidf_129  2.232793e-03\n",
       "20       tfidf_20  2.213665e-03\n",
       "224     tfidf_224  2.176944e-03\n",
       "289     tfidf_289  2.152466e-03\n",
       "445          mint  2.152417e-03\n",
       "79       tfidf_79  2.132252e-03\n",
       "16       tfidf_16  2.125842e-03\n",
       "222     tfidf_222  2.118084e-03\n",
       "103     tfidf_103  2.071466e-03\n",
       "409        hungry  2.061842e-03\n",
       "127     tfidf_127  2.047180e-03\n",
       "217     tfidf_217  2.034108e-03\n",
       "44       tfidf_44  1.996804e-03\n",
       "234     tfidf_234  1.968920e-03\n",
       "381     tfidf_381  1.966390e-03\n",
       "80       tfidf_80  1.950200e-03\n",
       "117     tfidf_117  1.944957e-03\n",
       "466       vanilla  1.937176e-03\n",
       "9         tfidf_9  1.928824e-03\n",
       "406        giggly  1.907554e-03\n",
       "179     tfidf_179  1.902438e-03\n",
       "96       tfidf_96  1.879175e-03\n",
       "154     tfidf_154  1.866167e-03\n",
       "277     tfidf_277  1.857346e-03\n",
       "267     tfidf_267  1.827139e-03\n",
       "124     tfidf_124  1.814390e-03\n",
       "385     tfidf_385  1.811566e-03\n",
       "325     tfidf_325  1.808420e-03\n",
       "419        tingly  1.762323e-03\n",
       "365     tfidf_365  1.757291e-03\n",
       "61       tfidf_61  1.740993e-03\n",
       "26       tfidf_26  1.692216e-03\n",
       "75       tfidf_75  1.689254e-03\n",
       "63       tfidf_63  1.677423e-03\n",
       "231     tfidf_231  1.674412e-03\n",
       "271     tfidf_271  1.654288e-03\n",
       "142     tfidf_142  1.640927e-03\n",
       "348     tfidf_348  1.640413e-03\n",
       "150     tfidf_150  1.632231e-03\n",
       "338     tfidf_338  1.621439e-03\n",
       "291     tfidf_291  1.609008e-03\n",
       "366     tfidf_366  1.606323e-03\n",
       "237     tfidf_237  1.599878e-03\n",
       "256     tfidf_256  1.593141e-03\n",
       "426     blueberry  1.592541e-03\n",
       "123     tfidf_123  1.568013e-03\n",
       "99       tfidf_99  1.559081e-03\n",
       "374     tfidf_374  1.546061e-03\n",
       "32       tfidf_32  1.521307e-03\n",
       "53       tfidf_53  1.507005e-03\n",
       "223     tfidf_223  1.504604e-03\n",
       "22       tfidf_22  1.469388e-03\n",
       "387     tfidf_387  1.454518e-03\n",
       "412      paranoid  1.453588e-03\n",
       "355     tfidf_355  1.440973e-03\n",
       "240     tfidf_240  1.440961e-03\n",
       "102     tfidf_102  1.435396e-03\n",
       "324     tfidf_324  1.426919e-03\n",
       "318     tfidf_318  1.384763e-03\n",
       "437         grape  1.368317e-03\n",
       "21       tfidf_21  1.363255e-03\n",
       "303     tfidf_303  1.362014e-03\n",
       "1         tfidf_1  1.355783e-03\n",
       "236     tfidf_236  1.354087e-03\n",
       "397         dizzy  1.345581e-03\n",
       "83       tfidf_83  1.340278e-03\n",
       "34       tfidf_34  1.336212e-03\n",
       "166     tfidf_166  1.329424e-03\n",
       "200     tfidf_200  1.321130e-03\n",
       "350     tfidf_350  1.311586e-03\n",
       "435       flowery  1.305491e-03\n",
       "255     tfidf_255  1.296271e-03\n",
       "451          pine  1.272407e-03\n",
       "393       aroused  1.264425e-03\n",
       "251     tfidf_251  1.244379e-03\n",
       "92       tfidf_92  1.243379e-03\n",
       "175     tfidf_175  1.223149e-03\n",
       "424         berry  1.223089e-03\n",
       "54       tfidf_54  1.211702e-03\n",
       "47       tfidf_47  1.207562e-03\n",
       "257     tfidf_257  1.207092e-03\n",
       "241     tfidf_241  1.206773e-03\n",
       "31       tfidf_31  1.197435e-03\n",
       "269     tfidf_269  1.191565e-03\n",
       "38       tfidf_38  1.185535e-03\n",
       "163     tfidf_163  1.177905e-03\n",
       "136     tfidf_136  1.174053e-03\n",
       "186     tfidf_186  1.168070e-03\n",
       "51       tfidf_51  1.125944e-03\n",
       "280     tfidf_280  1.116100e-03\n",
       "12       tfidf_12  1.115396e-03\n",
       "392       anxious  1.107570e-03\n",
       "45       tfidf_45  1.091021e-03\n",
       "169     tfidf_169  1.083065e-03\n",
       "230     tfidf_230  1.082644e-03\n",
       "202     tfidf_202  1.077915e-03\n",
       "319     tfidf_319  1.070168e-03\n",
       "274     tfidf_274  1.063242e-03\n",
       "4         tfidf_4  1.062434e-03\n",
       "310     tfidf_310  1.060829e-03\n",
       "331     tfidf_331  1.036807e-03\n",
       "220     tfidf_220  1.029196e-03\n",
       "204     tfidf_204  1.019535e-03\n",
       "359     tfidf_359  1.018877e-03\n",
       "84       tfidf_84  1.016301e-03\n",
       "86       tfidf_86  1.014938e-03\n",
       "372     tfidf_372  1.009128e-03\n",
       "17       tfidf_17  1.003683e-03\n",
       "353     tfidf_353  1.000586e-03\n",
       "120     tfidf_120  9.839242e-04\n",
       "458  spicy/herbal  9.804836e-04\n",
       "41       tfidf_41  9.694549e-04\n",
       "300     tfidf_300  9.608471e-04\n",
       "221     tfidf_221  9.606649e-04\n",
       "373     tfidf_373  9.519649e-04\n",
       "183     tfidf_183  9.478262e-04\n",
       "97       tfidf_97  9.471854e-04\n",
       "273     tfidf_273  9.438605e-04\n",
       "468         woody  9.409699e-04\n",
       "48       tfidf_48  9.393664e-04\n",
       "386     tfidf_386  9.267061e-04\n",
       "116     tfidf_116  9.173571e-04\n",
       "264     tfidf_264  9.152394e-04\n",
       "81       tfidf_81  9.125659e-04\n",
       "198     tfidf_198  9.083828e-04\n",
       "206     tfidf_206  8.873886e-04\n",
       "23       tfidf_23  8.702368e-04\n",
       "341     tfidf_341  8.678053e-04\n",
       "189     tfidf_189  8.567813e-04\n",
       "358     tfidf_358  8.555331e-04\n",
       "321     tfidf_321  8.517521e-04\n",
       "288     tfidf_288  8.514314e-04\n",
       "184     tfidf_184  8.447087e-04\n",
       "316     tfidf_316  8.297523e-04\n",
       "361     tfidf_361  8.271028e-04\n",
       "77       tfidf_77  7.965072e-04\n",
       "330     tfidf_330  7.955431e-04\n",
       "164     tfidf_164  7.837800e-04\n",
       "275     tfidf_275  7.780470e-04\n",
       "106     tfidf_106  7.554682e-04\n",
       "159     tfidf_159  7.475849e-04\n",
       "19       tfidf_19  7.414178e-04\n",
       "28       tfidf_28  7.366272e-04\n",
       "363     tfidf_363  7.306331e-04\n",
       "440      lavender  7.255115e-04\n",
       "216     tfidf_216  7.240539e-04\n",
       "297     tfidf_297  7.078844e-04\n",
       "152     tfidf_152  7.072109e-04\n",
       "375     tfidf_375  7.047448e-04\n",
       "295     tfidf_295  7.023482e-04\n",
       "76       tfidf_76  7.019337e-04\n",
       "24       tfidf_24  7.016713e-04\n",
       "326     tfidf_326  7.011253e-04\n",
       "333     tfidf_333  6.988227e-04\n",
       "105     tfidf_105  6.985632e-04\n",
       "380     tfidf_380  6.963774e-04\n",
       "2         tfidf_2  6.957745e-04\n",
       "232     tfidf_232  6.912700e-04\n",
       "369     tfidf_369  6.870769e-04\n",
       "286     tfidf_286  6.660035e-04\n",
       "282     tfidf_282  6.628915e-04\n",
       "153     tfidf_153  6.468217e-04\n",
       "110     tfidf_110  6.235542e-04\n",
       "276     tfidf_276  6.234449e-04\n",
       "302     tfidf_302  6.203101e-04\n",
       "211     tfidf_211  6.176079e-04\n",
       "56       tfidf_56  6.160845e-04\n",
       "85       tfidf_85  6.106519e-04\n",
       "261     tfidf_261  6.079287e-04\n",
       "49       tfidf_49  6.047226e-04\n",
       "13       tfidf_13  6.043709e-04\n",
       "305     tfidf_305  6.002526e-04\n",
       "40       tfidf_40  5.964425e-04\n",
       "265     tfidf_265  5.944665e-04\n",
       "6         tfidf_6  5.874833e-04\n",
       "464          tree  5.872815e-04\n",
       "193     tfidf_193  5.853621e-04\n",
       "334     tfidf_334  5.852084e-04\n",
       "436         fruit  5.831760e-04\n",
       "192     tfidf_192  5.700858e-04\n",
       "384     tfidf_384  5.666742e-04\n",
       "408      headache  5.615301e-04\n",
       "172     tfidf_172  5.605595e-04\n",
       "351     tfidf_351  5.547272e-04\n",
       "226     tfidf_226  5.530457e-04\n",
       "29       tfidf_29  5.502920e-04\n",
       "10       tfidf_10  5.476794e-04\n",
       "346     tfidf_346  5.473556e-04\n",
       "306     tfidf_306  5.459477e-04\n",
       "171     tfidf_171  5.425062e-04\n",
       "465      tropical  5.364246e-04\n",
       "14       tfidf_14  5.316600e-04\n",
       "118     tfidf_118  5.290767e-04\n",
       "268     tfidf_268  5.222687e-04\n",
       "170     tfidf_170  5.135911e-04\n",
       "227     tfidf_227  5.127186e-04\n",
       "39       tfidf_39  5.100999e-04\n",
       "131     tfidf_131  5.058514e-04\n",
       "182     tfidf_182  5.054375e-04\n",
       "58       tfidf_58  5.031594e-04\n",
       "195     tfidf_195  5.016341e-04\n",
       "347     tfidf_347  5.004204e-04\n",
       "304     tfidf_304  4.963792e-04\n",
       "59       tfidf_59  4.957546e-04\n",
       "146     tfidf_146  4.935182e-04\n",
       "356     tfidf_356  4.896305e-04\n",
       "108     tfidf_108  4.861927e-04\n",
       "112     tfidf_112  4.843679e-04\n",
       "263     tfidf_263  4.787812e-04\n",
       "290     tfidf_290  4.769917e-04\n",
       "100     tfidf_100  4.725026e-04\n",
       "320     tfidf_320  4.671089e-04\n",
       "215     tfidf_215  4.612564e-04\n",
       "88       tfidf_88  4.581701e-04\n",
       "91       tfidf_91  4.553514e-04\n",
       "197     tfidf_197  4.486015e-04\n",
       "188     tfidf_188  4.459960e-04\n",
       "157     tfidf_157  4.416749e-04\n",
       "177     tfidf_177  4.401556e-04\n",
       "214     tfidf_214  4.332589e-04\n",
       "160     tfidf_160  4.299952e-04\n",
       "298     tfidf_298  4.291315e-04\n",
       "254     tfidf_254  4.277271e-04\n",
       "134     tfidf_134  4.219513e-04\n",
       "33       tfidf_33  4.118554e-04\n",
       "185     tfidf_185  4.002230e-04\n",
       "323     tfidf_323  3.989425e-04\n",
       "208     tfidf_208  3.968747e-04\n",
       "133     tfidf_133  3.898685e-04\n",
       "125     tfidf_125  3.879433e-04\n",
       "349     tfidf_349  3.866992e-04\n",
       "294     tfidf_294  3.800840e-04\n",
       "370     tfidf_370  3.793312e-04\n",
       "66       tfidf_66  3.790093e-04\n",
       "293     tfidf_293  3.744790e-04\n",
       "243     tfidf_243  3.659703e-04\n",
       "213     tfidf_213  3.568670e-04\n",
       "317     tfidf_317  3.541018e-04\n",
       "364     tfidf_364  3.525627e-04\n",
       "249     tfidf_249  3.445452e-04\n",
       "187     tfidf_187  3.388551e-04\n",
       "315     tfidf_315  3.375957e-04\n",
       "62       tfidf_62  3.346418e-04\n",
       "109     tfidf_109  3.326963e-04\n",
       "156     tfidf_156  3.294101e-04\n",
       "0         tfidf_0  3.270714e-04\n",
       "229     tfidf_229  3.249599e-04\n",
       "378     tfidf_378  3.217024e-04\n",
       "165     tfidf_165  3.189871e-04\n",
       "52       tfidf_52  3.177664e-04\n",
       "248     tfidf_248  3.164836e-04\n",
       "244     tfidf_244  3.159290e-04\n",
       "296     tfidf_296  3.113221e-04\n",
       "137     tfidf_137  3.104193e-04\n",
       "113     tfidf_113  3.103535e-04\n",
       "60       tfidf_60  3.091106e-04\n",
       "139     tfidf_139  3.069687e-04\n",
       "246     tfidf_246  3.061032e-04\n",
       "252     tfidf_252  3.055740e-04\n",
       "148     tfidf_148  3.036563e-04\n",
       "8         tfidf_8  3.003589e-04\n",
       "209     tfidf_209  2.979136e-04\n",
       "72       tfidf_72  2.974473e-04\n",
       "299     tfidf_299  2.952563e-04\n",
       "111     tfidf_111  2.951825e-04\n",
       "327     tfidf_327  2.948605e-04\n",
       "442          lime  2.944530e-04\n",
       "35       tfidf_35  2.941008e-04\n",
       "180     tfidf_180  2.922584e-04\n",
       "15       tfidf_15  2.797344e-04\n",
       "301     tfidf_301  2.745941e-04\n",
       "181     tfidf_181  2.725236e-04\n",
       "50       tfidf_50  2.674619e-04\n",
       "377     tfidf_377  2.627162e-04\n",
       "155     tfidf_155  2.593912e-04\n",
       "322     tfidf_322  2.551091e-04\n",
       "65       tfidf_65  2.531372e-04\n",
       "307     tfidf_307  2.313141e-04\n",
       "115     tfidf_115  2.224085e-04\n",
       "201     tfidf_201  2.220232e-04\n",
       "379     tfidf_379  2.184576e-04\n",
       "196     tfidf_196  2.129042e-04\n",
       "446         nutty  2.102846e-04\n",
       "332     tfidf_332  2.052314e-04\n",
       "262     tfidf_262  2.029048e-04\n",
       "67       tfidf_67  1.948302e-04\n",
       "138     tfidf_138  1.929984e-04\n",
       "279     tfidf_279  1.916030e-04\n",
       "25       tfidf_25  1.891735e-04\n",
       "143     tfidf_143  1.886627e-04\n",
       "259     tfidf_259  1.878589e-04\n",
       "27       tfidf_27  1.828812e-04\n",
       "352     tfidf_352  1.818243e-04\n",
       "270     tfidf_270  1.816817e-04\n",
       "455          rose  1.773688e-04\n",
       "339     tfidf_339  1.717248e-04\n",
       "87       tfidf_87  1.673642e-04\n",
       "453          plum  1.670633e-04\n",
       "36       tfidf_36  1.666470e-04\n",
       "42       tfidf_42  1.633482e-04\n",
       "94       tfidf_94  1.628894e-04\n",
       "219     tfidf_219  1.612695e-04\n",
       "383     tfidf_383  1.611491e-04\n",
       "57       tfidf_57  1.521988e-04\n",
       "238     tfidf_238  1.514572e-04\n",
       "218     tfidf_218  1.466954e-04\n",
       "194     tfidf_194  1.440777e-04\n",
       "242     tfidf_242  1.412748e-04\n",
       "443         mango  1.371981e-04\n",
       "287     tfidf_287  1.352720e-04\n",
       "161     tfidf_161  1.305794e-04\n",
       "459    strawberry  1.293152e-04\n",
       "313     tfidf_313  1.254718e-04\n",
       "452     pineapple  1.240564e-04\n",
       "3         tfidf_3  1.229383e-04\n",
       "55       tfidf_55  1.208707e-04\n",
       "233     tfidf_233  1.198290e-04\n",
       "82       tfidf_82  1.139379e-04\n",
       "174     tfidf_174  1.105410e-04\n",
       "438    grapefruit  1.097581e-04\n",
       "225     tfidf_225  1.090495e-04\n",
       "147     tfidf_147  1.088952e-04\n",
       "429      chemical  1.054196e-04\n",
       "439         honey  1.022695e-04\n",
       "335     tfidf_335  9.838115e-05\n",
       "74       tfidf_74  9.444652e-05\n",
       "462           tea  9.374237e-05\n",
       "235     tfidf_235  8.863570e-05\n",
       "423       apricot  8.437947e-05\n",
       "450        pepper  8.249663e-05\n",
       "114     tfidf_114  7.376723e-05\n",
       "89       tfidf_89  7.056637e-05\n",
       "68       tfidf_68  6.617381e-05\n",
       "228     tfidf_228  6.356324e-05\n",
       "132     tfidf_132  6.098402e-05\n",
       "284     tfidf_284  5.720382e-05\n",
       "456          sage  5.661543e-05\n",
       "292     tfidf_292  5.054074e-05\n",
       "70       tfidf_70  4.920778e-05\n",
       "461           tar  4.767122e-05\n",
       "432        coffee  4.713226e-05\n",
       "368     tfidf_368  4.605883e-05\n",
       "18       tfidf_18  4.471904e-05\n",
       "427        butter  3.603295e-05\n",
       "448         peach  3.238420e-05\n",
       "191     tfidf_191  2.838294e-05\n",
       "444       menthol  2.324054e-05\n",
       "266     tfidf_266  2.181287e-05\n",
       "396    depression  2.139883e-05\n",
       "422         apple  1.907960e-05\n",
       "250     tfidf_250  1.835410e-05\n",
       "430      chestnut  1.826769e-05\n",
       "425   blue cheese  1.601830e-05\n",
       "467        violet  9.971046e-06\n",
       "421       ammonia  9.915319e-06\n",
       "95       tfidf_95  8.004983e-06\n",
       "463       tobacco  5.825062e-06\n",
       "449          pear  2.202018e-06\n",
       "391       anxiety  9.491970e-07\n",
       "389        indica  2.197864e-07\n",
       "390        sativa  1.436944e-07\n",
       "410     migraines  7.279284e-09\n",
       "404       fatigue  0.000000e+00\n",
       "403  eye pressure  0.000000e+00\n",
       "416    spasticity  0.000000e+00\n",
       "394     arthritis  0.000000e+00\n",
       "414      seizures  0.000000e+00\n",
       "417        stress  0.000000e+00\n",
       "401      epilepsy  0.000000e+00\n",
       "411          pain  0.000000e+00"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.set_option('display.max_rows', df_feat_ranked.shape[0]+1)\n",
    "df_feat_ranked"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/andalanputra/opt/anaconda3/lib/python3.9/site-packages/sklearn/feature_selection/_from_model.py:357: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  self.estimator_.fit(X, y, **fit_params)\n"
     ]
    }
   ],
   "source": [
    "selector = SelectFromModel(rfreg).fit(X_train1, y_train1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([2.67241452e-04, 2.09757252e-03, 7.29099103e-04, 1.56732390e-04,\n",
       "       1.34048374e-03, 2.90623193e-03, 6.82454889e-04, 5.04439149e-03,\n",
       "       2.22043871e-04, 1.73537313e-03, 6.52800272e-04, 3.23335662e-03,\n",
       "       1.23266165e-03, 7.25915399e-04, 4.37485707e-04, 1.78393344e-04,\n",
       "       2.11641008e-03, 1.22610103e-03, 1.19958134e-05, 9.07360365e-04,\n",
       "       2.46578300e-03, 1.59947263e-03, 1.22235009e-03, 8.53637618e-04,\n",
       "       7.44793869e-04, 2.40141557e-04, 1.75106148e-03, 1.13403896e-04,\n",
       "       4.80401975e-04, 3.20997506e-04, 4.71130816e-03, 1.35112918e-03,\n",
       "       1.43555691e-03, 2.25561241e-04, 1.20101203e-03, 9.78278214e-05,\n",
       "       1.90546625e-04, 7.80486688e-03, 8.61210264e-04, 7.16023741e-04,\n",
       "       4.63562347e-04, 7.21027953e-04, 1.57253453e-04, 4.12066208e-03,\n",
       "       2.11488986e-03, 1.09591966e-03, 3.13174996e-03, 1.39115587e-03,\n",
       "       8.85552013e-04, 5.20151220e-04, 2.18748281e-04, 7.63412158e-04,\n",
       "       2.21151673e-04, 1.21543198e-03, 1.56983652e-03, 4.36478885e-05,\n",
       "       4.99755835e-04, 1.75034846e-04, 6.56813243e-04, 4.69888291e-04,\n",
       "       1.85348200e-04, 1.80216402e-03, 3.09890032e-04, 1.82038502e-03,\n",
       "       5.24336311e-03, 2.19978636e-04, 4.28936966e-04, 1.98618837e-04,\n",
       "       6.49872738e-05, 2.83057217e-03, 1.05105694e-04, 3.99221760e-03,\n",
       "       2.10542130e-04, 3.81832788e-03, 8.10803754e-05, 1.92494258e-03,\n",
       "       6.43821975e-04, 8.49637083e-04, 1.08701930e-02, 2.62281349e-03,\n",
       "       2.13001340e-03, 6.25810223e-04, 1.44188898e-04, 1.87604015e-03,\n",
       "       8.75318152e-04, 8.07708176e-04, 1.11348377e-03, 2.66603864e-04,\n",
       "       5.24432831e-04, 1.40104044e-04, 2.33044014e-03, 3.35621352e-04,\n",
       "       1.16952294e-03, 3.67442589e-03, 2.89933965e-04, 1.34564988e-05,\n",
       "       2.21212575e-03, 8.86525898e-04, 2.79664524e-03, 1.43836378e-03,\n",
       "       5.34383012e-04, 2.77758901e-03, 1.33332931e-03, 2.16496600e-03,\n",
       "       4.55948162e-03, 5.99715109e-04, 6.67536427e-04, 4.50046796e-03,\n",
       "       4.65901116e-04, 4.16857498e-04, 4.56350071e-04, 3.97666089e-04,\n",
       "       3.86078010e-04, 3.98286316e-04, 4.54664881e-05, 1.63122444e-04,\n",
       "       1.00188968e-03, 1.70060843e-03, 5.74873245e-04, 3.65710338e-03,\n",
       "       1.02190743e-03, 4.85584322e-03, 3.13516741e-03, 1.69707587e-03,\n",
       "       1.47279447e-03, 3.87341751e-04, 3.03789882e-03, 2.26111373e-03,\n",
       "       7.70449339e-03, 2.33511090e-03, 2.88671433e-03, 3.39476637e-04,\n",
       "       6.43324819e-05, 7.71088642e-04, 5.19613968e-04, 2.58148550e-03,\n",
       "       8.50825341e-04, 2.95642594e-04, 1.65793233e-04, 2.56961384e-04,\n",
       "       4.76401474e-03, 8.55988623e-03, 1.44200735e-03, 2.10810799e-04,\n",
       "       4.63461368e-03, 9.22624118e-03, 5.84238075e-04, 1.31690372e-04,\n",
       "       2.69528020e-04, 1.24823628e-02, 1.54946403e-03, 7.58348399e-03,\n",
       "       5.92995654e-04, 4.32064709e-04, 1.77873954e-03, 2.85487808e-04,\n",
       "       3.70494238e-04, 3.96114756e-04, 4.14596096e-03, 7.25327563e-04,\n",
       "       4.11069804e-04, 1.32030278e-04, 6.00352497e-03, 1.11004576e-03,\n",
       "       8.61482368e-04, 3.04771752e-04, 1.25952130e-03, 6.91530741e-03,\n",
       "       1.25058541e-02, 1.16411981e-03, 5.14605464e-04, 3.40311720e-04,\n",
       "       5.93158835e-04, 5.01009119e-03, 2.12557329e-04, 1.36551073e-03,\n",
       "       5.70567164e-03, 5.68475974e-04, 3.73851792e-03, 1.86301893e-03,\n",
       "       2.53611141e-04, 2.12147665e-04, 6.29210344e-04, 5.49831978e-04,\n",
       "       5.88833051e-04, 4.14478828e-04, 1.24606437e-03, 3.52159921e-04,\n",
       "       4.01517458e-04, 9.40769735e-04, 5.26949926e-03, 4.08078369e-05,\n",
       "       7.07260066e-04, 6.35976681e-04, 2.18280605e-04, 6.13642357e-04,\n",
       "       2.80761451e-04, 3.65867109e-04, 8.22270453e-04, 9.30021621e-03,\n",
       "       1.56272823e-03, 1.93930354e-04, 1.16454823e-03, 4.53960055e-03,\n",
       "       1.44868808e-03, 3.17609428e-03, 1.12648313e-03, 6.12921684e-03,\n",
       "       2.86815769e-04, 4.16903780e-04, 7.06041524e-03, 5.93025278e-04,\n",
       "       2.39457798e-03, 6.58753662e-04, 1.56580038e-04, 4.49868487e-04,\n",
       "       8.48478471e-04, 1.91419436e-03, 1.84194659e-04, 1.18200567e-04,\n",
       "       7.92435297e-04, 9.80011317e-04, 2.38587545e-03, 1.58781678e-03,\n",
       "       1.97583600e-03, 2.10266380e-04, 5.16626798e-04, 5.42098263e-04,\n",
       "       6.59830351e-05, 1.90195956e-04, 1.34344983e-03, 2.09922685e-03,\n",
       "       3.66237005e-04, 1.19428166e-04, 2.02009153e-03, 3.79540889e-05,\n",
       "       1.93999170e-03, 1.82795020e-03, 7.02209366e-05, 8.84204456e-03,\n",
       "       1.20983445e-03, 1.39152079e-03, 1.74965206e-04, 4.90431242e-04,\n",
       "       3.49949419e-04, 7.95096758e-03, 2.44887539e-04, 3.71378391e-03,\n",
       "       2.23495377e-04, 2.64458980e-04, 9.63347053e-05, 7.91742107e-04,\n",
       "       2.21546801e-04, 9.19013313e-03, 5.38459539e-04, 1.34459559e-03,\n",
       "       1.39023024e-03, 1.08645058e-03, 4.24378397e-03, 2.03372550e-04,\n",
       "       2.85645845e-03, 7.04465964e-04, 1.53837745e-04, 5.13645925e-04,\n",
       "       9.26516530e-04, 6.44279988e-04, 4.09409247e-05, 1.94689351e-03,\n",
       "       5.69656846e-04, 1.44143916e-03, 2.14208157e-04, 1.26500694e-03,\n",
       "       5.53194575e-03, 1.00517943e-03, 9.65956791e-04, 9.18048432e-04,\n",
       "       7.16987104e-04, 1.52836049e-03, 2.49483516e-03, 1.77512712e-04,\n",
       "       1.04055072e-03, 4.60820992e-03, 5.63904893e-04, 3.60248972e-03,\n",
       "       9.65079845e-05, 7.41049313e-03, 9.68179042e-04, 2.07257651e-04,\n",
       "       1.03250898e-03, 2.41354904e-03, 5.45194833e-04, 1.54083385e-03,\n",
       "       7.23953863e-05, 3.47896533e-04, 4.17165659e-04, 8.65956418e-04,\n",
       "       2.83904568e-04, 8.23337039e-04, 5.21534589e-04, 2.29398041e-04,\n",
       "       8.71167668e-04, 2.61477861e-04, 6.61550808e-04, 1.50320787e-03,\n",
       "       3.40173837e-04, 4.48606731e-04, 6.45410192e-04, 3.02690725e-04,\n",
       "       2.10100302e-03, 8.96626772e-03, 1.38177643e-03, 3.49858059e-03,\n",
       "       9.19903642e-03, 1.04888110e-04, 2.60740630e-03, 4.14971059e-04,\n",
       "       7.85195598e-04, 4.38555420e-04, 1.56178718e-03, 9.85676466e-04,\n",
       "       4.35930239e-04, 1.03470845e-03, 2.25817074e-04, 5.04361109e-04,\n",
       "       1.15669847e-03, 2.09886444e-03, 5.57123323e-04, 4.18842576e-04,\n",
       "       3.07585986e-03, 2.58815880e-02, 7.97820640e-04, 8.43357937e-04,\n",
       "       1.75431066e-04, 7.06526148e-04, 3.59292688e-04, 7.45382325e-05,\n",
       "       2.39169599e-03, 3.82630416e-03, 1.40258810e-03, 2.28849054e-04,\n",
       "       3.40017209e-03, 5.96006889e-04, 1.57405209e-02, 4.02984793e-03,\n",
       "       2.52551656e-03, 2.58342948e-02, 6.17593722e-04, 3.84669287e-04,\n",
       "       1.05296951e-03, 3.89628547e-04, 1.39710487e-03, 4.01484671e-04,\n",
       "       1.89728298e-04, 1.06579543e-03, 2.14665752e-03, 1.59046205e-03,\n",
       "       6.32374921e-04, 4.83195522e-03, 8.56947069e-04, 1.01277718e-03,\n",
       "       2.39677509e-03, 6.03586472e-04, 3.72776097e-03, 8.04514292e-04,\n",
       "       3.49134838e-04, 1.32892697e-03, 1.76059845e-03, 2.89386431e-03,\n",
       "       1.01668741e-04, 6.14213872e-04, 3.14250616e-04, 2.80101888e-03,\n",
       "       8.83631064e-04, 1.05160666e-03, 1.51145635e-03, 5.76584808e-04,\n",
       "       3.27115871e-03, 2.50906155e-04, 3.03300556e-04, 1.67761720e-04,\n",
       "       7.08767681e-04, 2.20622696e-03, 6.12485056e-03, 2.05570677e-04,\n",
       "       6.32042578e-04, 1.62671449e-03, 1.07658209e-03, 1.79222234e-03,\n",
       "       1.67267875e-01, 1.64849677e-07, 1.59506825e-07, 2.63890517e-05,\n",
       "       1.14345125e-03, 1.38864117e-03, 0.00000000e+00, 4.77957307e-03,\n",
       "       2.03238346e-06, 1.32290603e-03, 2.46141602e-03, 3.45367089e-03,\n",
       "       4.18701727e-03, 0.00000000e+00, 3.23059084e-03, 0.00000000e+00,\n",
       "       0.00000000e+00, 3.33845335e-03, 1.93593179e-03, 4.34564115e-03,\n",
       "       4.75769671e-04, 1.93800552e-03, 2.38023694e-05, 0.00000000e+00,\n",
       "       1.48448060e-03, 6.26290221e-03, 0.00000000e+00, 3.29495826e-03,\n",
       "       0.00000000e+00, 0.00000000e+00, 3.04655058e-03, 1.64511598e-03,\n",
       "       3.57458808e-03, 1.95278679e-05, 1.21762067e-05, 4.71265338e-05,\n",
       "       1.42209128e-03, 1.20061055e-05, 1.77792610e-03, 4.16754321e-05,\n",
       "       6.37013720e-03, 8.04710469e-05, 5.70347777e-06, 8.84735907e-03,\n",
       "       6.66190027e-05, 2.58421979e-02, 3.88299453e-03, 1.33832515e-03,\n",
       "       1.02785446e-03, 1.19190114e-03, 1.30175946e-04, 1.66575597e-04,\n",
       "       5.07619022e-04, 1.34929408e-02, 2.10381982e-04, 2.30084340e-04,\n",
       "       3.92997178e-05, 1.89661859e-03, 1.36271800e-04, 1.40290718e-02,\n",
       "       2.50892520e-05, 9.56596762e-06, 8.10190005e-05, 1.06829800e-03,\n",
       "       8.05634645e-05, 9.91942878e-05, 2.90429548e-03, 1.68226340e-04,\n",
       "       3.86778493e-05, 3.78773686e-03, 7.53216037e-04, 1.33213205e-04,\n",
       "       7.43925635e-03, 1.45888103e-05, 1.05535379e-04, 3.27630862e-06,\n",
       "       5.31293917e-04, 4.58375009e-04, 1.77834645e-03, 2.78068563e-05,\n",
       "       6.82688487e-04])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "selector.estimator_.feature_importances_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0021321961620469083"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "selector.threshold_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "mask = selector.get_support()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([False, False, False, False, False,  True, False,  True, False,\n",
       "       False, False,  True, False, False, False, False, False, False,\n",
       "       False, False,  True, False, False, False, False, False, False,\n",
       "       False, False, False,  True, False, False, False, False, False,\n",
       "       False,  True, False, False, False, False, False,  True, False,\n",
       "       False,  True, False, False, False, False, False, False, False,\n",
       "       False, False, False, False, False, False, False, False, False,\n",
       "       False,  True, False, False, False, False,  True, False,  True,\n",
       "       False,  True, False, False, False, False,  True,  True, False,\n",
       "       False, False, False, False, False, False, False, False, False,\n",
       "        True, False, False,  True, False, False,  True, False,  True,\n",
       "       False, False,  True, False,  True,  True, False, False,  True,\n",
       "       False, False, False, False, False, False, False, False, False,\n",
       "       False, False,  True, False,  True,  True, False, False, False,\n",
       "        True,  True,  True,  True,  True, False, False, False, False,\n",
       "        True, False, False, False, False,  True,  True, False, False,\n",
       "        True,  True, False, False, False,  True, False,  True, False,\n",
       "       False, False, False, False, False,  True, False, False, False,\n",
       "        True, False, False, False, False,  True,  True, False, False,\n",
       "       False, False,  True, False, False,  True, False,  True, False,\n",
       "       False, False, False, False, False, False, False, False, False,\n",
       "       False,  True, False, False, False, False, False, False, False,\n",
       "       False,  True, False, False, False,  True, False,  True, False,\n",
       "        True, False, False,  True, False,  True, False, False, False,\n",
       "       False, False, False, False, False, False,  True, False, False,\n",
       "       False, False, False, False, False, False, False, False, False,\n",
       "       False, False, False, False, False,  True, False, False, False,\n",
       "       False, False,  True, False,  True, False, False, False, False,\n",
       "       False,  True, False, False, False, False,  True, False,  True,\n",
       "       False, False, False, False, False, False, False, False, False,\n",
       "       False, False,  True, False, False, False, False, False,  True,\n",
       "       False, False,  True, False,  True, False,  True, False, False,\n",
       "       False,  True, False, False, False, False, False, False, False,\n",
       "       False, False, False, False, False, False, False, False, False,\n",
       "       False, False, False,  True, False,  True,  True, False,  True,\n",
       "       False, False, False, False, False, False, False, False, False,\n",
       "       False, False, False, False,  True,  True, False, False, False,\n",
       "       False, False, False,  True,  True, False, False,  True, False,\n",
       "        True,  True,  True,  True, False, False, False, False, False,\n",
       "       False, False, False,  True, False, False,  True, False, False,\n",
       "        True, False,  True, False, False, False, False,  True, False,\n",
       "       False, False,  True, False, False, False, False,  True, False,\n",
       "       False, False, False,  True,  True, False, False, False, False,\n",
       "       False,  True, False, False, False, False, False, False,  True,\n",
       "       False, False,  True,  True,  True, False,  True, False, False,\n",
       "        True, False,  True, False, False, False, False, False,  True,\n",
       "       False,  True, False, False,  True, False,  True, False, False,\n",
       "       False, False, False, False, False,  True, False, False,  True,\n",
       "       False,  True,  True, False, False, False, False, False, False,\n",
       "        True, False, False, False, False, False,  True, False, False,\n",
       "       False, False, False, False,  True, False, False,  True, False,\n",
       "       False,  True, False, False, False, False, False, False, False,\n",
       "       False])"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "selected_features = X.columns[mask]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tfidf_5</th>\n",
       "      <th>tfidf_7</th>\n",
       "      <th>tfidf_11</th>\n",
       "      <th>tfidf_20</th>\n",
       "      <th>tfidf_30</th>\n",
       "      <th>tfidf_37</th>\n",
       "      <th>tfidf_43</th>\n",
       "      <th>tfidf_46</th>\n",
       "      <th>tfidf_64</th>\n",
       "      <th>tfidf_69</th>\n",
       "      <th>...</th>\n",
       "      <th>uplifted</th>\n",
       "      <th>cheese</th>\n",
       "      <th>citrus</th>\n",
       "      <th>diesel</th>\n",
       "      <th>earthy</th>\n",
       "      <th>lemon</th>\n",
       "      <th>orange</th>\n",
       "      <th>pungent</th>\n",
       "      <th>skunk</th>\n",
       "      <th>sweet</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.145484</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.165804</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.191769</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.298306</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.149052</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.107335</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44995</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44996</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.244511</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44997</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44998</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44999</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>45000 rows × 107 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        tfidf_5  tfidf_7  tfidf_11  tfidf_20  tfidf_30  tfidf_37  tfidf_43  \\\n",
       "0      0.145484      0.0  0.000000       0.0  0.000000       0.0       0.0   \n",
       "1      0.000000      0.0  0.165804       0.0  0.000000       0.0       0.0   \n",
       "2      0.000000      0.0  0.000000       0.0  0.000000       0.0       0.0   \n",
       "3      0.000000      0.0  0.298306       0.0  0.149052       0.0       0.0   \n",
       "4      0.107335      0.0  0.000000       0.0  0.000000       0.0       0.0   \n",
       "...         ...      ...       ...       ...       ...       ...       ...   \n",
       "44995  0.000000      0.0  0.000000       0.0  0.000000       0.0       0.0   \n",
       "44996  0.000000      0.0  0.000000       0.0  0.000000       0.0       0.0   \n",
       "44997  0.000000      0.0  0.000000       0.0  0.000000       0.0       0.0   \n",
       "44998  0.000000      0.0  0.000000       0.0  0.000000       0.0       0.0   \n",
       "44999  0.000000      0.0  0.000000       0.0  0.000000       0.0       0.0   \n",
       "\n",
       "       tfidf_46  tfidf_64  tfidf_69  ...  uplifted  cheese  citrus  diesel  \\\n",
       "0           0.0  0.000000       0.0  ...         1       1       0       0   \n",
       "1           0.0  0.191769       0.0  ...         0       0       0       0   \n",
       "2           0.0  0.000000       0.0  ...         1       0       0       0   \n",
       "3           0.0  0.000000       0.0  ...         1       1       0       0   \n",
       "4           0.0  0.000000       0.0  ...         0       1       0       0   \n",
       "...         ...       ...       ...  ...       ...     ...     ...     ...   \n",
       "44995       0.0  0.000000       0.0  ...         0       0       0       0   \n",
       "44996       0.0  0.244511       0.0  ...         0       0       0       0   \n",
       "44997       0.0  0.000000       0.0  ...         0       0       0       0   \n",
       "44998       0.0  0.000000       0.0  ...         1       0       0       0   \n",
       "44999       0.0  0.000000       0.0  ...         1       1       1       1   \n",
       "\n",
       "       earthy  lemon  orange  pungent  skunk  sweet  \n",
       "0           0      0       0        0      0      0  \n",
       "1           0      0       0        0      0      0  \n",
       "2           0      0       0        0      1      1  \n",
       "3           0      0       0        1      0      1  \n",
       "4           0      0       0        0      0      0  \n",
       "...       ...    ...     ...      ...    ...    ...  \n",
       "44995       0      0       0        0      0      0  \n",
       "44996       0      0       0        0      0      0  \n",
       "44997       0      0       0        0      0      0  \n",
       "44998       0      0       0        0      0      0  \n",
       "44999       1      1       1        1      1      1  \n",
       "\n",
       "[45000 rows x 107 columns]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "selected_X = df_rf[selected_features]\n",
    "selected_X"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train test split (after Feature Selection)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['selected_X_rf_tfidf_geran.pkl']"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import joblib\n",
    "\n",
    "joblib.dump(selector, \"selector_rf_tfidf_geran.pkl\")\n",
    "joblib.dump(selected_X, \"selected_X_rf_tfidf_geran.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(selected_X, y, random_state=1, test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train1, X_val, y_train1, y_val = train_test_split(X_train, y_train, random_state=1, test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/y1/pjvjlkjn5gl846rnyzr53p340000gn/T/ipykernel_9787/3758305.py:1: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  rfreg.fit(X_train1, y_train1)\n"
     ]
    }
   ],
   "source": [
    "rfreg.fit(X_train1, y_train1)\n",
    "y_pred_rfreg = rfreg.predict(X_val)\n",
    "y_pred_rfreg_r2 = rfreg.predict(X_train1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.030639508396076664"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mean_absolute_error(y_val, y_pred_rfreg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.009977757025161694"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mean_squared_error(y_val, y_pred_rfreg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.09988872321319206"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mean_squared_error(y_val, y_pred_rfreg, squared = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9775552102467789"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#train\n",
    "r2_score(y_train1, y_pred_rfreg_r2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9460105134764426"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#val\n",
    "r2_score(y_val, y_pred_rfreg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hyperparameter Tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "parameters = {'max_depth': [None, 10, 50, 100],\n",
    "              'max_features': ['auto', 'sqrt'],\n",
    "              'min_samples_leaf': [1, 2, 4],\n",
    "              'min_samples_split': [2, 5, 10],\n",
    "              'n_estimators': [100, 300, 500]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "rscv = RandomizedSearchCV(rfreg,  \n",
    "                     parameters,   \n",
    "                     cv=5, \n",
    "                     scoring='neg_mean_absolute_error',\n",
    "                     n_jobs = -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/andalanputra/opt/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/Users/andalanputra/opt/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/Users/andalanputra/opt/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/Users/andalanputra/opt/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/Users/andalanputra/opt/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/Users/andalanputra/opt/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/Users/andalanputra/opt/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/Users/andalanputra/opt/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/Users/andalanputra/opt/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/Users/andalanputra/opt/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/Users/andalanputra/opt/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/Users/andalanputra/opt/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/Users/andalanputra/opt/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/Users/andalanputra/opt/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/Users/andalanputra/opt/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/Users/andalanputra/opt/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/Users/andalanputra/opt/anaconda3/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
      "  warn(\n",
      "/Users/andalanputra/opt/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/Users/andalanputra/opt/anaconda3/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
      "  warn(\n",
      "/Users/andalanputra/opt/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/Users/andalanputra/opt/anaconda3/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
      "  warn(\n",
      "/Users/andalanputra/opt/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/Users/andalanputra/opt/anaconda3/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
      "  warn(\n",
      "/Users/andalanputra/opt/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/Users/andalanputra/opt/anaconda3/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
      "  warn(\n",
      "/Users/andalanputra/opt/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/Users/andalanputra/opt/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/Users/andalanputra/opt/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/Users/andalanputra/opt/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/Users/andalanputra/opt/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/Users/andalanputra/opt/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/Users/andalanputra/opt/anaconda3/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
      "  warn(\n",
      "/Users/andalanputra/opt/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/Users/andalanputra/opt/anaconda3/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
      "  warn(\n",
      "/Users/andalanputra/opt/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/Users/andalanputra/opt/anaconda3/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
      "  warn(\n",
      "/Users/andalanputra/opt/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/Users/andalanputra/opt/anaconda3/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
      "  warn(\n",
      "/Users/andalanputra/opt/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/Users/andalanputra/opt/anaconda3/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
      "  warn(\n",
      "/Users/andalanputra/opt/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/Users/andalanputra/opt/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/Users/andalanputra/opt/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/Users/andalanputra/opt/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/Users/andalanputra/opt/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/Users/andalanputra/opt/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/Users/andalanputra/opt/anaconda3/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
      "  warn(\n",
      "/Users/andalanputra/opt/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/Users/andalanputra/opt/anaconda3/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
      "  warn(\n",
      "/Users/andalanputra/opt/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/Users/andalanputra/opt/anaconda3/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
      "  warn(\n",
      "/Users/andalanputra/opt/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/Users/andalanputra/opt/anaconda3/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
      "  warn(\n",
      "/Users/andalanputra/opt/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/Users/andalanputra/opt/anaconda3/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
      "  warn(\n",
      "/Users/andalanputra/opt/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/Users/andalanputra/opt/anaconda3/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
      "  warn(\n",
      "/Users/andalanputra/opt/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/Users/andalanputra/opt/anaconda3/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
      "  warn(\n",
      "/Users/andalanputra/opt/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/Users/andalanputra/opt/anaconda3/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
      "  warn(\n",
      "/Users/andalanputra/opt/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/Users/andalanputra/opt/anaconda3/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
      "  warn(\n",
      "/Users/andalanputra/opt/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/Users/andalanputra/opt/anaconda3/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
      "  warn(\n",
      "/Users/andalanputra/opt/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/Users/andalanputra/opt/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/Users/andalanputra/opt/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/Users/andalanputra/opt/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/Users/andalanputra/opt/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/Users/andalanputra/opt/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_search.py:909: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  self.best_estimator_.fit(X, y, **fit_params)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-2 {color: black;background-color: white;}#sk-container-id-2 pre{padding: 0;}#sk-container-id-2 div.sk-toggleable {background-color: white;}#sk-container-id-2 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-2 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-2 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-2 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-2 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-2 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-2 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-2 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-2 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-2 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-2 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-2 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-2 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-2 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-2 div.sk-item {position: relative;z-index: 1;}#sk-container-id-2 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-2 div.sk-item::before, #sk-container-id-2 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-2 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-2 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-2 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-2 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-2 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-2 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-2 div.sk-label-container {text-align: center;}#sk-container-id-2 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-2 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-2\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>RandomizedSearchCV(cv=5, estimator=RandomForestRegressor(), n_jobs=-1,\n",
       "                   param_distributions={&#x27;max_depth&#x27;: [None, 10, 50, 100],\n",
       "                                        &#x27;max_features&#x27;: [&#x27;auto&#x27;, &#x27;sqrt&#x27;],\n",
       "                                        &#x27;min_samples_leaf&#x27;: [1, 2, 4],\n",
       "                                        &#x27;min_samples_split&#x27;: [2, 5, 10],\n",
       "                                        &#x27;n_estimators&#x27;: [100, 300, 500]},\n",
       "                   scoring=&#x27;neg_mean_absolute_error&#x27;)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" ><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">RandomizedSearchCV</label><div class=\"sk-toggleable__content\"><pre>RandomizedSearchCV(cv=5, estimator=RandomForestRegressor(), n_jobs=-1,\n",
       "                   param_distributions={&#x27;max_depth&#x27;: [None, 10, 50, 100],\n",
       "                                        &#x27;max_features&#x27;: [&#x27;auto&#x27;, &#x27;sqrt&#x27;],\n",
       "                                        &#x27;min_samples_leaf&#x27;: [1, 2, 4],\n",
       "                                        &#x27;min_samples_split&#x27;: [2, 5, 10],\n",
       "                                        &#x27;n_estimators&#x27;: [100, 300, 500]},\n",
       "                   scoring=&#x27;neg_mean_absolute_error&#x27;)</pre></div></div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-3\" type=\"checkbox\" ><label for=\"sk-estimator-id-3\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">estimator: RandomForestRegressor</label><div class=\"sk-toggleable__content\"><pre>RandomForestRegressor()</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-4\" type=\"checkbox\" ><label for=\"sk-estimator-id-4\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">RandomForestRegressor</label><div class=\"sk-toggleable__content\"><pre>RandomForestRegressor()</pre></div></div></div></div></div></div></div></div></div></div>"
      ],
      "text/plain": [
       "RandomizedSearchCV(cv=5, estimator=RandomForestRegressor(), n_jobs=-1,\n",
       "                   param_distributions={'max_depth': [None, 10, 50, 100],\n",
       "                                        'max_features': ['auto', 'sqrt'],\n",
       "                                        'min_samples_leaf': [1, 2, 4],\n",
       "                                        'min_samples_split': [2, 5, 10],\n",
       "                                        'n_estimators': [100, 300, 500]},\n",
       "                   scoring='neg_mean_absolute_error')"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rscv.fit(X_train1, y_train1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'n_estimators': 300,\n",
       " 'min_samples_split': 2,\n",
       " 'min_samples_leaf': 1,\n",
       " 'max_features': 'sqrt',\n",
       " 'max_depth': None}"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rscv.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['rscv_rf_tfidf_best_params_geran.pkl']"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "joblib.dump(rscv, \"rscv_rf_tfidf_geran.pkl\")\n",
    "joblib.dump(rscv.best_params_, \"rscv_rf_tfidf_best_params_geran.pkl\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "RF (after Hyperparameter Tuning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/y1/pjvjlkjn5gl846rnyzr53p340000gn/T/ipykernel_9787/1649723548.py:2: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  rfreg_ht.fit(X_train1, y_train1)\n"
     ]
    }
   ],
   "source": [
    "rfreg_ht = RandomForestRegressor(n_estimators = 300, min_samples_split = 2, min_samples_leaf = 1, max_features = 'sqrt', max_depth = None)\n",
    "rfreg_ht.fit(X_train1, y_train1)\n",
    "y_pred_rfreg = rfreg_ht.predict(X_val)\n",
    "y_pred_rfreg_r2 = rfreg_ht.predict(X_train1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.02851837880797825"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mean_absolute_error(y_val, y_pred_rfreg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.007195409465395055"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mean_squared_error(y_val, y_pred_rfreg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.08482575944484703"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mean_squared_error(y_val, y_pred_rfreg, squared = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.979895059230997"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#train\n",
    "r2_score(y_train1, y_pred_rfreg_r2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9610657524147189"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#val\n",
    "r2_score(y_val, y_pred_rfreg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Residual plots after Hyperparameter Tuning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Predicting model on the test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_rfreg_test = rfreg_ht.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['y_test_rfreg_tfidf_geran.pkl']"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "joblib.dump(y_pred_rfreg_test, \"y_pred_rfreg_test_tfidf_geran.pkl\")\n",
    "joblib.dump(y_test, \"y_test_rfreg_tfidf_geran.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.02987062752544957"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mean_absolute_error(y_test, y_pred_rfreg_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.007770204827766654"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mean_squared_error(y_test, y_pred_rfreg_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0881487653218504"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mean_squared_error(y_test, y_pred_rfreg_test, squared = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9577824878083815"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "r2_score(y_test, y_pred_rfreg_test)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Error analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 576x432 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 432x288 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# assume y_pred is a numpy array and y_true is a pandas dataframe\n",
    "fig, ax = plt.subplots(figsize=(8, 6))\n",
    "\n",
    "column = \"X..Geraniol\"  # specify the target variable name\n",
    "ax.hist(y_pred_rfreg_test, alpha=0.5, label='y_pred', bins=20)\n",
    "ax.hist(y_test[column], alpha=0.5, label='y_true', bins=20)\n",
    "ax.legend(loc='upper right')\n",
    "ax.set_title(column)\n",
    "\n",
    "plt.show()\n",
    "plt.savefig('error_hist_knn_tfidf_geran.png')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pearson R"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pearson correlation coefficient: 0.980\n",
      "P-value: 0.000\n"
     ]
    }
   ],
   "source": [
    "corr_coef, p_value = pearsonr(y_pred_rfreg_test.flatten(), y_test.values.ravel())\n",
    "\n",
    "print(f\"Pearson correlation coefficient: {corr_coef:.3f}\")\n",
    "print(f\"P-value: {p_value:.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:>"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "corr_matrix = y_test.corr()\n",
    "sns.heatmap(corr_matrix, annot=True, cmap='coolwarm', center=0)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
