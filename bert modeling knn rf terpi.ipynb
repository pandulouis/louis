{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn import preprocessing\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.neural_network import MLPRegressor\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "from sklearn.metrics import r2_score\n",
    "from scipy.stats import pearsonr\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.feature_selection import SelectFromModel\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_bert = pd.read_csv(\"df_terpi_bert.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>feature_0</th>\n",
       "      <th>feature_1</th>\n",
       "      <th>feature_2</th>\n",
       "      <th>feature_3</th>\n",
       "      <th>feature_4</th>\n",
       "      <th>feature_5</th>\n",
       "      <th>feature_6</th>\n",
       "      <th>feature_7</th>\n",
       "      <th>feature_8</th>\n",
       "      <th>...</th>\n",
       "      <th>feature_759</th>\n",
       "      <th>feature_760</th>\n",
       "      <th>feature_761</th>\n",
       "      <th>feature_762</th>\n",
       "      <th>feature_763</th>\n",
       "      <th>feature_764</th>\n",
       "      <th>feature_765</th>\n",
       "      <th>feature_766</th>\n",
       "      <th>feature_767</th>\n",
       "      <th>X..Terpinolene</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0.144370</td>\n",
       "      <td>0.133683</td>\n",
       "      <td>0.558613</td>\n",
       "      <td>0.002472</td>\n",
       "      <td>0.064213</td>\n",
       "      <td>-0.297644</td>\n",
       "      <td>0.649253</td>\n",
       "      <td>0.156834</td>\n",
       "      <td>-0.075428</td>\n",
       "      <td>...</td>\n",
       "      <td>0.171215</td>\n",
       "      <td>0.197233</td>\n",
       "      <td>-0.131170</td>\n",
       "      <td>0.210236</td>\n",
       "      <td>-0.728103</td>\n",
       "      <td>0.027258</td>\n",
       "      <td>-0.683708</td>\n",
       "      <td>-0.160281</td>\n",
       "      <td>-0.718498</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0.144370</td>\n",
       "      <td>0.133683</td>\n",
       "      <td>0.558613</td>\n",
       "      <td>0.002472</td>\n",
       "      <td>0.064213</td>\n",
       "      <td>-0.297644</td>\n",
       "      <td>0.649253</td>\n",
       "      <td>0.156834</td>\n",
       "      <td>-0.075428</td>\n",
       "      <td>...</td>\n",
       "      <td>0.171215</td>\n",
       "      <td>0.197233</td>\n",
       "      <td>-0.131170</td>\n",
       "      <td>0.210236</td>\n",
       "      <td>-0.728103</td>\n",
       "      <td>0.027258</td>\n",
       "      <td>-0.683708</td>\n",
       "      <td>-0.160281</td>\n",
       "      <td>-0.718498</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0.144370</td>\n",
       "      <td>0.133683</td>\n",
       "      <td>0.558613</td>\n",
       "      <td>0.002472</td>\n",
       "      <td>0.064213</td>\n",
       "      <td>-0.297644</td>\n",
       "      <td>0.649253</td>\n",
       "      <td>0.156834</td>\n",
       "      <td>-0.075428</td>\n",
       "      <td>...</td>\n",
       "      <td>0.171215</td>\n",
       "      <td>0.197233</td>\n",
       "      <td>-0.131170</td>\n",
       "      <td>0.210236</td>\n",
       "      <td>-0.728103</td>\n",
       "      <td>0.027258</td>\n",
       "      <td>-0.683708</td>\n",
       "      <td>-0.160281</td>\n",
       "      <td>-0.718498</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0.144370</td>\n",
       "      <td>0.133683</td>\n",
       "      <td>0.558613</td>\n",
       "      <td>0.002472</td>\n",
       "      <td>0.064213</td>\n",
       "      <td>-0.297644</td>\n",
       "      <td>0.649253</td>\n",
       "      <td>0.156834</td>\n",
       "      <td>-0.075428</td>\n",
       "      <td>...</td>\n",
       "      <td>0.171215</td>\n",
       "      <td>0.197233</td>\n",
       "      <td>-0.131170</td>\n",
       "      <td>0.210236</td>\n",
       "      <td>-0.728103</td>\n",
       "      <td>0.027258</td>\n",
       "      <td>-0.683708</td>\n",
       "      <td>-0.160281</td>\n",
       "      <td>-0.718498</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0.144370</td>\n",
       "      <td>0.133683</td>\n",
       "      <td>0.558613</td>\n",
       "      <td>0.002472</td>\n",
       "      <td>0.064213</td>\n",
       "      <td>-0.297644</td>\n",
       "      <td>0.649253</td>\n",
       "      <td>0.156834</td>\n",
       "      <td>-0.075428</td>\n",
       "      <td>...</td>\n",
       "      <td>0.171215</td>\n",
       "      <td>0.197233</td>\n",
       "      <td>-0.131170</td>\n",
       "      <td>0.210236</td>\n",
       "      <td>-0.728103</td>\n",
       "      <td>0.027258</td>\n",
       "      <td>-0.683708</td>\n",
       "      <td>-0.160281</td>\n",
       "      <td>-0.718498</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>74995</th>\n",
       "      <td>42965</td>\n",
       "      <td>0.206688</td>\n",
       "      <td>0.119958</td>\n",
       "      <td>0.570615</td>\n",
       "      <td>0.069948</td>\n",
       "      <td>0.053100</td>\n",
       "      <td>-0.416459</td>\n",
       "      <td>0.784668</td>\n",
       "      <td>0.089139</td>\n",
       "      <td>-0.113613</td>\n",
       "      <td>...</td>\n",
       "      <td>0.158980</td>\n",
       "      <td>0.153869</td>\n",
       "      <td>-0.091632</td>\n",
       "      <td>0.334816</td>\n",
       "      <td>-0.746073</td>\n",
       "      <td>0.152503</td>\n",
       "      <td>-0.820483</td>\n",
       "      <td>-0.203148</td>\n",
       "      <td>-0.826904</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>74996</th>\n",
       "      <td>42965</td>\n",
       "      <td>0.206688</td>\n",
       "      <td>0.119958</td>\n",
       "      <td>0.570615</td>\n",
       "      <td>0.069948</td>\n",
       "      <td>0.053100</td>\n",
       "      <td>-0.416459</td>\n",
       "      <td>0.784668</td>\n",
       "      <td>0.089139</td>\n",
       "      <td>-0.113613</td>\n",
       "      <td>...</td>\n",
       "      <td>0.158980</td>\n",
       "      <td>0.153869</td>\n",
       "      <td>-0.091632</td>\n",
       "      <td>0.334816</td>\n",
       "      <td>-0.746073</td>\n",
       "      <td>0.152503</td>\n",
       "      <td>-0.820483</td>\n",
       "      <td>-0.203148</td>\n",
       "      <td>-0.826904</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>74997</th>\n",
       "      <td>42970</td>\n",
       "      <td>0.109320</td>\n",
       "      <td>0.095256</td>\n",
       "      <td>0.523631</td>\n",
       "      <td>-0.007430</td>\n",
       "      <td>0.055264</td>\n",
       "      <td>-0.338708</td>\n",
       "      <td>0.570877</td>\n",
       "      <td>0.232808</td>\n",
       "      <td>-0.009438</td>\n",
       "      <td>...</td>\n",
       "      <td>0.124365</td>\n",
       "      <td>0.174935</td>\n",
       "      <td>-0.110914</td>\n",
       "      <td>0.197620</td>\n",
       "      <td>-0.678949</td>\n",
       "      <td>0.039182</td>\n",
       "      <td>-0.663883</td>\n",
       "      <td>-0.163899</td>\n",
       "      <td>-0.593018</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>74998</th>\n",
       "      <td>42972</td>\n",
       "      <td>0.102736</td>\n",
       "      <td>0.135983</td>\n",
       "      <td>0.550969</td>\n",
       "      <td>-0.014671</td>\n",
       "      <td>0.015193</td>\n",
       "      <td>-0.269029</td>\n",
       "      <td>0.679146</td>\n",
       "      <td>0.145063</td>\n",
       "      <td>-0.059002</td>\n",
       "      <td>...</td>\n",
       "      <td>0.252791</td>\n",
       "      <td>0.156139</td>\n",
       "      <td>-0.121033</td>\n",
       "      <td>0.199727</td>\n",
       "      <td>-0.782018</td>\n",
       "      <td>-0.003939</td>\n",
       "      <td>-0.664979</td>\n",
       "      <td>-0.150894</td>\n",
       "      <td>-0.634808</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>74999</th>\n",
       "      <td>42973</td>\n",
       "      <td>0.233248</td>\n",
       "      <td>0.109718</td>\n",
       "      <td>0.598537</td>\n",
       "      <td>0.061358</td>\n",
       "      <td>0.088095</td>\n",
       "      <td>-0.390093</td>\n",
       "      <td>0.800446</td>\n",
       "      <td>0.077057</td>\n",
       "      <td>-0.104278</td>\n",
       "      <td>...</td>\n",
       "      <td>0.195909</td>\n",
       "      <td>0.095593</td>\n",
       "      <td>-0.109210</td>\n",
       "      <td>0.319783</td>\n",
       "      <td>-0.766471</td>\n",
       "      <td>0.119461</td>\n",
       "      <td>-0.819312</td>\n",
       "      <td>-0.167582</td>\n",
       "      <td>-0.830700</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>75000 rows Ã— 770 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       index  feature_0  feature_1  feature_2  feature_3  feature_4  \\\n",
       "0          0   0.144370   0.133683   0.558613   0.002472   0.064213   \n",
       "1          0   0.144370   0.133683   0.558613   0.002472   0.064213   \n",
       "2          0   0.144370   0.133683   0.558613   0.002472   0.064213   \n",
       "3          0   0.144370   0.133683   0.558613   0.002472   0.064213   \n",
       "4          0   0.144370   0.133683   0.558613   0.002472   0.064213   \n",
       "...      ...        ...        ...        ...        ...        ...   \n",
       "74995  42965   0.206688   0.119958   0.570615   0.069948   0.053100   \n",
       "74996  42965   0.206688   0.119958   0.570615   0.069948   0.053100   \n",
       "74997  42970   0.109320   0.095256   0.523631  -0.007430   0.055264   \n",
       "74998  42972   0.102736   0.135983   0.550969  -0.014671   0.015193   \n",
       "74999  42973   0.233248   0.109718   0.598537   0.061358   0.088095   \n",
       "\n",
       "       feature_5  feature_6  feature_7  feature_8  ...  feature_759  \\\n",
       "0      -0.297644   0.649253   0.156834  -0.075428  ...     0.171215   \n",
       "1      -0.297644   0.649253   0.156834  -0.075428  ...     0.171215   \n",
       "2      -0.297644   0.649253   0.156834  -0.075428  ...     0.171215   \n",
       "3      -0.297644   0.649253   0.156834  -0.075428  ...     0.171215   \n",
       "4      -0.297644   0.649253   0.156834  -0.075428  ...     0.171215   \n",
       "...          ...        ...        ...        ...  ...          ...   \n",
       "74995  -0.416459   0.784668   0.089139  -0.113613  ...     0.158980   \n",
       "74996  -0.416459   0.784668   0.089139  -0.113613  ...     0.158980   \n",
       "74997  -0.338708   0.570877   0.232808  -0.009438  ...     0.124365   \n",
       "74998  -0.269029   0.679146   0.145063  -0.059002  ...     0.252791   \n",
       "74999  -0.390093   0.800446   0.077057  -0.104278  ...     0.195909   \n",
       "\n",
       "       feature_760  feature_761  feature_762  feature_763  feature_764  \\\n",
       "0         0.197233    -0.131170     0.210236    -0.728103     0.027258   \n",
       "1         0.197233    -0.131170     0.210236    -0.728103     0.027258   \n",
       "2         0.197233    -0.131170     0.210236    -0.728103     0.027258   \n",
       "3         0.197233    -0.131170     0.210236    -0.728103     0.027258   \n",
       "4         0.197233    -0.131170     0.210236    -0.728103     0.027258   \n",
       "...            ...          ...          ...          ...          ...   \n",
       "74995     0.153869    -0.091632     0.334816    -0.746073     0.152503   \n",
       "74996     0.153869    -0.091632     0.334816    -0.746073     0.152503   \n",
       "74997     0.174935    -0.110914     0.197620    -0.678949     0.039182   \n",
       "74998     0.156139    -0.121033     0.199727    -0.782018    -0.003939   \n",
       "74999     0.095593    -0.109210     0.319783    -0.766471     0.119461   \n",
       "\n",
       "       feature_765  feature_766  feature_767  X..Terpinolene  \n",
       "0        -0.683708    -0.160281    -0.718498             1.0  \n",
       "1        -0.683708    -0.160281    -0.718498             1.0  \n",
       "2        -0.683708    -0.160281    -0.718498             1.0  \n",
       "3        -0.683708    -0.160281    -0.718498             1.0  \n",
       "4        -0.683708    -0.160281    -0.718498             1.0  \n",
       "...            ...          ...          ...             ...  \n",
       "74995    -0.820483    -0.203148    -0.826904             0.0  \n",
       "74996    -0.820483    -0.203148    -0.826904             0.0  \n",
       "74997    -0.663883    -0.163899    -0.593018             0.0  \n",
       "74998    -0.664979    -0.150894    -0.634808             0.0  \n",
       "74999    -0.819312    -0.167582    -0.830700             0.0  \n",
       "\n",
       "[75000 rows x 770 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_bert"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['index',\n",
       " 'feature_0',\n",
       " 'feature_1',\n",
       " 'feature_2',\n",
       " 'feature_3',\n",
       " 'feature_4',\n",
       " 'feature_5',\n",
       " 'feature_6',\n",
       " 'feature_7',\n",
       " 'feature_8',\n",
       " 'feature_9',\n",
       " 'feature_10',\n",
       " 'feature_11',\n",
       " 'feature_12',\n",
       " 'feature_13',\n",
       " 'feature_14',\n",
       " 'feature_15',\n",
       " 'feature_16',\n",
       " 'feature_17',\n",
       " 'feature_18',\n",
       " 'feature_19',\n",
       " 'feature_20',\n",
       " 'feature_21',\n",
       " 'feature_22',\n",
       " 'feature_23',\n",
       " 'feature_24',\n",
       " 'feature_25',\n",
       " 'feature_26',\n",
       " 'feature_27',\n",
       " 'feature_28',\n",
       " 'feature_29',\n",
       " 'feature_30',\n",
       " 'feature_31',\n",
       " 'feature_32',\n",
       " 'feature_33',\n",
       " 'feature_34',\n",
       " 'feature_35',\n",
       " 'feature_36',\n",
       " 'feature_37',\n",
       " 'feature_38',\n",
       " 'feature_39',\n",
       " 'feature_40',\n",
       " 'feature_41',\n",
       " 'feature_42',\n",
       " 'feature_43',\n",
       " 'feature_44',\n",
       " 'feature_45',\n",
       " 'feature_46',\n",
       " 'feature_47',\n",
       " 'feature_48',\n",
       " 'feature_49',\n",
       " 'feature_50',\n",
       " 'feature_51',\n",
       " 'feature_52',\n",
       " 'feature_53',\n",
       " 'feature_54',\n",
       " 'feature_55',\n",
       " 'feature_56',\n",
       " 'feature_57',\n",
       " 'feature_58',\n",
       " 'feature_59',\n",
       " 'feature_60',\n",
       " 'feature_61',\n",
       " 'feature_62',\n",
       " 'feature_63',\n",
       " 'feature_64',\n",
       " 'feature_65',\n",
       " 'feature_66',\n",
       " 'feature_67',\n",
       " 'feature_68',\n",
       " 'feature_69',\n",
       " 'feature_70',\n",
       " 'feature_71',\n",
       " 'feature_72',\n",
       " 'feature_73',\n",
       " 'feature_74',\n",
       " 'feature_75',\n",
       " 'feature_76',\n",
       " 'feature_77',\n",
       " 'feature_78',\n",
       " 'feature_79',\n",
       " 'feature_80',\n",
       " 'feature_81',\n",
       " 'feature_82',\n",
       " 'feature_83',\n",
       " 'feature_84',\n",
       " 'feature_85',\n",
       " 'feature_86',\n",
       " 'feature_87',\n",
       " 'feature_88',\n",
       " 'feature_89',\n",
       " 'feature_90',\n",
       " 'feature_91',\n",
       " 'feature_92',\n",
       " 'feature_93',\n",
       " 'feature_94',\n",
       " 'feature_95',\n",
       " 'feature_96',\n",
       " 'feature_97',\n",
       " 'feature_98',\n",
       " 'feature_99',\n",
       " 'feature_100',\n",
       " 'feature_101',\n",
       " 'feature_102',\n",
       " 'feature_103',\n",
       " 'feature_104',\n",
       " 'feature_105',\n",
       " 'feature_106',\n",
       " 'feature_107',\n",
       " 'feature_108',\n",
       " 'feature_109',\n",
       " 'feature_110',\n",
       " 'feature_111',\n",
       " 'feature_112',\n",
       " 'feature_113',\n",
       " 'feature_114',\n",
       " 'feature_115',\n",
       " 'feature_116',\n",
       " 'feature_117',\n",
       " 'feature_118',\n",
       " 'feature_119',\n",
       " 'feature_120',\n",
       " 'feature_121',\n",
       " 'feature_122',\n",
       " 'feature_123',\n",
       " 'feature_124',\n",
       " 'feature_125',\n",
       " 'feature_126',\n",
       " 'feature_127',\n",
       " 'feature_128',\n",
       " 'feature_129',\n",
       " 'feature_130',\n",
       " 'feature_131',\n",
       " 'feature_132',\n",
       " 'feature_133',\n",
       " 'feature_134',\n",
       " 'feature_135',\n",
       " 'feature_136',\n",
       " 'feature_137',\n",
       " 'feature_138',\n",
       " 'feature_139',\n",
       " 'feature_140',\n",
       " 'feature_141',\n",
       " 'feature_142',\n",
       " 'feature_143',\n",
       " 'feature_144',\n",
       " 'feature_145',\n",
       " 'feature_146',\n",
       " 'feature_147',\n",
       " 'feature_148',\n",
       " 'feature_149',\n",
       " 'feature_150',\n",
       " 'feature_151',\n",
       " 'feature_152',\n",
       " 'feature_153',\n",
       " 'feature_154',\n",
       " 'feature_155',\n",
       " 'feature_156',\n",
       " 'feature_157',\n",
       " 'feature_158',\n",
       " 'feature_159',\n",
       " 'feature_160',\n",
       " 'feature_161',\n",
       " 'feature_162',\n",
       " 'feature_163',\n",
       " 'feature_164',\n",
       " 'feature_165',\n",
       " 'feature_166',\n",
       " 'feature_167',\n",
       " 'feature_168',\n",
       " 'feature_169',\n",
       " 'feature_170',\n",
       " 'feature_171',\n",
       " 'feature_172',\n",
       " 'feature_173',\n",
       " 'feature_174',\n",
       " 'feature_175',\n",
       " 'feature_176',\n",
       " 'feature_177',\n",
       " 'feature_178',\n",
       " 'feature_179',\n",
       " 'feature_180',\n",
       " 'feature_181',\n",
       " 'feature_182',\n",
       " 'feature_183',\n",
       " 'feature_184',\n",
       " 'feature_185',\n",
       " 'feature_186',\n",
       " 'feature_187',\n",
       " 'feature_188',\n",
       " 'feature_189',\n",
       " 'feature_190',\n",
       " 'feature_191',\n",
       " 'feature_192',\n",
       " 'feature_193',\n",
       " 'feature_194',\n",
       " 'feature_195',\n",
       " 'feature_196',\n",
       " 'feature_197',\n",
       " 'feature_198',\n",
       " 'feature_199',\n",
       " 'feature_200',\n",
       " 'feature_201',\n",
       " 'feature_202',\n",
       " 'feature_203',\n",
       " 'feature_204',\n",
       " 'feature_205',\n",
       " 'feature_206',\n",
       " 'feature_207',\n",
       " 'feature_208',\n",
       " 'feature_209',\n",
       " 'feature_210',\n",
       " 'feature_211',\n",
       " 'feature_212',\n",
       " 'feature_213',\n",
       " 'feature_214',\n",
       " 'feature_215',\n",
       " 'feature_216',\n",
       " 'feature_217',\n",
       " 'feature_218',\n",
       " 'feature_219',\n",
       " 'feature_220',\n",
       " 'feature_221',\n",
       " 'feature_222',\n",
       " 'feature_223',\n",
       " 'feature_224',\n",
       " 'feature_225',\n",
       " 'feature_226',\n",
       " 'feature_227',\n",
       " 'feature_228',\n",
       " 'feature_229',\n",
       " 'feature_230',\n",
       " 'feature_231',\n",
       " 'feature_232',\n",
       " 'feature_233',\n",
       " 'feature_234',\n",
       " 'feature_235',\n",
       " 'feature_236',\n",
       " 'feature_237',\n",
       " 'feature_238',\n",
       " 'feature_239',\n",
       " 'feature_240',\n",
       " 'feature_241',\n",
       " 'feature_242',\n",
       " 'feature_243',\n",
       " 'feature_244',\n",
       " 'feature_245',\n",
       " 'feature_246',\n",
       " 'feature_247',\n",
       " 'feature_248',\n",
       " 'feature_249',\n",
       " 'feature_250',\n",
       " 'feature_251',\n",
       " 'feature_252',\n",
       " 'feature_253',\n",
       " 'feature_254',\n",
       " 'feature_255',\n",
       " 'feature_256',\n",
       " 'feature_257',\n",
       " 'feature_258',\n",
       " 'feature_259',\n",
       " 'feature_260',\n",
       " 'feature_261',\n",
       " 'feature_262',\n",
       " 'feature_263',\n",
       " 'feature_264',\n",
       " 'feature_265',\n",
       " 'feature_266',\n",
       " 'feature_267',\n",
       " 'feature_268',\n",
       " 'feature_269',\n",
       " 'feature_270',\n",
       " 'feature_271',\n",
       " 'feature_272',\n",
       " 'feature_273',\n",
       " 'feature_274',\n",
       " 'feature_275',\n",
       " 'feature_276',\n",
       " 'feature_277',\n",
       " 'feature_278',\n",
       " 'feature_279',\n",
       " 'feature_280',\n",
       " 'feature_281',\n",
       " 'feature_282',\n",
       " 'feature_283',\n",
       " 'feature_284',\n",
       " 'feature_285',\n",
       " 'feature_286',\n",
       " 'feature_287',\n",
       " 'feature_288',\n",
       " 'feature_289',\n",
       " 'feature_290',\n",
       " 'feature_291',\n",
       " 'feature_292',\n",
       " 'feature_293',\n",
       " 'feature_294',\n",
       " 'feature_295',\n",
       " 'feature_296',\n",
       " 'feature_297',\n",
       " 'feature_298',\n",
       " 'feature_299',\n",
       " 'feature_300',\n",
       " 'feature_301',\n",
       " 'feature_302',\n",
       " 'feature_303',\n",
       " 'feature_304',\n",
       " 'feature_305',\n",
       " 'feature_306',\n",
       " 'feature_307',\n",
       " 'feature_308',\n",
       " 'feature_309',\n",
       " 'feature_310',\n",
       " 'feature_311',\n",
       " 'feature_312',\n",
       " 'feature_313',\n",
       " 'feature_314',\n",
       " 'feature_315',\n",
       " 'feature_316',\n",
       " 'feature_317',\n",
       " 'feature_318',\n",
       " 'feature_319',\n",
       " 'feature_320',\n",
       " 'feature_321',\n",
       " 'feature_322',\n",
       " 'feature_323',\n",
       " 'feature_324',\n",
       " 'feature_325',\n",
       " 'feature_326',\n",
       " 'feature_327',\n",
       " 'feature_328',\n",
       " 'feature_329',\n",
       " 'feature_330',\n",
       " 'feature_331',\n",
       " 'feature_332',\n",
       " 'feature_333',\n",
       " 'feature_334',\n",
       " 'feature_335',\n",
       " 'feature_336',\n",
       " 'feature_337',\n",
       " 'feature_338',\n",
       " 'feature_339',\n",
       " 'feature_340',\n",
       " 'feature_341',\n",
       " 'feature_342',\n",
       " 'feature_343',\n",
       " 'feature_344',\n",
       " 'feature_345',\n",
       " 'feature_346',\n",
       " 'feature_347',\n",
       " 'feature_348',\n",
       " 'feature_349',\n",
       " 'feature_350',\n",
       " 'feature_351',\n",
       " 'feature_352',\n",
       " 'feature_353',\n",
       " 'feature_354',\n",
       " 'feature_355',\n",
       " 'feature_356',\n",
       " 'feature_357',\n",
       " 'feature_358',\n",
       " 'feature_359',\n",
       " 'feature_360',\n",
       " 'feature_361',\n",
       " 'feature_362',\n",
       " 'feature_363',\n",
       " 'feature_364',\n",
       " 'feature_365',\n",
       " 'feature_366',\n",
       " 'feature_367',\n",
       " 'feature_368',\n",
       " 'feature_369',\n",
       " 'feature_370',\n",
       " 'feature_371',\n",
       " 'feature_372',\n",
       " 'feature_373',\n",
       " 'feature_374',\n",
       " 'feature_375',\n",
       " 'feature_376',\n",
       " 'feature_377',\n",
       " 'feature_378',\n",
       " 'feature_379',\n",
       " 'feature_380',\n",
       " 'feature_381',\n",
       " 'feature_382',\n",
       " 'feature_383',\n",
       " 'feature_384',\n",
       " 'feature_385',\n",
       " 'feature_386',\n",
       " 'feature_387',\n",
       " 'feature_388',\n",
       " 'feature_389',\n",
       " 'feature_390',\n",
       " 'feature_391',\n",
       " 'feature_392',\n",
       " 'feature_393',\n",
       " 'feature_394',\n",
       " 'feature_395',\n",
       " 'feature_396',\n",
       " 'feature_397',\n",
       " 'feature_398',\n",
       " 'feature_399',\n",
       " 'feature_400',\n",
       " 'feature_401',\n",
       " 'feature_402',\n",
       " 'feature_403',\n",
       " 'feature_404',\n",
       " 'feature_405',\n",
       " 'feature_406',\n",
       " 'feature_407',\n",
       " 'feature_408',\n",
       " 'feature_409',\n",
       " 'feature_410',\n",
       " 'feature_411',\n",
       " 'feature_412',\n",
       " 'feature_413',\n",
       " 'feature_414',\n",
       " 'feature_415',\n",
       " 'feature_416',\n",
       " 'feature_417',\n",
       " 'feature_418',\n",
       " 'feature_419',\n",
       " 'feature_420',\n",
       " 'feature_421',\n",
       " 'feature_422',\n",
       " 'feature_423',\n",
       " 'feature_424',\n",
       " 'feature_425',\n",
       " 'feature_426',\n",
       " 'feature_427',\n",
       " 'feature_428',\n",
       " 'feature_429',\n",
       " 'feature_430',\n",
       " 'feature_431',\n",
       " 'feature_432',\n",
       " 'feature_433',\n",
       " 'feature_434',\n",
       " 'feature_435',\n",
       " 'feature_436',\n",
       " 'feature_437',\n",
       " 'feature_438',\n",
       " 'feature_439',\n",
       " 'feature_440',\n",
       " 'feature_441',\n",
       " 'feature_442',\n",
       " 'feature_443',\n",
       " 'feature_444',\n",
       " 'feature_445',\n",
       " 'feature_446',\n",
       " 'feature_447',\n",
       " 'feature_448',\n",
       " 'feature_449',\n",
       " 'feature_450',\n",
       " 'feature_451',\n",
       " 'feature_452',\n",
       " 'feature_453',\n",
       " 'feature_454',\n",
       " 'feature_455',\n",
       " 'feature_456',\n",
       " 'feature_457',\n",
       " 'feature_458',\n",
       " 'feature_459',\n",
       " 'feature_460',\n",
       " 'feature_461',\n",
       " 'feature_462',\n",
       " 'feature_463',\n",
       " 'feature_464',\n",
       " 'feature_465',\n",
       " 'feature_466',\n",
       " 'feature_467',\n",
       " 'feature_468',\n",
       " 'feature_469',\n",
       " 'feature_470',\n",
       " 'feature_471',\n",
       " 'feature_472',\n",
       " 'feature_473',\n",
       " 'feature_474',\n",
       " 'feature_475',\n",
       " 'feature_476',\n",
       " 'feature_477',\n",
       " 'feature_478',\n",
       " 'feature_479',\n",
       " 'feature_480',\n",
       " 'feature_481',\n",
       " 'feature_482',\n",
       " 'feature_483',\n",
       " 'feature_484',\n",
       " 'feature_485',\n",
       " 'feature_486',\n",
       " 'feature_487',\n",
       " 'feature_488',\n",
       " 'feature_489',\n",
       " 'feature_490',\n",
       " 'feature_491',\n",
       " 'feature_492',\n",
       " 'feature_493',\n",
       " 'feature_494',\n",
       " 'feature_495',\n",
       " 'feature_496',\n",
       " 'feature_497',\n",
       " 'feature_498',\n",
       " 'feature_499',\n",
       " 'feature_500',\n",
       " 'feature_501',\n",
       " 'feature_502',\n",
       " 'feature_503',\n",
       " 'feature_504',\n",
       " 'feature_505',\n",
       " 'feature_506',\n",
       " 'feature_507',\n",
       " 'feature_508',\n",
       " 'feature_509',\n",
       " 'feature_510',\n",
       " 'feature_511',\n",
       " 'feature_512',\n",
       " 'feature_513',\n",
       " 'feature_514',\n",
       " 'feature_515',\n",
       " 'feature_516',\n",
       " 'feature_517',\n",
       " 'feature_518',\n",
       " 'feature_519',\n",
       " 'feature_520',\n",
       " 'feature_521',\n",
       " 'feature_522',\n",
       " 'feature_523',\n",
       " 'feature_524',\n",
       " 'feature_525',\n",
       " 'feature_526',\n",
       " 'feature_527',\n",
       " 'feature_528',\n",
       " 'feature_529',\n",
       " 'feature_530',\n",
       " 'feature_531',\n",
       " 'feature_532',\n",
       " 'feature_533',\n",
       " 'feature_534',\n",
       " 'feature_535',\n",
       " 'feature_536',\n",
       " 'feature_537',\n",
       " 'feature_538',\n",
       " 'feature_539',\n",
       " 'feature_540',\n",
       " 'feature_541',\n",
       " 'feature_542',\n",
       " 'feature_543',\n",
       " 'feature_544',\n",
       " 'feature_545',\n",
       " 'feature_546',\n",
       " 'feature_547',\n",
       " 'feature_548',\n",
       " 'feature_549',\n",
       " 'feature_550',\n",
       " 'feature_551',\n",
       " 'feature_552',\n",
       " 'feature_553',\n",
       " 'feature_554',\n",
       " 'feature_555',\n",
       " 'feature_556',\n",
       " 'feature_557',\n",
       " 'feature_558',\n",
       " 'feature_559',\n",
       " 'feature_560',\n",
       " 'feature_561',\n",
       " 'feature_562',\n",
       " 'feature_563',\n",
       " 'feature_564',\n",
       " 'feature_565',\n",
       " 'feature_566',\n",
       " 'feature_567',\n",
       " 'feature_568',\n",
       " 'feature_569',\n",
       " 'feature_570',\n",
       " 'feature_571',\n",
       " 'feature_572',\n",
       " 'feature_573',\n",
       " 'feature_574',\n",
       " 'feature_575',\n",
       " 'feature_576',\n",
       " 'feature_577',\n",
       " 'feature_578',\n",
       " 'feature_579',\n",
       " 'feature_580',\n",
       " 'feature_581',\n",
       " 'feature_582',\n",
       " 'feature_583',\n",
       " 'feature_584',\n",
       " 'feature_585',\n",
       " 'feature_586',\n",
       " 'feature_587',\n",
       " 'feature_588',\n",
       " 'feature_589',\n",
       " 'feature_590',\n",
       " 'feature_591',\n",
       " 'feature_592',\n",
       " 'feature_593',\n",
       " 'feature_594',\n",
       " 'feature_595',\n",
       " 'feature_596',\n",
       " 'feature_597',\n",
       " 'feature_598',\n",
       " 'feature_599',\n",
       " 'feature_600',\n",
       " 'feature_601',\n",
       " 'feature_602',\n",
       " 'feature_603',\n",
       " 'feature_604',\n",
       " 'feature_605',\n",
       " 'feature_606',\n",
       " 'feature_607',\n",
       " 'feature_608',\n",
       " 'feature_609',\n",
       " 'feature_610',\n",
       " 'feature_611',\n",
       " 'feature_612',\n",
       " 'feature_613',\n",
       " 'feature_614',\n",
       " 'feature_615',\n",
       " 'feature_616',\n",
       " 'feature_617',\n",
       " 'feature_618',\n",
       " 'feature_619',\n",
       " 'feature_620',\n",
       " 'feature_621',\n",
       " 'feature_622',\n",
       " 'feature_623',\n",
       " 'feature_624',\n",
       " 'feature_625',\n",
       " 'feature_626',\n",
       " 'feature_627',\n",
       " 'feature_628',\n",
       " 'feature_629',\n",
       " 'feature_630',\n",
       " 'feature_631',\n",
       " 'feature_632',\n",
       " 'feature_633',\n",
       " 'feature_634',\n",
       " 'feature_635',\n",
       " 'feature_636',\n",
       " 'feature_637',\n",
       " 'feature_638',\n",
       " 'feature_639',\n",
       " 'feature_640',\n",
       " 'feature_641',\n",
       " 'feature_642',\n",
       " 'feature_643',\n",
       " 'feature_644',\n",
       " 'feature_645',\n",
       " 'feature_646',\n",
       " 'feature_647',\n",
       " 'feature_648',\n",
       " 'feature_649',\n",
       " 'feature_650',\n",
       " 'feature_651',\n",
       " 'feature_652',\n",
       " 'feature_653',\n",
       " 'feature_654',\n",
       " 'feature_655',\n",
       " 'feature_656',\n",
       " 'feature_657',\n",
       " 'feature_658',\n",
       " 'feature_659',\n",
       " 'feature_660',\n",
       " 'feature_661',\n",
       " 'feature_662',\n",
       " 'feature_663',\n",
       " 'feature_664',\n",
       " 'feature_665',\n",
       " 'feature_666',\n",
       " 'feature_667',\n",
       " 'feature_668',\n",
       " 'feature_669',\n",
       " 'feature_670',\n",
       " 'feature_671',\n",
       " 'feature_672',\n",
       " 'feature_673',\n",
       " 'feature_674',\n",
       " 'feature_675',\n",
       " 'feature_676',\n",
       " 'feature_677',\n",
       " 'feature_678',\n",
       " 'feature_679',\n",
       " 'feature_680',\n",
       " 'feature_681',\n",
       " 'feature_682',\n",
       " 'feature_683',\n",
       " 'feature_684',\n",
       " 'feature_685',\n",
       " 'feature_686',\n",
       " 'feature_687',\n",
       " 'feature_688',\n",
       " 'feature_689',\n",
       " 'feature_690',\n",
       " 'feature_691',\n",
       " 'feature_692',\n",
       " 'feature_693',\n",
       " 'feature_694',\n",
       " 'feature_695',\n",
       " 'feature_696',\n",
       " 'feature_697',\n",
       " 'feature_698',\n",
       " 'feature_699',\n",
       " 'feature_700',\n",
       " 'feature_701',\n",
       " 'feature_702',\n",
       " 'feature_703',\n",
       " 'feature_704',\n",
       " 'feature_705',\n",
       " 'feature_706',\n",
       " 'feature_707',\n",
       " 'feature_708',\n",
       " 'feature_709',\n",
       " 'feature_710',\n",
       " 'feature_711',\n",
       " 'feature_712',\n",
       " 'feature_713',\n",
       " 'feature_714',\n",
       " 'feature_715',\n",
       " 'feature_716',\n",
       " 'feature_717',\n",
       " 'feature_718',\n",
       " 'feature_719',\n",
       " 'feature_720',\n",
       " 'feature_721',\n",
       " 'feature_722',\n",
       " 'feature_723',\n",
       " 'feature_724',\n",
       " 'feature_725',\n",
       " 'feature_726',\n",
       " 'feature_727',\n",
       " 'feature_728',\n",
       " 'feature_729',\n",
       " 'feature_730',\n",
       " 'feature_731',\n",
       " 'feature_732',\n",
       " 'feature_733',\n",
       " 'feature_734',\n",
       " 'feature_735',\n",
       " 'feature_736',\n",
       " 'feature_737',\n",
       " 'feature_738',\n",
       " 'feature_739',\n",
       " 'feature_740',\n",
       " 'feature_741',\n",
       " 'feature_742',\n",
       " 'feature_743',\n",
       " 'feature_744',\n",
       " 'feature_745',\n",
       " 'feature_746',\n",
       " 'feature_747',\n",
       " 'feature_748',\n",
       " 'feature_749',\n",
       " 'feature_750',\n",
       " 'feature_751',\n",
       " 'feature_752',\n",
       " 'feature_753',\n",
       " 'feature_754',\n",
       " 'feature_755',\n",
       " 'feature_756',\n",
       " 'feature_757',\n",
       " 'feature_758',\n",
       " 'feature_759',\n",
       " 'feature_760',\n",
       " 'feature_761',\n",
       " 'feature_762',\n",
       " 'feature_763',\n",
       " 'feature_764',\n",
       " 'feature_765',\n",
       " 'feature_766',\n",
       " 'feature_767',\n",
       " 'X..Terpinolene']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_bert.columns.to_list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df_bert.drop(['X..Terpinolene', 'index'], axis = 1)\n",
    "y = df_bert[['X..Terpinolene']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:ylabel='Count'>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "sns.histplot(y, bins = 10)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "pca = PCA()\n",
    "pca_comps = pca.fit_transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 1.66740718e+00, -5.99884740e-01, -3.10677775e-01, ...,\n",
       "         2.79971311e-04,  8.60721958e-04, -1.85314553e-08],\n",
       "       [ 1.66740718e+00, -5.99884740e-01, -3.10677775e-01, ...,\n",
       "         2.79971311e-04,  8.60721958e-04, -1.85314500e-08],\n",
       "       [ 1.66740718e+00, -5.99884740e-01, -3.10677775e-01, ...,\n",
       "         2.79971311e-04,  8.60721958e-04, -1.85314500e-08],\n",
       "       ...,\n",
       "       [ 2.87775466e+00, -2.88229265e-01, -3.06139389e-01, ...,\n",
       "        -2.22496221e-03, -5.92641872e-04, -2.46501209e-09],\n",
       "       [ 1.52280072e+00, -5.74773017e-01, -5.58869101e-01, ...,\n",
       "        -2.24270381e-03, -3.93472344e-03, -9.98878395e-09],\n",
       "       [-1.66775630e+00,  3.98470186e-01, -3.20403939e-01, ...,\n",
       "         2.19163011e-03, -4.06889588e-03, -2.89192044e-08]])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pca_comps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "numpy.ndarray"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(pca_comps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "explained_variance = pca.explained_variance_ratio_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(range(1, len(explained_variance)+1), explained_variance, 'bo-', linewidth=2)\n",
    "plt.xlabel('Number of components')\n",
    "plt.ylabel('Explained variance ratio')\n",
    "plt.title('Scree Plot')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the second derivative of the explained variance ratio curve\n",
    "second_der = np.diff(explained_variance, 2)\n",
    "\n",
    "# Find the index of the maximum value of the second derivative\n",
    "elbow_index = np.argmax(second_der) + 1\n",
    "\n",
    "# The optimal number of components is the index of the elbow point\n",
    "n_components_optimal = elbow_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n_components_optimal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_reduced = pca.transform(X)[:, :n_components_optimal]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 1.66740718],\n",
       "       [ 1.66740718],\n",
       "       [ 1.66740718],\n",
       "       ...,\n",
       "       [ 2.87775466],\n",
       "       [ 1.52280072],\n",
       "       [-1.6677563 ]])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_reduced"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pca_0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.667407</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.667407</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.667407</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.667407</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.667407</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>74995</th>\n",
       "      <td>-1.362526</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>74996</th>\n",
       "      <td>-1.362526</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>74997</th>\n",
       "      <td>2.877755</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>74998</th>\n",
       "      <td>1.522801</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>74999</th>\n",
       "      <td>-1.667756</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>75000 rows Ã— 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          pca_0\n",
       "0      1.667407\n",
       "1      1.667407\n",
       "2      1.667407\n",
       "3      1.667407\n",
       "4      1.667407\n",
       "...         ...\n",
       "74995 -1.362526\n",
       "74996 -1.362526\n",
       "74997  2.877755\n",
       "74998  1.522801\n",
       "74999 -1.667756\n",
       "\n",
       "[75000 rows x 1 columns]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_reduced = pd.DataFrame(X_reduced)\n",
    "X_reduced = X_reduced.add_prefix('pca_')\n",
    "X_reduced"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "train test split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X_reduced, y, random_state=1, test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train1, X_val, y_train1, y_val = train_test_split(X_train, y_train, random_state=1, test_size=0.2)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "kNN (before feature selection and hyperparameter tuning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "knreg = KNeighborsRegressor()\n",
    "knreg.fit(X_train1, y_train1)\n",
    "y_pred_knreg = knreg.predict(X_val)\n",
    "y_pred_knreg_r2 = knreg.predict(X_train1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.05845849530878479"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mean_absolute_error(y_val, y_pred_knreg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.018519957127375836"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mean_squared_error(y_val, y_pred_knreg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.13608804917176173"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mean_squared_error(y_val, y_pred_knreg, squared = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9104726560316883"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#train\n",
    "r2_score(y_train1, y_pred_knreg_r2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8437439248609704"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#val\n",
    "r2_score(y_val, y_pred_knreg)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "RF (before feature selection and hyperparameter tuning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/y1/pjvjlkjn5gl846rnyzr53p340000gn/T/ipykernel_6486/2685114911.py:2: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  rfreg.fit(X_train1, y_train1)\n"
     ]
    }
   ],
   "source": [
    "rfreg = RandomForestRegressor()\n",
    "rfreg.fit(X_train1, y_train1)\n",
    "y_pred_rfreg = rfreg.predict(X_val)\n",
    "y_pred_rfreg_r2 = rfreg.predict(X_train1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0348696613295725"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mean_absolute_error(y_val, y_pred_rfreg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.010706656049250569"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mean_squared_error(y_val, y_pred_rfreg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.1034729725544336"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mean_squared_error(y_val, y_pred_rfreg, squared = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.987637411452636"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#train\n",
    "r2_score(y_train1, y_pred_rfreg_r2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9096660947639843"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#val\n",
    "r2_score(y_val, y_pred_rfreg)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hyperparameter tuning (kNN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "parameters_knn = {'n_neighbors' : [5, 7, 9, 11, 13, 15], \n",
    "              'weights': ['uniform', 'distance']}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "rscv_knn = RandomizedSearchCV(knreg,  \n",
    "                     parameters_knn,   \n",
    "                     cv=5, \n",
    "                     scoring='neg_mean_absolute_error')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;background-color: white;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"â–¸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"â–¾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>RandomizedSearchCV(cv=5, estimator=KNeighborsRegressor(),\n",
       "                   param_distributions={&#x27;n_neighbors&#x27;: [5, 7, 9, 11, 13, 15],\n",
       "                                        &#x27;weights&#x27;: [&#x27;uniform&#x27;, &#x27;distance&#x27;]},\n",
       "                   scoring=&#x27;neg_mean_absolute_error&#x27;)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" ><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">RandomizedSearchCV</label><div class=\"sk-toggleable__content\"><pre>RandomizedSearchCV(cv=5, estimator=KNeighborsRegressor(),\n",
       "                   param_distributions={&#x27;n_neighbors&#x27;: [5, 7, 9, 11, 13, 15],\n",
       "                                        &#x27;weights&#x27;: [&#x27;uniform&#x27;, &#x27;distance&#x27;]},\n",
       "                   scoring=&#x27;neg_mean_absolute_error&#x27;)</pre></div></div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" ><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">estimator: KNeighborsRegressor</label><div class=\"sk-toggleable__content\"><pre>KNeighborsRegressor()</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-3\" type=\"checkbox\" ><label for=\"sk-estimator-id-3\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">KNeighborsRegressor</label><div class=\"sk-toggleable__content\"><pre>KNeighborsRegressor()</pre></div></div></div></div></div></div></div></div></div></div>"
      ],
      "text/plain": [
       "RandomizedSearchCV(cv=5, estimator=KNeighborsRegressor(),\n",
       "                   param_distributions={'n_neighbors': [5, 7, 9, 11, 13, 15],\n",
       "                                        'weights': ['uniform', 'distance']},\n",
       "                   scoring='neg_mean_absolute_error')"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rscv_knn.fit(X_train1, y_train1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'weights': 'distance', 'n_neighbors': 5}"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rscv_knn.best_params_"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "kNN (after hyperparameter tuning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "knreg_ht = KNeighborsRegressor(n_neighbors=5, weights='distance')\n",
    "knreg_ht.fit(X_train1, y_train1)\n",
    "y_pred_knreg_ht = knreg_ht.predict(X_val)\n",
    "y_pred_knreg_ht_r2 = knreg_ht.predict(X_train1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.03036116839655287"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mean_absolute_error(y_val, y_pred_knreg_ht)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.011342876512081377"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mean_squared_error(y_val, y_pred_knreg_ht)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.10650294133065705"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mean_squared_error(y_val, y_pred_knreg_ht, squared = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9998703271525485"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#train\n",
    "r2_score(y_train1, y_pred_knreg_ht_r2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9042981928967533"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#val\n",
    "r2_score(y_val, y_pred_knreg_ht)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hyperparameter tuning (RF)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "parameters_rf = {'max_depth': [None, 10, 50, 100],\n",
    "              'max_features': ['auto', 'sqrt'],\n",
    "              'min_samples_leaf': [1, 2, 4],\n",
    "              'min_samples_split': [2, 5, 10],\n",
    "              'n_estimators': [100, 300, 500]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "rscv_rf = RandomizedSearchCV(rfreg,  \n",
    "                     parameters_rf,   \n",
    "                     cv=5, \n",
    "                     scoring='neg_mean_absolute_error',\n",
    "                     n_jobs = -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/andalanputra/opt/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/Users/andalanputra/opt/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/Users/andalanputra/opt/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/Users/andalanputra/opt/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/Users/andalanputra/opt/anaconda3/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
      "  warn(\n",
      "/Users/andalanputra/opt/anaconda3/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
      "  warn(\n",
      "/Users/andalanputra/opt/anaconda3/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
      "  warn(\n",
      "/Users/andalanputra/opt/anaconda3/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
      "  warn(\n",
      "/Users/andalanputra/opt/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/Users/andalanputra/opt/anaconda3/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
      "  warn(\n",
      "/Users/andalanputra/opt/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/Users/andalanputra/opt/anaconda3/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
      "  warn(\n",
      "/Users/andalanputra/opt/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/Users/andalanputra/opt/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/Users/andalanputra/opt/anaconda3/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
      "  warn(\n",
      "/Users/andalanputra/opt/anaconda3/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
      "  warn(\n",
      "/Users/andalanputra/opt/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/Users/andalanputra/opt/anaconda3/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
      "  warn(\n",
      "/Users/andalanputra/opt/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/Users/andalanputra/opt/anaconda3/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
      "  warn(\n",
      "/Users/andalanputra/opt/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/Users/andalanputra/opt/anaconda3/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
      "  warn(\n",
      "/Users/andalanputra/opt/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/Users/andalanputra/opt/anaconda3/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
      "  warn(\n",
      "/Users/andalanputra/opt/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/Users/andalanputra/opt/anaconda3/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
      "  warn(\n",
      "/Users/andalanputra/opt/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/Users/andalanputra/opt/anaconda3/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
      "  warn(\n",
      "/Users/andalanputra/opt/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/Users/andalanputra/opt/anaconda3/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
      "  warn(\n",
      "/Users/andalanputra/opt/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/Users/andalanputra/opt/anaconda3/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
      "  warn(\n",
      "/Users/andalanputra/opt/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/Users/andalanputra/opt/anaconda3/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
      "  warn(\n",
      "/Users/andalanputra/opt/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/Users/andalanputra/opt/anaconda3/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
      "  warn(\n",
      "/Users/andalanputra/opt/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/Users/andalanputra/opt/anaconda3/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
      "  warn(\n",
      "/Users/andalanputra/opt/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/Users/andalanputra/opt/anaconda3/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
      "  warn(\n",
      "/Users/andalanputra/opt/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/Users/andalanputra/opt/anaconda3/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
      "  warn(\n",
      "/Users/andalanputra/opt/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/Users/andalanputra/opt/anaconda3/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
      "  warn(\n",
      "/Users/andalanputra/opt/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/Users/andalanputra/opt/anaconda3/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
      "  warn(\n",
      "/Users/andalanputra/opt/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/Users/andalanputra/opt/anaconda3/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
      "  warn(\n",
      "/Users/andalanputra/opt/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/Users/andalanputra/opt/anaconda3/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
      "  warn(\n",
      "/Users/andalanputra/opt/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/Users/andalanputra/opt/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/Users/andalanputra/opt/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/Users/andalanputra/opt/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/Users/andalanputra/opt/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/Users/andalanputra/opt/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/Users/andalanputra/opt/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/Users/andalanputra/opt/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/Users/andalanputra/opt/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/Users/andalanputra/opt/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/Users/andalanputra/opt/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/Users/andalanputra/opt/anaconda3/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
      "  warn(\n",
      "/Users/andalanputra/opt/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/Users/andalanputra/opt/anaconda3/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
      "  warn(\n",
      "/Users/andalanputra/opt/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/Users/andalanputra/opt/anaconda3/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
      "  warn(\n",
      "/Users/andalanputra/opt/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/Users/andalanputra/opt/anaconda3/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
      "  warn(\n",
      "/Users/andalanputra/opt/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/Users/andalanputra/opt/anaconda3/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
      "  warn(\n",
      "/Users/andalanputra/opt/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/Users/andalanputra/opt/anaconda3/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
      "  warn(\n",
      "/Users/andalanputra/opt/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/Users/andalanputra/opt/anaconda3/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
      "  warn(\n",
      "/Users/andalanputra/opt/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/Users/andalanputra/opt/anaconda3/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
      "  warn(\n",
      "/Users/andalanputra/opt/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/Users/andalanputra/opt/anaconda3/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
      "  warn(\n",
      "/Users/andalanputra/opt/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/Users/andalanputra/opt/anaconda3/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
      "  warn(\n",
      "/Users/andalanputra/opt/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/Users/andalanputra/opt/anaconda3/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
      "  warn(\n",
      "/Users/andalanputra/opt/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/Users/andalanputra/opt/anaconda3/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
      "  warn(\n",
      "/Users/andalanputra/opt/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/Users/andalanputra/opt/anaconda3/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
      "  warn(\n",
      "/Users/andalanputra/opt/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/Users/andalanputra/opt/anaconda3/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
      "  warn(\n",
      "/Users/andalanputra/opt/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/Users/andalanputra/opt/anaconda3/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
      "  warn(\n",
      "/Users/andalanputra/opt/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_search.py:909: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  self.best_estimator_.fit(X, y, **fit_params)\n",
      "/Users/andalanputra/opt/anaconda3/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
      "  warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-2 {color: black;background-color: white;}#sk-container-id-2 pre{padding: 0;}#sk-container-id-2 div.sk-toggleable {background-color: white;}#sk-container-id-2 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-2 label.sk-toggleable__label-arrow:before {content: \"â–¸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-2 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-2 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-2 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-2 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-2 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-2 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"â–¾\";}#sk-container-id-2 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-2 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-2 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-2 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-2 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-2 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-2 div.sk-item {position: relative;z-index: 1;}#sk-container-id-2 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-2 div.sk-item::before, #sk-container-id-2 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-2 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-2 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-2 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-2 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-2 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-2 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-2 div.sk-label-container {text-align: center;}#sk-container-id-2 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-2 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-2\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>RandomizedSearchCV(cv=5, estimator=RandomForestRegressor(), n_jobs=-1,\n",
       "                   param_distributions={&#x27;max_depth&#x27;: [None, 10, 50, 100],\n",
       "                                        &#x27;max_features&#x27;: [&#x27;auto&#x27;, &#x27;sqrt&#x27;],\n",
       "                                        &#x27;min_samples_leaf&#x27;: [1, 2, 4],\n",
       "                                        &#x27;min_samples_split&#x27;: [2, 5, 10],\n",
       "                                        &#x27;n_estimators&#x27;: [100, 300, 500]},\n",
       "                   scoring=&#x27;neg_mean_absolute_error&#x27;)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-4\" type=\"checkbox\" ><label for=\"sk-estimator-id-4\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">RandomizedSearchCV</label><div class=\"sk-toggleable__content\"><pre>RandomizedSearchCV(cv=5, estimator=RandomForestRegressor(), n_jobs=-1,\n",
       "                   param_distributions={&#x27;max_depth&#x27;: [None, 10, 50, 100],\n",
       "                                        &#x27;max_features&#x27;: [&#x27;auto&#x27;, &#x27;sqrt&#x27;],\n",
       "                                        &#x27;min_samples_leaf&#x27;: [1, 2, 4],\n",
       "                                        &#x27;min_samples_split&#x27;: [2, 5, 10],\n",
       "                                        &#x27;n_estimators&#x27;: [100, 300, 500]},\n",
       "                   scoring=&#x27;neg_mean_absolute_error&#x27;)</pre></div></div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-5\" type=\"checkbox\" ><label for=\"sk-estimator-id-5\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">estimator: RandomForestRegressor</label><div class=\"sk-toggleable__content\"><pre>RandomForestRegressor()</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-6\" type=\"checkbox\" ><label for=\"sk-estimator-id-6\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">RandomForestRegressor</label><div class=\"sk-toggleable__content\"><pre>RandomForestRegressor()</pre></div></div></div></div></div></div></div></div></div></div>"
      ],
      "text/plain": [
       "RandomizedSearchCV(cv=5, estimator=RandomForestRegressor(), n_jobs=-1,\n",
       "                   param_distributions={'max_depth': [None, 10, 50, 100],\n",
       "                                        'max_features': ['auto', 'sqrt'],\n",
       "                                        'min_samples_leaf': [1, 2, 4],\n",
       "                                        'min_samples_split': [2, 5, 10],\n",
       "                                        'n_estimators': [100, 300, 500]},\n",
       "                   scoring='neg_mean_absolute_error')"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rscv_rf.fit(X_train1, y_train1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'n_estimators': 500,\n",
       " 'min_samples_split': 2,\n",
       " 'min_samples_leaf': 1,\n",
       " 'max_features': 'auto',\n",
       " 'max_depth': 100}"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rscv_rf.best_params_"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "RF (after hyperparameter tuning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/y1/pjvjlkjn5gl846rnyzr53p340000gn/T/ipykernel_6486/1958167865.py:2: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  rfreg_ht.fit(X_train1, y_train1)\n",
      "/Users/andalanputra/opt/anaconda3/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
      "  warn(\n"
     ]
    }
   ],
   "source": [
    "rfreg_ht = RandomForestRegressor(n_estimators=500, min_samples_leaf=1, min_samples_split=2, max_features='auto', max_depth=100)\n",
    "rfreg_ht.fit(X_train1, y_train1)\n",
    "y_pred_rfreg_ht = rfreg_ht.predict(X_val)\n",
    "y_pred_rfreg_ht_r2 = rfreg_ht.predict(X_train1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.03498653887588823"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mean_absolute_error(y_val, y_pred_rfreg_ht)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.010721392606001691"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mean_squared_error(y_val, y_pred_rfreg_ht)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.10354415775890831"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mean_squared_error(y_val, y_pred_rfreg_ht, squared = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9878075748854683"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#train\n",
    "r2_score(y_train1, y_pred_rfreg_ht_r2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.909541759890898"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#val\n",
    "r2_score(y_val, y_pred_rfreg_ht)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Predicting on the test set (kNN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_knreg_test = knreg_ht.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['y_test_knreg_bert_terpi.pkl']"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import joblib\n",
    "\n",
    "joblib.dump(y_pred_knreg_test, \"y_pred_knreg_test_bert_terpi.pkl\")\n",
    "joblib.dump(y_test, \"y_test_knreg_bert_terpi.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.029421466517515267"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mean_absolute_error(y_test, y_pred_knreg_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.010782722689716804"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mean_squared_error(y_test, y_pred_knreg_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.10383988968463326"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mean_squared_error(y_test, y_pred_knreg_test, squared = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9098858567518657"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "r2_score(y_test, y_pred_knreg_test)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Error analysis (kNN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 576x432 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 432x288 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# assume y_pred is a numpy array and y_true is a pandas dataframe\n",
    "fig, ax = plt.subplots(figsize=(8, 6))\n",
    "\n",
    "column = \"X..Terpinolene\"  # specify the target variable name\n",
    "ax.hist(y_pred_knreg_test, alpha=0.5, label='y_pred', bins=20)\n",
    "ax.hist(y_test[column], alpha=0.5, label='y_true', bins=20)\n",
    "ax.legend(loc='upper right')\n",
    "ax.set_title(column)\n",
    "\n",
    "plt.show()\n",
    "plt.savefig('error_hist_knn_bert_terpi.png')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pearson R (kNN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pearson correlation coefficient: 0.956\n",
      "P-value: 0.000\n"
     ]
    }
   ],
   "source": [
    "corr_coef, p_value = pearsonr(y_pred_knreg_test.flatten(), y_test.values.ravel())\n",
    "\n",
    "print(f\"Pearson correlation coefficient: {corr_coef:.3f}\")\n",
    "print(f\"P-value: {p_value:.3f}\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Predicting on the test set (RF)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_rfreg_test = rfreg_ht.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['y_test_rfreg_bert_terpi.pkl']"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "joblib.dump(y_pred_rfreg_test, \"y_pred_rfreg_test_bert_terpi.pkl\")\n",
    "joblib.dump(y_test, \"y_test_rfreg_bert_terpi.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.03490246606372261"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mean_absolute_error(y_test, y_pred_rfreg_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.010346745350714635"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mean_squared_error(y_test, y_pred_rfreg_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.10171895276060718"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mean_squared_error(y_test, y_pred_rfreg_test, squared = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9135294378315544"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "r2_score(y_test, y_pred_rfreg_test)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Error analysis (RF)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 576x432 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 432x288 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# assume y_pred is a numpy array and y_true is a pandas dataframe\n",
    "fig, ax = plt.subplots(figsize=(8, 6))\n",
    "\n",
    "column = \"X..Terpinolene\"  # specify the target variable name\n",
    "ax.hist(y_pred_rfreg_test, alpha=0.5, label='y_pred', bins=20)\n",
    "ax.hist(y_test[column], alpha=0.5, label='y_true', bins=20)\n",
    "ax.legend(loc='upper right')\n",
    "ax.set_title(column)\n",
    "\n",
    "plt.show()\n",
    "plt.savefig('error_hist_rf_bert_terpi.png')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pearson R (RF)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pearson correlation coefficient: 0.957\n",
      "P-value: 0.000\n"
     ]
    }
   ],
   "source": [
    "corr_coef, p_value = pearsonr(y_pred_rfreg_test.flatten(), y_test.values.ravel())\n",
    "\n",
    "print(f\"Pearson correlation coefficient: {corr_coef:.3f}\")\n",
    "print(f\"P-value: {p_value:.3f}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
