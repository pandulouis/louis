{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn import preprocessing\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.neural_network import MLPRegressor\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "from sklearn.metrics import r2_score\n",
    "from scipy.stats import pearsonr\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.feature_selection import SelectFromModel\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compiling complete dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_rf = pd.read_csv(\"df_cbn_lsa.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>lsa_0</th>\n",
       "      <th>lsa_1</th>\n",
       "      <th>lsa_2</th>\n",
       "      <th>lsa_3</th>\n",
       "      <th>lsa_4</th>\n",
       "      <th>hybrid</th>\n",
       "      <th>indica</th>\n",
       "      <th>sativa</th>\n",
       "      <th>anxiety</th>\n",
       "      <th>...</th>\n",
       "      <th>sweet</th>\n",
       "      <th>tar</th>\n",
       "      <th>tea</th>\n",
       "      <th>tobacco</th>\n",
       "      <th>tree</th>\n",
       "      <th>tropical</th>\n",
       "      <th>vanilla</th>\n",
       "      <th>violet</th>\n",
       "      <th>woody</th>\n",
       "      <th>X..CBN</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0.341025</td>\n",
       "      <td>0.182753</td>\n",
       "      <td>0.008214</td>\n",
       "      <td>0.140406</td>\n",
       "      <td>-0.156943</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.137931</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0.341025</td>\n",
       "      <td>0.182753</td>\n",
       "      <td>0.008214</td>\n",
       "      <td>0.140406</td>\n",
       "      <td>-0.156943</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.137931</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>0.232158</td>\n",
       "      <td>-0.045496</td>\n",
       "      <td>0.187131</td>\n",
       "      <td>-0.000936</td>\n",
       "      <td>0.018518</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.137931</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>0.232158</td>\n",
       "      <td>-0.045496</td>\n",
       "      <td>0.187131</td>\n",
       "      <td>-0.000936</td>\n",
       "      <td>0.018518</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.137931</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>0.232158</td>\n",
       "      <td>-0.045496</td>\n",
       "      <td>0.187131</td>\n",
       "      <td>-0.000936</td>\n",
       "      <td>0.018518</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.137931</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>74995</th>\n",
       "      <td>42972</td>\n",
       "      <td>0.181714</td>\n",
       "      <td>-0.045560</td>\n",
       "      <td>-0.055692</td>\n",
       "      <td>0.015649</td>\n",
       "      <td>-0.045585</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.103448</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>74996</th>\n",
       "      <td>42973</td>\n",
       "      <td>0.055494</td>\n",
       "      <td>0.003622</td>\n",
       "      <td>-0.050252</td>\n",
       "      <td>-0.024795</td>\n",
       "      <td>-0.031141</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.103448</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>74997</th>\n",
       "      <td>42974</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.103448</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>74998</th>\n",
       "      <td>42974</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.103448</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>74999</th>\n",
       "      <td>42975</td>\n",
       "      <td>0.324915</td>\n",
       "      <td>0.131823</td>\n",
       "      <td>-0.099424</td>\n",
       "      <td>0.065491</td>\n",
       "      <td>0.038437</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.103448</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>75000 rows × 88 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       index     lsa_0     lsa_1     lsa_2     lsa_3     lsa_4  hybrid  \\\n",
       "0          0  0.341025  0.182753  0.008214  0.140406 -0.156943       1   \n",
       "1          0  0.341025  0.182753  0.008214  0.140406 -0.156943       1   \n",
       "2          1  0.232158 -0.045496  0.187131 -0.000936  0.018518       1   \n",
       "3          1  0.232158 -0.045496  0.187131 -0.000936  0.018518       1   \n",
       "4          1  0.232158 -0.045496  0.187131 -0.000936  0.018518       1   \n",
       "...      ...       ...       ...       ...       ...       ...     ...   \n",
       "74995  42972  0.181714 -0.045560 -0.055692  0.015649 -0.045585       0   \n",
       "74996  42973  0.055494  0.003622 -0.050252 -0.024795 -0.031141       0   \n",
       "74997  42974  0.000000  0.000000  0.000000  0.000000  0.000000       0   \n",
       "74998  42974  0.000000  0.000000  0.000000  0.000000  0.000000       0   \n",
       "74999  42975  0.324915  0.131823 -0.099424  0.065491  0.038437       0   \n",
       "\n",
       "       indica  sativa  anxiety  ...  sweet  tar  tea  tobacco  tree  tropical  \\\n",
       "0           0       0        0  ...      0    0    0        0     0         0   \n",
       "1           0       0        0  ...      0    0    0        0     0         0   \n",
       "2           0       0        0  ...      0    0    0        0     0         0   \n",
       "3           0       0        0  ...      0    0    0        0     0         0   \n",
       "4           0       0        0  ...      0    0    0        0     0         0   \n",
       "...       ...     ...      ...  ...    ...  ...  ...      ...   ...       ...   \n",
       "74995       1       0        0  ...      0    0    0        0     0         0   \n",
       "74996       1       0        0  ...      0    0    0        0     0         0   \n",
       "74997       1       0        0  ...      0    0    0        0     0         0   \n",
       "74998       1       0        0  ...      0    0    0        0     0         0   \n",
       "74999       1       0        0  ...      0    0    0        0     0         0   \n",
       "\n",
       "       vanilla  violet  woody    X..CBN  \n",
       "0            0       0      0  0.137931  \n",
       "1            0       0      0  0.137931  \n",
       "2            1       0      0  0.137931  \n",
       "3            1       0      0  0.137931  \n",
       "4            1       0      0  0.137931  \n",
       "...        ...     ...    ...       ...  \n",
       "74995        0       0      0  0.103448  \n",
       "74996        0       0      0  0.103448  \n",
       "74997        0       0      0  0.103448  \n",
       "74998        0       0      0  0.103448  \n",
       "74999        0       0      0  0.103448  \n",
       "\n",
       "[75000 rows x 88 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_rf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['index',\n",
       " 'lsa_0',\n",
       " 'lsa_1',\n",
       " 'lsa_2',\n",
       " 'lsa_3',\n",
       " 'lsa_4',\n",
       " 'hybrid',\n",
       " 'indica',\n",
       " 'sativa',\n",
       " 'anxiety',\n",
       " 'anxious',\n",
       " 'aroused',\n",
       " 'arthritis',\n",
       " 'creative',\n",
       " 'depression',\n",
       " 'dizzy',\n",
       " 'dry eyes',\n",
       " 'dry mouth',\n",
       " 'energetic',\n",
       " 'epilepsy',\n",
       " 'euphoric',\n",
       " 'eye pressure',\n",
       " 'fatigue',\n",
       " 'focused',\n",
       " 'giggly',\n",
       " 'happy',\n",
       " 'headache',\n",
       " 'hungry',\n",
       " 'migraines',\n",
       " 'pain',\n",
       " 'paranoid',\n",
       " 'relaxed',\n",
       " 'seizures',\n",
       " 'sleepy',\n",
       " 'spasticity',\n",
       " 'stress',\n",
       " 'talkative',\n",
       " 'tingly',\n",
       " 'uplifted',\n",
       " 'ammonia',\n",
       " 'apple',\n",
       " 'apricot',\n",
       " 'berry',\n",
       " 'blue cheese',\n",
       " 'blueberry',\n",
       " 'butter',\n",
       " 'cheese',\n",
       " 'chemical',\n",
       " 'chestnut',\n",
       " 'citrus',\n",
       " 'coffee',\n",
       " 'diesel',\n",
       " 'earthy',\n",
       " 'flowery',\n",
       " 'fruit',\n",
       " 'grape',\n",
       " 'grapefruit',\n",
       " 'honey',\n",
       " 'lavender',\n",
       " 'lemon',\n",
       " 'lime',\n",
       " 'mango',\n",
       " 'menthol',\n",
       " 'mint',\n",
       " 'nutty',\n",
       " 'orange',\n",
       " 'peach',\n",
       " 'pear',\n",
       " 'pepper',\n",
       " 'pine',\n",
       " 'pineapple',\n",
       " 'plum',\n",
       " 'pungent',\n",
       " 'rose',\n",
       " 'sage',\n",
       " 'skunk',\n",
       " 'spicy/herbal',\n",
       " 'strawberry',\n",
       " 'sweet',\n",
       " 'tar',\n",
       " 'tea',\n",
       " 'tobacco',\n",
       " 'tree',\n",
       " 'tropical',\n",
       " 'vanilla',\n",
       " 'violet',\n",
       " 'woody',\n",
       " 'X..CBN']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_rf.columns.to_list()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Splitting dependent and independent variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df_rf.drop(['index', 'X..CBN'], axis = 1)\n",
    "y = df_rf[['X..CBN']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plotting histograms on target variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.13793103],\n",
       "       [0.13793103],\n",
       "       [0.13793103],\n",
       "       ...,\n",
       "       [0.10344828],\n",
       "       [0.10344828],\n",
       "       [0.10344828]])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_array = y.to_numpy()\n",
    "y_array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:ylabel='Count'>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAZIAAAD4CAYAAADGmmByAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjQuMywgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/MnkTPAAAACXBIWXMAAAsTAAALEwEAmpwYAAAZdUlEQVR4nO3df5TV9X3n8ecrMAIxYhRHl2VmmKmhKnBqKqOlSbfHhk0kaU+wG3VJrUCW7ByRZq1GG2jOWfecDcaceCJruuAh6gIplVBqI9ktqRSNbk740TESEQl1qnW4lcpErGBciZD3/nE/o9eZOzOX+d4fc5nX45x77ve+v9/P/X4+6Lmv+f5WRGBmZjZc76t1B8zMrL45SMzMLBMHiZmZZeIgMTOzTBwkZmaWydhad6DazjvvvGhtba11N8zM6spTTz31s4hoLDZv1AVJa2srnZ2dte6GmVldkfTSQPO8a8vMzDJxkJiZWSYOEjMzy2TUHSMp5u233yaXy/HWW2/Vuisjyvjx42lqaqKhoaHWXTGzEcxBAuRyOc466yxaW1uRVOvujAgRwauvvkoul6Otra3W3TGzEcy7toC33nqLSZMmOUQKSGLSpEneSjOzITlIEodIf/43MbNSOEjMzCwTB0kRzS1TkVS2V3PL1EHXd/DgQdra2jhy5AgAr732Gm1tbbz00oDX/wBw9913c/HFFzNz5kwuvfRS1q9fD8CVV17JRRddxIc//GEuueQS1qxZ806b1tZWPvOZz7zzefPmzSxatGiY/1JmZj7YXlTuYDffePRA2b7v1k9cNOj85uZmlixZwrJly1izZg3Lli2jo6ODqVMHDqD77ruPbdu2sXv3biZOnMjrr7/Od7/73Xfmb9iwgfb2do4cOcKFF17IokWLOOOMMwDo7Oxk3759zJgxoyzjM7PSNbdMJXewuybrbmpu4WD34H+gDoeDZIS45ZZbmDVrFitXruSHP/wh3/zmNwdd/s477+Txxx9n4sSJAJx99tksXLiw33JvvPEGZ555JmPGjHmndtttt3HnnXeyYcOG8g7CzIZU7j9UT8VQf9QOl4NkhGhoaODrX/86c+fO5dFHH31n66GYY8eOcezYMS688MIBl7n++usZN24czz//PCtXrnxPkFx33XWsWrWKrq6uso7BzEYnHyMZQbZu3crkyZN59tlnB10uIoY8o2rDhg0888wzdHd3c/fdd7/neMuYMWO4/fbb+epXv1qWfpvZ6OYgGSH27NnDtm3b2LlzJ/fccw+HDh0acNmJEydy5pln8sILLwz5vY2NjVx22WXs2rXrPfUbbriBJ598ku7u2uyrNbPTh4NkBIgIlixZwsqVK2lpaeH222/ntttuG7TN8uXLWbp0KUePHgXg6NGj7zk7q9ebb77J008/3W83WENDA7fccgsrV64s2zjMbHTyMZIimppbynpQqqm5ZdD53/rWt2hpaeHjH/84ADfddBNr167liSee4Oabb2bPnj0AfP7zn+fGG2+kvb2dJUuW8MYbb3D55ZfT0NBAQ0MDX/ziF9/5zuuvv54JEyZw/PhxFi1axKxZs/qtd/HixXzlK18p2zjNbHRSRNS6D1XV3t4efR9stX//fi655JIa9Whk87+NWXlJqulZW8P9zZf0VES0F5vnXVtmZpaJg8TMzDKpWJBIelDSYUn9zmWVdJukkHReQW25pC5JByRdVVCfJWlvmnev0nmvksZJ+k6q75LUmqW/o20XXyn8b2JmpajkFslaYG7foqRm4ONAd0FtOjAfmJHarJLUewXdaqADmJZevd+5GHgtIj4E3AN8bbgdHT9+PK+++qp/OAv0Po9k/Pjxte6KmY1wFTtrKyKeHGAr4R7gT4BHCmrzgI0RcRx4UVIXcIWkfwImRsQOAEnrgauBranNf0vtNwN/JkkxjDRoamoil8vR09Nzqk1Pa71PSDQzG0xVT/+V9GngnyPiJ32uzJ4C7Cz4nEu1t9N033pvm4MAEXFC0uvAJOBnp9qvhoYGPwXQzGyYqhYkkt4PfBn4RLHZRWoxSH2wNsXW3UF+9xgtLYNf02FmZqemmmdtXQi0AT9Ju6yagB9L+jfktzSaC5ZtAl5O9aYidQrbSBoLnA0cKbbiiFgTEe0R0d7Y2Fi2AZmZWRWDJCL2RsT5EdEaEa3kg+CyiPgXYAswP52J1Ub+oPruiDgEHJM0O52ttYB3j61sAXrvm34N8Nhwjo+YmVk2lTz99yFgB3CRpJykxQMtGxH7gE3Ac8D3gaURcTLNXgLcD3QB/0j+QDvAA8CkdGD+VmBZRQZiZmaDquRZW58dYn5rn88rgBVFlusEZhapvwVcm62XZmaWla9sNzOzTBwkZmaWiYPEzMwycZCYmVkmDhIzM8vEQWJmZpk4SMzMLBMHiZmZZeIgMTOzTBwkZmaWiYPEzMwycZCYmVkmDhIzM8vEQWJmZpk4SMzMLBMHiZmZZeIgMTOzTBwkZmaWiYPEzMwyqViQSHpQ0mFJzxbUvi7pp5KekfTXkj5YMG+5pC5JByRdVVCfJWlvmnevJKX6OEnfSfVdklorNRYzMxtYJbdI1gJz+9S2ATMj4teAfwCWA0iaDswHZqQ2qySNSW1WAx3AtPTq/c7FwGsR8SHgHuBrFRuJmZkNqGJBEhFPAkf61B6NiBPp406gKU3PAzZGxPGIeBHoAq6QNBmYGBE7IiKA9cDVBW3WpenNwJzerRUzM6ueWh4j+U/A1jQ9BThYMC+XalPSdN/6e9qkcHodmFRsRZI6JHVK6uzp6SnbAMzMrEZBIunLwAlgQ2+pyGIxSH2wNv2LEWsioj0i2hsbG0+1u2ZmNoiqB4mkhcDvAden3VWQ39JoLlisCXg51ZuK1N/TRtJY4Gz67EozM7PKq2qQSJoLfAn4dES8WTBrCzA/nYnVRv6g+u6IOAQckzQ7Hf9YADxS0GZhmr4GeKwgmMzMrErGVuqLJT0EXAmcJykH3EH+LK1xwLZ0XHxnRNwYEfskbQKeI7/La2lEnExftYT8GWATyB9T6T2u8gDwbUld5LdE5ldqLGZmNrCKBUlEfLZI+YFBll8BrChS7wRmFqm/BVybpY9mZpadr2w3M7NMHCRmZpaJg8TMzDJxkJiZWSYOEhtUc8tUJNXk1dwytdbDN7MSVOysLTs95A52841HD9Rk3bd+4qKarNfMTo23SMzMLBMHiZmZZeIgMTOzTBwkZmaWiYPEzMwycZCYmVkmDhIzM8vEQWJmZpk4SMysZncw8N0LTg++st3ManYHA9+94PTgLRIzM8vEQWJmZpk4SMzMLJOKBYmkByUdlvRsQe1cSdskPZ/ezymYt1xSl6QDkq4qqM+StDfNu1eSUn2cpO+k+i5JrZUai5mZDaySWyRrgbl9asuA7RExDdiePiNpOjAfmJHarJI0JrVZDXQA09Kr9zsXA69FxIeAe4CvVWwkZmY2oIoFSUQ8CRzpU54HrEvT64CrC+obI+J4RLwIdAFXSJoMTIyIHRERwPo+bXq/azMwp3drxczMqqfax0guiIhDAOn9/FSfAhwsWC6XalPSdN/6e9pExAngdWBSsZVK6pDUKamzp6enTEMxMzMYOQfbi21JxCD1wdr0L0asiYj2iGhvbGwcZhfNzKyYagfJK2l3Fen9cKrngOaC5ZqAl1O9qUj9PW0kjQXOpv+uNDMzq7BqB8kWYGGaXgg8UlCfn87EaiN/UH132v11TNLsdPxjQZ82vd91DfBYOo5iZmZVVLFbpEh6CLgSOE9SDrgDuAvYJGkx0A1cCxAR+yRtAp4DTgBLI+Jk+qol5M8AmwBsTS+AB4BvS+oivyUyv1JjMTOzgVUsSCLiswPMmjPA8iuAFUXqncDMIvW3SEFkZma1M1IOtpuZWZ1ykJiZWSYOEjMzy8RBYtaHH/Jkdmr8YCuzPvyQJ7NT4y0SMzPLxEFiZmaZOEjMzCwTB4mZmWXiIDEzs0wcJGZmlklJQSLpo6XUzMxs9Cl1i+SbJdbMzGyUGfSCREm/CXwEaJR0a8GsicCYSnbMzMzqw1BXtp8BfCAtd1ZB/Sj5h0mZmdkoN2iQRMQTwBOS1kbES1Xqk5mZ1ZFS77U1TtIaoLWwTUR8rBKdMjOz+lFqkPwlcB9wP3ByiGXNzGwUKfWsrRMRsToidkfEU72v4a5U0i2S9kl6VtJDksZLOlfSNknPp/dzCpZfLqlL0gFJVxXUZ0nam+bdK0nD7ZOZmQ1PqUHyPUk3SZqcfvDPlXTucFYoaQrwX4D2iJhJ/uyv+cAyYHtETAO2p89Imp7mzwDmAqsk9Z4xthroAKal19zh9MnMzIav1CBZCNwO/Ah4Kr06M6x3LDBB0ljg/cDLwDxgXZq/Drg6Tc8DNkbE8Yh4EegCrpA0GZgYETsiIoD1BW3MzKxKSjpGEhFt5VphRPyzpLuBbuD/AY9GxKOSLoiIQ2mZQ5LOT02mADsLviKXam+n6b71fiR1kN9yoaWlZdh9b26ZSu5g97DbZ9HU3MLBbp84Z2YjT0lBImlBsXpErD/VFaZjH/OANuBfgb+U9IeDNSm26kHq/YsRa4A1AO3t7UWXKUWtnpwHfnqemY1cpZ61dXnB9HhgDvBj8ruTTtW/B16MiB4ASQ+Tv3r+FUmT09bIZOBwWj4HNBe0byK/KyyXpvvWzcysikrdtfWFws+Szga+Pcx1dgOzJb2f/K6tOeSPt/yc/LGYu9L7I2n5LcBfSPoG8G/JH1TfHREnJR2TNBvYBSzA9/8yM6u6UrdI+nqT/A/6KYuIXZI2k9+iOQE8TX630weATZIWkw+ba9Py+yRtAp5Lyy+NiN5rWZYAa4EJwNb0MjOzKir1GMn3ePf4wxjgEmDTcFcaEXcAd/QpHye/dVJs+RXAiiL1TmDmcPthZmbZlbpFcnfB9AngpYjIDbSwmZmNHiVdR5Ju3vhT8ncAPgf4RSU7ZWZm9aPUJyReB+wmf9ziOmCXJN9G3szMSt619WXg8og4DCCpEfg7YHOlOmZmZvWh1FukvK83RJJXT6GtmZmdxkrdIvm+pL8FHkqf/yPwN5XpkpmZ1ZOhntn+IeCCiLhd0n8Afov8rUl2ABuq0D8zMxvhhto9tRI4BhARD0fErRFxC/mtkZWV7ZqZmdWDoXZttUbEM32LEdEpqbUyXbKi9D783C4zG4mGCpLxg8ybUM6O2BDilzW587DvOmxmQxlq19bfS/rPfYvpfljDftSumZmdPobaIvlj4K8lXc+7wdEOnAH8fgX7ZWZmdWLQIImIV4CPSPod3r054v+JiMcq3jMzM6sLpT6P5HHg8Qr3xczM6pCvTjczs0wcJGZmlomDxMzMMnGQmJlZJg4SMzPLpCZBIumDkjZL+qmk/ZJ+U9K5krZJej69n1Ow/HJJXZIOSLqqoD5L0t407175HiJmZlVXqy2S/wF8PyIuBi4F9gPLgO0RMQ3Ynj4jaTowH5gBzAVWSRqTvmc10AFMS6+51RyEmZnVIEgkTQR+G3gAICJ+ERH/CswD1qXF1gFXp+l5wMaIOB4RLwJdwBWSJgMTI2JHRASwvqCNmZlVSS22SH4F6AH+l6SnJd0v6Uzyzz05BJDez0/LTwEOFrTPpdqUNN233o+kDkmdkjp7enrKOxozs1GuFkEyFrgMWB0Rvw78nLQbawDFjnvEIPX+xYg1EdEeEe2NjY2n2l8zMxtELYIkB+QiYlf6vJl8sLySdleR3g8XLN9c0L4JeDnVm4rUzcysiqoeJBHxL8BBSb0PupgDPAdsARam2kLgkTS9BZgvaZykNvIH1Xen3V/HJM1OZ2stKGhjZmZVUtJNGyvgC8AGSWcALwCfIx9qm9KzTrqBawEiYp+kTeTD5gSwNCJOpu9ZAqwl/5CtrellVp/8FEyrUzUJkojYQ/65Jn3NGWD5FcCKIvVO3r29vVl9q9FTMMFPwrRsfGW7mZll4iAxM7NMHCRmZpaJg8TMzDJxkJiZWSYOEjMzy8RBYmZmmThIzMwsEweJmZll4iAxM7NMHCRmZpaJg8TMzDJxkJiZWSYOEjMzy8RBYmZmmThIzMwsEweJmdVOeipkLV7NLVNrPfrTRq0etWtm5qdCniZqtkUiaYykpyX97/T5XEnbJD2f3s8pWHa5pC5JByRdVVCfJWlvmnev/MBrM7Oqq+WurZuB/QWflwHbI2IasD19RtJ0YD4wA5gLrJI0JrVZDXQA09JrbnW6bmZmvWoSJJKagN8F7i8ozwPWpel1wNUF9Y0RcTwiXgS6gCskTQYmRsSOiAhgfUEbMzOrklptkawE/gT4ZUHtgog4BJDez0/1KcDBguVyqTYlTfetm5lZFVU9SCT9HnA4Ip4qtUmRWgxSL7bODkmdkjp7enpKXK2ZmZWiFlskHwU+LemfgI3AxyT9OfBK2l1Fej+cls8BzQXtm4CXU72pSL2fiFgTEe0R0d7Y2FjOsZiZjXpVD5KIWB4RTRHRSv4g+mMR8YfAFmBhWmwh8Eia3gLMlzROUhv5g+q70+6vY5Jmp7O1FhS0MTOzKhlJ15HcBWyStBjoBq4FiIh9kjYBzwEngKURcTK1WQKsBSYAW9PLThfpYjUzG9lqGiQR8QPgB2n6VWDOAMutAFYUqXcCMyvXQ6upGl2s5gvVzE6Nb5FiZmaZOEjMzCwTB4mZmWXiIDEzs0wcJGZmlomDxMzMMnGQmJlZJg4SMzPLxEFiZmaZOEjMzCwTB4mZmWXiIDEzs0wcJGZmlomDxMzMMnGQmJlZJg4SMzPLxEFiZmaZOEjMzCwTB4mZmWVS9SCR1CzpcUn7Je2TdHOqnytpm6Tn0/s5BW2WS+qSdEDSVQX1WZL2pnn3SlK1x2NmNtrVYovkBPDFiLgEmA0slTQdWAZsj4hpwPb0mTRvPjADmAuskjQmfddqoAOYll5zqzkQMzOrQZBExKGI+HGaPgbsB6YA84B1abF1wNVpeh6wMSKOR8SLQBdwhaTJwMSI2BERAawvaGNmZlVS02MkklqBXwd2ARdExCHIhw1wflpsCnCwoFku1aak6b71YuvpkNQpqbOnp6esYzAzG+1qFiSSPgD8FfDHEXF0sEWL1GKQev9ixJqIaI+I9sbGxlPvrJmZDagmQSKpgXyIbIiIh1P5lbS7ivR+ONVzQHNB8ybg5VRvKlI3M7MqqsVZWwIeAPZHxDcKZm0BFqbphcAjBfX5ksZJaiN/UH132v11TNLs9J0LCtqYmVmVjK3BOj8K3ADslbQn1f4UuAvYJGkx0A1cCxAR+yRtAp4jf8bX0og4mdotAdYCE4Ct6WVmZlVU9SCJiB9S/PgGwJwB2qwAVhSpdwIzy9c7MzM7Vb6y3czMMnGQmJlZJg4SMzPLxEFiZmaZOEjMzCwTB4mZmWXiIDEzs0wcJGZmlomDxMzMMnGQmJlZJg4SMzPLxEFiZmaZOEjMzCwTB4mZmWXiIDEzs0wcJGZmlomDxMzMMnGQmJlZJg4SMzPLpO6DRNJcSQckdUlaVuv+mJmNNnUdJJLGAP8T+CQwHfispOm17ZWZ2ehS10ECXAF0RcQLEfELYCMwr8Z9MjMbVRQRte7DsEm6BpgbEZ9Pn28AfiMi/qjPch1AR/p4EXBgmKs8D/jZMNvWK495dPCYR4csY54aEY3FZowdfn9GBBWp9UvGiFgDrMm8MqkzItqzfk898ZhHB495dKjUmOt911YOaC743AS8XKO+mJmNSvUeJH8PTJPUJukMYD6wpcZ9MjMbVep611ZEnJD0R8DfAmOAByNiXwVXmXn3WB3ymEcHj3l0qMiY6/pgu5mZ1V6979oyM7Mac5CYmVkmDpIihrrtivLuTfOfkXRZLfpZTiWM+fo01mck/UjSpbXoZzmVensdSZdLOpmuW6prpYxZ0pWS9kjaJ+mJavexnEr4//psSd+T9JM03s/Vop/lJOlBSYclPTvA/PL/fkWEXwUv8gft/xH4FeAM4CfA9D7LfArYSv46ltnArlr3uwpj/ghwTpr+5GgYc8FyjwF/A1xT635X4b/zB4HngJb0+fxa97vC4/1T4GtpuhE4ApxR675nHPdvA5cBzw4wv+y/X94i6a+U267MA9ZH3k7gg5ImV7ujZTTkmCPiRxHxWvq4k/w1O/Ws1NvrfAH4K+BwNTtXIaWM+Q+AhyOiGyAi6nncpYw3gLMkCfgA+SA5Ud1ulldEPEl+HAMp+++Xg6S/KcDBgs+5VDvVZerJqY5nMfm/aOrZkGOWNAX4feC+Kvarkkr57/yrwDmSfiDpKUkLqta78itlvH8GXEL+Qua9wM0R8cvqdK9myv77VdfXkVRIKbddKenWLHWk5PFI+h3yQfJbFe1R5ZUy5pXAlyLiZP4P1rpXypjHArOAOcAEYIeknRHxD5XuXAWUMt6rgD3Ax4ALgW2S/m9EHK1w32qp7L9fDpL+Srntyul2a5aSxiPp14D7gU9GxKtV6lullDLmdmBjCpHzgE9JOhER361KD8uv1P+3fxYRPwd+LulJ4FKgHoOklPF+Drgr8gcPuiS9CFwM7K5OF2ui7L9f3rXVXym3XdkCLEhnP8wGXo+IQ9XuaBkNOWZJLcDDwA11+tdpX0OOOSLaIqI1IlqBzcBNdRwiUNr/248A/07SWEnvB34D2F/lfpZLKePtJr/1haQLyN8d/IWq9rL6yv775S2SPmKA265IujHNv4/8GTyfArqAN8n/VVO3ShzzfwUmAavSX+gnoo7vnFrimE8rpYw5IvZL+j7wDPBL4P6IKHoa6UhX4n/j/w6slbSX/C6fL0VEXd9aXtJDwJXAeZJywB1AA1Tu98u3SDEzs0y8a8vMzDJxkJiZWSYOEjMzy8RBYmZmmThIzMwsEweJmZll4iAxM7NM/j99XPxmkoK1OgAAAABJRU5ErkJggg==",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "sns.histplot(y, bins = 10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train test split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=1, test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train1, X_val, y_train1, y_val = train_test_split(X_train, y_train, random_state=1, test_size=0.25)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "RF modeling (before Feature selection and Hyperparameter Tuning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/y1/pjvjlkjn5gl846rnyzr53p340000gn/T/ipykernel_13315/119766249.py:2: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  rfreg.fit(X_train1, y_train1)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;background-color: white;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>RandomForestRegressor(n_jobs=-1)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">RandomForestRegressor</label><div class=\"sk-toggleable__content\"><pre>RandomForestRegressor(n_jobs=-1)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "RandomForestRegressor(n_jobs=-1)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rfreg = RandomForestRegressor(n_jobs = -1)\n",
    "rfreg.fit(X_train1, y_train1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_rfreg = rfreg.predict(X_val)\n",
    "y_pred_rfreg_r2 = rfreg.predict(X_train1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.03595344593426628"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mean_absolute_error(y_val, y_pred_rfreg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.006721150405678469"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mean_squared_error(y_val, y_pred_rfreg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.08198262258356016"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mean_squared_error(y_val, y_pred_rfreg, squared = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9851591179650917"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#train\n",
    "r2_score(y_train1, y_pred_rfreg_r2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.931891422491503"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#val\n",
    "r2_score(y_val, y_pred_rfreg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Residual plots for each target variable"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Feature Selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_feat = pd.DataFrame({\n",
    "    \"features\": X_train1.columns,\n",
    "    \"score\": rfreg.feature_importances_\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>features</th>\n",
       "      <th>score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>lsa_0</td>\n",
       "      <td>0.094124</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>lsa_1</td>\n",
       "      <td>0.079143</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>lsa_2</td>\n",
       "      <td>0.087327</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>lsa_3</td>\n",
       "      <td>0.077865</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>lsa_4</td>\n",
       "      <td>0.099736</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>81</th>\n",
       "      <td>tree</td>\n",
       "      <td>0.000564</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>82</th>\n",
       "      <td>tropical</td>\n",
       "      <td>0.001028</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>83</th>\n",
       "      <td>vanilla</td>\n",
       "      <td>0.003044</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>84</th>\n",
       "      <td>violet</td>\n",
       "      <td>0.000118</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>85</th>\n",
       "      <td>woody</td>\n",
       "      <td>0.001903</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>86 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    features     score\n",
       "0      lsa_0  0.094124\n",
       "1      lsa_1  0.079143\n",
       "2      lsa_2  0.087327\n",
       "3      lsa_3  0.077865\n",
       "4      lsa_4  0.099736\n",
       "..       ...       ...\n",
       "81      tree  0.000564\n",
       "82  tropical  0.001028\n",
       "83   vanilla  0.003044\n",
       "84    violet  0.000118\n",
       "85     woody  0.001903\n",
       "\n",
       "[86 rows x 2 columns]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_feat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_feat_ranked = df_feat.sort_values(\"score\", ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>features</th>\n",
       "      <th>score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>cheese</td>\n",
       "      <td>2.342905e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>lsa_4</td>\n",
       "      <td>9.973602e-02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>lsa_0</td>\n",
       "      <td>9.412358e-02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>lsa_2</td>\n",
       "      <td>8.732748e-02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>lsa_1</td>\n",
       "      <td>7.914332e-02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>lsa_3</td>\n",
       "      <td>7.786459e-02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>sativa</td>\n",
       "      <td>4.799625e-02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>blueberry</td>\n",
       "      <td>2.304788e-02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50</th>\n",
       "      <td>diesel</td>\n",
       "      <td>2.018805e-02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>hybrid</td>\n",
       "      <td>1.987787e-02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>64</th>\n",
       "      <td>orange</td>\n",
       "      <td>1.858717e-02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>apple</td>\n",
       "      <td>1.616009e-02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>citrus</td>\n",
       "      <td>1.001919e-02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>uplifted</td>\n",
       "      <td>9.452162e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>berry</td>\n",
       "      <td>9.096651e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>62</th>\n",
       "      <td>mint</td>\n",
       "      <td>9.061343e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>euphoric</td>\n",
       "      <td>7.413261e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>giggly</td>\n",
       "      <td>6.762102e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>happy</td>\n",
       "      <td>6.493642e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>dry mouth</td>\n",
       "      <td>6.482887e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>relaxed</td>\n",
       "      <td>6.251178e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>creative</td>\n",
       "      <td>6.164016e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>focused</td>\n",
       "      <td>5.558311e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>71</th>\n",
       "      <td>pungent</td>\n",
       "      <td>5.459169e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>77</th>\n",
       "      <td>sweet</td>\n",
       "      <td>4.860469e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51</th>\n",
       "      <td>earthy</td>\n",
       "      <td>4.824009e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>74</th>\n",
       "      <td>skunk</td>\n",
       "      <td>4.779006e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>hungry</td>\n",
       "      <td>4.674118e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>58</th>\n",
       "      <td>lemon</td>\n",
       "      <td>4.480454e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>sleepy</td>\n",
       "      <td>4.414779e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>indica</td>\n",
       "      <td>4.077856e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>energetic</td>\n",
       "      <td>3.986512e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>tingly</td>\n",
       "      <td>3.720881e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>68</th>\n",
       "      <td>pine</td>\n",
       "      <td>3.711256e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>talkative</td>\n",
       "      <td>3.700515e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52</th>\n",
       "      <td>flowery</td>\n",
       "      <td>3.578437e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>83</th>\n",
       "      <td>vanilla</td>\n",
       "      <td>3.044139e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54</th>\n",
       "      <td>grape</td>\n",
       "      <td>2.990402e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>dizzy</td>\n",
       "      <td>2.867638e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>dry eyes</td>\n",
       "      <td>2.794572e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>aroused</td>\n",
       "      <td>2.708559e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59</th>\n",
       "      <td>lime</td>\n",
       "      <td>2.649191e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>headache</td>\n",
       "      <td>2.346284e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>85</th>\n",
       "      <td>woody</td>\n",
       "      <td>1.903246e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>anxious</td>\n",
       "      <td>1.747627e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>butter</td>\n",
       "      <td>1.608207e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>paranoid</td>\n",
       "      <td>1.370948e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>56</th>\n",
       "      <td>honey</td>\n",
       "      <td>1.369868e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75</th>\n",
       "      <td>spicy/herbal</td>\n",
       "      <td>1.358237e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>63</th>\n",
       "      <td>nutty</td>\n",
       "      <td>1.237069e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>55</th>\n",
       "      <td>grapefruit</td>\n",
       "      <td>1.216494e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>coffee</td>\n",
       "      <td>1.177706e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>67</th>\n",
       "      <td>pepper</td>\n",
       "      <td>1.163584e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>82</th>\n",
       "      <td>tropical</td>\n",
       "      <td>1.027902e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>chemical</td>\n",
       "      <td>8.196494e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53</th>\n",
       "      <td>fruit</td>\n",
       "      <td>7.636508e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>79</th>\n",
       "      <td>tea</td>\n",
       "      <td>6.694980e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>60</th>\n",
       "      <td>mango</td>\n",
       "      <td>6.516458e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>57</th>\n",
       "      <td>lavender</td>\n",
       "      <td>5.728828e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>81</th>\n",
       "      <td>tree</td>\n",
       "      <td>5.640296e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>73</th>\n",
       "      <td>sage</td>\n",
       "      <td>4.914873e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>76</th>\n",
       "      <td>strawberry</td>\n",
       "      <td>4.891887e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>72</th>\n",
       "      <td>rose</td>\n",
       "      <td>4.607857e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>ammonia</td>\n",
       "      <td>2.877643e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>66</th>\n",
       "      <td>pear</td>\n",
       "      <td>2.803856e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>65</th>\n",
       "      <td>peach</td>\n",
       "      <td>2.125654e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>chestnut</td>\n",
       "      <td>2.045594e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>anxiety</td>\n",
       "      <td>1.861174e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>apricot</td>\n",
       "      <td>1.792549e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>78</th>\n",
       "      <td>tar</td>\n",
       "      <td>1.734985e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>69</th>\n",
       "      <td>pineapple</td>\n",
       "      <td>1.726144e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>61</th>\n",
       "      <td>menthol</td>\n",
       "      <td>1.500829e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>depression</td>\n",
       "      <td>1.463421e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>migraines</td>\n",
       "      <td>1.335062e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>70</th>\n",
       "      <td>plum</td>\n",
       "      <td>1.272941e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>84</th>\n",
       "      <td>violet</td>\n",
       "      <td>1.175575e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>80</th>\n",
       "      <td>tobacco</td>\n",
       "      <td>1.134127e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>blue cheese</td>\n",
       "      <td>8.475347e-05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>stress</td>\n",
       "      <td>5.594166e-07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>pain</td>\n",
       "      <td>2.285549e-07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>seizures</td>\n",
       "      <td>7.305607e-09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>eye pressure</td>\n",
       "      <td>6.029414e-09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>arthritis</td>\n",
       "      <td>4.481753e-09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>epilepsy</td>\n",
       "      <td>3.000406e-09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>fatigue</td>\n",
       "      <td>2.226797e-09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>spasticity</td>\n",
       "      <td>0.000000e+00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        features         score\n",
       "45        cheese  2.342905e-01\n",
       "4          lsa_4  9.973602e-02\n",
       "0          lsa_0  9.412358e-02\n",
       "2          lsa_2  8.732748e-02\n",
       "1          lsa_1  7.914332e-02\n",
       "3          lsa_3  7.786459e-02\n",
       "7         sativa  4.799625e-02\n",
       "43     blueberry  2.304788e-02\n",
       "50        diesel  2.018805e-02\n",
       "5         hybrid  1.987787e-02\n",
       "64        orange  1.858717e-02\n",
       "39         apple  1.616009e-02\n",
       "48        citrus  1.001919e-02\n",
       "37      uplifted  9.452162e-03\n",
       "41         berry  9.096651e-03\n",
       "62          mint  9.061343e-03\n",
       "19      euphoric  7.413261e-03\n",
       "23        giggly  6.762102e-03\n",
       "24         happy  6.493642e-03\n",
       "16     dry mouth  6.482887e-03\n",
       "30       relaxed  6.251178e-03\n",
       "12      creative  6.164016e-03\n",
       "22       focused  5.558311e-03\n",
       "71       pungent  5.459169e-03\n",
       "77         sweet  4.860469e-03\n",
       "51        earthy  4.824009e-03\n",
       "74         skunk  4.779006e-03\n",
       "26        hungry  4.674118e-03\n",
       "58         lemon  4.480454e-03\n",
       "32        sleepy  4.414779e-03\n",
       "6         indica  4.077856e-03\n",
       "17     energetic  3.986512e-03\n",
       "36        tingly  3.720881e-03\n",
       "68          pine  3.711256e-03\n",
       "35     talkative  3.700515e-03\n",
       "52       flowery  3.578437e-03\n",
       "83       vanilla  3.044139e-03\n",
       "54         grape  2.990402e-03\n",
       "14         dizzy  2.867638e-03\n",
       "15      dry eyes  2.794572e-03\n",
       "10       aroused  2.708559e-03\n",
       "59          lime  2.649191e-03\n",
       "25      headache  2.346284e-03\n",
       "85         woody  1.903246e-03\n",
       "9        anxious  1.747627e-03\n",
       "44        butter  1.608207e-03\n",
       "29      paranoid  1.370948e-03\n",
       "56         honey  1.369868e-03\n",
       "75  spicy/herbal  1.358237e-03\n",
       "63         nutty  1.237069e-03\n",
       "55    grapefruit  1.216494e-03\n",
       "49        coffee  1.177706e-03\n",
       "67        pepper  1.163584e-03\n",
       "82      tropical  1.027902e-03\n",
       "46      chemical  8.196494e-04\n",
       "53         fruit  7.636508e-04\n",
       "79           tea  6.694980e-04\n",
       "60         mango  6.516458e-04\n",
       "57      lavender  5.728828e-04\n",
       "81          tree  5.640296e-04\n",
       "73          sage  4.914873e-04\n",
       "76    strawberry  4.891887e-04\n",
       "72          rose  4.607857e-04\n",
       "38       ammonia  2.877643e-04\n",
       "66          pear  2.803856e-04\n",
       "65         peach  2.125654e-04\n",
       "47      chestnut  2.045594e-04\n",
       "8        anxiety  1.861174e-04\n",
       "40       apricot  1.792549e-04\n",
       "78           tar  1.734985e-04\n",
       "69     pineapple  1.726144e-04\n",
       "61       menthol  1.500829e-04\n",
       "13    depression  1.463421e-04\n",
       "27     migraines  1.335062e-04\n",
       "70          plum  1.272941e-04\n",
       "84        violet  1.175575e-04\n",
       "80       tobacco  1.134127e-04\n",
       "42   blue cheese  8.475347e-05\n",
       "34        stress  5.594166e-07\n",
       "28          pain  2.285549e-07\n",
       "31      seizures  7.305607e-09\n",
       "20  eye pressure  6.029414e-09\n",
       "11     arthritis  4.481753e-09\n",
       "18      epilepsy  3.000406e-09\n",
       "21       fatigue  2.226797e-09\n",
       "33    spasticity  0.000000e+00"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.set_option('display.max_rows', df_feat_ranked.shape[0]+1)\n",
    "df_feat_ranked"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/andalanputra/opt/anaconda3/lib/python3.9/site-packages/sklearn/feature_selection/_from_model.py:357: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  self.estimator_.fit(X, y, **fit_params)\n"
     ]
    }
   ],
   "source": [
    "selector = SelectFromModel(rfreg).fit(X_train1, y_train1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([9.32835944e-02, 8.04678068e-02, 8.70783828e-02, 7.66786039e-02,\n",
       "       1.00188715e-01, 2.00664784e-02, 4.01845277e-03, 4.78342419e-02,\n",
       "       1.60958335e-04, 1.80140194e-03, 2.88334215e-03, 2.59019026e-09,\n",
       "       5.78448936e-03, 1.84461914e-04, 3.11838019e-03, 2.57492941e-03,\n",
       "       6.38917886e-03, 3.92607434e-03, 5.79223996e-11, 7.77338999e-03,\n",
       "       8.53318136e-09, 2.25677277e-09, 5.48428269e-03, 6.63386822e-03,\n",
       "       6.62368418e-03, 2.44358255e-03, 4.64559409e-03, 1.89496379e-04,\n",
       "       7.31761041e-09, 1.33394541e-03, 6.45452867e-03, 3.47550276e-09,\n",
       "       4.23529723e-03, 0.00000000e+00, 2.38278278e-07, 3.74865157e-03,\n",
       "       3.91175146e-03, 9.84688918e-03, 3.14666380e-04, 1.61552761e-02,\n",
       "       1.57825687e-04, 9.01983029e-03, 1.11054390e-04, 2.29605540e-02,\n",
       "       1.47754621e-03, 2.34216159e-01, 7.25897867e-04, 1.53809351e-04,\n",
       "       1.04659947e-02, 1.12856763e-03, 2.03209820e-02, 5.02842740e-03,\n",
       "       3.31537510e-03, 6.78726215e-04, 2.94100307e-03, 1.27679184e-03,\n",
       "       1.36051029e-03, 5.56548478e-04, 4.63375955e-03, 2.34241823e-03,\n",
       "       8.47046852e-04, 1.73362967e-04, 9.08405554e-03, 1.41421935e-03,\n",
       "       1.86275622e-02, 1.95299052e-04, 3.16318161e-04, 1.09313641e-03,\n",
       "       3.56222406e-03, 1.44381062e-04, 1.37357738e-04, 5.10177263e-03,\n",
       "       5.29436624e-04, 4.95812769e-04, 4.69631895e-03, 1.49360232e-03,\n",
       "       4.56394975e-04, 4.77003157e-03, 1.52272346e-04, 6.03885931e-04,\n",
       "       1.18088335e-04, 4.75415763e-04, 1.11973251e-03, 3.35441773e-03,\n",
       "       9.13524318e-05, 1.84006084e-03])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "selector.estimator_.feature_importances_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.01162790697674419"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "selector.threshold_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "mask = selector.get_support()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ True,  True,  True,  True,  True,  True, False,  True, False,\n",
       "       False, False, False, False, False, False, False, False, False,\n",
       "       False, False, False, False, False, False, False, False, False,\n",
       "       False, False, False, False, False, False, False, False, False,\n",
       "       False, False, False,  True, False, False, False,  True, False,\n",
       "        True, False, False, False, False,  True, False, False, False,\n",
       "       False, False, False, False, False, False, False, False, False,\n",
       "       False,  True, False, False, False, False, False, False, False,\n",
       "       False, False, False, False, False, False, False, False, False,\n",
       "       False, False, False, False, False])"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "selected_features = X.columns[mask]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>lsa_0</th>\n",
       "      <th>lsa_1</th>\n",
       "      <th>lsa_2</th>\n",
       "      <th>lsa_3</th>\n",
       "      <th>lsa_4</th>\n",
       "      <th>hybrid</th>\n",
       "      <th>sativa</th>\n",
       "      <th>apple</th>\n",
       "      <th>blueberry</th>\n",
       "      <th>cheese</th>\n",
       "      <th>diesel</th>\n",
       "      <th>orange</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.341025</td>\n",
       "      <td>0.182753</td>\n",
       "      <td>0.008214</td>\n",
       "      <td>0.140406</td>\n",
       "      <td>-0.156943</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.341025</td>\n",
       "      <td>0.182753</td>\n",
       "      <td>0.008214</td>\n",
       "      <td>0.140406</td>\n",
       "      <td>-0.156943</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.232158</td>\n",
       "      <td>-0.045496</td>\n",
       "      <td>0.187131</td>\n",
       "      <td>-0.000936</td>\n",
       "      <td>0.018518</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.232158</td>\n",
       "      <td>-0.045496</td>\n",
       "      <td>0.187131</td>\n",
       "      <td>-0.000936</td>\n",
       "      <td>0.018518</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.232158</td>\n",
       "      <td>-0.045496</td>\n",
       "      <td>0.187131</td>\n",
       "      <td>-0.000936</td>\n",
       "      <td>0.018518</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>74995</th>\n",
       "      <td>0.181714</td>\n",
       "      <td>-0.045560</td>\n",
       "      <td>-0.055692</td>\n",
       "      <td>0.015649</td>\n",
       "      <td>-0.045585</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>74996</th>\n",
       "      <td>0.055494</td>\n",
       "      <td>0.003622</td>\n",
       "      <td>-0.050252</td>\n",
       "      <td>-0.024795</td>\n",
       "      <td>-0.031141</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>74997</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>74998</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>74999</th>\n",
       "      <td>0.324915</td>\n",
       "      <td>0.131823</td>\n",
       "      <td>-0.099424</td>\n",
       "      <td>0.065491</td>\n",
       "      <td>0.038437</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>75000 rows × 12 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          lsa_0     lsa_1     lsa_2     lsa_3     lsa_4  hybrid  sativa  \\\n",
       "0      0.341025  0.182753  0.008214  0.140406 -0.156943       1       0   \n",
       "1      0.341025  0.182753  0.008214  0.140406 -0.156943       1       0   \n",
       "2      0.232158 -0.045496  0.187131 -0.000936  0.018518       1       0   \n",
       "3      0.232158 -0.045496  0.187131 -0.000936  0.018518       1       0   \n",
       "4      0.232158 -0.045496  0.187131 -0.000936  0.018518       1       0   \n",
       "...         ...       ...       ...       ...       ...     ...     ...   \n",
       "74995  0.181714 -0.045560 -0.055692  0.015649 -0.045585       0       0   \n",
       "74996  0.055494  0.003622 -0.050252 -0.024795 -0.031141       0       0   \n",
       "74997  0.000000  0.000000  0.000000  0.000000  0.000000       0       0   \n",
       "74998  0.000000  0.000000  0.000000  0.000000  0.000000       0       0   \n",
       "74999  0.324915  0.131823 -0.099424  0.065491  0.038437       0       0   \n",
       "\n",
       "       apple  blueberry  cheese  diesel  orange  \n",
       "0          0          0       0       0       0  \n",
       "1          0          0       0       0       0  \n",
       "2          0          0       1       0       0  \n",
       "3          0          0       1       0       0  \n",
       "4          0          0       1       0       0  \n",
       "...      ...        ...     ...     ...     ...  \n",
       "74995      0          0       0       0       0  \n",
       "74996      0          0       0       0       0  \n",
       "74997      0          0       0       0       0  \n",
       "74998      0          0       0       0       0  \n",
       "74999      0          0       0       0       0  \n",
       "\n",
       "[75000 rows x 12 columns]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "selected_X = df_rf[selected_features]\n",
    "selected_X"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train test split (after Feature Selection)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['selected_X_rf_lsa_elbow_cbn.pkl']"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import joblib\n",
    "\n",
    "joblib.dump(selector, \"selector_rf_lsa_elbow_cbn.pkl\")\n",
    "joblib.dump(selected_X, \"selected_X_rf_lsa_elbow_cbn.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(selected_X, y, random_state=1, test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train1, X_val, y_train1, y_val = train_test_split(X_train, y_train, random_state=1, test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/y1/pjvjlkjn5gl846rnyzr53p340000gn/T/ipykernel_13315/3758305.py:1: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  rfreg.fit(X_train1, y_train1)\n"
     ]
    }
   ],
   "source": [
    "rfreg.fit(X_train1, y_train1)\n",
    "y_pred_rfreg = rfreg.predict(X_val)\n",
    "y_pred_rfreg_r2 = rfreg.predict(X_train1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.03913622007801573"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mean_absolute_error(y_val, y_pred_rfreg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.007348886878056696"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mean_squared_error(y_val, y_pred_rfreg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.08572564889259629"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mean_squared_error(y_val, y_pred_rfreg, squared = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9782333731247622"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#train\n",
    "r2_score(y_train1, y_pred_rfreg_r2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9250062033272413"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#val\n",
    "r2_score(y_val, y_pred_rfreg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hyperparameter Tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "parameters = { 'max_depth': [None, 10, 50, 100],\n",
    "              'max_features': ['auto', 'sqrt'],\n",
    "              'min_samples_leaf': [1, 2, 4],\n",
    "              'min_samples_split': [2, 5, 10],\n",
    "              'n_estimators': [100, 300, 500]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "rscv = RandomizedSearchCV(rfreg,  \n",
    "                     parameters,   \n",
    "                     cv=5, \n",
    "                     scoring='neg_mean_absolute_error',\n",
    "                     n_jobs= -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/andalanputra/opt/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/Users/andalanputra/opt/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/Users/andalanputra/opt/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/Users/andalanputra/opt/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/Users/andalanputra/opt/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/Users/andalanputra/opt/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/Users/andalanputra/opt/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/Users/andalanputra/opt/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/Users/andalanputra/opt/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/Users/andalanputra/opt/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/Users/andalanputra/opt/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/Users/andalanputra/opt/anaconda3/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
      "  warn(\n",
      "/Users/andalanputra/opt/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/Users/andalanputra/opt/anaconda3/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
      "  warn(\n",
      "/Users/andalanputra/opt/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/Users/andalanputra/opt/anaconda3/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
      "  warn(\n",
      "/Users/andalanputra/opt/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/Users/andalanputra/opt/anaconda3/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
      "  warn(\n",
      "/Users/andalanputra/opt/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/Users/andalanputra/opt/anaconda3/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
      "  warn(\n",
      "/Users/andalanputra/opt/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/Users/andalanputra/opt/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/Users/andalanputra/opt/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/Users/andalanputra/opt/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/Users/andalanputra/opt/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/Users/andalanputra/opt/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/Users/andalanputra/opt/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/Users/andalanputra/opt/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/Users/andalanputra/opt/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/Users/andalanputra/opt/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/Users/andalanputra/opt/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/Users/andalanputra/opt/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/Users/andalanputra/opt/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/Users/andalanputra/opt/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/Users/andalanputra/opt/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/Users/andalanputra/opt/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/Users/andalanputra/opt/anaconda3/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
      "  warn(\n",
      "/Users/andalanputra/opt/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/Users/andalanputra/opt/anaconda3/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
      "  warn(\n",
      "/Users/andalanputra/opt/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/Users/andalanputra/opt/anaconda3/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
      "  warn(\n",
      "/Users/andalanputra/opt/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/Users/andalanputra/opt/anaconda3/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
      "  warn(\n",
      "/Users/andalanputra/opt/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/Users/andalanputra/opt/anaconda3/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
      "  warn(\n",
      "/Users/andalanputra/opt/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/Users/andalanputra/opt/anaconda3/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
      "  warn(\n",
      "/Users/andalanputra/opt/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/Users/andalanputra/opt/anaconda3/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
      "  warn(\n",
      "/Users/andalanputra/opt/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/Users/andalanputra/opt/anaconda3/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
      "  warn(\n",
      "/Users/andalanputra/opt/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/Users/andalanputra/opt/anaconda3/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
      "  warn(\n",
      "/Users/andalanputra/opt/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/Users/andalanputra/opt/anaconda3/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
      "  warn(\n",
      "/Users/andalanputra/opt/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/Users/andalanputra/opt/anaconda3/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
      "  warn(\n",
      "/Users/andalanputra/opt/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/Users/andalanputra/opt/anaconda3/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
      "  warn(\n",
      "/Users/andalanputra/opt/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/Users/andalanputra/opt/anaconda3/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
      "  warn(\n",
      "/Users/andalanputra/opt/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/Users/andalanputra/opt/anaconda3/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
      "  warn(\n",
      "/Users/andalanputra/opt/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/Users/andalanputra/opt/anaconda3/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
      "  warn(\n",
      "/Users/andalanputra/opt/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/Users/andalanputra/opt/anaconda3/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
      "  warn(\n",
      "/Users/andalanputra/opt/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/Users/andalanputra/opt/anaconda3/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
      "  warn(\n",
      "/Users/andalanputra/opt/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/Users/andalanputra/opt/anaconda3/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
      "  warn(\n",
      "/Users/andalanputra/opt/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/Users/andalanputra/opt/anaconda3/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
      "  warn(\n",
      "/Users/andalanputra/opt/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/Users/andalanputra/opt/anaconda3/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
      "  warn(\n",
      "/Users/andalanputra/opt/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_search.py:909: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  self.best_estimator_.fit(X, y, **fit_params)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-2 {color: black;background-color: white;}#sk-container-id-2 pre{padding: 0;}#sk-container-id-2 div.sk-toggleable {background-color: white;}#sk-container-id-2 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-2 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-2 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-2 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-2 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-2 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-2 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-2 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-2 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-2 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-2 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-2 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-2 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-2 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-2 div.sk-item {position: relative;z-index: 1;}#sk-container-id-2 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-2 div.sk-item::before, #sk-container-id-2 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-2 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-2 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-2 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-2 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-2 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-2 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-2 div.sk-label-container {text-align: center;}#sk-container-id-2 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-2 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-2\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>RandomizedSearchCV(cv=5, estimator=RandomForestRegressor(n_jobs=-1), n_jobs=-1,\n",
       "                   param_distributions={&#x27;max_depth&#x27;: [None, 10, 50, 100],\n",
       "                                        &#x27;max_features&#x27;: [&#x27;auto&#x27;, &#x27;sqrt&#x27;],\n",
       "                                        &#x27;min_samples_leaf&#x27;: [1, 2, 4],\n",
       "                                        &#x27;min_samples_split&#x27;: [2, 5, 10],\n",
       "                                        &#x27;n_estimators&#x27;: [100, 300, 500]},\n",
       "                   scoring=&#x27;neg_mean_absolute_error&#x27;)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" ><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">RandomizedSearchCV</label><div class=\"sk-toggleable__content\"><pre>RandomizedSearchCV(cv=5, estimator=RandomForestRegressor(n_jobs=-1), n_jobs=-1,\n",
       "                   param_distributions={&#x27;max_depth&#x27;: [None, 10, 50, 100],\n",
       "                                        &#x27;max_features&#x27;: [&#x27;auto&#x27;, &#x27;sqrt&#x27;],\n",
       "                                        &#x27;min_samples_leaf&#x27;: [1, 2, 4],\n",
       "                                        &#x27;min_samples_split&#x27;: [2, 5, 10],\n",
       "                                        &#x27;n_estimators&#x27;: [100, 300, 500]},\n",
       "                   scoring=&#x27;neg_mean_absolute_error&#x27;)</pre></div></div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-3\" type=\"checkbox\" ><label for=\"sk-estimator-id-3\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">estimator: RandomForestRegressor</label><div class=\"sk-toggleable__content\"><pre>RandomForestRegressor(n_jobs=-1)</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-4\" type=\"checkbox\" ><label for=\"sk-estimator-id-4\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">RandomForestRegressor</label><div class=\"sk-toggleable__content\"><pre>RandomForestRegressor(n_jobs=-1)</pre></div></div></div></div></div></div></div></div></div></div>"
      ],
      "text/plain": [
       "RandomizedSearchCV(cv=5, estimator=RandomForestRegressor(n_jobs=-1), n_jobs=-1,\n",
       "                   param_distributions={'max_depth': [None, 10, 50, 100],\n",
       "                                        'max_features': ['auto', 'sqrt'],\n",
       "                                        'min_samples_leaf': [1, 2, 4],\n",
       "                                        'min_samples_split': [2, 5, 10],\n",
       "                                        'n_estimators': [100, 300, 500]},\n",
       "                   scoring='neg_mean_absolute_error')"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rscv.fit(X_train1, y_train1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'n_estimators': 100,\n",
       " 'min_samples_split': 2,\n",
       " 'min_samples_leaf': 1,\n",
       " 'max_features': 'sqrt',\n",
       " 'max_depth': 50}"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rscv.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['rscv_rf_lsa_elbow_best_params_cbn.pkl']"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "joblib.dump(rscv, \"rscv_rf_lsa_elbow_cbn.pkl\")\n",
    "joblib.dump(rscv.best_params_, \"rscv_rf_lsa_elbow_best_params_cbn.pkl\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "RF (after Hyperparameter Tuning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/y1/pjvjlkjn5gl846rnyzr53p340000gn/T/ipykernel_13315/2143269374.py:2: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  rfreg_ht.fit(X_train1, y_train1)\n"
     ]
    }
   ],
   "source": [
    "rfreg_ht = RandomForestRegressor(n_estimators = 100, min_samples_split = 2, max_features = 'sqrt', min_samples_leaf = 1, max_depth = 50)\n",
    "rfreg_ht.fit(X_train1, y_train1)\n",
    "y_pred_rfreg = rfreg_ht.predict(X_val)\n",
    "y_pred_rfreg_r2 = rfreg_ht.predict(X_train1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.03834063659540392"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mean_absolute_error(y_val, y_pred_rfreg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.006756811756765835"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mean_squared_error(y_val, y_pred_rfreg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.08219982820399221"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mean_squared_error(y_val, y_pred_rfreg, squared = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9789343830110983"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#train\n",
    "r2_score(y_train1, y_pred_rfreg_r2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9310482015234126"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#val\n",
    "r2_score(y_val, y_pred_rfreg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Residual plots after Hyperparameter Tuning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Predicting model on the test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_rfreg_test = rfreg_ht.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['y_test_rfreg_lsa_elbow_cbn.pkl']"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "joblib.dump(y_pred_rfreg_test, \"y_pred_rfreg_test_lsa_elbow_cbn.pkl\")\n",
    "joblib.dump(y_test, \"y_test_rfreg_lsa_elbow_cbn.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.03713759638076267"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mean_absolute_error(y_test, y_pred_rfreg_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.00671280401213635"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mean_squared_error(y_test, y_pred_rfreg_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.08193170333964961"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mean_squared_error(y_test, y_pred_rfreg_test, squared = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.931977788490517"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "r2_score(y_test, y_pred_rfreg_test)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Error analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 576x432 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 432x288 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# assume y_pred is a numpy array and y_true is a pandas dataframe\n",
    "fig, ax = plt.subplots(figsize=(8, 6))\n",
    "\n",
    "column = \"X..CBN\"  # specify the target variable name\n",
    "ax.hist(y_pred_rfreg_test, alpha=0.5, label='y_pred', bins=20)\n",
    "ax.hist(y_test[column], alpha=0.5, label='y_true', bins=20)\n",
    "ax.legend(loc='upper right')\n",
    "ax.set_title(column)\n",
    "\n",
    "plt.show()\n",
    "plt.savefig('error_hist_rf_lsa_elbow_cbn.png')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pearson R"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pearson correlation coefficient: 0.968\n",
      "P-value: 0.000\n"
     ]
    }
   ],
   "source": [
    "corr_coef, p_value = pearsonr(y_pred_rfreg_test.flatten(), y_test.values.ravel())\n",
    "\n",
    "print(f\"Pearson correlation coefficient: {corr_coef:.3f}\")\n",
    "print(f\"P-value: {p_value:.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:>"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAWoAAAD8CAYAAABekO4JAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjQuMywgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/MnkTPAAAACXBIWXMAAAsTAAALEwEAmpwYAAAVHUlEQVR4nO3df8xe5X3f8fdnxtYGIcIM4Vm2AySzCB7KHMoMKlNGwxIZUtUhChJeBxYyeUgLXajINo9/yF+bm0GiRCNmZvEwbQIlTRBuYCHMSuNFa4oNmN94OPzyg128hg6nQSqYfPfHfYxOb+4ffh7842C/X9LRfZ/rOtd1vpbQh6PrOfc5qSokSd319w53AZKk0QxqSeo4g1qSOs6glqSOM6glqeMMaknqOINakoZIsi7J7iRPDOn/cJI/T/K3Sb7Y17c0ybYk25OsarWfmOSBJM82n7PH1WFQS9JwtwFLR/S/Cvwb4MZ2Y5IZwM3AhcAiYHmSRU33KmBjVS0ENjb7IxnUkjREVW2iF8bD+ndX1Wbgzb6uJcD2qnquqt4A7gSWNX3LgPXN9/XAp8fVccwU656ye2ee7k8fJe2XT725Le92jqlkzm/u/T9XAROtprVVtfbd1gDMA3a09ieBc5rvc6pqF0BV7Upy8rjJDnpQS1JXNaF8IIK536D/4Uz7otWlD0k68CaBBa39+cDO5vsrSeYCNJ+7x01mUEvSgbcZWJjktCSzgEuBDU3fBmBF830FcM+4yVz6kKQhktwBnA+clGQSuAGYCVBVtyT5R8AW4P3Ar5JcCyyqqj1JrgHuB2YA66rqyWba1cBdSVYCLwGXjKvDoJakIapq+Zj+v6S3rDGo7z7gvgHtPwcumEodLn1IUscZ1JLUcQa1JHWcQS1JHWdQS1LHGdSS1HEGtSR1nEEtSR1nUEtSxxnUktRxBrUkdZxBLUkdZ1BLUscZ1JLUcQa1JHWcQS1JHWdQS1LHGdSS1HEGtSQNkWRdkt1JnhjSnyRfT7I9yWNJzmraT0+ytbXtad6nSJIvJXm51XfRuDp8Z6IkDXcb8F+A24f0XwgsbLZzgDXAOVW1DVgMkGQG8DJwd2vcV6vqxv0twitqSRqiqjYBr444ZBlwe/X8FDghydy+Yy4AflZVL063DoNakqZvHrCjtT/ZtLVdCtzR13ZNs1SyLsnscScxqCUdtZJMJNnS2iamOsWAtmrNPwv4LeA7rf41wIfoLY3sAm4adxLXqCUdtapqLbD2XUwxCSxo7c8Hdrb2LwQerqpXWud8+3uSW4HvjzuJV9SSNH0bgMubuz/OBV6rql2t/uX0LXv0rWFfDAy8o6TNK2pJGiLJHcD5wElJJoEbgJkAVXULcB9wEbAdeB24ojX2WOATwFV90345yWJ6SyQvDOh/B4NakoaoquVj+gu4ekjf68A/HNB+2VTrcOlDkjrOoJakjjOoJanjDGpJ6jiDWpI6zqCWpI4zqCWp4wxqSeo4g1qSOs6glqSOM6glqeMMaknqOINakjrOoJakjjOoJanjDGpJ6jiDWpI6zqCWpI4zqCWp4wxqSRoiyboku5MMfFN48/bxryfZnuSxJGe1+l5I8niSrUm2tNpPTPJAkmebz9nj6jCoJWm424ClI/ovBBY22wSwpq//N6pqcVWd3WpbBWysqoXAxmZ/JINakoaoqk3AqyMOWQbcXj0/BU5IMnfMtMuA9c339cCnx9VhUEs6aiWZSLKltU1McYp5wI7W/mTTBlDAD5M81DfvnKraBdB8njzuJMdMsShJOmJU1Vpg7buYIoOmbT7Pq6qdSU4GHkjyTHOFPmVeUUvS9E0CC1r784GdAFW173M3cDewpDnmlX3LI83n7nEnMaglafo2AJc3d3+cC7xWVbuSHJfkeIAkxwGfBJ5ojVnRfF8B3DPuJC59SNIQSe4AzgdOSjIJ3ADMBKiqW4D7gIuA7cDrwBXN0DnA3Umgl7PfrqofNH2rgbuSrAReAi4ZV4dBLUlDVNXyMf0FXD2g/Tngnw4Z83PggqnU4dKHJHWcQS1JHWdQS1LHGdSS1HEGtSR1nEEtSR1nUEtSxxnUktRxBrUkdZxBLUkdZ1BLUscZ1JLUcQa1JHWcQS1JHWdQS1LHGdSS1HEGtSR1nEEtSR1nUEvSEEnWJdmd5Ikh/Uny9STbkzyW5KymfUGSHyV5OsmTSb7QGvOlJC8n2dpsF42rw6CWpOFuA5aO6L8QWNhsE8Capn0vcF1VnQGcC1ydZFFr3FeranGz3TeuCINakoaoqk3AqyMOWQbcXj0/BU5IMreqdlXVw80cvwCeBuZNtw6DWtJRK8lEki2tbWKKU8wDdrT2J+kL5CSnAh8F/qLVfE2zVLIuyexxJzGoJR21qmptVZ3d2tZOcYoMmvbtzuR9wHeBa6tqT9O8BvgQsBjYBdw07iQGtSRN3ySwoLU/H9gJkGQmvZD+VlV9b98BVfVKVb1VVb8CbgWWjDuJQS1J07cBuLy5++Nc4LWq2pUkwDeBp6vqK+0BSea2di8GBt5R0nbMgaxYko4kSe4AzgdOSjIJ3ADMBKiqW4D7gIuA7cDrwBXN0POAy4DHk2xt2q5v7vD4cpLF9JZIXgCuGleHQS1JQ1TV8jH9BVw9oP0nDF6/pqoum2odLn1IUscZ1JLUcQa1JHWcQS1JHWdQS1LHGdSS1HEGtSR13ND7qJP8d1q/We9TVbXy4JQkSWob9YOX7w9o+wBwLTDjoFQjSXqHoUFdVd/d9z3JB4HrgY8Bq+n9hl2SdAiMXKNOckaSPwL+FPgJsKiq1lTVG4ekOknSyDXq7wBnAzcCvw+8Bby/91AoqKpRbz2QJB0go9ao/xm9PyZ+Ebiuadv3kJECPngQ65IkNUatUZ96COuQJA0xbo36mOYB2Ptef/7Z5jmqkqRDZGhQJ/kcsBt4sfm+Efgs8MdJ/v0hqk+Sjnqj1qivpfcCxuPpver8lKr6qyTHApuBPzj45UmSRi19vFFVf11VLwHbq+qvAKrqdcDb8zQtH7n1P/IvX/7ffOyRPz3cpUjvGaOC+h8k+WiSXwNmNd/Pavb//iGqT0eYyfXf48HfvPJwlyHtlyTrkuxOMvAFtM1Lbb+eZHuSx5Kc1epbmmRb07eq1X5ikgeSPNt8zh5Xx6ig/kvgK/Tuo973/abWvjRlr/5kC2+++trhLkPaX7cBS0f0XwgsbLYJYA1AkhnAzU3/ImB5kkXNmFXAxqpaSO9vf6v6J+036va888cNlqQjWVVtSnLqiEOWAbc3L7n9aZITkswFTqW3ZPwcQJI7m2Ofaj7Pb8avB/4MGHmDxqi7Pv51kne8LTfJ55L8q1GTJplIsiXJlh/86v+NOlSSDpt2VjXbxBSnmAfsaO1PNm3D2gHmVNUugObz5HEnGXXXx3X0HsLU74+BHwHfHjawqtYCawHunXn6sEelStJh1c6qacqAthrRPi2j1qhnVNUv3nGmqj3AzOmeUJKOIJPAgtb+fGDniHaAV5rlEZrP3eNOMiqoZyY5rr8xyfHArHETS4Ms/sOb+PX/dSfHnX4aH3/+xyy44rOHuyTp3dgAXN7c/XEu8FqznLEZWJjktCSzgEubY/eNWdF8XwHcM+4ko5Y+vgn8SZLfqaoXAJpF9ZvxedSapq2XXTf+IKkjktxB7w9/JyWZBG6gWVGoqluA+4CLgO3A68AVTd/eJNcA99N70cq6qnqymXY1cFeSlcBLwCXj6hh118eNSf4G+HGS99FbX/klsLqq1kz5XyxJ7zFVtXxMfwFXD+m7j16Q97f/HLhgKnWMuqLe93+MW5qgzqA1a0nSwbVfbyGvqr9ph3T71zeSpINrv4J6gN85oFVIkoaaVlBX1ecOdCGSpMGme0UtSTpEphXUSR4+0IVIkgYb9ayPBcP66L1UQJJ0CIy6ov5xkn+X5O1b+JLMSfJH9B53Kkk6BEYF9a/RexXXI0k+nuQLwIPAnwPnHIriJEmjf5n418BVTUD/T3oPFDm3qiYPVXGSpNFr1Cck+a/0fru+FPgT4H8k+fihKk6SNPon5A8D3wCurqq9wA+TLAa+keTFcb+BlyQdGKOC+mP9yxxVtRX49ST+4EWSDpGhSx+j1qKr6taDU44kqZ+/TJSkjjOoJanjDGpJ6jiDWpI6zqCWpCGSLE2yLcn2JKsG9M9OcneSx5I8mOTMpv30JFtb254k1zZ9X0rycqvvonF1jHwVlyQdrZLMoPcy708Ak8DmJBuq6qnWYdcDW6vq4iQfbo6/oKq2AYtb87wM3N0a99WqunF/a/GKWpIGWwJsr6rnquoN4E5gWd8xi4CNAFX1DHBqkjl9x1wA/KyqXpxuIQa1pKNWkokkW1rbRKt7HrCjtT/ZtLU9CnymmWsJcAowv++YS4E7+tquaZZL1iWZPa5Og1rSUauq1lbV2a1tbas7g4b07a8GZifZCvwe8Aiw9+0JklnAbwHfaY1ZQ+/JpIuBXezHY6Ndo5akwSaB9gtU5tN7iujbqmoPvQfXkSTA8822z4XAw1X1SmvM29+T3Ap8f1whXlFL0mCbgYVJTmuujC8FNrQPaJ4yOqvZvRLY1IT3PsvpW/ZIMre1ezHwxLhCvKKWpAGqam+Sa4D7gRnAuqp6Msnnm/5bgDOA25O8BTwFrNw3Psmx9O4Yuapv6i83TyIt4IUB/e+Qqv4llwPr3pmnH9wTSDpifOrNbYPWhadkKplzIM53KLj0IUkdZ1BLUscZ1JLUcQa1JHWcQS1JHWdQS1LHGdSS1HEGtSR1nEEtSR1nUEtSxxnUktRxBrUkdZxBLUkdZ1BLUscZ1JLUcQa1JHWcQS1JHWdQS1LHGdSSNESSpUm2JdmeZNWA/tlJ7k7yWJIHk5zZ6nshyeNJtibZ0mo/MckDSZ5tPmePq8OglqQBkswAbgYuBBYBy5Ms6jvsemBrVX0EuBz4Wl//b1TV4qo6u9W2CthYVQuBjc3+SAa1JA22BNheVc9V1RvAncCyvmMW0QtbquoZ4NQkc8bMuwxY33xfD3x6XCEGtaSjVpKJJFta20Srex6wo7U/2bS1PQp8pplrCXAKML/pK+CHSR7qm3dOVe0CaD5PHlfnMVP5R0nSkaSq1gJrh3Rn0JC+/dXA15JsBR4HHgH2Nn3nVdXOJCcDDyR5pqo2TadOg1qSBpsEFrT25wM72wdU1R7gCoAkAZ5vNqpqZ/O5O8nd9JZSNgGvJJlbVbuSzAV2jyvEpQ9JGmwzsDDJaUlmAZcCG9oHJDmh6QO4EthUVXuSHJfk+OaY44BPAk80x20AVjTfVwD3jCvEK2pJGqCq9ia5BrgfmAGsq6onk3y+6b8FOAO4PclbwFPAymb4HODu3kU2xwDfrqofNH2rgbuSrAReAi4ZV0uq+pdcDqx7Z55+cE8g6YjxqTe3DVoXnpKpZM6BON+h4NKHJHWcQS1JHWdQS1LHGdSS1HEGtSR1nEEtSR1nUEtSxxnUktRxBrUkdZxBLUkdZ1BLUscZ1JLUcQa1JHWcQS1JHWdQS1LHGdSS1HEGtSR1nEEtSR1nUEvSEEmWJtmWZHuSVQP6Zye5O8ljSR5McmbTviDJj5I8neTJJF9ojflSkpeTbG22i8bV4cttJWmAJDOAm4FPAJPA5iQbquqp1mHXA1ur6uIkH26OvwDYC1xXVQ83byN/KMkDrbFfraob97cWr6glabAlwPaqeq6q3gDuBJb1HbMI2AhQVc8ApyaZU1W7qurhpv0XwNPAvOkWYlBL0mDzgB2t/UneGbaPAp8BSLIEOAWY3z4gyanAR4G/aDVf0yyXrEsye1whBrWko1aSiSRbWttEu3vAkOrbXw3MTrIV+D3gEXrLHvvmfx/wXeDaqtrTNK8BPgQsBnYBN42r0zVqSUetqloLrB3SPQksaO3PB3b2jd8DXAGQJMDzzUaSmfRC+ltV9b3WmFf2fU9yK/D9cXV6RS1Jg20GFiY5Lcks4FJgQ/uAJCc0fQBXApuqak8T2t8Enq6qr/SNmdvavRh4YlwhXlFL0gBVtTfJNcD9wAxgXVU9meTzTf8twBnA7UneAp4CVjbDzwMuAx5vlkUArq+q+4AvJ1lMbxnlBeCqcbWkqn/J5cC6d+bpB/cEko4Yn3pz26B14SmZSuYciPMdCi59SFLHGdSS1HEGtSR1nEEtSR1nUEtSxxnUktRxBrUkdZxBLUkdZ1BLUscZ1JLUcQa1JHWcQS1JHWdQS1LHGdSS1HEGtSR1nEEtSR1nUEtSxxnUktRxBrUkdZxBLUlDJFmaZFuS7UlWDeifneTuJI8leTDJmePGJjkxyQNJnm0+Z4+rw6CWpAGSzABuBi4EFgHLkyzqO+x6YGtVfQS4HPjafoxdBWysqoXAxmZ/JINakgZbAmyvqueq6g3gTmBZ3zGL6IUtVfUMcGqSOWPGLgPWN9/XA58eV8gx7/IfMtZ75XXsOrSSTFTV2sNdh448U8mcJBPARKtpbeu/y3nAjlbfJHBO3xSPAp8BfpJkCXAKMH/M2DlVtQugqnYlOXlcnQc9qKUhJgCDWodVE8rD/jscFPjVt78a+FqSrcDjwCPA3v0cu98MakkabBJY0NqfD+xsH1BVe4ArAJIEeL7Zjh0x9pUkc5ur6bnA7nGFuEYtSYNtBhYmOS3JLOBSYEP7gCQnNH0AVwKbmvAeNXYDsKL5vgK4Z1whXlHrcHHZQ51WVXuTXAPcD8wA1lXVk0k+3/TfApwB3J7kLeApYOWosc3Uq4G7kqwEXgIuGVdLqqa9bCJJOgRc+pCkjjOoJanjDGpNWZIFSZ5PcmKzP7vZP2XMuC8meSbJE0keTXJ50/5nzU9ttyZ5urm3dd+YF5J8t7X/2SS3HaR/mtRJBrWmrKp2AGvo/VGE5nNtVb04bEzzB5hPAEuq6kzgY/zde01/u6oWA+cBf9D6SzrA2Un+yQH8J0jvKQa1puurwLlJrgX+OXDTmOOvB363uXWJqnqtqtYPOO59wC+Bt1ptNzbjpaOSt+dpWqrqzST/FvgB8MnmeQYDJTkeOL6qfjZiym8l+VtgIXBtVbWD+i7gd5P84wNRu/Re4xW13o0LgV3AmWOOC+N/PvvbzRPIPgB8sW+9+y3gPwP/YbqFSu9lBrWmJcliemvO5wK/3/wUdqBmueOXST44bt6q+r/Aw7zz4Td/SG9d+wPTrVl6rzKoNWXNMw3W0FuieIne1e6NY4b9J+DmJO9v5nh/++6O1tzHAh8F/s4ySVW9SW9d/Np3/Q+Q3mMMak3H54CXquqBZv8bwIeT/IvmKWIAJPlvSc5udtcAPwI2J3kC+DHwemvObzVjHwJuq6qHBpz3m/h3FR2F/Am5JHWcV9SS1HEGtSR1nEEtSR1nUEtSxxnUktRxBrUkdZxBLUkd9/8BO3kpQx+poucAAAAASUVORK5CYII=",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "corr_matrix = y_test.corr()\n",
    "sns.heatmap(corr_matrix, annot=True, cmap='coolwarm', center=0)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
