{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn import preprocessing\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.neural_network import MLPRegressor\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "from sklearn.metrics import r2_score\n",
    "from scipy.stats import pearsonr\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.feature_selection import SelectFromModel\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compiling complete dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_rf = pd.read_csv(\"df_linalol_lsa.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>lsa_0</th>\n",
       "      <th>lsa_1</th>\n",
       "      <th>lsa_2</th>\n",
       "      <th>lsa_3</th>\n",
       "      <th>lsa_4</th>\n",
       "      <th>hybrid</th>\n",
       "      <th>indica</th>\n",
       "      <th>sativa</th>\n",
       "      <th>anxiety</th>\n",
       "      <th>...</th>\n",
       "      <th>sweet</th>\n",
       "      <th>tar</th>\n",
       "      <th>tea</th>\n",
       "      <th>tobacco</th>\n",
       "      <th>tree</th>\n",
       "      <th>tropical</th>\n",
       "      <th>vanilla</th>\n",
       "      <th>violet</th>\n",
       "      <th>woody</th>\n",
       "      <th>X..Linalool</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0.341025</td>\n",
       "      <td>0.182753</td>\n",
       "      <td>0.008214</td>\n",
       "      <td>0.140406</td>\n",
       "      <td>-0.156943</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.5000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0.341025</td>\n",
       "      <td>0.182753</td>\n",
       "      <td>0.008214</td>\n",
       "      <td>0.140406</td>\n",
       "      <td>-0.156943</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.5000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>0.232158</td>\n",
       "      <td>-0.045496</td>\n",
       "      <td>0.187131</td>\n",
       "      <td>-0.000936</td>\n",
       "      <td>0.018518</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.5000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>0.232158</td>\n",
       "      <td>-0.045496</td>\n",
       "      <td>0.187131</td>\n",
       "      <td>-0.000936</td>\n",
       "      <td>0.018518</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.5000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>0.232158</td>\n",
       "      <td>-0.045496</td>\n",
       "      <td>0.187131</td>\n",
       "      <td>-0.000936</td>\n",
       "      <td>0.018518</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.5000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>74995</th>\n",
       "      <td>42971</td>\n",
       "      <td>0.184573</td>\n",
       "      <td>-0.137296</td>\n",
       "      <td>-0.095301</td>\n",
       "      <td>0.181735</td>\n",
       "      <td>-0.042683</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0625</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>74996</th>\n",
       "      <td>42972</td>\n",
       "      <td>0.181714</td>\n",
       "      <td>-0.045560</td>\n",
       "      <td>-0.055692</td>\n",
       "      <td>0.015649</td>\n",
       "      <td>-0.045585</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0625</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>74997</th>\n",
       "      <td>42972</td>\n",
       "      <td>0.181714</td>\n",
       "      <td>-0.045560</td>\n",
       "      <td>-0.055692</td>\n",
       "      <td>0.015649</td>\n",
       "      <td>-0.045585</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0625</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>74998</th>\n",
       "      <td>42975</td>\n",
       "      <td>0.324915</td>\n",
       "      <td>0.131823</td>\n",
       "      <td>-0.099424</td>\n",
       "      <td>0.065491</td>\n",
       "      <td>0.038437</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0625</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>74999</th>\n",
       "      <td>42976</td>\n",
       "      <td>0.270141</td>\n",
       "      <td>-0.004631</td>\n",
       "      <td>-0.151272</td>\n",
       "      <td>0.035538</td>\n",
       "      <td>0.083641</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0625</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>75000 rows × 88 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       index     lsa_0     lsa_1     lsa_2     lsa_3     lsa_4  hybrid  \\\n",
       "0          0  0.341025  0.182753  0.008214  0.140406 -0.156943       1   \n",
       "1          0  0.341025  0.182753  0.008214  0.140406 -0.156943       1   \n",
       "2          1  0.232158 -0.045496  0.187131 -0.000936  0.018518       1   \n",
       "3          1  0.232158 -0.045496  0.187131 -0.000936  0.018518       1   \n",
       "4          1  0.232158 -0.045496  0.187131 -0.000936  0.018518       1   \n",
       "...      ...       ...       ...       ...       ...       ...     ...   \n",
       "74995  42971  0.184573 -0.137296 -0.095301  0.181735 -0.042683       0   \n",
       "74996  42972  0.181714 -0.045560 -0.055692  0.015649 -0.045585       0   \n",
       "74997  42972  0.181714 -0.045560 -0.055692  0.015649 -0.045585       0   \n",
       "74998  42975  0.324915  0.131823 -0.099424  0.065491  0.038437       0   \n",
       "74999  42976  0.270141 -0.004631 -0.151272  0.035538  0.083641       0   \n",
       "\n",
       "       indica  sativa  anxiety  ...  sweet  tar  tea  tobacco  tree  tropical  \\\n",
       "0           0       0        0  ...      0    0    0        0     0         0   \n",
       "1           0       0        0  ...      0    0    0        0     0         0   \n",
       "2           0       0        0  ...      0    0    0        0     0         0   \n",
       "3           0       0        0  ...      0    0    0        0     0         0   \n",
       "4           0       0        0  ...      0    0    0        0     0         0   \n",
       "...       ...     ...      ...  ...    ...  ...  ...      ...   ...       ...   \n",
       "74995       1       0        0  ...      0    0    0        0     0         0   \n",
       "74996       1       0        0  ...      0    0    0        0     0         0   \n",
       "74997       1       0        0  ...      0    0    0        0     0         0   \n",
       "74998       1       0        0  ...      0    0    0        0     0         0   \n",
       "74999       1       0        0  ...      1    1    1        1     1         1   \n",
       "\n",
       "       vanilla  violet  woody  X..Linalool  \n",
       "0            0       0      0       0.5000  \n",
       "1            0       0      0       0.5000  \n",
       "2            1       0      0       0.5000  \n",
       "3            1       0      0       0.5000  \n",
       "4            1       0      0       0.5000  \n",
       "...        ...     ...    ...          ...  \n",
       "74995        0       0      0       0.0625  \n",
       "74996        0       0      0       0.0625  \n",
       "74997        0       0      0       0.0625  \n",
       "74998        0       0      0       0.0625  \n",
       "74999        1       1      1       0.0625  \n",
       "\n",
       "[75000 rows x 88 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_rf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['index',\n",
       " 'lsa_0',\n",
       " 'lsa_1',\n",
       " 'lsa_2',\n",
       " 'lsa_3',\n",
       " 'lsa_4',\n",
       " 'hybrid',\n",
       " 'indica',\n",
       " 'sativa',\n",
       " 'anxiety',\n",
       " 'anxious',\n",
       " 'aroused',\n",
       " 'arthritis',\n",
       " 'creative',\n",
       " 'depression',\n",
       " 'dizzy',\n",
       " 'dry eyes',\n",
       " 'dry mouth',\n",
       " 'energetic',\n",
       " 'epilepsy',\n",
       " 'euphoric',\n",
       " 'eye pressure',\n",
       " 'fatigue',\n",
       " 'focused',\n",
       " 'giggly',\n",
       " 'happy',\n",
       " 'headache',\n",
       " 'hungry',\n",
       " 'migraines',\n",
       " 'pain',\n",
       " 'paranoid',\n",
       " 'relaxed',\n",
       " 'seizures',\n",
       " 'sleepy',\n",
       " 'spasticity',\n",
       " 'stress',\n",
       " 'talkative',\n",
       " 'tingly',\n",
       " 'uplifted',\n",
       " 'ammonia',\n",
       " 'apple',\n",
       " 'apricot',\n",
       " 'berry',\n",
       " 'blue cheese',\n",
       " 'blueberry',\n",
       " 'butter',\n",
       " 'cheese',\n",
       " 'chemical',\n",
       " 'chestnut',\n",
       " 'citrus',\n",
       " 'coffee',\n",
       " 'diesel',\n",
       " 'earthy',\n",
       " 'flowery',\n",
       " 'fruit',\n",
       " 'grape',\n",
       " 'grapefruit',\n",
       " 'honey',\n",
       " 'lavender',\n",
       " 'lemon',\n",
       " 'lime',\n",
       " 'mango',\n",
       " 'menthol',\n",
       " 'mint',\n",
       " 'nutty',\n",
       " 'orange',\n",
       " 'peach',\n",
       " 'pear',\n",
       " 'pepper',\n",
       " 'pine',\n",
       " 'pineapple',\n",
       " 'plum',\n",
       " 'pungent',\n",
       " 'rose',\n",
       " 'sage',\n",
       " 'skunk',\n",
       " 'spicy/herbal',\n",
       " 'strawberry',\n",
       " 'sweet',\n",
       " 'tar',\n",
       " 'tea',\n",
       " 'tobacco',\n",
       " 'tree',\n",
       " 'tropical',\n",
       " 'vanilla',\n",
       " 'violet',\n",
       " 'woody',\n",
       " 'X..Linalool']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_rf.columns.to_list()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Splitting dependent and independent variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df_rf.drop(['index', 'X..Linalool'], axis = 1)\n",
    "y = df_rf[['X..Linalool']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plotting histograms on target variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.5   ],\n",
       "       [0.5   ],\n",
       "       [0.5   ],\n",
       "       ...,\n",
       "       [0.0625],\n",
       "       [0.0625],\n",
       "       [0.0625]])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_array = y.to_numpy()\n",
    "y_array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Axes: ylabel='Count'>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "sns.histplot(y, bins = 10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train test split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=1, test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train1, X_val, y_train1, y_val = train_test_split(X_train, y_train, random_state=1, test_size=0.25)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "RF modeling (before Feature selection and Hyperparameter Tuning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/ns/m5pnr0211w91v02hpv22958m0000gn/T/ipykernel_4060/119766249.py:2: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  rfreg.fit(X_train1, y_train1)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;background-color: white;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>RandomForestRegressor(n_jobs=-1)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">RandomForestRegressor</label><div class=\"sk-toggleable__content\"><pre>RandomForestRegressor(n_jobs=-1)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "RandomForestRegressor(n_jobs=-1)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rfreg = RandomForestRegressor(n_jobs = -1)\n",
    "rfreg.fit(X_train1, y_train1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_rfreg = rfreg.predict(X_val)\n",
    "y_pred_rfreg_r2 = rfreg.predict(X_train1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.036877768955267995"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mean_absolute_error(y_val, y_pred_rfreg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.006181291668096394"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mean_squared_error(y_val, y_pred_rfreg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.07862119096081154"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mean_squared_error(y_val, y_pred_rfreg, squared = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9828764296014347"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#train\n",
    "r2_score(y_train1, y_pred_rfreg_r2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9379997075606002"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#val\n",
    "r2_score(y_val, y_pred_rfreg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Residual plots for each target variable"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Feature Selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_feat = pd.DataFrame({\n",
    "    \"features\": X_train1.columns,\n",
    "    \"score\": rfreg.feature_importances_\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>features</th>\n",
       "      <th>score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>lsa_0</td>\n",
       "      <td>0.108706</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>lsa_1</td>\n",
       "      <td>0.091060</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>lsa_2</td>\n",
       "      <td>0.083020</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>lsa_3</td>\n",
       "      <td>0.082050</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>lsa_4</td>\n",
       "      <td>0.091344</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>81</th>\n",
       "      <td>tree</td>\n",
       "      <td>0.000446</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>82</th>\n",
       "      <td>tropical</td>\n",
       "      <td>0.001138</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>83</th>\n",
       "      <td>vanilla</td>\n",
       "      <td>0.001494</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>84</th>\n",
       "      <td>violet</td>\n",
       "      <td>0.000097</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>85</th>\n",
       "      <td>woody</td>\n",
       "      <td>0.002036</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>86 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    features     score\n",
       "0      lsa_0  0.108706\n",
       "1      lsa_1  0.091060\n",
       "2      lsa_2  0.083020\n",
       "3      lsa_3  0.082050\n",
       "4      lsa_4  0.091344\n",
       "..       ...       ...\n",
       "81      tree  0.000446\n",
       "82  tropical  0.001138\n",
       "83   vanilla  0.001494\n",
       "84    violet  0.000097\n",
       "85     woody  0.002036\n",
       "\n",
       "[86 rows x 2 columns]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_feat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_feat_ranked = df_feat.sort_values(\"score\", ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>features</th>\n",
       "      <th>score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>hybrid</td>\n",
       "      <td>2.319605e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>lsa_0</td>\n",
       "      <td>1.087065e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>lsa_4</td>\n",
       "      <td>9.134363e-02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>lsa_1</td>\n",
       "      <td>9.106041e-02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>lsa_2</td>\n",
       "      <td>8.302021e-02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>lsa_3</td>\n",
       "      <td>8.205048e-02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>cheese</td>\n",
       "      <td>2.371999e-02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>68</th>\n",
       "      <td>pine</td>\n",
       "      <td>2.071725e-02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51</th>\n",
       "      <td>earthy</td>\n",
       "      <td>1.635464e-02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>64</th>\n",
       "      <td>orange</td>\n",
       "      <td>1.557142e-02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>56</th>\n",
       "      <td>honey</td>\n",
       "      <td>1.536205e-02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>77</th>\n",
       "      <td>sweet</td>\n",
       "      <td>1.301642e-02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>happy</td>\n",
       "      <td>1.283400e-02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>relaxed</td>\n",
       "      <td>1.243922e-02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>blueberry</td>\n",
       "      <td>1.177300e-02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>tingly</td>\n",
       "      <td>1.160515e-02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>creative</td>\n",
       "      <td>1.068411e-02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>sleepy</td>\n",
       "      <td>1.065800e-02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50</th>\n",
       "      <td>diesel</td>\n",
       "      <td>9.301357e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>energetic</td>\n",
       "      <td>8.535780e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>euphoric</td>\n",
       "      <td>7.560328e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>aroused</td>\n",
       "      <td>7.547675e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>giggly</td>\n",
       "      <td>6.976517e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>dry mouth</td>\n",
       "      <td>6.609417e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>uplifted</td>\n",
       "      <td>6.526349e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>dry eyes</td>\n",
       "      <td>5.595899e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52</th>\n",
       "      <td>flowery</td>\n",
       "      <td>5.090598e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>74</th>\n",
       "      <td>skunk</td>\n",
       "      <td>5.023838e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>hungry</td>\n",
       "      <td>4.945845e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>58</th>\n",
       "      <td>lemon</td>\n",
       "      <td>4.275551e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54</th>\n",
       "      <td>grape</td>\n",
       "      <td>4.209498e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>talkative</td>\n",
       "      <td>4.181218e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>71</th>\n",
       "      <td>pungent</td>\n",
       "      <td>4.145800e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>focused</td>\n",
       "      <td>4.134624e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>citrus</td>\n",
       "      <td>3.581979e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>berry</td>\n",
       "      <td>3.436685e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>coffee</td>\n",
       "      <td>2.268116e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>85</th>\n",
       "      <td>woody</td>\n",
       "      <td>2.035682e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>79</th>\n",
       "      <td>tea</td>\n",
       "      <td>1.852957e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>sativa</td>\n",
       "      <td>1.805562e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>anxious</td>\n",
       "      <td>1.780681e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>62</th>\n",
       "      <td>mint</td>\n",
       "      <td>1.686632e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>chemical</td>\n",
       "      <td>1.590382e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>dizzy</td>\n",
       "      <td>1.501249e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>83</th>\n",
       "      <td>vanilla</td>\n",
       "      <td>1.494404e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>chestnut</td>\n",
       "      <td>1.454603e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75</th>\n",
       "      <td>spicy/herbal</td>\n",
       "      <td>1.407191e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>indica</td>\n",
       "      <td>1.280463e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59</th>\n",
       "      <td>lime</td>\n",
       "      <td>1.272899e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>butter</td>\n",
       "      <td>1.262648e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>paranoid</td>\n",
       "      <td>1.256531e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>82</th>\n",
       "      <td>tropical</td>\n",
       "      <td>1.137888e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>headache</td>\n",
       "      <td>9.842336e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>73</th>\n",
       "      <td>sage</td>\n",
       "      <td>9.189541e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>69</th>\n",
       "      <td>pineapple</td>\n",
       "      <td>8.674061e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>ammonia</td>\n",
       "      <td>8.248478e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>apple</td>\n",
       "      <td>7.843090e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>67</th>\n",
       "      <td>pepper</td>\n",
       "      <td>6.822245e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>60</th>\n",
       "      <td>mango</td>\n",
       "      <td>6.253656e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>63</th>\n",
       "      <td>nutty</td>\n",
       "      <td>5.094230e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>76</th>\n",
       "      <td>strawberry</td>\n",
       "      <td>4.553579e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>55</th>\n",
       "      <td>grapefruit</td>\n",
       "      <td>4.485784e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>81</th>\n",
       "      <td>tree</td>\n",
       "      <td>4.462515e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53</th>\n",
       "      <td>fruit</td>\n",
       "      <td>4.208432e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>72</th>\n",
       "      <td>rose</td>\n",
       "      <td>4.083709e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>65</th>\n",
       "      <td>peach</td>\n",
       "      <td>3.913662e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>80</th>\n",
       "      <td>tobacco</td>\n",
       "      <td>3.019444e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>57</th>\n",
       "      <td>lavender</td>\n",
       "      <td>2.865621e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>blue cheese</td>\n",
       "      <td>2.533344e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>70</th>\n",
       "      <td>plum</td>\n",
       "      <td>1.672123e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>61</th>\n",
       "      <td>menthol</td>\n",
       "      <td>1.501947e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>78</th>\n",
       "      <td>tar</td>\n",
       "      <td>1.182010e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>84</th>\n",
       "      <td>violet</td>\n",
       "      <td>9.660213e-05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>depression</td>\n",
       "      <td>4.971862e-05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>anxiety</td>\n",
       "      <td>4.861748e-05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>66</th>\n",
       "      <td>pear</td>\n",
       "      <td>4.559582e-05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>migraines</td>\n",
       "      <td>3.761717e-05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>apricot</td>\n",
       "      <td>3.197165e-05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>arthritis</td>\n",
       "      <td>3.167481e-07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>seizures</td>\n",
       "      <td>2.531644e-07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>epilepsy</td>\n",
       "      <td>2.526302e-07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>fatigue</td>\n",
       "      <td>2.183139e-07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>pain</td>\n",
       "      <td>6.311854e-08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>eye pressure</td>\n",
       "      <td>6.894076e-09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>spasticity</td>\n",
       "      <td>0.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>stress</td>\n",
       "      <td>0.000000e+00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        features         score\n",
       "5         hybrid  2.319605e-01\n",
       "0          lsa_0  1.087065e-01\n",
       "4          lsa_4  9.134363e-02\n",
       "1          lsa_1  9.106041e-02\n",
       "2          lsa_2  8.302021e-02\n",
       "3          lsa_3  8.205048e-02\n",
       "45        cheese  2.371999e-02\n",
       "68          pine  2.071725e-02\n",
       "51        earthy  1.635464e-02\n",
       "64        orange  1.557142e-02\n",
       "56         honey  1.536205e-02\n",
       "77         sweet  1.301642e-02\n",
       "24         happy  1.283400e-02\n",
       "30       relaxed  1.243922e-02\n",
       "43     blueberry  1.177300e-02\n",
       "36        tingly  1.160515e-02\n",
       "12      creative  1.068411e-02\n",
       "32        sleepy  1.065800e-02\n",
       "50        diesel  9.301357e-03\n",
       "17     energetic  8.535780e-03\n",
       "19      euphoric  7.560328e-03\n",
       "10       aroused  7.547675e-03\n",
       "23        giggly  6.976517e-03\n",
       "16     dry mouth  6.609417e-03\n",
       "37      uplifted  6.526349e-03\n",
       "15      dry eyes  5.595899e-03\n",
       "52       flowery  5.090598e-03\n",
       "74         skunk  5.023838e-03\n",
       "26        hungry  4.945845e-03\n",
       "58         lemon  4.275551e-03\n",
       "54         grape  4.209498e-03\n",
       "35     talkative  4.181218e-03\n",
       "71       pungent  4.145800e-03\n",
       "22       focused  4.134624e-03\n",
       "48        citrus  3.581979e-03\n",
       "41         berry  3.436685e-03\n",
       "49        coffee  2.268116e-03\n",
       "85         woody  2.035682e-03\n",
       "79           tea  1.852957e-03\n",
       "7         sativa  1.805562e-03\n",
       "9        anxious  1.780681e-03\n",
       "62          mint  1.686632e-03\n",
       "46      chemical  1.590382e-03\n",
       "14         dizzy  1.501249e-03\n",
       "83       vanilla  1.494404e-03\n",
       "47      chestnut  1.454603e-03\n",
       "75  spicy/herbal  1.407191e-03\n",
       "6         indica  1.280463e-03\n",
       "59          lime  1.272899e-03\n",
       "44        butter  1.262648e-03\n",
       "29      paranoid  1.256531e-03\n",
       "82      tropical  1.137888e-03\n",
       "25      headache  9.842336e-04\n",
       "73          sage  9.189541e-04\n",
       "69     pineapple  8.674061e-04\n",
       "38       ammonia  8.248478e-04\n",
       "39         apple  7.843090e-04\n",
       "67        pepper  6.822245e-04\n",
       "60         mango  6.253656e-04\n",
       "63         nutty  5.094230e-04\n",
       "76    strawberry  4.553579e-04\n",
       "55    grapefruit  4.485784e-04\n",
       "81          tree  4.462515e-04\n",
       "53         fruit  4.208432e-04\n",
       "72          rose  4.083709e-04\n",
       "65         peach  3.913662e-04\n",
       "80       tobacco  3.019444e-04\n",
       "57      lavender  2.865621e-04\n",
       "42   blue cheese  2.533344e-04\n",
       "70          plum  1.672123e-04\n",
       "61       menthol  1.501947e-04\n",
       "78           tar  1.182010e-04\n",
       "84        violet  9.660213e-05\n",
       "13    depression  4.971862e-05\n",
       "8        anxiety  4.861748e-05\n",
       "66          pear  4.559582e-05\n",
       "27     migraines  3.761717e-05\n",
       "40       apricot  3.197165e-05\n",
       "11     arthritis  3.167481e-07\n",
       "31      seizures  2.531644e-07\n",
       "18      epilepsy  2.526302e-07\n",
       "21       fatigue  2.183139e-07\n",
       "28          pain  6.311854e-08\n",
       "20  eye pressure  6.894076e-09\n",
       "33    spasticity  0.000000e+00\n",
       "34        stress  0.000000e+00"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.set_option('display.max_rows', df_feat_ranked.shape[0]+1)\n",
    "df_feat_ranked"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/louispandu/anaconda3/lib/python3.10/site-packages/sklearn/feature_selection/_from_model.py:357: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  self.estimator_.fit(X, y, **fit_params)\n"
     ]
    }
   ],
   "source": [
    "selector = SelectFromModel(rfreg).fit(X_train1, y_train1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1.09945451e-01, 8.99419501e-02, 8.26175908e-02, 8.14599450e-02,\n",
       "       9.39914846e-02, 2.32330678e-01, 1.34443520e-03, 1.63858512e-03,\n",
       "       4.45142776e-05, 2.00823118e-03, 7.37442298e-03, 8.18658143e-08,\n",
       "       9.87765659e-03, 2.77492151e-05, 1.46351240e-03, 5.62356328e-03,\n",
       "       6.12365967e-03, 7.87352481e-03, 2.22679773e-08, 7.28188842e-03,\n",
       "       2.01708975e-07, 1.05562080e-07, 4.34839787e-03, 7.14537405e-03,\n",
       "       1.29549494e-02, 9.61371342e-04, 4.80689307e-03, 4.35248264e-05,\n",
       "       2.84745726e-07, 1.30204590e-03, 1.19784703e-02, 6.05102643e-08,\n",
       "       1.06902778e-02, 0.00000000e+00, 0.00000000e+00, 4.58263030e-03,\n",
       "       1.14212113e-02, 7.12726576e-03, 8.72706001e-04, 7.65478588e-04,\n",
       "       2.46753622e-05, 3.34420771e-03, 2.78687659e-04, 1.15114577e-02,\n",
       "       1.23474425e-03, 2.37103974e-02, 1.61971885e-03, 1.50037001e-03,\n",
       "       3.77055298e-03, 2.04811986e-03, 9.78714634e-03, 1.61068955e-02,\n",
       "       5.13541258e-03, 5.15410663e-04, 3.97915961e-03, 6.57477119e-04,\n",
       "       1.59148527e-02, 3.69291180e-04, 4.20843387e-03, 9.11728618e-04,\n",
       "       5.46607618e-04, 1.49004203e-04, 1.73654247e-03, 5.89716936e-04,\n",
       "       1.53426197e-02, 4.05656321e-04, 5.23743253e-05, 7.13527750e-04,\n",
       "       2.00596390e-02, 1.07491478e-03, 1.63931836e-04, 4.13485646e-03,\n",
       "       4.18656210e-04, 9.03850412e-04, 4.67205619e-03, 1.43083679e-03,\n",
       "       4.50098144e-04, 1.26495093e-02, 2.77824198e-04, 1.88115590e-03,\n",
       "       6.54171469e-04, 3.83485845e-04, 1.04884653e-03, 1.47228208e-03,\n",
       "       9.45664247e-05, 2.09433382e-03])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "selector.estimator_.feature_importances_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.011627906976744186"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "selector.threshold_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "mask = selector.get_support()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ True,  True,  True,  True,  True,  True, False, False, False,\n",
       "       False, False, False, False, False, False, False, False, False,\n",
       "       False, False, False, False, False, False,  True, False, False,\n",
       "       False, False, False,  True, False, False, False, False, False,\n",
       "       False, False, False, False, False, False, False, False, False,\n",
       "        True, False, False, False, False, False,  True, False, False,\n",
       "       False, False,  True, False, False, False, False, False, False,\n",
       "       False,  True, False, False, False,  True, False, False, False,\n",
       "       False, False, False, False, False,  True, False, False, False,\n",
       "       False, False, False, False, False])"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "selected_features = X.columns[mask]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>lsa_0</th>\n",
       "      <th>lsa_1</th>\n",
       "      <th>lsa_2</th>\n",
       "      <th>lsa_3</th>\n",
       "      <th>lsa_4</th>\n",
       "      <th>hybrid</th>\n",
       "      <th>happy</th>\n",
       "      <th>relaxed</th>\n",
       "      <th>cheese</th>\n",
       "      <th>earthy</th>\n",
       "      <th>honey</th>\n",
       "      <th>orange</th>\n",
       "      <th>pine</th>\n",
       "      <th>sweet</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.341025</td>\n",
       "      <td>0.182753</td>\n",
       "      <td>0.008214</td>\n",
       "      <td>0.140406</td>\n",
       "      <td>-0.156943</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.341025</td>\n",
       "      <td>0.182753</td>\n",
       "      <td>0.008214</td>\n",
       "      <td>0.140406</td>\n",
       "      <td>-0.156943</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.232158</td>\n",
       "      <td>-0.045496</td>\n",
       "      <td>0.187131</td>\n",
       "      <td>-0.000936</td>\n",
       "      <td>0.018518</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.232158</td>\n",
       "      <td>-0.045496</td>\n",
       "      <td>0.187131</td>\n",
       "      <td>-0.000936</td>\n",
       "      <td>0.018518</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.232158</td>\n",
       "      <td>-0.045496</td>\n",
       "      <td>0.187131</td>\n",
       "      <td>-0.000936</td>\n",
       "      <td>0.018518</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>74995</th>\n",
       "      <td>0.184573</td>\n",
       "      <td>-0.137296</td>\n",
       "      <td>-0.095301</td>\n",
       "      <td>0.181735</td>\n",
       "      <td>-0.042683</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>74996</th>\n",
       "      <td>0.181714</td>\n",
       "      <td>-0.045560</td>\n",
       "      <td>-0.055692</td>\n",
       "      <td>0.015649</td>\n",
       "      <td>-0.045585</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>74997</th>\n",
       "      <td>0.181714</td>\n",
       "      <td>-0.045560</td>\n",
       "      <td>-0.055692</td>\n",
       "      <td>0.015649</td>\n",
       "      <td>-0.045585</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>74998</th>\n",
       "      <td>0.324915</td>\n",
       "      <td>0.131823</td>\n",
       "      <td>-0.099424</td>\n",
       "      <td>0.065491</td>\n",
       "      <td>0.038437</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>74999</th>\n",
       "      <td>0.270141</td>\n",
       "      <td>-0.004631</td>\n",
       "      <td>-0.151272</td>\n",
       "      <td>0.035538</td>\n",
       "      <td>0.083641</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>75000 rows × 14 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          lsa_0     lsa_1     lsa_2     lsa_3     lsa_4  hybrid  happy  \\\n",
       "0      0.341025  0.182753  0.008214  0.140406 -0.156943       1      0   \n",
       "1      0.341025  0.182753  0.008214  0.140406 -0.156943       1      0   \n",
       "2      0.232158 -0.045496  0.187131 -0.000936  0.018518       1      1   \n",
       "3      0.232158 -0.045496  0.187131 -0.000936  0.018518       1      1   \n",
       "4      0.232158 -0.045496  0.187131 -0.000936  0.018518       1      1   \n",
       "...         ...       ...       ...       ...       ...     ...    ...   \n",
       "74995  0.184573 -0.137296 -0.095301  0.181735 -0.042683       0      1   \n",
       "74996  0.181714 -0.045560 -0.055692  0.015649 -0.045585       0      1   \n",
       "74997  0.181714 -0.045560 -0.055692  0.015649 -0.045585       0      1   \n",
       "74998  0.324915  0.131823 -0.099424  0.065491  0.038437       0      1   \n",
       "74999  0.270141 -0.004631 -0.151272  0.035538  0.083641       0      1   \n",
       "\n",
       "       relaxed  cheese  earthy  honey  orange  pine  sweet  \n",
       "0            1       0       0      0       0     0      0  \n",
       "1            1       0       0      0       0     0      0  \n",
       "2            1       1       0      0       0     0      0  \n",
       "3            1       1       0      0       0     0      0  \n",
       "4            1       1       0      0       0     0      0  \n",
       "...        ...     ...     ...    ...     ...   ...    ...  \n",
       "74995        0       0       0      0       0     0      0  \n",
       "74996        1       0       0      0       0     0      0  \n",
       "74997        1       0       0      0       0     0      0  \n",
       "74998        1       0       0      0       0     0      0  \n",
       "74999        1       1       1      1       1     1      1  \n",
       "\n",
       "[75000 rows x 14 columns]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "selected_X = df_rf[selected_features]\n",
    "selected_X"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train test split (after Feature Selection)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['selected_X_rf_lsa_elbow_linalol.pkl']"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import joblib\n",
    "\n",
    "joblib.dump(selector, \"selector_rf_lsa_elbow_linalol.pkl\")\n",
    "joblib.dump(selected_X, \"selected_X_rf_lsa_elbow_linalol.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(selected_X, y, random_state=1, test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train1, X_val, y_train1, y_val = train_test_split(X_train, y_train, random_state=1, test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/ns/m5pnr0211w91v02hpv22958m0000gn/T/ipykernel_4060/3758305.py:1: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  rfreg.fit(X_train1, y_train1)\n"
     ]
    }
   ],
   "source": [
    "rfreg.fit(X_train1, y_train1)\n",
    "y_pred_rfreg = rfreg.predict(X_val)\n",
    "y_pred_rfreg_r2 = rfreg.predict(X_train1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.03912944073425985"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mean_absolute_error(y_val, y_pred_rfreg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.00676131424704873"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mean_squared_error(y_val, y_pred_rfreg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.08222721111073103"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mean_squared_error(y_val, y_pred_rfreg, squared = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9773803620737438"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#train\n",
    "r2_score(y_train1, y_pred_rfreg_r2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9324510063056475"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#val\n",
    "r2_score(y_val, y_pred_rfreg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hyperparameter Tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "parameters = { 'max_depth': [None, 10, 50, 100],\n",
    "              'max_features': ['auto', 'sqrt'],\n",
    "              'min_samples_leaf': [1, 2, 4],\n",
    "              'min_samples_split': [2, 5, 10],\n",
    "              'n_estimators': [100, 300, 500]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "rscv = RandomizedSearchCV(rfreg,  \n",
    "                     parameters,   \n",
    "                     cv=5, \n",
    "                     scoring='neg_mean_absolute_error',\n",
    "                     n_jobs= -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/louispandu/anaconda3/lib/python3.10/site-packages/sklearn/model_selection/_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/Users/louispandu/anaconda3/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
      "  warn(\n",
      "/Users/louispandu/anaconda3/lib/python3.10/site-packages/sklearn/model_selection/_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/Users/louispandu/anaconda3/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
      "  warn(\n",
      "/Users/louispandu/anaconda3/lib/python3.10/site-packages/sklearn/model_selection/_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/Users/louispandu/anaconda3/lib/python3.10/site-packages/sklearn/model_selection/_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/Users/louispandu/anaconda3/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
      "  warn(\n",
      "/Users/louispandu/anaconda3/lib/python3.10/site-packages/sklearn/model_selection/_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/Users/louispandu/anaconda3/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
      "  warn(\n",
      "/Users/louispandu/anaconda3/lib/python3.10/site-packages/sklearn/model_selection/_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/Users/louispandu/anaconda3/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
      "  warn(\n",
      "/Users/louispandu/anaconda3/lib/python3.10/site-packages/sklearn/model_selection/_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/Users/louispandu/anaconda3/lib/python3.10/site-packages/sklearn/model_selection/_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/Users/louispandu/anaconda3/lib/python3.10/site-packages/sklearn/model_selection/_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/Users/louispandu/anaconda3/lib/python3.10/site-packages/sklearn/model_selection/_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/Users/louispandu/anaconda3/lib/python3.10/site-packages/sklearn/model_selection/_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/Users/louispandu/anaconda3/lib/python3.10/site-packages/sklearn/model_selection/_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/Users/louispandu/anaconda3/lib/python3.10/site-packages/sklearn/model_selection/_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/Users/louispandu/anaconda3/lib/python3.10/site-packages/sklearn/model_selection/_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/Users/louispandu/anaconda3/lib/python3.10/site-packages/sklearn/model_selection/_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/Users/louispandu/anaconda3/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
      "  warn(\n",
      "/Users/louispandu/anaconda3/lib/python3.10/site-packages/sklearn/model_selection/_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/Users/louispandu/anaconda3/lib/python3.10/site-packages/sklearn/model_selection/_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/Users/louispandu/anaconda3/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
      "  warn(\n",
      "/Users/louispandu/anaconda3/lib/python3.10/site-packages/sklearn/model_selection/_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/Users/louispandu/anaconda3/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
      "  warn(\n",
      "/Users/louispandu/anaconda3/lib/python3.10/site-packages/sklearn/model_selection/_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/Users/louispandu/anaconda3/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
      "  warn(\n",
      "/Users/louispandu/anaconda3/lib/python3.10/site-packages/sklearn/model_selection/_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/Users/louispandu/anaconda3/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
      "  warn(\n",
      "/Users/louispandu/anaconda3/lib/python3.10/site-packages/sklearn/model_selection/_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/Users/louispandu/anaconda3/lib/python3.10/site-packages/sklearn/model_selection/_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/Users/louispandu/anaconda3/lib/python3.10/site-packages/sklearn/model_selection/_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/Users/louispandu/anaconda3/lib/python3.10/site-packages/sklearn/model_selection/_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/Users/louispandu/anaconda3/lib/python3.10/site-packages/sklearn/model_selection/_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/Users/louispandu/anaconda3/lib/python3.10/site-packages/sklearn/model_selection/_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/Users/louispandu/anaconda3/lib/python3.10/site-packages/sklearn/model_selection/_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/Users/louispandu/anaconda3/lib/python3.10/site-packages/sklearn/model_selection/_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/Users/louispandu/anaconda3/lib/python3.10/site-packages/sklearn/model_selection/_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/Users/louispandu/anaconda3/lib/python3.10/site-packages/sklearn/model_selection/_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/Users/louispandu/anaconda3/lib/python3.10/site-packages/sklearn/model_selection/_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/Users/louispandu/anaconda3/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
      "  warn(\n",
      "/Users/louispandu/anaconda3/lib/python3.10/site-packages/sklearn/model_selection/_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/Users/louispandu/anaconda3/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
      "  warn(\n",
      "/Users/louispandu/anaconda3/lib/python3.10/site-packages/sklearn/model_selection/_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/Users/louispandu/anaconda3/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
      "  warn(\n",
      "/Users/louispandu/anaconda3/lib/python3.10/site-packages/sklearn/model_selection/_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/Users/louispandu/anaconda3/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
      "  warn(\n",
      "/Users/louispandu/anaconda3/lib/python3.10/site-packages/sklearn/model_selection/_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/Users/louispandu/anaconda3/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
      "  warn(\n",
      "/Users/louispandu/anaconda3/lib/python3.10/site-packages/sklearn/model_selection/_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/Users/louispandu/anaconda3/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
      "  warn(\n",
      "/Users/louispandu/anaconda3/lib/python3.10/site-packages/sklearn/model_selection/_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/Users/louispandu/anaconda3/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
      "  warn(\n",
      "/Users/louispandu/anaconda3/lib/python3.10/site-packages/sklearn/model_selection/_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/Users/louispandu/anaconda3/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
      "  warn(\n",
      "/Users/louispandu/anaconda3/lib/python3.10/site-packages/sklearn/model_selection/_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/Users/louispandu/anaconda3/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
      "  warn(\n",
      "/Users/louispandu/anaconda3/lib/python3.10/site-packages/sklearn/model_selection/_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/Users/louispandu/anaconda3/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
      "  warn(\n",
      "/Users/louispandu/anaconda3/lib/python3.10/site-packages/sklearn/model_selection/_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/Users/louispandu/anaconda3/lib/python3.10/site-packages/sklearn/model_selection/_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/Users/louispandu/anaconda3/lib/python3.10/site-packages/sklearn/model_selection/_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/Users/louispandu/anaconda3/lib/python3.10/site-packages/sklearn/model_selection/_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/Users/louispandu/anaconda3/lib/python3.10/site-packages/sklearn/model_selection/_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/Users/louispandu/anaconda3/lib/python3.10/site-packages/sklearn/model_selection/_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/Users/louispandu/anaconda3/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
      "  warn(\n",
      "/Users/louispandu/anaconda3/lib/python3.10/site-packages/sklearn/model_selection/_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/Users/louispandu/anaconda3/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
      "  warn(\n",
      "/Users/louispandu/anaconda3/lib/python3.10/site-packages/sklearn/model_selection/_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/Users/louispandu/anaconda3/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
      "  warn(\n",
      "/Users/louispandu/anaconda3/lib/python3.10/site-packages/sklearn/model_selection/_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/Users/louispandu/anaconda3/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
      "  warn(\n",
      "/Users/louispandu/anaconda3/lib/python3.10/site-packages/sklearn/model_selection/_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/Users/louispandu/anaconda3/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
      "  warn(\n",
      "/Users/louispandu/anaconda3/lib/python3.10/site-packages/sklearn/model_selection/_search.py:909: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  self.best_estimator_.fit(X, y, **fit_params)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-2 {color: black;background-color: white;}#sk-container-id-2 pre{padding: 0;}#sk-container-id-2 div.sk-toggleable {background-color: white;}#sk-container-id-2 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-2 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-2 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-2 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-2 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-2 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-2 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-2 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-2 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-2 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-2 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-2 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-2 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-2 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-2 div.sk-item {position: relative;z-index: 1;}#sk-container-id-2 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-2 div.sk-item::before, #sk-container-id-2 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-2 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-2 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-2 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-2 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-2 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-2 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-2 div.sk-label-container {text-align: center;}#sk-container-id-2 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-2 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-2\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>RandomizedSearchCV(cv=5, estimator=RandomForestRegressor(n_jobs=-1), n_jobs=-1,\n",
       "                   param_distributions={&#x27;max_depth&#x27;: [None, 10, 50, 100],\n",
       "                                        &#x27;max_features&#x27;: [&#x27;auto&#x27;, &#x27;sqrt&#x27;],\n",
       "                                        &#x27;min_samples_leaf&#x27;: [1, 2, 4],\n",
       "                                        &#x27;min_samples_split&#x27;: [2, 5, 10],\n",
       "                                        &#x27;n_estimators&#x27;: [100, 300, 500]},\n",
       "                   scoring=&#x27;neg_mean_absolute_error&#x27;)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" ><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">RandomizedSearchCV</label><div class=\"sk-toggleable__content\"><pre>RandomizedSearchCV(cv=5, estimator=RandomForestRegressor(n_jobs=-1), n_jobs=-1,\n",
       "                   param_distributions={&#x27;max_depth&#x27;: [None, 10, 50, 100],\n",
       "                                        &#x27;max_features&#x27;: [&#x27;auto&#x27;, &#x27;sqrt&#x27;],\n",
       "                                        &#x27;min_samples_leaf&#x27;: [1, 2, 4],\n",
       "                                        &#x27;min_samples_split&#x27;: [2, 5, 10],\n",
       "                                        &#x27;n_estimators&#x27;: [100, 300, 500]},\n",
       "                   scoring=&#x27;neg_mean_absolute_error&#x27;)</pre></div></div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-3\" type=\"checkbox\" ><label for=\"sk-estimator-id-3\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">estimator: RandomForestRegressor</label><div class=\"sk-toggleable__content\"><pre>RandomForestRegressor(n_jobs=-1)</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-4\" type=\"checkbox\" ><label for=\"sk-estimator-id-4\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">RandomForestRegressor</label><div class=\"sk-toggleable__content\"><pre>RandomForestRegressor(n_jobs=-1)</pre></div></div></div></div></div></div></div></div></div></div>"
      ],
      "text/plain": [
       "RandomizedSearchCV(cv=5, estimator=RandomForestRegressor(n_jobs=-1), n_jobs=-1,\n",
       "                   param_distributions={'max_depth': [None, 10, 50, 100],\n",
       "                                        'max_features': ['auto', 'sqrt'],\n",
       "                                        'min_samples_leaf': [1, 2, 4],\n",
       "                                        'min_samples_split': [2, 5, 10],\n",
       "                                        'n_estimators': [100, 300, 500]},\n",
       "                   scoring='neg_mean_absolute_error')"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rscv.fit(X_train1, y_train1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'n_estimators': 300,\n",
       " 'min_samples_split': 2,\n",
       " 'min_samples_leaf': 1,\n",
       " 'max_features': 'sqrt',\n",
       " 'max_depth': 50}"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rscv.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['rscv_rf_lsa_elbow_best_params_linalol.pkl']"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "joblib.dump(rscv, \"rscv_rf_lsa_elbow_linalol.pkl\")\n",
    "joblib.dump(rscv.best_params_, \"rscv_rf_lsa_elbow_best_params_linalol.pkl\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "RF (after Hyperparameter Tuning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/ns/m5pnr0211w91v02hpv22958m0000gn/T/ipykernel_4060/2826620419.py:2: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  rfreg_ht.fit(X_train1, y_train1)\n"
     ]
    }
   ],
   "source": [
    "rfreg_ht = RandomForestRegressor(n_estimators = 300, min_samples_split = 2, max_features = 'sqrt', min_samples_leaf = 1, max_depth = 50)\n",
    "rfreg_ht.fit(X_train1, y_train1)\n",
    "y_pred_rfreg = rfreg_ht.predict(X_val)\n",
    "y_pred_rfreg_r2 = rfreg_ht.predict(X_train1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.03794793669682502"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mean_absolute_error(y_val, y_pred_rfreg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.006339843121408505"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mean_squared_error(y_val, y_pred_rfreg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.07962313182366357"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mean_squared_error(y_val, y_pred_rfreg, squared = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9780800171437942"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#train\n",
    "r2_score(y_train1, y_pred_rfreg_r2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.936661718804427"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#val\n",
    "r2_score(y_val, y_pred_rfreg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Residual plots after Hyperparameter Tuning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Predicting model on the test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_rfreg_test = rfreg_ht.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['y_test_rfreg_lsa_elbow_linalol.pkl']"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "joblib.dump(y_pred_rfreg_test, \"y_pred_rfreg_test_lsa_elbow_linalol.pkl\")\n",
    "joblib.dump(y_test, \"y_test_rfreg_lsa_elbow_linalol.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.037818756337487505"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mean_absolute_error(y_test, y_pred_rfreg_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.006473874546897029"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mean_squared_error(y_test, y_pred_rfreg_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.08046039116793448"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mean_squared_error(y_test, y_pred_rfreg_test, squared = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9356464293636334"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "r2_score(y_test, y_pred_rfreg_test)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Error analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAq0AAAIOCAYAAACS1DTrAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjcuMCwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy88F64QAAAACXBIWXMAAA9hAAAPYQGoP6dpAAAyu0lEQVR4nO3df3zP9f7/8fvbftrYm439svHhRClSKJs+hcyvkkQ4Zx0RiYtKDk61j3MyJ9mJDjqkI0dGiM4PfagOVsmPTGWfVopDQqitMbP5MdvM6/tHZ69vb5sf79ne7+fmdr1c3pe8X6/H6/V8vPa84N7T6/16OyzLsgQAAAAYrI63GwAAAAAuh9AKAAAA4xFaAQAAYDxCKwAAAIxHaAUAAIDxCK0AAAAwHqEVAAAAxiO0AgAAwHiEVgAAABiP0AoA/zFixAgFBARo586d5fb98Y9/lMPh0Nq1a906Z3JyshwOh44dO3bRmo8++kgOh0MfffSRuy27pWvXruratWuNHwPAtYnQCgD/MWfOHEVGRmrYsGEqKSmxt+/cuVNTpkzR8OHDdd9991X5uO3bt1d6errat29f5ecGgNqC0AoA/xESEqJFixYpMzNT06ZNkySVlJRo6NChioiI0Jw5c6pt3Li4OIWEhFTL+QGgNiC0AsDPJCQkaMyYMZo+fboyMjKUnJysL774QosWLZLT6ayWMSu6PWD48OGqV6+e9u3bp3vuuUf16tVTbGysJk6cqKKiIpfjp06dqk6dOik0NFQhISFq3769Fi1aJMuyLjv28ePHNXbsWDVp0kT+/v5q0aKFJk+eXG6Ms2fPKikpSc2bN5e/v7+aNGmixx9/XCdOnKiKHwEAXJavtxsAANPMnDlT69ev14MPPqjDhw9rzJgx6tGjh8f7KCkpUb9+/TRy5EhNnDhRmzdv1vPPPy+n06nnnnvOrjt48KBGjx6tpk2bSpK2b9+uJ598Ut9//71L3YXOnj2rbt266dtvv9XUqVN18803a8uWLUpJSVFmZqbeffddSZJlWerfv78++OADJSUl6c4779SXX36pKVOmKD09Xenp6QoICKjeHwaAax6hFQAuEBwcrGnTpikxMVGRkZGaOXOmV/ooLi7W1KlTNWjQIElS9+7dtWPHDq1YscIljC5evNj+9fnz59W1a1dZlqWXX35Zv//97+VwOCo8/5IlS/Tll1/qrbfessfo0aOH6tWrp2eeeUZpaWnq0aOHNmzYoPXr12vGjBn67W9/a9fFxsZqyJAhWrp0qUaNGlVdPwYAkMTtAQBQzvnz5zV37lzVqVNHOTk5+uKLL7zSh8PhKPfBr5tvvlnfffedy7YPP/xQCQkJcjqd8vHxkZ+fn5577jnl5uYqJyfnouf/8MMPFRwcrAcffNBl+/DhwyVJH3zwgV338+1lBg0apODgYLsOAKoToRUALvDSSy8pPT1dK1asUMuWLTVixAgVFhZ6vI+goCAFBga6bAsICNDZs2ft959++ql69uwpSVq4cKE+/vhjffbZZ5o8ebIkXbLv3NxcRUZGlluJDQ8Pl6+vr3Jzc+06X19fNW7c2KXO4XAoMjLSrgOA6kRoBYCf2bVrl5577jk9/PDDGjJkiFJTU7Vv3z47BJpm5cqV8vPz0zvvvKPBgwerc+fO6tix4xUdGxYWph9//LHcB7ZycnJ07tw5NWrUyK47d+6cjh496lJnWZays7PtOgCoToRWAPiPc+fOadiwYWrUqJFefvllSVJcXJwmTJigl19+WR9//LGXOyzP4XDI19dXPj4+9rbCwkK98cYblz22e/fuOnXqlN5++22X7UuXLrX3//y/y5Ytc6n7xz/+odOnT9v7AaA68UEsAPiPlJQU7dixQ//617/UoEEDe/vzzz+vtWvXasSIEcrMzFTdunV13XXXSZL27dtn140cOVJLlizRt99+q2bNmrmce+3atapfv365MS+8n9Rd9957r2bNmqXExEQ99thjys3N1UsvvXRFn+Z/+OGH9corr2jYsGE6ePCg2rZtq61bt2r69Om65557lJCQIOmnD1316tVLzzzzjAoKCnTHHXfYTw+49dZbNXTo0Ku6BgC4EoRWAJD0xRdf6Pnnn9eoUaPUu3dvl32BgYFKTU3VHXfcocmTJ2vWrFk6d+5cuXOUlpaqtLS0wuejjhgxosJxr+RZqpdy99136/XXX9eLL76o++67T02aNNGoUaMUHh6ukSNHXvLYwMBAbdy4UZMnT9bMmTN19OhRNWnSRJMmTdKUKVPsOofDobffflvJyclavHixXnjhBTVq1EhDhw7V9OnTedwVAI9wWFf7JyYAAABQzbinFQAAAMYjtAIAAMB4hFYAAAAYj9AKAAAA4xFaAQAAYDxCKwAAAIxXa5/Tev78ef3www+qX79+ue/VBgAAgPdZlqWTJ08qOjpadepcei211obWH374QbGxsd5uAwAAAJdx+PBhxcTEXLKm1obWsq9LPHz4sEJCQrzcDQAAAC5UUFCg2NjYCr/m+kK1NrSW3RIQEhJCaAUAADDYldzKyQexAAAAYDxCKwAAAIxHaAUAAIDxau09rQAAAD9XWlqqkpISb7dxTfHz85OPj0+VnIvQCgAAajXLspSdna0TJ054u5VrUoMGDRQZGXnVz80ntAIAgFqtLLCGh4crKCiILx3yEMuydObMGeXk5EiSoqKirup8hFYAAFBrlZaW2oE1LCzM2+1cc+rWrStJysnJUXh4+FXdKsAHsQAAQK1Vdg9rUFCQlzu5dpX97K/2fmJCKwAAqPW4JcB7qupnT2gFAACA8QitAAAAqLThw4erf//+1T4OH8QCAADXpNlpez063m96tPLoeLUNK60AAADXuOLiYm+3cFmEVgAAAMMsXbpUYWFhKioqctk+cOBAPfzww5c8Njk5WbfccosWLFig2NhYBQUFadCgQS5frlD2T/opKSmKjo5Wq1Y/rQJ///33GjJkiBo2bKiwsDDdf//9OnjwoH1caWmpJkyYoAYNGigsLExPP/20LMuqsuu+FEIrAACAYQYNGqTS0lKtWbPG3nbs2DG98847euSRRy57/L59+/TWW29p7dq1WrdunTIzM/X444+71HzwwQfavXu30tLS9M477+jMmTPq1q2b6tWrp82bN2vr1q2qV6+eevfuba/E/ulPf9Lrr7+uRYsWaevWrTp+/LhWr15dtRd/EYRWAAAAw9StW1eJiYlavHixvW358uWKiYlR165dL3v82bNntWTJEt1yyy266667NHfuXK1cuVLZ2dl2TXBwsP7617/qpptuUps2bbRy5UrVqVNHf/3rX9W2bVu1bt1aixcv1qFDh/TRRx9JkubMmaOkpCQNHDhQrVu31l/+8hc5nc6qvvwK8UEsAAAAA40aNUq33Xabvv/+ezVp0kSLFy/W8OHDr+i5p02bNlVMTIz9Pj4+XufPn9eePXsUGRkpSWrbtq38/f3tmoyMDO3bt0/169d3OdfZs2f17bffKj8/X1lZWYqPj7f3+fr6qmPHjh65RYDQCgAAYKBbb71V7dq109KlS9WrVy/t3LlTa9eurdS5yoLuzwNvcHCwS8358+fVoUMHLV++vNzxjRs3rtS4VYnQCgAAYKhHH31Us2fP1vfff6+EhATFxsZe0XGHDh3SDz/8oOjoaElSenq66tSpY3/gqiLt27fXqlWrFB4erpCQkAproqKitH37dt11112SpHPnzikjI0Pt27d388rcxz2tAAAAhnrooYf0/fdHtHDhQo345QNSQdblX0UnFRgYoGEP/VJffPy+tqx7W+OeGKvBD9ynyCDrp5qSQuncWZfjHrrvbjUKbaj7779fW7Zs0YEDB7Rp0yY99dRTOnLkiCTpqaee0h//+EetXr1a//73vzV27FiXpxJUJ0IrAACAoUJCQjSw372qFxys/n17X/Fx17X4Lw247x7dM2ioej7wK7VpfYPm/ynlkscEBQVp87/+qaZNm2rAgAFq3bq1RowYocLCQnvldeLEiXr44Yc1fPhwxcfHq379+nrggQeu6hqvlMPy1MO1PKygoEBOp1P5+fkXXeIGAAC129mzZ3XgwAE1b95cgYGB3m6nUnp0u0utr2+pP8+YdkX1ySkv6e131ylz6/uVGzAkqnLHXcSl5sCdvMY9rQAAAAY6fvy4NmzYoA83f6x5L73g7Xa8jtAKAABgoPbt2ysvL08vTp2s61teZ2+/qVNXfXf4SIXHLJgzw1PteRyhFQAAwED216cWZLlsf+9vy1RSUlLhMRHhjVW/fj0lJ02q5u48j9AKAABQgzRrGnP5olqIpwcAAADAeIRWAAAAGI/QCgAAAOMRWgEAAGA8QisAAACMR2gFAACA8XjkFQAAuDZtTPHseN2SPDLMVX+Nq6FYaQUAALgGXewLCkxFaAUAADDM0qVLFRYWpqKiIpftA3/9qB4ePe6ix6UuX6Wpf5ylL3buksMZLYczWqnLV0mSHM5o/WXRUt3/q+EKjvqFps2co9Tlq9Sg6Q0u53j77bflcDhctq1du1YdOnRQYGCgWrRooalTp+rcuXNVdLVXhtAKAABgmEGDBqm0tFRr1qyxtx3LzdU769/XIw8NuehxQwb008QnRuum1tcra2+msvZmasiAfvb+KSkv6f57emnntg814te/uqJe1q9fr1//+tcaN26cdu3apQULFig1NVUvvPBC5S+wEgitAAAAhqlbt64SExO1ePFie9vyt1YrJjpKXe/sfMnj6tULlq+vjyIjwhUZEa66deva+xMHPaARQ3+lFs2bXfHXwb7wwgt69tlnNWzYMLVo0UI9evTQ888/rwULFlT+AiuBD2IBAAAYaNSoUbrtttu09+ARRUdFatEbK5U45EGdLi695HHF587r/HnpVFH5f75v06aNy/az585LVsW1ZTIyMvTZZ5+5rKyWlpbq7NmzOnPmjIKCgipxde4jtAIAABjo1ltvVbt27bTirb8roVsXfb3733pr2etXdc4LA2Ydh0OWZblsu/ADWufPn9fUqVM1YMCAcucLDAy8qn7cQWgFAAAw1KOPPqo/vTRTWVk/qttd/62YJtGXPcbP31+l5y+9GlumUaMwnTx1SqdPn1Fw8E+BNjMz06Wmffv22rNnj6677jq3+69K3NMKAABgqIceekhZ2dlKXfamhiYOvqJjmsXG6LvvDuvLnV/rWO7xck8g+LmO7W9VUN26mjr9RX27/6De+sfbSk1Ndal57rnntHTpUiUnJ+vrr7/W7t27tWrVKv3ud7+7mktzG6EVAADAUCEhIbr/3j4KDg5S3z69ruiY+/v2UcLdXXTvgCFq3voW/W31movWhjZsoIXzX9aG9zcqrmsP/W31/yo5OdmlplevXnrnnXeUlpam2267TXFxcZo1a5aaNWt2NZfmNod14Y0MtURBQYGcTqfy8/MVEhLi7XYAAIAXnD17VgcOHFDz5s09ev9lVbq7y526vtV1mjn9Dx4Zr17j2Co936XmwJ28xkorAACAgY4fP66VK1dq09ZtGjVimLfb8To+iAUAAGCg9u3bKy8vT3/4fZJaXfcLe/ttd3bX4cPfV3jMyy+laMiDD3iqRY8itAIAABjo4MGDkqRTRw+7bP/HiiUqKan4uarh4Y2quy2vIbQCAADUIE1jr+ybrGob7mkFAACA8QitAACg1qulD0uqEarqZ09oBQAAtZafn58k6cyZM17u5NpV9rMvm4vK4p5WAABQa/n4+KhBgwbKycmRJAUFBcnhcHi5K/cUXeRDV9XF9+zZKjmPZVk6c+aMcnJy1KBBA/n4+FxdX1XSFQAAgKEiIyMlyQ6uNU3RqTyPjheQXzWhtUyDBg3sObgahFYAAFCrORwORUVFKTw8XCUlJd5ux22f//0tj453w4PPVNm5/Pz8rnqFtQyhFQAAXBN8fHyqLEB5VNFJjw5n6tfd8kEsAAAAGI/QCgAAAOMRWgEAAGA8QisAAACMR2gFAACA8QitAAAAMB6hFQAAAMYjtAIAAMB4hFYAAAAYj9AKAAAA4xFaAQAAYDxCKwAAAIxHaAUAAIDxCK0AAAAwHqEVAAAAxiO0AgAAwHiEVgAAABiP0AoAAADjEVoBAABgPEIrAAAAjEdoBQAAgPEIrQAAADAeoRUAAADGI7QCAADAeIRWAAAAGI/QCgAAAOMRWgEAAGA8QisAAACMR2gFAACA8QitAAAAMJ5boTUlJUW33Xab6tevr/DwcPXv31979uxxqbEsS8nJyYqOjlbdunXVtWtXff311y41RUVFevLJJ9WoUSMFBwerX79+OnLkiEtNXl6ehg4dKqfTKafTqaFDh+rEiROVu0oAAADUaG6F1k2bNunxxx/X9u3blZaWpnPnzqlnz546ffq0XTNjxgzNmjVL8+bN02effabIyEj16NFDJ0+etGvGjx+v1atXa+XKldq6datOnTqlvn37qrS01K5JTExUZmam1q1bp3Xr1ikzM1NDhw6tgksGAABATeOwLMuq7MFHjx5VeHi4Nm3apLvuukuWZSk6Olrjx4/XM888I+mnVdWIiAi9+OKLGj16tPLz89W4cWO98cYbGjJkiCTphx9+UGxsrN577z316tVLu3fv1o033qjt27erU6dOkqTt27crPj5e//73v3X99ddftreCggI5nU7l5+crJCSkspcIAADgVemLJnl0vPiRL3lsLHfy2lXd05qfny9JCg0NlSQdOHBA2dnZ6tmzp10TEBCgLl26aNu2bZKkjIwMlZSUuNRER0erTZs2dk16erqcTqcdWCUpLi5OTqfTrrlQUVGRCgoKXF4AAACoHSodWi3L0oQJE/Tf//3fatOmjSQpOztbkhQREeFSGxERYe/Lzs6Wv7+/GjZseMma8PDwcmOGh4fbNRdKSUmx7391Op2KjY2t7KUBAADAMJUOrU888YS+/PJLvfnmm+X2ORwOl/eWZZXbdqELayqqv9R5kpKSlJ+fb78OHz58JZcBAACAGqBSofXJJ5/UmjVrtHHjRsXExNjbIyMjJancamhOTo69+hoZGani4mLl5eVdsubHH38sN+7Ro0fLreKWCQgIUEhIiMsLAAAAtYNbodWyLD3xxBP65z//qQ8//FDNmzd32d+8eXNFRkYqLS3N3lZcXKxNmzapc+fOkqQOHTrIz8/PpSYrK0tfffWVXRMfH6/8/Hx9+umnds0nn3yi/Px8uwYAAADXDl93ih9//HGtWLFC//u//6v69evbK6pOp1N169aVw+HQ+PHjNX36dLVs2VItW7bU9OnTFRQUpMTERLt25MiRmjhxosLCwhQaGqpJkyapbdu2SkhIkCS1bt1avXv31qhRo7RgwQJJ0mOPPaa+ffte0ZMDAAAAULu4FVpfffVVSVLXrl1dti9evFjDhw+XJD399NMqLCzU2LFjlZeXp06dOmnDhg2qX7++XT979mz5+vpq8ODBKiwsVPfu3ZWamiofHx+7Zvny5Ro3bpz9lIF+/fpp3rx5lblGAAAA1HBX9ZxWk/GcVgAAUBvwnNafXNVzWgEAAABPILQCAADAeIRWAAAAGI/QCgAAAOMRWgEAAGA8QisAAACMR2gFAACA8QitAAAAMB6hFQAAAMYjtAIAAMB4hFYAAAAYj9AKAAAA4xFaAQAAYDxCKwAAAIxHaAUAAIDxCK0AAAAwHqEVAAAAxiO0AgAAwHiEVgAAABiP0AoAAADjEVoBAABgPEIrAAAAjEdoBQAAgPEIrQAAADAeoRUAAADGI7QCAADAeIRWAAAAGI/QCgAAAOMRWgEAAGA8QisAAACMR2gFAACA8QitAAAAMB6hFQAAAMYjtAIAAMB4hFYAAAAYj9AKAAAA4xFaAQAAYDxCKwAAAIxHaAUAAIDxCK0AAAAwHqEVAAAAxiO0AgAAwHiEVgAAABiP0AoAAADjEVoBAABgPEIrAAAAjEdoBQAAgPEIrQAAADAeoRUAAADGI7QCAADAeIRWAAAAGI/QCgAAAOMRWgEAAGA8QisAAACMR2gFAACA8QitAAAAMJ6vtxsAAMCbZqft9eh4v+nRyqPjAbUFK60AAAAwHqEVAAAAxiO0AgAAwHiEVgAAABiP0AoAAADjEVoBAABgPEIrAAAAjEdoBQAAgPEIrQAAADAeoRUAAADGI7QCAADAeIRWAAAAGI/QCgAAAOMRWgEAAGA8QisAAACMR2gFAACA8QitAAAAMJ6vtxsATDI7ba9Hx/tNj1YeHQ8AgJqKlVYAAAAYj5VWAMA1Le7Qax4e8SUPjwfUDqy0AgAAwHiEVgAAABiP0AoAAADjEVoBAABgPLc/iLV582bNnDlTGRkZysrK0urVq9W/f397//Dhw7VkyRKXYzp16qTt27fb74uKijRp0iS9+eabKiwsVPfu3TV//nzFxMTYNXl5eRo3bpzWrFkjSerXr5/mzp2rBg0auNsyYCwesQUAwJVxe6X19OnTateunebNm3fRmt69eysrK8t+vffeey77x48fr9WrV2vlypXaunWrTp06pb59+6q0tNSuSUxMVGZmptatW6d169YpMzNTQ4cOdbddAAAA1AJur7T26dNHffr0uWRNQECAIiMjK9yXn5+vRYsW6Y033lBCQoIkadmyZYqNjdX777+vXr16affu3Vq3bp22b9+uTp06SZIWLlyo+Ph47dmzR9dff727bQMAAKAGq5Z7Wj/66COFh4erVatWGjVqlHJycux9GRkZKikpUc+ePe1t0dHRatOmjbZt2yZJSk9Pl9PptAOrJMXFxcnpdNo1AAAAuHZU+ZcL9OnTR4MGDVKzZs104MAB/f73v9fdd9+tjIwMBQQEKDs7W/7+/mrYsKHLcREREcrOzpYkZWdnKzw8vNy5w8PD7ZoLFRUVqaioyH5fUFBQhVcFAAAAb6ry0DpkyBD7123atFHHjh3VrFkzvfvuuxowYMBFj7MsSw6Hw37/819frObnUlJSNHXq1KvoHAAAAKaq9kdeRUVFqVmzZvrmm28kSZGRkSouLlZeXp5LXU5OjiIiIuyaH3/8sdy5jh49atdcKCkpSfn5+fbr8OHDVXwlAAAA8JYqX2m9UG5urg4fPqyoqChJUocOHeTn56e0tDQNHjxYkpSVlaWvvvpKM2bMkCTFx8crPz9fn376qW6//XZJ0ieffKL8/Hx17ty5wnECAgIUEBBQ3ZcDAEDNsjHFs+N1S/LseLhmuB1aT506pX379tnvDxw4oMzMTIWGhio0NFTJyckaOHCgoqKidPDgQf3P//yPGjVqpAceeECS5HQ6NXLkSE2cOFFhYWEKDQ3VpEmT1LZtW/tpAq1bt1bv3r01atQoLViwQJL02GOPqW/fvjw5AAAA4BrkdmjdsWOHunXrZr+fMGGCJGnYsGF69dVXtXPnTi1dulQnTpxQVFSUunXrplWrVql+/fr2MbNnz5avr68GDx5sf7lAamqqfHx87Jrly5dr3Lhx9lMG+vXrd8lnwwIAAKD2cju0du3aVZZlXXT/+vXrL3uOwMBAzZ07V3Pnzr1oTWhoqJYtW+ZuewAAAKiFqv2DWAAAAMDVqvYPYgEAAO9J35/r0fHiu12+BqgMVloBAABgPEIrAAAAjEdoBQAAgPEIrQAAADAeoRUAAADGI7QCAADAeIRWAAAAGI/QCgAAAOMRWgEAAGA8QisAAACMR2gFAACA8QitAAAAMB6hFQAAAMYjtAIAAMB4hFYAAAAYj9AKAAAA4xFaAQAAYDxCKwAAAIxHaAUAAIDxCK0AAAAwHqEVAAAAxiO0AgAAwHiEVgAAABiP0AoAAADjEVoBAABgPEIrAAAAjEdoBQAAgPEIrQAAADAeoRUAAADGI7QCAADAeIRWAAAAGI/QCgAAAOMRWgEAAGA8QisAAACMR2gFAACA8QitAAAAMB6hFQAAAMYjtAIAAMB4hFYAAAAYj9AKAAAA4xFaAQAAYDxCKwAAAIzn6+0GcJU2pnh2vG5Jnh0PAABArLQCAACgBiC0AgAAwHiEVgAAABiP0AoAAADjEVoBAABgPEIrAAAAjMcjrwDULjwGDgBqJVZaAQAAYDxCKwAAAIxHaAUAAIDxCK0AAAAwHqEVAAAAxiO0AgAAwHiEVgAAABiP0AoAAADjEVoBAABgPEIrAAAAjEdoBQAAgPEIrQAAADAeoRUAAADGI7QCAADAeIRWAAAAGI/QCgAAAOMRWgEAAGA8QisAAACMR2gFAACA8QitAAAAMB6hFQAAAMYjtAIAAMB4hFYAAAAYj9AKAAAA4xFaAQAAYDxCKwAAAIxHaAUAAIDxCK0AAAAwnq+3GwDgObPT9np8zN/0aOXxMQEAtQ8rrQAAADCe2yutmzdv1syZM5WRkaGsrCytXr1a/fv3t/dblqWpU6fqtddeU15enjp16qRXXnlFN910k11TVFSkSZMm6c0331RhYaG6d++u+fPnKyYmxq7Jy8vTuHHjtGbNGklSv379NHfuXDVo0KDyVwug1kvfn+vR8eK7eXQ4ALhmuR1aT58+rXbt2umRRx7RwIEDy+2fMWOGZs2apdTUVLVq1UrTpk1Tjx49tGfPHtWvX1+SNH78eK1du1YrV65UWFiYJk6cqL59+yojI0M+Pj6SpMTERB05ckTr1q2TJD322GMaOnSo1q5dezXXC1xS3KHXPDre9qaPeXQ8AABqKrdDa58+fdSnT58K91mWpTlz5mjy5MkaMGCAJGnJkiWKiIjQihUrNHr0aOXn52vRokV64403lJCQIElatmyZYmNj9f7776tXr17avXu31q1bp+3bt6tTp06SpIULFyo+Pl579uzR9ddfX9nrBQAAQA1Upfe0HjhwQNnZ2erZs6e9LSAgQF26dNG2bdskSRkZGSopKXGpiY6OVps2beya9PR0OZ1OO7BKUlxcnJxOp10DAACAa0eVPj0gOztbkhQREeGyPSIiQt99951d4+/vr4YNG5arKTs+Oztb4eHh5c4fHh5u11yoqKhIRUVF9vuCgoLKXwgAAACMUi1PD3A4HC7vLcsqt+1CF9ZUVH+p86SkpMjpdNqv2NjYSnQOAAAAE1XpSmtkZKSkn1ZKo6Ki7O05OTn26mtkZKSKi4uVl5fnstqak5Ojzp072zU//vhjufMfPXq03CpumaSkJE2YMMF+X1BQQHAFUPtsTPHseN2SPDseAFxEla60Nm/eXJGRkUpLS7O3FRcXa9OmTXYg7dChg/z8/FxqsrKy9NVXX9k18fHxys/P16effmrXfPLJJ8rPz7drLhQQEKCQkBCXFwAAAGoHt1daT506pX379tnvDxw4oMzMTIWGhqpp06YaP368pk+frpYtW6ply5aaPn26goKClJiYKElyOp0aOXKkJk6cqLCwMIWGhmrSpElq27at/TSB1q1bq3fv3ho1apQWLFgg6adHXvXt25cnB6BW4RFbAABcGbdD644dO9St2/9/mnbZP8kPGzZMqampevrpp1VYWKixY8faXy6wYcMG+xmtkjR79mz5+vpq8ODB9pcLpKam2s9olaTly5dr3Lhx9lMG+vXrp3nz5lX6QgEAAFBzuR1au3btKsuyLrrf4XAoOTlZycnJF60JDAzU3LlzNXfu3IvWhIaGatmyZe62BwAAgFqoWp4eAAAAAFQlQisAAACMV6WPvAKq2uy0vR4dL86jowEAgCvFSisAAACMR2gFAACA8QitAAAAMB6hFQAAAMYjtAIAAMB4hFYAAAAYj9AKAAAA4xFaAQAAYDxCKwAAAIxHaAUAAIDxCK0AAAAwHqEVAAAAxiO0AgAAwHiEVgAAABiP0AoAAADj+Xq7AdQwG1M8POBAD48HAABMxEorAAAAjEdoBQAAgPEIrQAAADAeoRUAAADGI7QCAADAeIRWAAAAGI/QCgAAAOMRWgEAAGA8QisAAACMR2gFAACA8QitAAAAMB6hFQAAAMYjtAIAAMB4hFYAAAAYj9AKAAAA4xFaAQAAYDxCKwAAAIxHaAUAAIDxCK0AAAAwHqEVAAAAxiO0AgAAwHiEVgAAABiP0AoAAADjEVoBAABgPEIrAAAAjEdoBQAAgPEIrQAAADAeoRUAAADGI7QCAADAeIRWAAAAGM/X2w0A8Jy4Q695YdSXvDAmAKC2YaUVAAAAxiO0AgAAwHiEVgAAABiP0AoAAADj8UEsAAAAN8xO2+vR8eI8Opq5WGkFAACA8QitAAAAMB6hFQAAAMYjtAIAAMB4fBALAADADd75dkGw0goAAADjEVoBAABgPEIrAAAAjEdoBQAAgPEIrQAAADAeoRUAAADGI7QCAADAeIRWAAAAGI/QCgAAAOMRWgEAAGA8vsYVbknfn+vZAZt6djgAAGAmVloBAABgPEIrAAAAjEdoBQAAgPEIrQAAADAeoRUAAADGI7QCAADAeIRWAAAAGI/QCgAAAOMRWgEAAGA8vhELAHBxG1M8P2a3JM+PCcB4rLQCAADAeFUeWpOTk+VwOFxekZGR9n7LspScnKzo6GjVrVtXXbt21ddff+1yjqKiIj355JNq1KiRgoOD1a9fPx05cqSqWwUAAEANUS0rrTfddJOysrLs186dO+19M2bM0KxZszRv3jx99tlnioyMVI8ePXTy5Em7Zvz48Vq9erVWrlyprVu36tSpU+rbt69KS0uro10AAAAYrlruafX19XVZXS1jWZbmzJmjyZMna8CAAZKkJUuWKCIiQitWrNDo0aOVn5+vRYsW6Y033lBCQoIkadmyZYqNjdX777+vXr16VUfLAFAps9P2enS83/BJBADXqGpZaf3mm28UHR2t5s2b65e//KX2798vSTpw4ICys7PVs2dPuzYgIEBdunTRtm3bJEkZGRkqKSlxqYmOjlabNm3smooUFRWpoKDA5QUAAIDaocpDa6dOnbR06VKtX79eCxcuVHZ2tjp37qzc3FxlZ2dLkiIiIlyOiYiIsPdlZ2fL399fDRs2vGhNRVJSUuR0Ou1XbGxsFV8ZAAAAvKXKQ2ufPn00cOBAtW3bVgkJCXr33Xcl/XQbQBmHw+FyjGVZ5bZd6HI1SUlJys/Pt1+HDx++iqsAAACASar97qjg4GC1bdtW33zzjfr37y/pp9XUqKgouyYnJ8defY2MjFRxcbHy8vJcVltzcnLUuXPni44TEBCggICA6rkIAJXm6Xs+4zw6GgDAU6r9Oa1FRUXavXu3oqKi1Lx5c0VGRiotLc3eX1xcrE2bNtmBtEOHDvLz83OpycrK0ldffXXJ0AoAAIDaq8pXWidNmqT77rtPTZs2VU5OjqZNm6aCggINGzZMDodD48eP1/Tp09WyZUu1bNlS06dPV1BQkBITEyVJTqdTI0eO1MSJExUWFqbQ0FBNmjTJvt0AAAAA154qD61HjhzRr371Kx07dkyNGzdWXFyctm/frmbNmkmSnn76aRUWFmrs2LHKy8tTp06dtGHDBtWvX98+x+zZs+Xr66vBgwersLBQ3bt3V2pqqnx8fKq6XRgu7tBr3m4BMEr6/lyPjhffIsyj4wHAxVR5aF25cuUl9zscDiUnJys5OfmiNYGBgZo7d67mzp1bxd0BAACgJqr2e1oBAACAq0VoBQAAgPEIrQAAADAeoRUAAADGI7QCAADAeIRWAAAAGI/QCgAAAOMRWgEAAGA8QisAAACMR2gFAACA8QitAAAAMB6hFQAAAMbz9XYDAABzpe/P9fiY8d08PiSAGoCVVgAAABiPldaqtDHF2x0AAADUSqy0AgAAwHiEVgAAABiP0AoAAADjEVoBAABgPEIrAAAAjEdoBQAAgPEIrQAAADAeoRUAAADGI7QCAADAeIRWAAAAGI/QCgAAAOMRWgEAAGA8X283AKB2izv0mrdbAADUAqy0AgAAwHiEVgAAABiP0AoAAADjEVoBAABgPEIrAAAAjEdoBQAAgPEIrQAAADAeoRUAAADGI7QCAADAeIRWAAAAGI/QCgAAAOMRWgEAAGA8X283gKuTvj/X2y0AAABUO1ZaAQAAYDxCKwAAAIzH7QEAcBXiDr3m7RYA4JrASisAAACMR2gFAACA8QitAAAAMB6hFQAAAMYjtAIAAMB4hFYAAAAYj9AKAAAA4xFaAQAAYDxCKwAAAIxHaAUAAIDxCK0AAAAwHqEVAAAAxiO0AgAAwHiEVgAAABiP0AoAAADjEVoBAABgPEIrAAAAjEdoBQAAgPEIrQAAADAeoRUAAADGI7QCAADAeIRWAAAAGI/QCgAAAOMRWgEAAGA8QisAAACMR2gFAACA8QitAAAAMB6hFQAAAMYjtAIAAMB4hFYAAAAYj9AKAAAA4xFaAQAAYDxfbzdQm6Tvz/V2CwAAALUSK60AAAAwHqEVAAAAxiO0AgAAwHiEVgAAABiPD2IBAIAaa3baXo+PGefxESHVgJXW+fPnq3nz5goMDFSHDh20ZcsWb7cEAAAADzM6tK5atUrjx4/X5MmT9fnnn+vOO+9Unz59dOjQIW+3BgAAAA8y+vaAWbNmaeTIkXr00UclSXPmzNH69ev16quvKiUlxcvdAQDgPk//czb/lI3awtjQWlxcrIyMDD377LMu23v27Klt27aVqy8qKlJRUZH9Pj8/X5JUUFBQvY3+zOnCossXAQAuKeXt//PoeLd5+M/us6dPeXQ8T//d5Mm/dyXP/zyl2v/3vSfnsGwsy7IuW2tsaD127JhKS0sVERHhsj0iIkLZ2dnl6lNSUjR16tRy22NjY6utRwBAdZjn7QaqWS2/vidr+fVdC7wwhydPnpTT6bxkjbGhtYzD4XB5b1lWuW2SlJSUpAkTJtjvz58/r+PHjyssLKzC+qpWUFCg2NhYHT58WCEhIdU+Hqoec1jzMYc1H3NYszF/NZ+n59CyLJ08eVLR0dGXrTU2tDZq1Eg+Pj7lVlVzcnLKrb5KUkBAgAICAly2NWjQoDpbrFBISAi/UWs45rDmYw5rPuawZmP+aj5PzuHlVljLGPv0AH9/f3Xo0EFpaWku29PS0tS5c2cvdQUAAABvMHalVZImTJigoUOHqmPHjoqPj9drr72mQ4cOacyYMd5uDQAAAB5kdGgdMmSIcnNz9Yc//EFZWVlq06aN3nvvPTVr1szbrZUTEBCgKVOmlLtFATUHc1jzMYc1H3NYszF/NZ/Jc+iwruQZAwAAAIAXGXtPKwAAAFCG0AoAAADjEVoBAABgPEIrAAAAjEdodcP8+fPVvHlzBQYGqkOHDtqyZcsl6zdt2qQOHTooMDBQLVq00F/+8hcPdYqLcWcO//nPf6pHjx5q3LixQkJCFB8fr/Xr13uwW1TE3d+HZT7++GP5+vrqlltuqd4GcUnuzl9RUZEmT56sZs2aKSAgQL/4xS/0+uuve6hbVMTdOVy+fLnatWunoKAgRUVF6ZFHHlFubq6HusWFNm/erPvuu0/R0dFyOBx6++23L3uMMXnGwhVZuXKl5efnZy1cuNDatWuX9dRTT1nBwcHWd999V2H9/v37raCgIOupp56ydu3aZS1cuNDy8/Oz/v73v3u4c5Rxdw6feuop68UXX7Q+/fRTa+/evVZSUpLl5+dn/d///Z+HO0cZd+ewzIkTJ6wWLVpYPXv2tNq1a+eZZlFOZeavX79+VqdOnay0tDTrwIED1ieffGJ9/PHHHuwaP+fuHG7ZssWqU6eO9fLLL1v79++3tmzZYt10001W//79Pdw5yrz33nvW5MmTrX/84x+WJGv16tWXrDcpzxBar9Dtt99ujRkzxmXbDTfcYD377LMV1j/99NPWDTfc4LJt9OjRVlxcXLX1iEtzdw4rcuONN1pTp06t6tZwhSo7h0OGDLF+97vfWVOmTCG0epG78/evf/3LcjqdVm5urifawxVwdw5nzpxptWjRwmXbn//8ZysmJqbaesSVu5LQalKe4faAK1BcXKyMjAz17NnTZXvPnj21bdu2Co9JT08vV9+rVy/t2LFDJSUl1dYrKlaZObzQ+fPndfLkSYWGhlZHi7iMys7h4sWL9e2332rKlCnV3SIuoTLzt2bNGnXs2FEzZsxQkyZN1KpVK02aNEmFhYWeaBkXqMwcdu7cWUeOHNF7770ny7L0448/6u9//7vuvfdeT7SMKmBSnjH6G7FMcezYMZWWlioiIsJle0REhLKzsys8Jjs7u8L6c+fO6dixY4qKiqq2flFeZebwQn/60590+vRpDR48uDpaxGVUZg6/+eYbPfvss9qyZYt8ffnjzpsqM3/79+/X1q1bFRgYqNWrV+vYsWMaO3asjh8/zn2tXlCZOezcubOWL1+uIUOG6OzZszp37pz69eunuXPneqJlVAGT8gwrrW5wOBwu7y3LKrftcvUVbYfnuDuHZd58800lJydr1apVCg8Pr672cAWudA5LS0uVmJioqVOnqlWrVp5qD5fhzu/B8+fPy+FwaPny5br99tt1zz33aNasWUpNTWW11YvcmcNdu3Zp3Lhxeu6555SRkaF169bpwIEDGjNmjCdaRRUxJc+w9HAFGjVqJB8fn3L/J5mTk1Pu/z7KREZGVljv6+ursLCwausVFavMHJZZtWqVRo4cqb/97W9KSEiozjZxCe7O4cmTJ7Vjxw59/vnneuKJJyT9FIIsy5Kvr682bNigu+++2yO9o3K/B6OiotSkSRM5nU57W+vWrWVZlo4cOaKWLVtWa89wVZk5TElJ0R133KHf/va3kqSbb75ZwcHBuvPOOzVt2jT+1bEGMCnPsNJ6Bfz9/dWhQwelpaW5bE9LS1Pnzp0rPCY+Pr5c/YYNG9SxY0f5+flVW6+oWGXmUPpphXX48OFasWIF92B5mbtzGBISop07dyozM9N+jRkzRtdff70yMzPVqVMnT7UOVe734B133KEffvhBp06dsrft3btXderUUUxMTLX2i/IqM4dnzpxRnTquUcPHx0fS/1+tg9mMyjMe/+hXDVX2mI9FixZZu3btssaPH28FBwdbBw8etCzLsp599llr6NChdn3ZIyJ+85vfWLt27bIWLVrEI6+8zN05XLFiheXr62u98sorVlZWlv06ceKEty7hmufuHF6Ipwd4l7vzd/LkSSsmJsZ68MEHra+//tratGmT1bJlS+vRRx/11iVc89ydw8WLF1u+vr7W/PnzrW+//dbaunWr1bFjR+v222/31iVc806ePGl9/vnn1ueff25JsmbNmmV9/vnn9mPLTM4zhFY3vPLKK1azZs0sf39/q3379tamTZvsfcOGDbO6dOniUv/RRx9Zt956q+Xv72/913/9l/Xqq696uGNcyJ057NKliyWp3GvYsGGebxw2d38f/hyh1fvcnb/du3dbCQkJVt26da2YmBhrwoQJ1pkzZzzcNX7O3Tn885//bN14441W3bp1raioKOuhhx6yjhw54uGuUWbjxo2X/LvN5DzjsCzW5wEAAGA27mkFAACA8QitAAAAMB6hFQAAAMYjtAIAAMB4hFYAAAAYj9AKAAAA4xFaAQAAYDxCKwAAAIxHaAUAAIDxCK0AAAAwHqEVAAAAxiO0AgAAwHj/D/Q05RxjRkMTAAAAAElFTkSuQmCC",
      "text/plain": [
       "<Figure size 800x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# assume y_pred is a numpy array and y_true is a pandas dataframe\n",
    "fig, ax = plt.subplots(figsize=(8, 6))\n",
    "\n",
    "column = \"X..Linalool\"  # specify the target variable name\n",
    "ax.hist(y_pred_rfreg_test, alpha=0.5, label='y_pred', bins=20)\n",
    "ax.hist(y_test[column], alpha=0.5, label='y_true', bins=20)\n",
    "ax.legend(loc='upper right')\n",
    "ax.set_title(column)\n",
    "\n",
    "plt.show()\n",
    "plt.savefig('error_hist_rf_lsa_elbow_linalol.png')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pearson R"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pearson correlation coefficient: 0.969\n",
      "P-value: 0.000\n"
     ]
    }
   ],
   "source": [
    "corr_coef, p_value = pearsonr(y_pred_rfreg_test.flatten(), y_test.values.ravel())\n",
    "\n",
    "print(f\"Pearson correlation coefficient: {corr_coef:.3f}\")\n",
    "print(f\"P-value: {p_value:.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Axes: >"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "corr_matrix = y_test.corr()\n",
    "sns.heatmap(corr_matrix, annot=True, cmap='coolwarm', center=0)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
