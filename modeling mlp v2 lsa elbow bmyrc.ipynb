{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn import preprocessing\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.neural_network import MLPRegressor\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "from sklearn.metrics import r2_score\n",
    "from scipy.stats import pearsonr\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.feature_selection import SelectFromModel\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compiling complete dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_mlp = pd.read_csv(\"df_bmyrc_lsa.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>lsa_0</th>\n",
       "      <th>lsa_1</th>\n",
       "      <th>lsa_2</th>\n",
       "      <th>lsa_3</th>\n",
       "      <th>lsa_4</th>\n",
       "      <th>hybrid</th>\n",
       "      <th>indica</th>\n",
       "      <th>sativa</th>\n",
       "      <th>anxiety</th>\n",
       "      <th>...</th>\n",
       "      <th>sweet</th>\n",
       "      <th>tar</th>\n",
       "      <th>tea</th>\n",
       "      <th>tobacco</th>\n",
       "      <th>tree</th>\n",
       "      <th>tropical</th>\n",
       "      <th>vanilla</th>\n",
       "      <th>violet</th>\n",
       "      <th>woody</th>\n",
       "      <th>X..Beta-Myrcene</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0.232158</td>\n",
       "      <td>-0.045496</td>\n",
       "      <td>0.187131</td>\n",
       "      <td>-0.000936</td>\n",
       "      <td>0.018518</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.484375</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0.232158</td>\n",
       "      <td>-0.045496</td>\n",
       "      <td>0.187131</td>\n",
       "      <td>-0.000936</td>\n",
       "      <td>0.018518</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.484375</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>0.243491</td>\n",
       "      <td>0.034313</td>\n",
       "      <td>0.080290</td>\n",
       "      <td>-0.165609</td>\n",
       "      <td>0.019773</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.484375</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>0.243491</td>\n",
       "      <td>0.034313</td>\n",
       "      <td>0.080290</td>\n",
       "      <td>-0.165609</td>\n",
       "      <td>0.019773</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.484375</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>0.356758</td>\n",
       "      <td>-0.100188</td>\n",
       "      <td>-0.099331</td>\n",
       "      <td>-0.001421</td>\n",
       "      <td>0.006253</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.484375</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>74995</th>\n",
       "      <td>42973</td>\n",
       "      <td>0.055494</td>\n",
       "      <td>0.003622</td>\n",
       "      <td>-0.050252</td>\n",
       "      <td>-0.024795</td>\n",
       "      <td>-0.031141</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.273438</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>74996</th>\n",
       "      <td>42974</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.273438</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>74997</th>\n",
       "      <td>42975</td>\n",
       "      <td>0.324915</td>\n",
       "      <td>0.131823</td>\n",
       "      <td>-0.099424</td>\n",
       "      <td>0.065491</td>\n",
       "      <td>0.038437</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.273438</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>74998</th>\n",
       "      <td>42975</td>\n",
       "      <td>0.324915</td>\n",
       "      <td>0.131823</td>\n",
       "      <td>-0.099424</td>\n",
       "      <td>0.065491</td>\n",
       "      <td>0.038437</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.273438</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>74999</th>\n",
       "      <td>42976</td>\n",
       "      <td>0.270141</td>\n",
       "      <td>-0.004631</td>\n",
       "      <td>-0.151272</td>\n",
       "      <td>0.035538</td>\n",
       "      <td>0.083641</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.273438</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>75000 rows × 88 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       index     lsa_0     lsa_1     lsa_2     lsa_3     lsa_4  hybrid  \\\n",
       "0          1  0.232158 -0.045496  0.187131 -0.000936  0.018518       1   \n",
       "1          1  0.232158 -0.045496  0.187131 -0.000936  0.018518       1   \n",
       "2          3  0.243491  0.034313  0.080290 -0.165609  0.019773       1   \n",
       "3          3  0.243491  0.034313  0.080290 -0.165609  0.019773       1   \n",
       "4          5  0.356758 -0.100188 -0.099331 -0.001421  0.006253       1   \n",
       "...      ...       ...       ...       ...       ...       ...     ...   \n",
       "74995  42973  0.055494  0.003622 -0.050252 -0.024795 -0.031141       0   \n",
       "74996  42974  0.000000  0.000000  0.000000  0.000000  0.000000       0   \n",
       "74997  42975  0.324915  0.131823 -0.099424  0.065491  0.038437       0   \n",
       "74998  42975  0.324915  0.131823 -0.099424  0.065491  0.038437       0   \n",
       "74999  42976  0.270141 -0.004631 -0.151272  0.035538  0.083641       0   \n",
       "\n",
       "       indica  sativa  anxiety  ...  sweet  tar  tea  tobacco  tree  tropical  \\\n",
       "0           0       0        0  ...      0    0    0        0     0         0   \n",
       "1           0       0        0  ...      0    0    0        0     0         0   \n",
       "2           0       0        0  ...      0    1    0        0     0         0   \n",
       "3           0       0        0  ...      0    1    0        0     0         0   \n",
       "4           0       0        0  ...      0    0    0        0     0         0   \n",
       "...       ...     ...      ...  ...    ...  ...  ...      ...   ...       ...   \n",
       "74995       1       0        0  ...      0    0    0        0     0         0   \n",
       "74996       1       0        0  ...      0    0    0        0     0         0   \n",
       "74997       1       0        0  ...      0    0    0        0     0         0   \n",
       "74998       1       0        0  ...      0    0    0        0     0         0   \n",
       "74999       1       0        0  ...      1    1    1        1     1         1   \n",
       "\n",
       "       vanilla  violet  woody  X..Beta-Myrcene  \n",
       "0            1       0      0         0.484375  \n",
       "1            1       0      0         0.484375  \n",
       "2            0       0      0         0.484375  \n",
       "3            0       0      0         0.484375  \n",
       "4            1       0      0         0.484375  \n",
       "...        ...     ...    ...              ...  \n",
       "74995        0       0      0         0.273438  \n",
       "74996        0       0      0         0.273438  \n",
       "74997        0       0      0         0.273438  \n",
       "74998        0       0      0         0.273438  \n",
       "74999        1       1      1         0.273438  \n",
       "\n",
       "[75000 rows x 88 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_mlp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['index',\n",
       " 'lsa_0',\n",
       " 'lsa_1',\n",
       " 'lsa_2',\n",
       " 'lsa_3',\n",
       " 'lsa_4',\n",
       " 'hybrid',\n",
       " 'indica',\n",
       " 'sativa',\n",
       " 'anxiety',\n",
       " 'anxious',\n",
       " 'aroused',\n",
       " 'arthritis',\n",
       " 'creative',\n",
       " 'depression',\n",
       " 'dizzy',\n",
       " 'dry eyes',\n",
       " 'dry mouth',\n",
       " 'energetic',\n",
       " 'epilepsy',\n",
       " 'euphoric',\n",
       " 'eye pressure',\n",
       " 'fatigue',\n",
       " 'focused',\n",
       " 'giggly',\n",
       " 'happy',\n",
       " 'headache',\n",
       " 'hungry',\n",
       " 'migraines',\n",
       " 'pain',\n",
       " 'paranoid',\n",
       " 'relaxed',\n",
       " 'seizures',\n",
       " 'sleepy',\n",
       " 'spasticity',\n",
       " 'stress',\n",
       " 'talkative',\n",
       " 'tingly',\n",
       " 'uplifted',\n",
       " 'ammonia',\n",
       " 'apple',\n",
       " 'apricot',\n",
       " 'berry',\n",
       " 'blue cheese',\n",
       " 'blueberry',\n",
       " 'butter',\n",
       " 'cheese',\n",
       " 'chemical',\n",
       " 'chestnut',\n",
       " 'citrus',\n",
       " 'coffee',\n",
       " 'diesel',\n",
       " 'earthy',\n",
       " 'flowery',\n",
       " 'fruit',\n",
       " 'grape',\n",
       " 'grapefruit',\n",
       " 'honey',\n",
       " 'lavender',\n",
       " 'lemon',\n",
       " 'lime',\n",
       " 'mango',\n",
       " 'menthol',\n",
       " 'mint',\n",
       " 'nutty',\n",
       " 'orange',\n",
       " 'peach',\n",
       " 'pear',\n",
       " 'pepper',\n",
       " 'pine',\n",
       " 'pineapple',\n",
       " 'plum',\n",
       " 'pungent',\n",
       " 'rose',\n",
       " 'sage',\n",
       " 'skunk',\n",
       " 'spicy/herbal',\n",
       " 'strawberry',\n",
       " 'sweet',\n",
       " 'tar',\n",
       " 'tea',\n",
       " 'tobacco',\n",
       " 'tree',\n",
       " 'tropical',\n",
       " 'vanilla',\n",
       " 'violet',\n",
       " 'woody',\n",
       " 'X..Beta-Myrcene']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_mlp.columns.to_list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df_mlp.drop(['index', 'X..Beta-Myrcene'], axis = 1)\n",
    "y = df_mlp[['X..Beta-Myrcene']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:ylabel='Count'>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "sns.histplot(y, bins = 10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train test split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=1, test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train1, X_val, y_train1, y_val = train_test_split(X_train, y_train, random_state=1, test_size=0.25)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "MLP modeling (before Feature selection and Hyperparameter Tuning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/andalanputra/opt/anaconda3/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:1623: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    }
   ],
   "source": [
    "mlpreg = MLPRegressor(random_state=1, early_stopping=True)\n",
    "mlpreg.fit(X_train1, y_train1)\n",
    "y_pred_mlp = mlpreg.predict(X_val)\n",
    "y_pred_mlp_r2 = mlpreg.predict(X_train1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.1538556893813141"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mean_absolute_error(y_val, y_pred_mlp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6266982856499197"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#train\n",
    "r2_score(y_train1, y_pred_mlp_r2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5038038062929986"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#val\n",
    "r2_score(y_val, y_pred_mlp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Residual plots for each target variable"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Feature Selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "rfreg = RandomForestRegressor()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/andalanputra/opt/anaconda3/lib/python3.9/site-packages/sklearn/feature_selection/_from_model.py:357: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  self.estimator_.fit(X, y, **fit_params)\n"
     ]
    }
   ],
   "source": [
    "selector = SelectFromModel(rfreg).fit(X_train1, y_train1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1.21901247e-01, 1.26868272e-01, 1.17362348e-01, 1.10383286e-01,\n",
       "       1.15230347e-01, 1.26119750e-03, 1.36638284e-02, 3.15645960e-02,\n",
       "       7.04119848e-05, 2.46332260e-03, 5.23505421e-03, 4.10675195e-07,\n",
       "       1.10043111e-02, 8.57297092e-05, 4.09637644e-03, 6.74533177e-03,\n",
       "       9.10057157e-03, 8.11609683e-03, 7.82600865e-07, 1.10498198e-02,\n",
       "       0.00000000e+00, 1.20035568e-06, 9.35562852e-03, 6.84770303e-03,\n",
       "       1.33605334e-02, 3.39462571e-03, 9.27922345e-03, 8.30618980e-05,\n",
       "       5.43899376e-08, 3.03378706e-03, 1.42818656e-02, 1.09655727e-07,\n",
       "       1.32769320e-02, 0.00000000e+00, 0.00000000e+00, 8.95880934e-03,\n",
       "       8.32348983e-03, 9.27921695e-03, 7.05089159e-04, 8.18457508e-04,\n",
       "       1.07826823e-04, 7.32033037e-03, 3.39950360e-04, 1.52505407e-02,\n",
       "       5.81447800e-04, 9.71834541e-03, 2.23228947e-03, 4.51147200e-04,\n",
       "       7.73391263e-03, 3.68163016e-03, 1.60650738e-02, 1.15314962e-02,\n",
       "       4.53681801e-03, 4.53940907e-03, 4.49178094e-03, 5.32109809e-04,\n",
       "       2.24203128e-03, 9.07525344e-04, 1.06327239e-02, 1.14450118e-03,\n",
       "       1.02626650e-03, 3.98397335e-04, 1.86543779e-02, 1.08822382e-03,\n",
       "       8.91508913e-03, 1.22029252e-04, 5.14814124e-05, 6.16526788e-04,\n",
       "       5.17115723e-03, 3.03115527e-04, 5.97530080e-04, 4.89204626e-03,\n",
       "       6.30203289e-04, 1.03810677e-02, 4.84488614e-03, 5.05503273e-03,\n",
       "       9.02915042e-04, 1.45283527e-02, 7.06388024e-04, 3.25858791e-03,\n",
       "       1.49187279e-03, 3.81763581e-03, 2.60401884e-03, 2.18305913e-03,\n",
       "       7.64983050e-04, 5.75073522e-03])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "selector.estimator_.feature_importances_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.011627906976744186"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "selector.threshold_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "mask = selector.get_support()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ True,  True,  True,  True,  True, False,  True,  True, False,\n",
       "       False, False, False, False, False, False, False, False, False,\n",
       "       False, False, False, False, False, False,  True, False, False,\n",
       "       False, False, False,  True, False,  True, False, False, False,\n",
       "       False, False, False, False, False, False, False,  True, False,\n",
       "       False, False, False, False, False,  True, False, False, False,\n",
       "       False, False, False, False, False, False, False, False,  True,\n",
       "       False, False, False, False, False, False, False, False, False,\n",
       "       False, False, False, False, False,  True, False, False, False,\n",
       "       False, False, False, False, False])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "selected_features = X.columns[mask]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>lsa_0</th>\n",
       "      <th>lsa_1</th>\n",
       "      <th>lsa_2</th>\n",
       "      <th>lsa_3</th>\n",
       "      <th>lsa_4</th>\n",
       "      <th>indica</th>\n",
       "      <th>sativa</th>\n",
       "      <th>happy</th>\n",
       "      <th>relaxed</th>\n",
       "      <th>sleepy</th>\n",
       "      <th>blueberry</th>\n",
       "      <th>diesel</th>\n",
       "      <th>mint</th>\n",
       "      <th>sweet</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.232158</td>\n",
       "      <td>-0.045496</td>\n",
       "      <td>0.187131</td>\n",
       "      <td>-0.000936</td>\n",
       "      <td>0.018518</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.232158</td>\n",
       "      <td>-0.045496</td>\n",
       "      <td>0.187131</td>\n",
       "      <td>-0.000936</td>\n",
       "      <td>0.018518</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.243491</td>\n",
       "      <td>0.034313</td>\n",
       "      <td>0.080290</td>\n",
       "      <td>-0.165609</td>\n",
       "      <td>0.019773</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.243491</td>\n",
       "      <td>0.034313</td>\n",
       "      <td>0.080290</td>\n",
       "      <td>-0.165609</td>\n",
       "      <td>0.019773</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.356758</td>\n",
       "      <td>-0.100188</td>\n",
       "      <td>-0.099331</td>\n",
       "      <td>-0.001421</td>\n",
       "      <td>0.006253</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>74995</th>\n",
       "      <td>0.055494</td>\n",
       "      <td>0.003622</td>\n",
       "      <td>-0.050252</td>\n",
       "      <td>-0.024795</td>\n",
       "      <td>-0.031141</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>74996</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>74997</th>\n",
       "      <td>0.324915</td>\n",
       "      <td>0.131823</td>\n",
       "      <td>-0.099424</td>\n",
       "      <td>0.065491</td>\n",
       "      <td>0.038437</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>74998</th>\n",
       "      <td>0.324915</td>\n",
       "      <td>0.131823</td>\n",
       "      <td>-0.099424</td>\n",
       "      <td>0.065491</td>\n",
       "      <td>0.038437</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>74999</th>\n",
       "      <td>0.270141</td>\n",
       "      <td>-0.004631</td>\n",
       "      <td>-0.151272</td>\n",
       "      <td>0.035538</td>\n",
       "      <td>0.083641</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>75000 rows × 14 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          lsa_0     lsa_1     lsa_2     lsa_3     lsa_4  indica  sativa  \\\n",
       "0      0.232158 -0.045496  0.187131 -0.000936  0.018518       0       0   \n",
       "1      0.232158 -0.045496  0.187131 -0.000936  0.018518       0       0   \n",
       "2      0.243491  0.034313  0.080290 -0.165609  0.019773       0       0   \n",
       "3      0.243491  0.034313  0.080290 -0.165609  0.019773       0       0   \n",
       "4      0.356758 -0.100188 -0.099331 -0.001421  0.006253       0       0   \n",
       "...         ...       ...       ...       ...       ...     ...     ...   \n",
       "74995  0.055494  0.003622 -0.050252 -0.024795 -0.031141       1       0   \n",
       "74996  0.000000  0.000000  0.000000  0.000000  0.000000       1       0   \n",
       "74997  0.324915  0.131823 -0.099424  0.065491  0.038437       1       0   \n",
       "74998  0.324915  0.131823 -0.099424  0.065491  0.038437       1       0   \n",
       "74999  0.270141 -0.004631 -0.151272  0.035538  0.083641       1       0   \n",
       "\n",
       "       happy  relaxed  sleepy  blueberry  diesel  mint  sweet  \n",
       "0          1        1       0          0       0     0      0  \n",
       "1          1        1       0          0       0     0      0  \n",
       "2          0        1       0          0       0     0      0  \n",
       "3          0        1       0          0       0     0      0  \n",
       "4          0        1       0          0       0     0      0  \n",
       "...      ...      ...     ...        ...     ...   ...    ...  \n",
       "74995      0        0       0          0       0     0      0  \n",
       "74996      0        0       0          0       0     0      0  \n",
       "74997      1        1       1          0       0     0      0  \n",
       "74998      1        1       1          0       0     0      0  \n",
       "74999      1        1       1          1       1     1      1  \n",
       "\n",
       "[75000 rows x 14 columns]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "selected_X = df_mlp[selected_features]\n",
    "selected_X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['lsa_0',\n",
       " 'lsa_1',\n",
       " 'lsa_2',\n",
       " 'lsa_3',\n",
       " 'lsa_4',\n",
       " 'indica',\n",
       " 'sativa',\n",
       " 'happy',\n",
       " 'relaxed',\n",
       " 'sleepy',\n",
       " 'blueberry',\n",
       " 'diesel',\n",
       " 'mint',\n",
       " 'sweet']"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "selected_X.columns.to_list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['selected_X_mlp_lsa_elbow_bmyrc.pkl']"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import joblib\n",
    "\n",
    "joblib.dump(selector, \"selector_mlp_lsa_elbow_bmyrc.pkl\")\n",
    "joblib.dump(selected_X, \"selected_X_mlp_lsa_elbow_bmyrc.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import joblib\n",
    "\n",
    "# selected_X = joblib.load(\"selected_X_mlp_lsa_elbow_bmyrc.pkl\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train test split (after Feature Selection)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(selected_X, y, random_state=1, test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train1, X_val, y_train1, y_val = train_test_split(X_train, y_train, random_state=1, test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/andalanputra/opt/anaconda3/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:1623: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    }
   ],
   "source": [
    "mlpreg.fit(X_train1, y_train1)\n",
    "y_pred_mlpreg = mlpreg.predict(X_val)\n",
    "y_pred_mlpreg_r2 = mlpreg.predict(X_train1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.21448797934790015"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mean_absolute_error(y_val, y_pred_mlpreg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.2696150097623028"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#train\n",
    "r2_score(y_train1, y_pred_mlpreg_r2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.24229301402919678"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#val\n",
    "r2_score(y_val, y_pred_mlpreg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hyperparameter Tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "parameters = {'hidden_layer_sizes': [(100,), (50, 50, 50), (50, 100, 50)],\n",
    "              'activation': ['tanh', 'relu'], #only tanh and relu\n",
    "              'max_iter': [200, 500, 1000]\n",
    "              }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "rscv = RandomizedSearchCV(mlpreg,  \n",
    "                     parameters,   \n",
    "                     cv=5, \n",
    "                     scoring='neg_mean_absolute_error',\n",
    "                     n_jobs=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/andalanputra/opt/anaconda3/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:1623: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/Users/andalanputra/opt/anaconda3/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:1623: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/Users/andalanputra/opt/anaconda3/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:1623: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/Users/andalanputra/opt/anaconda3/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:1623: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/Users/andalanputra/opt/anaconda3/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:1623: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/Users/andalanputra/opt/anaconda3/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:1623: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/Users/andalanputra/opt/anaconda3/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:1623: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/Users/andalanputra/opt/anaconda3/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:1623: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/Users/andalanputra/opt/anaconda3/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:1623: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/Users/andalanputra/opt/anaconda3/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:1623: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/Users/andalanputra/opt/anaconda3/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:1623: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/Users/andalanputra/opt/anaconda3/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/Users/andalanputra/opt/anaconda3/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:1623: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/Users/andalanputra/opt/anaconda3/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/Users/andalanputra/opt/anaconda3/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:1623: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/Users/andalanputra/opt/anaconda3/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:1623: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/Users/andalanputra/opt/anaconda3/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/Users/andalanputra/opt/anaconda3/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:1623: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/Users/andalanputra/opt/anaconda3/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:1623: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/Users/andalanputra/opt/anaconda3/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:1623: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/Users/andalanputra/opt/anaconda3/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:1623: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/Users/andalanputra/opt/anaconda3/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:1623: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/Users/andalanputra/opt/anaconda3/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:1623: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/Users/andalanputra/opt/anaconda3/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:1623: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/Users/andalanputra/opt/anaconda3/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:1623: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/Users/andalanputra/opt/anaconda3/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/Users/andalanputra/opt/anaconda3/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:1623: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/Users/andalanputra/opt/anaconda3/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:1623: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/Users/andalanputra/opt/anaconda3/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:1623: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/Users/andalanputra/opt/anaconda3/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:1623: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/Users/andalanputra/opt/anaconda3/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:1623: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/Users/andalanputra/opt/anaconda3/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:1623: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/Users/andalanputra/opt/anaconda3/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:1623: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/Users/andalanputra/opt/anaconda3/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:1623: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/Users/andalanputra/opt/anaconda3/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:1623: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/Users/andalanputra/opt/anaconda3/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:1623: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/Users/andalanputra/opt/anaconda3/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:1623: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/Users/andalanputra/opt/anaconda3/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:1623: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/Users/andalanputra/opt/anaconda3/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:1623: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/Users/andalanputra/opt/anaconda3/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:1623: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/Users/andalanputra/opt/anaconda3/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:1623: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/Users/andalanputra/opt/anaconda3/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:1623: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/Users/andalanputra/opt/anaconda3/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:1623: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/Users/andalanputra/opt/anaconda3/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:1623: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/Users/andalanputra/opt/anaconda3/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:1623: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/Users/andalanputra/opt/anaconda3/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:1623: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/Users/andalanputra/opt/anaconda3/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:1623: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/Users/andalanputra/opt/anaconda3/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:1623: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/Users/andalanputra/opt/anaconda3/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:1623: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/Users/andalanputra/opt/anaconda3/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:1623: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/Users/andalanputra/opt/anaconda3/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:1623: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/Users/andalanputra/opt/anaconda3/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:1623: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/Users/andalanputra/opt/anaconda3/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:1623: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/Users/andalanputra/opt/anaconda3/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:1623: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/Users/andalanputra/opt/anaconda3/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:1623: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;background-color: white;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>RandomizedSearchCV(cv=5,\n",
       "                   estimator=MLPRegressor(early_stopping=True, random_state=1),\n",
       "                   n_jobs=-1,\n",
       "                   param_distributions={&#x27;activation&#x27;: [&#x27;tanh&#x27;, &#x27;relu&#x27;],\n",
       "                                        &#x27;hidden_layer_sizes&#x27;: [(100,),\n",
       "                                                               (50, 50, 50),\n",
       "                                                               (50, 100, 50)],\n",
       "                                        &#x27;max_iter&#x27;: [200, 500, 1000]},\n",
       "                   scoring=&#x27;neg_mean_absolute_error&#x27;)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" ><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">RandomizedSearchCV</label><div class=\"sk-toggleable__content\"><pre>RandomizedSearchCV(cv=5,\n",
       "                   estimator=MLPRegressor(early_stopping=True, random_state=1),\n",
       "                   n_jobs=-1,\n",
       "                   param_distributions={&#x27;activation&#x27;: [&#x27;tanh&#x27;, &#x27;relu&#x27;],\n",
       "                                        &#x27;hidden_layer_sizes&#x27;: [(100,),\n",
       "                                                               (50, 50, 50),\n",
       "                                                               (50, 100, 50)],\n",
       "                                        &#x27;max_iter&#x27;: [200, 500, 1000]},\n",
       "                   scoring=&#x27;neg_mean_absolute_error&#x27;)</pre></div></div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" ><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">estimator: MLPRegressor</label><div class=\"sk-toggleable__content\"><pre>MLPRegressor(early_stopping=True, random_state=1)</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-3\" type=\"checkbox\" ><label for=\"sk-estimator-id-3\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">MLPRegressor</label><div class=\"sk-toggleable__content\"><pre>MLPRegressor(early_stopping=True, random_state=1)</pre></div></div></div></div></div></div></div></div></div></div>"
      ],
      "text/plain": [
       "RandomizedSearchCV(cv=5,\n",
       "                   estimator=MLPRegressor(early_stopping=True, random_state=1),\n",
       "                   n_jobs=-1,\n",
       "                   param_distributions={'activation': ['tanh', 'relu'],\n",
       "                                        'hidden_layer_sizes': [(100,),\n",
       "                                                               (50, 50, 50),\n",
       "                                                               (50, 100, 50)],\n",
       "                                        'max_iter': [200, 500, 1000]},\n",
       "                   scoring='neg_mean_absolute_error')"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rscv.fit(X_train1, y_train1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'max_iter': 1000, 'hidden_layer_sizes': (50, 100, 50), 'activation': 'tanh'}"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rscv.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['rscv_mlp_lsa_elbow_best_params_bmyrc.pkl']"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "joblib.dump(rscv, \"rscv_mlp_lsa_elbow_bmyrc.pkl\")\n",
    "joblib.dump(rscv.best_params_, \"rscv_mlp_lsa_elbow_best_params_bmyrc.pkl\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "MLP fit (after hyperparameter tuning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/andalanputra/opt/anaconda3/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:1623: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    }
   ],
   "source": [
    "mlpreg_ht = MLPRegressor(random_state=1, max_iter=1000, activation = 'tanh', hidden_layer_sizes= (50,100,50), early_stopping=True)\n",
    "mlpreg_ht.fit(X_train1, y_train1)\n",
    "y_pred_mlp_ht = mlpreg_ht.predict(X_val)\n",
    "y_pred_mlp_r2_ht = mlpreg_ht.predict(X_train1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.1389850169799586"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mean_absolute_error(y_val, y_pred_mlp_ht)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7128359121428495"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#train\n",
    "r2_score(y_train1, y_pred_mlp_r2_ht)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5755530051933617"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#val\n",
    "r2_score(y_val, y_pred_mlp_ht)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Residual plots after Hyperparameter Tuning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Predicting model on the test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_mlpreg_test = mlpreg_ht.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['y_test_mlpreg_lsa_elbow_bmyrc.pkl']"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "joblib.dump(y_pred_mlpreg_test, \"y_pred_mlpreg_test_lsa_elbow_bmyrc.pkl\")\n",
    "joblib.dump(y_test, \"y_test_mlpreg_lsa_elbow_bmyrc.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.13869398452300385"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mean_absolute_error(y_test, y_pred_mlpreg_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.03613945195781789"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mean_squared_error(y_test, y_pred_mlpreg_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.1901037925918836"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mean_squared_error(y_test, y_pred_mlpreg_test, squared = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5745721077260217"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "r2_score(y_test, y_pred_mlpreg_test)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Error analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 576x432 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 432x288 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# assume y_pred is a numpy array and y_true is a pandas dataframe\n",
    "fig, ax = plt.subplots(figsize=(8, 6))\n",
    "\n",
    "column = \"X..Beta-Myrcene\"  # specify the target variable name\n",
    "ax.hist(y_pred_mlpreg_test, alpha=0.5, label='y_pred', bins=20)\n",
    "ax.hist(y_test[column], alpha=0.5, label='y_true', bins=20)\n",
    "ax.legend(loc='upper right')\n",
    "ax.set_title(column)\n",
    "\n",
    "plt.show()\n",
    "plt.savefig('error_hist_mlp_lsa_elbow_bmyrc.png')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pearson R"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pearson correlation coefficient: 0.764\n",
      "P-value: 0.000\n"
     ]
    }
   ],
   "source": [
    "corr_coef, p_value = pearsonr(y_pred_mlpreg_test.flatten(), y_test.values.ravel())\n",
    "\n",
    "print(f\"Pearson correlation coefficient: {corr_coef:.3f}\")\n",
    "print(f\"P-value: {p_value:.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:>"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "corr_matrix = y_test.corr()\n",
    "sns.heatmap(corr_matrix, annot=True, cmap='coolwarm', center=0)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
