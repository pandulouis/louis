{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn import preprocessing\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.neural_network import MLPRegressor\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "from sklearn.metrics import r2_score\n",
    "from scipy.stats import pearsonr\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.feature_selection import SelectFromModel\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compiling complete dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_mlp = pd.read_csv(\"df_geran_lsa.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>lsa_0</th>\n",
       "      <th>lsa_1</th>\n",
       "      <th>lsa_2</th>\n",
       "      <th>lsa_3</th>\n",
       "      <th>lsa_4</th>\n",
       "      <th>hybrid</th>\n",
       "      <th>indica</th>\n",
       "      <th>sativa</th>\n",
       "      <th>anxiety</th>\n",
       "      <th>...</th>\n",
       "      <th>sweet</th>\n",
       "      <th>tar</th>\n",
       "      <th>tea</th>\n",
       "      <th>tobacco</th>\n",
       "      <th>tree</th>\n",
       "      <th>tropical</th>\n",
       "      <th>vanilla</th>\n",
       "      <th>violet</th>\n",
       "      <th>woody</th>\n",
       "      <th>X..Geraniol</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3</td>\n",
       "      <td>0.243491</td>\n",
       "      <td>0.034313</td>\n",
       "      <td>0.080290</td>\n",
       "      <td>-0.165609</td>\n",
       "      <td>0.019773</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4</td>\n",
       "      <td>0.238648</td>\n",
       "      <td>-0.048758</td>\n",
       "      <td>-0.107398</td>\n",
       "      <td>-0.067096</td>\n",
       "      <td>-0.006558</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>11</td>\n",
       "      <td>0.260672</td>\n",
       "      <td>-0.019644</td>\n",
       "      <td>0.215790</td>\n",
       "      <td>-0.106098</td>\n",
       "      <td>0.058930</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>12</td>\n",
       "      <td>0.301049</td>\n",
       "      <td>-0.056156</td>\n",
       "      <td>-0.030174</td>\n",
       "      <td>-0.036708</td>\n",
       "      <td>0.015147</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>21</td>\n",
       "      <td>0.412179</td>\n",
       "      <td>-0.004705</td>\n",
       "      <td>-0.130429</td>\n",
       "      <td>0.000645</td>\n",
       "      <td>-0.119390</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44995</th>\n",
       "      <td>42970</td>\n",
       "      <td>0.440634</td>\n",
       "      <td>-0.078839</td>\n",
       "      <td>0.085152</td>\n",
       "      <td>0.087878</td>\n",
       "      <td>-0.133604</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44996</th>\n",
       "      <td>42972</td>\n",
       "      <td>0.181714</td>\n",
       "      <td>-0.045560</td>\n",
       "      <td>-0.055692</td>\n",
       "      <td>0.015649</td>\n",
       "      <td>-0.045585</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44997</th>\n",
       "      <td>42974</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44998</th>\n",
       "      <td>42975</td>\n",
       "      <td>0.324915</td>\n",
       "      <td>0.131823</td>\n",
       "      <td>-0.099424</td>\n",
       "      <td>0.065491</td>\n",
       "      <td>0.038437</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44999</th>\n",
       "      <td>42976</td>\n",
       "      <td>0.270141</td>\n",
       "      <td>-0.004631</td>\n",
       "      <td>-0.151272</td>\n",
       "      <td>0.035538</td>\n",
       "      <td>0.083641</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>45000 rows × 88 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       index     lsa_0     lsa_1     lsa_2     lsa_3     lsa_4  hybrid  \\\n",
       "0          3  0.243491  0.034313  0.080290 -0.165609  0.019773       1   \n",
       "1          4  0.238648 -0.048758 -0.107398 -0.067096 -0.006558       1   \n",
       "2         11  0.260672 -0.019644  0.215790 -0.106098  0.058930       1   \n",
       "3         12  0.301049 -0.056156 -0.030174 -0.036708  0.015147       1   \n",
       "4         21  0.412179 -0.004705 -0.130429  0.000645 -0.119390       1   \n",
       "...      ...       ...       ...       ...       ...       ...     ...   \n",
       "44995  42970  0.440634 -0.078839  0.085152  0.087878 -0.133604       0   \n",
       "44996  42972  0.181714 -0.045560 -0.055692  0.015649 -0.045585       0   \n",
       "44997  42974  0.000000  0.000000  0.000000  0.000000  0.000000       0   \n",
       "44998  42975  0.324915  0.131823 -0.099424  0.065491  0.038437       0   \n",
       "44999  42976  0.270141 -0.004631 -0.151272  0.035538  0.083641       0   \n",
       "\n",
       "       indica  sativa  anxiety  ...  sweet  tar  tea  tobacco  tree  tropical  \\\n",
       "0           0       0        0  ...      0    1    0        0     0         0   \n",
       "1           0       0        0  ...      0    0    0        0     0         0   \n",
       "2           0       0        0  ...      1    0    0        0     0         0   \n",
       "3           0       0        0  ...      1    0    0        0     0         0   \n",
       "4           0       0        0  ...      0    0    0        0     0         0   \n",
       "...       ...     ...      ...  ...    ...  ...  ...      ...   ...       ...   \n",
       "44995       1       0        0  ...      0    0    0        0     0         0   \n",
       "44996       1       0        0  ...      0    0    0        0     0         0   \n",
       "44997       1       0        0  ...      0    0    0        0     0         0   \n",
       "44998       1       0        0  ...      0    0    0        0     0         0   \n",
       "44999       1       0        0  ...      1    1    1        1     1         1   \n",
       "\n",
       "       vanilla  violet  woody  X..Geraniol  \n",
       "0            0       0      0          0.0  \n",
       "1            0       0      0          0.0  \n",
       "2            0       0      0          0.0  \n",
       "3            1       0      0          0.0  \n",
       "4            0       0      0          0.0  \n",
       "...        ...     ...    ...          ...  \n",
       "44995        0       0      0          0.0  \n",
       "44996        0       0      0          0.0  \n",
       "44997        0       0      0          0.0  \n",
       "44998        0       0      0          0.0  \n",
       "44999        1       1      1          0.0  \n",
       "\n",
       "[45000 rows x 88 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_mlp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['index',\n",
       " 'lsa_0',\n",
       " 'lsa_1',\n",
       " 'lsa_2',\n",
       " 'lsa_3',\n",
       " 'lsa_4',\n",
       " 'hybrid',\n",
       " 'indica',\n",
       " 'sativa',\n",
       " 'anxiety',\n",
       " 'anxious',\n",
       " 'aroused',\n",
       " 'arthritis',\n",
       " 'creative',\n",
       " 'depression',\n",
       " 'dizzy',\n",
       " 'dry eyes',\n",
       " 'dry mouth',\n",
       " 'energetic',\n",
       " 'epilepsy',\n",
       " 'euphoric',\n",
       " 'eye pressure',\n",
       " 'fatigue',\n",
       " 'focused',\n",
       " 'giggly',\n",
       " 'happy',\n",
       " 'headache',\n",
       " 'hungry',\n",
       " 'migraines',\n",
       " 'pain',\n",
       " 'paranoid',\n",
       " 'relaxed',\n",
       " 'seizures',\n",
       " 'sleepy',\n",
       " 'spasticity',\n",
       " 'stress',\n",
       " 'talkative',\n",
       " 'tingly',\n",
       " 'uplifted',\n",
       " 'ammonia',\n",
       " 'apple',\n",
       " 'apricot',\n",
       " 'berry',\n",
       " 'blue cheese',\n",
       " 'blueberry',\n",
       " 'butter',\n",
       " 'cheese',\n",
       " 'chemical',\n",
       " 'chestnut',\n",
       " 'citrus',\n",
       " 'coffee',\n",
       " 'diesel',\n",
       " 'earthy',\n",
       " 'flowery',\n",
       " 'fruit',\n",
       " 'grape',\n",
       " 'grapefruit',\n",
       " 'honey',\n",
       " 'lavender',\n",
       " 'lemon',\n",
       " 'lime',\n",
       " 'mango',\n",
       " 'menthol',\n",
       " 'mint',\n",
       " 'nutty',\n",
       " 'orange',\n",
       " 'peach',\n",
       " 'pear',\n",
       " 'pepper',\n",
       " 'pine',\n",
       " 'pineapple',\n",
       " 'plum',\n",
       " 'pungent',\n",
       " 'rose',\n",
       " 'sage',\n",
       " 'skunk',\n",
       " 'spicy/herbal',\n",
       " 'strawberry',\n",
       " 'sweet',\n",
       " 'tar',\n",
       " 'tea',\n",
       " 'tobacco',\n",
       " 'tree',\n",
       " 'tropical',\n",
       " 'vanilla',\n",
       " 'violet',\n",
       " 'woody',\n",
       " 'X..Geraniol']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_mlp.columns.to_list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df_mlp.drop(['index', 'X..Geraniol'], axis = 1)\n",
    "y = df_mlp[['X..Geraniol']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:ylabel='Count'>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "sns.histplot(y, bins = 10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train test split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=1, test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train1, X_val, y_train1, y_val = train_test_split(X_train, y_train, random_state=1, test_size=0.25)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "MLP modeling (before Feature selection and Hyperparameter Tuning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/andalanputra/opt/anaconda3/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:1623: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    }
   ],
   "source": [
    "mlpreg = MLPRegressor(random_state=1, early_stopping=True)\n",
    "mlpreg.fit(X_train1, y_train1)\n",
    "y_pred_mlp = mlpreg.predict(X_val)\n",
    "y_pred_mlp_r2 = mlpreg.predict(X_train1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.1486339005914757"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mean_absolute_error(y_val, y_pred_mlp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7816938711231604"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#train\n",
    "r2_score(y_train1, y_pred_mlp_r2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7134121462154983"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#val\n",
    "r2_score(y_val, y_pred_mlp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Residual plots for each target variable"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Feature Selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "rfreg = RandomForestRegressor()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/andalanputra/opt/anaconda3/lib/python3.9/site-packages/sklearn/feature_selection/_from_model.py:357: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  self.estimator_.fit(X, y, **fit_params)\n"
     ]
    }
   ],
   "source": [
    "selector = SelectFromModel(rfreg).fit(X_train1, y_train1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1.07124865e-01, 1.06941956e-01, 1.27715687e-01, 9.34299895e-02,\n",
       "       1.04550994e-01, 1.67132660e-01, 2.61811013e-07, 2.09207586e-07,\n",
       "       2.05589674e-04, 2.36721347e-03, 4.22794122e-03, 7.15415347e-20,\n",
       "       8.37080382e-03, 2.05499092e-04, 7.75920735e-03, 5.39613856e-03,\n",
       "       7.67373345e-03, 8.02642377e-03, 1.59669512e-18, 7.25933074e-03,\n",
       "       3.16054311e-19, 7.17007047e-21, 8.64325574e-03, 4.52865235e-03,\n",
       "       6.28595690e-03, 3.11247691e-03, 6.14765729e-03, 2.36782787e-04,\n",
       "       5.50906527e-08, 3.25332220e-03, 9.11198070e-03, 0.00000000e+00,\n",
       "       7.53887789e-03, 0.00000000e+00, 0.00000000e+00, 8.70997265e-03,\n",
       "       4.72861494e-03, 6.29962698e-03, 1.25370535e-04, 1.27872728e-04,\n",
       "       4.25532045e-05, 5.41617738e-03, 1.59700680e-04, 2.91299310e-03,\n",
       "       6.82341587e-04, 6.07674381e-03, 3.90282782e-04, 1.22235459e-05,\n",
       "       1.51874553e-02, 7.46766566e-05, 2.63895755e-02, 5.77491089e-03,\n",
       "       4.09578561e-03, 1.59551284e-03, 3.17250435e-03, 1.40100431e-03,\n",
       "       4.80273340e-04, 8.88956780e-04, 1.20901899e-02, 5.92813114e-04,\n",
       "       4.99261815e-04, 1.80749441e-04, 5.22391118e-03, 1.90284318e-04,\n",
       "       1.64977265e-02, 2.40145549e-04, 5.09725401e-05, 1.16567849e-03,\n",
       "       2.64302876e-03, 4.86475505e-04, 6.54533001e-04, 8.63369488e-03,\n",
       "       3.84941642e-03, 2.19949963e-04, 5.23188309e-03, 8.77843834e-03,\n",
       "       8.61822833e-04, 1.53315448e-02, 1.48031482e-03, 4.48895767e-04,\n",
       "       3.35310000e-04, 1.70077510e-03, 1.01586160e-03, 3.84816946e-03,\n",
       "       1.90371715e-04, 5.56513013e-03])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "selector.estimator_.feature_importances_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.01162790697674419"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "selector.threshold_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "mask = selector.get_support()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ True,  True,  True,  True,  True,  True, False, False, False,\n",
       "       False, False, False, False, False, False, False, False, False,\n",
       "       False, False, False, False, False, False, False, False, False,\n",
       "       False, False, False, False, False, False, False, False, False,\n",
       "       False, False, False, False, False, False, False, False, False,\n",
       "       False, False, False,  True, False,  True, False, False, False,\n",
       "       False, False, False, False,  True, False, False, False, False,\n",
       "       False,  True, False, False, False, False, False, False, False,\n",
       "       False, False, False, False, False,  True, False, False, False,\n",
       "       False, False, False, False, False])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "selected_features = X.columns[mask]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>lsa_0</th>\n",
       "      <th>lsa_1</th>\n",
       "      <th>lsa_2</th>\n",
       "      <th>lsa_3</th>\n",
       "      <th>lsa_4</th>\n",
       "      <th>hybrid</th>\n",
       "      <th>citrus</th>\n",
       "      <th>diesel</th>\n",
       "      <th>lemon</th>\n",
       "      <th>orange</th>\n",
       "      <th>sweet</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.243491</td>\n",
       "      <td>0.034313</td>\n",
       "      <td>0.080290</td>\n",
       "      <td>-0.165609</td>\n",
       "      <td>0.019773</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.238648</td>\n",
       "      <td>-0.048758</td>\n",
       "      <td>-0.107398</td>\n",
       "      <td>-0.067096</td>\n",
       "      <td>-0.006558</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.260672</td>\n",
       "      <td>-0.019644</td>\n",
       "      <td>0.215790</td>\n",
       "      <td>-0.106098</td>\n",
       "      <td>0.058930</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.301049</td>\n",
       "      <td>-0.056156</td>\n",
       "      <td>-0.030174</td>\n",
       "      <td>-0.036708</td>\n",
       "      <td>0.015147</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.412179</td>\n",
       "      <td>-0.004705</td>\n",
       "      <td>-0.130429</td>\n",
       "      <td>0.000645</td>\n",
       "      <td>-0.119390</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44995</th>\n",
       "      <td>0.440634</td>\n",
       "      <td>-0.078839</td>\n",
       "      <td>0.085152</td>\n",
       "      <td>0.087878</td>\n",
       "      <td>-0.133604</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44996</th>\n",
       "      <td>0.181714</td>\n",
       "      <td>-0.045560</td>\n",
       "      <td>-0.055692</td>\n",
       "      <td>0.015649</td>\n",
       "      <td>-0.045585</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44997</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44998</th>\n",
       "      <td>0.324915</td>\n",
       "      <td>0.131823</td>\n",
       "      <td>-0.099424</td>\n",
       "      <td>0.065491</td>\n",
       "      <td>0.038437</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44999</th>\n",
       "      <td>0.270141</td>\n",
       "      <td>-0.004631</td>\n",
       "      <td>-0.151272</td>\n",
       "      <td>0.035538</td>\n",
       "      <td>0.083641</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>45000 rows × 11 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          lsa_0     lsa_1     lsa_2     lsa_3     lsa_4  hybrid  citrus  \\\n",
       "0      0.243491  0.034313  0.080290 -0.165609  0.019773       1       0   \n",
       "1      0.238648 -0.048758 -0.107398 -0.067096 -0.006558       1       0   \n",
       "2      0.260672 -0.019644  0.215790 -0.106098  0.058930       1       0   \n",
       "3      0.301049 -0.056156 -0.030174 -0.036708  0.015147       1       0   \n",
       "4      0.412179 -0.004705 -0.130429  0.000645 -0.119390       1       0   \n",
       "...         ...       ...       ...       ...       ...     ...     ...   \n",
       "44995  0.440634 -0.078839  0.085152  0.087878 -0.133604       0       0   \n",
       "44996  0.181714 -0.045560 -0.055692  0.015649 -0.045585       0       0   \n",
       "44997  0.000000  0.000000  0.000000  0.000000  0.000000       0       0   \n",
       "44998  0.324915  0.131823 -0.099424  0.065491  0.038437       0       0   \n",
       "44999  0.270141 -0.004631 -0.151272  0.035538  0.083641       0       1   \n",
       "\n",
       "       diesel  lemon  orange  sweet  \n",
       "0           0      0       0      0  \n",
       "1           0      0       0      0  \n",
       "2           0      0       0      1  \n",
       "3           0      0       0      1  \n",
       "4           0      0       0      0  \n",
       "...       ...    ...     ...    ...  \n",
       "44995       0      0       0      0  \n",
       "44996       0      0       0      0  \n",
       "44997       0      0       0      0  \n",
       "44998       0      0       0      0  \n",
       "44999       1      1       1      1  \n",
       "\n",
       "[45000 rows x 11 columns]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "selected_X = df_mlp[selected_features]\n",
    "selected_X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['lsa_0',\n",
       " 'lsa_1',\n",
       " 'lsa_2',\n",
       " 'lsa_3',\n",
       " 'lsa_4',\n",
       " 'hybrid',\n",
       " 'citrus',\n",
       " 'diesel',\n",
       " 'lemon',\n",
       " 'orange',\n",
       " 'sweet']"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "selected_X.columns.to_list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['selected_X_mlp_lsa_elbow_geran.pkl']"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import joblib\n",
    "\n",
    "joblib.dump(selector, \"selector_mlp_lsa_elbow_geran.pkl\")\n",
    "joblib.dump(selected_X, \"selected_X_mlp_lsa_elbow_geran.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import joblib\n",
    "\n",
    "# selected_X = joblib.load(\"selected_X_mlp_lsa_elbow_geran.pkl\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train test split (after Feature Selection)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(selected_X, y, random_state=1, test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train1, X_val, y_train1, y_val = train_test_split(X_train, y_train, random_state=1, test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/andalanputra/opt/anaconda3/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:1623: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    }
   ],
   "source": [
    "mlpreg.fit(X_train1, y_train1)\n",
    "y_pred_mlpreg = mlpreg.predict(X_val)\n",
    "y_pred_mlpreg_r2 = mlpreg.predict(X_train1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.2811310023333186"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mean_absolute_error(y_val, y_pred_mlpreg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.40272850544300676"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#train\n",
    "r2_score(y_train1, y_pred_mlpreg_r2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.37009430212611194"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#val\n",
    "r2_score(y_val, y_pred_mlpreg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hyperparameter Tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "parameters = {'hidden_layer_sizes': [(100,), (50, 50, 50), (50, 100, 50)],\n",
    "              'activation': ['tanh', 'relu'], #only tanh and relu\n",
    "              'max_iter': [200, 500, 1000]\n",
    "              }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "rscv = RandomizedSearchCV(mlpreg,  \n",
    "                     parameters,   \n",
    "                     cv=5, \n",
    "                     scoring='neg_mean_absolute_error',\n",
    "                     n_jobs=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/andalanputra/opt/anaconda3/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:1623: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/Users/andalanputra/opt/anaconda3/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:1623: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/Users/andalanputra/opt/anaconda3/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:1623: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/Users/andalanputra/opt/anaconda3/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:1623: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/Users/andalanputra/opt/anaconda3/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:1623: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/Users/andalanputra/opt/anaconda3/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:1623: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/Users/andalanputra/opt/anaconda3/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:1623: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/Users/andalanputra/opt/anaconda3/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:1623: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/Users/andalanputra/opt/anaconda3/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:1623: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/Users/andalanputra/opt/anaconda3/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:1623: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/Users/andalanputra/opt/anaconda3/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:1623: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/Users/andalanputra/opt/anaconda3/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:1623: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/Users/andalanputra/opt/anaconda3/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:1623: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/Users/andalanputra/opt/anaconda3/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:1623: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/Users/andalanputra/opt/anaconda3/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:1623: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/Users/andalanputra/opt/anaconda3/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:1623: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/Users/andalanputra/opt/anaconda3/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:1623: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/Users/andalanputra/opt/anaconda3/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:1623: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/Users/andalanputra/opt/anaconda3/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:1623: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/Users/andalanputra/opt/anaconda3/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:1623: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/Users/andalanputra/opt/anaconda3/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:1623: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/Users/andalanputra/opt/anaconda3/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:1623: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/Users/andalanputra/opt/anaconda3/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:1623: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/Users/andalanputra/opt/anaconda3/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:1623: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/Users/andalanputra/opt/anaconda3/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/Users/andalanputra/opt/anaconda3/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:1623: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/Users/andalanputra/opt/anaconda3/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:1623: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/Users/andalanputra/opt/anaconda3/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/Users/andalanputra/opt/anaconda3/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:1623: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/Users/andalanputra/opt/anaconda3/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:1623: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/Users/andalanputra/opt/anaconda3/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:1623: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/Users/andalanputra/opt/anaconda3/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:1623: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/Users/andalanputra/opt/anaconda3/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:1623: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/Users/andalanputra/opt/anaconda3/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:1623: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/Users/andalanputra/opt/anaconda3/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:1623: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/Users/andalanputra/opt/anaconda3/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:1623: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/Users/andalanputra/opt/anaconda3/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:1623: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/Users/andalanputra/opt/anaconda3/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:1623: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/Users/andalanputra/opt/anaconda3/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:1623: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/Users/andalanputra/opt/anaconda3/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:1623: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/Users/andalanputra/opt/anaconda3/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:1623: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/Users/andalanputra/opt/anaconda3/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:1623: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/Users/andalanputra/opt/anaconda3/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:1623: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/Users/andalanputra/opt/anaconda3/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:1623: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/Users/andalanputra/opt/anaconda3/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:1623: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/Users/andalanputra/opt/anaconda3/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:1623: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/Users/andalanputra/opt/anaconda3/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:1623: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/Users/andalanputra/opt/anaconda3/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:1623: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/Users/andalanputra/opt/anaconda3/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:1623: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/Users/andalanputra/opt/anaconda3/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:1623: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/Users/andalanputra/opt/anaconda3/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:1623: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/Users/andalanputra/opt/anaconda3/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:1623: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/Users/andalanputra/opt/anaconda3/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:1623: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;background-color: white;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>RandomizedSearchCV(cv=5,\n",
       "                   estimator=MLPRegressor(early_stopping=True, random_state=1),\n",
       "                   n_jobs=-1,\n",
       "                   param_distributions={&#x27;activation&#x27;: [&#x27;tanh&#x27;, &#x27;relu&#x27;],\n",
       "                                        &#x27;hidden_layer_sizes&#x27;: [(100,),\n",
       "                                                               (50, 50, 50),\n",
       "                                                               (50, 100, 50)],\n",
       "                                        &#x27;max_iter&#x27;: [200, 500, 1000]},\n",
       "                   scoring=&#x27;neg_mean_absolute_error&#x27;)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" ><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">RandomizedSearchCV</label><div class=\"sk-toggleable__content\"><pre>RandomizedSearchCV(cv=5,\n",
       "                   estimator=MLPRegressor(early_stopping=True, random_state=1),\n",
       "                   n_jobs=-1,\n",
       "                   param_distributions={&#x27;activation&#x27;: [&#x27;tanh&#x27;, &#x27;relu&#x27;],\n",
       "                                        &#x27;hidden_layer_sizes&#x27;: [(100,),\n",
       "                                                               (50, 50, 50),\n",
       "                                                               (50, 100, 50)],\n",
       "                                        &#x27;max_iter&#x27;: [200, 500, 1000]},\n",
       "                   scoring=&#x27;neg_mean_absolute_error&#x27;)</pre></div></div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" ><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">estimator: MLPRegressor</label><div class=\"sk-toggleable__content\"><pre>MLPRegressor(early_stopping=True, random_state=1)</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-3\" type=\"checkbox\" ><label for=\"sk-estimator-id-3\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">MLPRegressor</label><div class=\"sk-toggleable__content\"><pre>MLPRegressor(early_stopping=True, random_state=1)</pre></div></div></div></div></div></div></div></div></div></div>"
      ],
      "text/plain": [
       "RandomizedSearchCV(cv=5,\n",
       "                   estimator=MLPRegressor(early_stopping=True, random_state=1),\n",
       "                   n_jobs=-1,\n",
       "                   param_distributions={'activation': ['tanh', 'relu'],\n",
       "                                        'hidden_layer_sizes': [(100,),\n",
       "                                                               (50, 50, 50),\n",
       "                                                               (50, 100, 50)],\n",
       "                                        'max_iter': [200, 500, 1000]},\n",
       "                   scoring='neg_mean_absolute_error')"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rscv.fit(X_train1, y_train1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'max_iter': 1000, 'hidden_layer_sizes': (50, 100, 50), 'activation': 'tanh'}"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rscv.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['rscv_mlp_lsa_elbow_best_params_geran.pkl']"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "joblib.dump(rscv, \"rscv_mlp_lsa_elbow_geran.pkl\")\n",
    "joblib.dump(rscv.best_params_, \"rscv_mlp_lsa_elbow_best_params_geran.pkl\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "MLP fit (after hyperparameter tuning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/andalanputra/opt/anaconda3/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:1623: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    }
   ],
   "source": [
    "mlpreg_ht = MLPRegressor(random_state=1, max_iter=1000, activation = 'tanh', hidden_layer_sizes= (50,100,50), early_stopping=True)\n",
    "mlpreg_ht.fit(X_train1, y_train1)\n",
    "y_pred_mlp_ht = mlpreg_ht.predict(X_val)\n",
    "y_pred_mlp_r2_ht = mlpreg_ht.predict(X_train1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.11532725077037359"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mean_absolute_error(y_val, y_pred_mlp_ht)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8677939015565586"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#train\n",
    "r2_score(y_train1, y_pred_mlp_r2_ht)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.79225137323539"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#val\n",
    "r2_score(y_val, y_pred_mlp_ht)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Residual plots after Hyperparameter Tuning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Predicting model on the test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_mlpreg_test = mlpreg_ht.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['y_test_mlpreg_lsa_elbow_geran.pkl']"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "joblib.dump(y_pred_mlpreg_test, \"y_pred_mlpreg_test_lsa_elbow_geran.pkl\")\n",
    "joblib.dump(y_test, \"y_test_mlpreg_lsa_elbow_geran.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.11819899733490496"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mean_absolute_error(y_test, y_pred_mlpreg_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.04169621981148611"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mean_squared_error(y_test, y_pred_mlpreg_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.20419652252544876"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mean_squared_error(y_test, y_pred_mlpreg_test, squared = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7734537625127476"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "r2_score(y_test, y_pred_mlpreg_test)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Error analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 576x432 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 432x288 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# assume y_pred is a numpy array and y_true is a pandas dataframe\n",
    "fig, ax = plt.subplots(figsize=(8, 6))\n",
    "\n",
    "column = \"X..Geraniol\"  # specify the target variable name\n",
    "ax.hist(y_pred_mlpreg_test, alpha=0.5, label='y_pred', bins=20)\n",
    "ax.hist(y_test[column], alpha=0.5, label='y_true', bins=20)\n",
    "ax.legend(loc='upper right')\n",
    "ax.set_title(column)\n",
    "\n",
    "plt.show()\n",
    "plt.savefig('error_hist_mlp_lsa_elbow_geran.png')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pearson R"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pearson correlation coefficient: 0.882\n",
      "P-value: 0.000\n"
     ]
    }
   ],
   "source": [
    "corr_coef, p_value = pearsonr(y_pred_mlpreg_test.flatten(), y_test.values.ravel())\n",
    "\n",
    "print(f\"Pearson correlation coefficient: {corr_coef:.3f}\")\n",
    "print(f\"P-value: {p_value:.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:>"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "corr_matrix = y_test.corr()\n",
    "sns.heatmap(corr_matrix, annot=True, cmap='coolwarm', center=0)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
