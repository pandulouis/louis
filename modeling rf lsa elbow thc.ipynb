{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn import preprocessing\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.neural_network import MLPRegressor\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "from sklearn.metrics import r2_score\n",
    "from scipy.stats import pearsonr\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.feature_selection import SelectFromModel\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compiling complete dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_rf = pd.read_csv(\"df_thc_lsa.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>lsa_0</th>\n",
       "      <th>lsa_1</th>\n",
       "      <th>lsa_2</th>\n",
       "      <th>lsa_3</th>\n",
       "      <th>lsa_4</th>\n",
       "      <th>hybrid</th>\n",
       "      <th>indica</th>\n",
       "      <th>sativa</th>\n",
       "      <th>anxiety</th>\n",
       "      <th>anxious</th>\n",
       "      <th>...</th>\n",
       "      <th>sweet</th>\n",
       "      <th>tar</th>\n",
       "      <th>tea</th>\n",
       "      <th>tobacco</th>\n",
       "      <th>tree</th>\n",
       "      <th>tropical</th>\n",
       "      <th>vanilla</th>\n",
       "      <th>violet</th>\n",
       "      <th>woody</th>\n",
       "      <th>X..Delta9-THC</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.341025</td>\n",
       "      <td>0.182753</td>\n",
       "      <td>0.008214</td>\n",
       "      <td>0.140406</td>\n",
       "      <td>-0.156943</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.259712</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.232158</td>\n",
       "      <td>-0.045496</td>\n",
       "      <td>0.187131</td>\n",
       "      <td>-0.000936</td>\n",
       "      <td>0.018518</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.259712</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.261225</td>\n",
       "      <td>0.100324</td>\n",
       "      <td>-0.043622</td>\n",
       "      <td>0.141860</td>\n",
       "      <td>-0.034786</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.259712</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.243491</td>\n",
       "      <td>0.034313</td>\n",
       "      <td>0.080290</td>\n",
       "      <td>-0.165609</td>\n",
       "      <td>0.019773</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.259712</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.243491</td>\n",
       "      <td>0.034313</td>\n",
       "      <td>0.080290</td>\n",
       "      <td>-0.165609</td>\n",
       "      <td>0.019773</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.259712</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>74995</th>\n",
       "      <td>0.181714</td>\n",
       "      <td>-0.045560</td>\n",
       "      <td>-0.055692</td>\n",
       "      <td>0.015649</td>\n",
       "      <td>-0.045585</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.562557</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>74996</th>\n",
       "      <td>0.055494</td>\n",
       "      <td>0.003622</td>\n",
       "      <td>-0.050252</td>\n",
       "      <td>-0.024795</td>\n",
       "      <td>-0.031141</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.562557</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>74997</th>\n",
       "      <td>0.055494</td>\n",
       "      <td>0.003622</td>\n",
       "      <td>-0.050252</td>\n",
       "      <td>-0.024795</td>\n",
       "      <td>-0.031141</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.562557</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>74998</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.562557</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>74999</th>\n",
       "      <td>0.270141</td>\n",
       "      <td>-0.004631</td>\n",
       "      <td>-0.151272</td>\n",
       "      <td>0.035538</td>\n",
       "      <td>0.083641</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.562557</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>75000 rows × 87 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          lsa_0     lsa_1     lsa_2     lsa_3     lsa_4  hybrid  indica  \\\n",
       "0      0.341025  0.182753  0.008214  0.140406 -0.156943       1       0   \n",
       "1      0.232158 -0.045496  0.187131 -0.000936  0.018518       1       0   \n",
       "2      0.261225  0.100324 -0.043622  0.141860 -0.034786       1       0   \n",
       "3      0.243491  0.034313  0.080290 -0.165609  0.019773       1       0   \n",
       "4      0.243491  0.034313  0.080290 -0.165609  0.019773       1       0   \n",
       "...         ...       ...       ...       ...       ...     ...     ...   \n",
       "74995  0.181714 -0.045560 -0.055692  0.015649 -0.045585       0       1   \n",
       "74996  0.055494  0.003622 -0.050252 -0.024795 -0.031141       0       1   \n",
       "74997  0.055494  0.003622 -0.050252 -0.024795 -0.031141       0       1   \n",
       "74998  0.000000  0.000000  0.000000  0.000000  0.000000       0       1   \n",
       "74999  0.270141 -0.004631 -0.151272  0.035538  0.083641       0       1   \n",
       "\n",
       "       sativa  anxiety  anxious  ...  sweet  tar  tea  tobacco  tree  \\\n",
       "0           0        0        0  ...      0    0    0        0     0   \n",
       "1           0        0        0  ...      0    0    0        0     0   \n",
       "2           0        0        0  ...      1    0    0        0     0   \n",
       "3           0        0        0  ...      0    1    0        0     0   \n",
       "4           0        0        0  ...      0    1    0        0     0   \n",
       "...       ...      ...      ...  ...    ...  ...  ...      ...   ...   \n",
       "74995       0        0        0  ...      0    0    0        0     0   \n",
       "74996       0        0        0  ...      0    0    0        0     0   \n",
       "74997       0        0        0  ...      0    0    0        0     0   \n",
       "74998       0        0        0  ...      0    0    0        0     0   \n",
       "74999       0        0        1  ...      1    1    1        1     1   \n",
       "\n",
       "       tropical  vanilla  violet  woody  X..Delta9-THC  \n",
       "0             0        0       0      0       0.259712  \n",
       "1             0        1       0      0       0.259712  \n",
       "2             0        1       0      0       0.259712  \n",
       "3             0        0       0      0       0.259712  \n",
       "4             0        0       0      0       0.259712  \n",
       "...         ...      ...     ...    ...            ...  \n",
       "74995         0        0       0      0       0.562557  \n",
       "74996         0        0       0      0       0.562557  \n",
       "74997         0        0       0      0       0.562557  \n",
       "74998         0        0       0      0       0.562557  \n",
       "74999         1        1       1      1       0.562557  \n",
       "\n",
       "[75000 rows x 87 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_rf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['lsa_0',\n",
       " 'lsa_1',\n",
       " 'lsa_2',\n",
       " 'lsa_3',\n",
       " 'lsa_4',\n",
       " 'hybrid',\n",
       " 'indica',\n",
       " 'sativa',\n",
       " 'anxiety',\n",
       " 'anxious',\n",
       " 'aroused',\n",
       " 'arthritis',\n",
       " 'creative',\n",
       " 'depression',\n",
       " 'dizzy',\n",
       " 'dry eyes',\n",
       " 'dry mouth',\n",
       " 'energetic',\n",
       " 'epilepsy',\n",
       " 'euphoric',\n",
       " 'eye pressure',\n",
       " 'fatigue',\n",
       " 'focused',\n",
       " 'giggly',\n",
       " 'happy',\n",
       " 'headache',\n",
       " 'hungry',\n",
       " 'migraines',\n",
       " 'pain',\n",
       " 'paranoid',\n",
       " 'relaxed',\n",
       " 'seizures',\n",
       " 'sleepy',\n",
       " 'spasticity',\n",
       " 'stress',\n",
       " 'talkative',\n",
       " 'tingly',\n",
       " 'uplifted',\n",
       " 'ammonia',\n",
       " 'apple',\n",
       " 'apricot',\n",
       " 'berry',\n",
       " 'blue cheese',\n",
       " 'blueberry',\n",
       " 'butter',\n",
       " 'cheese',\n",
       " 'chemical',\n",
       " 'chestnut',\n",
       " 'citrus',\n",
       " 'coffee',\n",
       " 'diesel',\n",
       " 'earthy',\n",
       " 'flowery',\n",
       " 'fruit',\n",
       " 'grape',\n",
       " 'grapefruit',\n",
       " 'honey',\n",
       " 'lavender',\n",
       " 'lemon',\n",
       " 'lime',\n",
       " 'mango',\n",
       " 'menthol',\n",
       " 'mint',\n",
       " 'nutty',\n",
       " 'orange',\n",
       " 'peach',\n",
       " 'pear',\n",
       " 'pepper',\n",
       " 'pine',\n",
       " 'pineapple',\n",
       " 'plum',\n",
       " 'pungent',\n",
       " 'rose',\n",
       " 'sage',\n",
       " 'skunk',\n",
       " 'spicy/herbal',\n",
       " 'strawberry',\n",
       " 'sweet',\n",
       " 'tar',\n",
       " 'tea',\n",
       " 'tobacco',\n",
       " 'tree',\n",
       " 'tropical',\n",
       " 'vanilla',\n",
       " 'violet',\n",
       " 'woody',\n",
       " 'X..Delta9-THC']"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_rf.columns.to_list()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Splitting dependent and independent variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df_rf.drop(['X..Delta9-THC'], axis = 1)\n",
    "y = df_rf[['X..Delta9-THC']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plotting histograms on target variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.25971245],\n",
       "       [0.25971245],\n",
       "       [0.25971245],\n",
       "       ...,\n",
       "       [0.56255736],\n",
       "       [0.56255736],\n",
       "       [0.56255736]])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_array = y.to_numpy()\n",
    "y_array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:ylabel='Count'>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAZIAAAD4CAYAAADGmmByAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjQuMywgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/MnkTPAAAACXBIWXMAAAsTAAALEwEAmpwYAAAaEElEQVR4nO3de5BV5b3m8e/DTcBbUFuLoRvoRECFQkZaT3sZixyikhwVTfAExxM6GZkuUTMcHUnQU6VViVhaWh4OJmARJWBCiYyXSDKHHBAvmUQup4moXLXHC92RSAcdQx0EBX/zx16N26Yvm16992bTz6dqV6/9rvWu9b427qfX+669liICMzOzzupR7AaYmVlpc5CYmVkqDhIzM0vFQWJmZqk4SMzMLJVexW5AoZ1yyikxdOjQYjfDzKykrF+//i8RUdbaum4XJEOHDqWurq7YzTAzKymS3m1rnYe2zMwsFQeJmZml4iAxM7NUut0ciR09Pv30UxobG9m7d2+xm2Kt6Nu3L+Xl5fTu3bvYTbE8c5BYyWpsbOT4449n6NChSCp2cyxLRLBr1y4aGxuprKwsdnMszzy0ZSVr7969nHzyyQ6RI5AkTj75ZJ8tdhMOEitpDpEjl3833YeDxMzMUnGQ2FGjYvAQJHXZq2LwkHaP19DQQGVlJR988AEAH374IZWVlbz7bpvf2+K73/0ulZWVnH322QwfPpwpU6bwpz/9qcO+jRs37uAXae+5556c/ns88cQTjB49mpEjR/KDH/zgkPVXX301Y8aM4fTTT+fEE09kzJgxjBkzhpdffvkLxwN45513GDVq1MH369at4+KLL2bEiBGcccYZTJ06lT179uTULjv6eLLdjhqNDdt5cMW2LtvfrZeOaHd9RUUF06ZNY+bMmcyfP5+ZM2dSW1vLkCHtB9D999/PpEmTiAhmz57NV7/6VTZu3EifPn1yatc999zDHXfc0e42u3btYsaMGaxfv56ysjJqampYtWoV48ePP7jNM888A8CLL77IAw88wG9+85ucjv/+++9zzTXXsGTJEs4//3wigqeeeordu3fTv3//nPZxJKgYPITGhu0FP255xWAatrf9x0YpcpCYpXDLLbcwduxYZs+eze9//3seeuihnOtK4pZbbuGZZ55h+fLlTJw4kRUrVnDXXXexb98+vvKVr/Dzn/+c44477mCdmTNn8vHHHzNmzBhGjhzJ4sWLueqqq2hoaGDv3r1Mnz6d2tpa3nrrLYYPH05ZWebWSF/72td46qmnvhAknfXTn/6Umpoazj///IP9mDRpUur9FlpX/+GRq47+QClFDhKzFHr37s3999/PhAkTWLFiRc5nFdnOOecctm7dyoUXXsjdd9/Nc889x7HHHst9993Hgw8+yJ133nlw23vvvZef/OQnbNiw4WDZggULOOmkk/j4448599xz+da3vsXpp5/O1q1beeeddygvL+dXv/oVn3zyyWG167rrrqNfv34AfPLJJ/TokRkJ37hxIzU1NYfdTzt6OUjMUlq+fDkDBw5k48aNXHLJJYddPyIAWLNmDZs3b+bCCy8EMh/ezX/1t2fOnDkHh6kaGhp48803qa6uZt68eXz729+mR48eXHDBBbz11luH1a7FixdTVVUFZOZILr/88sOqb92Hg8QshQ0bNrBy5UrWrFnDRRddxOTJkxk4cOBh7eOVV15h/PjxRASXXHIJjz/+eM51X3zxRZ577jlWr15N//79GTdu3MHvblxxxRVcccUVAMyfP5+ePXty4MABxo4dC8CVV17Jj370o8NqK8DIkSNZv349EydOPOy6dnTyVVtmnRQRTJs2jdmzZzN48GBmzJjBbbfddlj158yZw44dO5gwYQLV1dX84Q9/oL6+HoA9e/bwxhtvHFKvd+/efPrppwB89NFHDBgwgP79+7N161bWrFlzcLudO3cCmavJ5s6dy9SpU+nZsycbNmxgw4YNnQoRgJtvvplFixaxdu3ag2W//OUv+fOf/9yp/Vnp8xnJYSjWVR5wdF7p0dXKKwZ36URmecXgdtf/7Gc/Y/DgwQeHs2688UYWLlzISy+9xPTp0w/OY0ydOpUbbrjh4DDRjBkz+PGPf8yePXuorq7mhRdeoE+fPpSVlbFw4UKuvfZa9u3bB8Ddd9/N8OHDv3Dc2tpaRo8ezTnnnMOCBQt4+OGHGT16NCNGjKC6uvrgdtOnT+fVV18F4M477zxkP5112mmnsWTJEm677TZ27txJjx49uPjii/nmN7/ZJfu30qPm8dnuoqqqKjr7YCtJRbnKAzJXenS331VHtmzZwplnnlnsZlg7juTfUbH+fy7V/5clrY+IqtbWeWjLzMxScZCYmVkqDhIraaU4RNBd+HfTfThIrGT17duXXbt2+QPrCNT8PJK+ffsWuylWAL5qy0pWeXk5jY2NNDU1Fbsp1ormJyTa0c9BYiWrd+/efvqe2REgb0NbkhZI2ilpY1bZ/ZK2SnpN0jOSvpS17nZJ9ZK2Sbosq3yspNeTdXOUPC1H0jGSnkjK10oamq++mJlZ2/I5R7IQmNCibCUwKiJGA28AtwNIOguYDIxM6syV1DOpMw+oBYYlr+Z9Xg98GBGnA/8M3Je3npiZWZvyFiQR8TvggxZlKyJif/J2DdA8gDoRWBIR+yLibaAeOE/SQOCEiFgdmRnVx4CrsuosSpafBMY3n62YmVnhFPOqrf8GLE+WBwENWesak7JByXLL8i/UScLpI+Dk1g4kqVZSnaQ6T8yamXWtogSJpH8C9gOLm4ta2SzaKW+vzqGFEfMjoioiqpof9GNmn+vqxxR31eOMrTQU/KotSTXA5cD4+PwLAI1ARdZm5cB7SXl5K+XZdRol9QJOpMVQmpnlxk8LtDQKekYiaQLwQ+DKiNiTtWoZMDm5EquSzKT6uojYAeyWVJ3Mf0wBns2q0/yYtknA8+FvppmZFVzezkgkPQ6MA06R1AjcReYqrWOAlcm8+JqIuCEiNklaCmwmM+R1U0QcSHY1jcwVYP3IzKk0z6s8CvxCUj2ZM5HJ+eqLmZm1LW9BEhHXtlL8aDvbzwJmtVJeB4xqpXwvcE2aNpqZWXq+15aZmaXiIDEzs1QcJGZmloqDxMzMUnGQmJlZKg4SMzNLxUFiZmapOEjMzCwVB4mZmaXiIDEzs1QcJGZmloqDxMzMUnGQmJlZKg4SMzNLxUFiZmapOEjMzCwVB4mZmaXiIDEzs1QcJGZmloqDxMzMUnGQmJlZKg4SMzNLJW9BImmBpJ2SNmaVnSRppaQ3k58DstbdLqle0jZJl2WVj5X0erJujiQl5cdIeiIpXytpaL76YmZmbcvnGclCYEKLspnAqogYBqxK3iPpLGAyMDKpM1dSz6TOPKAWGJa8mvd5PfBhRJwO/DNwX956YmZmbcpbkETE74APWhRPBBYly4uAq7LKl0TEvoh4G6gHzpM0EDghIlZHRACPtajTvK8ngfHNZytmZlY4hZ4jOS0idgAkP09NygcBDVnbNSZlg5LlluVfqBMR+4GPgJPz1nIzM2vVkTLZ3tqZRLRT3l6dQ3cu1Uqqk1TX1NTUySaamVlrCh0k7yfDVSQ/dybljUBF1nblwHtJeXkr5V+oI6kXcCKHDqUBEBHzI6IqIqrKysq6qCtmZgaFD5JlQE2yXAM8m1U+ObkSq5LMpPq6ZPhrt6TqZP5jSos6zfuaBDyfzKOYmVkB9crXjiU9DowDTpHUCNwF3AsslXQ9sB24BiAiNklaCmwG9gM3RcSBZFfTyFwB1g9YnrwAHgV+IamezJnI5Hz1xczM2pa3IImIa9tYNb6N7WcBs1oprwNGtVK+lySIzMyseI6UyXYzMytRDhIzM0vFQWLtqhg8BElFeVUMHlLs7ptZDvI2R2JHh8aG7Ty4YltRjn3rpSOKclwzOzw+IzEzs1QcJGZmloqDxMzMUnGQmJlZKg4SMzNLxUFiZmapOEjMzCwVB4mZmaXiIDEzs1QcJGZmloqDxMzMUnGQmJlZKg4SMzNLxUFiZmapOEjMzCwVB4mZmaXiIDEzs1QcJGZmloqDxMzMUilKkEi6RdImSRslPS6pr6STJK2U9Gbyc0DW9rdLqpe0TdJlWeVjJb2erJsjScXoj5lZd1bwIJE0CPgfQFVEjAJ6ApOBmcCqiBgGrEreI+msZP1IYAIwV1LPZHfzgFpgWPKaUMCumJkZxRva6gX0k9QL6A+8B0wEFiXrFwFXJcsTgSURsS8i3gbqgfMkDQROiIjVERHAY1l1zMysQAoeJBHxJ+ABYDuwA/goIlYAp0XEjmSbHcCpSZVBQEPWLhqTskHJcsvyQ0iqlVQnqa6pqakru2Nm1u0VY2hrAJmzjErgPwHHSvqH9qq0UhbtlB9aGDE/IqoioqqsrOxwm2xmZu0oxtDW14C3I6IpIj4FngYuAN5PhqtIfu5Mtm8EKrLql5MZCmtMlluWm5lZARUjSLYD1ZL6J1dZjQe2AMuAmmSbGuDZZHkZMFnSMZIqyUyqr0uGv3ZLqk72MyWrjlnJqRg8BElFeZml0avQB4yItZKeBP4I7AdeAeYDxwFLJV1PJmyuSbbfJGkpsDnZ/qaIOJDsbhqwEOgHLE9eZiWpsWE7D67YVpRj33rpiKIc144OBQ8SgIi4C7irRfE+MmcnrW0/C5jVSnkdMKrLG2hmZjnLaWhL0oW5lJmZWfeT6xzJQzmWmZlZN9Pu0Jak88lcUVUm6dasVSeQ+Ua6mZl1cx3NkfQhMwneCzg+q/yvwKR8NcrMzEpHu0ESES8BL0laGBHvFqhNZmZWQnK9ausYSfOBodl1IuJv89EoMzMrHbkGyf8CHgYeAQ50sK2ZmXUjuQbJ/oiYl9eWmJlZScr18t9fS7pR0sDkAVQnSTopry0zK5Ji3arErFTlekbSfA+sGVllAXy5a5tjVnzFulWJb1NipSqnIImIynw3xMzMSlNOQSJpSmvlEfFY1zbHzMxKTa5DW+dmLfclc3PFP5J5vK2ZmXVjuQ5tfT/7vaQTgV/kpUVmZlZSOvtgqz1kHjBlZmbdXK5zJL/m8+eh9wTOBJbmq1FmZlY6cp0jeSBreT/wbkQ05qE9ZmZWYnIa2kpu3riVzB2ABwCf5LNRZmZWOnJ9QuLfA+vIPEf974G1knwbeTMzy3lo65+AcyNiJ4CkMuA54Ml8NczMzEpDrldt9WgOkcSuw6hrZmZHsVzPSH4r6d+Ax5P33wb+NT9NMjOzUtLRM9tPB06LiBmSvglcBAhYDSwuQPvMzOwI19Hw1GxgN0BEPB0Rt0bELWTORmZ39qCSviTpSUlbJW2RdH5ya/qVkt5Mfg7I2v52SfWStkm6LKt8rKTXk3Vz5Htxm5kVXEdBMjQiXmtZGBF1ZB6721n/Avw2Is4Azga2ADOBVRExDFiVvEfSWcBkYCQwAZgrqWeyn3lALZlv2Q9L1puZWQF1FCR921nXrzMHlHQCcDHwKEBEfBIR/w+YCCxKNlsEXJUsTwSWRMS+iHgbqAfOkzQQOCEiVkdEkLmBZHMdMzMrkI6C5N8l/feWhZKuB9Z38phfBpqAn0t6RdIjko4lMxezAyD5eWqy/SCgIat+Y1I2KFluWX4ISbWS6iTVNTU1dbLZZmbWmo6u2vpH4BlJ1/F5cFQBfYCrUxzzHOD7EbFW0r+QDGO1obV5j2in/NDCiPnAfICqqqpWtzEzs85pN0gi4n3gAklfBUYlxf87Ip5PccxGoDEi1ibvnyQTJO9LGhgRO5Jhq51Z21dk1S8H3kvKy1spNzOzAsr1XlsvRMRDyStNiBARfwYaJDU/oHo8sBlYxufPhq8Bnk2WlwGTJR0jqZLMpPq6ZPhrt6Tq5GqtKVl1zMysQHL9QmJX+z6wWFIf4C3ge2RCbWky/7KdzH29iIhNkpaSCZv9wE0RcSDZzzRgIZmJ/+XJy8zMCqgoQRIRG8jMtbQ0vo3tZwGzWimv4/MhNzMzKwLfL8vMzFJxkJiZWSrFmiMx65h64LvemB35HCR25IrPeHDFtoIf9tZLR3S8kZkd5KEtMzNLxUFiZmapOEjMzCwVB4mZmaXiIDEzs1QcJGZmloqDxMzMUnGQmJlZKg4SMzNLxUFiZmapOEjMzCwVB4mZmaXiIDEzs1QcJGZmloqDxMzMUnGQmJlZKg4SMzNLxUFiZmapFC1IJPWU9Iqk3yTvT5K0UtKbyc8BWdveLqle0jZJl2WVj5X0erJujvyAbzOzgivmGcl0YEvW+5nAqogYBqxK3iPpLGAyMBKYAMyV1DOpMw+oBYYlrwmFabqZmTUrSpBIKgf+Dngkq3gisChZXgRclVW+JCL2RcTbQD1wnqSBwAkRsToiAngsq46ZmRVIsc5IZgM/AD7LKjstInYAJD9PTcoHAQ1Z2zUmZYOS5Zblh5BUK6lOUl1TU1OXdMDMzDIKHiSSLgd2RsT6XKu0UhbtlB9aGDE/IqoioqqsrCzHw5qZWS56FeGYFwJXSvoG0Bc4QdIvgfclDYyIHcmw1c5k+0agIqt+OfBeUl7eSrmZmRVQwc9IIuL2iCiPiKFkJtGfj4h/AJYBNclmNcCzyfIyYLKkYyRVkplUX5cMf+2WVJ1crTUlq46ZmRVIMc5I2nIvsFTS9cB24BqAiNgkaSmwGdgP3BQRB5I604CFQD9gefIyM7MCKmqQRMSLwIvJ8i5gfBvbzQJmtVJeB4zKXwvNzKwj/ma7mZml4iAxM7NUHCRmZpaKg8TMzFJxkJiZWSoOEjMzS8VBYmZmqThIzMwsFQeJmZml4iAxM7NUjqR7bZlZd6Me+AnZpc9BYmbFE5/x4IptRTn0rZeOKMpxj0Ye2jIzs1QcJGZmloqDxMzMUnGQmJlZKg4SMzNLxUFiZmapOEjMzCwVB4mZmaXiIDEzs1T8zfZS4VtJmNkRykFSKop0KwnfRsLMOlLwoS1JFZJekLRF0iZJ05PykyStlPRm8nNAVp3bJdVL2ibpsqzysZJeT9bNkf9kNzMruGLMkewH/mdEnAlUAzdJOguYCayKiGHAquQ9ybrJwEhgAjBXUs9kX/OAWmBY8ppQyI6YmVkRgiQidkTEH5Pl3cAWYBAwEViUbLYIuCpZnggsiYh9EfE2UA+cJ2kgcEJErI6IAB7LqmNmZgVS1Ku2JA0F/jOwFjgtInZAJmyAU5PNBgENWdUak7JByXLL8taOUyupTlJdU1NTl/bBzKy7K1qQSDoOeAr4x4j4a3ubtlIW7ZQfWhgxPyKqIqKqrKzs8BtrZtZVkiswi/GqGDwkL10qylVbknqTCZHFEfF0Uvy+pIERsSMZttqZlDcCFVnVy4H3kvLyVsrNzI5cR+HDvIpx1ZaAR4EtEfFg1qplQE2yXAM8m1U+WdIxkirJTKqvS4a/dkuqTvY5JauOmZkVSDHOSC4EvgO8LmlDUnYHcC+wVNL1wHbgGoCI2CRpKbCZzBVfN0XEgaTeNGAh0A9YnrzMzKyACh4kEfF7Wp/fABjfRp1ZwKxWyuuAUV3XOjMzO1y+15aZmaXiIDEzs1QcJGZmloqDxMzMUnGQmJlZKg4SMzNLxUFiZmapOEjMzCwVB4mZmaXiIDEzs1QcJGZmloqDxMzMUnGQmJlZKg4SMzNLxUFiZmapOEjMzCwVB4mZmaXiIDEzs1QcJGZmloqDxMzMUnGQmJlZKg4SMzNLxUFiZmaplHyQSJogaZukekkzi90eM7PupqSDRFJP4KfA14GzgGslnVXcVpmZdS8lHSTAeUB9RLwVEZ8AS4CJRW6TmVm3oogodhs6TdIkYEJETE3efwf4m4i4ucV2tUBt8nYEsK2ThzwF+Esn65Yq97l7cJ+7hzR9HhIRZa2t6NX59hwR1ErZIckYEfOB+akPJtVFRFXa/ZQS97l7cJ+7h3z1udSHthqBiqz35cB7RWqLmVm3VOpB8u/AMEmVkvoAk4FlRW6TmVm3UtJDWxGxX9LNwL8BPYEFEbEpj4dMPTxWgtzn7sF97h7y0ueSnmw3M7PiK/WhLTMzKzIHiZmZpeIgaUVHt11Rxpxk/WuSzilGO7tSDn2+Lunra5JelnR2MdrZlXK9vY6kcyUdSL63VNJy6bOkcZI2SNok6aVCt7Er5fDv+kRJv5b0atLf7xWjnV1J0gJJOyVtbGN9139+RYRfWS8yk/b/F/gy0Ad4FTirxTbfAJaT+R5LNbC22O0uQJ8vAAYky1/vDn3O2u554F+BScVudwF+z18CNgODk/enFrvdee7vHcB9yXIZ8AHQp9htT9nvi4FzgI1trO/yzy+fkRwql9uuTAQei4w1wJckDSx0Q7tQh32OiJcj4sPk7Roy39kpZbneXuf7wFPAzkI2Lk9y6fN/BZ6OiO0AEVHK/c6lvwEcL0nAcWSCZH9hm9m1IuJ3ZPrRli7//HKQHGoQ0JD1vjEpO9xtSsnh9ud6Mn/RlLIO+yxpEHA18HAB25VPufyehwMDJL0oab2kKQVrXdfLpb8/Ac4k80Xm14HpEfFZYZpXNF3++VXS3yPJk1xuu5LTrVlKSM79kfRVMkFyUV5blH+59Hk28MOIOJD5g7Xk5dLnXsBYYDzQD1gtaU1EvJHvxuVBLv29DNgA/C3wFWClpP8TEX/Nc9uKqcs/vxwkh8rltitH261ZcuqPpNHAI8DXI2JXgdqWL7n0uQpYkoTIKcA3JO2PiF8VpIVdL9d/23+JiP8A/kPS74CzgVIMklz6+z3g3shMHtRLehs4A1hXmCYWRZd/fnlo61C53HZlGTAlufqhGvgoInYUuqFdqMM+SxoMPA18p0T/Om2pwz5HRGVEDI2IocCTwI0lHCKQ27/tZ4H/IqmXpP7A3wBbCtzOrpJLf7eTOftC0mlk7g7+VkFbWXhd/vnlM5IWoo3brki6IVn/MJkreL4B1AN7yPxVU7Jy7POdwMnA3OQv9P1RwndOzbHPR5Vc+hwRWyT9FngN+Ax4JCJavYz0SJfj7/jHwEJJr5MZ8vlhRJT0reUlPQ6MA06R1AjcBfSG/H1++RYpZmaWioe2zMwsFQeJmZml4iAxM7NUHCRmZpaKg8TMzFJxkJiZWSoOEjMzS+X/Ay3cLAi0orHKAAAAAElFTkSuQmCC",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "sns.histplot(y, bins = 10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train test split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=1, test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train1, X_val, y_train1, y_val = train_test_split(X_train, y_train, random_state=1, test_size=0.25)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "RF modeling (before Feature selection and Hyperparameter Tuning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/y1/pjvjlkjn5gl846rnyzr53p340000gn/T/ipykernel_11883/119766249.py:2: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  rfreg.fit(X_train1, y_train1)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;background-color: white;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>RandomForestRegressor(n_jobs=-1)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">RandomForestRegressor</label><div class=\"sk-toggleable__content\"><pre>RandomForestRegressor(n_jobs=-1)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "RandomForestRegressor(n_jobs=-1)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rfreg = RandomForestRegressor(n_jobs = -1)\n",
    "rfreg.fit(X_train1, y_train1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_rfreg = rfreg.predict(X_val)\n",
    "y_pred_rfreg_r2 = rfreg.predict(X_train1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.058768143938891744"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mean_absolute_error(y_val, y_pred_rfreg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.012256266119816572"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mean_squared_error(y_val, y_pred_rfreg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.11070802193073712"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mean_squared_error(y_val, y_pred_rfreg, squared = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9645212317971562"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#train\n",
    "r2_score(y_train1, y_pred_rfreg_r2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.851490569891552"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#val\n",
    "r2_score(y_val, y_pred_rfreg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Residual plots for each target variable"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Feature Selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_feat = pd.DataFrame({\n",
    "    \"features\": X_train1.columns,\n",
    "    \"score\": rfreg.feature_importances_\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>features</th>\n",
       "      <th>score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>lsa_0</td>\n",
       "      <td>0.130599</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>lsa_1</td>\n",
       "      <td>0.120140</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>lsa_2</td>\n",
       "      <td>0.127144</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>lsa_3</td>\n",
       "      <td>0.117640</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>lsa_4</td>\n",
       "      <td>0.122074</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>81</th>\n",
       "      <td>tree</td>\n",
       "      <td>0.001101</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>82</th>\n",
       "      <td>tropical</td>\n",
       "      <td>0.002854</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>83</th>\n",
       "      <td>vanilla</td>\n",
       "      <td>0.006075</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>84</th>\n",
       "      <td>violet</td>\n",
       "      <td>0.000466</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>85</th>\n",
       "      <td>woody</td>\n",
       "      <td>0.003198</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>86 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    features     score\n",
       "0      lsa_0  0.130599\n",
       "1      lsa_1  0.120140\n",
       "2      lsa_2  0.127144\n",
       "3      lsa_3  0.117640\n",
       "4      lsa_4  0.122074\n",
       "..       ...       ...\n",
       "81      tree  0.001101\n",
       "82  tropical  0.002854\n",
       "83   vanilla  0.006075\n",
       "84    violet  0.000466\n",
       "85     woody  0.003198\n",
       "\n",
       "[86 rows x 2 columns]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_feat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_feat_ranked = df_feat.sort_values(\"score\", ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>features</th>\n",
       "      <th>score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>lsa_0</td>\n",
       "      <td>1.305989e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>lsa_2</td>\n",
       "      <td>1.271435e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>lsa_4</td>\n",
       "      <td>1.220742e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>lsa_1</td>\n",
       "      <td>1.201399e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>lsa_3</td>\n",
       "      <td>1.176396e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50</th>\n",
       "      <td>diesel</td>\n",
       "      <td>2.789599e-02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>sativa</td>\n",
       "      <td>2.787680e-02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>64</th>\n",
       "      <td>orange</td>\n",
       "      <td>1.891444e-02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>relaxed</td>\n",
       "      <td>1.267395e-02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51</th>\n",
       "      <td>earthy</td>\n",
       "      <td>1.249844e-02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>58</th>\n",
       "      <td>lemon</td>\n",
       "      <td>1.249517e-02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>77</th>\n",
       "      <td>sweet</td>\n",
       "      <td>1.232372e-02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>sleepy</td>\n",
       "      <td>1.188417e-02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>hybrid</td>\n",
       "      <td>1.171192e-02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>indica</td>\n",
       "      <td>1.085972e-02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>68</th>\n",
       "      <td>pine</td>\n",
       "      <td>1.072394e-02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>cheese</td>\n",
       "      <td>1.054451e-02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>euphoric</td>\n",
       "      <td>1.001589e-02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>happy</td>\n",
       "      <td>9.946949e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>uplifted</td>\n",
       "      <td>9.465297e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>hungry</td>\n",
       "      <td>9.174490e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>aroused</td>\n",
       "      <td>8.682706e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>creative</td>\n",
       "      <td>8.410636e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>dry mouth</td>\n",
       "      <td>8.409039e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>71</th>\n",
       "      <td>pungent</td>\n",
       "      <td>7.839291e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>focused</td>\n",
       "      <td>7.714984e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>energetic</td>\n",
       "      <td>7.563724e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54</th>\n",
       "      <td>grape</td>\n",
       "      <td>7.413184e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>giggly</td>\n",
       "      <td>6.890276e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>dry eyes</td>\n",
       "      <td>6.746163e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>citrus</td>\n",
       "      <td>6.145111e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>83</th>\n",
       "      <td>vanilla</td>\n",
       "      <td>6.075135e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>tingly</td>\n",
       "      <td>6.069875e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>talkative</td>\n",
       "      <td>5.620657e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>berry</td>\n",
       "      <td>4.962256e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>blueberry</td>\n",
       "      <td>4.954507e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>62</th>\n",
       "      <td>mint</td>\n",
       "      <td>3.989084e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>dizzy</td>\n",
       "      <td>3.965183e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>74</th>\n",
       "      <td>skunk</td>\n",
       "      <td>3.512248e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75</th>\n",
       "      <td>spicy/herbal</td>\n",
       "      <td>3.300839e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52</th>\n",
       "      <td>flowery</td>\n",
       "      <td>3.263952e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>85</th>\n",
       "      <td>woody</td>\n",
       "      <td>3.197613e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>82</th>\n",
       "      <td>tropical</td>\n",
       "      <td>2.853581e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>61</th>\n",
       "      <td>menthol</td>\n",
       "      <td>2.698083e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>headache</td>\n",
       "      <td>2.644593e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>paranoid</td>\n",
       "      <td>2.170740e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>67</th>\n",
       "      <td>pepper</td>\n",
       "      <td>2.164302e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>anxious</td>\n",
       "      <td>2.117566e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59</th>\n",
       "      <td>lime</td>\n",
       "      <td>1.774714e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>ammonia</td>\n",
       "      <td>1.642993e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>55</th>\n",
       "      <td>grapefruit</td>\n",
       "      <td>1.566591e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>chemical</td>\n",
       "      <td>1.506208e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>72</th>\n",
       "      <td>rose</td>\n",
       "      <td>1.393654e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53</th>\n",
       "      <td>fruit</td>\n",
       "      <td>1.287871e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>coffee</td>\n",
       "      <td>1.230160e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>76</th>\n",
       "      <td>strawberry</td>\n",
       "      <td>1.195076e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>butter</td>\n",
       "      <td>1.194248e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>56</th>\n",
       "      <td>honey</td>\n",
       "      <td>1.150758e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>63</th>\n",
       "      <td>nutty</td>\n",
       "      <td>1.142368e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>81</th>\n",
       "      <td>tree</td>\n",
       "      <td>1.100740e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>79</th>\n",
       "      <td>tea</td>\n",
       "      <td>7.683649e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>57</th>\n",
       "      <td>lavender</td>\n",
       "      <td>7.678183e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>60</th>\n",
       "      <td>mango</td>\n",
       "      <td>7.545179e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>66</th>\n",
       "      <td>pear</td>\n",
       "      <td>7.174416e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>73</th>\n",
       "      <td>sage</td>\n",
       "      <td>6.552360e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>69</th>\n",
       "      <td>pineapple</td>\n",
       "      <td>6.047713e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>apricot</td>\n",
       "      <td>5.030568e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>84</th>\n",
       "      <td>violet</td>\n",
       "      <td>4.655665e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>78</th>\n",
       "      <td>tar</td>\n",
       "      <td>4.243337e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>70</th>\n",
       "      <td>plum</td>\n",
       "      <td>3.969453e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>apple</td>\n",
       "      <td>3.357634e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>80</th>\n",
       "      <td>tobacco</td>\n",
       "      <td>3.044163e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>65</th>\n",
       "      <td>peach</td>\n",
       "      <td>3.041389e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>chestnut</td>\n",
       "      <td>2.556242e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>blue cheese</td>\n",
       "      <td>2.245244e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>anxiety</td>\n",
       "      <td>1.171303e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>migraines</td>\n",
       "      <td>1.090879e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>depression</td>\n",
       "      <td>1.086599e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>fatigue</td>\n",
       "      <td>5.457546e-06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>seizures</td>\n",
       "      <td>4.367327e-06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>epilepsy</td>\n",
       "      <td>3.751446e-06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>eye pressure</td>\n",
       "      <td>3.486483e-06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>arthritis</td>\n",
       "      <td>1.456857e-06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>pain</td>\n",
       "      <td>1.280002e-06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>stress</td>\n",
       "      <td>5.800331e-07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>spasticity</td>\n",
       "      <td>0.000000e+00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        features         score\n",
       "0          lsa_0  1.305989e-01\n",
       "2          lsa_2  1.271435e-01\n",
       "4          lsa_4  1.220742e-01\n",
       "1          lsa_1  1.201399e-01\n",
       "3          lsa_3  1.176396e-01\n",
       "50        diesel  2.789599e-02\n",
       "7         sativa  2.787680e-02\n",
       "64        orange  1.891444e-02\n",
       "30       relaxed  1.267395e-02\n",
       "51        earthy  1.249844e-02\n",
       "58         lemon  1.249517e-02\n",
       "77         sweet  1.232372e-02\n",
       "32        sleepy  1.188417e-02\n",
       "5         hybrid  1.171192e-02\n",
       "6         indica  1.085972e-02\n",
       "68          pine  1.072394e-02\n",
       "45        cheese  1.054451e-02\n",
       "19      euphoric  1.001589e-02\n",
       "24         happy  9.946949e-03\n",
       "37      uplifted  9.465297e-03\n",
       "26        hungry  9.174490e-03\n",
       "10       aroused  8.682706e-03\n",
       "12      creative  8.410636e-03\n",
       "16     dry mouth  8.409039e-03\n",
       "71       pungent  7.839291e-03\n",
       "22       focused  7.714984e-03\n",
       "17     energetic  7.563724e-03\n",
       "54         grape  7.413184e-03\n",
       "23        giggly  6.890276e-03\n",
       "15      dry eyes  6.746163e-03\n",
       "48        citrus  6.145111e-03\n",
       "83       vanilla  6.075135e-03\n",
       "36        tingly  6.069875e-03\n",
       "35     talkative  5.620657e-03\n",
       "41         berry  4.962256e-03\n",
       "43     blueberry  4.954507e-03\n",
       "62          mint  3.989084e-03\n",
       "14         dizzy  3.965183e-03\n",
       "74         skunk  3.512248e-03\n",
       "75  spicy/herbal  3.300839e-03\n",
       "52       flowery  3.263952e-03\n",
       "85         woody  3.197613e-03\n",
       "82      tropical  2.853581e-03\n",
       "61       menthol  2.698083e-03\n",
       "25      headache  2.644593e-03\n",
       "29      paranoid  2.170740e-03\n",
       "67        pepper  2.164302e-03\n",
       "9        anxious  2.117566e-03\n",
       "59          lime  1.774714e-03\n",
       "38       ammonia  1.642993e-03\n",
       "55    grapefruit  1.566591e-03\n",
       "46      chemical  1.506208e-03\n",
       "72          rose  1.393654e-03\n",
       "53         fruit  1.287871e-03\n",
       "49        coffee  1.230160e-03\n",
       "76    strawberry  1.195076e-03\n",
       "44        butter  1.194248e-03\n",
       "56         honey  1.150758e-03\n",
       "63         nutty  1.142368e-03\n",
       "81          tree  1.100740e-03\n",
       "79           tea  7.683649e-04\n",
       "57      lavender  7.678183e-04\n",
       "60         mango  7.545179e-04\n",
       "66          pear  7.174416e-04\n",
       "73          sage  6.552360e-04\n",
       "69     pineapple  6.047713e-04\n",
       "40       apricot  5.030568e-04\n",
       "84        violet  4.655665e-04\n",
       "78           tar  4.243337e-04\n",
       "70          plum  3.969453e-04\n",
       "39         apple  3.357634e-04\n",
       "80       tobacco  3.044163e-04\n",
       "65         peach  3.041389e-04\n",
       "47      chestnut  2.556242e-04\n",
       "42   blue cheese  2.245244e-04\n",
       "8        anxiety  1.171303e-04\n",
       "27     migraines  1.090879e-04\n",
       "13    depression  1.086599e-04\n",
       "21       fatigue  5.457546e-06\n",
       "31      seizures  4.367327e-06\n",
       "18      epilepsy  3.751446e-06\n",
       "20  eye pressure  3.486483e-06\n",
       "11     arthritis  1.456857e-06\n",
       "28          pain  1.280002e-06\n",
       "34        stress  5.800331e-07\n",
       "33    spasticity  0.000000e+00"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.set_option('display.max_rows', df_feat_ranked.shape[0]+1)\n",
    "df_feat_ranked"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/andalanputra/opt/anaconda3/lib/python3.9/site-packages/sklearn/feature_selection/_from_model.py:357: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  self.estimator_.fit(X, y, **fit_params)\n"
     ]
    }
   ],
   "source": [
    "selector = SelectFromModel(rfreg).fit(X_train1, y_train1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1.27359559e-01, 1.18041789e-01, 1.28094855e-01, 1.19393239e-01,\n",
       "       1.24665834e-01, 1.14090877e-02, 1.07825579e-02, 2.79191495e-02,\n",
       "       8.45893128e-05, 1.95978419e-03, 9.06357231e-03, 6.54614287e-06,\n",
       "       8.08877369e-03, 1.04313032e-04, 3.85709248e-03, 6.61879297e-03,\n",
       "       8.53207652e-03, 7.45443359e-03, 2.25505821e-06, 9.79262230e-03,\n",
       "       2.37147979e-06, 5.90855508e-06, 7.68551762e-03, 6.72774888e-03,\n",
       "       1.01294169e-02, 2.53459177e-03, 9.62417318e-03, 1.04199603e-04,\n",
       "       3.46509533e-06, 2.26972447e-03, 1.27692856e-02, 4.28833463e-06,\n",
       "       1.15563184e-02, 0.00000000e+00, 4.22794746e-07, 5.71016092e-03,\n",
       "       6.40019863e-03, 9.12952121e-03, 1.59672833e-03, 4.00182067e-04,\n",
       "       6.63303689e-04, 5.61819224e-03, 2.14625700e-04, 4.98632455e-03,\n",
       "       1.36914389e-03, 1.00868418e-02, 1.56173216e-03, 2.84872399e-04,\n",
       "       6.32426402e-03, 1.30723673e-03, 2.83741158e-02, 1.25700771e-02,\n",
       "       3.17115996e-03, 1.19639123e-03, 7.65895145e-03, 1.42210443e-03,\n",
       "       1.14149104e-03, 8.37642701e-04, 1.23724775e-02, 1.63128061e-03,\n",
       "       7.44107371e-04, 2.65575468e-03, 3.91942330e-03, 1.11161877e-03,\n",
       "       1.91049624e-02, 2.34879270e-04, 7.41662993e-04, 2.09225928e-03,\n",
       "       1.08253362e-02, 6.40275263e-04, 3.80824708e-04, 7.94373980e-03,\n",
       "       1.33560270e-03, 6.40354229e-04, 3.42572504e-03, 3.17848143e-03,\n",
       "       9.86219674e-04, 1.24596496e-02, 5.43678306e-04, 7.97390248e-04,\n",
       "       2.87863696e-04, 8.74490777e-04, 3.05512928e-03, 5.55294153e-03,\n",
       "       5.70767096e-04, 3.21948582e-03])"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "selector.estimator_.feature_importances_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.011627906976744186"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "selector.threshold_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "mask = selector.get_support()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ True,  True,  True,  True,  True, False, False,  True, False,\n",
       "       False, False, False, False, False, False, False, False, False,\n",
       "       False, False, False, False, False, False, False, False, False,\n",
       "       False, False, False,  True, False, False, False, False, False,\n",
       "       False, False, False, False, False, False, False, False, False,\n",
       "       False, False, False, False, False,  True,  True, False, False,\n",
       "       False, False, False, False,  True, False, False, False, False,\n",
       "       False,  True, False, False, False, False, False, False, False,\n",
       "       False, False, False, False, False,  True, False, False, False,\n",
       "       False, False, False, False, False])"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "selected_features = X.columns[mask]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>lsa_0</th>\n",
       "      <th>lsa_1</th>\n",
       "      <th>lsa_2</th>\n",
       "      <th>lsa_3</th>\n",
       "      <th>lsa_4</th>\n",
       "      <th>sativa</th>\n",
       "      <th>relaxed</th>\n",
       "      <th>diesel</th>\n",
       "      <th>earthy</th>\n",
       "      <th>lemon</th>\n",
       "      <th>orange</th>\n",
       "      <th>sweet</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.341025</td>\n",
       "      <td>0.182753</td>\n",
       "      <td>0.008214</td>\n",
       "      <td>0.140406</td>\n",
       "      <td>-0.156943</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.232158</td>\n",
       "      <td>-0.045496</td>\n",
       "      <td>0.187131</td>\n",
       "      <td>-0.000936</td>\n",
       "      <td>0.018518</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.261225</td>\n",
       "      <td>0.100324</td>\n",
       "      <td>-0.043622</td>\n",
       "      <td>0.141860</td>\n",
       "      <td>-0.034786</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.243491</td>\n",
       "      <td>0.034313</td>\n",
       "      <td>0.080290</td>\n",
       "      <td>-0.165609</td>\n",
       "      <td>0.019773</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.243491</td>\n",
       "      <td>0.034313</td>\n",
       "      <td>0.080290</td>\n",
       "      <td>-0.165609</td>\n",
       "      <td>0.019773</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>74995</th>\n",
       "      <td>0.181714</td>\n",
       "      <td>-0.045560</td>\n",
       "      <td>-0.055692</td>\n",
       "      <td>0.015649</td>\n",
       "      <td>-0.045585</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>74996</th>\n",
       "      <td>0.055494</td>\n",
       "      <td>0.003622</td>\n",
       "      <td>-0.050252</td>\n",
       "      <td>-0.024795</td>\n",
       "      <td>-0.031141</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>74997</th>\n",
       "      <td>0.055494</td>\n",
       "      <td>0.003622</td>\n",
       "      <td>-0.050252</td>\n",
       "      <td>-0.024795</td>\n",
       "      <td>-0.031141</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>74998</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>74999</th>\n",
       "      <td>0.270141</td>\n",
       "      <td>-0.004631</td>\n",
       "      <td>-0.151272</td>\n",
       "      <td>0.035538</td>\n",
       "      <td>0.083641</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>75000 rows × 12 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          lsa_0     lsa_1     lsa_2     lsa_3     lsa_4  sativa  relaxed  \\\n",
       "0      0.341025  0.182753  0.008214  0.140406 -0.156943       0        1   \n",
       "1      0.232158 -0.045496  0.187131 -0.000936  0.018518       0        1   \n",
       "2      0.261225  0.100324 -0.043622  0.141860 -0.034786       0        0   \n",
       "3      0.243491  0.034313  0.080290 -0.165609  0.019773       0        1   \n",
       "4      0.243491  0.034313  0.080290 -0.165609  0.019773       0        1   \n",
       "...         ...       ...       ...       ...       ...     ...      ...   \n",
       "74995  0.181714 -0.045560 -0.055692  0.015649 -0.045585       0        1   \n",
       "74996  0.055494  0.003622 -0.050252 -0.024795 -0.031141       0        0   \n",
       "74997  0.055494  0.003622 -0.050252 -0.024795 -0.031141       0        0   \n",
       "74998  0.000000  0.000000  0.000000  0.000000  0.000000       0        0   \n",
       "74999  0.270141 -0.004631 -0.151272  0.035538  0.083641       0        1   \n",
       "\n",
       "       diesel  earthy  lemon  orange  sweet  \n",
       "0           0       0      0       0      0  \n",
       "1           0       0      0       0      0  \n",
       "2           0       0      0       0      1  \n",
       "3           0       0      0       0      0  \n",
       "4           0       0      0       0      0  \n",
       "...       ...     ...    ...     ...    ...  \n",
       "74995       0       0      0       0      0  \n",
       "74996       0       0      0       0      0  \n",
       "74997       0       0      0       0      0  \n",
       "74998       0       0      0       0      0  \n",
       "74999       1       1      1       1      1  \n",
       "\n",
       "[75000 rows x 12 columns]"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "selected_X = df_rf[selected_features]\n",
    "selected_X"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train test split (after Feature Selection)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['selected_X_rf_lsa_elbow_thc.pkl']"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import joblib\n",
    "\n",
    "joblib.dump(selector, \"selector_rf_lsa_elbow_thc.pkl\")\n",
    "joblib.dump(selected_X, \"selected_X_rf_lsa_elbow_thc.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(selected_X, y, random_state=1, test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train1, X_val, y_train1, y_val = train_test_split(X_train, y_train, random_state=1, test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/y1/pjvjlkjn5gl846rnyzr53p340000gn/T/ipykernel_11883/3758305.py:1: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  rfreg.fit(X_train1, y_train1)\n"
     ]
    }
   ],
   "source": [
    "rfreg.fit(X_train1, y_train1)\n",
    "y_pred_rfreg = rfreg.predict(X_val)\n",
    "y_pred_rfreg_r2 = rfreg.predict(X_train1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.06341846854055548"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mean_absolute_error(y_val, y_pred_rfreg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.01384480853150437"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mean_squared_error(y_val, y_pred_rfreg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.11766396445600653"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mean_squared_error(y_val, y_pred_rfreg, squared = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9513606694724311"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#train\n",
    "r2_score(y_train1, y_pred_rfreg_r2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8314337884438647"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#val\n",
    "r2_score(y_val, y_pred_rfreg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hyperparameter Tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "parameters = { 'max_depth': [None, 10, 50, 100],\n",
    "              'max_features': ['auto', 'sqrt'],\n",
    "              'min_samples_leaf': [1, 2, 4],\n",
    "              'min_samples_split': [2, 5, 10],\n",
    "              'n_estimators': [100, 300, 500]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "rscv = RandomizedSearchCV(rfreg,  \n",
    "                     parameters,   \n",
    "                     cv=5, \n",
    "                     scoring='neg_mean_absolute_error',\n",
    "                     n_jobs= -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/andalanputra/opt/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/Users/andalanputra/opt/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/Users/andalanputra/opt/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/Users/andalanputra/opt/anaconda3/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
      "  warn(\n",
      "/Users/andalanputra/opt/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/Users/andalanputra/opt/anaconda3/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
      "  warn(\n",
      "/Users/andalanputra/opt/anaconda3/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
      "  warn(\n",
      "/Users/andalanputra/opt/anaconda3/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
      "  warn(\n",
      "/Users/andalanputra/opt/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/Users/andalanputra/opt/anaconda3/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
      "  warn(\n",
      "/Users/andalanputra/opt/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/Users/andalanputra/opt/anaconda3/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
      "  warn(\n",
      "/Users/andalanputra/opt/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/Users/andalanputra/opt/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/Users/andalanputra/opt/anaconda3/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
      "  warn(\n",
      "/Users/andalanputra/opt/anaconda3/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
      "  warn(\n",
      "/Users/andalanputra/opt/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/Users/andalanputra/opt/anaconda3/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
      "  warn(\n",
      "/Users/andalanputra/opt/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/Users/andalanputra/opt/anaconda3/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
      "  warn(\n",
      "/Users/andalanputra/opt/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/Users/andalanputra/opt/anaconda3/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
      "  warn(\n",
      "/Users/andalanputra/opt/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/Users/andalanputra/opt/anaconda3/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
      "  warn(\n",
      "/Users/andalanputra/opt/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/Users/andalanputra/opt/anaconda3/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
      "  warn(\n",
      "/Users/andalanputra/opt/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/Users/andalanputra/opt/anaconda3/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
      "  warn(\n",
      "/Users/andalanputra/opt/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/Users/andalanputra/opt/anaconda3/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
      "  warn(\n",
      "/Users/andalanputra/opt/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/Users/andalanputra/opt/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/Users/andalanputra/opt/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/Users/andalanputra/opt/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/Users/andalanputra/opt/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/Users/andalanputra/opt/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/Users/andalanputra/opt/anaconda3/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
      "  warn(\n",
      "/Users/andalanputra/opt/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/Users/andalanputra/opt/anaconda3/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
      "  warn(\n",
      "/Users/andalanputra/opt/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/Users/andalanputra/opt/anaconda3/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
      "  warn(\n",
      "/Users/andalanputra/opt/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/Users/andalanputra/opt/anaconda3/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
      "  warn(\n",
      "/Users/andalanputra/opt/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/Users/andalanputra/opt/anaconda3/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
      "  warn(\n",
      "/Users/andalanputra/opt/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/Users/andalanputra/opt/anaconda3/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
      "  warn(\n",
      "/Users/andalanputra/opt/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/Users/andalanputra/opt/anaconda3/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
      "  warn(\n",
      "/Users/andalanputra/opt/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/Users/andalanputra/opt/anaconda3/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
      "  warn(\n",
      "/Users/andalanputra/opt/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/Users/andalanputra/opt/anaconda3/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
      "  warn(\n",
      "/Users/andalanputra/opt/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/Users/andalanputra/opt/anaconda3/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
      "  warn(\n",
      "/Users/andalanputra/opt/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/Users/andalanputra/opt/anaconda3/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
      "  warn(\n",
      "/Users/andalanputra/opt/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/Users/andalanputra/opt/anaconda3/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
      "  warn(\n",
      "/Users/andalanputra/opt/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/Users/andalanputra/opt/anaconda3/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
      "  warn(\n",
      "/Users/andalanputra/opt/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/Users/andalanputra/opt/anaconda3/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
      "  warn(\n",
      "/Users/andalanputra/opt/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/Users/andalanputra/opt/anaconda3/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
      "  warn(\n",
      "/Users/andalanputra/opt/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/Users/andalanputra/opt/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/Users/andalanputra/opt/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/Users/andalanputra/opt/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/Users/andalanputra/opt/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/Users/andalanputra/opt/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/Users/andalanputra/opt/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/Users/andalanputra/opt/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/Users/andalanputra/opt/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/Users/andalanputra/opt/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/Users/andalanputra/opt/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/Users/andalanputra/opt/anaconda3/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
      "  warn(\n",
      "/Users/andalanputra/opt/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/Users/andalanputra/opt/anaconda3/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
      "  warn(\n",
      "/Users/andalanputra/opt/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/Users/andalanputra/opt/anaconda3/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
      "  warn(\n",
      "/Users/andalanputra/opt/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/Users/andalanputra/opt/anaconda3/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
      "  warn(\n",
      "/Users/andalanputra/opt/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/Users/andalanputra/opt/anaconda3/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
      "  warn(\n",
      "/Users/andalanputra/opt/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_search.py:909: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  self.best_estimator_.fit(X, y, **fit_params)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-2 {color: black;background-color: white;}#sk-container-id-2 pre{padding: 0;}#sk-container-id-2 div.sk-toggleable {background-color: white;}#sk-container-id-2 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-2 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-2 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-2 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-2 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-2 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-2 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-2 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-2 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-2 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-2 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-2 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-2 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-2 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-2 div.sk-item {position: relative;z-index: 1;}#sk-container-id-2 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-2 div.sk-item::before, #sk-container-id-2 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-2 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-2 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-2 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-2 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-2 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-2 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-2 div.sk-label-container {text-align: center;}#sk-container-id-2 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-2 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-2\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>RandomizedSearchCV(cv=5, estimator=RandomForestRegressor(n_jobs=-1), n_jobs=-1,\n",
       "                   param_distributions={&#x27;max_depth&#x27;: [None, 10, 50, 100],\n",
       "                                        &#x27;max_features&#x27;: [&#x27;auto&#x27;, &#x27;sqrt&#x27;],\n",
       "                                        &#x27;min_samples_leaf&#x27;: [1, 2, 4],\n",
       "                                        &#x27;min_samples_split&#x27;: [2, 5, 10],\n",
       "                                        &#x27;n_estimators&#x27;: [100, 300, 500]},\n",
       "                   scoring=&#x27;neg_mean_absolute_error&#x27;)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" ><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">RandomizedSearchCV</label><div class=\"sk-toggleable__content\"><pre>RandomizedSearchCV(cv=5, estimator=RandomForestRegressor(n_jobs=-1), n_jobs=-1,\n",
       "                   param_distributions={&#x27;max_depth&#x27;: [None, 10, 50, 100],\n",
       "                                        &#x27;max_features&#x27;: [&#x27;auto&#x27;, &#x27;sqrt&#x27;],\n",
       "                                        &#x27;min_samples_leaf&#x27;: [1, 2, 4],\n",
       "                                        &#x27;min_samples_split&#x27;: [2, 5, 10],\n",
       "                                        &#x27;n_estimators&#x27;: [100, 300, 500]},\n",
       "                   scoring=&#x27;neg_mean_absolute_error&#x27;)</pre></div></div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-3\" type=\"checkbox\" ><label for=\"sk-estimator-id-3\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">estimator: RandomForestRegressor</label><div class=\"sk-toggleable__content\"><pre>RandomForestRegressor(n_jobs=-1)</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-4\" type=\"checkbox\" ><label for=\"sk-estimator-id-4\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">RandomForestRegressor</label><div class=\"sk-toggleable__content\"><pre>RandomForestRegressor(n_jobs=-1)</pre></div></div></div></div></div></div></div></div></div></div>"
      ],
      "text/plain": [
       "RandomizedSearchCV(cv=5, estimator=RandomForestRegressor(n_jobs=-1), n_jobs=-1,\n",
       "                   param_distributions={'max_depth': [None, 10, 50, 100],\n",
       "                                        'max_features': ['auto', 'sqrt'],\n",
       "                                        'min_samples_leaf': [1, 2, 4],\n",
       "                                        'min_samples_split': [2, 5, 10],\n",
       "                                        'n_estimators': [100, 300, 500]},\n",
       "                   scoring='neg_mean_absolute_error')"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rscv.fit(X_train1, y_train1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'n_estimators': 100,\n",
       " 'min_samples_split': 2,\n",
       " 'min_samples_leaf': 1,\n",
       " 'max_features': 'sqrt',\n",
       " 'max_depth': 50}"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rscv.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['rscv_rf_lsa_elbow_best_params_thc.pkl']"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "joblib.dump(rscv, \"rscv_rf_lsa_elbow_thc.pkl\")\n",
    "joblib.dump(rscv.best_params_, \"rscv_rf_lsa_elbow_best_params_thc.pkl\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "RF (after Hyperparameter Tuning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/y1/pjvjlkjn5gl846rnyzr53p340000gn/T/ipykernel_11883/2143269374.py:2: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  rfreg_ht.fit(X_train1, y_train1)\n"
     ]
    }
   ],
   "source": [
    "rfreg_ht = RandomForestRegressor(n_estimators = 100, min_samples_split = 2, max_features = 'sqrt', min_samples_leaf = 1, max_depth = 50)\n",
    "rfreg_ht.fit(X_train1, y_train1)\n",
    "y_pred_rfreg = rfreg_ht.predict(X_val)\n",
    "y_pred_rfreg_r2 = rfreg_ht.predict(X_train1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0632013608952759"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mean_absolute_error(y_val, y_pred_rfreg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.01350104018206182"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mean_squared_error(y_val, y_pred_rfreg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.11619397653089346"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mean_squared_error(y_val, y_pred_rfreg, squared = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9518964892116502"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#train\n",
    "r2_score(y_train1, y_pred_rfreg_r2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.835619308827666"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#val\n",
    "r2_score(y_val, y_pred_rfreg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Residual plots after Hyperparameter Tuning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Predicting model on the test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_rfreg_test = rfreg_ht.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['y_test_rfreg_lsa_elbow_thc.pkl']"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "joblib.dump(y_pred_rfreg_test, \"y_pred_rfreg_test_lsa_elbow_thc.pkl\")\n",
    "joblib.dump(y_test, \"y_test_rfreg_lsa_elbow_thc.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.06099702451049167"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mean_absolute_error(y_test, y_pred_rfreg_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.012845422894384872"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mean_squared_error(y_test, y_pred_rfreg_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.11333764994204208"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mean_squared_error(y_test, y_pred_rfreg_test, squared = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8439008786658198"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "r2_score(y_test, y_pred_rfreg_test)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Error analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 576x432 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 432x288 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# assume y_pred is a numpy array and y_true is a pandas dataframe\n",
    "fig, ax = plt.subplots(figsize=(8, 6))\n",
    "\n",
    "column = \"X..Delta9-THC\"  # specify the target variable name\n",
    "ax.hist(y_pred_rfreg_test, alpha=0.5, label='y_pred', bins=20)\n",
    "ax.hist(y_test[column], alpha=0.5, label='y_true', bins=20)\n",
    "ax.legend(loc='upper right')\n",
    "ax.set_title(column)\n",
    "\n",
    "plt.show()\n",
    "plt.savefig('error_hist_rf_lsa_elbow_thc.png')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pearson R"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pearson correlation coefficient: 0.921\n",
      "P-value: 0.000\n"
     ]
    }
   ],
   "source": [
    "corr_coef, p_value = pearsonr(y_pred_rfreg_test.flatten(), y_test.values.ravel())\n",
    "\n",
    "print(f\"Pearson correlation coefficient: {corr_coef:.3f}\")\n",
    "print(f\"P-value: {p_value:.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:>"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "corr_matrix = y_test.corr()\n",
    "sns.heatmap(corr_matrix, annot=True, cmap='coolwarm', center=0)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
