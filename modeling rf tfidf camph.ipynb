{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn import preprocessing\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.neural_network import MLPRegressor\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "from sklearn.metrics import r2_score\n",
    "from scipy.stats import pearsonr\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.feature_selection import SelectFromModel\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compiling complete dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_rf = pd.read_csv(\"df_camph_tfidf.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['index',\n",
       " 'tfidf_0',\n",
       " 'tfidf_1',\n",
       " 'tfidf_2',\n",
       " 'tfidf_3',\n",
       " 'tfidf_4',\n",
       " 'tfidf_5',\n",
       " 'tfidf_6',\n",
       " 'tfidf_7',\n",
       " 'tfidf_8',\n",
       " 'tfidf_9',\n",
       " 'tfidf_10',\n",
       " 'tfidf_11',\n",
       " 'tfidf_12',\n",
       " 'tfidf_13',\n",
       " 'tfidf_14',\n",
       " 'tfidf_15',\n",
       " 'tfidf_16',\n",
       " 'tfidf_17',\n",
       " 'tfidf_18',\n",
       " 'tfidf_19',\n",
       " 'tfidf_20',\n",
       " 'tfidf_21',\n",
       " 'tfidf_22',\n",
       " 'tfidf_23',\n",
       " 'tfidf_24',\n",
       " 'tfidf_25',\n",
       " 'tfidf_26',\n",
       " 'tfidf_27',\n",
       " 'tfidf_28',\n",
       " 'tfidf_29',\n",
       " 'tfidf_30',\n",
       " 'tfidf_31',\n",
       " 'tfidf_32',\n",
       " 'tfidf_33',\n",
       " 'tfidf_34',\n",
       " 'tfidf_35',\n",
       " 'tfidf_36',\n",
       " 'tfidf_37',\n",
       " 'tfidf_38',\n",
       " 'tfidf_39',\n",
       " 'tfidf_40',\n",
       " 'tfidf_41',\n",
       " 'tfidf_42',\n",
       " 'tfidf_43',\n",
       " 'tfidf_44',\n",
       " 'tfidf_45',\n",
       " 'tfidf_46',\n",
       " 'tfidf_47',\n",
       " 'tfidf_48',\n",
       " 'tfidf_49',\n",
       " 'tfidf_50',\n",
       " 'tfidf_51',\n",
       " 'tfidf_52',\n",
       " 'tfidf_53',\n",
       " 'tfidf_54',\n",
       " 'tfidf_55',\n",
       " 'tfidf_56',\n",
       " 'tfidf_57',\n",
       " 'tfidf_58',\n",
       " 'tfidf_59',\n",
       " 'tfidf_60',\n",
       " 'tfidf_61',\n",
       " 'tfidf_62',\n",
       " 'tfidf_63',\n",
       " 'tfidf_64',\n",
       " 'tfidf_65',\n",
       " 'tfidf_66',\n",
       " 'tfidf_67',\n",
       " 'tfidf_68',\n",
       " 'tfidf_69',\n",
       " 'tfidf_70',\n",
       " 'tfidf_71',\n",
       " 'tfidf_72',\n",
       " 'tfidf_73',\n",
       " 'tfidf_74',\n",
       " 'tfidf_75',\n",
       " 'tfidf_76',\n",
       " 'tfidf_77',\n",
       " 'tfidf_78',\n",
       " 'tfidf_79',\n",
       " 'tfidf_80',\n",
       " 'tfidf_81',\n",
       " 'tfidf_82',\n",
       " 'tfidf_83',\n",
       " 'tfidf_84',\n",
       " 'tfidf_85',\n",
       " 'tfidf_86',\n",
       " 'tfidf_87',\n",
       " 'tfidf_88',\n",
       " 'tfidf_89',\n",
       " 'tfidf_90',\n",
       " 'tfidf_91',\n",
       " 'tfidf_92',\n",
       " 'tfidf_93',\n",
       " 'tfidf_94',\n",
       " 'tfidf_95',\n",
       " 'tfidf_96',\n",
       " 'tfidf_97',\n",
       " 'tfidf_98',\n",
       " 'tfidf_99',\n",
       " 'tfidf_100',\n",
       " 'tfidf_101',\n",
       " 'tfidf_102',\n",
       " 'tfidf_103',\n",
       " 'tfidf_104',\n",
       " 'tfidf_105',\n",
       " 'tfidf_106',\n",
       " 'tfidf_107',\n",
       " 'tfidf_108',\n",
       " 'tfidf_109',\n",
       " 'tfidf_110',\n",
       " 'tfidf_111',\n",
       " 'tfidf_112',\n",
       " 'tfidf_113',\n",
       " 'tfidf_114',\n",
       " 'tfidf_115',\n",
       " 'tfidf_116',\n",
       " 'tfidf_117',\n",
       " 'tfidf_118',\n",
       " 'tfidf_119',\n",
       " 'tfidf_120',\n",
       " 'tfidf_121',\n",
       " 'tfidf_122',\n",
       " 'tfidf_123',\n",
       " 'tfidf_124',\n",
       " 'tfidf_125',\n",
       " 'tfidf_126',\n",
       " 'tfidf_127',\n",
       " 'tfidf_128',\n",
       " 'tfidf_129',\n",
       " 'tfidf_130',\n",
       " 'tfidf_131',\n",
       " 'tfidf_132',\n",
       " 'tfidf_133',\n",
       " 'tfidf_134',\n",
       " 'tfidf_135',\n",
       " 'tfidf_136',\n",
       " 'tfidf_137',\n",
       " 'tfidf_138',\n",
       " 'tfidf_139',\n",
       " 'tfidf_140',\n",
       " 'tfidf_141',\n",
       " 'tfidf_142',\n",
       " 'tfidf_143',\n",
       " 'tfidf_144',\n",
       " 'tfidf_145',\n",
       " 'tfidf_146',\n",
       " 'tfidf_147',\n",
       " 'tfidf_148',\n",
       " 'tfidf_149',\n",
       " 'tfidf_150',\n",
       " 'tfidf_151',\n",
       " 'tfidf_152',\n",
       " 'tfidf_153',\n",
       " 'tfidf_154',\n",
       " 'tfidf_155',\n",
       " 'tfidf_156',\n",
       " 'tfidf_157',\n",
       " 'tfidf_158',\n",
       " 'tfidf_159',\n",
       " 'tfidf_160',\n",
       " 'tfidf_161',\n",
       " 'tfidf_162',\n",
       " 'tfidf_163',\n",
       " 'tfidf_164',\n",
       " 'tfidf_165',\n",
       " 'tfidf_166',\n",
       " 'tfidf_167',\n",
       " 'tfidf_168',\n",
       " 'tfidf_169',\n",
       " 'tfidf_170',\n",
       " 'tfidf_171',\n",
       " 'tfidf_172',\n",
       " 'tfidf_173',\n",
       " 'tfidf_174',\n",
       " 'tfidf_175',\n",
       " 'tfidf_176',\n",
       " 'tfidf_177',\n",
       " 'tfidf_178',\n",
       " 'tfidf_179',\n",
       " 'tfidf_180',\n",
       " 'tfidf_181',\n",
       " 'tfidf_182',\n",
       " 'tfidf_183',\n",
       " 'tfidf_184',\n",
       " 'tfidf_185',\n",
       " 'tfidf_186',\n",
       " 'tfidf_187',\n",
       " 'tfidf_188',\n",
       " 'tfidf_189',\n",
       " 'tfidf_190',\n",
       " 'tfidf_191',\n",
       " 'tfidf_192',\n",
       " 'tfidf_193',\n",
       " 'tfidf_194',\n",
       " 'tfidf_195',\n",
       " 'tfidf_196',\n",
       " 'tfidf_197',\n",
       " 'tfidf_198',\n",
       " 'tfidf_199',\n",
       " 'tfidf_200',\n",
       " 'tfidf_201',\n",
       " 'tfidf_202',\n",
       " 'tfidf_203',\n",
       " 'tfidf_204',\n",
       " 'tfidf_205',\n",
       " 'tfidf_206',\n",
       " 'tfidf_207',\n",
       " 'tfidf_208',\n",
       " 'tfidf_209',\n",
       " 'tfidf_210',\n",
       " 'tfidf_211',\n",
       " 'tfidf_212',\n",
       " 'tfidf_213',\n",
       " 'tfidf_214',\n",
       " 'tfidf_215',\n",
       " 'tfidf_216',\n",
       " 'tfidf_217',\n",
       " 'tfidf_218',\n",
       " 'tfidf_219',\n",
       " 'tfidf_220',\n",
       " 'tfidf_221',\n",
       " 'tfidf_222',\n",
       " 'tfidf_223',\n",
       " 'tfidf_224',\n",
       " 'tfidf_225',\n",
       " 'tfidf_226',\n",
       " 'tfidf_227',\n",
       " 'tfidf_228',\n",
       " 'tfidf_229',\n",
       " 'tfidf_230',\n",
       " 'tfidf_231',\n",
       " 'tfidf_232',\n",
       " 'tfidf_233',\n",
       " 'tfidf_234',\n",
       " 'tfidf_235',\n",
       " 'tfidf_236',\n",
       " 'tfidf_237',\n",
       " 'tfidf_238',\n",
       " 'tfidf_239',\n",
       " 'tfidf_240',\n",
       " 'tfidf_241',\n",
       " 'tfidf_242',\n",
       " 'tfidf_243',\n",
       " 'tfidf_244',\n",
       " 'tfidf_245',\n",
       " 'tfidf_246',\n",
       " 'tfidf_247',\n",
       " 'tfidf_248',\n",
       " 'tfidf_249',\n",
       " 'tfidf_250',\n",
       " 'tfidf_251',\n",
       " 'tfidf_252',\n",
       " 'tfidf_253',\n",
       " 'tfidf_254',\n",
       " 'tfidf_255',\n",
       " 'tfidf_256',\n",
       " 'tfidf_257',\n",
       " 'tfidf_258',\n",
       " 'tfidf_259',\n",
       " 'tfidf_260',\n",
       " 'tfidf_261',\n",
       " 'tfidf_262',\n",
       " 'tfidf_263',\n",
       " 'tfidf_264',\n",
       " 'tfidf_265',\n",
       " 'tfidf_266',\n",
       " 'tfidf_267',\n",
       " 'tfidf_268',\n",
       " 'tfidf_269',\n",
       " 'tfidf_270',\n",
       " 'tfidf_271',\n",
       " 'tfidf_272',\n",
       " 'tfidf_273',\n",
       " 'tfidf_274',\n",
       " 'tfidf_275',\n",
       " 'tfidf_276',\n",
       " 'tfidf_277',\n",
       " 'tfidf_278',\n",
       " 'tfidf_279',\n",
       " 'tfidf_280',\n",
       " 'tfidf_281',\n",
       " 'tfidf_282',\n",
       " 'tfidf_283',\n",
       " 'tfidf_284',\n",
       " 'tfidf_285',\n",
       " 'tfidf_286',\n",
       " 'tfidf_287',\n",
       " 'tfidf_288',\n",
       " 'tfidf_289',\n",
       " 'tfidf_290',\n",
       " 'tfidf_291',\n",
       " 'tfidf_292',\n",
       " 'tfidf_293',\n",
       " 'tfidf_294',\n",
       " 'tfidf_295',\n",
       " 'tfidf_296',\n",
       " 'tfidf_297',\n",
       " 'tfidf_298',\n",
       " 'tfidf_299',\n",
       " 'tfidf_300',\n",
       " 'tfidf_301',\n",
       " 'tfidf_302',\n",
       " 'tfidf_303',\n",
       " 'tfidf_304',\n",
       " 'tfidf_305',\n",
       " 'tfidf_306',\n",
       " 'tfidf_307',\n",
       " 'tfidf_308',\n",
       " 'tfidf_309',\n",
       " 'tfidf_310',\n",
       " 'tfidf_311',\n",
       " 'tfidf_312',\n",
       " 'tfidf_313',\n",
       " 'tfidf_314',\n",
       " 'tfidf_315',\n",
       " 'tfidf_316',\n",
       " 'tfidf_317',\n",
       " 'tfidf_318',\n",
       " 'tfidf_319',\n",
       " 'tfidf_320',\n",
       " 'tfidf_321',\n",
       " 'tfidf_322',\n",
       " 'tfidf_323',\n",
       " 'tfidf_324',\n",
       " 'tfidf_325',\n",
       " 'tfidf_326',\n",
       " 'tfidf_327',\n",
       " 'tfidf_328',\n",
       " 'tfidf_329',\n",
       " 'tfidf_330',\n",
       " 'tfidf_331',\n",
       " 'tfidf_332',\n",
       " 'tfidf_333',\n",
       " 'tfidf_334',\n",
       " 'tfidf_335',\n",
       " 'tfidf_336',\n",
       " 'tfidf_337',\n",
       " 'tfidf_338',\n",
       " 'tfidf_339',\n",
       " 'tfidf_340',\n",
       " 'tfidf_341',\n",
       " 'tfidf_342',\n",
       " 'tfidf_343',\n",
       " 'tfidf_344',\n",
       " 'tfidf_345',\n",
       " 'tfidf_346',\n",
       " 'tfidf_347',\n",
       " 'tfidf_348',\n",
       " 'tfidf_349',\n",
       " 'tfidf_350',\n",
       " 'tfidf_351',\n",
       " 'tfidf_352',\n",
       " 'tfidf_353',\n",
       " 'tfidf_354',\n",
       " 'tfidf_355',\n",
       " 'tfidf_356',\n",
       " 'tfidf_357',\n",
       " 'tfidf_358',\n",
       " 'tfidf_359',\n",
       " 'tfidf_360',\n",
       " 'tfidf_361',\n",
       " 'tfidf_362',\n",
       " 'tfidf_363',\n",
       " 'tfidf_364',\n",
       " 'tfidf_365',\n",
       " 'tfidf_366',\n",
       " 'tfidf_367',\n",
       " 'tfidf_368',\n",
       " 'tfidf_369',\n",
       " 'tfidf_370',\n",
       " 'tfidf_371',\n",
       " 'tfidf_372',\n",
       " 'tfidf_373',\n",
       " 'tfidf_374',\n",
       " 'tfidf_375',\n",
       " 'tfidf_376',\n",
       " 'tfidf_377',\n",
       " 'tfidf_378',\n",
       " 'tfidf_379',\n",
       " 'tfidf_380',\n",
       " 'tfidf_381',\n",
       " 'tfidf_382',\n",
       " 'tfidf_383',\n",
       " 'tfidf_384',\n",
       " 'tfidf_385',\n",
       " 'tfidf_386',\n",
       " 'tfidf_387',\n",
       " 'hybrid',\n",
       " 'indica',\n",
       " 'sativa',\n",
       " 'anxiety',\n",
       " 'anxious',\n",
       " 'aroused',\n",
       " 'arthritis',\n",
       " 'creative',\n",
       " 'depression',\n",
       " 'dizzy',\n",
       " 'dry eyes',\n",
       " 'dry mouth',\n",
       " 'energetic',\n",
       " 'epilepsy',\n",
       " 'euphoric',\n",
       " 'eye pressure',\n",
       " 'fatigue',\n",
       " 'focused',\n",
       " 'giggly',\n",
       " 'happy',\n",
       " 'headache',\n",
       " 'hungry',\n",
       " 'migraines',\n",
       " 'pain',\n",
       " 'paranoid',\n",
       " 'relaxed',\n",
       " 'seizures',\n",
       " 'sleepy',\n",
       " 'spasticity',\n",
       " 'stress',\n",
       " 'talkative',\n",
       " 'tingly',\n",
       " 'uplifted',\n",
       " 'ammonia',\n",
       " 'apple',\n",
       " 'apricot',\n",
       " 'berry',\n",
       " 'blue cheese',\n",
       " 'blueberry',\n",
       " 'butter',\n",
       " 'cheese',\n",
       " 'chemical',\n",
       " 'chestnut',\n",
       " 'citrus',\n",
       " 'coffee',\n",
       " 'diesel',\n",
       " 'earthy',\n",
       " 'flowery',\n",
       " 'fruit',\n",
       " 'grape',\n",
       " 'grapefruit',\n",
       " 'honey',\n",
       " 'lavender',\n",
       " 'lemon',\n",
       " 'lime',\n",
       " 'mango',\n",
       " 'menthol',\n",
       " 'mint',\n",
       " 'nutty',\n",
       " 'orange',\n",
       " 'peach',\n",
       " 'pear',\n",
       " 'pepper',\n",
       " 'pine',\n",
       " 'pineapple',\n",
       " 'plum',\n",
       " 'pungent',\n",
       " 'rose',\n",
       " 'sage',\n",
       " 'skunk',\n",
       " 'spicy/herbal',\n",
       " 'strawberry',\n",
       " 'sweet',\n",
       " 'tar',\n",
       " 'tea',\n",
       " 'tobacco',\n",
       " 'tree',\n",
       " 'tropical',\n",
       " 'vanilla',\n",
       " 'violet',\n",
       " 'woody',\n",
       " 'X..Camphene']"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_rf.columns.to_list()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Splitting dependent and independent variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df_rf.drop(['index', 'X..Camphene'], axis = 1)\n",
    "y = df_rf[['X..Camphene']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plotting histograms on target variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.22222222],\n",
       "       [0.22222222],\n",
       "       [0.22222222],\n",
       "       ...,\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ]])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_array = y.to_numpy()\n",
    "y_array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Axes: ylabel='Count'>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "sns.histplot(y, bins = 10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train test split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=1, test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train1, X_val, y_train1, y_val = train_test_split(X_train, y_train, random_state=1, test_size=0.25)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "RF modeling (before Feature selection and Hyperparameter Tuning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/ns/m5pnr0211w91v02hpv22958m0000gn/T/ipykernel_87881/350139188.py:2: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  rfreg.fit(X_train1, y_train1)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;background-color: white;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>RandomForestRegressor()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">RandomForestRegressor</label><div class=\"sk-toggleable__content\"><pre>RandomForestRegressor()</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "RandomForestRegressor()"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rfreg = RandomForestRegressor()\n",
    "rfreg.fit(X_train1, y_train1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_rfreg = rfreg.predict(X_val)\n",
    "y_pred_rfreg_r2 = rfreg.predict(X_train1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.05669104344838087"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mean_absolute_error(y_val, y_pred_rfreg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.012676028087908577"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mean_squared_error(y_val, y_pred_rfreg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.1125878682980923"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mean_squared_error(y_val, y_pred_rfreg, squared = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9765922340100872"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#train\n",
    "r2_score(y_train1, y_pred_rfreg_r2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8856260529611186"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#val\n",
    "r2_score(y_val, y_pred_rfreg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Residual plots for each target variable"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Feature Selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_feat = pd.DataFrame({\n",
    "    \"features\": X_train1.columns,\n",
    "    \"score\": rfreg.feature_importances_\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>features</th>\n",
       "      <th>score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>tfidf_0</td>\n",
       "      <td>0.001680</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>tfidf_1</td>\n",
       "      <td>0.000678</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>tfidf_2</td>\n",
       "      <td>0.000528</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>tfidf_3</td>\n",
       "      <td>0.000266</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>tfidf_4</td>\n",
       "      <td>0.001483</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>464</th>\n",
       "      <td>tree</td>\n",
       "      <td>0.000479</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>465</th>\n",
       "      <td>tropical</td>\n",
       "      <td>0.001400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>466</th>\n",
       "      <td>vanilla</td>\n",
       "      <td>0.002714</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>467</th>\n",
       "      <td>violet</td>\n",
       "      <td>0.000083</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>468</th>\n",
       "      <td>woody</td>\n",
       "      <td>0.001680</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>469 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     features     score\n",
       "0     tfidf_0  0.001680\n",
       "1     tfidf_1  0.000678\n",
       "2     tfidf_2  0.000528\n",
       "3     tfidf_3  0.000266\n",
       "4     tfidf_4  0.001483\n",
       "..        ...       ...\n",
       "464      tree  0.000479\n",
       "465  tropical  0.001400\n",
       "466   vanilla  0.002714\n",
       "467    violet  0.000083\n",
       "468     woody  0.001680\n",
       "\n",
       "[469 rows x 2 columns]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_feat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_feat_ranked = df_feat.sort_values(\"score\", ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>features</th>\n",
       "      <th>score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>433</th>\n",
       "      <td>diesel</td>\n",
       "      <td>1.557018e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>443</th>\n",
       "      <td>mango</td>\n",
       "      <td>5.092749e-02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>390</th>\n",
       "      <td>sativa</td>\n",
       "      <td>2.885505e-02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>388</th>\n",
       "      <td>hybrid</td>\n",
       "      <td>2.644686e-02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>426</th>\n",
       "      <td>blueberry</td>\n",
       "      <td>1.983689e-02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>389</th>\n",
       "      <td>indica</td>\n",
       "      <td>1.673876e-02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>272</th>\n",
       "      <td>tfidf_272</td>\n",
       "      <td>1.486275e-02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>141</th>\n",
       "      <td>tfidf_141</td>\n",
       "      <td>1.425407e-02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>329</th>\n",
       "      <td>tfidf_329</td>\n",
       "      <td>1.355326e-02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>431</th>\n",
       "      <td>citrus</td>\n",
       "      <td>1.081232e-02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>168</th>\n",
       "      <td>tfidf_168</td>\n",
       "      <td>1.072228e-02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>345</th>\n",
       "      <td>tfidf_345</td>\n",
       "      <td>1.071238e-02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>149</th>\n",
       "      <td>tfidf_149</td>\n",
       "      <td>9.456866e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>145</th>\n",
       "      <td>tfidf_145</td>\n",
       "      <td>9.381184e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>459</th>\n",
       "      <td>strawberry</td>\n",
       "      <td>8.791444e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>239</th>\n",
       "      <td>tfidf_239</td>\n",
       "      <td>8.184002e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>437</th>\n",
       "      <td>grape</td>\n",
       "      <td>7.450607e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>312</th>\n",
       "      <td>tfidf_312</td>\n",
       "      <td>7.398193e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>357</th>\n",
       "      <td>tfidf_357</td>\n",
       "      <td>6.717043e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>285</th>\n",
       "      <td>tfidf_285</td>\n",
       "      <td>6.224752e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>253</th>\n",
       "      <td>tfidf_253</td>\n",
       "      <td>5.910649e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>309</th>\n",
       "      <td>tfidf_309</td>\n",
       "      <td>5.863109e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>207</th>\n",
       "      <td>tfidf_207</td>\n",
       "      <td>5.831222e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>199</th>\n",
       "      <td>tfidf_199</td>\n",
       "      <td>5.616585e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>tfidf_7</td>\n",
       "      <td>5.578498e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>434</th>\n",
       "      <td>earthy</td>\n",
       "      <td>5.438159e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>281</th>\n",
       "      <td>tfidf_281</td>\n",
       "      <td>5.400202e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>tfidf_30</td>\n",
       "      <td>5.360040e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>441</th>\n",
       "      <td>lemon</td>\n",
       "      <td>5.044943e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>162</th>\n",
       "      <td>tfidf_162</td>\n",
       "      <td>4.856184e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>196</th>\n",
       "      <td>tfidf_196</td>\n",
       "      <td>4.830943e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>400</th>\n",
       "      <td>energetic</td>\n",
       "      <td>4.805606e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>245</th>\n",
       "      <td>tfidf_245</td>\n",
       "      <td>4.711933e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>325</th>\n",
       "      <td>tfidf_325</td>\n",
       "      <td>4.703153e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>230</th>\n",
       "      <td>tfidf_230</td>\n",
       "      <td>4.443127e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>399</th>\n",
       "      <td>dry mouth</td>\n",
       "      <td>4.390081e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>121</th>\n",
       "      <td>tfidf_121</td>\n",
       "      <td>4.280813e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>424</th>\n",
       "      <td>berry</td>\n",
       "      <td>4.115724e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>tfidf_37</td>\n",
       "      <td>4.110179e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>210</th>\n",
       "      <td>tfidf_210</td>\n",
       "      <td>3.882792e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>93</th>\n",
       "      <td>tfidf_93</td>\n",
       "      <td>3.874828e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>151</th>\n",
       "      <td>tfidf_151</td>\n",
       "      <td>3.838046e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>429</th>\n",
       "      <td>chemical</td>\n",
       "      <td>3.804599e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>413</th>\n",
       "      <td>relaxed</td>\n",
       "      <td>3.777501e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>458</th>\n",
       "      <td>spicy/herbal</td>\n",
       "      <td>3.776995e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>428</th>\n",
       "      <td>cheese</td>\n",
       "      <td>3.691412e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>128</th>\n",
       "      <td>tfidf_128</td>\n",
       "      <td>3.664054e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>205</th>\n",
       "      <td>tfidf_205</td>\n",
       "      <td>3.593225e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>tfidf_11</td>\n",
       "      <td>3.550774e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>407</th>\n",
       "      <td>happy</td>\n",
       "      <td>3.513907e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>111</th>\n",
       "      <td>tfidf_111</td>\n",
       "      <td>3.469634e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>tfidf_98</td>\n",
       "      <td>3.460486e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>78</th>\n",
       "      <td>tfidf_78</td>\n",
       "      <td>3.363012e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>457</th>\n",
       "      <td>skunk</td>\n",
       "      <td>3.354802e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>tfidf_43</td>\n",
       "      <td>3.333806e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>263</th>\n",
       "      <td>tfidf_263</td>\n",
       "      <td>3.319770e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>273</th>\n",
       "      <td>tfidf_273</td>\n",
       "      <td>3.311840e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>366</th>\n",
       "      <td>tfidf_366</td>\n",
       "      <td>3.283322e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>460</th>\n",
       "      <td>sweet</td>\n",
       "      <td>3.257280e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>402</th>\n",
       "      <td>euphoric</td>\n",
       "      <td>3.133910e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>319</th>\n",
       "      <td>tfidf_319</td>\n",
       "      <td>3.125429e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>409</th>\n",
       "      <td>hungry</td>\n",
       "      <td>3.088334e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>158</th>\n",
       "      <td>tfidf_158</td>\n",
       "      <td>3.079402e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>445</th>\n",
       "      <td>mint</td>\n",
       "      <td>3.078735e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>420</th>\n",
       "      <td>uplifted</td>\n",
       "      <td>3.057867e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>349</th>\n",
       "      <td>tfidf_349</td>\n",
       "      <td>3.049951e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>337</th>\n",
       "      <td>tfidf_337</td>\n",
       "      <td>3.023161e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>tfidf_26</td>\n",
       "      <td>3.001940e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>144</th>\n",
       "      <td>tfidf_144</td>\n",
       "      <td>2.981062e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>tfidf_39</td>\n",
       "      <td>2.930448e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>236</th>\n",
       "      <td>tfidf_236</td>\n",
       "      <td>2.888760e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>362</th>\n",
       "      <td>tfidf_362</td>\n",
       "      <td>2.872226e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>314</th>\n",
       "      <td>tfidf_314</td>\n",
       "      <td>2.866305e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>119</th>\n",
       "      <td>tfidf_119</td>\n",
       "      <td>2.753660e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>466</th>\n",
       "      <td>vanilla</td>\n",
       "      <td>2.714035e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>374</th>\n",
       "      <td>tfidf_374</td>\n",
       "      <td>2.677493e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>167</th>\n",
       "      <td>tfidf_167</td>\n",
       "      <td>2.667748e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>tfidf_6</td>\n",
       "      <td>2.666065e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>304</th>\n",
       "      <td>tfidf_304</td>\n",
       "      <td>2.631683e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>258</th>\n",
       "      <td>tfidf_258</td>\n",
       "      <td>2.629831e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>240</th>\n",
       "      <td>tfidf_240</td>\n",
       "      <td>2.538534e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>340</th>\n",
       "      <td>tfidf_340</td>\n",
       "      <td>2.536389e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>tfidf_48</td>\n",
       "      <td>2.517944e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>342</th>\n",
       "      <td>tfidf_342</td>\n",
       "      <td>2.513768e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>406</th>\n",
       "      <td>giggly</td>\n",
       "      <td>2.513762e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>367</th>\n",
       "      <td>tfidf_367</td>\n",
       "      <td>2.508874e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>79</th>\n",
       "      <td>tfidf_79</td>\n",
       "      <td>2.508800e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>395</th>\n",
       "      <td>creative</td>\n",
       "      <td>2.467274e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>291</th>\n",
       "      <td>tfidf_291</td>\n",
       "      <td>2.447940e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>109</th>\n",
       "      <td>tfidf_109</td>\n",
       "      <td>2.444949e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>90</th>\n",
       "      <td>tfidf_90</td>\n",
       "      <td>2.365282e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>173</th>\n",
       "      <td>tfidf_173</td>\n",
       "      <td>2.313945e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>360</th>\n",
       "      <td>tfidf_360</td>\n",
       "      <td>2.242297e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>73</th>\n",
       "      <td>tfidf_73</td>\n",
       "      <td>2.238994e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>381</th>\n",
       "      <td>tfidf_381</td>\n",
       "      <td>2.221980e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>200</th>\n",
       "      <td>tfidf_200</td>\n",
       "      <td>2.205151e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>419</th>\n",
       "      <td>tingly</td>\n",
       "      <td>2.165910e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>447</th>\n",
       "      <td>orange</td>\n",
       "      <td>2.132863e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>418</th>\n",
       "      <td>talkative</td>\n",
       "      <td>2.119739e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>tfidf_46</td>\n",
       "      <td>2.115834e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>190</th>\n",
       "      <td>tfidf_190</td>\n",
       "      <td>2.085447e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>370</th>\n",
       "      <td>tfidf_370</td>\n",
       "      <td>2.082622e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>405</th>\n",
       "      <td>focused</td>\n",
       "      <td>2.078432e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>274</th>\n",
       "      <td>tfidf_274</td>\n",
       "      <td>2.074264e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>373</th>\n",
       "      <td>tfidf_373</td>\n",
       "      <td>2.066468e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>343</th>\n",
       "      <td>tfidf_343</td>\n",
       "      <td>2.037769e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>456</th>\n",
       "      <td>sage</td>\n",
       "      <td>2.027274e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>415</th>\n",
       "      <td>sleepy</td>\n",
       "      <td>2.008146e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>317</th>\n",
       "      <td>tfidf_317</td>\n",
       "      <td>2.004170e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>303</th>\n",
       "      <td>tfidf_303</td>\n",
       "      <td>1.976494e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>282</th>\n",
       "      <td>tfidf_282</td>\n",
       "      <td>1.970752e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>104</th>\n",
       "      <td>tfidf_104</td>\n",
       "      <td>1.965406e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>283</th>\n",
       "      <td>tfidf_283</td>\n",
       "      <td>1.946572e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>246</th>\n",
       "      <td>tfidf_246</td>\n",
       "      <td>1.897191e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>135</th>\n",
       "      <td>tfidf_135</td>\n",
       "      <td>1.843421e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>159</th>\n",
       "      <td>tfidf_159</td>\n",
       "      <td>1.843417e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>372</th>\n",
       "      <td>tfidf_372</td>\n",
       "      <td>1.834378e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>442</th>\n",
       "      <td>lime</td>\n",
       "      <td>1.831575e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>382</th>\n",
       "      <td>tfidf_382</td>\n",
       "      <td>1.810553e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>267</th>\n",
       "      <td>tfidf_267</td>\n",
       "      <td>1.793399e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>451</th>\n",
       "      <td>pine</td>\n",
       "      <td>1.774155e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>103</th>\n",
       "      <td>tfidf_103</td>\n",
       "      <td>1.733281e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>74</th>\n",
       "      <td>tfidf_74</td>\n",
       "      <td>1.716684e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>332</th>\n",
       "      <td>tfidf_332</td>\n",
       "      <td>1.711727e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>232</th>\n",
       "      <td>tfidf_232</td>\n",
       "      <td>1.711054e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>137</th>\n",
       "      <td>tfidf_137</td>\n",
       "      <td>1.703221e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>177</th>\n",
       "      <td>tfidf_177</td>\n",
       "      <td>1.698961e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>161</th>\n",
       "      <td>tfidf_161</td>\n",
       "      <td>1.693304e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>265</th>\n",
       "      <td>tfidf_265</td>\n",
       "      <td>1.686773e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>468</th>\n",
       "      <td>woody</td>\n",
       "      <td>1.680157e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>tfidf_0</td>\n",
       "      <td>1.680094e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>tfidf_20</td>\n",
       "      <td>1.630916e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>189</th>\n",
       "      <td>tfidf_189</td>\n",
       "      <td>1.607933e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>82</th>\n",
       "      <td>tfidf_82</td>\n",
       "      <td>1.601175e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>454</th>\n",
       "      <td>pungent</td>\n",
       "      <td>1.600513e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>369</th>\n",
       "      <td>tfidf_369</td>\n",
       "      <td>1.564381e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>178</th>\n",
       "      <td>tfidf_178</td>\n",
       "      <td>1.561613e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>153</th>\n",
       "      <td>tfidf_153</td>\n",
       "      <td>1.558633e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>255</th>\n",
       "      <td>tfidf_255</td>\n",
       "      <td>1.536865e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>359</th>\n",
       "      <td>tfidf_359</td>\n",
       "      <td>1.524169e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>61</th>\n",
       "      <td>tfidf_61</td>\n",
       "      <td>1.515206e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>139</th>\n",
       "      <td>tfidf_139</td>\n",
       "      <td>1.510382e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>tfidf_97</td>\n",
       "      <td>1.505176e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>tfidf_34</td>\n",
       "      <td>1.497345e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>tfidf_4</td>\n",
       "      <td>1.483423e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>278</th>\n",
       "      <td>tfidf_278</td>\n",
       "      <td>1.428429e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>338</th>\n",
       "      <td>tfidf_338</td>\n",
       "      <td>1.427806e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>166</th>\n",
       "      <td>tfidf_166</td>\n",
       "      <td>1.413125e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>393</th>\n",
       "      <td>aroused</td>\n",
       "      <td>1.400899e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>465</th>\n",
       "      <td>tropical</td>\n",
       "      <td>1.399736e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>tfidf_29</td>\n",
       "      <td>1.384891e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>152</th>\n",
       "      <td>tfidf_152</td>\n",
       "      <td>1.376116e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>264</th>\n",
       "      <td>tfidf_264</td>\n",
       "      <td>1.375685e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>280</th>\n",
       "      <td>tfidf_280</td>\n",
       "      <td>1.371507e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>114</th>\n",
       "      <td>tfidf_114</td>\n",
       "      <td>1.361785e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>398</th>\n",
       "      <td>dry eyes</td>\n",
       "      <td>1.360486e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>130</th>\n",
       "      <td>tfidf_130</td>\n",
       "      <td>1.339460e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>350</th>\n",
       "      <td>tfidf_350</td>\n",
       "      <td>1.317614e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>tfidf_16</td>\n",
       "      <td>1.313627e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>371</th>\n",
       "      <td>tfidf_371</td>\n",
       "      <td>1.313096e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>182</th>\n",
       "      <td>tfidf_182</td>\n",
       "      <td>1.305052e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>126</th>\n",
       "      <td>tfidf_126</td>\n",
       "      <td>1.299786e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>217</th>\n",
       "      <td>tfidf_217</td>\n",
       "      <td>1.299739e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>64</th>\n",
       "      <td>tfidf_64</td>\n",
       "      <td>1.297923e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>146</th>\n",
       "      <td>tfidf_146</td>\n",
       "      <td>1.292167e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>249</th>\n",
       "      <td>tfidf_249</td>\n",
       "      <td>1.284246e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>tfidf_41</td>\n",
       "      <td>1.277527e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>320</th>\n",
       "      <td>tfidf_320</td>\n",
       "      <td>1.275988e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>101</th>\n",
       "      <td>tfidf_101</td>\n",
       "      <td>1.258143e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>110</th>\n",
       "      <td>tfidf_110</td>\n",
       "      <td>1.251376e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>376</th>\n",
       "      <td>tfidf_376</td>\n",
       "      <td>1.244437e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>386</th>\n",
       "      <td>tfidf_386</td>\n",
       "      <td>1.226636e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>184</th>\n",
       "      <td>tfidf_184</td>\n",
       "      <td>1.223694e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>311</th>\n",
       "      <td>tfidf_311</td>\n",
       "      <td>1.222976e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>tfidf_5</td>\n",
       "      <td>1.216128e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>421</th>\n",
       "      <td>ammonia</td>\n",
       "      <td>1.212284e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>321</th>\n",
       "      <td>tfidf_321</td>\n",
       "      <td>1.206766e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>297</th>\n",
       "      <td>tfidf_297</td>\n",
       "      <td>1.204583e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>129</th>\n",
       "      <td>tfidf_129</td>\n",
       "      <td>1.200730e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>tfidf_99</td>\n",
       "      <td>1.194695e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>125</th>\n",
       "      <td>tfidf_125</td>\n",
       "      <td>1.194324e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>76</th>\n",
       "      <td>tfidf_76</td>\n",
       "      <td>1.192377e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>301</th>\n",
       "      <td>tfidf_301</td>\n",
       "      <td>1.180630e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>194</th>\n",
       "      <td>tfidf_194</td>\n",
       "      <td>1.180564e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>157</th>\n",
       "      <td>tfidf_157</td>\n",
       "      <td>1.177611e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>310</th>\n",
       "      <td>tfidf_310</td>\n",
       "      <td>1.167575e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>237</th>\n",
       "      <td>tfidf_237</td>\n",
       "      <td>1.163059e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>326</th>\n",
       "      <td>tfidf_326</td>\n",
       "      <td>1.158211e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>222</th>\n",
       "      <td>tfidf_222</td>\n",
       "      <td>1.153859e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>80</th>\n",
       "      <td>tfidf_80</td>\n",
       "      <td>1.149465e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>tfidf_9</td>\n",
       "      <td>1.148424e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>385</th>\n",
       "      <td>tfidf_385</td>\n",
       "      <td>1.136211e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>348</th>\n",
       "      <td>tfidf_348</td>\n",
       "      <td>1.126624e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>tfidf_36</td>\n",
       "      <td>1.123436e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>124</th>\n",
       "      <td>tfidf_124</td>\n",
       "      <td>1.116527e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>181</th>\n",
       "      <td>tfidf_181</td>\n",
       "      <td>1.109132e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>175</th>\n",
       "      <td>tfidf_175</td>\n",
       "      <td>1.098598e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>221</th>\n",
       "      <td>tfidf_221</td>\n",
       "      <td>1.083936e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>tfidf_23</td>\n",
       "      <td>1.077787e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>233</th>\n",
       "      <td>tfidf_233</td>\n",
       "      <td>1.071398e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>tfidf_14</td>\n",
       "      <td>1.066679e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>228</th>\n",
       "      <td>tfidf_228</td>\n",
       "      <td>1.050894e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>203</th>\n",
       "      <td>tfidf_203</td>\n",
       "      <td>1.046809e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>160</th>\n",
       "      <td>tfidf_160</td>\n",
       "      <td>1.045851e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>336</th>\n",
       "      <td>tfidf_336</td>\n",
       "      <td>1.045467e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>243</th>\n",
       "      <td>tfidf_243</td>\n",
       "      <td>1.044765e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>142</th>\n",
       "      <td>tfidf_142</td>\n",
       "      <td>1.038809e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50</th>\n",
       "      <td>tfidf_50</td>\n",
       "      <td>1.036629e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>271</th>\n",
       "      <td>tfidf_271</td>\n",
       "      <td>1.034205e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>107</th>\n",
       "      <td>tfidf_107</td>\n",
       "      <td>1.031491e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>455</th>\n",
       "      <td>rose</td>\n",
       "      <td>1.027803e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>136</th>\n",
       "      <td>tfidf_136</td>\n",
       "      <td>1.013002e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>81</th>\n",
       "      <td>tfidf_81</td>\n",
       "      <td>1.007210e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>198</th>\n",
       "      <td>tfidf_198</td>\n",
       "      <td>1.004887e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>tfidf_17</td>\n",
       "      <td>1.003293e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>224</th>\n",
       "      <td>tfidf_224</td>\n",
       "      <td>9.991121e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54</th>\n",
       "      <td>tfidf_54</td>\n",
       "      <td>9.952871e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>354</th>\n",
       "      <td>tfidf_354</td>\n",
       "      <td>9.879219e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>289</th>\n",
       "      <td>tfidf_289</td>\n",
       "      <td>9.845744e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>tfidf_21</td>\n",
       "      <td>9.757395e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>215</th>\n",
       "      <td>tfidf_215</td>\n",
       "      <td>9.671298e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>344</th>\n",
       "      <td>tfidf_344</td>\n",
       "      <td>9.667509e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>288</th>\n",
       "      <td>tfidf_288</td>\n",
       "      <td>9.572057e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>154</th>\n",
       "      <td>tfidf_154</td>\n",
       "      <td>9.561375e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>118</th>\n",
       "      <td>tfidf_118</td>\n",
       "      <td>9.547401e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>254</th>\n",
       "      <td>tfidf_254</td>\n",
       "      <td>9.428696e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75</th>\n",
       "      <td>tfidf_75</td>\n",
       "      <td>9.391458e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>294</th>\n",
       "      <td>tfidf_294</td>\n",
       "      <td>9.332259e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>234</th>\n",
       "      <td>tfidf_234</td>\n",
       "      <td>9.289449e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>117</th>\n",
       "      <td>tfidf_117</td>\n",
       "      <td>9.260707e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>229</th>\n",
       "      <td>tfidf_229</td>\n",
       "      <td>9.225289e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>123</th>\n",
       "      <td>tfidf_123</td>\n",
       "      <td>9.162157e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>202</th>\n",
       "      <td>tfidf_202</td>\n",
       "      <td>9.132217e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>318</th>\n",
       "      <td>tfidf_318</td>\n",
       "      <td>9.121368e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>69</th>\n",
       "      <td>tfidf_69</td>\n",
       "      <td>9.083519e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53</th>\n",
       "      <td>tfidf_53</td>\n",
       "      <td>9.019752e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>163</th>\n",
       "      <td>tfidf_163</td>\n",
       "      <td>9.019064e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>tfidf_19</td>\n",
       "      <td>8.999725e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>164</th>\n",
       "      <td>tfidf_164</td>\n",
       "      <td>8.995389e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>116</th>\n",
       "      <td>tfidf_116</td>\n",
       "      <td>8.899685e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>436</th>\n",
       "      <td>fruit</td>\n",
       "      <td>8.896790e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>tfidf_96</td>\n",
       "      <td>8.798738e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52</th>\n",
       "      <td>tfidf_52</td>\n",
       "      <td>8.794251e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>412</th>\n",
       "      <td>paranoid</td>\n",
       "      <td>8.762024e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>71</th>\n",
       "      <td>tfidf_71</td>\n",
       "      <td>8.747323e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>122</th>\n",
       "      <td>tfidf_122</td>\n",
       "      <td>8.677249e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>206</th>\n",
       "      <td>tfidf_206</td>\n",
       "      <td>8.665723e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>353</th>\n",
       "      <td>tfidf_353</td>\n",
       "      <td>8.628822e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>397</th>\n",
       "      <td>dizzy</td>\n",
       "      <td>8.561910e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>277</th>\n",
       "      <td>tfidf_277</td>\n",
       "      <td>8.528952e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>438</th>\n",
       "      <td>grapefruit</td>\n",
       "      <td>8.469292e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>251</th>\n",
       "      <td>tfidf_251</td>\n",
       "      <td>8.419663e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>368</th>\n",
       "      <td>tfidf_368</td>\n",
       "      <td>8.381937e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>287</th>\n",
       "      <td>tfidf_287</td>\n",
       "      <td>8.357295e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>377</th>\n",
       "      <td>tfidf_377</td>\n",
       "      <td>8.292246e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>120</th>\n",
       "      <td>tfidf_120</td>\n",
       "      <td>8.271966e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>91</th>\n",
       "      <td>tfidf_91</td>\n",
       "      <td>8.233753e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>56</th>\n",
       "      <td>tfidf_56</td>\n",
       "      <td>8.172129e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>355</th>\n",
       "      <td>tfidf_355</td>\n",
       "      <td>8.171278e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>tfidf_22</td>\n",
       "      <td>8.138276e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>231</th>\n",
       "      <td>tfidf_231</td>\n",
       "      <td>8.101537e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>316</th>\n",
       "      <td>tfidf_316</td>\n",
       "      <td>7.967163e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>225</th>\n",
       "      <td>tfidf_225</td>\n",
       "      <td>7.822258e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>341</th>\n",
       "      <td>tfidf_341</td>\n",
       "      <td>7.739122e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>392</th>\n",
       "      <td>anxious</td>\n",
       "      <td>7.704575e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>138</th>\n",
       "      <td>tfidf_138</td>\n",
       "      <td>7.653283e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>358</th>\n",
       "      <td>tfidf_358</td>\n",
       "      <td>7.624001e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>tfidf_32</td>\n",
       "      <td>7.447753e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>77</th>\n",
       "      <td>tfidf_77</td>\n",
       "      <td>7.412940e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>227</th>\n",
       "      <td>tfidf_227</td>\n",
       "      <td>7.411121e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>440</th>\n",
       "      <td>lavender</td>\n",
       "      <td>7.380446e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>193</th>\n",
       "      <td>tfidf_193</td>\n",
       "      <td>7.373575e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>211</th>\n",
       "      <td>tfidf_211</td>\n",
       "      <td>7.333444e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>256</th>\n",
       "      <td>tfidf_256</td>\n",
       "      <td>7.195378e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>105</th>\n",
       "      <td>tfidf_105</td>\n",
       "      <td>7.192924e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>tfidf_45</td>\n",
       "      <td>7.185629e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>219</th>\n",
       "      <td>tfidf_219</td>\n",
       "      <td>7.141612e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>328</th>\n",
       "      <td>tfidf_328</td>\n",
       "      <td>7.137150e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>132</th>\n",
       "      <td>tfidf_132</td>\n",
       "      <td>7.085701e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>72</th>\n",
       "      <td>tfidf_72</td>\n",
       "      <td>6.932397e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>463</th>\n",
       "      <td>tobacco</td>\n",
       "      <td>6.910355e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>213</th>\n",
       "      <td>tfidf_213</td>\n",
       "      <td>6.889557e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>208</th>\n",
       "      <td>tfidf_208</td>\n",
       "      <td>6.883700e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>66</th>\n",
       "      <td>tfidf_66</td>\n",
       "      <td>6.850332e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>tfidf_1</td>\n",
       "      <td>6.784106e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>270</th>\n",
       "      <td>tfidf_270</td>\n",
       "      <td>6.707440e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>tfidf_25</td>\n",
       "      <td>6.702573e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>214</th>\n",
       "      <td>tfidf_214</td>\n",
       "      <td>6.694050e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>260</th>\n",
       "      <td>tfidf_260</td>\n",
       "      <td>6.496868e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>tfidf_27</td>\n",
       "      <td>6.485422e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>262</th>\n",
       "      <td>tfidf_262</td>\n",
       "      <td>6.485357e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>241</th>\n",
       "      <td>tfidf_241</td>\n",
       "      <td>6.474491e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>tfidf_28</td>\n",
       "      <td>6.363119e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>387</th>\n",
       "      <td>tfidf_387</td>\n",
       "      <td>6.359895e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>331</th>\n",
       "      <td>tfidf_331</td>\n",
       "      <td>6.339506e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>363</th>\n",
       "      <td>tfidf_363</td>\n",
       "      <td>6.228027e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>333</th>\n",
       "      <td>tfidf_333</td>\n",
       "      <td>6.191510e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>306</th>\n",
       "      <td>tfidf_306</td>\n",
       "      <td>6.159302e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>379</th>\n",
       "      <td>tfidf_379</td>\n",
       "      <td>6.153414e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>185</th>\n",
       "      <td>tfidf_185</td>\n",
       "      <td>6.096782e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>223</th>\n",
       "      <td>tfidf_223</td>\n",
       "      <td>6.058577e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>226</th>\n",
       "      <td>tfidf_226</td>\n",
       "      <td>6.017239e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>315</th>\n",
       "      <td>tfidf_315</td>\n",
       "      <td>6.016185e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>57</th>\n",
       "      <td>tfidf_57</td>\n",
       "      <td>6.000416e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>tfidf_40</td>\n",
       "      <td>5.998326e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>257</th>\n",
       "      <td>tfidf_257</td>\n",
       "      <td>5.983256e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>112</th>\n",
       "      <td>tfidf_112</td>\n",
       "      <td>5.944057e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>247</th>\n",
       "      <td>tfidf_247</td>\n",
       "      <td>5.938130e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>88</th>\n",
       "      <td>tfidf_88</td>\n",
       "      <td>5.868448e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>292</th>\n",
       "      <td>tfidf_292</td>\n",
       "      <td>5.829622e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>170</th>\n",
       "      <td>tfidf_170</td>\n",
       "      <td>5.822352e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>295</th>\n",
       "      <td>tfidf_295</td>\n",
       "      <td>5.719016e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>365</th>\n",
       "      <td>tfidf_365</td>\n",
       "      <td>5.674769e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>63</th>\n",
       "      <td>tfidf_63</td>\n",
       "      <td>5.603457e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>352</th>\n",
       "      <td>tfidf_352</td>\n",
       "      <td>5.566054e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>165</th>\n",
       "      <td>tfidf_165</td>\n",
       "      <td>5.480557e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>435</th>\n",
       "      <td>flowery</td>\n",
       "      <td>5.441499e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>85</th>\n",
       "      <td>tfidf_85</td>\n",
       "      <td>5.416993e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>108</th>\n",
       "      <td>tfidf_108</td>\n",
       "      <td>5.408731e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>147</th>\n",
       "      <td>tfidf_147</td>\n",
       "      <td>5.408251e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>187</th>\n",
       "      <td>tfidf_187</td>\n",
       "      <td>5.406721e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>180</th>\n",
       "      <td>tfidf_180</td>\n",
       "      <td>5.398716e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>58</th>\n",
       "      <td>tfidf_58</td>\n",
       "      <td>5.350833e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>197</th>\n",
       "      <td>tfidf_197</td>\n",
       "      <td>5.314792e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>384</th>\n",
       "      <td>tfidf_384</td>\n",
       "      <td>5.311171e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>tfidf_2</td>\n",
       "      <td>5.282757e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>156</th>\n",
       "      <td>tfidf_156</td>\n",
       "      <td>5.260789e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>188</th>\n",
       "      <td>tfidf_188</td>\n",
       "      <td>5.213558e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>220</th>\n",
       "      <td>tfidf_220</td>\n",
       "      <td>5.183076e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>252</th>\n",
       "      <td>tfidf_252</td>\n",
       "      <td>5.083934e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>102</th>\n",
       "      <td>tfidf_102</td>\n",
       "      <td>5.081821e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>143</th>\n",
       "      <td>tfidf_143</td>\n",
       "      <td>5.032744e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>313</th>\n",
       "      <td>tfidf_313</td>\n",
       "      <td>5.003633e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>65</th>\n",
       "      <td>tfidf_65</td>\n",
       "      <td>4.981843e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>201</th>\n",
       "      <td>tfidf_201</td>\n",
       "      <td>4.917561e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>tfidf_10</td>\n",
       "      <td>4.908079e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>tfidf_35</td>\n",
       "      <td>4.901722e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>284</th>\n",
       "      <td>tfidf_284</td>\n",
       "      <td>4.898366e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>286</th>\n",
       "      <td>tfidf_286</td>\n",
       "      <td>4.880751e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>269</th>\n",
       "      <td>tfidf_269</td>\n",
       "      <td>4.880283e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>179</th>\n",
       "      <td>tfidf_179</td>\n",
       "      <td>4.878131e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59</th>\n",
       "      <td>tfidf_59</td>\n",
       "      <td>4.849720e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>464</th>\n",
       "      <td>tree</td>\n",
       "      <td>4.788669e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>tfidf_31</td>\n",
       "      <td>4.779540e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>186</th>\n",
       "      <td>tfidf_186</td>\n",
       "      <td>4.774593e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>192</th>\n",
       "      <td>tfidf_192</td>\n",
       "      <td>4.747021e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>171</th>\n",
       "      <td>tfidf_171</td>\n",
       "      <td>4.647540e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>183</th>\n",
       "      <td>tfidf_183</td>\n",
       "      <td>4.545746e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>276</th>\n",
       "      <td>tfidf_276</td>\n",
       "      <td>4.515695e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>115</th>\n",
       "      <td>tfidf_115</td>\n",
       "      <td>4.502703e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>408</th>\n",
       "      <td>headache</td>\n",
       "      <td>4.465171e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>tfidf_33</td>\n",
       "      <td>4.457326e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>339</th>\n",
       "      <td>tfidf_339</td>\n",
       "      <td>4.447436e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>432</th>\n",
       "      <td>coffee</td>\n",
       "      <td>4.411210e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>106</th>\n",
       "      <td>tfidf_106</td>\n",
       "      <td>4.408745e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>261</th>\n",
       "      <td>tfidf_261</td>\n",
       "      <td>4.340304e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>259</th>\n",
       "      <td>tfidf_259</td>\n",
       "      <td>4.327658e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>380</th>\n",
       "      <td>tfidf_380</td>\n",
       "      <td>4.260649e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>113</th>\n",
       "      <td>tfidf_113</td>\n",
       "      <td>4.212613e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>347</th>\n",
       "      <td>tfidf_347</td>\n",
       "      <td>4.205459e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>323</th>\n",
       "      <td>tfidf_323</td>\n",
       "      <td>4.199743e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>127</th>\n",
       "      <td>tfidf_127</td>\n",
       "      <td>4.157432e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>84</th>\n",
       "      <td>tfidf_84</td>\n",
       "      <td>4.081726e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>155</th>\n",
       "      <td>tfidf_155</td>\n",
       "      <td>4.062887e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>324</th>\n",
       "      <td>tfidf_324</td>\n",
       "      <td>3.988590e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>172</th>\n",
       "      <td>tfidf_172</td>\n",
       "      <td>3.961463e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>209</th>\n",
       "      <td>tfidf_209</td>\n",
       "      <td>3.960377e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>86</th>\n",
       "      <td>tfidf_86</td>\n",
       "      <td>3.873685e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>195</th>\n",
       "      <td>tfidf_195</td>\n",
       "      <td>3.867855e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>tfidf_44</td>\n",
       "      <td>3.862284e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>216</th>\n",
       "      <td>tfidf_216</td>\n",
       "      <td>3.849737e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>92</th>\n",
       "      <td>tfidf_92</td>\n",
       "      <td>3.840317e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>308</th>\n",
       "      <td>tfidf_308</td>\n",
       "      <td>3.840104e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>70</th>\n",
       "      <td>tfidf_70</td>\n",
       "      <td>3.824924e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>140</th>\n",
       "      <td>tfidf_140</td>\n",
       "      <td>3.798910e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>94</th>\n",
       "      <td>tfidf_94</td>\n",
       "      <td>3.797574e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>461</th>\n",
       "      <td>tar</td>\n",
       "      <td>3.789976e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>364</th>\n",
       "      <td>tfidf_364</td>\n",
       "      <td>3.771017e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>334</th>\n",
       "      <td>tfidf_334</td>\n",
       "      <td>3.723662e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>174</th>\n",
       "      <td>tfidf_174</td>\n",
       "      <td>3.675048e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>176</th>\n",
       "      <td>tfidf_176</td>\n",
       "      <td>3.661949e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>446</th>\n",
       "      <td>nutty</td>\n",
       "      <td>3.615191e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>tfidf_24</td>\n",
       "      <td>3.579002e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>356</th>\n",
       "      <td>tfidf_356</td>\n",
       "      <td>3.552371e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>tfidf_49</td>\n",
       "      <td>3.538805e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>275</th>\n",
       "      <td>tfidf_275</td>\n",
       "      <td>3.382444e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>452</th>\n",
       "      <td>pineapple</td>\n",
       "      <td>3.361866e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>361</th>\n",
       "      <td>tfidf_361</td>\n",
       "      <td>3.347223e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>tfidf_12</td>\n",
       "      <td>3.309767e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>83</th>\n",
       "      <td>tfidf_83</td>\n",
       "      <td>3.247989e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>299</th>\n",
       "      <td>tfidf_299</td>\n",
       "      <td>3.246019e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>375</th>\n",
       "      <td>tfidf_375</td>\n",
       "      <td>3.181501e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>244</th>\n",
       "      <td>tfidf_244</td>\n",
       "      <td>3.143098e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>tfidf_18</td>\n",
       "      <td>3.124055e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>296</th>\n",
       "      <td>tfidf_296</td>\n",
       "      <td>3.091822e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>62</th>\n",
       "      <td>tfidf_62</td>\n",
       "      <td>3.081028e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>67</th>\n",
       "      <td>tfidf_67</td>\n",
       "      <td>3.048214e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>427</th>\n",
       "      <td>butter</td>\n",
       "      <td>3.021232e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>335</th>\n",
       "      <td>tfidf_335</td>\n",
       "      <td>2.974771e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>148</th>\n",
       "      <td>tfidf_148</td>\n",
       "      <td>2.969564e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>346</th>\n",
       "      <td>tfidf_346</td>\n",
       "      <td>2.942171e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>279</th>\n",
       "      <td>tfidf_279</td>\n",
       "      <td>2.921803e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>383</th>\n",
       "      <td>tfidf_383</td>\n",
       "      <td>2.903242e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>235</th>\n",
       "      <td>tfidf_235</td>\n",
       "      <td>2.872784e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>tfidf_47</td>\n",
       "      <td>2.857332e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>450</th>\n",
       "      <td>pepper</td>\n",
       "      <td>2.801136e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>378</th>\n",
       "      <td>tfidf_378</td>\n",
       "      <td>2.759456e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>307</th>\n",
       "      <td>tfidf_307</td>\n",
       "      <td>2.714189e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>tfidf_3</td>\n",
       "      <td>2.656310e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>169</th>\n",
       "      <td>tfidf_169</td>\n",
       "      <td>2.643464e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>330</th>\n",
       "      <td>tfidf_330</td>\n",
       "      <td>2.602443e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>298</th>\n",
       "      <td>tfidf_298</td>\n",
       "      <td>2.552014e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>tfidf_38</td>\n",
       "      <td>2.532045e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51</th>\n",
       "      <td>tfidf_51</td>\n",
       "      <td>2.528680e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>322</th>\n",
       "      <td>tfidf_322</td>\n",
       "      <td>2.521152e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>212</th>\n",
       "      <td>tfidf_212</td>\n",
       "      <td>2.514400e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>131</th>\n",
       "      <td>tfidf_131</td>\n",
       "      <td>2.504011e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>68</th>\n",
       "      <td>tfidf_68</td>\n",
       "      <td>2.469942e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>238</th>\n",
       "      <td>tfidf_238</td>\n",
       "      <td>2.451270e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>55</th>\n",
       "      <td>tfidf_55</td>\n",
       "      <td>2.418314e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>290</th>\n",
       "      <td>tfidf_290</td>\n",
       "      <td>2.359483e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>462</th>\n",
       "      <td>tea</td>\n",
       "      <td>2.314900e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>134</th>\n",
       "      <td>tfidf_134</td>\n",
       "      <td>2.300717e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>248</th>\n",
       "      <td>tfidf_248</td>\n",
       "      <td>2.216941e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>448</th>\n",
       "      <td>peach</td>\n",
       "      <td>2.211496e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>100</th>\n",
       "      <td>tfidf_100</td>\n",
       "      <td>2.189186e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>204</th>\n",
       "      <td>tfidf_204</td>\n",
       "      <td>2.135161e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>tfidf_13</td>\n",
       "      <td>2.131007e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>268</th>\n",
       "      <td>tfidf_268</td>\n",
       "      <td>2.111316e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>87</th>\n",
       "      <td>tfidf_87</td>\n",
       "      <td>2.088114e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>133</th>\n",
       "      <td>tfidf_133</td>\n",
       "      <td>2.082596e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>300</th>\n",
       "      <td>tfidf_300</td>\n",
       "      <td>2.080660e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>266</th>\n",
       "      <td>tfidf_266</td>\n",
       "      <td>2.075124e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>tfidf_95</td>\n",
       "      <td>1.992919e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>327</th>\n",
       "      <td>tfidf_327</td>\n",
       "      <td>1.961141e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>150</th>\n",
       "      <td>tfidf_150</td>\n",
       "      <td>1.956963e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>351</th>\n",
       "      <td>tfidf_351</td>\n",
       "      <td>1.944784e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>60</th>\n",
       "      <td>tfidf_60</td>\n",
       "      <td>1.922291e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>305</th>\n",
       "      <td>tfidf_305</td>\n",
       "      <td>1.912762e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>89</th>\n",
       "      <td>tfidf_89</td>\n",
       "      <td>1.728399e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>tfidf_15</td>\n",
       "      <td>1.691510e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>191</th>\n",
       "      <td>tfidf_191</td>\n",
       "      <td>1.640736e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>tfidf_8</td>\n",
       "      <td>1.597994e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>250</th>\n",
       "      <td>tfidf_250</td>\n",
       "      <td>1.579339e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>tfidf_42</td>\n",
       "      <td>1.519522e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>218</th>\n",
       "      <td>tfidf_218</td>\n",
       "      <td>1.396420e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>293</th>\n",
       "      <td>tfidf_293</td>\n",
       "      <td>1.277785e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>242</th>\n",
       "      <td>tfidf_242</td>\n",
       "      <td>1.125495e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>439</th>\n",
       "      <td>honey</td>\n",
       "      <td>1.104800e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>453</th>\n",
       "      <td>plum</td>\n",
       "      <td>1.075571e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>302</th>\n",
       "      <td>tfidf_302</td>\n",
       "      <td>1.047018e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>430</th>\n",
       "      <td>chestnut</td>\n",
       "      <td>8.566180e-05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>467</th>\n",
       "      <td>violet</td>\n",
       "      <td>8.296552e-05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>425</th>\n",
       "      <td>blue cheese</td>\n",
       "      <td>6.664112e-05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>423</th>\n",
       "      <td>apricot</td>\n",
       "      <td>6.388015e-05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>422</th>\n",
       "      <td>apple</td>\n",
       "      <td>4.274627e-05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>444</th>\n",
       "      <td>menthol</td>\n",
       "      <td>4.225592e-05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>410</th>\n",
       "      <td>migraines</td>\n",
       "      <td>1.930116e-05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>449</th>\n",
       "      <td>pear</td>\n",
       "      <td>1.561361e-05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>391</th>\n",
       "      <td>anxiety</td>\n",
       "      <td>1.175506e-05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>396</th>\n",
       "      <td>depression</td>\n",
       "      <td>1.080270e-05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>411</th>\n",
       "      <td>pain</td>\n",
       "      <td>6.908236e-08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>414</th>\n",
       "      <td>seizures</td>\n",
       "      <td>1.481888e-09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>403</th>\n",
       "      <td>eye pressure</td>\n",
       "      <td>1.411152e-09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>401</th>\n",
       "      <td>epilepsy</td>\n",
       "      <td>4.958197e-10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>394</th>\n",
       "      <td>arthritis</td>\n",
       "      <td>0.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>404</th>\n",
       "      <td>fatigue</td>\n",
       "      <td>0.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>416</th>\n",
       "      <td>spasticity</td>\n",
       "      <td>0.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>417</th>\n",
       "      <td>stress</td>\n",
       "      <td>0.000000e+00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         features         score\n",
       "433        diesel  1.557018e-01\n",
       "443         mango  5.092749e-02\n",
       "390        sativa  2.885505e-02\n",
       "388        hybrid  2.644686e-02\n",
       "426     blueberry  1.983689e-02\n",
       "389        indica  1.673876e-02\n",
       "272     tfidf_272  1.486275e-02\n",
       "141     tfidf_141  1.425407e-02\n",
       "329     tfidf_329  1.355326e-02\n",
       "431        citrus  1.081232e-02\n",
       "168     tfidf_168  1.072228e-02\n",
       "345     tfidf_345  1.071238e-02\n",
       "149     tfidf_149  9.456866e-03\n",
       "145     tfidf_145  9.381184e-03\n",
       "459    strawberry  8.791444e-03\n",
       "239     tfidf_239  8.184002e-03\n",
       "437         grape  7.450607e-03\n",
       "312     tfidf_312  7.398193e-03\n",
       "357     tfidf_357  6.717043e-03\n",
       "285     tfidf_285  6.224752e-03\n",
       "253     tfidf_253  5.910649e-03\n",
       "309     tfidf_309  5.863109e-03\n",
       "207     tfidf_207  5.831222e-03\n",
       "199     tfidf_199  5.616585e-03\n",
       "7         tfidf_7  5.578498e-03\n",
       "434        earthy  5.438159e-03\n",
       "281     tfidf_281  5.400202e-03\n",
       "30       tfidf_30  5.360040e-03\n",
       "441         lemon  5.044943e-03\n",
       "162     tfidf_162  4.856184e-03\n",
       "196     tfidf_196  4.830943e-03\n",
       "400     energetic  4.805606e-03\n",
       "245     tfidf_245  4.711933e-03\n",
       "325     tfidf_325  4.703153e-03\n",
       "230     tfidf_230  4.443127e-03\n",
       "399     dry mouth  4.390081e-03\n",
       "121     tfidf_121  4.280813e-03\n",
       "424         berry  4.115724e-03\n",
       "37       tfidf_37  4.110179e-03\n",
       "210     tfidf_210  3.882792e-03\n",
       "93       tfidf_93  3.874828e-03\n",
       "151     tfidf_151  3.838046e-03\n",
       "429      chemical  3.804599e-03\n",
       "413       relaxed  3.777501e-03\n",
       "458  spicy/herbal  3.776995e-03\n",
       "428        cheese  3.691412e-03\n",
       "128     tfidf_128  3.664054e-03\n",
       "205     tfidf_205  3.593225e-03\n",
       "11       tfidf_11  3.550774e-03\n",
       "407         happy  3.513907e-03\n",
       "111     tfidf_111  3.469634e-03\n",
       "98       tfidf_98  3.460486e-03\n",
       "78       tfidf_78  3.363012e-03\n",
       "457         skunk  3.354802e-03\n",
       "43       tfidf_43  3.333806e-03\n",
       "263     tfidf_263  3.319770e-03\n",
       "273     tfidf_273  3.311840e-03\n",
       "366     tfidf_366  3.283322e-03\n",
       "460         sweet  3.257280e-03\n",
       "402      euphoric  3.133910e-03\n",
       "319     tfidf_319  3.125429e-03\n",
       "409        hungry  3.088334e-03\n",
       "158     tfidf_158  3.079402e-03\n",
       "445          mint  3.078735e-03\n",
       "420      uplifted  3.057867e-03\n",
       "349     tfidf_349  3.049951e-03\n",
       "337     tfidf_337  3.023161e-03\n",
       "26       tfidf_26  3.001940e-03\n",
       "144     tfidf_144  2.981062e-03\n",
       "39       tfidf_39  2.930448e-03\n",
       "236     tfidf_236  2.888760e-03\n",
       "362     tfidf_362  2.872226e-03\n",
       "314     tfidf_314  2.866305e-03\n",
       "119     tfidf_119  2.753660e-03\n",
       "466       vanilla  2.714035e-03\n",
       "374     tfidf_374  2.677493e-03\n",
       "167     tfidf_167  2.667748e-03\n",
       "6         tfidf_6  2.666065e-03\n",
       "304     tfidf_304  2.631683e-03\n",
       "258     tfidf_258  2.629831e-03\n",
       "240     tfidf_240  2.538534e-03\n",
       "340     tfidf_340  2.536389e-03\n",
       "48       tfidf_48  2.517944e-03\n",
       "342     tfidf_342  2.513768e-03\n",
       "406        giggly  2.513762e-03\n",
       "367     tfidf_367  2.508874e-03\n",
       "79       tfidf_79  2.508800e-03\n",
       "395      creative  2.467274e-03\n",
       "291     tfidf_291  2.447940e-03\n",
       "109     tfidf_109  2.444949e-03\n",
       "90       tfidf_90  2.365282e-03\n",
       "173     tfidf_173  2.313945e-03\n",
       "360     tfidf_360  2.242297e-03\n",
       "73       tfidf_73  2.238994e-03\n",
       "381     tfidf_381  2.221980e-03\n",
       "200     tfidf_200  2.205151e-03\n",
       "419        tingly  2.165910e-03\n",
       "447        orange  2.132863e-03\n",
       "418     talkative  2.119739e-03\n",
       "46       tfidf_46  2.115834e-03\n",
       "190     tfidf_190  2.085447e-03\n",
       "370     tfidf_370  2.082622e-03\n",
       "405       focused  2.078432e-03\n",
       "274     tfidf_274  2.074264e-03\n",
       "373     tfidf_373  2.066468e-03\n",
       "343     tfidf_343  2.037769e-03\n",
       "456          sage  2.027274e-03\n",
       "415        sleepy  2.008146e-03\n",
       "317     tfidf_317  2.004170e-03\n",
       "303     tfidf_303  1.976494e-03\n",
       "282     tfidf_282  1.970752e-03\n",
       "104     tfidf_104  1.965406e-03\n",
       "283     tfidf_283  1.946572e-03\n",
       "246     tfidf_246  1.897191e-03\n",
       "135     tfidf_135  1.843421e-03\n",
       "159     tfidf_159  1.843417e-03\n",
       "372     tfidf_372  1.834378e-03\n",
       "442          lime  1.831575e-03\n",
       "382     tfidf_382  1.810553e-03\n",
       "267     tfidf_267  1.793399e-03\n",
       "451          pine  1.774155e-03\n",
       "103     tfidf_103  1.733281e-03\n",
       "74       tfidf_74  1.716684e-03\n",
       "332     tfidf_332  1.711727e-03\n",
       "232     tfidf_232  1.711054e-03\n",
       "137     tfidf_137  1.703221e-03\n",
       "177     tfidf_177  1.698961e-03\n",
       "161     tfidf_161  1.693304e-03\n",
       "265     tfidf_265  1.686773e-03\n",
       "468         woody  1.680157e-03\n",
       "0         tfidf_0  1.680094e-03\n",
       "20       tfidf_20  1.630916e-03\n",
       "189     tfidf_189  1.607933e-03\n",
       "82       tfidf_82  1.601175e-03\n",
       "454       pungent  1.600513e-03\n",
       "369     tfidf_369  1.564381e-03\n",
       "178     tfidf_178  1.561613e-03\n",
       "153     tfidf_153  1.558633e-03\n",
       "255     tfidf_255  1.536865e-03\n",
       "359     tfidf_359  1.524169e-03\n",
       "61       tfidf_61  1.515206e-03\n",
       "139     tfidf_139  1.510382e-03\n",
       "97       tfidf_97  1.505176e-03\n",
       "34       tfidf_34  1.497345e-03\n",
       "4         tfidf_4  1.483423e-03\n",
       "278     tfidf_278  1.428429e-03\n",
       "338     tfidf_338  1.427806e-03\n",
       "166     tfidf_166  1.413125e-03\n",
       "393       aroused  1.400899e-03\n",
       "465      tropical  1.399736e-03\n",
       "29       tfidf_29  1.384891e-03\n",
       "152     tfidf_152  1.376116e-03\n",
       "264     tfidf_264  1.375685e-03\n",
       "280     tfidf_280  1.371507e-03\n",
       "114     tfidf_114  1.361785e-03\n",
       "398      dry eyes  1.360486e-03\n",
       "130     tfidf_130  1.339460e-03\n",
       "350     tfidf_350  1.317614e-03\n",
       "16       tfidf_16  1.313627e-03\n",
       "371     tfidf_371  1.313096e-03\n",
       "182     tfidf_182  1.305052e-03\n",
       "126     tfidf_126  1.299786e-03\n",
       "217     tfidf_217  1.299739e-03\n",
       "64       tfidf_64  1.297923e-03\n",
       "146     tfidf_146  1.292167e-03\n",
       "249     tfidf_249  1.284246e-03\n",
       "41       tfidf_41  1.277527e-03\n",
       "320     tfidf_320  1.275988e-03\n",
       "101     tfidf_101  1.258143e-03\n",
       "110     tfidf_110  1.251376e-03\n",
       "376     tfidf_376  1.244437e-03\n",
       "386     tfidf_386  1.226636e-03\n",
       "184     tfidf_184  1.223694e-03\n",
       "311     tfidf_311  1.222976e-03\n",
       "5         tfidf_5  1.216128e-03\n",
       "421       ammonia  1.212284e-03\n",
       "321     tfidf_321  1.206766e-03\n",
       "297     tfidf_297  1.204583e-03\n",
       "129     tfidf_129  1.200730e-03\n",
       "99       tfidf_99  1.194695e-03\n",
       "125     tfidf_125  1.194324e-03\n",
       "76       tfidf_76  1.192377e-03\n",
       "301     tfidf_301  1.180630e-03\n",
       "194     tfidf_194  1.180564e-03\n",
       "157     tfidf_157  1.177611e-03\n",
       "310     tfidf_310  1.167575e-03\n",
       "237     tfidf_237  1.163059e-03\n",
       "326     tfidf_326  1.158211e-03\n",
       "222     tfidf_222  1.153859e-03\n",
       "80       tfidf_80  1.149465e-03\n",
       "9         tfidf_9  1.148424e-03\n",
       "385     tfidf_385  1.136211e-03\n",
       "348     tfidf_348  1.126624e-03\n",
       "36       tfidf_36  1.123436e-03\n",
       "124     tfidf_124  1.116527e-03\n",
       "181     tfidf_181  1.109132e-03\n",
       "175     tfidf_175  1.098598e-03\n",
       "221     tfidf_221  1.083936e-03\n",
       "23       tfidf_23  1.077787e-03\n",
       "233     tfidf_233  1.071398e-03\n",
       "14       tfidf_14  1.066679e-03\n",
       "228     tfidf_228  1.050894e-03\n",
       "203     tfidf_203  1.046809e-03\n",
       "160     tfidf_160  1.045851e-03\n",
       "336     tfidf_336  1.045467e-03\n",
       "243     tfidf_243  1.044765e-03\n",
       "142     tfidf_142  1.038809e-03\n",
       "50       tfidf_50  1.036629e-03\n",
       "271     tfidf_271  1.034205e-03\n",
       "107     tfidf_107  1.031491e-03\n",
       "455          rose  1.027803e-03\n",
       "136     tfidf_136  1.013002e-03\n",
       "81       tfidf_81  1.007210e-03\n",
       "198     tfidf_198  1.004887e-03\n",
       "17       tfidf_17  1.003293e-03\n",
       "224     tfidf_224  9.991121e-04\n",
       "54       tfidf_54  9.952871e-04\n",
       "354     tfidf_354  9.879219e-04\n",
       "289     tfidf_289  9.845744e-04\n",
       "21       tfidf_21  9.757395e-04\n",
       "215     tfidf_215  9.671298e-04\n",
       "344     tfidf_344  9.667509e-04\n",
       "288     tfidf_288  9.572057e-04\n",
       "154     tfidf_154  9.561375e-04\n",
       "118     tfidf_118  9.547401e-04\n",
       "254     tfidf_254  9.428696e-04\n",
       "75       tfidf_75  9.391458e-04\n",
       "294     tfidf_294  9.332259e-04\n",
       "234     tfidf_234  9.289449e-04\n",
       "117     tfidf_117  9.260707e-04\n",
       "229     tfidf_229  9.225289e-04\n",
       "123     tfidf_123  9.162157e-04\n",
       "202     tfidf_202  9.132217e-04\n",
       "318     tfidf_318  9.121368e-04\n",
       "69       tfidf_69  9.083519e-04\n",
       "53       tfidf_53  9.019752e-04\n",
       "163     tfidf_163  9.019064e-04\n",
       "19       tfidf_19  8.999725e-04\n",
       "164     tfidf_164  8.995389e-04\n",
       "116     tfidf_116  8.899685e-04\n",
       "436         fruit  8.896790e-04\n",
       "96       tfidf_96  8.798738e-04\n",
       "52       tfidf_52  8.794251e-04\n",
       "412      paranoid  8.762024e-04\n",
       "71       tfidf_71  8.747323e-04\n",
       "122     tfidf_122  8.677249e-04\n",
       "206     tfidf_206  8.665723e-04\n",
       "353     tfidf_353  8.628822e-04\n",
       "397         dizzy  8.561910e-04\n",
       "277     tfidf_277  8.528952e-04\n",
       "438    grapefruit  8.469292e-04\n",
       "251     tfidf_251  8.419663e-04\n",
       "368     tfidf_368  8.381937e-04\n",
       "287     tfidf_287  8.357295e-04\n",
       "377     tfidf_377  8.292246e-04\n",
       "120     tfidf_120  8.271966e-04\n",
       "91       tfidf_91  8.233753e-04\n",
       "56       tfidf_56  8.172129e-04\n",
       "355     tfidf_355  8.171278e-04\n",
       "22       tfidf_22  8.138276e-04\n",
       "231     tfidf_231  8.101537e-04\n",
       "316     tfidf_316  7.967163e-04\n",
       "225     tfidf_225  7.822258e-04\n",
       "341     tfidf_341  7.739122e-04\n",
       "392       anxious  7.704575e-04\n",
       "138     tfidf_138  7.653283e-04\n",
       "358     tfidf_358  7.624001e-04\n",
       "32       tfidf_32  7.447753e-04\n",
       "77       tfidf_77  7.412940e-04\n",
       "227     tfidf_227  7.411121e-04\n",
       "440      lavender  7.380446e-04\n",
       "193     tfidf_193  7.373575e-04\n",
       "211     tfidf_211  7.333444e-04\n",
       "256     tfidf_256  7.195378e-04\n",
       "105     tfidf_105  7.192924e-04\n",
       "45       tfidf_45  7.185629e-04\n",
       "219     tfidf_219  7.141612e-04\n",
       "328     tfidf_328  7.137150e-04\n",
       "132     tfidf_132  7.085701e-04\n",
       "72       tfidf_72  6.932397e-04\n",
       "463       tobacco  6.910355e-04\n",
       "213     tfidf_213  6.889557e-04\n",
       "208     tfidf_208  6.883700e-04\n",
       "66       tfidf_66  6.850332e-04\n",
       "1         tfidf_1  6.784106e-04\n",
       "270     tfidf_270  6.707440e-04\n",
       "25       tfidf_25  6.702573e-04\n",
       "214     tfidf_214  6.694050e-04\n",
       "260     tfidf_260  6.496868e-04\n",
       "27       tfidf_27  6.485422e-04\n",
       "262     tfidf_262  6.485357e-04\n",
       "241     tfidf_241  6.474491e-04\n",
       "28       tfidf_28  6.363119e-04\n",
       "387     tfidf_387  6.359895e-04\n",
       "331     tfidf_331  6.339506e-04\n",
       "363     tfidf_363  6.228027e-04\n",
       "333     tfidf_333  6.191510e-04\n",
       "306     tfidf_306  6.159302e-04\n",
       "379     tfidf_379  6.153414e-04\n",
       "185     tfidf_185  6.096782e-04\n",
       "223     tfidf_223  6.058577e-04\n",
       "226     tfidf_226  6.017239e-04\n",
       "315     tfidf_315  6.016185e-04\n",
       "57       tfidf_57  6.000416e-04\n",
       "40       tfidf_40  5.998326e-04\n",
       "257     tfidf_257  5.983256e-04\n",
       "112     tfidf_112  5.944057e-04\n",
       "247     tfidf_247  5.938130e-04\n",
       "88       tfidf_88  5.868448e-04\n",
       "292     tfidf_292  5.829622e-04\n",
       "170     tfidf_170  5.822352e-04\n",
       "295     tfidf_295  5.719016e-04\n",
       "365     tfidf_365  5.674769e-04\n",
       "63       tfidf_63  5.603457e-04\n",
       "352     tfidf_352  5.566054e-04\n",
       "165     tfidf_165  5.480557e-04\n",
       "435       flowery  5.441499e-04\n",
       "85       tfidf_85  5.416993e-04\n",
       "108     tfidf_108  5.408731e-04\n",
       "147     tfidf_147  5.408251e-04\n",
       "187     tfidf_187  5.406721e-04\n",
       "180     tfidf_180  5.398716e-04\n",
       "58       tfidf_58  5.350833e-04\n",
       "197     tfidf_197  5.314792e-04\n",
       "384     tfidf_384  5.311171e-04\n",
       "2         tfidf_2  5.282757e-04\n",
       "156     tfidf_156  5.260789e-04\n",
       "188     tfidf_188  5.213558e-04\n",
       "220     tfidf_220  5.183076e-04\n",
       "252     tfidf_252  5.083934e-04\n",
       "102     tfidf_102  5.081821e-04\n",
       "143     tfidf_143  5.032744e-04\n",
       "313     tfidf_313  5.003633e-04\n",
       "65       tfidf_65  4.981843e-04\n",
       "201     tfidf_201  4.917561e-04\n",
       "10       tfidf_10  4.908079e-04\n",
       "35       tfidf_35  4.901722e-04\n",
       "284     tfidf_284  4.898366e-04\n",
       "286     tfidf_286  4.880751e-04\n",
       "269     tfidf_269  4.880283e-04\n",
       "179     tfidf_179  4.878131e-04\n",
       "59       tfidf_59  4.849720e-04\n",
       "464          tree  4.788669e-04\n",
       "31       tfidf_31  4.779540e-04\n",
       "186     tfidf_186  4.774593e-04\n",
       "192     tfidf_192  4.747021e-04\n",
       "171     tfidf_171  4.647540e-04\n",
       "183     tfidf_183  4.545746e-04\n",
       "276     tfidf_276  4.515695e-04\n",
       "115     tfidf_115  4.502703e-04\n",
       "408      headache  4.465171e-04\n",
       "33       tfidf_33  4.457326e-04\n",
       "339     tfidf_339  4.447436e-04\n",
       "432        coffee  4.411210e-04\n",
       "106     tfidf_106  4.408745e-04\n",
       "261     tfidf_261  4.340304e-04\n",
       "259     tfidf_259  4.327658e-04\n",
       "380     tfidf_380  4.260649e-04\n",
       "113     tfidf_113  4.212613e-04\n",
       "347     tfidf_347  4.205459e-04\n",
       "323     tfidf_323  4.199743e-04\n",
       "127     tfidf_127  4.157432e-04\n",
       "84       tfidf_84  4.081726e-04\n",
       "155     tfidf_155  4.062887e-04\n",
       "324     tfidf_324  3.988590e-04\n",
       "172     tfidf_172  3.961463e-04\n",
       "209     tfidf_209  3.960377e-04\n",
       "86       tfidf_86  3.873685e-04\n",
       "195     tfidf_195  3.867855e-04\n",
       "44       tfidf_44  3.862284e-04\n",
       "216     tfidf_216  3.849737e-04\n",
       "92       tfidf_92  3.840317e-04\n",
       "308     tfidf_308  3.840104e-04\n",
       "70       tfidf_70  3.824924e-04\n",
       "140     tfidf_140  3.798910e-04\n",
       "94       tfidf_94  3.797574e-04\n",
       "461           tar  3.789976e-04\n",
       "364     tfidf_364  3.771017e-04\n",
       "334     tfidf_334  3.723662e-04\n",
       "174     tfidf_174  3.675048e-04\n",
       "176     tfidf_176  3.661949e-04\n",
       "446         nutty  3.615191e-04\n",
       "24       tfidf_24  3.579002e-04\n",
       "356     tfidf_356  3.552371e-04\n",
       "49       tfidf_49  3.538805e-04\n",
       "275     tfidf_275  3.382444e-04\n",
       "452     pineapple  3.361866e-04\n",
       "361     tfidf_361  3.347223e-04\n",
       "12       tfidf_12  3.309767e-04\n",
       "83       tfidf_83  3.247989e-04\n",
       "299     tfidf_299  3.246019e-04\n",
       "375     tfidf_375  3.181501e-04\n",
       "244     tfidf_244  3.143098e-04\n",
       "18       tfidf_18  3.124055e-04\n",
       "296     tfidf_296  3.091822e-04\n",
       "62       tfidf_62  3.081028e-04\n",
       "67       tfidf_67  3.048214e-04\n",
       "427        butter  3.021232e-04\n",
       "335     tfidf_335  2.974771e-04\n",
       "148     tfidf_148  2.969564e-04\n",
       "346     tfidf_346  2.942171e-04\n",
       "279     tfidf_279  2.921803e-04\n",
       "383     tfidf_383  2.903242e-04\n",
       "235     tfidf_235  2.872784e-04\n",
       "47       tfidf_47  2.857332e-04\n",
       "450        pepper  2.801136e-04\n",
       "378     tfidf_378  2.759456e-04\n",
       "307     tfidf_307  2.714189e-04\n",
       "3         tfidf_3  2.656310e-04\n",
       "169     tfidf_169  2.643464e-04\n",
       "330     tfidf_330  2.602443e-04\n",
       "298     tfidf_298  2.552014e-04\n",
       "38       tfidf_38  2.532045e-04\n",
       "51       tfidf_51  2.528680e-04\n",
       "322     tfidf_322  2.521152e-04\n",
       "212     tfidf_212  2.514400e-04\n",
       "131     tfidf_131  2.504011e-04\n",
       "68       tfidf_68  2.469942e-04\n",
       "238     tfidf_238  2.451270e-04\n",
       "55       tfidf_55  2.418314e-04\n",
       "290     tfidf_290  2.359483e-04\n",
       "462           tea  2.314900e-04\n",
       "134     tfidf_134  2.300717e-04\n",
       "248     tfidf_248  2.216941e-04\n",
       "448         peach  2.211496e-04\n",
       "100     tfidf_100  2.189186e-04\n",
       "204     tfidf_204  2.135161e-04\n",
       "13       tfidf_13  2.131007e-04\n",
       "268     tfidf_268  2.111316e-04\n",
       "87       tfidf_87  2.088114e-04\n",
       "133     tfidf_133  2.082596e-04\n",
       "300     tfidf_300  2.080660e-04\n",
       "266     tfidf_266  2.075124e-04\n",
       "95       tfidf_95  1.992919e-04\n",
       "327     tfidf_327  1.961141e-04\n",
       "150     tfidf_150  1.956963e-04\n",
       "351     tfidf_351  1.944784e-04\n",
       "60       tfidf_60  1.922291e-04\n",
       "305     tfidf_305  1.912762e-04\n",
       "89       tfidf_89  1.728399e-04\n",
       "15       tfidf_15  1.691510e-04\n",
       "191     tfidf_191  1.640736e-04\n",
       "8         tfidf_8  1.597994e-04\n",
       "250     tfidf_250  1.579339e-04\n",
       "42       tfidf_42  1.519522e-04\n",
       "218     tfidf_218  1.396420e-04\n",
       "293     tfidf_293  1.277785e-04\n",
       "242     tfidf_242  1.125495e-04\n",
       "439         honey  1.104800e-04\n",
       "453          plum  1.075571e-04\n",
       "302     tfidf_302  1.047018e-04\n",
       "430      chestnut  8.566180e-05\n",
       "467        violet  8.296552e-05\n",
       "425   blue cheese  6.664112e-05\n",
       "423       apricot  6.388015e-05\n",
       "422         apple  4.274627e-05\n",
       "444       menthol  4.225592e-05\n",
       "410     migraines  1.930116e-05\n",
       "449          pear  1.561361e-05\n",
       "391       anxiety  1.175506e-05\n",
       "396    depression  1.080270e-05\n",
       "411          pain  6.908236e-08\n",
       "414      seizures  1.481888e-09\n",
       "403  eye pressure  1.411152e-09\n",
       "401      epilepsy  4.958197e-10\n",
       "394     arthritis  0.000000e+00\n",
       "404       fatigue  0.000000e+00\n",
       "416    spasticity  0.000000e+00\n",
       "417        stress  0.000000e+00"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.set_option('display.max_rows', df_feat_ranked.shape[0]+1)\n",
    "df_feat_ranked"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/louispandu/anaconda3/lib/python3.10/site-packages/sklearn/feature_selection/_from_model.py:357: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  self.estimator_.fit(X, y, **fit_params)\n"
     ]
    }
   ],
   "source": [
    "selector = SelectFromModel(rfreg).fit(X_train1, y_train1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1.62697215e-03, 7.87331403e-04, 4.79858570e-04, 2.75836509e-04,\n",
       "       1.52738420e-03, 1.23189069e-03, 3.04812445e-03, 5.45269897e-03,\n",
       "       1.74629687e-04, 1.14692510e-03, 4.99878740e-04, 3.36140925e-03,\n",
       "       3.40826236e-04, 2.37087791e-04, 1.38558785e-03, 1.48278051e-04,\n",
       "       1.61309511e-03, 1.07953411e-03, 3.04815201e-04, 9.53268946e-04,\n",
       "       1.87553486e-03, 1.15867461e-03, 8.09119953e-04, 9.74372265e-04,\n",
       "       2.73153863e-04, 5.70321050e-04, 3.05896325e-03, 5.81131563e-04,\n",
       "       6.75935633e-04, 1.35466137e-03, 5.40406716e-03, 4.69255241e-04,\n",
       "       7.53196414e-04, 4.05196030e-04, 1.41847019e-03, 4.67771427e-04,\n",
       "       1.39217273e-03, 3.97488840e-03, 2.81802140e-04, 2.76803986e-03,\n",
       "       6.05181556e-04, 1.27704062e-03, 1.60051131e-04, 3.35617430e-03,\n",
       "       3.79193996e-04, 7.75156534e-04, 2.14400874e-03, 3.08102620e-04,\n",
       "       2.48952383e-03, 3.56150171e-04, 9.76587384e-04, 2.48745893e-04,\n",
       "       9.09181243e-04, 9.31325067e-04, 9.77127294e-04, 2.26894413e-04,\n",
       "       8.91677224e-04, 5.74567279e-04, 5.71749142e-04, 5.22582388e-04,\n",
       "       2.57725669e-04, 1.48153909e-03, 2.86653123e-04, 5.24301669e-04,\n",
       "       1.25412953e-03, 5.21705381e-04, 7.60379110e-04, 2.79543501e-04,\n",
       "       2.62214947e-04, 9.35640240e-04, 3.55257796e-04, 8.62064370e-04,\n",
       "       6.08473703e-04, 2.42625619e-03, 1.77326500e-03, 8.64901303e-04,\n",
       "       1.32691581e-03, 1.01858906e-03, 3.37248170e-03, 2.37156123e-03,\n",
       "       1.10817501e-03, 8.18312397e-04, 1.59482895e-03, 3.05426072e-04,\n",
       "       3.61497896e-04, 5.62378680e-04, 3.98257291e-04, 2.21162024e-04,\n",
       "       5.48884455e-04, 2.71661102e-04, 2.52128142e-03, 8.92347716e-04,\n",
       "       3.22401331e-04, 3.91876355e-03, 4.08774315e-04, 2.29010855e-04,\n",
       "       9.14528332e-04, 1.56468040e-03, 3.23761820e-03, 1.21379832e-03,\n",
       "       2.44295813e-04, 1.30714661e-03, 4.36974949e-04, 1.59228202e-03,\n",
       "       1.82435453e-03, 7.04833336e-04, 5.60274488e-04, 1.14244362e-03,\n",
       "       5.47782049e-04, 2.53447452e-03, 1.24774209e-03, 2.98114258e-03,\n",
       "       5.93552451e-04, 4.44324894e-04, 1.16613013e-03, 4.65068019e-04,\n",
       "       8.97571025e-04, 8.99892463e-04, 9.30002994e-04, 2.59342495e-03,\n",
       "       8.15360672e-04, 4.02738718e-03, 1.02157445e-03, 9.56097354e-04,\n",
       "       1.19077142e-03, 1.23436325e-03, 1.32452923e-03, 3.52033390e-04,\n",
       "       3.67158755e-03, 1.16104355e-03, 1.23132840e-03, 2.67407469e-04,\n",
       "       7.32185569e-04, 2.13512217e-04, 2.61987334e-04, 1.78688517e-03,\n",
       "       8.91338107e-04, 1.73777159e-03, 7.58295445e-04, 1.48295406e-03,\n",
       "       5.10459601e-04, 1.36655738e-02, 1.13550461e-03, 4.80760300e-04,\n",
       "       2.88365451e-03, 9.67869913e-03, 1.35627754e-03, 4.98366810e-04,\n",
       "       3.39398935e-04, 8.94299877e-03, 2.43087992e-04, 4.20616521e-03,\n",
       "       1.58635330e-03, 1.58679504e-03, 9.82439687e-04, 3.67949644e-04,\n",
       "       5.83057859e-04, 1.10516209e-03, 3.24325982e-03, 1.80176207e-03,\n",
       "       9.09355166e-04, 1.78728286e-03, 4.93079557e-03, 1.01141070e-03,\n",
       "       8.42822486e-04, 6.05793441e-04, 1.49033022e-03, 2.74947640e-03,\n",
       "       1.03319813e-02, 3.04203192e-04, 5.69836593e-04, 4.31390529e-04,\n",
       "       4.64897791e-04, 2.24880874e-03, 4.05091148e-04, 1.05003738e-03,\n",
       "       3.33930765e-04, 1.75551551e-03, 1.58711741e-03, 5.11638107e-04,\n",
       "       5.14821669e-04, 1.22430120e-03, 1.12693730e-03, 5.15079746e-04,\n",
       "       1.30526598e-03, 5.32416230e-04, 5.18336416e-04, 5.55290938e-04,\n",
       "       5.24941850e-04, 1.54411308e-03, 1.96328119e-03, 2.12255647e-04,\n",
       "       5.43977061e-04, 6.93708825e-04, 1.36576203e-03, 3.14007930e-04,\n",
       "       5.11012188e-03, 4.52031096e-04, 1.04012199e-03, 5.32704597e-03,\n",
       "       2.42903235e-03, 5.12470263e-04, 8.77667221e-04, 1.13041027e-03,\n",
       "       1.85261373e-04, 3.59676160e-03, 9.53723998e-04, 6.06743133e-03,\n",
       "       7.52291198e-04, 4.84427093e-04, 4.01627991e-03, 8.40590365e-04,\n",
       "       3.29144496e-04, 7.56186322e-04, 7.45998154e-04, 7.84408269e-04,\n",
       "       3.51792546e-04, 1.24470785e-03, 1.70641606e-04, 8.24576175e-04,\n",
       "       5.18046359e-04, 1.10798054e-03, 1.16733448e-03, 8.67580618e-04,\n",
       "       1.01775723e-03, 6.61933574e-04, 5.23283693e-04, 6.89061198e-04,\n",
       "       9.59222558e-04, 7.97264712e-04, 4.56527620e-03, 8.15976258e-04,\n",
       "       1.65322149e-03, 1.41503057e-03, 8.78438821e-04, 2.90432605e-04,\n",
       "       3.03324846e-03, 1.34977009e-03, 2.37015645e-04, 8.01943096e-03,\n",
       "       2.46935942e-03, 6.35754149e-04, 1.14219025e-04, 1.12399173e-03,\n",
       "       3.93291211e-04, 4.45571525e-03, 2.18425099e-03, 6.24830211e-04,\n",
       "       2.57481156e-04, 1.08911700e-03, 1.31655195e-04, 7.90929413e-04,\n",
       "       4.96557394e-04, 5.77442713e-03, 1.02684050e-03, 1.50442494e-03,\n",
       "       6.71043248e-04, 5.67954385e-04, 2.62411074e-03, 4.47205070e-04,\n",
       "       6.12540613e-04, 2.99990705e-04, 6.87842355e-04, 3.39170752e-03,\n",
       "       1.42426117e-03, 1.70599417e-03, 2.04544052e-04, 1.88505607e-03,\n",
       "       2.41276926e-04, 4.26835484e-04, 7.31786518e-04, 1.11677996e-03,\n",
       "       1.47666474e-02, 3.21756214e-03, 1.99183502e-03, 3.83562895e-04,\n",
       "       4.62579289e-04, 8.33929076e-04, 1.36201400e-03, 2.64572593e-04,\n",
       "       1.52950557e-03, 5.15069276e-03, 2.01424436e-03, 2.00125944e-03,\n",
       "       4.41024905e-04, 6.02814786e-03, 4.89689293e-04, 7.02261884e-04,\n",
       "       8.62850592e-04, 9.75200483e-04, 2.05497134e-04, 2.08823797e-03,\n",
       "       5.96116575e-04, 1.04971167e-04, 9.31727979e-04, 4.73322557e-04,\n",
       "       3.85143623e-04, 1.19927314e-03, 2.64382058e-04, 3.60543264e-04,\n",
       "       1.65240413e-04, 1.25392017e-03, 2.28446667e-04, 1.89692069e-03,\n",
       "       2.38821569e-03, 2.61435080e-04, 6.45653441e-04, 2.54906517e-04,\n",
       "       3.87103465e-04, 6.01538886e-03, 1.10478283e-03, 1.29666517e-03,\n",
       "       7.08091476e-03, 4.96386592e-04, 2.83269124e-03, 5.95529612e-04,\n",
       "       7.20847842e-04, 1.91688397e-03, 9.38176870e-04, 2.99271586e-03,\n",
       "       1.28340118e-03, 1.05642307e-03, 2.19288013e-04, 5.39340553e-04,\n",
       "       3.86531601e-04, 4.95510592e-03, 1.11973926e-03, 1.88624304e-04,\n",
       "       6.74707120e-04, 1.31034916e-02, 2.01228963e-04, 6.41958664e-04,\n",
       "       1.42359296e-03, 6.58942309e-04, 4.82528283e-04, 2.76707998e-04,\n",
       "       1.16261729e-03, 3.00003182e-03, 1.55707833e-03, 4.41715817e-04,\n",
       "       2.63316292e-03, 8.11449763e-04, 2.58587944e-03, 1.99995627e-03,\n",
       "       1.12334491e-03, 1.01743280e-02, 2.72545676e-04, 4.27739582e-04,\n",
       "       1.34319460e-03, 2.88561098e-03, 1.15586650e-03, 1.83997625e-04,\n",
       "       5.32294695e-04, 8.55765058e-04, 9.29953614e-04, 7.85289619e-04,\n",
       "       3.59762542e-04, 6.79039216e-03, 7.66277767e-04, 1.48198801e-03,\n",
       "       2.20981346e-03, 3.34812939e-04, 2.91828786e-03, 5.95012196e-04,\n",
       "       3.39590229e-04, 4.83804986e-04, 3.29140669e-03, 2.57848903e-03,\n",
       "       8.52034287e-04, 1.54685443e-03, 2.02072404e-03, 1.42937736e-03,\n",
       "       1.80812794e-03, 1.95572921e-03, 2.99485321e-03, 2.60222233e-04,\n",
       "       1.30475416e-03, 8.19337280e-04, 3.04116405e-04, 7.07662356e-04,\n",
       "       4.97615508e-04, 2.30456162e-03, 1.83630741e-03, 2.89623021e-04,\n",
       "       7.02120858e-04, 9.76151608e-04, 1.23474906e-03, 6.71925239e-04,\n",
       "       2.63568049e-02, 1.68130751e-02, 2.90441333e-02, 2.30462370e-05,\n",
       "       8.94585461e-04, 1.32292986e-03, 0.00000000e+00, 2.51537303e-03,\n",
       "       1.55719956e-05, 8.07516708e-04, 1.39926232e-03, 4.84004857e-03,\n",
       "       4.53477500e-03, 0.00000000e+00, 3.15348093e-03, 0.00000000e+00,\n",
       "       2.81905890e-09, 2.08419889e-03, 2.37028847e-03, 3.37519614e-03,\n",
       "       4.63043570e-04, 3.01685302e-03, 1.87483574e-05, 0.00000000e+00,\n",
       "       8.83992178e-04, 3.90290751e-03, 0.00000000e+00, 2.13509093e-03,\n",
       "       0.00000000e+00, 0.00000000e+00, 2.09339991e-03, 1.97643953e-03,\n",
       "       2.85707290e-03, 1.37289741e-03, 2.12169160e-05, 9.28655620e-05,\n",
       "       4.20632557e-03, 8.85058581e-05, 1.97106007e-02, 3.36433176e-04,\n",
       "       3.78938685e-03, 4.03807155e-03, 1.06282961e-04, 1.11776084e-02,\n",
       "       4.81246451e-04, 1.55870658e-01, 5.02530997e-03, 6.04975737e-04,\n",
       "       8.73680626e-04, 7.37141015e-03, 7.95301630e-04, 1.19206025e-04,\n",
       "       6.45993512e-04, 5.02845999e-03, 1.75622531e-03, 5.09424471e-02,\n",
       "       4.47878441e-05, 3.26108145e-03, 4.42587050e-04, 2.11136776e-03,\n",
       "       1.82626429e-04, 1.24150682e-05, 2.07625475e-04, 1.71583023e-03,\n",
       "       3.65629886e-04, 1.16801425e-04, 1.61302240e-03, 1.02918054e-03,\n",
       "       2.07114577e-03, 3.22341558e-03, 3.64303154e-03, 8.81824472e-03,\n",
       "       3.27068248e-03, 3.33246470e-04, 1.87037285e-04, 7.32346216e-04,\n",
       "       4.22876106e-04, 1.38275993e-03, 2.67232173e-03, 1.16105481e-04,\n",
       "       1.52250669e-03])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "selector.estimator_.feature_importances_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0021321961620469083"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "selector.threshold_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "mask = selector.get_support()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([False, False, False, False, False, False,  True,  True, False,\n",
       "       False, False,  True, False, False, False, False, False, False,\n",
       "       False, False, False, False, False, False, False, False,  True,\n",
       "       False, False, False,  True, False, False, False, False, False,\n",
       "       False,  True, False,  True, False, False, False,  True, False,\n",
       "       False,  True, False,  True, False, False, False, False, False,\n",
       "       False, False, False, False, False, False, False, False, False,\n",
       "       False, False, False, False, False, False, False, False, False,\n",
       "       False,  True, False, False, False, False,  True,  True, False,\n",
       "       False, False, False, False, False, False, False, False, False,\n",
       "        True, False, False,  True, False, False, False, False,  True,\n",
       "       False, False, False, False, False, False, False, False, False,\n",
       "       False,  True, False,  True, False, False, False, False, False,\n",
       "       False, False,  True, False,  True, False, False, False, False,\n",
       "       False, False,  True, False, False, False, False, False, False,\n",
       "       False, False, False, False, False, False,  True, False, False,\n",
       "        True,  True, False, False, False,  True, False,  True, False,\n",
       "       False, False, False, False, False,  True, False, False, False,\n",
       "        True, False, False, False, False,  True,  True, False, False,\n",
       "       False, False,  True, False, False, False, False, False, False,\n",
       "       False, False, False, False, False, False, False, False, False,\n",
       "       False, False, False, False, False, False, False,  True, False,\n",
       "       False,  True,  True, False, False, False, False,  True, False,\n",
       "        True, False, False,  True, False, False, False, False, False,\n",
       "       False, False, False, False, False, False, False, False, False,\n",
       "       False, False, False, False, False,  True, False, False, False,\n",
       "       False, False,  True, False, False,  True,  True, False, False,\n",
       "       False, False,  True,  True, False, False, False, False, False,\n",
       "       False,  True, False, False, False, False,  True, False, False,\n",
       "       False, False,  True, False, False, False, False, False, False,\n",
       "       False, False,  True,  True, False, False, False, False, False,\n",
       "       False, False,  True, False, False, False,  True, False, False,\n",
       "       False, False, False, False, False, False, False, False, False,\n",
       "       False, False, False, False, False, False, False,  True, False,\n",
       "       False, False, False,  True, False, False,  True, False,  True,\n",
       "       False, False, False, False,  True, False, False, False, False,\n",
       "       False,  True, False, False, False,  True, False, False, False,\n",
       "       False, False, False, False,  True, False, False,  True, False,\n",
       "        True, False, False,  True, False, False, False,  True, False,\n",
       "       False, False, False, False, False, False,  True, False, False,\n",
       "        True, False,  True, False, False, False,  True,  True, False,\n",
       "       False, False, False, False, False,  True, False, False, False,\n",
       "       False, False, False,  True, False, False, False, False, False,\n",
       "       False,  True,  True,  True, False, False, False, False,  True,\n",
       "       False, False, False,  True,  True, False,  True, False, False,\n",
       "       False,  True,  True, False,  True, False, False, False,  True,\n",
       "       False,  True, False, False, False, False,  True, False, False,\n",
       "       False,  True, False,  True, False,  True,  True, False,  True,\n",
       "       False,  True,  True, False, False,  True, False, False, False,\n",
       "        True, False,  True, False,  True, False, False, False, False,\n",
       "       False, False, False, False, False, False, False,  True,  True,\n",
       "        True,  True, False, False, False, False, False,  True, False,\n",
       "       False])"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "selected_features = X.columns[mask]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tfidf_6</th>\n",
       "      <th>tfidf_7</th>\n",
       "      <th>tfidf_11</th>\n",
       "      <th>tfidf_26</th>\n",
       "      <th>tfidf_30</th>\n",
       "      <th>tfidf_37</th>\n",
       "      <th>tfidf_39</th>\n",
       "      <th>tfidf_43</th>\n",
       "      <th>tfidf_46</th>\n",
       "      <th>tfidf_48</th>\n",
       "      <th>...</th>\n",
       "      <th>earthy</th>\n",
       "      <th>grape</th>\n",
       "      <th>lemon</th>\n",
       "      <th>mango</th>\n",
       "      <th>mint</th>\n",
       "      <th>skunk</th>\n",
       "      <th>spicy/herbal</th>\n",
       "      <th>strawberry</th>\n",
       "      <th>sweet</th>\n",
       "      <th>vanilla</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.14162</td>\n",
       "      <td>0.189796</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.198545</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.165804</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.115840</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>74995</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>74996</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>74997</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>74998</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>74999</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>75000 rows × 98 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       tfidf_6  tfidf_7  tfidf_11  tfidf_26  tfidf_30  tfidf_37  tfidf_39  \\\n",
       "0          0.0      0.0  0.000000       0.0       0.0   0.14162  0.189796   \n",
       "1          0.0      0.0  0.000000       0.0       0.0   0.00000  0.000000   \n",
       "2          0.0      0.0  0.000000       0.0       0.0   0.00000  0.000000   \n",
       "3          0.0      0.0  0.165804       0.0       0.0   0.00000  0.000000   \n",
       "4          0.0      0.0  0.115840       0.0       0.0   0.00000  0.000000   \n",
       "...        ...      ...       ...       ...       ...       ...       ...   \n",
       "74995      0.0      0.0  0.000000       0.0       0.0   0.00000  0.000000   \n",
       "74996      0.0      0.0  0.000000       0.0       0.0   0.00000  0.000000   \n",
       "74997      0.0      0.0  0.000000       0.0       0.0   0.00000  0.000000   \n",
       "74998      0.0      0.0  0.000000       0.0       0.0   0.00000  0.000000   \n",
       "74999      0.0      0.0  0.000000       0.0       0.0   0.00000  0.000000   \n",
       "\n",
       "       tfidf_43  tfidf_46  tfidf_48  ...  earthy  grape  lemon  mango  mint  \\\n",
       "0      0.000000       0.0       0.0  ...       0      0      0      0     0   \n",
       "1      0.000000       0.0       0.0  ...       0      0      0      0     0   \n",
       "2      0.198545       0.0       0.0  ...       0      0      0      0     0   \n",
       "3      0.000000       0.0       0.0  ...       0      0      0      0     0   \n",
       "4      0.000000       0.0       0.0  ...       1      0      0      0     0   \n",
       "...         ...       ...       ...  ...     ...    ...    ...    ...   ...   \n",
       "74995  0.000000       0.0       0.0  ...       0      0      0      0     0   \n",
       "74996  0.000000       0.0       0.0  ...       0      0      0      0     0   \n",
       "74997  0.000000       0.0       0.0  ...       0      0      0      0     0   \n",
       "74998  0.000000       0.0       0.0  ...       0      0      0      0     0   \n",
       "74999  0.000000       0.0       0.0  ...       0      0      0      0     0   \n",
       "\n",
       "       skunk  spicy/herbal  strawberry  sweet  vanilla  \n",
       "0          0             0           0      0        0  \n",
       "1          0             1           0      0        1  \n",
       "2          0             0           0      1        1  \n",
       "3          0             0           0      0        0  \n",
       "4          1             0           0      0        1  \n",
       "...      ...           ...         ...    ...      ...  \n",
       "74995      0             0           0      0        0  \n",
       "74996      0             0           0      0        0  \n",
       "74997      0             0           0      0        0  \n",
       "74998      0             0           0      0        0  \n",
       "74999      0             0           0      0        0  \n",
       "\n",
       "[75000 rows x 98 columns]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "selected_X = df_rf[selected_features]\n",
    "selected_X"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train test split (after Feature Selection)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['selected_X_rf_tfidf_camph.pkl']"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import joblib\n",
    "\n",
    "joblib.dump(selector, \"selector_rf_tfidf_camph.pkl\")\n",
    "joblib.dump(selected_X, \"selected_X_rf_tfidf_camph.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(selected_X, y, random_state=1, test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train1, X_val, y_train1, y_val = train_test_split(X_train, y_train, random_state=1, test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/ns/m5pnr0211w91v02hpv22958m0000gn/T/ipykernel_87881/3758305.py:1: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  rfreg.fit(X_train1, y_train1)\n"
     ]
    }
   ],
   "source": [
    "rfreg.fit(X_train1, y_train1)\n",
    "y_pred_rfreg = rfreg.predict(X_val)\n",
    "y_pred_rfreg_r2 = rfreg.predict(X_train1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.05593999170570889"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mean_absolute_error(y_val, y_pred_rfreg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.012349639955195888"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mean_squared_error(y_val, y_pred_rfreg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.1111289339245"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mean_squared_error(y_val, y_pred_rfreg, squared = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.971751146693683"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#train\n",
    "r2_score(y_train1, y_pred_rfreg_r2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8890578234947513"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#val\n",
    "r2_score(y_val, y_pred_rfreg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hyperparameter Tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "parameters = {'max_depth': [None, 10, 50, 100],\n",
    "              'max_features': ['auto', 'sqrt'],\n",
    "              'min_samples_leaf': [1, 2, 4],\n",
    "              'min_samples_split': [2, 5, 10],\n",
    "              'n_estimators': [100, 300, 500]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "rscv = RandomizedSearchCV(rfreg,  \n",
    "                     parameters,   \n",
    "                     cv=5, \n",
    "                     scoring='neg_mean_absolute_error',\n",
    "                     n_jobs = -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/louispandu/anaconda3/lib/python3.10/site-packages/sklearn/model_selection/_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/Users/louispandu/anaconda3/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
      "  warn(\n",
      "/Users/louispandu/anaconda3/lib/python3.10/site-packages/sklearn/model_selection/_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/Users/louispandu/anaconda3/lib/python3.10/site-packages/sklearn/model_selection/_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/Users/louispandu/anaconda3/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
      "  warn(\n",
      "/Users/louispandu/anaconda3/lib/python3.10/site-packages/sklearn/model_selection/_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/Users/louispandu/anaconda3/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
      "  warn(\n",
      "/Users/louispandu/anaconda3/lib/python3.10/site-packages/sklearn/model_selection/_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/Users/louispandu/anaconda3/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
      "  warn(\n",
      "/Users/louispandu/anaconda3/lib/python3.10/site-packages/sklearn/model_selection/_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/Users/louispandu/anaconda3/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
      "  warn(\n",
      "/Users/louispandu/anaconda3/lib/python3.10/site-packages/sklearn/model_selection/_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/Users/louispandu/anaconda3/lib/python3.10/site-packages/sklearn/model_selection/_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/Users/louispandu/anaconda3/lib/python3.10/site-packages/sklearn/model_selection/_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/Users/louispandu/anaconda3/lib/python3.10/site-packages/sklearn/model_selection/_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/Users/louispandu/anaconda3/lib/python3.10/site-packages/sklearn/model_selection/_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/Users/louispandu/anaconda3/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
      "  warn(\n",
      "/Users/louispandu/anaconda3/lib/python3.10/site-packages/sklearn/model_selection/_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/Users/louispandu/anaconda3/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
      "  warn(\n",
      "/Users/louispandu/anaconda3/lib/python3.10/site-packages/sklearn/model_selection/_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/Users/louispandu/anaconda3/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
      "  warn(\n",
      "/Users/louispandu/anaconda3/lib/python3.10/site-packages/sklearn/model_selection/_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/Users/louispandu/anaconda3/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
      "  warn(\n",
      "/Users/louispandu/anaconda3/lib/python3.10/site-packages/sklearn/model_selection/_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/Users/louispandu/anaconda3/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
      "  warn(\n",
      "/Users/louispandu/anaconda3/lib/python3.10/site-packages/sklearn/model_selection/_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/Users/louispandu/anaconda3/lib/python3.10/site-packages/sklearn/model_selection/_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/Users/louispandu/anaconda3/lib/python3.10/site-packages/sklearn/model_selection/_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/Users/louispandu/anaconda3/lib/python3.10/site-packages/sklearn/model_selection/_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/Users/louispandu/anaconda3/lib/python3.10/site-packages/sklearn/model_selection/_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/Users/louispandu/anaconda3/lib/python3.10/site-packages/sklearn/model_selection/_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/Users/louispandu/anaconda3/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
      "  warn(\n",
      "/Users/louispandu/anaconda3/lib/python3.10/site-packages/sklearn/model_selection/_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/Users/louispandu/anaconda3/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
      "  warn(\n",
      "/Users/louispandu/anaconda3/lib/python3.10/site-packages/sklearn/model_selection/_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/Users/louispandu/anaconda3/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
      "  warn(\n",
      "/Users/louispandu/anaconda3/lib/python3.10/site-packages/sklearn/model_selection/_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/Users/louispandu/anaconda3/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
      "  warn(\n",
      "/Users/louispandu/anaconda3/lib/python3.10/site-packages/sklearn/model_selection/_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/Users/louispandu/anaconda3/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
      "  warn(\n",
      "/Users/louispandu/anaconda3/lib/python3.10/site-packages/sklearn/model_selection/_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/Users/louispandu/anaconda3/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
      "  warn(\n",
      "/Users/louispandu/anaconda3/lib/python3.10/site-packages/sklearn/model_selection/_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/Users/louispandu/anaconda3/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
      "  warn(\n",
      "/Users/louispandu/anaconda3/lib/python3.10/site-packages/sklearn/model_selection/_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/Users/louispandu/anaconda3/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
      "  warn(\n",
      "/Users/louispandu/anaconda3/lib/python3.10/site-packages/sklearn/model_selection/_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/Users/louispandu/anaconda3/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
      "  warn(\n",
      "/Users/louispandu/anaconda3/lib/python3.10/site-packages/sklearn/model_selection/_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/Users/louispandu/anaconda3/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
      "  warn(\n",
      "/Users/louispandu/anaconda3/lib/python3.10/site-packages/sklearn/model_selection/_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/Users/louispandu/anaconda3/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
      "  warn(\n",
      "/Users/louispandu/anaconda3/lib/python3.10/site-packages/sklearn/model_selection/_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/Users/louispandu/anaconda3/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
      "  warn(\n",
      "/Users/louispandu/anaconda3/lib/python3.10/site-packages/sklearn/model_selection/_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/Users/louispandu/anaconda3/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
      "  warn(\n",
      "/Users/louispandu/anaconda3/lib/python3.10/site-packages/sklearn/model_selection/_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/Users/louispandu/anaconda3/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
      "  warn(\n",
      "/Users/louispandu/anaconda3/lib/python3.10/site-packages/sklearn/model_selection/_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/Users/louispandu/anaconda3/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
      "  warn(\n",
      "/Users/louispandu/anaconda3/lib/python3.10/site-packages/sklearn/model_selection/_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/Users/louispandu/anaconda3/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
      "  warn(\n",
      "/Users/louispandu/anaconda3/lib/python3.10/site-packages/sklearn/model_selection/_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/Users/louispandu/anaconda3/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
      "  warn(\n",
      "/Users/louispandu/anaconda3/lib/python3.10/site-packages/sklearn/model_selection/_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/Users/louispandu/anaconda3/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
      "  warn(\n",
      "/Users/louispandu/anaconda3/lib/python3.10/site-packages/sklearn/model_selection/_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/Users/louispandu/anaconda3/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
      "  warn(\n",
      "/Users/louispandu/anaconda3/lib/python3.10/site-packages/sklearn/model_selection/_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/Users/louispandu/anaconda3/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
      "  warn(\n",
      "/Users/louispandu/anaconda3/lib/python3.10/site-packages/sklearn/model_selection/_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/Users/louispandu/anaconda3/lib/python3.10/site-packages/sklearn/model_selection/_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/Users/louispandu/anaconda3/lib/python3.10/site-packages/sklearn/model_selection/_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/Users/louispandu/anaconda3/lib/python3.10/site-packages/sklearn/model_selection/_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/Users/louispandu/anaconda3/lib/python3.10/site-packages/sklearn/model_selection/_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/Users/louispandu/anaconda3/lib/python3.10/site-packages/sklearn/model_selection/_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/Users/louispandu/anaconda3/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
      "  warn(\n",
      "/Users/louispandu/anaconda3/lib/python3.10/site-packages/sklearn/model_selection/_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/Users/louispandu/anaconda3/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
      "  warn(\n",
      "/Users/louispandu/anaconda3/lib/python3.10/site-packages/sklearn/model_selection/_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/Users/louispandu/anaconda3/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
      "  warn(\n",
      "/Users/louispandu/anaconda3/lib/python3.10/site-packages/sklearn/model_selection/_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/Users/louispandu/anaconda3/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
      "  warn(\n",
      "/Users/louispandu/anaconda3/lib/python3.10/site-packages/sklearn/model_selection/_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/Users/louispandu/anaconda3/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
      "  warn(\n",
      "/Users/louispandu/anaconda3/lib/python3.10/site-packages/sklearn/model_selection/_search.py:909: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  self.best_estimator_.fit(X, y, **fit_params)\n",
      "/Users/louispandu/anaconda3/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
      "  warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-2 {color: black;background-color: white;}#sk-container-id-2 pre{padding: 0;}#sk-container-id-2 div.sk-toggleable {background-color: white;}#sk-container-id-2 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-2 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-2 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-2 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-2 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-2 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-2 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-2 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-2 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-2 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-2 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-2 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-2 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-2 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-2 div.sk-item {position: relative;z-index: 1;}#sk-container-id-2 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-2 div.sk-item::before, #sk-container-id-2 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-2 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-2 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-2 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-2 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-2 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-2 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-2 div.sk-label-container {text-align: center;}#sk-container-id-2 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-2 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-2\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>RandomizedSearchCV(cv=5, estimator=RandomForestRegressor(), n_jobs=-1,\n",
       "                   param_distributions={&#x27;max_depth&#x27;: [None, 10, 50, 100],\n",
       "                                        &#x27;max_features&#x27;: [&#x27;auto&#x27;, &#x27;sqrt&#x27;],\n",
       "                                        &#x27;min_samples_leaf&#x27;: [1, 2, 4],\n",
       "                                        &#x27;min_samples_split&#x27;: [2, 5, 10],\n",
       "                                        &#x27;n_estimators&#x27;: [100, 300, 500]},\n",
       "                   scoring=&#x27;neg_mean_absolute_error&#x27;)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" ><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">RandomizedSearchCV</label><div class=\"sk-toggleable__content\"><pre>RandomizedSearchCV(cv=5, estimator=RandomForestRegressor(), n_jobs=-1,\n",
       "                   param_distributions={&#x27;max_depth&#x27;: [None, 10, 50, 100],\n",
       "                                        &#x27;max_features&#x27;: [&#x27;auto&#x27;, &#x27;sqrt&#x27;],\n",
       "                                        &#x27;min_samples_leaf&#x27;: [1, 2, 4],\n",
       "                                        &#x27;min_samples_split&#x27;: [2, 5, 10],\n",
       "                                        &#x27;n_estimators&#x27;: [100, 300, 500]},\n",
       "                   scoring=&#x27;neg_mean_absolute_error&#x27;)</pre></div></div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-3\" type=\"checkbox\" ><label for=\"sk-estimator-id-3\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">estimator: RandomForestRegressor</label><div class=\"sk-toggleable__content\"><pre>RandomForestRegressor()</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-4\" type=\"checkbox\" ><label for=\"sk-estimator-id-4\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">RandomForestRegressor</label><div class=\"sk-toggleable__content\"><pre>RandomForestRegressor()</pre></div></div></div></div></div></div></div></div></div></div>"
      ],
      "text/plain": [
       "RandomizedSearchCV(cv=5, estimator=RandomForestRegressor(), n_jobs=-1,\n",
       "                   param_distributions={'max_depth': [None, 10, 50, 100],\n",
       "                                        'max_features': ['auto', 'sqrt'],\n",
       "                                        'min_samples_leaf': [1, 2, 4],\n",
       "                                        'min_samples_split': [2, 5, 10],\n",
       "                                        'n_estimators': [100, 300, 500]},\n",
       "                   scoring='neg_mean_absolute_error')"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rscv.fit(X_train1, y_train1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'n_estimators': 300,\n",
       " 'min_samples_split': 2,\n",
       " 'min_samples_leaf': 1,\n",
       " 'max_features': 'auto',\n",
       " 'max_depth': None}"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rscv.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['rscv_rf_tfidf_best_params_camph.pkl']"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "joblib.dump(rscv, \"rscv_rf_tfidf_camph.pkl\")\n",
    "joblib.dump(rscv.best_params_, \"rscv_rf_tfidf_best_params_camph.pkl\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "RF (after Hyperparameter Tuning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/ns/m5pnr0211w91v02hpv22958m0000gn/T/ipykernel_87881/210623243.py:2: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  rfreg_ht.fit(X_train1, y_train1)\n",
      "/Users/louispandu/anaconda3/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
      "  warn(\n"
     ]
    }
   ],
   "source": [
    "rfreg_ht = RandomForestRegressor(n_estimators = 300, min_samples_split = 2, min_samples_leaf = 1, max_features = 'auto', max_depth = None)\n",
    "rfreg_ht.fit(X_train1, y_train1)\n",
    "y_pred_rfreg = rfreg_ht.predict(X_val)\n",
    "y_pred_rfreg_r2 = rfreg_ht.predict(X_train1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.055623424922694585"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mean_absolute_error(y_val, y_pred_rfreg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.01223322872989285"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mean_squared_error(y_val, y_pred_rfreg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.1106039272806027"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mean_squared_error(y_val, y_pred_rfreg, squared = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.972336771772643"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#train\n",
    "r2_score(y_train1, y_pred_rfreg_r2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8901035960639611"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#val\n",
    "r2_score(y_val, y_pred_rfreg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Residual plots after Hyperparameter Tuning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Predicting model on the test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_rfreg_test = rfreg_ht.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['y_test_rfreg_tfidf_camph.pkl']"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "joblib.dump(y_pred_rfreg_test, \"y_pred_rfreg_test_tfidf_camph.pkl\")\n",
    "joblib.dump(y_test, \"y_test_rfreg_tfidf_camph.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.05421715294972489"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mean_absolute_error(y_test, y_pred_rfreg_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.011643321034123268"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mean_squared_error(y_test, y_pred_rfreg_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.10790422157693029"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mean_squared_error(y_test, y_pred_rfreg_test, squared = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8966880674172134"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "r2_score(y_test, y_pred_rfreg_test)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Error analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 800x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# assume y_pred is a numpy array and y_true is a pandas dataframe\n",
    "fig, ax = plt.subplots(figsize=(8, 6))\n",
    "\n",
    "column = \"X..Camphene\"  # specify the target variable name\n",
    "ax.hist(y_pred_rfreg_test, alpha=0.5, label='y_pred', bins=20)\n",
    "ax.hist(y_test[column], alpha=0.5, label='y_true', bins=20)\n",
    "ax.legend(loc='upper right')\n",
    "ax.set_title(column)\n",
    "\n",
    "plt.show()\n",
    "plt.savefig('error_hist_knn_tfidf_camph.png')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pearson R"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pearson correlation coefficient: 0.949\n",
      "P-value: 0.000\n"
     ]
    }
   ],
   "source": [
    "corr_coef, p_value = pearsonr(y_pred_rfreg_test.flatten(), y_test.values.ravel())\n",
    "\n",
    "print(f\"Pearson correlation coefficient: {corr_coef:.3f}\")\n",
    "print(f\"P-value: {p_value:.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Axes: >"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAhUAAAGiCAYAAABQwzQuAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjcuMCwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy88F64QAAAACXBIWXMAAA9hAAAPYQGoP6dpAAA1IUlEQVR4nO3de1xVdb7/8fcWYYMapGIgmYKOIQZ5AeM2eCkHovTkZJPayXTGLp7pIvJzmvCSqBUnMnMcQdNklM6kdnK0mrREGy8cMMIB03TUUtvlsIdwSsZLG4T1+8PjnvZstL1tcYR8PR+P9Xi4v+uzvuuznct++11rr20xDMMQAADA99TmSjcAAAB+GAgVAADAFIQKAABgCkIFAAAwBaECAACYglABAABMQagAAACmIFQAAABTECoAAIApCBUAAMAUhAoAAFqIHTt2aOTIkQoLC5PFYtGGDRsuWV9VVaX77rtPkZGRatOmjTIyMpqsW7dunfr27Sur1aq+fftq/fr1bjX5+fmKiIiQv7+/YmNjtXPnTq/7J1QAANBCnD59Wv369dPixYs9qnc4HOrSpYtmzJihfv36NVlTWlqqMWPGaPz48dqzZ4/Gjx+ve++9Vx988IGzZu3atcrIyNCMGTNUUVGhlJQUpaeny2azedW/hR8UAwCg5bFYLFq/fr1GjRrlUf3QoUPVv39/LVy40GV8zJgxqq2t1aZNm5xjt99+uzp27KjVq1dLkuLj4zVw4EAtWbLEWRMVFaVRo0YpJyfH455ZqQAAoBk5HA7V1ta6bA6H4//s/KWlpUpNTXUZS0tLU0lJiSSprq5Ou3fvdqtJTU111niq7fdr1Tzv+EZe6RYAAK3EnfUHm3V+Mz+TPpwxTnPmzHEZmz17trKzs007x6XY7XaFhIS4jIWEhMhut0uSampq1NDQcMkaT7WYUAEAwA9RVlaWMjMzXcasVuv/aQ8Wi8XltWEYbmOe1HwXQgUAAM3IarX+n4eIbwsNDXVbcaiurnauTAQHB8vHx+eSNZ7ingoAAH7AEhMTVVRU5DK2efNmJSUlSZL8/PwUGxvrVlNUVOSs8RQrFQAAtBCnTp3SJ5984nx99OhRVVZWqlOnTurevbuysrJ0/PhxFRYWOmsqKyudx3755ZeqrKyUn5+f+vbtK0maMmWKBg8erOeff1533XWX3nzzTW3ZskXFxcXOOTIzMzV+/HjFxcUpMTFRy5Ytk81m0+TJk73qv8V8pZQbNQEAnmpNN2p60+u2bds0bNgwt/EJEyZo5cqVmjhxoo4dO6Zt27Y59zV130OPHj107Ngx5+s33nhDM2fO1JEjR9SrVy89++yzuvvuu12Oyc/PV25urqqqqhQdHa2XXnpJgwcP9rh3iVABAGiFfqihorXjngoAAGAKQgUAADAFoQIAAJiCUAEAAExBqAAAAKYgVAAAAFMQKgAAgCkIFQAAwBSECgAAYApCBQAAMAWhAgAAmIJQAQAATEGoAAAApiBUAAAAUxAqAACAKQgVAADAFIQKAABgCkIFAAAwBaECAACYglABAABMQagAAACmIFQAAABTECoAAIApCBUAAMAUhAoAAGAKQgUAADAFoQIAAJiCUAEAAExBqAAAAKYgVAAAAFMQKgAAgCkIFQAAwBSECgAAYApCBQAAMAWhAgAAmIJQAQBAC7Fjxw6NHDlSYWFhslgs2rBhw3ces337dsXGxsrf3189e/bU0qVLXfYPHTpUFovFbbvzzjudNdnZ2W77Q0NDve6fUAEAQAtx+vRp9evXT4sXL/ao/ujRo7rjjjuUkpKiiooKTZ8+XU888YTWrVvnrPnDH/6gqqoq57Zv3z75+PjoZz/7mctcN910k0vd3r17ve6/rddHAACAZpGenq709HSP65cuXaru3btr4cKFkqSoqCiVl5dr/vz5Gj16tCSpU6dOLsesWbNG7dq1cwsVbdu2vazViW9jpQIAgGbkcDhUW1vrsjkcDlPmLi0tVWpqqstYWlqaysvLVV9f3+QxK1as0NixY9W+fXuX8cOHDyssLEwREREaO3asjhw54nU/hAoAAJpRTk6OgoKCXLacnBxT5rbb7QoJCXEZCwkJ0blz51RTU+NWX1ZWpn379unBBx90GY+Pj1dhYaHee+89LV++XHa7XUlJSTpx4oRX/XD5AwCAZpSVlaXMzEyXMavVatr8FovF5bVhGE2OS+dXKaKjo3XLLbe4jH/7kktMTIwSExPVq1cvrVq1yq33SyFUAADQjKxWq6kh4ttCQ0Nlt9tdxqqrq9W2bVt17tzZZfzMmTNas2aN5s6d+53ztm/fXjExMTp8+LBX/XD5AwCAVioxMVFFRUUuY5s3b1ZcXJx8fX1dxl9//XU5HA7df//93zmvw+HQgQMH1LVrV6/6IVQAANBCnDp1SpWVlaqsrJR0/iujlZWVstlsks5fSnnggQec9ZMnT9Znn32mzMxMHThwQAUFBVqxYoWmTZvmNveKFSs0atQotxUMSZo2bZq2b9+uo0eP6oMPPtA999yj2tpaTZgwwav+ufwBAEALUV5ermHDhjlfX7ifYcKECVq5cqWqqqqcAUOSIiIitHHjRk2dOlV5eXkKCwvTokWLnF8nveDQoUMqLi7W5s2bmzzvF198oXHjxqmmpkZdunRRQkKCdu3apR49enjVv8W4cEfHFfaOb+SVbgEA0ErcWX+wWec38zOpuXttSbj8AQAATEGoAAAApiBUAAAAUxAqAACAKQgVAADAFIQKAABgCkIFAAAwBaECAACYglABAABMQagAAACmIFQAAABTECoAAIApCBUAAMAUhAoAAGAKQgUAADAFoQIAAJiCUAEAAExBqAAAAKYgVAAAAFMQKgAAgCkIFQAAwBSECgAAYApCBQAAMAWhAgAAmIJQAQAATEGoAAAApiBUAAAAUxAqAACAKQgVAADAFIQKAABgCkIFAAAwBaECAACYglABAABMQagAAACmIFQAAABTECoAAGghduzYoZEjRyosLEwWi0UbNmz4zmO2b9+u2NhY+fv7q2fPnlq6dKnL/pUrV8pisbht33zzjUtdfn6+IiIi5O/vr9jYWO3cudPr/gkVAAC0EKdPn1a/fv20ePFij+qPHj2qO+64QykpKaqoqND06dP1xBNPaN26dS51gYGBqqqqctn8/f2d+9euXauMjAzNmDFDFRUVSklJUXp6umw2m1f9t/WqGgAANJv09HSlp6d7XL906VJ1795dCxculCRFRUWpvLxc8+fP1+jRo511FotFoaGhF51nwYIFmjRpkh588EFJ0sKFC/Xee+9pyZIlysnJ8bgfVioAAGhGDodDtbW1LpvD4TBl7tLSUqWmprqMpaWlqby8XPX19c6xU6dOqUePHurWrZtGjBihiooK5766ujrt3r3bbZ7U1FSVlJR41Q+hAgCAZpSTk6OgoCCXzZt//V+K3W5XSEiIy1hISIjOnTunmpoaSVKfPn20cuVKvfXWW1q9erX8/f2VnJysw4cPS5JqamrU0NDQ5Dx2u92rfrj8AQBAM8rKylJmZqbLmNVqNW1+i8Xi8towDJfxhIQEJSQkOPcnJydr4MCB+u1vf6tFixZdcp5/HfsuhAoAAJqR1Wo1NUR8W2hoqNtqQnV1tdq2bavOnTs3eUybNm00aNAg50pFcHCwfHx8mpznX1cvvguXPwAAaKUSExNVVFTkMrZ582bFxcXJ19e3yWMMw1BlZaW6du0qSfLz81NsbKzbPEVFRUpKSvKqH1YqAABoIU6dOqVPPvnE+fro0aOqrKxUp06d1L17d2VlZen48eMqLCyUJE2ePFmLFy9WZmamHnroIZWWlmrFihVavXq1c445c+YoISFBvXv3Vm1trRYtWqTKykrl5eU5azIzMzV+/HjFxcUpMTFRy5Ytk81m0+TJk73qn1ABAEALUV5ermHDhjlfX7gXY8KECVq5cqWqqqpcnh0RERGhjRs3aurUqcrLy1NYWJgWLVrk8nXSr7/+Wg8//LDsdruCgoI0YMAA7dixQ7fccouzZsyYMTpx4oTmzp2rqqoqRUdHa+PGjerRo4dX/VuMC3d0XGHv+EZe6RYAAK3EnfUHm3V+Mz+TmrvXloR7KgAAgCkIFQAAwBSECgAAYApCBQAAMAWhAgAAmIJQAQAATEGoAAAApiBUAAAAUxAqAACAKQgVAADAFIQKAABgCkIFAAAwBaECAACYglABAABMQagAAACmIFQAAABTECoAAIApCBUAAMAUhAoAAGAKQgUAADAFoQIAAJiCUAEAAExBqAAAAKYgVAAAAFMQKgAAgCkIFQAAwBSECgAAYApCBQAAMAWhAgAAmIJQAQAATEGoAAAApiBUAAAAUxAqAACAKQgVAADAFIQKAABgCkIFAAAwBaECAIAWYseOHRo5cqTCwsJksVi0YcOG7zxm+/btio2Nlb+/v3r27KmlS5e67F++fLlSUlLUsWNHdezYUcOHD1dZWZlLTXZ2tiwWi8sWGhrqdf+ECgAAWojTp0+rX79+Wrx4sUf1R48e1R133KGUlBRVVFRo+vTpeuKJJ7Ru3TpnzbZt2zRu3Dj96U9/Umlpqbp3767U1FQdP37cZa6bbrpJVVVVzm3v3r1e99/W6yMAAIDHHA6HHA6Hy5jVapXVanWrTU9PV3p6usdzL126VN27d9fChQslSVFRUSovL9f8+fM1evRoSdLvf/97l2OWL1+uN954Q1u3btUDDzzgHG/btu1lrU58GysVAAA0o5ycHAUFBblsOTk5psxdWlqq1NRUl7G0tDSVl5ervr6+yWPOnDmj+vp6derUyWX88OHDCgsLU0REhMaOHasjR4543Q8rFQAANKOsrCxlZma6jDW1SnE57Ha7QkJCXMZCQkJ07tw51dTUqGvXrm7HPPXUU7r++us1fPhw51h8fLwKCwt144036m9/+5ueeeYZJSUl6eOPP1bnzp097odQAQBAM7rYpQ6zWCwWl9eGYTQ5Lkm5ublavXq1tm3bJn9/f+f4ty+5xMTEKDExUb169dKqVavcAtGlXNblj507d+r+++9XYmKi80aPV199VcXFxZczHQAAuAyhoaGy2+0uY9XV1Wrbtq3bCsP8+fP13HPPafPmzbr55psvOW/79u0VExOjw4cPe9WP16Fi3bp1SktLU0BAgCoqKpw3n/zjH//Qc8895+10AADgMiUmJqqoqMhlbPPmzYqLi5Ovr69z7IUXXtC8efP07rvvKi4u7jvndTgcOnDgQJOXTy7F61DxzDPPaOnSpVq+fLlLw0lJSfrzn//s7XQAAOB/nTp1SpWVlaqsrJR0/iujlZWVstlsks7fn/Htb2xMnjxZn332mTIzM3XgwAEVFBRoxYoVmjZtmrMmNzdXM2fOVEFBgcLDw2W322W323Xq1ClnzbRp07R9+3YdPXpUH3zwge655x7V1tZqwoQJXvXvdag4ePCgBg8e7DYeGBior7/+2tvpAADA/yovL9eAAQM0YMAASVJmZqYGDBigp59+WpJUVVXlDBiSFBERoY0bN2rbtm3q37+/5s2bp0WLFjm/TipJ+fn5qqur0z333KOuXbs6t/nz5ztrvvjiC40bN06RkZG6++675efnp127dqlHjx5e9e/1jZpdu3bVJ598ovDwcJfx4uJi9ezZ09vpAADA/xo6dKjzRsumrFy50m1syJAhl7xScOzYse8875o1azxp7zt5vVLxyCOPaMqUKfrggw9ksVj017/+Vb///e81bdo0/fKXvzSlKQAA0Pp4vVLx5JNP6uTJkxo2bJi++eYbDR48WFarVdOmTdNjjz3WHD0CAIBWwGJcap3lEs6cOaP9+/ersbFRffv2VYcOHb5XI+/4Rn6v4wEAV4876w826/xmfiY1d68tyWU//Kpdu3YefS0FAABcHbwOFadPn9Z//ud/auvWraqurlZjY6PL/st5VjgAAGj9vA4VDz74oLZv367x48era9euTT4GFAAAXH28DhWbNm3SO++8o+Tk5OboBwAAtFJef6W0Y8eObj+XCgAA4HWomDdvnp5++mmdOXOmOfoBAACtlNeXP1588UV9+umnCgkJUXh4uMvvf0ji9z8AALhKeR0qRo0a1QxtAACA1s7rUDF79uzm6AMAALRyXt9TIUlff/21XnnlFWVlZenvf/+7pPOXPY4fP25qcwAAoPXweqXio48+0vDhwxUUFKRjx47poYceUqdOnbR+/Xp99tlnKiwsbI4+AQBAC+f1SkVmZqYmTpyow4cPy9/f3zmenp6uHTt2mNocAABoPbwOFR9++KEeeeQRt/Hrr79edrvdlKYAAEDr43Wo8Pf3V21trdv4wYMH1aVLF1OaAgAArY/XoeKuu+7S3LlzVV9fL0myWCyy2Wx66qmnNHr0aNMbBAAArYPXoWL+/Pn68ssvdd111+ns2bMaMmSIfvSjH+maa67Rs88+2xw9AgCAVsDrb38EBgaquLhY77//vv785z+rsbFRAwcO1PDhw5ujPwAA0Ep4HSouuPXWW3Xrrbea2QsAAGjFLitUbN26VVu3blV1dbUaGxtd9hUUFJjSGAAAaF28DhVz5szR3LlzFRcXp65du8pisTRHXwAAoJXxOlQsXbpUK1eu1Pjx45ujHwAA0Ep5/e2Puro6JSUlNUcvAACgFfM6VDz44IN67bXXmqMXAADQinl0+SMzM9P558bGRi1btkxbtmzRzTffLF9fX5faBQsWmNshAABoFTwKFRUVFS6v+/fvL0nat2+fyzg3bQIAcPXyKFT86U9/au4+AABAK+f1PRXf9vnnn+uLL74wqxcAANCKeR0qzp07p1mzZikoKEjh4eHq0aOHgoKCNHPmTOePjAEAgKuP18+peOyxx7R+/Xrl5uYqMTFRklRaWqrs7GzV1NRo6dKlpjcJAABaPothGIY3BwQFBWnNmjVKT093Gd+0aZPGjh2rkydPXlYj7/hGXtZxAICrz531B5t1fjM/k5q715bE68sf/v7+Cg8PdxsPDw+Xn5+fGT0BV7VOP45T3Poluu2znbqz/qBC/u22K90SAHjE61Dx6KOPat68eXI4HM4xh8OhZ599Vo899pipzQFXI5/27VT70UF9PGXulW4FALzidaioqKjQH//4R3Xr1k3Dhw/X8OHD1a1bN7399tvas2eP7r77bucGwHtfvrdDh2YvlH1D0ZVuBcD/sR07dmjkyJEKCwuTxWLRhg0bvvOY7du3KzY2Vv7+/urZs2eT9zauW7dOffv2ldVqVd++fbV+/Xq3mvz8fEVERMjf31+xsbHauXOn1/17faPmtddeq9GjR7uM3XDDDV6fGAAAuDp9+rT69eunn//8526ftU05evSo7rjjDj300EP6r//6L/3P//yPfvnLX6pLly7O40tLSzVmzBjNmzdPP/3pT7V+/Xrde++9Ki4uVnx8vCRp7dq1ysjIUH5+vpKTk/Xyyy8rPT1d+/fvV/fu3T3u3+sbNc3gcDhcLp9I0vudYuVr+V6PzQB+cO6sP6jy0b/U397aeqVbAVqU1nSj5vBTH7l95lmtVlmt1kseZ7FYtH79eo0aNeqiNb/+9a/11ltv6cCBA86xyZMna8+ePSotLZUkjRkzRrW1tdq0aZOz5vbbb1fHjh21evVqSVJ8fLwGDhyoJUuWOGuioqI0atQo5eTkePxer8ineE5OjoKCgly21xv/fiVaAQCgWTX1mefNB/WllJaWKjU11WUsLS1N5eXlzmdHXaympKRE0vlfH9+9e7dbTWpqqrPGU16HihMnTujRRx9V3759FRwcrE6dOrlsnsjKytLJkyddtnvbeHYsAACtSVOfeVlZWabMbbfbFRIS4jIWEhKic+fOqaam5pI1drtdklRTU6OGhoZL1njK63sq7r//fn366aeaNGmSQkJCLutHxJpa9uHSBwDgh8iTSx3fx79+Dl+4q+Hb403V/OuYJzXfxetQUVxcrOLiYvXr18/bQwF4wKd9O7X/0T9vjGoX0U2B/fqo7u8n9c3nVVewMwAtTWhoqNtqQnV1tdq2bavOnTtfsubCykRwcLB8fHwuWeMpr5cH+vTpo7Nnz3p7GAAPBcVGK6X8TaWUvylJ6jt/ulLK39SN2U9c4c4AtDSJiYkqKnL9+vnmzZsVFxcnX1/fS9YkJSVJkvz8/BQbG+tWU1RU5KzxlNcrFfn5+Xrqqaf09NNPKzo62tn0BYGBgd5OCeBb/r6jjMfWA1epU6dO6ZNPPnG+Pnr0qCorK9WpUyd1795dWVlZOn78uAoLCyWd/6bH4sWLlZmZqYceekilpaVasWKF81sdkjRlyhQNHjxYzz//vO666y69+eab2rJli4qLi501mZmZGj9+vOLi4pSYmKhly5bJZrNp8uTJXvV/Wc+pOHnypG699VaX8QvXXhoaGrydEgAASCovL9ewYcOcrzMzMyVJEyZM0MqVK1VVVSWbzebcHxERoY0bN2rq1KnKy8tTWFiYFi1a5PKMi6SkJK1Zs0YzZ87UrFmz1KtXL61du9b5jArp/NdOT5w4oblz56qqqkrR0dHauHGjevTo4VX/Xj+n4pZbblHbtm01ZcqUJm/UHDJkiFcNXMC/zAAAnmpNz6m4mn5QzOuVin379qmiokKRkYQAAADwT17fqBkXF6fPP/+8OXoBAACtmNcrFY8//rimTJmiX/3qV4qJiXG7UfPmm282rTkAANB6eH1PRZs27osbFovle9+oyT0VAABPcU9Fy+T1SsXRo0ebow8AANDKeR0qvP16CQAAuDp4HSou2L9/v2w2m+rq6lzG/+3f/u17NwUAAFofr0PFkSNH9NOf/lR79+513ksh/fOHSHj4FQAAVyevv1I6ZcoURURE6G9/+5vatWunjz/+WDt27FBcXJy2bdvWDC0CAIDWwOuVitLSUr3//vvq0qWL2rRpozZt2ujHP/6xcnJy9MQTT6iioqI5+gQAAC2c1ysVDQ0N6tChg6TzP5f617/+VdL5GzgPHrx6vjYDAABceb1SER0drY8++kg9e/ZUfHy8cnNz5efnp2XLlqlnz57N0SMAAGgFvA4VM2fO1OnTpyVJzzzzjEaMGKGUlBR17txZa9euNb1BAADQOngdKtLS0px/7tmzp/bv36+///3v6tixo9svlgIAgKuHx/dUNDQ06KOPPtLZs2fd9vn7+2vv3r1qbGw0tTkAANB6eBwqXn31Vf3iF7+Qn5+f2z6r1apf/OIXeu2110xtDgAAtB4eh4oVK1Zo2rRp8vHxcdvn4+OjJ598UsuWLTO1OQAA0Hp4HCoOHjyohISEi+4fNGiQDhw4YEpTAACg9fE4VJw+fVq1tbUX3f+Pf/xDZ86cMaUpAADQ+ngcKnr37q2SkpKL7i8uLlbv3r1NaQoAALQ+HoeK++67TzNnztRHH33ktm/Pnj16+umndd9995naHAAAaD08fk7F1KlTtWnTJsXGxmr48OHq06ePLBaLDhw4oC1btig5OVlTp05tzl4BAEAL5nGo8PX11ebNm/XSSy/ptdde044dO2QYhm688UY9++yzysjIkK+vb3P2CgAAWjCLYRjGlW5Ckt7xjbzSLQAAWok765v3ByzN/Exq7l5bEq9/pRQAAKAppoWKCRMm6NZbbzVrOgAA0Mp4/YNiF3P99derTRsWPgAAuFqZFiqee+45s6YCAACtEEsLAADAFKaFijfffFOFhYVmTQcAAFoZ00LFr3/9a/385z83azoAANDKmHZPxV/+8hezpgIAAK2QxysVTz/9tM6dO3fR/TabTT/5yU9MaQoAALQ+HoeKlStXatCgQdq7d6/bvmXLlik6Olpt25q28AEAAFoZj0PFvn37FBMTo0GDBiknJ0eNjY2y2WwaPny4nnzySS1YsECbNm1qzl4BAEAL5nGoCAwMVGFhodauXavf/OY3GjhwoGJiYtS2bVvt3btXDz74YHP2CQDAVSE/P18RERHy9/dXbGysdu7cecn6vLw8RUVFKSAgQJGRkW7fxBw6dKgsFovbdueddzprsrOz3faHhoZ63bvX1yvi4+MVExOjrVu3qn379nryySd1ww03eH1iAADgau3atcrIyFB+fr6Sk5P18ssvKz09Xfv371f37t3d6pcsWaKsrCwtX75cgwYNUllZmR566CF17NhRI0eOlCT94Q9/UF1dnfOYEydOqF+/fvrZz37mMtdNN92kLVu2OF/7+Ph43b9XXyldvXq1brrpJjU2NurAgQP6j//4D6Wnp2vKlCk6e/as1ycHAAD/tGDBAk2aNEkPPvigoqKitHDhQt1www1asmRJk/WvvvqqHnnkEY0ZM0Y9e/bU2LFjNWnSJD3//PPOmk6dOik0NNS5FRUVqV27dm6hom3bti51Xbp08bp/j0PFPffco4cffljZ2dnaunWrIiMjlZubq23btundd99Vv379VFpa6nUDAAD8kDkcDtXW1rpsDofDra6urk67d+9Wamqqy3hqaqpKSkouOre/v7/LWEBAgMrKylRfX9/kMStWrNDYsWPVvn17l/HDhw8rLCxMERERGjt2rI4cOeLN25TkRaioqqpSRUWFHn/8cZfxxMRE7dmzR+np6RoyZIjXDQAA8EOWk5OjoKAgly0nJ8etrqamRg0NDQoJCXEZDwkJkd1ub3LutLQ0vfLKK9q9e7cMw1B5ebkKCgpUX1+vmpoat/qysjLt27fP7T7I+Ph4FRYW6r333tPy5ctlt9uVlJSkEydOePVePb6nYufOnRf9FVJ/f3/95je/0ejRo706OQAAP3RZWVnKzMx0GbNarRett1gsLq8Nw3Abu2DWrFmy2+1KSEiQYRgKCQnRxIkTlZub2+Q9EStWrFB0dLRuueUWl/H09HTnn2NiYpSYmKhevXpp1apVbr1fiscrFZ78rPngwYM9PjEAAFcDq9WqwMBAl62pUBEcHCwfHx+3VYnq6mq31YsLAgICVFBQoDNnzujYsWOy2WwKDw/XNddco+DgYJfaM2fOaM2aNR59W7N9+/aKiYnR4cOHvXin/EopAAAtgp+fn2JjY1VUVOQyXlRUpKSkpEse6+vrq27dusnHx0dr1qzRiBEj3BYDXn/9dTkcDt1///3f2YvD4dCBAwfUtWtXr94Dj8AEAKCFyMzM1Pjx4xUXF6fExEQtW7ZMNptNkydPlnT+Usrx48edz6I4dOiQysrKFB8fr6+++koLFizQvn37tGrVKre5V6xYoVGjRqlz585u+6ZNm6aRI0eqe/fuqq6u1jPPPKPa2lpNmDDBq/4JFQAAtBBjxozRiRMnNHfuXFVVVSk6OlobN25Ujx49JJ3/0oTNZnPWNzQ06MUXX9TBgwfl6+urYcOGqaSkROHh4S7zHjp0SMXFxdq8eXOT5/3iiy80btw41dTUqEuXLkpISNCuXbuc5/WUxTAMw7u33Dze8Y280i0AAFqJO+sPNuv8Zn4mNXevLQn3VAAAAFMQKgAAgCkIFQAAwBSECgAAYApCBQAAMAWhAgAAmIJQAQAATEGoAAAApiBUAAAAUxAqAACAKQgVAADAFIQKAABgCkIFAAAwBaECAACYglABAABMQagAAACmIFQAAABTECoAAIApCBUAAMAUhAoAAGAKQgUAADAFoQIAAJiCUAEAAExBqAAAAKYgVAAAAFMQKgAAgCkIFQAAwBSECgAAYApCBQAAMAWhAgAAmIJQAQAATEGoAAAApiBUAAAAUxAqAACAKQgVAADAFIQKAABakPz8fEVERMjf31+xsbHauXPnJevz8vIUFRWlgIAARUZGqrCw0GX/ypUrZbFY3LZvvvnme523KYQKAABaiLVr1yojI0MzZsxQRUWFUlJSlJ6eLpvN1mT9kiVLlJWVpezsbH388ceaM2eOHn30Ub399tsudYGBgaqqqnLZ/P39L/u8F2MxDMPw/m2b7x3fyCvdAgCglbiz/mCzzm/mZ5I3vcbHx2vgwIFasmSJcywqKkqjRo1STk6OW31SUpKSk5P1wgsvOMcyMjJUXl6u4uJiSedXKjIyMvT111+bdt6LYaUCAIBm5HA4VFtb67I5HA63urq6Ou3evVupqaku46mpqSopKbno3N9ecZCkgIAAlZWVqb6+3jl26tQp9ejRQ926ddOIESNUUVHxvc57MYQKAACaUU5OjoKCgly2pv71X1NTo4aGBoWEhLiMh4SEyG63Nzl3WlqaXnnlFe3evVuGYai8vFwFBQWqr69XTU2NJKlPnz5auXKl3nrrLa1evVr+/v5KTk7W4cOHL/u8F9PWq2oAAOCVrKwsZWZmuoxZrdaL1lssFpfXhmG4jV0wa9Ys2e12JSQkyDAMhYSEaOLEicrNzZWPj48kKSEhQQkJCc5jkpOTNXDgQP32t7/VokWLLuu8F8NKBQAAzchqtSowMNBlaypUBAcHy8fHx211oLq62m0V4YKAgAAVFBTozJkzOnbsmGw2m8LDw3XNNdcoODi4yWPatGmjQYMGOVcqLue8F0OoAACgBfDz81NsbKyKiopcxouKipSUlHTJY319fdWtWzf5+PhozZo1GjFihNq0afoj3jAMVVZWqmvXrt/7vP+Kyx8AALQQmZmZGj9+vOLi4pSYmKhly5bJZrNp8uTJks5fSjl+/LjzWRSHDh1SWVmZ4uPj9dVXX2nBggXat2+fVq1a5Zxzzpw5SkhIUO/evVVbW6tFixapsrJSeXl5Hp/XU4QKAABaiDFjxujEiROaO3euqqqqFB0drY0bN6pHjx6SpKqqKpdnRzQ0NOjFF1/UwYMH5evrq2HDhqmkpETh4eHOmq+//loPP/yw7Ha7goKCNGDAAO3YsUO33HKLx+f1FM+pAAC0Oj/U51S0dtxTAQAATEGoAAAApiBUAAAAUxAqAACAKQgVAADAFIQKAABgCkIFAAAwBaECAACYglABAABMQagAAACmIFQAAABTECoAAIApCBUAAMAUhAoAAGAKQgUAADAFoQIAAJiCUAEAAExBqAAAAKYgVAAAAFMQKgAAgCkIFQAAwBSECgAAYApCBQAAMAWhAgAAmIJQAQAATEGoAAAApiBUAAAAUxAqAACAKQgVAADAFIQKAABgCkIFAAAwBaECAACYglABAABMQagAAACmIFQAAABTECoAAGhB8vPzFRERIX9/f8XGxmrnzp2XrM/Ly1NUVJQCAgIUGRmpwsJCl/3Lly9XSkqKOnbsqI4dO2r48OEqKytzqcnOzpbFYnHZQkNDve6dUAEAQAuxdu1aZWRkaMaMGaqoqFBKSorS09Nls9marF+yZImysrKUnZ2tjz/+WHPmzNGjjz6qt99+21mzbds2jRs3Tn/6059UWlqq7t27KzU1VcePH3eZ66abblJVVZVz27t3r9f9WwzDMLw+qhm84xt5pVsAALQSd9YfbNb5zfxM8qbX+Ph4DRw4UEuWLHGORUVFadSoUcrJyXGrT0pKUnJysl544QXnWEZGhsrLy1VcXNzkORoaGtSxY0ctXrxYDzzwgKTzKxUbNmxQZWWlx702hZUKAACakcPhUG1trcvmcDjc6urq6rR7926lpqa6jKempqqkpOSic/v7+7uMBQQEqKysTPX19U0ec+bMGdXX16tTp04u44cPH1ZYWJgiIiI0duxYHTlyxJu3KYlQAQBAs8rJyVFQUJDL1tSqQ01NjRoaGhQSEuIyHhISIrvd3uTcaWlpeuWVV7R7924ZhqHy8nIVFBSovr5eNTU1TR7z1FNP6frrr9fw4cOdY/Hx8SosLNR7772n5cuXy263KykpSSdOnPDqvbb1qhoAAHglKytLmZmZLmNWq/Wi9RaLxeW1YRhuYxfMmjVLdrtdCQkJMgxDISEhmjhxonJzc+Xj4+NWn5ubq9WrV2vbtm0uKxzp6enOP8fExCgxMVG9evXSqlWr3Hq/FFYqAABoRlarVYGBgS5bU6EiODhYPj4+bqsS1dXVbqsXFwQEBKigoEBnzpzRsWPHZLPZFB4ermuuuUbBwcEutfPnz9dzzz2nzZs36+abb75kz+3bt1dMTIwOHz7s1XslVAAA0AL4+fkpNjZWRUVFLuNFRUVKSkq65LG+vr7q1q2bfHx8tGbNGo0YMUJt2vzzI/6FF17QvHnz9O677youLu47e3E4HDpw4IC6du3q1Xvg8gcAAC1EZmamxo8fr7i4OCUmJmrZsmWy2WyaPHmypPOXUo4fP+58FsWhQ4dUVlam+Ph4ffXVV1qwYIH27dunVatWOefMzc3VrFmz9Nprryk8PNy5EtKhQwd16NBBkjRt2jSNHDlS3bt3V3V1tZ555hnV1tZqwoQJXvVPqAAAoIUYM2aMTpw4oblz56qqqkrR0dHauHGjevToIUmqqqpyeWZFQ0ODXnzxRR08eFC+vr4aNmyYSkpKFB4e7qzJz89XXV2d7rnnHpdzzZ49W9nZ2ZKkL774QuPGjVNNTY26dOmihIQE7dq1y3leT/GcCgBAq/NDfU5Fa8c9FQAAwBSECgAAYApCBQAAMAWhAgAAmIJQAQAATEGoAAAApiBUAAAAUxAqAACAKQgVAADAFIQKAABgCkIFAAAwBaECAACYglABAABMQagAAACmIFQAAABTECoAAIApCBUAAMAUhAoAAGAKQgUAADAFoQIAAJiCUAEAAExBqAAAAKYgVAAAAFMQKgAAgCkIFQAAwBSECgAAYApCBQAAMAWhAgAAmIJQAQAATEGoAAAApiBUAAAAUxAqAACAKQgVAADAFIQKAABgCkIFAAAwBaECAACYglABAEALkp+fr4iICPn7+ys2NlY7d+68ZH1eXp6ioqIUEBCgyMhIFRYWutWsW7dOffv2ldVqVd++fbV+/frvfd6mECoAAGgh1q5dq4yMDM2YMUMVFRVKSUlRenq6bDZbk/VLlixRVlaWsrOz9fHHH2vOnDl69NFH9fbbbztrSktLNWbMGI0fP1579uzR+PHjde+99+qDDz647PNejMUwDOPy3rq53vGNvNItAABaiTvrDzbr/GZ+Jg0/9ZEcDofLmNVqldVqdauNj4/XwIEDtWTJEudYVFSURo0apZycHLf6pKQkJScn64UXXnCOZWRkqLy8XMXFxZKkMWPGqLa2Vps2bXLW3H777erYsaNWr159Wee9mLYeVzaz5v4vCNDaOBwO5eTkKCsrq8n/8wHQfMz8TMrOztacOXNcxmbPnq3s7GyXsbq6Ou3evVtPPfWUy3hqaqpKSkqanNvhcMjf399lLCAgQGVlZaqvr5evr69KS0s1depUl5q0tDQtXLjwss97MVz+AFooh8OhOXPmuP0LB0DrkpWVpZMnT7psWVlZbnU1NTVqaGhQSEiIy3hISIjsdnuTc6elpemVV17R7t27ZRiGysvLVVBQoPr6etXU1EiS7Hb7Jee8nPNeTItZqQAA4IfoYpc6LsZisbi8NgzDbeyCWbNmyW63KyEhQYZhKCQkRBMnTlRubq58fHy8mtOb814MKxUAALQAwcHB8vHxcVsdqK6udltFuCAgIEAFBQU6c+aMjh07JpvNpvDwcF1zzTUKDg6WJIWGhl5yzss578UQKgAAaAH8/PwUGxuroqIil/GioiIlJSVd8lhfX19169ZNPj4+WrNmjUaMGKE2bc5/xCcmJrrNuXnzZuec3+e8/4rLH0ALZbVaNXv2bG7SBK4imZmZGj9+vOLi4pSYmKhly5bJZrNp8uTJks7fn3H8+HHnsygOHTqksrIyxcfH66uvvtKCBQu0b98+rVq1yjnnlClTNHjwYD3//PO666679Oabb2rLli3Ob4d4cl6PGQAAoMXIy8szevToYfj5+RkDBw40tm/f7tw3YcIEY8iQIc7X+/fvN/r3728EBAQYgYGBxl133WX85S9/cZvzv//7v43IyEjD19fX6NOnj7Fu3TqvzuupFvOcCgAA0LpxTwUAADAFoQIAAJiCUAEAAExBqAB+YIYOHaqMjIwr3QaAqxChAleFhoYGJSUlafTo0S7jJ0+e1A033KCZM2d6PFddXZ1yc3PVr18/tWvXTsHBwUpOTtbvfvc71dfXm906ALQaPKcCVwUfHx+tWrVK/fv31+9//3v9+7//uyTp8ccfV6dOnfT00097NE9dXZ3S0tK0Z88ezZs3T8nJyQoMDNSuXbs0f/58DRgwQP3792/GdwIALRcrFbhq9O7dWzk5OXr88cf117/+VW+++abWrFmjVatWyc/Pz6M5Fi5cqB07dmjr1q169NFH1b9/f/Xs2VP33XefPvjgA/Xu3VuS9O677+rHP/6xrr32WnXu3FkjRozQp59+6pzn2LFjslgsev3115WSkqKAgAANGjRIhw4d0ocffqi4uDh16NBBt99+u7788kvncRMnTtSoUaM0Z84cXXfddQoMDNQjjzyiuro6lz4bGxv15JNPqlOnTgoNDXX7NcSTJ0/q4Ycfds5x6623as+ePc792dnZ6t+/v1599VWFh4crKChIY8eO1T/+8Q9njWEYys3NVc+ePRUQEKB+/frpjTfe8Pg/DwA/QF4/2QJoxRobG42hQ4cat912m3HdddcZ8+bN8+r4m2++2UhNTf3OujfeeMNYt26dcejQIaOiosIYOXKkERMTYzQ0NBiGYRhHjx41JBl9+vQx3n33XWP//v1GQkKCMXDgQGPo0KFGcXGx8ec//9n40Y9+ZEyePNk574QJE4wOHToYY8aMMfbt22f88Y9/NLp06WJMnz7dWTNkyBAjMDDQyM7ONg4dOmSsWrXKsFgsxubNm51/B8nJycbIkSONDz/80Dh06JDx//7f/zM6d+5snDhxwjAMw5g9e7bRoUMH4+677zb27t1r7NixwwgNDXU5z/Tp0539f/rpp8bvfvc7w2q1Gtu2bfPq7xTADwehAledAwcOGJKMmJgYo76+3qtjAwICjCeeeMLrc1ZXVxuSjL179xqG8c9Q8corrzhrVq9ebUgytm7d6hzLyckxIiMjna8nTJhgdOrUyTh9+rRzbMmSJUaHDh2cgWXIkCHGj3/8Y5fzDxo0yPj1r39tGIZhbN261QgMDDS++eYbl5pevXoZL7/8smEY50NFu3btjNraWuf+X/3qV0Z8fLxhGIZx6tQpw9/f3ygpKXGZY9KkSca4ceO8/NsB8EPBPRW46hQUFKhdu3Y6evSovvjiC4WHh3t8rOHhTwF/+umnmjVrlnbt2qWamho1NjZKkmw2m6Kjo511N998s/PPF34NMCYmxmWsurraZe4LN4hekJiYqFOnTunzzz9Xjx493OaVpK5duzrn2b17t06dOqXOnTu71Jw9e9blEs2FXzpsao79+/frm2++0U9+8hOXOerq6jRgwIBL/t0A+OEiVOCqUlpaqpdeekmbNm1Sbm6uJk2apC1btngUFCTpxhtv1IEDB76zbuTIkbrhhhu0fPlyhYWFqbGxUdHR0W73Pvj6+jr/fKGHfx27EEi+y7ffw7fn+Nd5Ghsb1bVrV23bts1tjmuvvdbjOSTpnXfe0fXXX+9Sxw+gAVcvQgWuGmfPntWECRP0yCOPaPjw4brxxhsVHR2tl19+2eNf4rvvvvs0ffp0VVRUuP2L/Ny5c3I4HPrmm2904MABvfzyy0pJSZEkl18D/L727Nmjs2fPKiAgQJK0a9cudejQQd26dfPo+IEDB8put6tt27ZerdJ8W9++fWW1WmWz2TRkyJDLmgPADw/f/sBV46mnnlJjY6Oef/55SVL37t314osv6le/+pWOHTsmSerTp4/Wr1/vPCYrK0sPPPCA83VGRoaSk5N12223KS8vT3v27NGRI0f0+uuvKz4+XocPH1bHjh3VuXNnLVu2TJ988onef/99ZWZmmvY+6urqNGnSJO3fv1+bNm3S7Nmz9dhjj6lNG8/+5zx8+HAlJiZq1KhReu+993Ts2DGVlJRo5syZKi8v92iOa665RtOmTdPUqVO1atUqffrpp6qoqFBeXp7LTy4DuLqwUoGrwvbt25WXl6dt27apffv2zvGHHnpIb7zxhvMyyMGDB3Xy5Enn/qqqKtlsNudrq9WqoqIivfTSS3r55Zc1bdo0tWvXTlFRUXriiScUHR2tNm3aaM2aNc7XkZGRWrRokYYOHWrKe7ntttvUu3dvDR48WA6HQ2PHjnX7yuilWCwWbdy4UTNmzNAvfvELffnllwoNDdXgwYOd93V4Yt68ebruuuuUk5OjI0eO6Nprr9XAgQM1ffr0y3hXAH4I+OlzoBWZOHGivv76a23YsOFKtwIAbrj8AQAATEGoAAAApuDyBwAAMAUrFQAAwBSECgAAYApCBQAAMAWhAgAAmIJQAQAATEGoAAAApiBUAAAAUxAqAACAKf4/5ychKpSITYEAAAAASUVORK5CYII=",
      "text/plain": [
       "<Figure size 640x480 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "corr_matrix = y_test.corr()\n",
    "sns.heatmap(corr_matrix, annot=True, cmap='coolwarm', center=0)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
