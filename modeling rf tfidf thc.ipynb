{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn import preprocessing\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.neural_network import MLPRegressor\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "from sklearn.metrics import r2_score\n",
    "from scipy.stats import pearsonr\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.feature_selection import SelectFromModel\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compiling complete dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_rf = pd.read_csv(\"df_thc_tfidf.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['tfidf_0',\n",
       " 'tfidf_1',\n",
       " 'tfidf_2',\n",
       " 'tfidf_3',\n",
       " 'tfidf_4',\n",
       " 'tfidf_5',\n",
       " 'tfidf_6',\n",
       " 'tfidf_7',\n",
       " 'tfidf_8',\n",
       " 'tfidf_9',\n",
       " 'tfidf_10',\n",
       " 'tfidf_11',\n",
       " 'tfidf_12',\n",
       " 'tfidf_13',\n",
       " 'tfidf_14',\n",
       " 'tfidf_15',\n",
       " 'tfidf_16',\n",
       " 'tfidf_17',\n",
       " 'tfidf_18',\n",
       " 'tfidf_19',\n",
       " 'tfidf_20',\n",
       " 'tfidf_21',\n",
       " 'tfidf_22',\n",
       " 'tfidf_23',\n",
       " 'tfidf_24',\n",
       " 'tfidf_25',\n",
       " 'tfidf_26',\n",
       " 'tfidf_27',\n",
       " 'tfidf_28',\n",
       " 'tfidf_29',\n",
       " 'tfidf_30',\n",
       " 'tfidf_31',\n",
       " 'tfidf_32',\n",
       " 'tfidf_33',\n",
       " 'tfidf_34',\n",
       " 'tfidf_35',\n",
       " 'tfidf_36',\n",
       " 'tfidf_37',\n",
       " 'tfidf_38',\n",
       " 'tfidf_39',\n",
       " 'tfidf_40',\n",
       " 'tfidf_41',\n",
       " 'tfidf_42',\n",
       " 'tfidf_43',\n",
       " 'tfidf_44',\n",
       " 'tfidf_45',\n",
       " 'tfidf_46',\n",
       " 'tfidf_47',\n",
       " 'tfidf_48',\n",
       " 'tfidf_49',\n",
       " 'tfidf_50',\n",
       " 'tfidf_51',\n",
       " 'tfidf_52',\n",
       " 'tfidf_53',\n",
       " 'tfidf_54',\n",
       " 'tfidf_55',\n",
       " 'tfidf_56',\n",
       " 'tfidf_57',\n",
       " 'tfidf_58',\n",
       " 'tfidf_59',\n",
       " 'tfidf_60',\n",
       " 'tfidf_61',\n",
       " 'tfidf_62',\n",
       " 'tfidf_63',\n",
       " 'tfidf_64',\n",
       " 'tfidf_65',\n",
       " 'tfidf_66',\n",
       " 'tfidf_67',\n",
       " 'tfidf_68',\n",
       " 'tfidf_69',\n",
       " 'tfidf_70',\n",
       " 'tfidf_71',\n",
       " 'tfidf_72',\n",
       " 'tfidf_73',\n",
       " 'tfidf_74',\n",
       " 'tfidf_75',\n",
       " 'tfidf_76',\n",
       " 'tfidf_77',\n",
       " 'tfidf_78',\n",
       " 'tfidf_79',\n",
       " 'tfidf_80',\n",
       " 'tfidf_81',\n",
       " 'tfidf_82',\n",
       " 'tfidf_83',\n",
       " 'tfidf_84',\n",
       " 'tfidf_85',\n",
       " 'tfidf_86',\n",
       " 'tfidf_87',\n",
       " 'tfidf_88',\n",
       " 'tfidf_89',\n",
       " 'tfidf_90',\n",
       " 'tfidf_91',\n",
       " 'tfidf_92',\n",
       " 'tfidf_93',\n",
       " 'tfidf_94',\n",
       " 'tfidf_95',\n",
       " 'tfidf_96',\n",
       " 'tfidf_97',\n",
       " 'tfidf_98',\n",
       " 'tfidf_99',\n",
       " 'tfidf_100',\n",
       " 'tfidf_101',\n",
       " 'tfidf_102',\n",
       " 'tfidf_103',\n",
       " 'tfidf_104',\n",
       " 'tfidf_105',\n",
       " 'tfidf_106',\n",
       " 'tfidf_107',\n",
       " 'tfidf_108',\n",
       " 'tfidf_109',\n",
       " 'tfidf_110',\n",
       " 'tfidf_111',\n",
       " 'tfidf_112',\n",
       " 'tfidf_113',\n",
       " 'tfidf_114',\n",
       " 'tfidf_115',\n",
       " 'tfidf_116',\n",
       " 'tfidf_117',\n",
       " 'tfidf_118',\n",
       " 'tfidf_119',\n",
       " 'tfidf_120',\n",
       " 'tfidf_121',\n",
       " 'tfidf_122',\n",
       " 'tfidf_123',\n",
       " 'tfidf_124',\n",
       " 'tfidf_125',\n",
       " 'tfidf_126',\n",
       " 'tfidf_127',\n",
       " 'tfidf_128',\n",
       " 'tfidf_129',\n",
       " 'tfidf_130',\n",
       " 'tfidf_131',\n",
       " 'tfidf_132',\n",
       " 'tfidf_133',\n",
       " 'tfidf_134',\n",
       " 'tfidf_135',\n",
       " 'tfidf_136',\n",
       " 'tfidf_137',\n",
       " 'tfidf_138',\n",
       " 'tfidf_139',\n",
       " 'tfidf_140',\n",
       " 'tfidf_141',\n",
       " 'tfidf_142',\n",
       " 'tfidf_143',\n",
       " 'tfidf_144',\n",
       " 'tfidf_145',\n",
       " 'tfidf_146',\n",
       " 'tfidf_147',\n",
       " 'tfidf_148',\n",
       " 'tfidf_149',\n",
       " 'tfidf_150',\n",
       " 'tfidf_151',\n",
       " 'tfidf_152',\n",
       " 'tfidf_153',\n",
       " 'tfidf_154',\n",
       " 'tfidf_155',\n",
       " 'tfidf_156',\n",
       " 'tfidf_157',\n",
       " 'tfidf_158',\n",
       " 'tfidf_159',\n",
       " 'tfidf_160',\n",
       " 'tfidf_161',\n",
       " 'tfidf_162',\n",
       " 'tfidf_163',\n",
       " 'tfidf_164',\n",
       " 'tfidf_165',\n",
       " 'tfidf_166',\n",
       " 'tfidf_167',\n",
       " 'tfidf_168',\n",
       " 'tfidf_169',\n",
       " 'tfidf_170',\n",
       " 'tfidf_171',\n",
       " 'tfidf_172',\n",
       " 'tfidf_173',\n",
       " 'tfidf_174',\n",
       " 'tfidf_175',\n",
       " 'tfidf_176',\n",
       " 'tfidf_177',\n",
       " 'tfidf_178',\n",
       " 'tfidf_179',\n",
       " 'tfidf_180',\n",
       " 'tfidf_181',\n",
       " 'tfidf_182',\n",
       " 'tfidf_183',\n",
       " 'tfidf_184',\n",
       " 'tfidf_185',\n",
       " 'tfidf_186',\n",
       " 'tfidf_187',\n",
       " 'tfidf_188',\n",
       " 'tfidf_189',\n",
       " 'tfidf_190',\n",
       " 'tfidf_191',\n",
       " 'tfidf_192',\n",
       " 'tfidf_193',\n",
       " 'tfidf_194',\n",
       " 'tfidf_195',\n",
       " 'tfidf_196',\n",
       " 'tfidf_197',\n",
       " 'tfidf_198',\n",
       " 'tfidf_199',\n",
       " 'tfidf_200',\n",
       " 'tfidf_201',\n",
       " 'tfidf_202',\n",
       " 'tfidf_203',\n",
       " 'tfidf_204',\n",
       " 'tfidf_205',\n",
       " 'tfidf_206',\n",
       " 'tfidf_207',\n",
       " 'tfidf_208',\n",
       " 'tfidf_209',\n",
       " 'tfidf_210',\n",
       " 'tfidf_211',\n",
       " 'tfidf_212',\n",
       " 'tfidf_213',\n",
       " 'tfidf_214',\n",
       " 'tfidf_215',\n",
       " 'tfidf_216',\n",
       " 'tfidf_217',\n",
       " 'tfidf_218',\n",
       " 'tfidf_219',\n",
       " 'tfidf_220',\n",
       " 'tfidf_221',\n",
       " 'tfidf_222',\n",
       " 'tfidf_223',\n",
       " 'tfidf_224',\n",
       " 'tfidf_225',\n",
       " 'tfidf_226',\n",
       " 'tfidf_227',\n",
       " 'tfidf_228',\n",
       " 'tfidf_229',\n",
       " 'tfidf_230',\n",
       " 'tfidf_231',\n",
       " 'tfidf_232',\n",
       " 'tfidf_233',\n",
       " 'tfidf_234',\n",
       " 'tfidf_235',\n",
       " 'tfidf_236',\n",
       " 'tfidf_237',\n",
       " 'tfidf_238',\n",
       " 'tfidf_239',\n",
       " 'tfidf_240',\n",
       " 'tfidf_241',\n",
       " 'tfidf_242',\n",
       " 'tfidf_243',\n",
       " 'tfidf_244',\n",
       " 'tfidf_245',\n",
       " 'tfidf_246',\n",
       " 'tfidf_247',\n",
       " 'tfidf_248',\n",
       " 'tfidf_249',\n",
       " 'tfidf_250',\n",
       " 'tfidf_251',\n",
       " 'tfidf_252',\n",
       " 'tfidf_253',\n",
       " 'tfidf_254',\n",
       " 'tfidf_255',\n",
       " 'tfidf_256',\n",
       " 'tfidf_257',\n",
       " 'tfidf_258',\n",
       " 'tfidf_259',\n",
       " 'tfidf_260',\n",
       " 'tfidf_261',\n",
       " 'tfidf_262',\n",
       " 'tfidf_263',\n",
       " 'tfidf_264',\n",
       " 'tfidf_265',\n",
       " 'tfidf_266',\n",
       " 'tfidf_267',\n",
       " 'tfidf_268',\n",
       " 'tfidf_269',\n",
       " 'tfidf_270',\n",
       " 'tfidf_271',\n",
       " 'tfidf_272',\n",
       " 'tfidf_273',\n",
       " 'tfidf_274',\n",
       " 'tfidf_275',\n",
       " 'tfidf_276',\n",
       " 'tfidf_277',\n",
       " 'tfidf_278',\n",
       " 'tfidf_279',\n",
       " 'tfidf_280',\n",
       " 'tfidf_281',\n",
       " 'tfidf_282',\n",
       " 'tfidf_283',\n",
       " 'tfidf_284',\n",
       " 'tfidf_285',\n",
       " 'tfidf_286',\n",
       " 'tfidf_287',\n",
       " 'tfidf_288',\n",
       " 'tfidf_289',\n",
       " 'tfidf_290',\n",
       " 'tfidf_291',\n",
       " 'tfidf_292',\n",
       " 'tfidf_293',\n",
       " 'tfidf_294',\n",
       " 'tfidf_295',\n",
       " 'tfidf_296',\n",
       " 'tfidf_297',\n",
       " 'tfidf_298',\n",
       " 'tfidf_299',\n",
       " 'tfidf_300',\n",
       " 'tfidf_301',\n",
       " 'tfidf_302',\n",
       " 'tfidf_303',\n",
       " 'tfidf_304',\n",
       " 'tfidf_305',\n",
       " 'tfidf_306',\n",
       " 'tfidf_307',\n",
       " 'tfidf_308',\n",
       " 'tfidf_309',\n",
       " 'tfidf_310',\n",
       " 'tfidf_311',\n",
       " 'tfidf_312',\n",
       " 'tfidf_313',\n",
       " 'tfidf_314',\n",
       " 'tfidf_315',\n",
       " 'tfidf_316',\n",
       " 'tfidf_317',\n",
       " 'tfidf_318',\n",
       " 'tfidf_319',\n",
       " 'tfidf_320',\n",
       " 'tfidf_321',\n",
       " 'tfidf_322',\n",
       " 'tfidf_323',\n",
       " 'tfidf_324',\n",
       " 'tfidf_325',\n",
       " 'tfidf_326',\n",
       " 'tfidf_327',\n",
       " 'tfidf_328',\n",
       " 'tfidf_329',\n",
       " 'tfidf_330',\n",
       " 'tfidf_331',\n",
       " 'tfidf_332',\n",
       " 'tfidf_333',\n",
       " 'tfidf_334',\n",
       " 'tfidf_335',\n",
       " 'tfidf_336',\n",
       " 'tfidf_337',\n",
       " 'tfidf_338',\n",
       " 'tfidf_339',\n",
       " 'tfidf_340',\n",
       " 'tfidf_341',\n",
       " 'tfidf_342',\n",
       " 'tfidf_343',\n",
       " 'tfidf_344',\n",
       " 'tfidf_345',\n",
       " 'tfidf_346',\n",
       " 'tfidf_347',\n",
       " 'tfidf_348',\n",
       " 'tfidf_349',\n",
       " 'tfidf_350',\n",
       " 'tfidf_351',\n",
       " 'tfidf_352',\n",
       " 'tfidf_353',\n",
       " 'tfidf_354',\n",
       " 'tfidf_355',\n",
       " 'tfidf_356',\n",
       " 'tfidf_357',\n",
       " 'tfidf_358',\n",
       " 'tfidf_359',\n",
       " 'tfidf_360',\n",
       " 'tfidf_361',\n",
       " 'tfidf_362',\n",
       " 'tfidf_363',\n",
       " 'tfidf_364',\n",
       " 'tfidf_365',\n",
       " 'tfidf_366',\n",
       " 'tfidf_367',\n",
       " 'tfidf_368',\n",
       " 'tfidf_369',\n",
       " 'tfidf_370',\n",
       " 'tfidf_371',\n",
       " 'tfidf_372',\n",
       " 'tfidf_373',\n",
       " 'tfidf_374',\n",
       " 'tfidf_375',\n",
       " 'tfidf_376',\n",
       " 'tfidf_377',\n",
       " 'tfidf_378',\n",
       " 'tfidf_379',\n",
       " 'tfidf_380',\n",
       " 'tfidf_381',\n",
       " 'tfidf_382',\n",
       " 'tfidf_383',\n",
       " 'tfidf_384',\n",
       " 'tfidf_385',\n",
       " 'tfidf_386',\n",
       " 'tfidf_387',\n",
       " 'hybrid',\n",
       " 'indica',\n",
       " 'sativa',\n",
       " 'anxiety',\n",
       " 'anxious',\n",
       " 'aroused',\n",
       " 'arthritis',\n",
       " 'creative',\n",
       " 'depression',\n",
       " 'dizzy',\n",
       " 'dry eyes',\n",
       " 'dry mouth',\n",
       " 'energetic',\n",
       " 'epilepsy',\n",
       " 'euphoric',\n",
       " 'eye pressure',\n",
       " 'fatigue',\n",
       " 'focused',\n",
       " 'giggly',\n",
       " 'happy',\n",
       " 'headache',\n",
       " 'hungry',\n",
       " 'migraines',\n",
       " 'pain',\n",
       " 'paranoid',\n",
       " 'relaxed',\n",
       " 'seizures',\n",
       " 'sleepy',\n",
       " 'spasticity',\n",
       " 'stress',\n",
       " 'talkative',\n",
       " 'tingly',\n",
       " 'uplifted',\n",
       " 'ammonia',\n",
       " 'apple',\n",
       " 'apricot',\n",
       " 'berry',\n",
       " 'blue cheese',\n",
       " 'blueberry',\n",
       " 'butter',\n",
       " 'cheese',\n",
       " 'chemical',\n",
       " 'chestnut',\n",
       " 'citrus',\n",
       " 'coffee',\n",
       " 'diesel',\n",
       " 'earthy',\n",
       " 'flowery',\n",
       " 'fruit',\n",
       " 'grape',\n",
       " 'grapefruit',\n",
       " 'honey',\n",
       " 'lavender',\n",
       " 'lemon',\n",
       " 'lime',\n",
       " 'mango',\n",
       " 'menthol',\n",
       " 'mint',\n",
       " 'nutty',\n",
       " 'orange',\n",
       " 'peach',\n",
       " 'pear',\n",
       " 'pepper',\n",
       " 'pine',\n",
       " 'pineapple',\n",
       " 'plum',\n",
       " 'pungent',\n",
       " 'rose',\n",
       " 'sage',\n",
       " 'skunk',\n",
       " 'spicy/herbal',\n",
       " 'strawberry',\n",
       " 'sweet',\n",
       " 'tar',\n",
       " 'tea',\n",
       " 'tobacco',\n",
       " 'tree',\n",
       " 'tropical',\n",
       " 'vanilla',\n",
       " 'violet',\n",
       " 'woody',\n",
       " 'X..Delta9-THC']"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_rf.columns.to_list()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Splitting dependent and independent variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df_rf.drop(['X..Delta9-THC'], axis = 1)\n",
    "y = df_rf[['X..Delta9-THC']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plotting histograms on target variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.25971245],\n",
       "       [0.25971245],\n",
       "       [0.25971245],\n",
       "       ...,\n",
       "       [0.56255736],\n",
       "       [0.56255736],\n",
       "       [0.56255736]])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_array = y.to_numpy()\n",
    "y_array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:ylabel='Count'>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "sns.histplot(y, bins = 10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train test split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=1, test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train1, X_val, y_train1, y_val = train_test_split(X_train, y_train, random_state=1, test_size=0.25)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "RF modeling (before Feature selection and Hyperparameter Tuning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/y1/pjvjlkjn5gl846rnyzr53p340000gn/T/ipykernel_7013/350139188.py:2: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  rfreg.fit(X_train1, y_train1)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;background-color: white;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>RandomForestRegressor()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">RandomForestRegressor</label><div class=\"sk-toggleable__content\"><pre>RandomForestRegressor()</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "RandomForestRegressor()"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rfreg = RandomForestRegressor()\n",
    "rfreg.fit(X_train1, y_train1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_rfreg = rfreg.predict(X_val)\n",
    "y_pred_rfreg_r2 = rfreg.predict(X_train1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.058546765248321135"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mean_absolute_error(y_val, y_pred_rfreg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.012392023318844776"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mean_squared_error(y_val, y_pred_rfreg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.11131946513905273"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mean_squared_error(y_val, y_pred_rfreg, squared = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9645485716988268"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#train\n",
    "r2_score(y_train1, y_pred_rfreg_r2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8498455971026371"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#val\n",
    "r2_score(y_val, y_pred_rfreg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Residual plots for each target variable"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Feature Selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_feat = pd.DataFrame({\n",
    "    \"features\": X_train1.columns,\n",
    "    \"score\": rfreg.feature_importances_\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>features</th>\n",
       "      <th>score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>tfidf_0</td>\n",
       "      <td>0.000857</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>tfidf_1</td>\n",
       "      <td>0.000898</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>tfidf_2</td>\n",
       "      <td>0.000433</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>tfidf_3</td>\n",
       "      <td>0.000408</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>tfidf_4</td>\n",
       "      <td>0.001686</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>464</th>\n",
       "      <td>tree</td>\n",
       "      <td>0.000481</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>465</th>\n",
       "      <td>tropical</td>\n",
       "      <td>0.000937</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>466</th>\n",
       "      <td>vanilla</td>\n",
       "      <td>0.004828</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>467</th>\n",
       "      <td>violet</td>\n",
       "      <td>0.000140</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>468</th>\n",
       "      <td>woody</td>\n",
       "      <td>0.001884</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>469 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     features     score\n",
       "0     tfidf_0  0.000857\n",
       "1     tfidf_1  0.000898\n",
       "2     tfidf_2  0.000433\n",
       "3     tfidf_3  0.000408\n",
       "4     tfidf_4  0.001686\n",
       "..        ...       ...\n",
       "464      tree  0.000481\n",
       "465  tropical  0.000937\n",
       "466   vanilla  0.004828\n",
       "467    violet  0.000140\n",
       "468     woody  0.001884\n",
       "\n",
       "[469 rows x 2 columns]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_feat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_feat_ranked = df_feat.sort_values(\"score\", ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>features</th>\n",
       "      <th>score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>433</th>\n",
       "      <td>diesel</td>\n",
       "      <td>2.832516e-02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>390</th>\n",
       "      <td>sativa</td>\n",
       "      <td>2.797008e-02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>329</th>\n",
       "      <td>tfidf_329</td>\n",
       "      <td>1.950504e-02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>447</th>\n",
       "      <td>orange</td>\n",
       "      <td>1.869393e-02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>285</th>\n",
       "      <td>tfidf_285</td>\n",
       "      <td>1.609934e-02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>168</th>\n",
       "      <td>tfidf_168</td>\n",
       "      <td>1.557688e-02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>121</th>\n",
       "      <td>tfidf_121</td>\n",
       "      <td>1.459099e-02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>253</th>\n",
       "      <td>tfidf_253</td>\n",
       "      <td>1.326426e-02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>345</th>\n",
       "      <td>tfidf_345</td>\n",
       "      <td>1.292524e-02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>149</th>\n",
       "      <td>tfidf_149</td>\n",
       "      <td>1.287764e-02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>145</th>\n",
       "      <td>tfidf_145</td>\n",
       "      <td>1.186637e-02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>389</th>\n",
       "      <td>indica</td>\n",
       "      <td>1.077542e-02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>239</th>\n",
       "      <td>tfidf_239</td>\n",
       "      <td>9.929492e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>303</th>\n",
       "      <td>tfidf_303</td>\n",
       "      <td>9.757407e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>312</th>\n",
       "      <td>tfidf_312</td>\n",
       "      <td>9.281440e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>tfidf_19</td>\n",
       "      <td>9.279606e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>428</th>\n",
       "      <td>cheese</td>\n",
       "      <td>8.793401e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>141</th>\n",
       "      <td>tfidf_141</td>\n",
       "      <td>8.615596e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>460</th>\n",
       "      <td>sweet</td>\n",
       "      <td>8.275369e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>314</th>\n",
       "      <td>tfidf_314</td>\n",
       "      <td>8.252456e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>199</th>\n",
       "      <td>tfidf_199</td>\n",
       "      <td>8.119864e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>93</th>\n",
       "      <td>tfidf_93</td>\n",
       "      <td>8.034595e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>320</th>\n",
       "      <td>tfidf_320</td>\n",
       "      <td>7.999877e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>tfidf_37</td>\n",
       "      <td>7.922347e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>162</th>\n",
       "      <td>tfidf_162</td>\n",
       "      <td>7.727214e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>388</th>\n",
       "      <td>hybrid</td>\n",
       "      <td>7.666722e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>451</th>\n",
       "      <td>pine</td>\n",
       "      <td>7.514518e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>tfidf_9</td>\n",
       "      <td>6.916314e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>tfidf_24</td>\n",
       "      <td>6.838688e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>402</th>\n",
       "      <td>euphoric</td>\n",
       "      <td>6.794102e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>434</th>\n",
       "      <td>earthy</td>\n",
       "      <td>6.740390e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>413</th>\n",
       "      <td>relaxed</td>\n",
       "      <td>6.680474e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>tfidf_43</td>\n",
       "      <td>6.591092e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>178</th>\n",
       "      <td>tfidf_178</td>\n",
       "      <td>6.562101e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>tfidf_39</td>\n",
       "      <td>6.487399e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>245</th>\n",
       "      <td>tfidf_245</td>\n",
       "      <td>6.390487e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>73</th>\n",
       "      <td>tfidf_73</td>\n",
       "      <td>6.084237e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>341</th>\n",
       "      <td>tfidf_341</td>\n",
       "      <td>5.960411e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>281</th>\n",
       "      <td>tfidf_281</td>\n",
       "      <td>5.855686e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>309</th>\n",
       "      <td>tfidf_309</td>\n",
       "      <td>5.479754e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>207</th>\n",
       "      <td>tfidf_207</td>\n",
       "      <td>5.407985e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>407</th>\n",
       "      <td>happy</td>\n",
       "      <td>5.311460e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>210</th>\n",
       "      <td>tfidf_210</td>\n",
       "      <td>5.247212e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>tfidf_7</td>\n",
       "      <td>5.209974e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>350</th>\n",
       "      <td>tfidf_350</td>\n",
       "      <td>5.028196e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>441</th>\n",
       "      <td>lemon</td>\n",
       "      <td>4.988592e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>tfidf_21</td>\n",
       "      <td>4.981262e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>267</th>\n",
       "      <td>tfidf_267</td>\n",
       "      <td>4.831737e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>466</th>\n",
       "      <td>vanilla</td>\n",
       "      <td>4.827514e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>78</th>\n",
       "      <td>tfidf_78</td>\n",
       "      <td>4.823165e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>420</th>\n",
       "      <td>uplifted</td>\n",
       "      <td>4.814985e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>158</th>\n",
       "      <td>tfidf_158</td>\n",
       "      <td>4.738560e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>151</th>\n",
       "      <td>tfidf_151</td>\n",
       "      <td>4.619555e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>108</th>\n",
       "      <td>tfidf_108</td>\n",
       "      <td>4.545168e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>283</th>\n",
       "      <td>tfidf_283</td>\n",
       "      <td>4.412581e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>tfidf_11</td>\n",
       "      <td>4.411112e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>90</th>\n",
       "      <td>tfidf_90</td>\n",
       "      <td>4.360513e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>357</th>\n",
       "      <td>tfidf_357</td>\n",
       "      <td>4.338765e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>415</th>\n",
       "      <td>sleepy</td>\n",
       "      <td>4.288324e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>364</th>\n",
       "      <td>tfidf_364</td>\n",
       "      <td>4.239926e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>164</th>\n",
       "      <td>tfidf_164</td>\n",
       "      <td>4.236906e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>tfidf_32</td>\n",
       "      <td>4.229022e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>366</th>\n",
       "      <td>tfidf_366</td>\n",
       "      <td>4.160045e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>144</th>\n",
       "      <td>tfidf_144</td>\n",
       "      <td>4.007452e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>362</th>\n",
       "      <td>tfidf_362</td>\n",
       "      <td>3.955167e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>399</th>\n",
       "      <td>dry mouth</td>\n",
       "      <td>3.921088e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>376</th>\n",
       "      <td>tfidf_376</td>\n",
       "      <td>3.872378e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>167</th>\n",
       "      <td>tfidf_167</td>\n",
       "      <td>3.870332e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>67</th>\n",
       "      <td>tfidf_67</td>\n",
       "      <td>3.866647e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>377</th>\n",
       "      <td>tfidf_377</td>\n",
       "      <td>3.853596e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>337</th>\n",
       "      <td>tfidf_337</td>\n",
       "      <td>3.822328e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>437</th>\n",
       "      <td>grape</td>\n",
       "      <td>3.801422e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>409</th>\n",
       "      <td>hungry</td>\n",
       "      <td>3.562250e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>319</th>\n",
       "      <td>tfidf_319</td>\n",
       "      <td>3.559519e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>229</th>\n",
       "      <td>tfidf_229</td>\n",
       "      <td>3.548563e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>173</th>\n",
       "      <td>tfidf_173</td>\n",
       "      <td>3.533901e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>251</th>\n",
       "      <td>tfidf_251</td>\n",
       "      <td>3.520088e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>110</th>\n",
       "      <td>tfidf_110</td>\n",
       "      <td>3.499952e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>400</th>\n",
       "      <td>energetic</td>\n",
       "      <td>3.449501e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>128</th>\n",
       "      <td>tfidf_128</td>\n",
       "      <td>3.424828e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>tfidf_30</td>\n",
       "      <td>3.348725e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>343</th>\n",
       "      <td>tfidf_343</td>\n",
       "      <td>3.263999e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>119</th>\n",
       "      <td>tfidf_119</td>\n",
       "      <td>3.252446e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>tfidf_48</td>\n",
       "      <td>3.228936e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>395</th>\n",
       "      <td>creative</td>\n",
       "      <td>3.184989e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>454</th>\n",
       "      <td>pungent</td>\n",
       "      <td>3.112510e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>431</th>\n",
       "      <td>citrus</td>\n",
       "      <td>3.063602e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>405</th>\n",
       "      <td>focused</td>\n",
       "      <td>3.057161e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>258</th>\n",
       "      <td>tfidf_258</td>\n",
       "      <td>3.056758e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>342</th>\n",
       "      <td>tfidf_342</td>\n",
       "      <td>2.965901e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>418</th>\n",
       "      <td>talkative</td>\n",
       "      <td>2.900900e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>200</th>\n",
       "      <td>tfidf_200</td>\n",
       "      <td>2.900336e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>382</th>\n",
       "      <td>tfidf_382</td>\n",
       "      <td>2.895391e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>353</th>\n",
       "      <td>tfidf_353</td>\n",
       "      <td>2.879876e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>270</th>\n",
       "      <td>tfidf_270</td>\n",
       "      <td>2.780784e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>181</th>\n",
       "      <td>tfidf_181</td>\n",
       "      <td>2.745032e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>340</th>\n",
       "      <td>tfidf_340</td>\n",
       "      <td>2.735531e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>tfidf_5</td>\n",
       "      <td>2.729543e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>426</th>\n",
       "      <td>blueberry</td>\n",
       "      <td>2.674783e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>360</th>\n",
       "      <td>tfidf_360</td>\n",
       "      <td>2.672848e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>380</th>\n",
       "      <td>tfidf_380</td>\n",
       "      <td>2.668731e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>406</th>\n",
       "      <td>giggly</td>\n",
       "      <td>2.652161e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>291</th>\n",
       "      <td>tfidf_291</td>\n",
       "      <td>2.605717e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>176</th>\n",
       "      <td>tfidf_176</td>\n",
       "      <td>2.583948e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>tfidf_14</td>\n",
       "      <td>2.562318e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>104</th>\n",
       "      <td>tfidf_104</td>\n",
       "      <td>2.555963e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>371</th>\n",
       "      <td>tfidf_371</td>\n",
       "      <td>2.544252e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>117</th>\n",
       "      <td>tfidf_117</td>\n",
       "      <td>2.508256e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>292</th>\n",
       "      <td>tfidf_292</td>\n",
       "      <td>2.497994e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>374</th>\n",
       "      <td>tfidf_374</td>\n",
       "      <td>2.480515e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>373</th>\n",
       "      <td>tfidf_373</td>\n",
       "      <td>2.477565e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>217</th>\n",
       "      <td>tfidf_217</td>\n",
       "      <td>2.435217e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>154</th>\n",
       "      <td>tfidf_154</td>\n",
       "      <td>2.422647e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>228</th>\n",
       "      <td>tfidf_228</td>\n",
       "      <td>2.410295e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>294</th>\n",
       "      <td>tfidf_294</td>\n",
       "      <td>2.390530e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>180</th>\n",
       "      <td>tfidf_180</td>\n",
       "      <td>2.372841e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>tfidf_98</td>\n",
       "      <td>2.353668e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>159</th>\n",
       "      <td>tfidf_159</td>\n",
       "      <td>2.349950e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>166</th>\n",
       "      <td>tfidf_166</td>\n",
       "      <td>2.341950e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>419</th>\n",
       "      <td>tingly</td>\n",
       "      <td>2.325269e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>65</th>\n",
       "      <td>tfidf_65</td>\n",
       "      <td>2.318667e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>367</th>\n",
       "      <td>tfidf_367</td>\n",
       "      <td>2.306919e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>tfidf_16</td>\n",
       "      <td>2.290587e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>264</th>\n",
       "      <td>tfidf_264</td>\n",
       "      <td>2.258993e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>347</th>\n",
       "      <td>tfidf_347</td>\n",
       "      <td>2.254493e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>398</th>\n",
       "      <td>dry eyes</td>\n",
       "      <td>2.250142e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>61</th>\n",
       "      <td>tfidf_61</td>\n",
       "      <td>2.239528e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>230</th>\n",
       "      <td>tfidf_230</td>\n",
       "      <td>2.234745e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>tfidf_20</td>\n",
       "      <td>2.213758e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>246</th>\n",
       "      <td>tfidf_246</td>\n",
       "      <td>2.205824e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>289</th>\n",
       "      <td>tfidf_289</td>\n",
       "      <td>2.166856e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>231</th>\n",
       "      <td>tfidf_231</td>\n",
       "      <td>2.152674e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>tfidf_15</td>\n",
       "      <td>2.150090e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>445</th>\n",
       "      <td>mint</td>\n",
       "      <td>2.147444e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>80</th>\n",
       "      <td>tfidf_80</td>\n",
       "      <td>2.136242e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>278</th>\n",
       "      <td>tfidf_278</td>\n",
       "      <td>2.090871e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>295</th>\n",
       "      <td>tfidf_295</td>\n",
       "      <td>2.087692e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>205</th>\n",
       "      <td>tfidf_205</td>\n",
       "      <td>2.024761e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>58</th>\n",
       "      <td>tfidf_58</td>\n",
       "      <td>2.012240e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>424</th>\n",
       "      <td>berry</td>\n",
       "      <td>1.974491e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>161</th>\n",
       "      <td>tfidf_161</td>\n",
       "      <td>1.943260e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>240</th>\n",
       "      <td>tfidf_240</td>\n",
       "      <td>1.916079e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>468</th>\n",
       "      <td>woody</td>\n",
       "      <td>1.884309e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>126</th>\n",
       "      <td>tfidf_126</td>\n",
       "      <td>1.875247e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>370</th>\n",
       "      <td>tfidf_370</td>\n",
       "      <td>1.840447e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>111</th>\n",
       "      <td>tfidf_111</td>\n",
       "      <td>1.828374e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>115</th>\n",
       "      <td>tfidf_115</td>\n",
       "      <td>1.827733e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>354</th>\n",
       "      <td>tfidf_354</td>\n",
       "      <td>1.795266e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>336</th>\n",
       "      <td>tfidf_336</td>\n",
       "      <td>1.765069e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>129</th>\n",
       "      <td>tfidf_129</td>\n",
       "      <td>1.748624e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>221</th>\n",
       "      <td>tfidf_221</td>\n",
       "      <td>1.746800e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>113</th>\n",
       "      <td>tfidf_113</td>\n",
       "      <td>1.735274e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>325</th>\n",
       "      <td>tfidf_325</td>\n",
       "      <td>1.731606e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>338</th>\n",
       "      <td>tfidf_338</td>\n",
       "      <td>1.716320e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>tfidf_46</td>\n",
       "      <td>1.705577e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>455</th>\n",
       "      <td>rose</td>\n",
       "      <td>1.698182e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>tfidf_4</td>\n",
       "      <td>1.686310e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>206</th>\n",
       "      <td>tfidf_206</td>\n",
       "      <td>1.666038e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50</th>\n",
       "      <td>tfidf_50</td>\n",
       "      <td>1.646268e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>457</th>\n",
       "      <td>skunk</td>\n",
       "      <td>1.639860e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>262</th>\n",
       "      <td>tfidf_262</td>\n",
       "      <td>1.639358e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>385</th>\n",
       "      <td>tfidf_385</td>\n",
       "      <td>1.635333e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>393</th>\n",
       "      <td>aroused</td>\n",
       "      <td>1.626152e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>265</th>\n",
       "      <td>tfidf_265</td>\n",
       "      <td>1.620997e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>57</th>\n",
       "      <td>tfidf_57</td>\n",
       "      <td>1.618316e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>91</th>\n",
       "      <td>tfidf_91</td>\n",
       "      <td>1.598925e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>349</th>\n",
       "      <td>tfidf_349</td>\n",
       "      <td>1.598477e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>272</th>\n",
       "      <td>tfidf_272</td>\n",
       "      <td>1.589224e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54</th>\n",
       "      <td>tfidf_54</td>\n",
       "      <td>1.577645e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>124</th>\n",
       "      <td>tfidf_124</td>\n",
       "      <td>1.572864e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>237</th>\n",
       "      <td>tfidf_237</td>\n",
       "      <td>1.570347e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>79</th>\n",
       "      <td>tfidf_79</td>\n",
       "      <td>1.565493e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>tfidf_26</td>\n",
       "      <td>1.559143e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>203</th>\n",
       "      <td>tfidf_203</td>\n",
       "      <td>1.551348e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>152</th>\n",
       "      <td>tfidf_152</td>\n",
       "      <td>1.541019e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>103</th>\n",
       "      <td>tfidf_103</td>\n",
       "      <td>1.537022e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>208</th>\n",
       "      <td>tfidf_208</td>\n",
       "      <td>1.529443e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>298</th>\n",
       "      <td>tfidf_298</td>\n",
       "      <td>1.515476e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>tfidf_28</td>\n",
       "      <td>1.503361e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>153</th>\n",
       "      <td>tfidf_153</td>\n",
       "      <td>1.498530e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>182</th>\n",
       "      <td>tfidf_182</td>\n",
       "      <td>1.490908e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>195</th>\n",
       "      <td>tfidf_195</td>\n",
       "      <td>1.486406e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>260</th>\n",
       "      <td>tfidf_260</td>\n",
       "      <td>1.478214e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>tfidf_6</td>\n",
       "      <td>1.471944e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>123</th>\n",
       "      <td>tfidf_123</td>\n",
       "      <td>1.470729e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>190</th>\n",
       "      <td>tfidf_190</td>\n",
       "      <td>1.468744e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>287</th>\n",
       "      <td>tfidf_287</td>\n",
       "      <td>1.454632e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>332</th>\n",
       "      <td>tfidf_332</td>\n",
       "      <td>1.454608e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>273</th>\n",
       "      <td>tfidf_273</td>\n",
       "      <td>1.453541e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>286</th>\n",
       "      <td>tfidf_286</td>\n",
       "      <td>1.446359e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>369</th>\n",
       "      <td>tfidf_369</td>\n",
       "      <td>1.434016e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>355</th>\n",
       "      <td>tfidf_355</td>\n",
       "      <td>1.432341e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>tfidf_13</td>\n",
       "      <td>1.425046e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>tfidf_34</td>\n",
       "      <td>1.417817e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>101</th>\n",
       "      <td>tfidf_101</td>\n",
       "      <td>1.415049e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>94</th>\n",
       "      <td>tfidf_94</td>\n",
       "      <td>1.414589e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>tfidf_17</td>\n",
       "      <td>1.413795e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>280</th>\n",
       "      <td>tfidf_280</td>\n",
       "      <td>1.401804e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>381</th>\n",
       "      <td>tfidf_381</td>\n",
       "      <td>1.396574e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>175</th>\n",
       "      <td>tfidf_175</td>\n",
       "      <td>1.380697e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>193</th>\n",
       "      <td>tfidf_193</td>\n",
       "      <td>1.376838e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>227</th>\n",
       "      <td>tfidf_227</td>\n",
       "      <td>1.358239e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>259</th>\n",
       "      <td>tfidf_259</td>\n",
       "      <td>1.351675e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>tfidf_99</td>\n",
       "      <td>1.323047e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>321</th>\n",
       "      <td>tfidf_321</td>\n",
       "      <td>1.306051e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>238</th>\n",
       "      <td>tfidf_238</td>\n",
       "      <td>1.302458e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>184</th>\n",
       "      <td>tfidf_184</td>\n",
       "      <td>1.298167e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>120</th>\n",
       "      <td>tfidf_120</td>\n",
       "      <td>1.292029e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>tfidf_41</td>\n",
       "      <td>1.289296e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>311</th>\n",
       "      <td>tfidf_311</td>\n",
       "      <td>1.281989e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>189</th>\n",
       "      <td>tfidf_189</td>\n",
       "      <td>1.265536e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>243</th>\n",
       "      <td>tfidf_243</td>\n",
       "      <td>1.248521e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>268</th>\n",
       "      <td>tfidf_268</td>\n",
       "      <td>1.238483e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>304</th>\n",
       "      <td>tfidf_304</td>\n",
       "      <td>1.232276e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>130</th>\n",
       "      <td>tfidf_130</td>\n",
       "      <td>1.230719e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>198</th>\n",
       "      <td>tfidf_198</td>\n",
       "      <td>1.230396e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>107</th>\n",
       "      <td>tfidf_107</td>\n",
       "      <td>1.225900e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>372</th>\n",
       "      <td>tfidf_372</td>\n",
       "      <td>1.223010e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>116</th>\n",
       "      <td>tfidf_116</td>\n",
       "      <td>1.220277e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>139</th>\n",
       "      <td>tfidf_139</td>\n",
       "      <td>1.211643e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>261</th>\n",
       "      <td>tfidf_261</td>\n",
       "      <td>1.193513e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>134</th>\n",
       "      <td>tfidf_134</td>\n",
       "      <td>1.182911e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>185</th>\n",
       "      <td>tfidf_185</td>\n",
       "      <td>1.180483e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>423</th>\n",
       "      <td>apricot</td>\n",
       "      <td>1.180327e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>tfidf_45</td>\n",
       "      <td>1.164103e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>76</th>\n",
       "      <td>tfidf_76</td>\n",
       "      <td>1.146962e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>344</th>\n",
       "      <td>tfidf_344</td>\n",
       "      <td>1.146196e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>tfidf_96</td>\n",
       "      <td>1.141643e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>234</th>\n",
       "      <td>tfidf_234</td>\n",
       "      <td>1.131230e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>81</th>\n",
       "      <td>tfidf_81</td>\n",
       "      <td>1.105826e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>tfidf_22</td>\n",
       "      <td>1.102873e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>397</th>\n",
       "      <td>dizzy</td>\n",
       "      <td>1.089978e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>tfidf_27</td>\n",
       "      <td>1.065785e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>171</th>\n",
       "      <td>tfidf_171</td>\n",
       "      <td>1.063847e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>297</th>\n",
       "      <td>tfidf_297</td>\n",
       "      <td>1.060519e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75</th>\n",
       "      <td>tfidf_75</td>\n",
       "      <td>1.050640e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>163</th>\n",
       "      <td>tfidf_163</td>\n",
       "      <td>1.049067e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>77</th>\n",
       "      <td>tfidf_77</td>\n",
       "      <td>1.048276e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>tfidf_35</td>\n",
       "      <td>1.045735e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>387</th>\n",
       "      <td>tfidf_387</td>\n",
       "      <td>1.045061e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>326</th>\n",
       "      <td>tfidf_326</td>\n",
       "      <td>1.043533e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>196</th>\n",
       "      <td>tfidf_196</td>\n",
       "      <td>1.036287e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>64</th>\n",
       "      <td>tfidf_64</td>\n",
       "      <td>1.029043e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>288</th>\n",
       "      <td>tfidf_288</td>\n",
       "      <td>1.028954e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>215</th>\n",
       "      <td>tfidf_215</td>\n",
       "      <td>1.021686e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>279</th>\n",
       "      <td>tfidf_279</td>\n",
       "      <td>9.921292e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>70</th>\n",
       "      <td>tfidf_70</td>\n",
       "      <td>9.702064e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>68</th>\n",
       "      <td>tfidf_68</td>\n",
       "      <td>9.575364e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>465</th>\n",
       "      <td>tropical</td>\n",
       "      <td>9.372741e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>222</th>\n",
       "      <td>tfidf_222</td>\n",
       "      <td>9.366568e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>tfidf_40</td>\n",
       "      <td>9.332058e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>69</th>\n",
       "      <td>tfidf_69</td>\n",
       "      <td>9.305525e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>85</th>\n",
       "      <td>tfidf_85</td>\n",
       "      <td>9.146263e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>386</th>\n",
       "      <td>tfidf_386</td>\n",
       "      <td>9.136063e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>112</th>\n",
       "      <td>tfidf_112</td>\n",
       "      <td>9.116718e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>62</th>\n",
       "      <td>tfidf_62</td>\n",
       "      <td>9.096141e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>247</th>\n",
       "      <td>tfidf_247</td>\n",
       "      <td>9.040413e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>146</th>\n",
       "      <td>tfidf_146</td>\n",
       "      <td>8.999351e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>105</th>\n",
       "      <td>tfidf_105</td>\n",
       "      <td>8.998966e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>tfidf_1</td>\n",
       "      <td>8.979723e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>257</th>\n",
       "      <td>tfidf_257</td>\n",
       "      <td>8.962971e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>148</th>\n",
       "      <td>tfidf_148</td>\n",
       "      <td>8.695145e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>421</th>\n",
       "      <td>ammonia</td>\n",
       "      <td>8.613357e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>tfidf_0</td>\n",
       "      <td>8.572175e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>435</th>\n",
       "      <td>flowery</td>\n",
       "      <td>8.529566e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>236</th>\n",
       "      <td>tfidf_236</td>\n",
       "      <td>8.512071e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>136</th>\n",
       "      <td>tfidf_136</td>\n",
       "      <td>8.412281e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>450</th>\n",
       "      <td>pepper</td>\n",
       "      <td>8.403365e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>86</th>\n",
       "      <td>tfidf_86</td>\n",
       "      <td>8.354140e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>63</th>\n",
       "      <td>tfidf_63</td>\n",
       "      <td>8.267928e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>135</th>\n",
       "      <td>tfidf_135</td>\n",
       "      <td>8.263199e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>282</th>\n",
       "      <td>tfidf_282</td>\n",
       "      <td>8.241895e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>458</th>\n",
       "      <td>spicy/herbal</td>\n",
       "      <td>8.231307e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>102</th>\n",
       "      <td>tfidf_102</td>\n",
       "      <td>8.073941e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>88</th>\n",
       "      <td>tfidf_88</td>\n",
       "      <td>8.021226e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>235</th>\n",
       "      <td>tfidf_235</td>\n",
       "      <td>7.997224e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>tfidf_33</td>\n",
       "      <td>7.951315e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>170</th>\n",
       "      <td>tfidf_170</td>\n",
       "      <td>7.939472e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>412</th>\n",
       "      <td>paranoid</td>\n",
       "      <td>7.902793e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52</th>\n",
       "      <td>tfidf_52</td>\n",
       "      <td>7.861098e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>271</th>\n",
       "      <td>tfidf_271</td>\n",
       "      <td>7.858461e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>436</th>\n",
       "      <td>fruit</td>\n",
       "      <td>7.819039e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>232</th>\n",
       "      <td>tfidf_232</td>\n",
       "      <td>7.818282e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>363</th>\n",
       "      <td>tfidf_363</td>\n",
       "      <td>7.812131e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>438</th>\n",
       "      <td>grapefruit</td>\n",
       "      <td>7.698523e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>443</th>\n",
       "      <td>mango</td>\n",
       "      <td>7.694372e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>133</th>\n",
       "      <td>tfidf_133</td>\n",
       "      <td>7.657485e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>263</th>\n",
       "      <td>tfidf_263</td>\n",
       "      <td>7.605853e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>313</th>\n",
       "      <td>tfidf_313</td>\n",
       "      <td>7.498046e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>254</th>\n",
       "      <td>tfidf_254</td>\n",
       "      <td>7.421620e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>tfidf_10</td>\n",
       "      <td>7.406536e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>284</th>\n",
       "      <td>tfidf_284</td>\n",
       "      <td>7.402040e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>225</th>\n",
       "      <td>tfidf_225</td>\n",
       "      <td>7.334910e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>211</th>\n",
       "      <td>tfidf_211</td>\n",
       "      <td>7.321278e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>223</th>\n",
       "      <td>tfidf_223</td>\n",
       "      <td>7.284348e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>183</th>\n",
       "      <td>tfidf_183</td>\n",
       "      <td>7.221437e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>202</th>\n",
       "      <td>tfidf_202</td>\n",
       "      <td>7.143844e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>56</th>\n",
       "      <td>tfidf_56</td>\n",
       "      <td>7.137356e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>277</th>\n",
       "      <td>tfidf_277</td>\n",
       "      <td>7.102867e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>125</th>\n",
       "      <td>tfidf_125</td>\n",
       "      <td>7.028343e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>tfidf_97</td>\n",
       "      <td>6.956160e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>276</th>\n",
       "      <td>tfidf_276</td>\n",
       "      <td>6.932219e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>188</th>\n",
       "      <td>tfidf_188</td>\n",
       "      <td>6.872141e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>384</th>\n",
       "      <td>tfidf_384</td>\n",
       "      <td>6.839646e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>335</th>\n",
       "      <td>tfidf_335</td>\n",
       "      <td>6.801575e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>317</th>\n",
       "      <td>tfidf_317</td>\n",
       "      <td>6.757570e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>220</th>\n",
       "      <td>tfidf_220</td>\n",
       "      <td>6.757237e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>214</th>\n",
       "      <td>tfidf_214</td>\n",
       "      <td>6.727249e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>172</th>\n",
       "      <td>tfidf_172</td>\n",
       "      <td>6.654628e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>tfidf_31</td>\n",
       "      <td>6.651346e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>218</th>\n",
       "      <td>tfidf_218</td>\n",
       "      <td>6.634036e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>186</th>\n",
       "      <td>tfidf_186</td>\n",
       "      <td>6.616703e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>216</th>\n",
       "      <td>tfidf_216</td>\n",
       "      <td>6.615108e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>318</th>\n",
       "      <td>tfidf_318</td>\n",
       "      <td>6.611060e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>275</th>\n",
       "      <td>tfidf_275</td>\n",
       "      <td>6.608521e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>tfidf_23</td>\n",
       "      <td>6.596965e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>137</th>\n",
       "      <td>tfidf_137</td>\n",
       "      <td>6.587372e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>71</th>\n",
       "      <td>tfidf_71</td>\n",
       "      <td>6.587352e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>82</th>\n",
       "      <td>tfidf_82</td>\n",
       "      <td>6.578352e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>194</th>\n",
       "      <td>tfidf_194</td>\n",
       "      <td>6.570953e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>356</th>\n",
       "      <td>tfidf_356</td>\n",
       "      <td>6.559977e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>157</th>\n",
       "      <td>tfidf_157</td>\n",
       "      <td>6.453456e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>138</th>\n",
       "      <td>tfidf_138</td>\n",
       "      <td>6.399732e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>132</th>\n",
       "      <td>tfidf_132</td>\n",
       "      <td>6.397224e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>109</th>\n",
       "      <td>tfidf_109</td>\n",
       "      <td>6.396826e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>tfidf_12</td>\n",
       "      <td>6.394375e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>226</th>\n",
       "      <td>tfidf_226</td>\n",
       "      <td>6.382321e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>244</th>\n",
       "      <td>tfidf_244</td>\n",
       "      <td>6.339904e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>333</th>\n",
       "      <td>tfidf_333</td>\n",
       "      <td>6.253366e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>179</th>\n",
       "      <td>tfidf_179</td>\n",
       "      <td>6.207732e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>346</th>\n",
       "      <td>tfidf_346</td>\n",
       "      <td>6.178175e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>106</th>\n",
       "      <td>tfidf_106</td>\n",
       "      <td>6.163469e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>432</th>\n",
       "      <td>coffee</td>\n",
       "      <td>6.144547e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>408</th>\n",
       "      <td>headache</td>\n",
       "      <td>6.080852e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>348</th>\n",
       "      <td>tfidf_348</td>\n",
       "      <td>6.070308e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>255</th>\n",
       "      <td>tfidf_255</td>\n",
       "      <td>6.040016e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>310</th>\n",
       "      <td>tfidf_310</td>\n",
       "      <td>5.990062e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>tfidf_18</td>\n",
       "      <td>5.945380e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>339</th>\n",
       "      <td>tfidf_339</td>\n",
       "      <td>5.808102e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>122</th>\n",
       "      <td>tfidf_122</td>\n",
       "      <td>5.763454e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>392</th>\n",
       "      <td>anxious</td>\n",
       "      <td>5.721071e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>100</th>\n",
       "      <td>tfidf_100</td>\n",
       "      <td>5.685731e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>308</th>\n",
       "      <td>tfidf_308</td>\n",
       "      <td>5.652519e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>359</th>\n",
       "      <td>tfidf_359</td>\n",
       "      <td>5.633557e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>160</th>\n",
       "      <td>tfidf_160</td>\n",
       "      <td>5.595201e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>84</th>\n",
       "      <td>tfidf_84</td>\n",
       "      <td>5.577173e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>tfidf_49</td>\n",
       "      <td>5.542163e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>tfidf_29</td>\n",
       "      <td>5.438595e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>439</th>\n",
       "      <td>honey</td>\n",
       "      <td>5.424814e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>274</th>\n",
       "      <td>tfidf_274</td>\n",
       "      <td>5.412922e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>323</th>\n",
       "      <td>tfidf_323</td>\n",
       "      <td>5.402012e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>249</th>\n",
       "      <td>tfidf_249</td>\n",
       "      <td>5.355518e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>209</th>\n",
       "      <td>tfidf_209</td>\n",
       "      <td>5.192582e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>142</th>\n",
       "      <td>tfidf_142</td>\n",
       "      <td>5.179061e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>429</th>\n",
       "      <td>chemical</td>\n",
       "      <td>5.129868e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>233</th>\n",
       "      <td>tfidf_233</td>\n",
       "      <td>5.127744e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>442</th>\n",
       "      <td>lime</td>\n",
       "      <td>5.118810e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>361</th>\n",
       "      <td>tfidf_361</td>\n",
       "      <td>4.986947e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>224</th>\n",
       "      <td>tfidf_224</td>\n",
       "      <td>4.949380e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>316</th>\n",
       "      <td>tfidf_316</td>\n",
       "      <td>4.946699e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>452</th>\n",
       "      <td>pineapple</td>\n",
       "      <td>4.943806e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>248</th>\n",
       "      <td>tfidf_248</td>\n",
       "      <td>4.935277e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>219</th>\n",
       "      <td>tfidf_219</td>\n",
       "      <td>4.926077e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>307</th>\n",
       "      <td>tfidf_307</td>\n",
       "      <td>4.839117e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>147</th>\n",
       "      <td>tfidf_147</td>\n",
       "      <td>4.838422e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>299</th>\n",
       "      <td>tfidf_299</td>\n",
       "      <td>4.815016e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>464</th>\n",
       "      <td>tree</td>\n",
       "      <td>4.811971e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>290</th>\n",
       "      <td>tfidf_290</td>\n",
       "      <td>4.753049e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53</th>\n",
       "      <td>tfidf_53</td>\n",
       "      <td>4.748602e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>446</th>\n",
       "      <td>nutty</td>\n",
       "      <td>4.740253e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>459</th>\n",
       "      <td>strawberry</td>\n",
       "      <td>4.731871e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>92</th>\n",
       "      <td>tfidf_92</td>\n",
       "      <td>4.712428e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>324</th>\n",
       "      <td>tfidf_324</td>\n",
       "      <td>4.703752e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51</th>\n",
       "      <td>tfidf_51</td>\n",
       "      <td>4.697149e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>66</th>\n",
       "      <td>tfidf_66</td>\n",
       "      <td>4.598551e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>55</th>\n",
       "      <td>tfidf_55</td>\n",
       "      <td>4.561256e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>305</th>\n",
       "      <td>tfidf_305</td>\n",
       "      <td>4.523420e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>83</th>\n",
       "      <td>tfidf_83</td>\n",
       "      <td>4.498608e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>301</th>\n",
       "      <td>tfidf_301</td>\n",
       "      <td>4.451532e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>375</th>\n",
       "      <td>tfidf_375</td>\n",
       "      <td>4.412749e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>tfidf_2</td>\n",
       "      <td>4.331554e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>187</th>\n",
       "      <td>tfidf_187</td>\n",
       "      <td>4.320304e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>293</th>\n",
       "      <td>tfidf_293</td>\n",
       "      <td>4.263801e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>156</th>\n",
       "      <td>tfidf_156</td>\n",
       "      <td>4.258652e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>127</th>\n",
       "      <td>tfidf_127</td>\n",
       "      <td>4.196956e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>327</th>\n",
       "      <td>tfidf_327</td>\n",
       "      <td>4.188572e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>155</th>\n",
       "      <td>tfidf_155</td>\n",
       "      <td>4.179005e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>256</th>\n",
       "      <td>tfidf_256</td>\n",
       "      <td>4.178878e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>269</th>\n",
       "      <td>tfidf_269</td>\n",
       "      <td>4.172307e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>72</th>\n",
       "      <td>tfidf_72</td>\n",
       "      <td>4.139911e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>334</th>\n",
       "      <td>tfidf_334</td>\n",
       "      <td>4.134345e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>351</th>\n",
       "      <td>tfidf_351</td>\n",
       "      <td>4.102120e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>140</th>\n",
       "      <td>tfidf_140</td>\n",
       "      <td>4.089015e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>tfidf_25</td>\n",
       "      <td>4.083638e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>358</th>\n",
       "      <td>tfidf_358</td>\n",
       "      <td>4.082123e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>tfidf_3</td>\n",
       "      <td>4.080081e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>440</th>\n",
       "      <td>lavender</td>\n",
       "      <td>4.051701e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59</th>\n",
       "      <td>tfidf_59</td>\n",
       "      <td>4.042766e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>169</th>\n",
       "      <td>tfidf_169</td>\n",
       "      <td>3.997844e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>165</th>\n",
       "      <td>tfidf_165</td>\n",
       "      <td>3.984783e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>tfidf_44</td>\n",
       "      <td>3.965230e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>462</th>\n",
       "      <td>tea</td>\n",
       "      <td>3.910220e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>300</th>\n",
       "      <td>tfidf_300</td>\n",
       "      <td>3.879122e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>87</th>\n",
       "      <td>tfidf_87</td>\n",
       "      <td>3.850605e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>306</th>\n",
       "      <td>tfidf_306</td>\n",
       "      <td>3.731452e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>118</th>\n",
       "      <td>tfidf_118</td>\n",
       "      <td>3.716694e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>150</th>\n",
       "      <td>tfidf_150</td>\n",
       "      <td>3.617955e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>368</th>\n",
       "      <td>tfidf_368</td>\n",
       "      <td>3.613440e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>tfidf_38</td>\n",
       "      <td>3.558555e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>296</th>\n",
       "      <td>tfidf_296</td>\n",
       "      <td>3.503595e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>328</th>\n",
       "      <td>tfidf_328</td>\n",
       "      <td>3.421472e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>60</th>\n",
       "      <td>tfidf_60</td>\n",
       "      <td>3.388047e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>456</th>\n",
       "      <td>sage</td>\n",
       "      <td>3.325193e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>379</th>\n",
       "      <td>tfidf_379</td>\n",
       "      <td>3.310431e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>330</th>\n",
       "      <td>tfidf_330</td>\n",
       "      <td>3.290300e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>352</th>\n",
       "      <td>tfidf_352</td>\n",
       "      <td>3.277432e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>427</th>\n",
       "      <td>butter</td>\n",
       "      <td>3.197104e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>201</th>\n",
       "      <td>tfidf_201</td>\n",
       "      <td>3.165191e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>383</th>\n",
       "      <td>tfidf_383</td>\n",
       "      <td>3.147965e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>212</th>\n",
       "      <td>tfidf_212</td>\n",
       "      <td>3.141445e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>174</th>\n",
       "      <td>tfidf_174</td>\n",
       "      <td>3.120144e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>213</th>\n",
       "      <td>tfidf_213</td>\n",
       "      <td>3.104044e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>461</th>\n",
       "      <td>tar</td>\n",
       "      <td>3.077542e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>192</th>\n",
       "      <td>tfidf_192</td>\n",
       "      <td>3.062697e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>365</th>\n",
       "      <td>tfidf_365</td>\n",
       "      <td>3.047672e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>331</th>\n",
       "      <td>tfidf_331</td>\n",
       "      <td>3.031317e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>315</th>\n",
       "      <td>tfidf_315</td>\n",
       "      <td>3.016935e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>tfidf_42</td>\n",
       "      <td>2.947676e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>114</th>\n",
       "      <td>tfidf_114</td>\n",
       "      <td>2.902804e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>177</th>\n",
       "      <td>tfidf_177</td>\n",
       "      <td>2.791501e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>191</th>\n",
       "      <td>tfidf_191</td>\n",
       "      <td>2.733516e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>tfidf_36</td>\n",
       "      <td>2.712538e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>131</th>\n",
       "      <td>tfidf_131</td>\n",
       "      <td>2.689384e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>tfidf_8</td>\n",
       "      <td>2.482872e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>378</th>\n",
       "      <td>tfidf_378</td>\n",
       "      <td>2.453470e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>tfidf_47</td>\n",
       "      <td>2.377061e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>89</th>\n",
       "      <td>tfidf_89</td>\n",
       "      <td>2.371382e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>143</th>\n",
       "      <td>tfidf_143</td>\n",
       "      <td>2.348801e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>242</th>\n",
       "      <td>tfidf_242</td>\n",
       "      <td>2.299404e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>322</th>\n",
       "      <td>tfidf_322</td>\n",
       "      <td>2.179724e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>74</th>\n",
       "      <td>tfidf_74</td>\n",
       "      <td>2.162910e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>252</th>\n",
       "      <td>tfidf_252</td>\n",
       "      <td>2.162541e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>197</th>\n",
       "      <td>tfidf_197</td>\n",
       "      <td>2.007052e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>463</th>\n",
       "      <td>tobacco</td>\n",
       "      <td>1.981464e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>204</th>\n",
       "      <td>tfidf_204</td>\n",
       "      <td>1.906983e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>tfidf_95</td>\n",
       "      <td>1.752997e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>453</th>\n",
       "      <td>plum</td>\n",
       "      <td>1.640457e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>250</th>\n",
       "      <td>tfidf_250</td>\n",
       "      <td>1.600262e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>241</th>\n",
       "      <td>tfidf_241</td>\n",
       "      <td>1.570295e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>449</th>\n",
       "      <td>pear</td>\n",
       "      <td>1.475459e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>467</th>\n",
       "      <td>violet</td>\n",
       "      <td>1.396575e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>425</th>\n",
       "      <td>blue cheese</td>\n",
       "      <td>1.360597e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>266</th>\n",
       "      <td>tfidf_266</td>\n",
       "      <td>1.260185e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>302</th>\n",
       "      <td>tfidf_302</td>\n",
       "      <td>1.234242e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>444</th>\n",
       "      <td>menthol</td>\n",
       "      <td>1.011927e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>422</th>\n",
       "      <td>apple</td>\n",
       "      <td>9.589234e-05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>430</th>\n",
       "      <td>chestnut</td>\n",
       "      <td>5.960513e-05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>391</th>\n",
       "      <td>anxiety</td>\n",
       "      <td>3.942447e-05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>448</th>\n",
       "      <td>peach</td>\n",
       "      <td>3.145905e-05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>396</th>\n",
       "      <td>depression</td>\n",
       "      <td>3.118104e-05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>410</th>\n",
       "      <td>migraines</td>\n",
       "      <td>2.091404e-05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>404</th>\n",
       "      <td>fatigue</td>\n",
       "      <td>7.477164e-07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>394</th>\n",
       "      <td>arthritis</td>\n",
       "      <td>2.378775e-07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>403</th>\n",
       "      <td>eye pressure</td>\n",
       "      <td>1.598560e-08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>411</th>\n",
       "      <td>pain</td>\n",
       "      <td>4.218864e-09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>414</th>\n",
       "      <td>seizures</td>\n",
       "      <td>0.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>416</th>\n",
       "      <td>spasticity</td>\n",
       "      <td>0.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>401</th>\n",
       "      <td>epilepsy</td>\n",
       "      <td>0.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>417</th>\n",
       "      <td>stress</td>\n",
       "      <td>0.000000e+00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         features         score\n",
       "433        diesel  2.832516e-02\n",
       "390        sativa  2.797008e-02\n",
       "329     tfidf_329  1.950504e-02\n",
       "447        orange  1.869393e-02\n",
       "285     tfidf_285  1.609934e-02\n",
       "168     tfidf_168  1.557688e-02\n",
       "121     tfidf_121  1.459099e-02\n",
       "253     tfidf_253  1.326426e-02\n",
       "345     tfidf_345  1.292524e-02\n",
       "149     tfidf_149  1.287764e-02\n",
       "145     tfidf_145  1.186637e-02\n",
       "389        indica  1.077542e-02\n",
       "239     tfidf_239  9.929492e-03\n",
       "303     tfidf_303  9.757407e-03\n",
       "312     tfidf_312  9.281440e-03\n",
       "19       tfidf_19  9.279606e-03\n",
       "428        cheese  8.793401e-03\n",
       "141     tfidf_141  8.615596e-03\n",
       "460         sweet  8.275369e-03\n",
       "314     tfidf_314  8.252456e-03\n",
       "199     tfidf_199  8.119864e-03\n",
       "93       tfidf_93  8.034595e-03\n",
       "320     tfidf_320  7.999877e-03\n",
       "37       tfidf_37  7.922347e-03\n",
       "162     tfidf_162  7.727214e-03\n",
       "388        hybrid  7.666722e-03\n",
       "451          pine  7.514518e-03\n",
       "9         tfidf_9  6.916314e-03\n",
       "24       tfidf_24  6.838688e-03\n",
       "402      euphoric  6.794102e-03\n",
       "434        earthy  6.740390e-03\n",
       "413       relaxed  6.680474e-03\n",
       "43       tfidf_43  6.591092e-03\n",
       "178     tfidf_178  6.562101e-03\n",
       "39       tfidf_39  6.487399e-03\n",
       "245     tfidf_245  6.390487e-03\n",
       "73       tfidf_73  6.084237e-03\n",
       "341     tfidf_341  5.960411e-03\n",
       "281     tfidf_281  5.855686e-03\n",
       "309     tfidf_309  5.479754e-03\n",
       "207     tfidf_207  5.407985e-03\n",
       "407         happy  5.311460e-03\n",
       "210     tfidf_210  5.247212e-03\n",
       "7         tfidf_7  5.209974e-03\n",
       "350     tfidf_350  5.028196e-03\n",
       "441         lemon  4.988592e-03\n",
       "21       tfidf_21  4.981262e-03\n",
       "267     tfidf_267  4.831737e-03\n",
       "466       vanilla  4.827514e-03\n",
       "78       tfidf_78  4.823165e-03\n",
       "420      uplifted  4.814985e-03\n",
       "158     tfidf_158  4.738560e-03\n",
       "151     tfidf_151  4.619555e-03\n",
       "108     tfidf_108  4.545168e-03\n",
       "283     tfidf_283  4.412581e-03\n",
       "11       tfidf_11  4.411112e-03\n",
       "90       tfidf_90  4.360513e-03\n",
       "357     tfidf_357  4.338765e-03\n",
       "415        sleepy  4.288324e-03\n",
       "364     tfidf_364  4.239926e-03\n",
       "164     tfidf_164  4.236906e-03\n",
       "32       tfidf_32  4.229022e-03\n",
       "366     tfidf_366  4.160045e-03\n",
       "144     tfidf_144  4.007452e-03\n",
       "362     tfidf_362  3.955167e-03\n",
       "399     dry mouth  3.921088e-03\n",
       "376     tfidf_376  3.872378e-03\n",
       "167     tfidf_167  3.870332e-03\n",
       "67       tfidf_67  3.866647e-03\n",
       "377     tfidf_377  3.853596e-03\n",
       "337     tfidf_337  3.822328e-03\n",
       "437         grape  3.801422e-03\n",
       "409        hungry  3.562250e-03\n",
       "319     tfidf_319  3.559519e-03\n",
       "229     tfidf_229  3.548563e-03\n",
       "173     tfidf_173  3.533901e-03\n",
       "251     tfidf_251  3.520088e-03\n",
       "110     tfidf_110  3.499952e-03\n",
       "400     energetic  3.449501e-03\n",
       "128     tfidf_128  3.424828e-03\n",
       "30       tfidf_30  3.348725e-03\n",
       "343     tfidf_343  3.263999e-03\n",
       "119     tfidf_119  3.252446e-03\n",
       "48       tfidf_48  3.228936e-03\n",
       "395      creative  3.184989e-03\n",
       "454       pungent  3.112510e-03\n",
       "431        citrus  3.063602e-03\n",
       "405       focused  3.057161e-03\n",
       "258     tfidf_258  3.056758e-03\n",
       "342     tfidf_342  2.965901e-03\n",
       "418     talkative  2.900900e-03\n",
       "200     tfidf_200  2.900336e-03\n",
       "382     tfidf_382  2.895391e-03\n",
       "353     tfidf_353  2.879876e-03\n",
       "270     tfidf_270  2.780784e-03\n",
       "181     tfidf_181  2.745032e-03\n",
       "340     tfidf_340  2.735531e-03\n",
       "5         tfidf_5  2.729543e-03\n",
       "426     blueberry  2.674783e-03\n",
       "360     tfidf_360  2.672848e-03\n",
       "380     tfidf_380  2.668731e-03\n",
       "406        giggly  2.652161e-03\n",
       "291     tfidf_291  2.605717e-03\n",
       "176     tfidf_176  2.583948e-03\n",
       "14       tfidf_14  2.562318e-03\n",
       "104     tfidf_104  2.555963e-03\n",
       "371     tfidf_371  2.544252e-03\n",
       "117     tfidf_117  2.508256e-03\n",
       "292     tfidf_292  2.497994e-03\n",
       "374     tfidf_374  2.480515e-03\n",
       "373     tfidf_373  2.477565e-03\n",
       "217     tfidf_217  2.435217e-03\n",
       "154     tfidf_154  2.422647e-03\n",
       "228     tfidf_228  2.410295e-03\n",
       "294     tfidf_294  2.390530e-03\n",
       "180     tfidf_180  2.372841e-03\n",
       "98       tfidf_98  2.353668e-03\n",
       "159     tfidf_159  2.349950e-03\n",
       "166     tfidf_166  2.341950e-03\n",
       "419        tingly  2.325269e-03\n",
       "65       tfidf_65  2.318667e-03\n",
       "367     tfidf_367  2.306919e-03\n",
       "16       tfidf_16  2.290587e-03\n",
       "264     tfidf_264  2.258993e-03\n",
       "347     tfidf_347  2.254493e-03\n",
       "398      dry eyes  2.250142e-03\n",
       "61       tfidf_61  2.239528e-03\n",
       "230     tfidf_230  2.234745e-03\n",
       "20       tfidf_20  2.213758e-03\n",
       "246     tfidf_246  2.205824e-03\n",
       "289     tfidf_289  2.166856e-03\n",
       "231     tfidf_231  2.152674e-03\n",
       "15       tfidf_15  2.150090e-03\n",
       "445          mint  2.147444e-03\n",
       "80       tfidf_80  2.136242e-03\n",
       "278     tfidf_278  2.090871e-03\n",
       "295     tfidf_295  2.087692e-03\n",
       "205     tfidf_205  2.024761e-03\n",
       "58       tfidf_58  2.012240e-03\n",
       "424         berry  1.974491e-03\n",
       "161     tfidf_161  1.943260e-03\n",
       "240     tfidf_240  1.916079e-03\n",
       "468         woody  1.884309e-03\n",
       "126     tfidf_126  1.875247e-03\n",
       "370     tfidf_370  1.840447e-03\n",
       "111     tfidf_111  1.828374e-03\n",
       "115     tfidf_115  1.827733e-03\n",
       "354     tfidf_354  1.795266e-03\n",
       "336     tfidf_336  1.765069e-03\n",
       "129     tfidf_129  1.748624e-03\n",
       "221     tfidf_221  1.746800e-03\n",
       "113     tfidf_113  1.735274e-03\n",
       "325     tfidf_325  1.731606e-03\n",
       "338     tfidf_338  1.716320e-03\n",
       "46       tfidf_46  1.705577e-03\n",
       "455          rose  1.698182e-03\n",
       "4         tfidf_4  1.686310e-03\n",
       "206     tfidf_206  1.666038e-03\n",
       "50       tfidf_50  1.646268e-03\n",
       "457         skunk  1.639860e-03\n",
       "262     tfidf_262  1.639358e-03\n",
       "385     tfidf_385  1.635333e-03\n",
       "393       aroused  1.626152e-03\n",
       "265     tfidf_265  1.620997e-03\n",
       "57       tfidf_57  1.618316e-03\n",
       "91       tfidf_91  1.598925e-03\n",
       "349     tfidf_349  1.598477e-03\n",
       "272     tfidf_272  1.589224e-03\n",
       "54       tfidf_54  1.577645e-03\n",
       "124     tfidf_124  1.572864e-03\n",
       "237     tfidf_237  1.570347e-03\n",
       "79       tfidf_79  1.565493e-03\n",
       "26       tfidf_26  1.559143e-03\n",
       "203     tfidf_203  1.551348e-03\n",
       "152     tfidf_152  1.541019e-03\n",
       "103     tfidf_103  1.537022e-03\n",
       "208     tfidf_208  1.529443e-03\n",
       "298     tfidf_298  1.515476e-03\n",
       "28       tfidf_28  1.503361e-03\n",
       "153     tfidf_153  1.498530e-03\n",
       "182     tfidf_182  1.490908e-03\n",
       "195     tfidf_195  1.486406e-03\n",
       "260     tfidf_260  1.478214e-03\n",
       "6         tfidf_6  1.471944e-03\n",
       "123     tfidf_123  1.470729e-03\n",
       "190     tfidf_190  1.468744e-03\n",
       "287     tfidf_287  1.454632e-03\n",
       "332     tfidf_332  1.454608e-03\n",
       "273     tfidf_273  1.453541e-03\n",
       "286     tfidf_286  1.446359e-03\n",
       "369     tfidf_369  1.434016e-03\n",
       "355     tfidf_355  1.432341e-03\n",
       "13       tfidf_13  1.425046e-03\n",
       "34       tfidf_34  1.417817e-03\n",
       "101     tfidf_101  1.415049e-03\n",
       "94       tfidf_94  1.414589e-03\n",
       "17       tfidf_17  1.413795e-03\n",
       "280     tfidf_280  1.401804e-03\n",
       "381     tfidf_381  1.396574e-03\n",
       "175     tfidf_175  1.380697e-03\n",
       "193     tfidf_193  1.376838e-03\n",
       "227     tfidf_227  1.358239e-03\n",
       "259     tfidf_259  1.351675e-03\n",
       "99       tfidf_99  1.323047e-03\n",
       "321     tfidf_321  1.306051e-03\n",
       "238     tfidf_238  1.302458e-03\n",
       "184     tfidf_184  1.298167e-03\n",
       "120     tfidf_120  1.292029e-03\n",
       "41       tfidf_41  1.289296e-03\n",
       "311     tfidf_311  1.281989e-03\n",
       "189     tfidf_189  1.265536e-03\n",
       "243     tfidf_243  1.248521e-03\n",
       "268     tfidf_268  1.238483e-03\n",
       "304     tfidf_304  1.232276e-03\n",
       "130     tfidf_130  1.230719e-03\n",
       "198     tfidf_198  1.230396e-03\n",
       "107     tfidf_107  1.225900e-03\n",
       "372     tfidf_372  1.223010e-03\n",
       "116     tfidf_116  1.220277e-03\n",
       "139     tfidf_139  1.211643e-03\n",
       "261     tfidf_261  1.193513e-03\n",
       "134     tfidf_134  1.182911e-03\n",
       "185     tfidf_185  1.180483e-03\n",
       "423       apricot  1.180327e-03\n",
       "45       tfidf_45  1.164103e-03\n",
       "76       tfidf_76  1.146962e-03\n",
       "344     tfidf_344  1.146196e-03\n",
       "96       tfidf_96  1.141643e-03\n",
       "234     tfidf_234  1.131230e-03\n",
       "81       tfidf_81  1.105826e-03\n",
       "22       tfidf_22  1.102873e-03\n",
       "397         dizzy  1.089978e-03\n",
       "27       tfidf_27  1.065785e-03\n",
       "171     tfidf_171  1.063847e-03\n",
       "297     tfidf_297  1.060519e-03\n",
       "75       tfidf_75  1.050640e-03\n",
       "163     tfidf_163  1.049067e-03\n",
       "77       tfidf_77  1.048276e-03\n",
       "35       tfidf_35  1.045735e-03\n",
       "387     tfidf_387  1.045061e-03\n",
       "326     tfidf_326  1.043533e-03\n",
       "196     tfidf_196  1.036287e-03\n",
       "64       tfidf_64  1.029043e-03\n",
       "288     tfidf_288  1.028954e-03\n",
       "215     tfidf_215  1.021686e-03\n",
       "279     tfidf_279  9.921292e-04\n",
       "70       tfidf_70  9.702064e-04\n",
       "68       tfidf_68  9.575364e-04\n",
       "465      tropical  9.372741e-04\n",
       "222     tfidf_222  9.366568e-04\n",
       "40       tfidf_40  9.332058e-04\n",
       "69       tfidf_69  9.305525e-04\n",
       "85       tfidf_85  9.146263e-04\n",
       "386     tfidf_386  9.136063e-04\n",
       "112     tfidf_112  9.116718e-04\n",
       "62       tfidf_62  9.096141e-04\n",
       "247     tfidf_247  9.040413e-04\n",
       "146     tfidf_146  8.999351e-04\n",
       "105     tfidf_105  8.998966e-04\n",
       "1         tfidf_1  8.979723e-04\n",
       "257     tfidf_257  8.962971e-04\n",
       "148     tfidf_148  8.695145e-04\n",
       "421       ammonia  8.613357e-04\n",
       "0         tfidf_0  8.572175e-04\n",
       "435       flowery  8.529566e-04\n",
       "236     tfidf_236  8.512071e-04\n",
       "136     tfidf_136  8.412281e-04\n",
       "450        pepper  8.403365e-04\n",
       "86       tfidf_86  8.354140e-04\n",
       "63       tfidf_63  8.267928e-04\n",
       "135     tfidf_135  8.263199e-04\n",
       "282     tfidf_282  8.241895e-04\n",
       "458  spicy/herbal  8.231307e-04\n",
       "102     tfidf_102  8.073941e-04\n",
       "88       tfidf_88  8.021226e-04\n",
       "235     tfidf_235  7.997224e-04\n",
       "33       tfidf_33  7.951315e-04\n",
       "170     tfidf_170  7.939472e-04\n",
       "412      paranoid  7.902793e-04\n",
       "52       tfidf_52  7.861098e-04\n",
       "271     tfidf_271  7.858461e-04\n",
       "436         fruit  7.819039e-04\n",
       "232     tfidf_232  7.818282e-04\n",
       "363     tfidf_363  7.812131e-04\n",
       "438    grapefruit  7.698523e-04\n",
       "443         mango  7.694372e-04\n",
       "133     tfidf_133  7.657485e-04\n",
       "263     tfidf_263  7.605853e-04\n",
       "313     tfidf_313  7.498046e-04\n",
       "254     tfidf_254  7.421620e-04\n",
       "10       tfidf_10  7.406536e-04\n",
       "284     tfidf_284  7.402040e-04\n",
       "225     tfidf_225  7.334910e-04\n",
       "211     tfidf_211  7.321278e-04\n",
       "223     tfidf_223  7.284348e-04\n",
       "183     tfidf_183  7.221437e-04\n",
       "202     tfidf_202  7.143844e-04\n",
       "56       tfidf_56  7.137356e-04\n",
       "277     tfidf_277  7.102867e-04\n",
       "125     tfidf_125  7.028343e-04\n",
       "97       tfidf_97  6.956160e-04\n",
       "276     tfidf_276  6.932219e-04\n",
       "188     tfidf_188  6.872141e-04\n",
       "384     tfidf_384  6.839646e-04\n",
       "335     tfidf_335  6.801575e-04\n",
       "317     tfidf_317  6.757570e-04\n",
       "220     tfidf_220  6.757237e-04\n",
       "214     tfidf_214  6.727249e-04\n",
       "172     tfidf_172  6.654628e-04\n",
       "31       tfidf_31  6.651346e-04\n",
       "218     tfidf_218  6.634036e-04\n",
       "186     tfidf_186  6.616703e-04\n",
       "216     tfidf_216  6.615108e-04\n",
       "318     tfidf_318  6.611060e-04\n",
       "275     tfidf_275  6.608521e-04\n",
       "23       tfidf_23  6.596965e-04\n",
       "137     tfidf_137  6.587372e-04\n",
       "71       tfidf_71  6.587352e-04\n",
       "82       tfidf_82  6.578352e-04\n",
       "194     tfidf_194  6.570953e-04\n",
       "356     tfidf_356  6.559977e-04\n",
       "157     tfidf_157  6.453456e-04\n",
       "138     tfidf_138  6.399732e-04\n",
       "132     tfidf_132  6.397224e-04\n",
       "109     tfidf_109  6.396826e-04\n",
       "12       tfidf_12  6.394375e-04\n",
       "226     tfidf_226  6.382321e-04\n",
       "244     tfidf_244  6.339904e-04\n",
       "333     tfidf_333  6.253366e-04\n",
       "179     tfidf_179  6.207732e-04\n",
       "346     tfidf_346  6.178175e-04\n",
       "106     tfidf_106  6.163469e-04\n",
       "432        coffee  6.144547e-04\n",
       "408      headache  6.080852e-04\n",
       "348     tfidf_348  6.070308e-04\n",
       "255     tfidf_255  6.040016e-04\n",
       "310     tfidf_310  5.990062e-04\n",
       "18       tfidf_18  5.945380e-04\n",
       "339     tfidf_339  5.808102e-04\n",
       "122     tfidf_122  5.763454e-04\n",
       "392       anxious  5.721071e-04\n",
       "100     tfidf_100  5.685731e-04\n",
       "308     tfidf_308  5.652519e-04\n",
       "359     tfidf_359  5.633557e-04\n",
       "160     tfidf_160  5.595201e-04\n",
       "84       tfidf_84  5.577173e-04\n",
       "49       tfidf_49  5.542163e-04\n",
       "29       tfidf_29  5.438595e-04\n",
       "439         honey  5.424814e-04\n",
       "274     tfidf_274  5.412922e-04\n",
       "323     tfidf_323  5.402012e-04\n",
       "249     tfidf_249  5.355518e-04\n",
       "209     tfidf_209  5.192582e-04\n",
       "142     tfidf_142  5.179061e-04\n",
       "429      chemical  5.129868e-04\n",
       "233     tfidf_233  5.127744e-04\n",
       "442          lime  5.118810e-04\n",
       "361     tfidf_361  4.986947e-04\n",
       "224     tfidf_224  4.949380e-04\n",
       "316     tfidf_316  4.946699e-04\n",
       "452     pineapple  4.943806e-04\n",
       "248     tfidf_248  4.935277e-04\n",
       "219     tfidf_219  4.926077e-04\n",
       "307     tfidf_307  4.839117e-04\n",
       "147     tfidf_147  4.838422e-04\n",
       "299     tfidf_299  4.815016e-04\n",
       "464          tree  4.811971e-04\n",
       "290     tfidf_290  4.753049e-04\n",
       "53       tfidf_53  4.748602e-04\n",
       "446         nutty  4.740253e-04\n",
       "459    strawberry  4.731871e-04\n",
       "92       tfidf_92  4.712428e-04\n",
       "324     tfidf_324  4.703752e-04\n",
       "51       tfidf_51  4.697149e-04\n",
       "66       tfidf_66  4.598551e-04\n",
       "55       tfidf_55  4.561256e-04\n",
       "305     tfidf_305  4.523420e-04\n",
       "83       tfidf_83  4.498608e-04\n",
       "301     tfidf_301  4.451532e-04\n",
       "375     tfidf_375  4.412749e-04\n",
       "2         tfidf_2  4.331554e-04\n",
       "187     tfidf_187  4.320304e-04\n",
       "293     tfidf_293  4.263801e-04\n",
       "156     tfidf_156  4.258652e-04\n",
       "127     tfidf_127  4.196956e-04\n",
       "327     tfidf_327  4.188572e-04\n",
       "155     tfidf_155  4.179005e-04\n",
       "256     tfidf_256  4.178878e-04\n",
       "269     tfidf_269  4.172307e-04\n",
       "72       tfidf_72  4.139911e-04\n",
       "334     tfidf_334  4.134345e-04\n",
       "351     tfidf_351  4.102120e-04\n",
       "140     tfidf_140  4.089015e-04\n",
       "25       tfidf_25  4.083638e-04\n",
       "358     tfidf_358  4.082123e-04\n",
       "3         tfidf_3  4.080081e-04\n",
       "440      lavender  4.051701e-04\n",
       "59       tfidf_59  4.042766e-04\n",
       "169     tfidf_169  3.997844e-04\n",
       "165     tfidf_165  3.984783e-04\n",
       "44       tfidf_44  3.965230e-04\n",
       "462           tea  3.910220e-04\n",
       "300     tfidf_300  3.879122e-04\n",
       "87       tfidf_87  3.850605e-04\n",
       "306     tfidf_306  3.731452e-04\n",
       "118     tfidf_118  3.716694e-04\n",
       "150     tfidf_150  3.617955e-04\n",
       "368     tfidf_368  3.613440e-04\n",
       "38       tfidf_38  3.558555e-04\n",
       "296     tfidf_296  3.503595e-04\n",
       "328     tfidf_328  3.421472e-04\n",
       "60       tfidf_60  3.388047e-04\n",
       "456          sage  3.325193e-04\n",
       "379     tfidf_379  3.310431e-04\n",
       "330     tfidf_330  3.290300e-04\n",
       "352     tfidf_352  3.277432e-04\n",
       "427        butter  3.197104e-04\n",
       "201     tfidf_201  3.165191e-04\n",
       "383     tfidf_383  3.147965e-04\n",
       "212     tfidf_212  3.141445e-04\n",
       "174     tfidf_174  3.120144e-04\n",
       "213     tfidf_213  3.104044e-04\n",
       "461           tar  3.077542e-04\n",
       "192     tfidf_192  3.062697e-04\n",
       "365     tfidf_365  3.047672e-04\n",
       "331     tfidf_331  3.031317e-04\n",
       "315     tfidf_315  3.016935e-04\n",
       "42       tfidf_42  2.947676e-04\n",
       "114     tfidf_114  2.902804e-04\n",
       "177     tfidf_177  2.791501e-04\n",
       "191     tfidf_191  2.733516e-04\n",
       "36       tfidf_36  2.712538e-04\n",
       "131     tfidf_131  2.689384e-04\n",
       "8         tfidf_8  2.482872e-04\n",
       "378     tfidf_378  2.453470e-04\n",
       "47       tfidf_47  2.377061e-04\n",
       "89       tfidf_89  2.371382e-04\n",
       "143     tfidf_143  2.348801e-04\n",
       "242     tfidf_242  2.299404e-04\n",
       "322     tfidf_322  2.179724e-04\n",
       "74       tfidf_74  2.162910e-04\n",
       "252     tfidf_252  2.162541e-04\n",
       "197     tfidf_197  2.007052e-04\n",
       "463       tobacco  1.981464e-04\n",
       "204     tfidf_204  1.906983e-04\n",
       "95       tfidf_95  1.752997e-04\n",
       "453          plum  1.640457e-04\n",
       "250     tfidf_250  1.600262e-04\n",
       "241     tfidf_241  1.570295e-04\n",
       "449          pear  1.475459e-04\n",
       "467        violet  1.396575e-04\n",
       "425   blue cheese  1.360597e-04\n",
       "266     tfidf_266  1.260185e-04\n",
       "302     tfidf_302  1.234242e-04\n",
       "444       menthol  1.011927e-04\n",
       "422         apple  9.589234e-05\n",
       "430      chestnut  5.960513e-05\n",
       "391       anxiety  3.942447e-05\n",
       "448         peach  3.145905e-05\n",
       "396    depression  3.118104e-05\n",
       "410     migraines  2.091404e-05\n",
       "404       fatigue  7.477164e-07\n",
       "394     arthritis  2.378775e-07\n",
       "403  eye pressure  1.598560e-08\n",
       "411          pain  4.218864e-09\n",
       "414      seizures  0.000000e+00\n",
       "416    spasticity  0.000000e+00\n",
       "401      epilepsy  0.000000e+00\n",
       "417        stress  0.000000e+00"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.set_option('display.max_rows', df_feat_ranked.shape[0]+1)\n",
    "df_feat_ranked"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/andalanputra/opt/anaconda3/lib/python3.9/site-packages/sklearn/feature_selection/_from_model.py:357: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  self.estimator_.fit(X, y, **fit_params)\n"
     ]
    }
   ],
   "source": [
    "selector = SelectFromModel(rfreg).fit(X_train1, y_train1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([9.47708676e-04, 8.79250098e-04, 4.93398909e-04, 4.52654963e-04,\n",
       "       1.70362077e-03, 2.58859684e-03, 1.39750032e-03, 5.16166319e-03,\n",
       "       2.40364649e-04, 6.97370245e-03, 7.85130061e-04, 4.65415368e-03,\n",
       "       5.89195581e-04, 1.44322328e-03, 2.62240809e-03, 2.09923060e-03,\n",
       "       2.27456106e-03, 1.26980130e-03, 5.35011850e-04, 8.98750080e-03,\n",
       "       2.33496265e-03, 5.12155573e-03, 1.11213974e-03, 6.15247331e-04,\n",
       "       6.74689811e-03, 4.05770799e-04, 1.52279864e-03, 1.06246207e-03,\n",
       "       1.39537436e-03, 4.04862262e-04, 3.63041483e-03, 6.91469766e-04,\n",
       "       4.43408892e-03, 7.46579183e-04, 1.49100749e-03, 9.41025238e-04,\n",
       "       2.38536385e-04, 7.81401109e-03, 4.60543379e-04, 6.73335860e-03,\n",
       "       7.95325800e-04, 1.22014297e-03, 3.04324928e-04, 6.80706394e-03,\n",
       "       3.95289675e-04, 1.12512776e-03, 1.88603650e-03, 2.15491721e-04,\n",
       "       3.16001952e-03, 5.61213424e-04, 1.70654531e-03, 5.40527093e-04,\n",
       "       9.05088984e-04, 4.50402397e-04, 1.58788305e-03, 4.80662259e-04,\n",
       "       9.47472996e-04, 1.70253910e-03, 1.94186888e-03, 4.61454146e-04,\n",
       "       3.92955477e-04, 1.97832860e-03, 6.40529643e-04, 8.06580452e-04,\n",
       "       9.65325032e-04, 2.07371970e-03, 3.07086259e-04, 2.93875141e-03,\n",
       "       9.29334134e-04, 9.03351506e-04, 9.18446276e-04, 6.39772128e-04,\n",
       "       3.40126270e-04, 6.33646658e-03, 1.48035738e-04, 9.86280283e-04,\n",
       "       1.08788800e-03, 7.94184100e-04, 4.91108164e-03, 1.45651639e-03,\n",
       "       2.28164491e-03, 1.36784680e-03, 6.74449678e-04, 5.33407920e-04,\n",
       "       5.88969721e-04, 7.72523967e-04, 7.68312812e-04, 4.15933923e-04,\n",
       "       7.31764490e-04, 2.12897184e-04, 3.96123944e-03, 1.81208435e-03,\n",
       "       5.17653283e-04, 7.74821300e-03, 1.45274184e-03, 1.88312785e-04,\n",
       "       1.06091798e-03, 6.70793366e-04, 2.25764711e-03, 1.32759357e-03,\n",
       "       6.10784268e-04, 1.34442524e-03, 9.79540234e-04, 1.36746838e-03,\n",
       "       2.44568005e-03, 8.59828144e-04, 6.24174956e-04, 1.12151198e-03,\n",
       "       4.65553392e-03, 7.45106525e-04, 3.52299089e-03, 1.99515424e-03,\n",
       "       9.04889412e-04, 1.72803945e-03, 2.77875212e-04, 1.74738126e-03,\n",
       "       1.19735734e-03, 3.08183098e-03, 3.98147652e-04, 3.47006386e-03,\n",
       "       1.41389356e-03, 1.43151871e-02, 6.81475401e-04, 1.43147322e-03,\n",
       "       1.69293289e-03, 7.16572244e-04, 1.94769826e-03, 4.63580865e-04,\n",
       "       3.12395506e-03, 1.66375569e-03, 1.16917600e-03, 2.18577252e-04,\n",
       "       7.22466121e-04, 8.53767923e-04, 1.01682965e-03, 8.06764882e-04,\n",
       "       8.52790823e-04, 7.23153514e-04, 5.99345263e-04, 1.37556713e-03,\n",
       "       4.81882936e-04, 8.93885736e-03, 4.99126168e-04, 3.05607025e-04,\n",
       "       3.99850869e-03, 1.24816852e-02, 9.33973541e-04, 5.34821284e-04,\n",
       "       9.46283980e-04, 1.29068292e-02, 3.68834654e-04, 4.73773089e-03,\n",
       "       1.56530799e-03, 1.27079740e-03, 2.42296381e-03, 4.33092776e-04,\n",
       "       3.94371996e-04, 6.56558217e-04, 4.45668039e-03, 2.11079414e-03,\n",
       "       5.49674550e-04, 1.85688316e-03, 7.78716899e-03, 9.64075182e-04,\n",
       "       4.36559928e-03, 4.41575972e-04, 2.29253434e-03, 3.85125964e-03,\n",
       "       1.52986234e-02, 3.23559507e-04, 8.27112832e-04, 7.63029981e-04,\n",
       "       4.86000641e-04, 3.47431447e-03, 3.11220314e-04, 1.31650520e-03,\n",
       "       2.60590947e-03, 3.29009856e-04, 5.70769459e-03, 7.89373071e-04,\n",
       "       2.20591850e-03, 3.20915068e-03, 1.26187953e-03, 6.95296748e-04,\n",
       "       1.33875825e-03, 1.06546000e-03, 7.25773132e-04, 3.99724976e-04,\n",
       "       7.34807917e-04, 1.15786759e-03, 1.46950184e-03, 2.72355692e-04,\n",
       "       3.22687489e-04, 1.41273202e-03, 5.66392368e-04, 1.56857240e-03,\n",
       "       1.11994448e-03, 2.34640863e-04, 1.33805703e-03, 8.14933093e-03,\n",
       "       2.57853585e-03, 3.02208767e-04, 7.90327199e-04, 1.40151095e-03,\n",
       "       1.65964847e-04, 2.01296480e-03, 1.56320276e-03, 5.41015915e-03,\n",
       "       1.35898262e-03, 5.67032437e-04, 5.37670115e-03, 6.65746341e-04,\n",
       "       2.84090166e-04, 3.10393870e-04, 7.57912686e-04, 9.80082474e-04,\n",
       "       6.44840727e-04, 2.59088888e-03, 8.54506837e-04, 6.10554553e-04,\n",
       "       6.64972934e-04, 1.58378663e-03, 9.13353239e-04, 7.74862634e-04,\n",
       "       5.17730995e-04, 6.24221325e-04, 5.57317146e-04, 1.44948059e-03,\n",
       "       2.19223827e-03, 3.72171669e-03, 2.22177472e-03, 2.07531177e-03,\n",
       "       7.55052290e-04, 5.78166436e-04, 1.00152452e-03, 5.85849341e-04,\n",
       "       9.67238472e-04, 1.49851445e-03, 1.50516230e-03, 1.00105441e-02,\n",
       "       1.89461693e-03, 1.53056804e-04, 2.35004654e-04, 9.10968510e-04,\n",
       "       7.85924728e-04, 6.22973286e-03, 2.19901639e-03, 8.88239385e-04,\n",
       "       4.77923514e-04, 5.22229881e-04, 1.18720403e-04, 3.56441734e-03,\n",
       "       2.39977338e-04, 1.26393073e-02, 8.03879413e-04, 5.80117428e-04,\n",
       "       3.23305791e-04, 9.08865385e-04, 3.16934834e-03, 1.45503554e-03,\n",
       "       1.56255896e-03, 1.62959598e-03, 1.32997241e-03, 6.59614545e-04,\n",
       "       2.27390835e-03, 1.48917717e-03, 1.51455131e-04, 5.04719442e-03,\n",
       "       1.13586412e-03, 4.03455538e-04, 2.71431872e-03, 8.82935425e-04,\n",
       "       1.63743387e-03, 1.28710969e-03, 4.57460120e-04, 6.59077747e-04,\n",
       "       7.22250006e-04, 7.91279072e-04, 2.09727091e-03, 9.16933211e-04,\n",
       "       1.07612777e-03, 5.81652295e-03, 7.44756439e-04, 4.58529475e-03,\n",
       "       9.16895383e-04, 1.66633920e-02, 1.59607992e-03, 1.32967064e-03,\n",
       "       9.99398859e-04, 1.90470382e-03, 3.51298707e-04, 2.57089825e-03,\n",
       "       2.43136359e-03, 4.16959213e-04, 2.40021484e-03, 2.18559964e-03,\n",
       "       3.58020432e-04, 1.07829689e-03, 1.63963773e-03, 5.69679734e-04,\n",
       "       3.50729438e-04, 3.40632658e-04, 1.18753250e-04, 9.63527683e-03,\n",
       "       1.18300180e-03, 4.75583784e-04, 4.66486474e-04, 4.09209872e-04,\n",
       "       4.95698915e-04, 5.49793526e-03, 5.42364663e-04, 1.50787096e-03,\n",
       "       8.65944952e-03, 5.72680582e-04, 8.25506145e-03, 3.83573054e-04,\n",
       "       4.47505322e-04, 7.99016640e-04, 6.50485598e-04, 4.00247188e-03,\n",
       "       8.22079634e-03, 1.29615573e-03, 2.14931238e-04, 6.54321627e-04,\n",
       "       4.29661341e-04, 1.80490264e-03, 7.95978574e-04, 4.71151495e-04,\n",
       "       2.82788677e-04, 2.00580203e-02, 3.34202063e-04, 2.68421603e-04,\n",
       "       1.43992940e-03, 5.21923747e-04, 4.19199734e-04, 5.77924564e-04,\n",
       "       1.85764920e-03, 3.94730035e-03, 1.74954942e-03, 7.06794502e-04,\n",
       "       2.76387005e-03, 5.50125756e-03, 2.89199148e-03, 3.10281956e-03,\n",
       "       1.97021868e-03, 1.29309340e-02, 8.57028926e-04, 2.00845677e-03,\n",
       "       7.22354696e-04, 1.41583711e-03, 5.31923545e-03, 4.03500030e-04,\n",
       "       3.27196924e-04, 2.98325046e-03, 1.75541102e-03, 1.41736078e-03,\n",
       "       4.29990711e-04, 4.43065028e-03, 4.56937156e-04, 5.94577635e-04,\n",
       "       2.95417167e-03, 5.03350288e-04, 3.96423109e-03, 7.73288272e-04,\n",
       "       4.96879228e-03, 2.99477438e-04, 4.04021261e-03, 2.86023974e-03,\n",
       "       3.79012615e-04, 1.52697844e-03, 1.62640227e-03, 2.31467091e-03,\n",
       "       1.32548353e-03, 2.18783929e-03, 2.25301788e-03, 4.37472258e-04,\n",
       "       3.59548231e-03, 3.97904948e-03, 2.63326569e-04, 3.25988562e-04,\n",
       "       2.83216272e-03, 1.31033134e-03, 2.80648026e-03, 3.66050741e-04,\n",
       "       5.54727464e-04, 1.79594223e-03, 8.74072257e-04, 1.22022848e-03,\n",
       "       8.37307728e-03, 1.06038152e-02, 2.81124792e-02, 2.43022894e-05,\n",
       "       6.52357507e-04, 1.83447416e-03, 5.48452111e-09, 3.34624108e-03,\n",
       "       2.46444688e-05, 1.25188210e-03, 2.02078353e-03, 4.07145851e-03,\n",
       "       3.27234554e-03, 2.44054704e-07, 6.95462961e-03, 5.70477360e-09,\n",
       "       1.64802735e-10, 3.02236078e-03, 2.67294637e-03, 5.51327999e-03,\n",
       "       5.70983350e-04, 3.91811205e-03, 3.42950688e-05, 0.00000000e+00,\n",
       "       7.57086657e-04, 6.05387823e-03, 0.00000000e+00, 4.20723146e-03,\n",
       "       0.00000000e+00, 1.10871040e-08, 2.88839756e-03, 2.54117826e-03,\n",
       "       4.74546653e-03, 9.72016615e-04, 8.90134318e-05, 9.74788687e-04,\n",
       "       1.91525227e-03, 1.20701564e-04, 2.75128227e-03, 3.65933551e-04,\n",
       "       8.90489656e-03, 5.14652868e-04, 5.71507448e-05, 3.14244152e-03,\n",
       "       5.75413063e-04, 2.77386340e-02, 6.96925586e-03, 8.31810621e-04,\n",
       "       8.84004971e-04, 4.11473119e-03, 6.63711489e-04, 6.11912907e-04,\n",
       "       4.30957706e-04, 4.91917229e-03, 4.02465381e-04, 7.50547785e-04,\n",
       "       1.52503454e-04, 2.00295115e-03, 5.31182328e-04, 1.89469992e-02,\n",
       "       3.11971358e-05, 1.33447592e-04, 7.64328865e-04, 7.73525690e-03,\n",
       "       5.32304571e-04, 1.61266186e-04, 3.17513281e-03, 1.78169716e-03,\n",
       "       3.34568085e-04, 1.64998124e-03, 7.96481343e-04, 4.56165596e-04,\n",
       "       8.28962348e-03, 3.86671515e-04, 3.08567873e-04, 1.80467988e-04,\n",
       "       4.35226784e-04, 8.59369164e-04, 4.47581444e-03, 1.47448786e-04,\n",
       "       2.08967900e-03])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "selector.estimator_.feature_importances_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0021321961620469083"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "selector.threshold_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "mask = selector.get_support()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([False, False, False, False, False,  True, False,  True, False,\n",
       "        True, False,  True, False, False,  True, False,  True, False,\n",
       "       False,  True,  True,  True, False, False,  True, False, False,\n",
       "       False, False, False,  True, False,  True, False, False, False,\n",
       "       False,  True, False,  True, False, False, False,  True, False,\n",
       "       False, False, False,  True, False, False, False, False, False,\n",
       "       False, False, False, False, False, False, False, False, False,\n",
       "       False, False, False, False,  True, False, False, False, False,\n",
       "       False,  True, False, False, False, False,  True, False,  True,\n",
       "       False, False, False, False, False, False, False, False, False,\n",
       "        True, False, False,  True, False, False, False, False,  True,\n",
       "       False, False, False, False, False,  True, False, False, False,\n",
       "        True, False,  True, False, False, False, False, False, False,\n",
       "        True, False,  True, False,  True, False, False, False, False,\n",
       "       False, False,  True, False, False, False, False, False, False,\n",
       "       False, False, False, False, False, False,  True, False, False,\n",
       "        True,  True, False, False, False,  True, False,  True, False,\n",
       "       False,  True, False, False, False,  True, False, False, False,\n",
       "        True, False,  True, False,  True,  True,  True, False, False,\n",
       "       False, False,  True, False, False,  True, False,  True, False,\n",
       "        True,  True, False, False, False, False, False, False, False,\n",
       "       False, False, False, False, False, False, False, False, False,\n",
       "       False,  True,  True, False, False, False, False, False, False,\n",
       "        True, False, False,  True, False, False, False, False, False,\n",
       "       False,  True, False, False, False, False, False, False, False,\n",
       "       False, False, False,  True,  True,  True, False, False, False,\n",
       "       False, False, False, False, False,  True, False, False, False,\n",
       "       False, False,  True,  True, False, False, False, False,  True,\n",
       "       False,  True, False, False, False, False,  True, False, False,\n",
       "       False, False, False,  True, False, False,  True, False, False,\n",
       "        True, False, False, False, False, False, False, False, False,\n",
       "       False, False,  True, False,  True, False,  True, False, False,\n",
       "       False, False, False,  True,  True, False,  True,  True, False,\n",
       "       False, False, False, False, False, False,  True, False, False,\n",
       "       False, False, False,  True, False, False,  True, False,  True,\n",
       "       False, False, False, False,  True,  True, False, False, False,\n",
       "       False, False, False, False, False,  True, False, False, False,\n",
       "       False, False, False, False,  True, False, False,  True,  True,\n",
       "        True,  True, False,  True, False, False, False, False,  True,\n",
       "       False, False,  True, False, False, False,  True, False, False,\n",
       "        True, False,  True, False,  True, False,  True,  True, False,\n",
       "       False, False,  True, False,  True,  True, False,  True,  True,\n",
       "       False, False,  True, False,  True, False, False, False, False,\n",
       "       False,  True,  True,  True, False, False, False, False,  True,\n",
       "       False, False, False,  True,  True, False,  True, False, False,\n",
       "        True,  True,  True, False,  True, False, False, False,  True,\n",
       "       False,  True, False, False,  True,  True,  True, False, False,\n",
       "       False, False, False,  True, False,  True, False, False,  True,\n",
       "       False,  True,  True, False, False,  True, False, False, False,\n",
       "        True, False, False, False, False, False,  True, False, False,\n",
       "       False,  True, False, False,  True, False, False, False, False,\n",
       "       False,  True, False, False, False, False, False,  True, False,\n",
       "       False])"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "selected_features = X.columns[mask]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tfidf_5</th>\n",
       "      <th>tfidf_7</th>\n",
       "      <th>tfidf_9</th>\n",
       "      <th>tfidf_11</th>\n",
       "      <th>tfidf_14</th>\n",
       "      <th>tfidf_16</th>\n",
       "      <th>tfidf_19</th>\n",
       "      <th>tfidf_20</th>\n",
       "      <th>tfidf_21</th>\n",
       "      <th>tfidf_24</th>\n",
       "      <th>...</th>\n",
       "      <th>citrus</th>\n",
       "      <th>diesel</th>\n",
       "      <th>earthy</th>\n",
       "      <th>grape</th>\n",
       "      <th>lemon</th>\n",
       "      <th>orange</th>\n",
       "      <th>pine</th>\n",
       "      <th>pungent</th>\n",
       "      <th>sweet</th>\n",
       "      <th>vanilla</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.396758</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.145484</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.145484</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>74995</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>74996</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>74997</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>74998</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>74999</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>75000 rows × 127 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        tfidf_5  tfidf_7  tfidf_9  tfidf_11  tfidf_14  tfidf_16  tfidf_19  \\\n",
       "0      0.000000      0.0      0.0       0.0       0.0       0.0       0.0   \n",
       "1      0.000000      0.0      0.0       0.0       0.0       0.0       0.0   \n",
       "2      0.000000      0.0      0.0       0.0       0.0       0.0       0.0   \n",
       "3      0.145484      0.0      0.0       0.0       0.0       0.0       0.0   \n",
       "4      0.145484      0.0      0.0       0.0       0.0       0.0       0.0   \n",
       "...         ...      ...      ...       ...       ...       ...       ...   \n",
       "74995  0.000000      0.0      0.0       0.0       0.0       0.0       0.0   \n",
       "74996  0.000000      0.0      0.0       0.0       0.0       0.0       0.0   \n",
       "74997  0.000000      0.0      0.0       0.0       0.0       0.0       0.0   \n",
       "74998  0.000000      0.0      0.0       0.0       0.0       0.0       0.0   \n",
       "74999  0.000000      0.0      0.0       0.0       0.0       0.0       0.0   \n",
       "\n",
       "       tfidf_20  tfidf_21  tfidf_24  ...  citrus  diesel  earthy  grape  \\\n",
       "0           0.0       0.0  0.000000  ...       0       0       0      0   \n",
       "1           0.0       0.0  0.396758  ...       0       0       0      0   \n",
       "2           0.0       0.0  0.000000  ...       0       0       0      0   \n",
       "3           0.0       0.0  0.000000  ...       0       0       0      1   \n",
       "4           0.0       0.0  0.000000  ...       0       0       0      1   \n",
       "...         ...       ...       ...  ...     ...     ...     ...    ...   \n",
       "74995       0.0       0.0  0.000000  ...       0       0       0      0   \n",
       "74996       0.0       0.0  0.000000  ...       0       0       0      0   \n",
       "74997       0.0       0.0  0.000000  ...       0       0       0      0   \n",
       "74998       0.0       0.0  0.000000  ...       0       0       0      0   \n",
       "74999       0.0       0.0  0.000000  ...       1       1       1      1   \n",
       "\n",
       "       lemon  orange  pine  pungent  sweet  vanilla  \n",
       "0          0       0     0        0      0        0  \n",
       "1          0       0     0        0      0        1  \n",
       "2          0       0     0        0      1        1  \n",
       "3          0       0     1        0      0        0  \n",
       "4          0       0     1        0      0        0  \n",
       "...      ...     ...   ...      ...    ...      ...  \n",
       "74995      0       0     0        0      0        0  \n",
       "74996      0       0     0        0      0        0  \n",
       "74997      0       0     0        0      0        0  \n",
       "74998      0       0     0        0      0        0  \n",
       "74999      1       1     1        1      1        1  \n",
       "\n",
       "[75000 rows x 127 columns]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "selected_X = df_rf[selected_features]\n",
    "selected_X"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train test split (after Feature Selection)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['selected_X_rf_tfidf_thc.pkl']"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import joblib\n",
    "\n",
    "joblib.dump(selector, \"selector_rf_tfidf_thc.pkl\")\n",
    "joblib.dump(selected_X, \"selected_X_rf_tfidf_thc.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(selected_X, y, random_state=1, test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train1, X_val, y_train1, y_val = train_test_split(X_train, y_train, random_state=1, test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/y1/pjvjlkjn5gl846rnyzr53p340000gn/T/ipykernel_7013/3758305.py:1: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  rfreg.fit(X_train1, y_train1)\n"
     ]
    }
   ],
   "source": [
    "rfreg.fit(X_train1, y_train1)\n",
    "y_pred_rfreg = rfreg.predict(X_val)\n",
    "y_pred_rfreg_r2 = rfreg.predict(X_train1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.05737045585210325"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mean_absolute_error(y_val, y_pred_rfreg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.012067161159699248"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mean_squared_error(y_val, y_pred_rfreg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.10985063113018172"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mean_squared_error(y_val, y_pred_rfreg, squared = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9594636265502688"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#train\n",
    "r2_score(y_train1, y_pred_rfreg_r2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8530773729156935"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#val\n",
    "r2_score(y_val, y_pred_rfreg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hyperparameter Tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "parameters = {'max_depth': [None, 10, 50, 100],\n",
    "              'max_features': ['auto', 'sqrt'],\n",
    "              'min_samples_leaf': [1, 2, 4],\n",
    "              'min_samples_split': [2, 5, 10],\n",
    "              'n_estimators': [100, 300, 500]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "rscv = RandomizedSearchCV(rfreg,  \n",
    "                     parameters,   \n",
    "                     cv=5, \n",
    "                     scoring='neg_mean_absolute_error',\n",
    "                     n_jobs = -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/andalanputra/opt/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/Users/andalanputra/opt/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/Users/andalanputra/opt/anaconda3/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
      "  warn(\n",
      "/Users/andalanputra/opt/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/Users/andalanputra/opt/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/Users/andalanputra/opt/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/Users/andalanputra/opt/anaconda3/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
      "  warn(\n",
      "/Users/andalanputra/opt/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/Users/andalanputra/opt/anaconda3/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
      "  warn(\n",
      "/Users/andalanputra/opt/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/Users/andalanputra/opt/anaconda3/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
      "  warn(\n",
      "/Users/andalanputra/opt/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/Users/andalanputra/opt/anaconda3/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
      "  warn(\n",
      "/Users/andalanputra/opt/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/Users/andalanputra/opt/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/Users/andalanputra/opt/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/Users/andalanputra/opt/anaconda3/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
      "  warn(\n",
      "/Users/andalanputra/opt/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/Users/andalanputra/opt/anaconda3/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
      "  warn(\n",
      "/Users/andalanputra/opt/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/Users/andalanputra/opt/anaconda3/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
      "  warn(\n",
      "/Users/andalanputra/opt/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/Users/andalanputra/opt/anaconda3/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
      "  warn(\n",
      "/Users/andalanputra/opt/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/Users/andalanputra/opt/anaconda3/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
      "  warn(\n",
      "/Users/andalanputra/opt/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/Users/andalanputra/opt/anaconda3/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
      "  warn(\n",
      "/Users/andalanputra/opt/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/Users/andalanputra/opt/anaconda3/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
      "  warn(\n",
      "/Users/andalanputra/opt/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/Users/andalanputra/opt/anaconda3/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
      "  warn(\n",
      "/Users/andalanputra/opt/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/Users/andalanputra/opt/anaconda3/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
      "  warn(\n",
      "/Users/andalanputra/opt/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/Users/andalanputra/opt/anaconda3/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
      "  warn(\n",
      "/Users/andalanputra/opt/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/Users/andalanputra/opt/anaconda3/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
      "  warn(\n",
      "/Users/andalanputra/opt/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/Users/andalanputra/opt/anaconda3/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
      "  warn(\n",
      "/Users/andalanputra/opt/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/Users/andalanputra/opt/anaconda3/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
      "  warn(\n",
      "/Users/andalanputra/opt/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/Users/andalanputra/opt/anaconda3/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
      "  warn(\n",
      "/Users/andalanputra/opt/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/Users/andalanputra/opt/anaconda3/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
      "  warn(\n",
      "/Users/andalanputra/opt/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/Users/andalanputra/opt/anaconda3/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
      "  warn(\n",
      "/Users/andalanputra/opt/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/Users/andalanputra/opt/anaconda3/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
      "  warn(\n",
      "/Users/andalanputra/opt/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/Users/andalanputra/opt/anaconda3/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
      "  warn(\n",
      "/Users/andalanputra/opt/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/Users/andalanputra/opt/anaconda3/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
      "  warn(\n",
      "/Users/andalanputra/opt/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/Users/andalanputra/opt/anaconda3/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
      "  warn(\n",
      "/Users/andalanputra/opt/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/Users/andalanputra/opt/anaconda3/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
      "  warn(\n",
      "/Users/andalanputra/opt/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/Users/andalanputra/opt/anaconda3/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
      "  warn(\n",
      "/Users/andalanputra/opt/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/Users/andalanputra/opt/anaconda3/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
      "  warn(\n",
      "/Users/andalanputra/opt/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/Users/andalanputra/opt/anaconda3/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
      "  warn(\n",
      "/Users/andalanputra/opt/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/Users/andalanputra/opt/anaconda3/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
      "  warn(\n",
      "/Users/andalanputra/opt/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/Users/andalanputra/opt/anaconda3/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
      "  warn(\n",
      "/Users/andalanputra/opt/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/Users/andalanputra/opt/anaconda3/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
      "  warn(\n",
      "/Users/andalanputra/opt/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/Users/andalanputra/opt/anaconda3/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
      "  warn(\n",
      "/Users/andalanputra/opt/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/Users/andalanputra/opt/anaconda3/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
      "  warn(\n",
      "/Users/andalanputra/opt/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/Users/andalanputra/opt/anaconda3/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
      "  warn(\n",
      "/Users/andalanputra/opt/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/Users/andalanputra/opt/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/Users/andalanputra/opt/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/Users/andalanputra/opt/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/Users/andalanputra/opt/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/Users/andalanputra/opt/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/Users/andalanputra/opt/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/Users/andalanputra/opt/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/Users/andalanputra/opt/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/Users/andalanputra/opt/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/Users/andalanputra/opt/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_search.py:909: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  self.best_estimator_.fit(X, y, **fit_params)\n",
      "/Users/andalanputra/opt/anaconda3/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
      "  warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-2 {color: black;background-color: white;}#sk-container-id-2 pre{padding: 0;}#sk-container-id-2 div.sk-toggleable {background-color: white;}#sk-container-id-2 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-2 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-2 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-2 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-2 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-2 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-2 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-2 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-2 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-2 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-2 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-2 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-2 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-2 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-2 div.sk-item {position: relative;z-index: 1;}#sk-container-id-2 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-2 div.sk-item::before, #sk-container-id-2 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-2 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-2 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-2 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-2 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-2 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-2 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-2 div.sk-label-container {text-align: center;}#sk-container-id-2 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-2 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-2\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>RandomizedSearchCV(cv=5, estimator=RandomForestRegressor(), n_jobs=-1,\n",
       "                   param_distributions={&#x27;max_depth&#x27;: [None, 10, 50, 100],\n",
       "                                        &#x27;max_features&#x27;: [&#x27;auto&#x27;, &#x27;sqrt&#x27;],\n",
       "                                        &#x27;min_samples_leaf&#x27;: [1, 2, 4],\n",
       "                                        &#x27;min_samples_split&#x27;: [2, 5, 10],\n",
       "                                        &#x27;n_estimators&#x27;: [100, 300, 500]},\n",
       "                   scoring=&#x27;neg_mean_absolute_error&#x27;)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" ><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">RandomizedSearchCV</label><div class=\"sk-toggleable__content\"><pre>RandomizedSearchCV(cv=5, estimator=RandomForestRegressor(), n_jobs=-1,\n",
       "                   param_distributions={&#x27;max_depth&#x27;: [None, 10, 50, 100],\n",
       "                                        &#x27;max_features&#x27;: [&#x27;auto&#x27;, &#x27;sqrt&#x27;],\n",
       "                                        &#x27;min_samples_leaf&#x27;: [1, 2, 4],\n",
       "                                        &#x27;min_samples_split&#x27;: [2, 5, 10],\n",
       "                                        &#x27;n_estimators&#x27;: [100, 300, 500]},\n",
       "                   scoring=&#x27;neg_mean_absolute_error&#x27;)</pre></div></div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-3\" type=\"checkbox\" ><label for=\"sk-estimator-id-3\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">estimator: RandomForestRegressor</label><div class=\"sk-toggleable__content\"><pre>RandomForestRegressor()</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-4\" type=\"checkbox\" ><label for=\"sk-estimator-id-4\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">RandomForestRegressor</label><div class=\"sk-toggleable__content\"><pre>RandomForestRegressor()</pre></div></div></div></div></div></div></div></div></div></div>"
      ],
      "text/plain": [
       "RandomizedSearchCV(cv=5, estimator=RandomForestRegressor(), n_jobs=-1,\n",
       "                   param_distributions={'max_depth': [None, 10, 50, 100],\n",
       "                                        'max_features': ['auto', 'sqrt'],\n",
       "                                        'min_samples_leaf': [1, 2, 4],\n",
       "                                        'min_samples_split': [2, 5, 10],\n",
       "                                        'n_estimators': [100, 300, 500]},\n",
       "                   scoring='neg_mean_absolute_error')"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rscv.fit(X_train1, y_train1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'n_estimators': 100,\n",
       " 'min_samples_split': 2,\n",
       " 'min_samples_leaf': 2,\n",
       " 'max_features': 'auto',\n",
       " 'max_depth': 100}"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rscv.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['rscv_rf_tfidf_best_params_thc.pkl']"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "joblib.dump(rscv, \"rscv_rf_tfidf_thc.pkl\")\n",
    "joblib.dump(rscv.best_params_, \"rscv_rf_tfidf_best_params_thc.pkl\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "RF (after Hyperparameter Tuning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/y1/pjvjlkjn5gl846rnyzr53p340000gn/T/ipykernel_7013/197028604.py:2: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  rfreg_ht.fit(X_train1, y_train1)\n",
      "/Users/andalanputra/opt/anaconda3/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
      "  warn(\n"
     ]
    }
   ],
   "source": [
    "rfreg_ht = RandomForestRegressor(n_estimators = 100, min_samples_split = 2, min_samples_leaf = 2, max_features = 'auto', max_depth = 100)\n",
    "rfreg_ht.fit(X_train1, y_train1)\n",
    "y_pred_rfreg = rfreg_ht.predict(X_val)\n",
    "y_pred_rfreg_r2 = rfreg_ht.predict(X_train1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.06781239657563443"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mean_absolute_error(y_val, y_pred_rfreg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.013793842958941612"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mean_squared_error(y_val, y_pred_rfreg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.11744719221395467"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mean_squared_error(y_val, y_pred_rfreg, squared = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.939190830585193"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#train\n",
    "r2_score(y_train1, y_pred_rfreg_r2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8320543151537245"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#val\n",
    "r2_score(y_val, y_pred_rfreg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Residual plots after Hyperparameter Tuning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Predicting model on the test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_rfreg_test = rfreg_ht.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['y_test_rfreg_tfidf_thc.pkl']"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "joblib.dump(y_pred_rfreg_test, \"y_pred_rfreg_test_tfidf_thc.pkl\")\n",
    "joblib.dump(y_test, \"y_test_rfreg_tfidf_thc.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.06634701738733041"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mean_absolute_error(y_test, y_pred_rfreg_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.013429966928470111"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mean_squared_error(y_test, y_pred_rfreg_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.1158877341588406"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mean_squared_error(y_test, y_pred_rfreg_test, squared = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.836797429378702"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "r2_score(y_test, y_pred_rfreg_test)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Error analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 576x432 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 432x288 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# assume y_pred is a numpy array and y_true is a pandas dataframe\n",
    "fig, ax = plt.subplots(figsize=(8, 6))\n",
    "\n",
    "column = \"X..Delta9-THC\"  # specify the target variable name\n",
    "ax.hist(y_pred_rfreg_test, alpha=0.5, label='y_pred', bins=20)\n",
    "ax.hist(y_test[column], alpha=0.5, label='y_true', bins=20)\n",
    "ax.legend(loc='upper right')\n",
    "ax.set_title(column)\n",
    "\n",
    "plt.show()\n",
    "plt.savefig('error_hist_knn_tfidf_thc.png')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pearson R"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pearson correlation coefficient: 0.918\n",
      "P-value: 0.000\n"
     ]
    }
   ],
   "source": [
    "corr_coef, p_value = pearsonr(y_pred_rfreg_test.flatten(), y_test.values.ravel())\n",
    "\n",
    "print(f\"Pearson correlation coefficient: {corr_coef:.3f}\")\n",
    "print(f\"P-value: {p_value:.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:>"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "corr_matrix = y_test.corr()\n",
    "sns.heatmap(corr_matrix, annot=True, cmap='coolwarm', center=0)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
