{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn import preprocessing\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.neural_network import MLPRegressor\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "from sklearn.metrics import r2_score\n",
    "from scipy.stats import pearsonr\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.feature_selection import SelectFromModel\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compiling complete dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_rf = pd.read_csv(\"df_bocim_tfidf.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['index',\n",
       " 'tfidf_0',\n",
       " 'tfidf_1',\n",
       " 'tfidf_2',\n",
       " 'tfidf_3',\n",
       " 'tfidf_4',\n",
       " 'tfidf_5',\n",
       " 'tfidf_6',\n",
       " 'tfidf_7',\n",
       " 'tfidf_8',\n",
       " 'tfidf_9',\n",
       " 'tfidf_10',\n",
       " 'tfidf_11',\n",
       " 'tfidf_12',\n",
       " 'tfidf_13',\n",
       " 'tfidf_14',\n",
       " 'tfidf_15',\n",
       " 'tfidf_16',\n",
       " 'tfidf_17',\n",
       " 'tfidf_18',\n",
       " 'tfidf_19',\n",
       " 'tfidf_20',\n",
       " 'tfidf_21',\n",
       " 'tfidf_22',\n",
       " 'tfidf_23',\n",
       " 'tfidf_24',\n",
       " 'tfidf_25',\n",
       " 'tfidf_26',\n",
       " 'tfidf_27',\n",
       " 'tfidf_28',\n",
       " 'tfidf_29',\n",
       " 'tfidf_30',\n",
       " 'tfidf_31',\n",
       " 'tfidf_32',\n",
       " 'tfidf_33',\n",
       " 'tfidf_34',\n",
       " 'tfidf_35',\n",
       " 'tfidf_36',\n",
       " 'tfidf_37',\n",
       " 'tfidf_38',\n",
       " 'tfidf_39',\n",
       " 'tfidf_40',\n",
       " 'tfidf_41',\n",
       " 'tfidf_42',\n",
       " 'tfidf_43',\n",
       " 'tfidf_44',\n",
       " 'tfidf_45',\n",
       " 'tfidf_46',\n",
       " 'tfidf_47',\n",
       " 'tfidf_48',\n",
       " 'tfidf_49',\n",
       " 'tfidf_50',\n",
       " 'tfidf_51',\n",
       " 'tfidf_52',\n",
       " 'tfidf_53',\n",
       " 'tfidf_54',\n",
       " 'tfidf_55',\n",
       " 'tfidf_56',\n",
       " 'tfidf_57',\n",
       " 'tfidf_58',\n",
       " 'tfidf_59',\n",
       " 'tfidf_60',\n",
       " 'tfidf_61',\n",
       " 'tfidf_62',\n",
       " 'tfidf_63',\n",
       " 'tfidf_64',\n",
       " 'tfidf_65',\n",
       " 'tfidf_66',\n",
       " 'tfidf_67',\n",
       " 'tfidf_68',\n",
       " 'tfidf_69',\n",
       " 'tfidf_70',\n",
       " 'tfidf_71',\n",
       " 'tfidf_72',\n",
       " 'tfidf_73',\n",
       " 'tfidf_74',\n",
       " 'tfidf_75',\n",
       " 'tfidf_76',\n",
       " 'tfidf_77',\n",
       " 'tfidf_78',\n",
       " 'tfidf_79',\n",
       " 'tfidf_80',\n",
       " 'tfidf_81',\n",
       " 'tfidf_82',\n",
       " 'tfidf_83',\n",
       " 'tfidf_84',\n",
       " 'tfidf_85',\n",
       " 'tfidf_86',\n",
       " 'tfidf_87',\n",
       " 'tfidf_88',\n",
       " 'tfidf_89',\n",
       " 'tfidf_90',\n",
       " 'tfidf_91',\n",
       " 'tfidf_92',\n",
       " 'tfidf_93',\n",
       " 'tfidf_94',\n",
       " 'tfidf_95',\n",
       " 'tfidf_96',\n",
       " 'tfidf_97',\n",
       " 'tfidf_98',\n",
       " 'tfidf_99',\n",
       " 'tfidf_100',\n",
       " 'tfidf_101',\n",
       " 'tfidf_102',\n",
       " 'tfidf_103',\n",
       " 'tfidf_104',\n",
       " 'tfidf_105',\n",
       " 'tfidf_106',\n",
       " 'tfidf_107',\n",
       " 'tfidf_108',\n",
       " 'tfidf_109',\n",
       " 'tfidf_110',\n",
       " 'tfidf_111',\n",
       " 'tfidf_112',\n",
       " 'tfidf_113',\n",
       " 'tfidf_114',\n",
       " 'tfidf_115',\n",
       " 'tfidf_116',\n",
       " 'tfidf_117',\n",
       " 'tfidf_118',\n",
       " 'tfidf_119',\n",
       " 'tfidf_120',\n",
       " 'tfidf_121',\n",
       " 'tfidf_122',\n",
       " 'tfidf_123',\n",
       " 'tfidf_124',\n",
       " 'tfidf_125',\n",
       " 'tfidf_126',\n",
       " 'tfidf_127',\n",
       " 'tfidf_128',\n",
       " 'tfidf_129',\n",
       " 'tfidf_130',\n",
       " 'tfidf_131',\n",
       " 'tfidf_132',\n",
       " 'tfidf_133',\n",
       " 'tfidf_134',\n",
       " 'tfidf_135',\n",
       " 'tfidf_136',\n",
       " 'tfidf_137',\n",
       " 'tfidf_138',\n",
       " 'tfidf_139',\n",
       " 'tfidf_140',\n",
       " 'tfidf_141',\n",
       " 'tfidf_142',\n",
       " 'tfidf_143',\n",
       " 'tfidf_144',\n",
       " 'tfidf_145',\n",
       " 'tfidf_146',\n",
       " 'tfidf_147',\n",
       " 'tfidf_148',\n",
       " 'tfidf_149',\n",
       " 'tfidf_150',\n",
       " 'tfidf_151',\n",
       " 'tfidf_152',\n",
       " 'tfidf_153',\n",
       " 'tfidf_154',\n",
       " 'tfidf_155',\n",
       " 'tfidf_156',\n",
       " 'tfidf_157',\n",
       " 'tfidf_158',\n",
       " 'tfidf_159',\n",
       " 'tfidf_160',\n",
       " 'tfidf_161',\n",
       " 'tfidf_162',\n",
       " 'tfidf_163',\n",
       " 'tfidf_164',\n",
       " 'tfidf_165',\n",
       " 'tfidf_166',\n",
       " 'tfidf_167',\n",
       " 'tfidf_168',\n",
       " 'tfidf_169',\n",
       " 'tfidf_170',\n",
       " 'tfidf_171',\n",
       " 'tfidf_172',\n",
       " 'tfidf_173',\n",
       " 'tfidf_174',\n",
       " 'tfidf_175',\n",
       " 'tfidf_176',\n",
       " 'tfidf_177',\n",
       " 'tfidf_178',\n",
       " 'tfidf_179',\n",
       " 'tfidf_180',\n",
       " 'tfidf_181',\n",
       " 'tfidf_182',\n",
       " 'tfidf_183',\n",
       " 'tfidf_184',\n",
       " 'tfidf_185',\n",
       " 'tfidf_186',\n",
       " 'tfidf_187',\n",
       " 'tfidf_188',\n",
       " 'tfidf_189',\n",
       " 'tfidf_190',\n",
       " 'tfidf_191',\n",
       " 'tfidf_192',\n",
       " 'tfidf_193',\n",
       " 'tfidf_194',\n",
       " 'tfidf_195',\n",
       " 'tfidf_196',\n",
       " 'tfidf_197',\n",
       " 'tfidf_198',\n",
       " 'tfidf_199',\n",
       " 'tfidf_200',\n",
       " 'tfidf_201',\n",
       " 'tfidf_202',\n",
       " 'tfidf_203',\n",
       " 'tfidf_204',\n",
       " 'tfidf_205',\n",
       " 'tfidf_206',\n",
       " 'tfidf_207',\n",
       " 'tfidf_208',\n",
       " 'tfidf_209',\n",
       " 'tfidf_210',\n",
       " 'tfidf_211',\n",
       " 'tfidf_212',\n",
       " 'tfidf_213',\n",
       " 'tfidf_214',\n",
       " 'tfidf_215',\n",
       " 'tfidf_216',\n",
       " 'tfidf_217',\n",
       " 'tfidf_218',\n",
       " 'tfidf_219',\n",
       " 'tfidf_220',\n",
       " 'tfidf_221',\n",
       " 'tfidf_222',\n",
       " 'tfidf_223',\n",
       " 'tfidf_224',\n",
       " 'tfidf_225',\n",
       " 'tfidf_226',\n",
       " 'tfidf_227',\n",
       " 'tfidf_228',\n",
       " 'tfidf_229',\n",
       " 'tfidf_230',\n",
       " 'tfidf_231',\n",
       " 'tfidf_232',\n",
       " 'tfidf_233',\n",
       " 'tfidf_234',\n",
       " 'tfidf_235',\n",
       " 'tfidf_236',\n",
       " 'tfidf_237',\n",
       " 'tfidf_238',\n",
       " 'tfidf_239',\n",
       " 'tfidf_240',\n",
       " 'tfidf_241',\n",
       " 'tfidf_242',\n",
       " 'tfidf_243',\n",
       " 'tfidf_244',\n",
       " 'tfidf_245',\n",
       " 'tfidf_246',\n",
       " 'tfidf_247',\n",
       " 'tfidf_248',\n",
       " 'tfidf_249',\n",
       " 'tfidf_250',\n",
       " 'tfidf_251',\n",
       " 'tfidf_252',\n",
       " 'tfidf_253',\n",
       " 'tfidf_254',\n",
       " 'tfidf_255',\n",
       " 'tfidf_256',\n",
       " 'tfidf_257',\n",
       " 'tfidf_258',\n",
       " 'tfidf_259',\n",
       " 'tfidf_260',\n",
       " 'tfidf_261',\n",
       " 'tfidf_262',\n",
       " 'tfidf_263',\n",
       " 'tfidf_264',\n",
       " 'tfidf_265',\n",
       " 'tfidf_266',\n",
       " 'tfidf_267',\n",
       " 'tfidf_268',\n",
       " 'tfidf_269',\n",
       " 'tfidf_270',\n",
       " 'tfidf_271',\n",
       " 'tfidf_272',\n",
       " 'tfidf_273',\n",
       " 'tfidf_274',\n",
       " 'tfidf_275',\n",
       " 'tfidf_276',\n",
       " 'tfidf_277',\n",
       " 'tfidf_278',\n",
       " 'tfidf_279',\n",
       " 'tfidf_280',\n",
       " 'tfidf_281',\n",
       " 'tfidf_282',\n",
       " 'tfidf_283',\n",
       " 'tfidf_284',\n",
       " 'tfidf_285',\n",
       " 'tfidf_286',\n",
       " 'tfidf_287',\n",
       " 'tfidf_288',\n",
       " 'tfidf_289',\n",
       " 'tfidf_290',\n",
       " 'tfidf_291',\n",
       " 'tfidf_292',\n",
       " 'tfidf_293',\n",
       " 'tfidf_294',\n",
       " 'tfidf_295',\n",
       " 'tfidf_296',\n",
       " 'tfidf_297',\n",
       " 'tfidf_298',\n",
       " 'tfidf_299',\n",
       " 'tfidf_300',\n",
       " 'tfidf_301',\n",
       " 'tfidf_302',\n",
       " 'tfidf_303',\n",
       " 'tfidf_304',\n",
       " 'tfidf_305',\n",
       " 'tfidf_306',\n",
       " 'tfidf_307',\n",
       " 'tfidf_308',\n",
       " 'tfidf_309',\n",
       " 'tfidf_310',\n",
       " 'tfidf_311',\n",
       " 'tfidf_312',\n",
       " 'tfidf_313',\n",
       " 'tfidf_314',\n",
       " 'tfidf_315',\n",
       " 'tfidf_316',\n",
       " 'tfidf_317',\n",
       " 'tfidf_318',\n",
       " 'tfidf_319',\n",
       " 'tfidf_320',\n",
       " 'tfidf_321',\n",
       " 'tfidf_322',\n",
       " 'tfidf_323',\n",
       " 'tfidf_324',\n",
       " 'tfidf_325',\n",
       " 'tfidf_326',\n",
       " 'tfidf_327',\n",
       " 'tfidf_328',\n",
       " 'tfidf_329',\n",
       " 'tfidf_330',\n",
       " 'tfidf_331',\n",
       " 'tfidf_332',\n",
       " 'tfidf_333',\n",
       " 'tfidf_334',\n",
       " 'tfidf_335',\n",
       " 'tfidf_336',\n",
       " 'tfidf_337',\n",
       " 'tfidf_338',\n",
       " 'tfidf_339',\n",
       " 'tfidf_340',\n",
       " 'tfidf_341',\n",
       " 'tfidf_342',\n",
       " 'tfidf_343',\n",
       " 'tfidf_344',\n",
       " 'tfidf_345',\n",
       " 'tfidf_346',\n",
       " 'tfidf_347',\n",
       " 'tfidf_348',\n",
       " 'tfidf_349',\n",
       " 'tfidf_350',\n",
       " 'tfidf_351',\n",
       " 'tfidf_352',\n",
       " 'tfidf_353',\n",
       " 'tfidf_354',\n",
       " 'tfidf_355',\n",
       " 'tfidf_356',\n",
       " 'tfidf_357',\n",
       " 'tfidf_358',\n",
       " 'tfidf_359',\n",
       " 'tfidf_360',\n",
       " 'tfidf_361',\n",
       " 'tfidf_362',\n",
       " 'tfidf_363',\n",
       " 'tfidf_364',\n",
       " 'tfidf_365',\n",
       " 'tfidf_366',\n",
       " 'tfidf_367',\n",
       " 'tfidf_368',\n",
       " 'tfidf_369',\n",
       " 'tfidf_370',\n",
       " 'tfidf_371',\n",
       " 'tfidf_372',\n",
       " 'tfidf_373',\n",
       " 'tfidf_374',\n",
       " 'tfidf_375',\n",
       " 'tfidf_376',\n",
       " 'tfidf_377',\n",
       " 'tfidf_378',\n",
       " 'tfidf_379',\n",
       " 'tfidf_380',\n",
       " 'tfidf_381',\n",
       " 'tfidf_382',\n",
       " 'tfidf_383',\n",
       " 'tfidf_384',\n",
       " 'tfidf_385',\n",
       " 'tfidf_386',\n",
       " 'tfidf_387',\n",
       " 'hybrid',\n",
       " 'indica',\n",
       " 'sativa',\n",
       " 'anxiety',\n",
       " 'anxious',\n",
       " 'aroused',\n",
       " 'arthritis',\n",
       " 'creative',\n",
       " 'depression',\n",
       " 'dizzy',\n",
       " 'dry eyes',\n",
       " 'dry mouth',\n",
       " 'energetic',\n",
       " 'epilepsy',\n",
       " 'euphoric',\n",
       " 'eye pressure',\n",
       " 'fatigue',\n",
       " 'focused',\n",
       " 'giggly',\n",
       " 'happy',\n",
       " 'headache',\n",
       " 'hungry',\n",
       " 'migraines',\n",
       " 'pain',\n",
       " 'paranoid',\n",
       " 'relaxed',\n",
       " 'seizures',\n",
       " 'sleepy',\n",
       " 'spasticity',\n",
       " 'stress',\n",
       " 'talkative',\n",
       " 'tingly',\n",
       " 'uplifted',\n",
       " 'ammonia',\n",
       " 'apple',\n",
       " 'apricot',\n",
       " 'berry',\n",
       " 'blue cheese',\n",
       " 'blueberry',\n",
       " 'butter',\n",
       " 'cheese',\n",
       " 'chemical',\n",
       " 'chestnut',\n",
       " 'citrus',\n",
       " 'coffee',\n",
       " 'diesel',\n",
       " 'earthy',\n",
       " 'flowery',\n",
       " 'fruit',\n",
       " 'grape',\n",
       " 'grapefruit',\n",
       " 'honey',\n",
       " 'lavender',\n",
       " 'lemon',\n",
       " 'lime',\n",
       " 'mango',\n",
       " 'menthol',\n",
       " 'mint',\n",
       " 'nutty',\n",
       " 'orange',\n",
       " 'peach',\n",
       " 'pear',\n",
       " 'pepper',\n",
       " 'pine',\n",
       " 'pineapple',\n",
       " 'plum',\n",
       " 'pungent',\n",
       " 'rose',\n",
       " 'sage',\n",
       " 'skunk',\n",
       " 'spicy/herbal',\n",
       " 'strawberry',\n",
       " 'sweet',\n",
       " 'tar',\n",
       " 'tea',\n",
       " 'tobacco',\n",
       " 'tree',\n",
       " 'tropical',\n",
       " 'vanilla',\n",
       " 'violet',\n",
       " 'woody',\n",
       " 'X..Beta-Ocimene']"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_rf.columns.to_list()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Splitting dependent and independent variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df_rf.drop(['index', 'X..Beta-Ocimene'], axis = 1)\n",
    "y = df_rf[['X..Beta-Ocimene']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plotting histograms on target variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.66666667],\n",
       "       [0.66666667],\n",
       "       [0.66666667],\n",
       "       ...,\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ]])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_array = y.to_numpy()\n",
    "y_array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Axes: ylabel='Count'>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAk0AAAGdCAYAAAAPLEfqAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjcuMCwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy88F64QAAAACXBIWXMAAA9hAAAPYQGoP6dpAAA9RklEQVR4nO3de1RVdf7/8deRm8LIUSRuCWgNEoqZ4qjoNGkZSirfskYdjdHGsL5NmildzCmpyZwyy9JqzDGtoMGZKZtWOgRaauYtMSYvZGYUUiCiXEQRCPfvj77uX0e8bBA4HHs+1tprcfZ+n33e+xNxXu7z2fvYDMMwBAAAgPNq4+wGAAAAXAGhCQAAwAJCEwAAgAWEJgAAAAsITQAAABYQmgAAACwgNAEAAFhAaAIAALDA3dkNXEpOnTql77//Xu3bt5fNZnN2OwAAwALDMHTs2DGFhISoTZtzn08iNDWh77//XqGhoc5uAwAANMLBgwfVuXPnc24nNDWh9u3bS/px0H19fZ3cDQAAsKKiokKhoaHm+/i5EJqa0OmP5Hx9fQlNAAC4mAtNrWEiOAAAgAWEJgAAAAsITQAAABYwpwkA0KQMw9APP/yguro6Z7cCSJLc3Nzk7u5+0bcDIjQBAJpMTU2NCgsLdeLECWe3Ajjw9vZWcHCwPD09G70PQhMAoEmcOnVKeXl5cnNzU0hIiDw9PbnRL5zOMAzV1NTo8OHDysvLU0RExHlvYHk+hCYAQJOoqanRqVOnFBoaKm9vb2e3A5jatWsnDw8Pffvtt6qpqVHbtm0btR+nTgTfuHGjRo0apZCQENlsNr377rsO220221mX+fPnmzWDBw+ut33cuHEO+yktLVViYqLsdrvsdrsSExNVVlbmUJOfn69Ro0bJx8dH/v7+mjZtmmpqaprr0AHgktXYf8UDzakpfi+d+pt9/Phx9erVS4sXLz7r9sLCQofltddek81m06233upQl5SU5FC3ZMkSh+3jx49XTk6OMjIylJGRoZycHCUmJprb6+rqNGLECB0/flybNm1Senq63n77bc2cObPpDxoAALgkp348Fx8fr/j4+HNuDwoKcnj873//W0OGDNEVV1zhsN7b27te7Wm5ubnKyMjQ1q1b1b9/f0nS0qVLFRsbq3379ikyMlKZmZnau3evDh48qJCQEEnSggULNGnSJM2dO5e7ewPARcrPz1dJSUmLvZ6/v7/CwsJa7PXw8+Ayc5oOHTqk1atX6/XXX6+3LS0tTampqQoMDFR8fLzmzJljfn/Mli1bZLfbzcAkSQMGDJDdbtfmzZsVGRmpLVu2KDo62gxMkjRs2DBVV1crOztbQ4YMOWtP1dXVqq6uNh9XVFQ01eECwCUjPz9fV0VFqaoFr6hr5+2tL3JzCU5NKCUlRe+++65ycnKc3YrTuExoev3119W+fXuNHj3aYf2ECRPUtWtXBQUFaffu3Zo1a5b++9//KisrS5JUVFSkgICAevsLCAhQUVGRWRMYGOiwvWPHjvL09DRrzmbevHl6/PHHL/bQAOCSVlJSoqoTJzThofkKDLuy2V/vUP4BpT39gEpKSiyFprq6Ol177bUKDg7W22+/ba4vLy9XdHS0Jk6cqCeffPKC+1mxYoXuuOMO87GPj48iIyM1e/bseu9dF9rP9OnT6829vRibN2/Wk08+qS1btqiqqkoRERGaNGmSpk+fLjc3N0v7SE5O1tSpU5usJ1fkMqHptdde04QJE+rNeE9KSjJ/jo6OVkREhPr27audO3eqT58+ks7+BXyGYTist1JzplmzZmnGjBnm49PfkgwAqC8w7Ep1jujh7DbqcXNz0+uvv65rrrlGaWlpmjBhgiRp6tSp8vPz02OPPWZ5X76+vtq3b58k6dixY1q+fLnGjBmjPXv2KDIysln6v5BVq1ZpzJgxuuOOO/TRRx+pQ4cOWrt2rR588EFt3bpV//jHPyzdGuIXv/iFfvGLX7RAx62XS4Smjz/+WPv27dPKlSsvWNunTx95eHho//796tOnj4KCgnTo0KF6dYcPHzbPLgUFBWnbtm0O20tLS1VbW1vvDNRPeXl5ycvLq4FH0zgtPR+gKTCnAICriIiI0Lx58zR16lQNGTJEn376qdLT07V9+/YG3QzRZrOZc2yDgoL05JNP6tlnn9Xnn39uhqaamhr96U9/UlpamsrKyhQdHa2nn35agwcP1vr1682zVaeDzJw5c5SSkqLU1FQtXLhQ+/btk4+Pj66//notXLjwrJ+mnHb8+HElJSUpISFBr776qrn+zjvvVGBgoBISEvSPf/xDY8eOlSQVFBQoOTlZmZmZqq6uVlRUlF566SX179+/3sdzkyZNUllZmfr166cXXnhB1dXVuv/++zV79mzNmjVLy5Ytk7e3t5544gn94Q9/MF/7u+++04wZM5SZmak2bdro17/+tV544QV16dLFYb+//vWvtWDBAtXU1GjcuHFauHChPDw8LjiGzcklQtOyZcsUExOjXr16XbB2z549qq2tVXBwsCQpNjZW5eXl2r59u/r16ydJ2rZtm8rLyzVw4ECzZu7cuSosLDSfl5mZKS8vL8XExDTTUVnnjPkATYE5BQBcydSpU7Vq1Sr9/ve/165du/TYY4/pmmuuafT+6urq9MYbb0iS+cmHJN1xxx365ptvlJ6erpCQEK1atUrDhw/Xrl27NHDgQC1cuFCPPfaYecbq9Nmdmpoa/fnPf1ZkZKSKi4t1//33a9KkSVqzZs05e8jMzNSRI0eUnJxcb9uoUaPUrVs3/f3vf9fYsWNVWVmp6667Tpdffrnee+89BQUFaefOnTp16tQ59//hhx+qc+fO2rhxoz755BNNnjxZW7Zs0W9+8xtt27ZNK1eu1N13360bb7xRoaGhOnHihIYMGaJrr71WGzdulLu7u5588kkNHz5cn3/+uRlQP/roIwUHB+ujjz7SV199pbFjx+qaa64xP1063xhGREQ08L+UdU4NTZWVlfrqq6/Mx3l5ecrJyZGfn5/5RltRUaF//vOfWrBgQb3nHzhwQGlpabrpppvk7++vvXv3aubMmerdu7cGDRokSYqKitLw4cOVlJRk3opgypQpGjlypJn64+Li1L17dyUmJmr+/Pk6evSokpOTlZSU1CqunGvp+QBNoaFzCgDA2Ww2m1555RVFRUWpZ8+eevjhhxu8j/LycjPkVFVVycPDQ6+++qquvPLHv90HDhzQ3//+dxUUFJgXHyUnJysjI0PLly/XU089Jbvd7nDG6rSfnq254oor9OKLL6pfv36qrKw858dmX375paQf3wvP5qqrrjJr3nrrLR0+fFiffvqp/Pz8JEm//OUvz3u8fn5+evHFF9WmTRtFRkbqmWee0YkTJ/TII49I+nEay1/+8hd98sknGjdunNLT09WmTRv97W9/M8+kLV++XB06dND69esVFxcn6cd5xYsXL5abm5uuuuoqjRgxQuvWrVNSUpKlMWwuTg1NO3bscLgy7fT8oIkTJ2rFihWSpPT0dBmGod/97nf1nu/p6al169bphRdeUGVlpUJDQzVixAjNmTPHYWJbWlqapk2bZv7HSEhIcLg3lJubm1avXq177rlHgwYNUrt27TR+/Hg9++yzzXHYjdZa5wMAwKXitddek7e3t/Ly8lRQUGB+ZGRV+/bttXPnTknSiRMntHbtWt11113q1KmTRo0apZ07d8owDHXr1s3hedXV1erUqdN59/3ZZ58pJSVFOTk5Onr0qHkGKD8/X927d1ePHj307bffSpKuvfZa/ec//zGfaxjGWff507m7OTk56t27txmYrOjRo4fDTSMDAwMVHR1tPnZzc1OnTp1UXFwsScrOztZXX31lXuF+2smTJ3XgwAGH/f70fTw4OFi7du2SpIsaw4vl1NA0ePDgc/6HPG3KlCmaMmXKWbeFhoZqw4YNF3wdPz8/paamnrcmLCxM77///gX3BQC4NG3ZskXPP/+8/vOf/+iZZ57R5MmTtXbt2gZ9f16bNm0czs5cffXVyszM1NNPP61Ro0bp1KlTcnNzU3Z2dr2r1s43yfr48eOKi4tTXFycUlNTddlllyk/P1/Dhg0zv71izZo1qq2tlfTj14ZIMoNFbm6uOSXlp7744gt1797d4TkNcXqO0Wk2m+2s604HvFOnTikmJkZpaWn19nXZZZedd78/3UdjxrApuMScJgAAmlNVVZUmTpyou+66S0OHDlW3bt0UHR2tJUuW6O67776ofbu5uamqqkqS1Lt3b9XV1am4uFjXXnvtWes9PT1VV1fnsO6LL75QSUmJ/vKXv5hXae/YscOhJjw8vN6+4uLi5OfnpwULFtQLTe+9957279+vP//5z5J+DHh/+9vfdPTo0QadbWqIPn36aOXKlQoICGj09BcrY9hcCE0AgBZxKP/AhYuc9DoPP/ywTp06paefflrSj58+LFiwQDNmzNDw4cPVpUsXXXXVVZo3b55uueUWST/O1/nuu+/Myd7Sjx93nb6/X1VVlbKysvTBBx+Yty3o1q2bJkyYoN///vdasGCBevfurZKSEn344Yfq2bOnbrrpJnXp0kWVlZVat26devXqJW9vb4WFhcnT01OLFi3S3Xffrd27d5th53x8fHy0ZMkSjRs3TlOmTNG9994rX19frVu3Tg888IBuu+02jRkzRpL0u9/9Tk899ZRuvvlmzZs3T8HBwfrss88UEhKi2NjYBo/p2UyYMEHz58/X//zP/+iJJ55Q586dlZ+fr3feeUcPPPCAOnfufMF9WBnD5kJoAgA0K39/f7Xz9lba0w+02Gu28/aWv7+/pdoNGzbopZde0vr16+Xj42OuT0pK0r/+9S/zY7p9+/apvLzc3F5YWKj8/HyHfVVUVJhXYXt5eSk8PFxPPPGEHnroIbNm+fLlevLJJzVz5kx999136tSpk2JjY803+4EDB+ruu+/W2LFjdeTIEfOWAytWrNAjjzyiF198UX369NGzzz6rhISECx7fbbfdpo8++khPPfWUfvOb36iqqkq//OUvNXv2bE2fPt38+NHT01OZmZmaOXOmbrrpJv3www/q3r27XnrpJUvjaIW3t7c2btyohx56SKNHj9axY8d0+eWX64YbbmjQmacLjWFzsRkXmlQEyyoqKmS321VeXt6kV93t3LlTMTExmvHSOy4zEbxg/x4998fRys7OdrjUFsCl6+TJk8rLy1PXrl3r3YiY756Ds53v99Pq+zdnmgAAzS4sLIwQA5fX5sIlAAAAIDQBAABYQGgCAACwgNAEAGhSXF+E1qgpfi8JTQCAJnH6Ls4nXOzLxfHzcPr38sy7jTcEV88BAJqEm5ubOnToYH7PmLe3d4O+ggRoDoZh6MSJEyouLlaHDh3qffVKQxCaAABNJigoSJLM4AS0Fh06dDB/PxuL0AQAaDI2m03BwcEKCAgwvzwWcDYPD4+LOsN0GqEJANDk3NzcmuRNCmhNmAgOAABgAaEJAADAAkITAACABYQmAAAACwhNAAAAFhCaAAAALCA0AQAAWEBoAgAAsIDQBAAAYAGhCQAAwAJCEwAAgAWEJgAAAAsITQAAABYQmgAAACwgNAEAAFhAaAIAALCA0AQAAGABoQkAAMACQhMAAIAFhCYAAAALCE0AAAAWEJoAAAAsIDQBAABYQGgCAACwgNAEAABgAaEJAADAAqeGpo0bN2rUqFEKCQmRzWbTu+++67B90qRJstlsDsuAAQMcaqqrqzV16lT5+/vLx8dHCQkJKigocKgpLS1VYmKi7Ha77Ha7EhMTVVZW5lCTn5+vUaNGycfHR/7+/po2bZpqamqa47ABAIALcmpoOn78uHr16qXFixefs2b48OEqLCw0lzVr1jhsnz59ulatWqX09HRt2rRJlZWVGjlypOrq6sya8ePHKycnRxkZGcrIyFBOTo4SExPN7XV1dRoxYoSOHz+uTZs2KT09XW+//bZmzpzZ9AcNAABckrszXzw+Pl7x8fHnrfHy8lJQUNBZt5WXl2vZsmV68803NXToUElSamqqQkNDtXbtWg0bNky5ubnKyMjQ1q1b1b9/f0nS0qVLFRsbq3379ikyMlKZmZnau3evDh48qJCQEEnSggULNGnSJM2dO1e+vr5NeNQAAMAVOTU0WbF+/XoFBASoQ4cOuu666zR37lwFBARIkrKzs1VbW6u4uDizPiQkRNHR0dq8ebOGDRumLVu2yG63m4FJkgYMGCC73a7NmzcrMjJSW7ZsUXR0tBmYJGnYsGGqrq5Wdna2hgwZctbeqqurVV1dbT6uqKho6sMHgIuSn5+vkpISZ7fRIP7+/goLC3N2G0A9rTo0xcfH67e//a3Cw8OVl5enRx99VNdff72ys7Pl5eWloqIieXp6qmPHjg7PCwwMVFFRkSSpqKjIDFk/FRAQ4FATGBjosL1jx47y9PQ0a85m3rx5evzxxy/2MAGgWeTn5+uqqChVnTjh7FYapJ23t77IzSU4odVp1aFp7Nix5s/R0dHq27evwsPDtXr1ao0ePfqczzMMQzabzXz8058vpuZMs2bN0owZM8zHFRUVCg0NPfcBAUALKikpUdWJE5rw0HwFhl3p7HYsOZR/QGlPP6CSkhJCE1qdVh2azhQcHKzw8HDt379fkhQUFKSamhqVlpY6nG0qLi7WwIEDzZpDhw7V29fhw4fNs0tBQUHatm2bw/bS0lLV1tbWOwP1U15eXvLy8rro4wKA5hQYdqU6R/RwdhuAy3Op+zQdOXJEBw8eVHBwsCQpJiZGHh4eysrKMmsKCwu1e/duMzTFxsaqvLxc27dvN2u2bdum8vJyh5rdu3ersLDQrMnMzJSXl5diYmJa4tAAAEAr59QzTZWVlfrqq6/Mx3l5ecrJyZGfn5/8/PyUkpKiW2+9VcHBwfrmm2/0yCOPyN/fX7fccoskyW63a/LkyZo5c6Y6deokPz8/JScnq2fPnubVdFFRURo+fLiSkpK0ZMkSSdKUKVM0cuRIRUZGSpLi4uLUvXt3JSYmav78+Tp69KiSk5OVlJTElXMAAECSk0PTjh07HK5MOz0/aOLEiXrllVe0a9cuvfHGGyorK1NwcLCGDBmilStXqn379uZznn/+ebm7u2vMmDGqqqrSDTfcoBUrVsjNzc2sSUtL07Rp08yr7BISEhzuDeXm5qbVq1frnnvu0aBBg9SuXTuNHz9ezz77bHMPAQAAcBFODU2DBw+WYRjn3P7BBx9ccB9t27bVokWLtGjRonPW+Pn5KTU19bz7CQsL0/vvv3/B1wMAAD9PLjWnCQAAwFkITQAAABYQmgAAACwgNAEAAFhAaAIAALCA0AQAAGABoQkAAMACQhMAAIAFhCYAAAALCE0AAAAWEJoAAAAsIDQBAABYQGgCAACwwN3ZDQAA4Ory8/NVUlLi7DYaxN/fX2FhYc5uw6UQmgAAuAj5+fm6KipKVSdOOLuVBmnn7a0vcnMJTg1AaAIA4CKUlJSo6sQJTXhovgLDrnR2O5Ycyj+gtKcfUElJCaGpAQhNAAA0gcCwK9U5ooez20AzYiI4AACABYQmAAAACwhNAAAAFhCaAAAALCA0AQAAWEBoAgAAsIDQBAAAYAGhCQAAwAJCEwAAgAWEJgAAAAsITQAAABYQmgAAACwgNAEAAFhAaAIAALCA0AQAAGABoQkAAMACQhMAAIAFhCYAAAALCE0AAAAWEJoAAAAsIDQBAABYQGgCAACwgNAEAABggVND08aNGzVq1CiFhITIZrPp3XffNbfV1tbqoYceUs+ePeXj46OQkBD9/ve/1/fff++wj8GDB8tmszks48aNc6gpLS1VYmKi7Ha77Ha7EhMTVVZW5lCTn5+vUaNGycfHR/7+/po2bZpqamqa69ABAICLcWpoOn78uHr16qXFixfX23bixAnt3LlTjz76qHbu3Kl33nlHX375pRISEurVJiUlqbCw0FyWLFnisH38+PHKyclRRkaGMjIylJOTo8TERHN7XV2dRowYoePHj2vTpk1KT0/X22+/rZkzZzb9QQMAAJfk7swXj4+PV3x8/Fm32e12ZWVlOaxbtGiR+vXrp/z8fIWFhZnrvb29FRQUdNb95ObmKiMjQ1u3blX//v0lSUuXLlVsbKz27dunyMhIZWZmau/evTp48KBCQkIkSQsWLNCkSZM0d+5c+fr6NsXhAgAAF+ZSc5rKy8tls9nUoUMHh/VpaWny9/dXjx49lJycrGPHjpnbtmzZIrvdbgYmSRowYIDsdrs2b95s1kRHR5uBSZKGDRum6upqZWdnn7Of6upqVVRUOCwAAODS5NQzTQ1x8uRJPfzwwxo/frzDmZ8JEyaoa9euCgoK0u7duzVr1iz997//Nc9SFRUVKSAgoN7+AgICVFRUZNYEBgY6bO/YsaM8PT3NmrOZN2+eHn/88aY4PAAA0Mq5RGiqra3VuHHjdOrUKb388ssO25KSksyfo6OjFRERob59+2rnzp3q06ePJMlms9Xbp2EYDuut1Jxp1qxZmjFjhvm4oqJCoaGh1g8MAAC4jFb/8Vxtba3GjBmjvLw8ZWVlXXB+UZ8+feTh4aH9+/dLkoKCgnTo0KF6dYcPHzbPLgUFBdU7o1RaWqra2tp6Z6B+ysvLS76+vg4LAAC4NLXq0HQ6MO3fv19r165Vp06dLvicPXv2qLa2VsHBwZKk2NhYlZeXa/v27WbNtm3bVF5eroEDB5o1u3fvVmFhoVmTmZkpLy8vxcTENPFRAQAAV+TUj+cqKyv11VdfmY/z8vKUk5MjPz8/hYSE6LbbbtPOnTv1/vvvq66uzjwb5OfnJ09PTx04cEBpaWm66aab5O/vr71792rmzJnq3bu3Bg0aJEmKiorS8OHDlZSUZN6KYMqUKRo5cqQiIyMlSXFxcerevbsSExM1f/58HT16VMnJyUpKSuLsEQAAkOTkM007duxQ79691bt3b0nSjBkz1Lt3bz322GMqKCjQe++9p4KCAl1zzTUKDg42l9NXvXl6emrdunUaNmyYIiMjNW3aNMXFxWnt2rVyc3MzXyctLU09e/ZUXFyc4uLidPXVV+vNN980t7u5uWn16tVq27atBg0apDFjxujmm2/Ws88+27IDAgAAWi2nnmkaPHiwDMM45/bzbZOk0NBQbdiw4YKv4+fnp9TU1PPWhIWF6f3337/gvgAAwM9Tq57TBAAA0FoQmgAAACwgNAEAAFhAaAIAALCA0AQAAGABoQkAAMACQhMAAIAFhCYAAAALCE0AAAAWEJoAAAAsIDQBAABYQGgCAACwgNAEAABgAaEJAADAAkITAACABYQmAAAACwhNAAAAFhCaAAAALCA0AQAAWEBoAgAAsIDQBAAAYAGhCQAAwAJCEwAAgAXuzm4AwM9Tfn6+SkpKnN1Gg/j7+yssLMzZbQBwEkITgBaXn5+vq6KiVHXihLNbaZB23t76IjeX4AT8TBGaALS4kpISVZ04oQkPzVdg2JXObseSQ/kHlPb0AyopKSE0AT9ThCYAThMYdqU6R/RwdhsAYAkTwQEAACwgNAEAAFhAaAIAALCA0AQAAGABoQkAAMACQhMAAIAFhCYAAAALCE0AAAAWEJoAAAAsIDQBAABYQGgCAACwgNAEAABggVND08aNGzVq1CiFhITIZrPp3XffddhuGIZSUlIUEhKidu3aafDgwdqzZ49DTXV1taZOnSp/f3/5+PgoISFBBQUFDjWlpaVKTEyU3W6X3W5XYmKiysrKHGry8/M1atQo+fj4yN/fX9OmTVNNTU1zHDYAAHBBTg1Nx48fV69evbR48eKzbn/mmWf03HPPafHixfr0008VFBSkG2+8UceOHTNrpk+frlWrVik9PV2bNm1SZWWlRo4cqbq6OrNm/PjxysnJUUZGhjIyMpSTk6PExERze11dnUaMGKHjx49r06ZNSk9P19tvv62ZM2c238EDAACX4u7MF4+Pj1d8fPxZtxmGoYULF2r27NkaPXq0JOn1119XYGCg3nrrLd11110qLy/XsmXL9Oabb2ro0KGSpNTUVIWGhmrt2rUaNmyYcnNzlZGRoa1bt6p///6SpKVLlyo2Nlb79u1TZGSkMjMztXfvXh08eFAhISGSpAULFmjSpEmaO3eufH19W2A0AABAa9Zq5zTl5eWpqKhIcXFx5jovLy9dd9112rx5syQpOztbtbW1DjUhISGKjo42a7Zs2SK73W4GJkkaMGCA7Ha7Q010dLQZmCRp2LBhqq6uVnZ29jl7rK6uVkVFhcMCAAAuTY0KTVdccYWOHDlSb31ZWZmuuOKKi25KkoqKiiRJgYGBDusDAwPNbUVFRfL09FTHjh3PWxMQEFBv/wEBAQ41Z75Ox44d5enpadaczbx588x5Una7XaGhoQ08SgAA4CoaFZq++eYbhzlDp1VXV+u777676KZ+ymazOTw2DKPeujOdWXO2+sbUnGnWrFkqLy83l4MHD563LwAA4LoaNKfpvffeM3/+4IMPZLfbzcd1dXVat26dunTp0iSNBQUFSfrxLFBwcLC5vri42DwrFBQUpJqaGpWWljqcbSouLtbAgQPNmkOHDtXb/+HDhx32s23bNoftpaWlqq2trXcG6qe8vLzk5eXVyCMEAACupEGh6eabb5b041mZiRMnOmzz8PBQly5dtGDBgiZprGvXrgoKClJWVpZ69+4tSaqpqdGGDRv09NNPS5JiYmLk4eGhrKwsjRkzRpJUWFio3bt365lnnpEkxcbGqry8XNu3b1e/fv0kSdu2bVN5ebkZrGJjYzV37lwVFhaaAS0zM1NeXl6KiYlpkuMBAACurUGh6dSpU5J+DDSffvqp/P39L+rFKysr9dVXX5mP8/LylJOTIz8/P4WFhWn69Ol66qmnFBERoYiICD311FPy9vbW+PHjJUl2u12TJ0/WzJkz1alTJ/n5+Sk5OVk9e/Y0r6aLiorS8OHDlZSUpCVLlkiSpkyZopEjRyoyMlKSFBcXp+7duysxMVHz58/X0aNHlZycrKSkJK6cAwAAkhp5y4G8vLwmefEdO3ZoyJAh5uMZM2ZIkiZOnKgVK1bowQcfVFVVle655x6Vlpaqf//+yszMVPv27c3nPP/883J3d9eYMWNUVVWlG264QStWrJCbm5tZk5aWpmnTpplX2SUkJDjcG8rNzU2rV6/WPffco0GDBqldu3YaP368nn322SY5TgAA4PoafZ+mdevWad26dSouLjbPQJ322muvWdrH4MGDZRjGObfbbDalpKQoJSXlnDVt27bVokWLtGjRonPW+Pn5KTU19by9hIWF6f33379gzwAA4OepUaHp8ccf1xNPPKG+ffsqODj4glezAQAAuLpGhaa//vWvWrFihcNXkQAAAFzKGnWfppqaGvPKMwAAgJ+DRoWmO++8U2+99VZT9wIAANBqNerjuZMnT+rVV1/V2rVrdfXVV8vDw8Nh+3PPPdckzQEAALQWjQpNn3/+ua655hpJ0u7dux22MSkcAABcihoVmj766KOm7gMAAKBVa9ScJgAAgJ+bRp1pGjJkyHk/hvvwww8b3RAAAEBr1KjQdHo+02m1tbXKycnR7t27632RLwAAwKWgUaHp+eefP+v6lJQUVVZWXlRDAAAArVGTzmm6/fbbLX/vHAAAgCtp0tC0ZcsWtW3btil3CQAA0Co06uO50aNHOzw2DEOFhYXasWOHHn300SZpDAAAoDVpVGiy2+0Oj9u0aaPIyEg98cQTiouLa5LGAAAAWpNGhably5c3dR8AAACtWqNC02nZ2dnKzc2VzWZT9+7d1bt376bqCwAAoFVpVGgqLi7WuHHjtH79enXo0EGGYai8vFxDhgxRenq6LrvssqbuEwAAwKkadfXc1KlTVVFRoT179ujo0aMqLS3V7t27VVFRoWnTpjV1jwAAAE7XqDNNGRkZWrt2raKiosx13bt310svvcREcAAAcElq1JmmU6dOycPDo956Dw8PnTp16qKbAgAAaG0aFZquv/563Xffffr+++/Ndd99953uv/9+3XDDDU3WHAAAQGvRqNC0ePFiHTt2TF26dNGVV16pX/7yl+ratauOHTumRYsWNXWPAAAATteoOU2hoaHauXOnsrKy9MUXX8gwDHXv3l1Dhw5t6v4AAABahQadafrwww/VvXt3VVRUSJJuvPFGTZ06VdOmTdOvfvUr9ejRQx9//HGzNAoAAOBMDQpNCxcuVFJSknx9fetts9vtuuuuu/Tcc881WXMAAACtRYNC03//+18NHz78nNvj4uKUnZ190U0BAAC0Ng0KTYcOHTrrrQZOc3d31+HDhy+6KQAAgNamQaHp8ssv165du865/fPPP1dwcPBFNwUAANDaNCg03XTTTXrsscd08uTJetuqqqo0Z84cjRw5ssmaAwAAaC0adMuBP/3pT3rnnXfUrVs33XvvvYqMjJTNZlNubq5eeukl1dXVafbs2c3VKwAAgNM0KDQFBgZq8+bN+t///V/NmjVLhmFIkmw2m4YNG6aXX35ZgYGBzdIoAACAMzX45pbh4eFas2aNSktL9dVXX8kwDEVERKhjx47N0R8AAECr0Kg7gktSx44d9atf/aopewEAAGi1GvXdcwAAAD83hCYAAAALCE0AAAAWEJoAAAAsIDQBAABYQGgCAACwoNWHpi5dushms9Vb/vjHP0qSJk2aVG/bgAEDHPZRXV2tqVOnyt/fXz4+PkpISFBBQYFDTWlpqRITE2W322W325WYmKiysrKWOkwAANDKtfrQ9Omnn6qwsNBcsrKyJEm//e1vzZrhw4c71KxZs8ZhH9OnT9eqVauUnp6uTZs2qbKyUiNHjlRdXZ1ZM378eOXk5CgjI0MZGRnKyclRYmJiyxwkAABo9Rp9c8uWctlllzk8/stf/qIrr7xS1113nbnOy8tLQUFBZ31+eXm5li1bpjfffFNDhw6VJKWmpio0NFRr167VsGHDlJubq4yMDG3dulX9+/eXJC1dulSxsbHat2+fIiMjm+noAACAq2j1Z5p+qqamRqmpqfrDH/4gm81mrl+/fr0CAgLUrVs3JSUlqbi42NyWnZ2t2tpaxcXFmetCQkIUHR2tzZs3S5K2bNkiu91uBiZJGjBggOx2u1lzNtXV1aqoqHBYAADApcmlQtO7776rsrIyTZo0yVwXHx+vtLQ0ffjhh1qwYIE+/fRTXX/99aqurpYkFRUVydPTs9534wUGBqqoqMisCQgIqPd6AQEBZs3ZzJs3z5wDZbfbFRoa2gRHCQAAWqNW//HcTy1btkzx8fEKCQkx140dO9b8OTo6Wn379lV4eLhWr16t0aNHn3NfhmE4nK366c/nqjnTrFmzNGPGDPNxRUUFwQkAgEuUy4Smb7/9VmvXrtU777xz3rrg4GCFh4dr//79kqSgoCDV1NSotLTU4WxTcXGxBg4caNYcOnSo3r4OHz6swMDAc76Wl5eXvLy8GnM4AADAxbjMx3PLly9XQECARowYcd66I0eO6ODBgwoODpYkxcTEyMPDw7zqTpIKCwu1e/duMzTFxsaqvLxc27dvN2u2bdum8vJyswYAAPy8ucSZplOnTmn58uWaOHGi3N3/f8uVlZVKSUnRrbfequDgYH3zzTd65JFH5O/vr1tuuUWSZLfbNXnyZM2cOVOdOnWSn5+fkpOT1bNnT/NquqioKA0fPlxJSUlasmSJJGnKlCkaOXIkV84BAABJLhKa1q5dq/z8fP3hD39wWO/m5qZdu3bpjTfeUFlZmYKDgzVkyBCtXLlS7du3N+uef/55ubu7a8yYMaqqqtINN9ygFStWyM3NzaxJS0vTtGnTzKvsEhIStHjx4pY5QAAA0Oq5RGiKi4uTYRj11rdr104ffPDBBZ/ftm1bLVq0SIsWLTpnjZ+fn1JTUy+qTwAAcOlymTlNAAAAzkRoAgAAsIDQBAAAYAGhCQAAwAJCEwAAgAWEJgAAAAsITQAAABYQmgAAACwgNAEAAFhAaAIAALCA0AQAAGABoQkAAMACQhMAAIAFhCYAAAALCE0AAAAWEJoAAAAsIDQBAABYQGgCAACwgNAEAABgAaEJAADAAkITAACABYQmAAAACwhNAAAAFhCaAAAALCA0AQAAWEBoAgAAsIDQBAAAYAGhCQAAwAJCEwAAgAWEJgAAAAsITQAAABYQmgAAACwgNAEAAFhAaAIAALCA0AQAAGABoQkAAMACd2c3gEtbbm6us1toEH9/f4WFhTm7DQBAK0RoQrOoOHpYknT77bc7uZOGaeftrS9ycwlOAIB6CE1oFlWVFZKkEXfNVuTVMU7uxppD+QeU9vQDKikpITQBAOohNKFZdQoJV+eIHs5uAwCAi9aqJ4KnpKTIZrM5LEFBQeZ2wzCUkpKikJAQtWvXToMHD9aePXsc9lFdXa2pU6fK399fPj4+SkhIUEFBgUNNaWmpEhMTZbfbZbfblZiYqLKyspY4RAAA4CJadWiSpB49eqiwsNBcdu3aZW575pln9Nxzz2nx4sX69NNPFRQUpBtvvFHHjh0za6ZPn65Vq1YpPT1dmzZtUmVlpUaOHKm6ujqzZvz48crJyVFGRoYyMjKUk5OjxMTEFj1OAADQurX6j+fc3d0dzi6dZhiGFi5cqNmzZ2v06NGSpNdff12BgYF66623dNddd6m8vFzLli3Tm2++qaFDh0qSUlNTFRoaqrVr12rYsGHKzc1VRkaGtm7dqv79+0uSli5dqtjYWO3bt0+RkZEtd7AAAKDVavVnmvbv36+QkBB17dpV48aN09dffy1JysvLU1FRkeLi4sxaLy8vXXfdddq8ebMkKTs7W7W1tQ41ISEhio6ONmu2bNkiu91uBiZJGjBggOx2u1lzLtXV1aqoqHBYAADApalVh6b+/fvrjTfe0AcffKClS5eqqKhIAwcO1JEjR1RUVCRJCgwMdHhOYGCgua2oqEienp7q2LHjeWsCAgLqvXZAQIBZcy7z5s0z50HZ7XaFhoY2+lgBAEDr1qpDU3x8vG699Vb17NlTQ4cO1erVqyX9+DHcaTabzeE5hmHUW3emM2vOVm9lP7NmzVJ5ebm5HDx48ILHBAAAXFOrDk1n8vHxUc+ePbV//35zntOZZ4OKi4vNs09BQUGqqalRaWnpeWsOHTpU77UOHz5c7yzWmby8vOTr6+uwAACAS5NLhabq6mrl5uYqODhYXbt2VVBQkLKyssztNTU12rBhgwYOHChJiomJkYeHh0NNYWGhdu/ebdbExsaqvLxc27dvN2u2bdum8vJyswYAAKBVXz2XnJysUaNGKSwsTMXFxXryySdVUVGhiRMnymazafr06XrqqacUERGhiIgIPfXUU/L29tb48eMlSXa7XZMnT9bMmTPVqVMn+fn5KTk52fy4T5KioqI0fPhwJSUlacmSJZKkKVOmaOTIkVw5BwAATK06NBUUFOh3v/udSkpKdNlll2nAgAHaunWrwsPDJUkPPvigqqqqdM8996i0tFT9+/dXZmam2rdvb+7j+eefl7u7u8aMGaOqqirdcMMNWrFihdzc3MyatLQ0TZs2zbzKLiEhQYsXL27ZgwUAAK1aqw5N6enp591us9mUkpKilJSUc9a0bdtWixYt0qJFi85Z4+fnp9TU1Ma2CQAAfgZcak4TAACAsxCaAAAALCA0AQAAWEBoAgAAsIDQBAAAYAGhCQAAwIJWfcsBABeWn5+vkpISZ7fRILm5uc5uAQAajNAEuLD8/HxdFRWlqhMnnN1Ko1RWVjq7BQCwjNAEuLCSkhJVnTihCQ/NV2DYlc5ux7Lc7Rv0n9df0MmTJ53dCgBYRmgCLgGBYVeqc0QPZ7dh2aH8A85uAQAajIngAAAAFhCaAAAALODjOQBoAFe68s+VegVcAaEJACyoOHpYknT77bc7uZOG4ypFoGkQmgDAgqrKCknSiLtmK/LqGCd3Yw1XKQJNi9AEAA3QKSTcZa5U5CpFoGkxERwAAMACQhMAAIAFhCYAAAALCE0AAAAWEJoAAAAsIDQBAABYQGgCAACwgNAEAABgAaEJAADAAkITAACABYQmAAAACwhNAAAAFhCaAAAALCA0AQAAWEBoAgAAsIDQBAAAYIG7sxsAWpvc3Fxnt2CZK/UKAK6O0AT8n4qjhyVJt99+u5M7abjKykpntwAAlzxCE/B/qiorJEkj7pqtyKtjnNyNNbnbN+g/r7+gkydPOrsVALjkEZqAM3QKCVfniB7ObsOSQ/kHnN0CAPxsMBEcAADAAkITAACABYQmAAAAC1p1aJo3b55+9atfqX379goICNDNN9+sffv2OdRMmjRJNpvNYRkwYIBDTXV1taZOnSp/f3/5+PgoISFBBQUFDjWlpaVKTEyU3W6X3W5XYmKiysrKmvsQAQCAi2jVoWnDhg364x//qK1btyorK0s//PCD4uLidPz4cYe64cOHq7Cw0FzWrFnjsH369OlatWqV0tPTtWnTJlVWVmrkyJGqq6sza8aPH6+cnBxlZGQoIyNDOTk5SkxMbJHjBAAArV+rvnouIyPD4fHy5csVEBCg7Oxs/eY3vzHXe3l5KSgo6Kz7KC8v17Jly/Tmm29q6NChkqTU1FSFhoZq7dq1GjZsmHJzc5WRkaGtW7eqf//+kqSlS5cqNjZW+/btU2RkZDMdIQAAcBWt+kzTmcrLyyVJfn5+DuvXr1+vgIAAdevWTUlJSSouLja3ZWdnq7a2VnFxcea6kJAQRUdHa/PmzZKkLVu2yG63m4FJkgYMGCC73W7WAACAn7dWfabppwzD0IwZM/TrX/9a0dHR5vr4+Hj99re/VXh4uPLy8vToo4/q+uuvV3Z2try8vFRUVCRPT0917NjRYX+BgYEqKiqSJBUVFSkgIKDeawYEBJg1Z1NdXa3q6mrzcUVFxcUeJgAAaKVcJjTde++9+vzzz7Vp0yaH9WPHjjV/jo6OVt++fRUeHq7Vq1dr9OjR59yfYRiy2Wzm45/+fK6aM82bN0+PP/54Qw4DAAC4KJf4eG7q1Kl677339NFHH6lz587nrQ0ODlZ4eLj2798vSQoKClJNTY1KS0sd6oqLixUYGGjWHDp0qN6+Dh8+bNaczaxZs1ReXm4uBw8ebOihAQAAF9GqQ5NhGLr33nv1zjvv6MMPP1TXrl0v+JwjR47o4MGDCg4OliTFxMTIw8NDWVlZZk1hYaF2796tgQMHSpJiY2NVXl6u7du3mzXbtm1TeXm5WXM2Xl5e8vX1dVgAAMClqVV/PPfHP/5Rb731lv7973+rffv25vwiu92udu3aqbKyUikpKbr11lsVHBysb775Ro888oj8/f11yy23mLWTJ0/WzJkz1alTJ/n5+Sk5OVk9e/Y0r6aLiorS8OHDlZSUpCVLlkiSpkyZopEjR3LlHAAAkNTKQ9Mrr7wiSRo8eLDD+uXLl2vSpElyc3PTrl279MYbb6isrEzBwcEaMmSIVq5cqfbt25v1zz//vNzd3TVmzBhVVVXphhtu0IoVK+Tm5mbWpKWladq0aeZVdgkJCVq8eHHzHyQAAHAJrTo0GYZx3u3t2rXTBx98cMH9tG3bVosWLdKiRYvOWePn56fU1NQG9wgAAH4eWvWcJgAAgNaC0AQAAGABoQkAAMACQhMAAIAFhCYAAAALCE0AAAAWEJoAAAAsIDQBAABYQGgCAACwgNAEAABgAaEJAADAAkITAACABYQmAAAACwhNAAAAFhCaAAAALCA0AQAAWEBoAgAAsIDQBAAAYAGhCQAAwAJCEwAAgAWEJgAAAAsITQAAABa4O7sBAADgHLm5uc5uoUH8/f0VFhbmtNcnNAEA8DNTcfSwJOn22293cicN087bW1/k5jotOBGaAAD4mamqrJAkjbhrtiKvjnFyN9Ycyj+gtKcfUElJCaEJAAC0rE4h4eoc0cPZbbgMJoIDAABYQGgCAACwgNAEAABgAaEJAADAAkITAACABYQmAAAACwhNAAAAFhCaAAAALCA0AQAAWEBoAgAAsIDQBAAAYAGhCQAAwAJCEwAAgAWEJgAAAAsITWd4+eWX1bVrV7Vt21YxMTH6+OOPnd0SAABoBQhNP7Fy5UpNnz5ds2fP1meffaZrr71W8fHxys/Pd3ZrAADAyQhNP/Hcc89p8uTJuvPOOxUVFaWFCxcqNDRUr7zyirNbAwAATubu7AZai5qaGmVnZ+vhhx92WB8XF6fNmzef9TnV1dWqrq42H5eXl0uSKioqmrS3yspKSVLB/j2qrjrRpPtuLofyD0iSir75Ugd8vJ3cjTX03HJcsW96bhmHC/IkSdnZ2ebfvtZu3759kvgb3dxO/25UVlY2+fvs6f0ZhnH+QgOGYRjGd999Z0gyPvnkE4f1c+fONbp163bW58yZM8eQxMLCwsLCwnIJLAcPHjxvVuBM0xlsNpvDY8Mw6q07bdasWZoxY4b5+NSpUzp69Kg6dep0zuc0RkVFhUJDQ3Xw4EH5+vo22X7hiHFuOYx1y2CcWwbj3DKac5wNw9CxY8cUEhJy3jpC0//x9/eXm5ubioqKHNYXFxcrMDDwrM/x8vKSl5eXw7oOHTo0V4vy9fXlf8gWwDi3HMa6ZTDOLYNxbhnNNc52u/2CNUwE/z+enp6KiYlRVlaWw/qsrCwNHDjQSV0BAIDWgjNNPzFjxgwlJiaqb9++io2N1auvvqr8/Hzdfffdzm4NAAA4GaHpJ8aOHasjR47oiSeeUGFhoaKjo7VmzRqFh4c7tS8vLy/NmTOn3keBaFqMc8thrFsG49wyGOeW0RrG2WYYF7q+DgAAAMxpAgAAsIDQBAAAYAGhCQAAwAJCEwAAgAWEplbi5ZdfVteuXdW2bVvFxMTo448/Pm/9hg0bFBMTo7Zt2+qKK67QX//61xbq1LU1ZJzfeecd3Xjjjbrsssvk6+ur2NhYffDBBy3Yretq6O/zaZ988onc3d11zTXXNG+Dl5CGjnV1dbVmz56t8PBweXl56corr9Rrr73WQt26roaOc1pamnr16iVvb28FBwfrjjvu0JEjR1qoW9e0ceNGjRo1SiEhIbLZbHr33Xcv+JwWfy9ski9uw0VJT083PDw8jKVLlxp79+417rvvPsPHx8f49ttvz1r/9ddfG97e3sZ9991n7N2711i6dKnh4eFh/Otf/2rhzl1LQ8f5vvvuM55++mlj+/btxpdffmnMmjXL8PDwMHbu3NnCnbuWho7zaWVlZcYVV1xhxMXFGb169WqZZl1cY8Y6ISHB6N+/v5GVlWXk5eUZ27Ztq/edm3DU0HH++OOPjTZt2hgvvPCC8fXXXxsff/yx0aNHD+Pmm29u4c5dy5o1a4zZs2cbb7/9tiHJWLVq1XnrnfFeSGhqBfr162fcfffdDuuuuuoq4+GHHz5r/YMPPmhcddVVDuvuuusuY8CAAc3W46WgoeN8Nt27dzcef/zxpm7tktLYcR47dqzxpz/9yZgzZw6hyaKGjvV//vMfw263G0eOHGmJ9i4ZDR3n+fPnG1dccYXDuhdffNHo3Llzs/V4qbESmpzxXsjHc05WU1Oj7OxsxcXFOayPi4vT5s2bz/qcLVu21KsfNmyYduzYodra2mbr1ZU1ZpzPdOrUKR07dkx+fn7N0eIlobHjvHz5ch04cEBz5sxp7hYvGY0Z6/fee099+/bVM888o8svv1zdunVTcnKyqqqqWqJll9SYcR44cKAKCgq0Zs0aGYahQ4cO6V//+pdGjBjREi3/bDjjvZA7gjtZSUmJ6urq6n0pcGBgYL0vDz6tqKjorPU//PCDSkpKFBwc3Gz9uqrGjPOZFixYoOPHj2vMmDHN0eIloTHjvH//fj388MP6+OOP5e7OnySrGjPWX3/9tTZt2qS2bdtq1apVKikp0T333KOjR48yr+kcGjPOAwcOVFpamsaOHauTJ0/qhx9+UEJCghYtWtQSLf9sOOO9kDNNrYTNZnN4bBhGvXUXqj/bejhq6Dif9ve//10pKSlauXKlAgICmqu9S4bVca6rq9P48eP1+OOPq1u3bi3V3iWlIb/Tp06dks1mU1pamvr166ebbrpJzz33nFasWMHZpgtoyDjv3btX06ZN02OPPabs7GxlZGQoLy+P7zFtBi39Xsg/65zM399fbm5u9f7FUlxcXC9BnxYUFHTWend3d3Xq1KnZenVljRnn01auXKnJkyfrn//8p4YOHdqcbbq8ho7zsWPHtGPHDn322We69957Jf34xm4Yhtzd3ZWZmanrr7++RXp3NY35nQ4ODtbll18uu91urouKipJhGCooKFBERESz9uyKGjPO8+bN06BBg/TAAw9Ikq6++mr5+Pjo2muv1ZNPPsmnAU3EGe+FnGlyMk9PT8XExCgrK8thfVZWlgYOHHjW58TGxtarz8zMVN++feXh4dFsvbqyxoyz9OMZpkmTJumtt95iPoIFDR1nX19f7dq1Szk5OeZy9913KzIyUjk5Oerfv39Lte5yGvM7PWjQIH3//feqrKw013355Zdq06aNOnfu3Kz9uqrGjPOJEyfUpo3j26ubm5uk/38mBBfPKe+FzTbFHJadvpx12bJlxt69e43p06cbPj4+xjfffGMYhmE8/PDDRmJioll/+jLL+++/39i7d6+xbNkybjlgQUPH+a233jLc3d2Nl156ySgsLDSXsrIyZx2CS2joOJ+Jq+esa+hYHzt2zOjcubNx2223GXv27DE2bNhgREREGHfeeaezDsElNHScly9fbri7uxsvv/yyceDAAWPTpk1G3759jX79+jnrEFzCsWPHjM8++8z47LPPDEnGc889Z3z22WfmrR1aw3shoamVeOmll4zw8HDD09PT6NOnj7FhwwZz28SJE43rrrvOoX79+vVG7969DU9PT6NLly7GK6+80sIdu6aGjPN1111nSKq3TJw4seUbdzEN/X3+KUJTwzR0rHNzc42hQ4ca7dq1Mzp37mzMmDHDOHHiRAt37XoaOs4vvvii0b17d6Ndu3ZGcHCwMWHCBKOgoKCFu3YtH3300Xn/5raG90KbYXCuEAAA4EKY0wQAAGABoQkAAMACQhMAAIAFhCYAAAALCE0AAAAWEJoAAAAsIDQBAABYQGgCAACwgNAEAABgAaEJAADAAkITAACABYQmAAAAC/4fNMXtzlJenvQAAAAASUVORK5CYII=",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "sns.histplot(y, bins = 10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train test split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=1, test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train1, X_val, y_train1, y_val = train_test_split(X_train, y_train, random_state=1, test_size=0.25)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "RF modeling (before Feature selection and Hyperparameter Tuning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/ns/m5pnr0211w91v02hpv22958m0000gn/T/ipykernel_86350/350139188.py:2: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  rfreg.fit(X_train1, y_train1)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;background-color: white;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>RandomForestRegressor()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">RandomForestRegressor</label><div class=\"sk-toggleable__content\"><pre>RandomForestRegressor()</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "RandomForestRegressor()"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rfreg = RandomForestRegressor()\n",
    "rfreg.fit(X_train1, y_train1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_rfreg = rfreg.predict(X_val)\n",
    "y_pred_rfreg_r2 = rfreg.predict(X_train1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.031243432875167804"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mean_absolute_error(y_val, y_pred_rfreg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.005587788342384502"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mean_squared_error(y_val, y_pred_rfreg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.07475151063613698"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mean_squared_error(y_val, y_pred_rfreg, squared = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9859709517481916"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#train\n",
    "r2_score(y_train1, y_pred_rfreg_r2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9370553617871817"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#val\n",
    "r2_score(y_val, y_pred_rfreg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Residual plots for each target variable"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Feature Selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_feat = pd.DataFrame({\n",
    "    \"features\": X_train1.columns,\n",
    "    \"score\": rfreg.feature_importances_\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>features</th>\n",
       "      <th>score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>tfidf_0</td>\n",
       "      <td>0.001745</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>tfidf_1</td>\n",
       "      <td>0.000539</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>tfidf_2</td>\n",
       "      <td>0.000669</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>tfidf_3</td>\n",
       "      <td>0.001158</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>tfidf_4</td>\n",
       "      <td>0.003924</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>464</th>\n",
       "      <td>tree</td>\n",
       "      <td>0.000700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>465</th>\n",
       "      <td>tropical</td>\n",
       "      <td>0.000223</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>466</th>\n",
       "      <td>vanilla</td>\n",
       "      <td>0.036270</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>467</th>\n",
       "      <td>violet</td>\n",
       "      <td>0.000007</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>468</th>\n",
       "      <td>woody</td>\n",
       "      <td>0.000785</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>469 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     features     score\n",
       "0     tfidf_0  0.001745\n",
       "1     tfidf_1  0.000539\n",
       "2     tfidf_2  0.000669\n",
       "3     tfidf_3  0.001158\n",
       "4     tfidf_4  0.003924\n",
       "..        ...       ...\n",
       "464      tree  0.000700\n",
       "465  tropical  0.000223\n",
       "466   vanilla  0.036270\n",
       "467    violet  0.000007\n",
       "468     woody  0.000785\n",
       "\n",
       "[469 rows x 2 columns]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_feat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_feat_ranked = df_feat.sort_values(\"score\", ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>features</th>\n",
       "      <th>score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>390</th>\n",
       "      <td>sativa</td>\n",
       "      <td>0.209317</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>466</th>\n",
       "      <td>vanilla</td>\n",
       "      <td>0.036270</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>388</th>\n",
       "      <td>hybrid</td>\n",
       "      <td>0.029427</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>288</th>\n",
       "      <td>tfidf_288</td>\n",
       "      <td>0.014485</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>329</th>\n",
       "      <td>tfidf_329</td>\n",
       "      <td>0.013169</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>149</th>\n",
       "      <td>tfidf_149</td>\n",
       "      <td>0.013019</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>447</th>\n",
       "      <td>orange</td>\n",
       "      <td>0.012127</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>312</th>\n",
       "      <td>tfidf_312</td>\n",
       "      <td>0.011865</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>145</th>\n",
       "      <td>tfidf_145</td>\n",
       "      <td>0.011202</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>345</th>\n",
       "      <td>tfidf_345</td>\n",
       "      <td>0.009993</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>161</th>\n",
       "      <td>tfidf_161</td>\n",
       "      <td>0.009905</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>165</th>\n",
       "      <td>tfidf_165</td>\n",
       "      <td>0.009605</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>168</th>\n",
       "      <td>tfidf_168</td>\n",
       "      <td>0.009546</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>tfidf_97</td>\n",
       "      <td>0.008829</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>141</th>\n",
       "      <td>tfidf_141</td>\n",
       "      <td>0.008448</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>121</th>\n",
       "      <td>tfidf_121</td>\n",
       "      <td>0.007916</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>218</th>\n",
       "      <td>tfidf_218</td>\n",
       "      <td>0.007844</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>78</th>\n",
       "      <td>tfidf_78</td>\n",
       "      <td>0.007750</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>163</th>\n",
       "      <td>tfidf_163</td>\n",
       "      <td>0.007605</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>355</th>\n",
       "      <td>tfidf_355</td>\n",
       "      <td>0.007531</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>175</th>\n",
       "      <td>tfidf_175</td>\n",
       "      <td>0.006981</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>309</th>\n",
       "      <td>tfidf_309</td>\n",
       "      <td>0.006891</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>239</th>\n",
       "      <td>tfidf_239</td>\n",
       "      <td>0.006684</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>357</th>\n",
       "      <td>tfidf_357</td>\n",
       "      <td>0.006631</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>157</th>\n",
       "      <td>tfidf_157</td>\n",
       "      <td>0.006567</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>245</th>\n",
       "      <td>tfidf_245</td>\n",
       "      <td>0.006146</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>tfidf_32</td>\n",
       "      <td>0.006009</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>236</th>\n",
       "      <td>tfidf_236</td>\n",
       "      <td>0.005724</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>210</th>\n",
       "      <td>tfidf_210</td>\n",
       "      <td>0.005680</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>235</th>\n",
       "      <td>tfidf_235</td>\n",
       "      <td>0.005539</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>441</th>\n",
       "      <td>lemon</td>\n",
       "      <td>0.005489</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>433</th>\n",
       "      <td>diesel</td>\n",
       "      <td>0.005460</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>151</th>\n",
       "      <td>tfidf_151</td>\n",
       "      <td>0.005333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>156</th>\n",
       "      <td>tfidf_156</td>\n",
       "      <td>0.005231</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>460</th>\n",
       "      <td>sweet</td>\n",
       "      <td>0.005178</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>362</th>\n",
       "      <td>tfidf_362</td>\n",
       "      <td>0.005170</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>93</th>\n",
       "      <td>tfidf_93</td>\n",
       "      <td>0.005137</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>424</th>\n",
       "      <td>berry</td>\n",
       "      <td>0.005091</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>323</th>\n",
       "      <td>tfidf_323</td>\n",
       "      <td>0.004968</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>358</th>\n",
       "      <td>tfidf_358</td>\n",
       "      <td>0.004886</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>340</th>\n",
       "      <td>tfidf_340</td>\n",
       "      <td>0.004718</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>tfidf_23</td>\n",
       "      <td>0.004647</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>409</th>\n",
       "      <td>hungry</td>\n",
       "      <td>0.004628</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>234</th>\n",
       "      <td>tfidf_234</td>\n",
       "      <td>0.004608</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>200</th>\n",
       "      <td>tfidf_200</td>\n",
       "      <td>0.004408</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>285</th>\n",
       "      <td>tfidf_285</td>\n",
       "      <td>0.004325</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>418</th>\n",
       "      <td>talkative</td>\n",
       "      <td>0.004308</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>80</th>\n",
       "      <td>tfidf_80</td>\n",
       "      <td>0.004205</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>376</th>\n",
       "      <td>tfidf_376</td>\n",
       "      <td>0.004174</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>69</th>\n",
       "      <td>tfidf_69</td>\n",
       "      <td>0.004091</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>199</th>\n",
       "      <td>tfidf_199</td>\n",
       "      <td>0.004066</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>413</th>\n",
       "      <td>relaxed</td>\n",
       "      <td>0.004062</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>105</th>\n",
       "      <td>tfidf_105</td>\n",
       "      <td>0.003941</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>300</th>\n",
       "      <td>tfidf_300</td>\n",
       "      <td>0.003926</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>tfidf_4</td>\n",
       "      <td>0.003924</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>144</th>\n",
       "      <td>tfidf_144</td>\n",
       "      <td>0.003767</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>405</th>\n",
       "      <td>focused</td>\n",
       "      <td>0.003721</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>281</th>\n",
       "      <td>tfidf_281</td>\n",
       "      <td>0.003579</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>366</th>\n",
       "      <td>tfidf_366</td>\n",
       "      <td>0.003578</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>207</th>\n",
       "      <td>tfidf_207</td>\n",
       "      <td>0.003557</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>402</th>\n",
       "      <td>euphoric</td>\n",
       "      <td>0.003509</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>272</th>\n",
       "      <td>tfidf_272</td>\n",
       "      <td>0.003494</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>400</th>\n",
       "      <td>energetic</td>\n",
       "      <td>0.003482</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>415</th>\n",
       "      <td>sleepy</td>\n",
       "      <td>0.003479</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>tfidf_7</td>\n",
       "      <td>0.003477</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>431</th>\n",
       "      <td>citrus</td>\n",
       "      <td>0.003457</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>351</th>\n",
       "      <td>tfidf_351</td>\n",
       "      <td>0.003335</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>428</th>\n",
       "      <td>cheese</td>\n",
       "      <td>0.003252</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>162</th>\n",
       "      <td>tfidf_162</td>\n",
       "      <td>0.003200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>420</th>\n",
       "      <td>uplifted</td>\n",
       "      <td>0.003181</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>150</th>\n",
       "      <td>tfidf_150</td>\n",
       "      <td>0.003166</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>tfidf_30</td>\n",
       "      <td>0.003127</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>380</th>\n",
       "      <td>tfidf_380</td>\n",
       "      <td>0.003121</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>193</th>\n",
       "      <td>tfidf_193</td>\n",
       "      <td>0.003055</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>395</th>\n",
       "      <td>creative</td>\n",
       "      <td>0.003049</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>222</th>\n",
       "      <td>tfidf_222</td>\n",
       "      <td>0.002993</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>442</th>\n",
       "      <td>lime</td>\n",
       "      <td>0.002913</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>251</th>\n",
       "      <td>tfidf_251</td>\n",
       "      <td>0.002902</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>181</th>\n",
       "      <td>tfidf_181</td>\n",
       "      <td>0.002816</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>407</th>\n",
       "      <td>happy</td>\n",
       "      <td>0.002790</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>338</th>\n",
       "      <td>tfidf_338</td>\n",
       "      <td>0.002761</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>253</th>\n",
       "      <td>tfidf_253</td>\n",
       "      <td>0.002746</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>276</th>\n",
       "      <td>tfidf_276</td>\n",
       "      <td>0.002708</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>319</th>\n",
       "      <td>tfidf_319</td>\n",
       "      <td>0.002670</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>386</th>\n",
       "      <td>tfidf_386</td>\n",
       "      <td>0.002634</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>111</th>\n",
       "      <td>tfidf_111</td>\n",
       "      <td>0.002610</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>128</th>\n",
       "      <td>tfidf_128</td>\n",
       "      <td>0.002566</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>277</th>\n",
       "      <td>tfidf_277</td>\n",
       "      <td>0.002545</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>158</th>\n",
       "      <td>tfidf_158</td>\n",
       "      <td>0.002531</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>434</th>\n",
       "      <td>earthy</td>\n",
       "      <td>0.002449</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>119</th>\n",
       "      <td>tfidf_119</td>\n",
       "      <td>0.002405</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>371</th>\n",
       "      <td>tfidf_371</td>\n",
       "      <td>0.002398</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>tfidf_26</td>\n",
       "      <td>0.002358</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>375</th>\n",
       "      <td>tfidf_375</td>\n",
       "      <td>0.002343</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>333</th>\n",
       "      <td>tfidf_333</td>\n",
       "      <td>0.002342</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>167</th>\n",
       "      <td>tfidf_167</td>\n",
       "      <td>0.002325</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51</th>\n",
       "      <td>tfidf_51</td>\n",
       "      <td>0.002321</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>86</th>\n",
       "      <td>tfidf_86</td>\n",
       "      <td>0.002320</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>tfidf_37</td>\n",
       "      <td>0.002286</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>399</th>\n",
       "      <td>dry mouth</td>\n",
       "      <td>0.002275</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>258</th>\n",
       "      <td>tfidf_258</td>\n",
       "      <td>0.002259</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>342</th>\n",
       "      <td>tfidf_342</td>\n",
       "      <td>0.002256</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>73</th>\n",
       "      <td>tfidf_73</td>\n",
       "      <td>0.002213</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>445</th>\n",
       "      <td>mint</td>\n",
       "      <td>0.002199</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>tfidf_48</td>\n",
       "      <td>0.002145</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>314</th>\n",
       "      <td>tfidf_314</td>\n",
       "      <td>0.002097</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>291</th>\n",
       "      <td>tfidf_291</td>\n",
       "      <td>0.002095</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>426</th>\n",
       "      <td>blueberry</td>\n",
       "      <td>0.002081</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>437</th>\n",
       "      <td>grape</td>\n",
       "      <td>0.002062</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53</th>\n",
       "      <td>tfidf_53</td>\n",
       "      <td>0.002060</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>226</th>\n",
       "      <td>tfidf_226</td>\n",
       "      <td>0.002055</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>tfidf_34</td>\n",
       "      <td>0.002038</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>337</th>\n",
       "      <td>tfidf_337</td>\n",
       "      <td>0.002002</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>457</th>\n",
       "      <td>skunk</td>\n",
       "      <td>0.001986</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>tfidf_21</td>\n",
       "      <td>0.001954</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>173</th>\n",
       "      <td>tfidf_173</td>\n",
       "      <td>0.001950</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>tfidf_46</td>\n",
       "      <td>0.001933</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>350</th>\n",
       "      <td>tfidf_350</td>\n",
       "      <td>0.001922</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>336</th>\n",
       "      <td>tfidf_336</td>\n",
       "      <td>0.001860</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>tfidf_43</td>\n",
       "      <td>0.001847</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>126</th>\n",
       "      <td>tfidf_126</td>\n",
       "      <td>0.001845</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>211</th>\n",
       "      <td>tfidf_211</td>\n",
       "      <td>0.001798</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>451</th>\n",
       "      <td>pine</td>\n",
       "      <td>0.001796</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>189</th>\n",
       "      <td>tfidf_189</td>\n",
       "      <td>0.001795</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>117</th>\n",
       "      <td>tfidf_117</td>\n",
       "      <td>0.001794</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>347</th>\n",
       "      <td>tfidf_347</td>\n",
       "      <td>0.001786</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>246</th>\n",
       "      <td>tfidf_246</td>\n",
       "      <td>0.001783</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>91</th>\n",
       "      <td>tfidf_91</td>\n",
       "      <td>0.001782</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>267</th>\n",
       "      <td>tfidf_267</td>\n",
       "      <td>0.001774</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>398</th>\n",
       "      <td>dry eyes</td>\n",
       "      <td>0.001758</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>tfidf_0</td>\n",
       "      <td>0.001745</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>170</th>\n",
       "      <td>tfidf_170</td>\n",
       "      <td>0.001724</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>456</th>\n",
       "      <td>sage</td>\n",
       "      <td>0.001715</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>283</th>\n",
       "      <td>tfidf_283</td>\n",
       "      <td>0.001691</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>406</th>\n",
       "      <td>giggly</td>\n",
       "      <td>0.001671</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>353</th>\n",
       "      <td>tfidf_353</td>\n",
       "      <td>0.001599</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>146</th>\n",
       "      <td>tfidf_146</td>\n",
       "      <td>0.001576</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>419</th>\n",
       "      <td>tingly</td>\n",
       "      <td>0.001544</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>225</th>\n",
       "      <td>tfidf_225</td>\n",
       "      <td>0.001533</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>205</th>\n",
       "      <td>tfidf_205</td>\n",
       "      <td>0.001500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>325</th>\n",
       "      <td>tfidf_325</td>\n",
       "      <td>0.001484</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>82</th>\n",
       "      <td>tfidf_82</td>\n",
       "      <td>0.001481</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>tfidf_17</td>\n",
       "      <td>0.001474</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75</th>\n",
       "      <td>tfidf_75</td>\n",
       "      <td>0.001435</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>101</th>\n",
       "      <td>tfidf_101</td>\n",
       "      <td>0.001432</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>89</th>\n",
       "      <td>tfidf_89</td>\n",
       "      <td>0.001429</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>166</th>\n",
       "      <td>tfidf_166</td>\n",
       "      <td>0.001423</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>367</th>\n",
       "      <td>tfidf_367</td>\n",
       "      <td>0.001423</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>122</th>\n",
       "      <td>tfidf_122</td>\n",
       "      <td>0.001414</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>343</th>\n",
       "      <td>tfidf_343</td>\n",
       "      <td>0.001381</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>tfidf_22</td>\n",
       "      <td>0.001376</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>278</th>\n",
       "      <td>tfidf_278</td>\n",
       "      <td>0.001363</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>tfidf_96</td>\n",
       "      <td>0.001350</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>58</th>\n",
       "      <td>tfidf_58</td>\n",
       "      <td>0.001340</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>106</th>\n",
       "      <td>tfidf_106</td>\n",
       "      <td>0.001333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>tfidf_98</td>\n",
       "      <td>0.001324</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>178</th>\n",
       "      <td>tfidf_178</td>\n",
       "      <td>0.001321</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>321</th>\n",
       "      <td>tfidf_321</td>\n",
       "      <td>0.001308</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>72</th>\n",
       "      <td>tfidf_72</td>\n",
       "      <td>0.001297</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>233</th>\n",
       "      <td>tfidf_233</td>\n",
       "      <td>0.001293</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>382</th>\n",
       "      <td>tfidf_382</td>\n",
       "      <td>0.001258</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>190</th>\n",
       "      <td>tfidf_190</td>\n",
       "      <td>0.001248</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>318</th>\n",
       "      <td>tfidf_318</td>\n",
       "      <td>0.001240</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>171</th>\n",
       "      <td>tfidf_171</td>\n",
       "      <td>0.001232</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>133</th>\n",
       "      <td>tfidf_133</td>\n",
       "      <td>0.001219</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>64</th>\n",
       "      <td>tfidf_64</td>\n",
       "      <td>0.001214</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>tfidf_41</td>\n",
       "      <td>0.001211</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>tfidf_11</td>\n",
       "      <td>0.001210</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>221</th>\n",
       "      <td>tfidf_221</td>\n",
       "      <td>0.001206</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>303</th>\n",
       "      <td>tfidf_303</td>\n",
       "      <td>0.001202</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>286</th>\n",
       "      <td>tfidf_286</td>\n",
       "      <td>0.001191</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>381</th>\n",
       "      <td>tfidf_381</td>\n",
       "      <td>0.001164</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>tfidf_3</td>\n",
       "      <td>0.001158</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>123</th>\n",
       "      <td>tfidf_123</td>\n",
       "      <td>0.001157</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>374</th>\n",
       "      <td>tfidf_374</td>\n",
       "      <td>0.001143</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>tfidf_20</td>\n",
       "      <td>0.001137</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>154</th>\n",
       "      <td>tfidf_154</td>\n",
       "      <td>0.001103</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>454</th>\n",
       "      <td>pungent</td>\n",
       "      <td>0.001072</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>61</th>\n",
       "      <td>tfidf_61</td>\n",
       "      <td>0.001070</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>88</th>\n",
       "      <td>tfidf_88</td>\n",
       "      <td>0.001038</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>264</th>\n",
       "      <td>tfidf_264</td>\n",
       "      <td>0.001037</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>203</th>\n",
       "      <td>tfidf_203</td>\n",
       "      <td>0.001035</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>370</th>\n",
       "      <td>tfidf_370</td>\n",
       "      <td>0.001033</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>85</th>\n",
       "      <td>tfidf_85</td>\n",
       "      <td>0.001025</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>209</th>\n",
       "      <td>tfidf_209</td>\n",
       "      <td>0.001024</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>65</th>\n",
       "      <td>tfidf_65</td>\n",
       "      <td>0.001019</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>425</th>\n",
       "      <td>blue cheese</td>\n",
       "      <td>0.001007</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>tfidf_24</td>\n",
       "      <td>0.001004</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>tfidf_9</td>\n",
       "      <td>0.000998</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>tfidf_95</td>\n",
       "      <td>0.000998</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>334</th>\n",
       "      <td>tfidf_334</td>\n",
       "      <td>0.000988</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>230</th>\n",
       "      <td>tfidf_230</td>\n",
       "      <td>0.000953</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>tfidf_5</td>\n",
       "      <td>0.000950</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>130</th>\n",
       "      <td>tfidf_130</td>\n",
       "      <td>0.000949</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>107</th>\n",
       "      <td>tfidf_107</td>\n",
       "      <td>0.000945</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>262</th>\n",
       "      <td>tfidf_262</td>\n",
       "      <td>0.000939</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>273</th>\n",
       "      <td>tfidf_273</td>\n",
       "      <td>0.000921</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>191</th>\n",
       "      <td>tfidf_191</td>\n",
       "      <td>0.000912</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>393</th>\n",
       "      <td>aroused</td>\n",
       "      <td>0.000908</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>188</th>\n",
       "      <td>tfidf_188</td>\n",
       "      <td>0.000903</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>369</th>\n",
       "      <td>tfidf_369</td>\n",
       "      <td>0.000876</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>71</th>\n",
       "      <td>tfidf_71</td>\n",
       "      <td>0.000863</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>124</th>\n",
       "      <td>tfidf_124</td>\n",
       "      <td>0.000861</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>304</th>\n",
       "      <td>tfidf_304</td>\n",
       "      <td>0.000860</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>104</th>\n",
       "      <td>tfidf_104</td>\n",
       "      <td>0.000839</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>206</th>\n",
       "      <td>tfidf_206</td>\n",
       "      <td>0.000833</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>289</th>\n",
       "      <td>tfidf_289</td>\n",
       "      <td>0.000833</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>94</th>\n",
       "      <td>tfidf_94</td>\n",
       "      <td>0.000819</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>385</th>\n",
       "      <td>tfidf_385</td>\n",
       "      <td>0.000814</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>112</th>\n",
       "      <td>tfidf_112</td>\n",
       "      <td>0.000814</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>139</th>\n",
       "      <td>tfidf_139</td>\n",
       "      <td>0.000805</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>354</th>\n",
       "      <td>tfidf_354</td>\n",
       "      <td>0.000788</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>57</th>\n",
       "      <td>tfidf_57</td>\n",
       "      <td>0.000787</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>468</th>\n",
       "      <td>woody</td>\n",
       "      <td>0.000785</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>348</th>\n",
       "      <td>tfidf_348</td>\n",
       "      <td>0.000783</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>237</th>\n",
       "      <td>tfidf_237</td>\n",
       "      <td>0.000765</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>224</th>\n",
       "      <td>tfidf_224</td>\n",
       "      <td>0.000750</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>132</th>\n",
       "      <td>tfidf_132</td>\n",
       "      <td>0.000741</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>208</th>\n",
       "      <td>tfidf_208</td>\n",
       "      <td>0.000738</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>136</th>\n",
       "      <td>tfidf_136</td>\n",
       "      <td>0.000729</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>397</th>\n",
       "      <td>dizzy</td>\n",
       "      <td>0.000714</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>412</th>\n",
       "      <td>paranoid</td>\n",
       "      <td>0.000711</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>103</th>\n",
       "      <td>tfidf_103</td>\n",
       "      <td>0.000706</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>195</th>\n",
       "      <td>tfidf_195</td>\n",
       "      <td>0.000705</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>365</th>\n",
       "      <td>tfidf_365</td>\n",
       "      <td>0.000705</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>464</th>\n",
       "      <td>tree</td>\n",
       "      <td>0.000700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>344</th>\n",
       "      <td>tfidf_344</td>\n",
       "      <td>0.000690</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>116</th>\n",
       "      <td>tfidf_116</td>\n",
       "      <td>0.000690</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54</th>\n",
       "      <td>tfidf_54</td>\n",
       "      <td>0.000682</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>129</th>\n",
       "      <td>tfidf_129</td>\n",
       "      <td>0.000674</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>tfidf_16</td>\n",
       "      <td>0.000672</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>tfidf_27</td>\n",
       "      <td>0.000669</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>tfidf_2</td>\n",
       "      <td>0.000669</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>83</th>\n",
       "      <td>tfidf_83</td>\n",
       "      <td>0.000667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>216</th>\n",
       "      <td>tfidf_216</td>\n",
       "      <td>0.000658</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>341</th>\n",
       "      <td>tfidf_341</td>\n",
       "      <td>0.000651</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>360</th>\n",
       "      <td>tfidf_360</td>\n",
       "      <td>0.000644</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>186</th>\n",
       "      <td>tfidf_186</td>\n",
       "      <td>0.000629</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>194</th>\n",
       "      <td>tfidf_194</td>\n",
       "      <td>0.000629</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>tfidf_49</td>\n",
       "      <td>0.000628</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>153</th>\n",
       "      <td>tfidf_153</td>\n",
       "      <td>0.000627</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>240</th>\n",
       "      <td>tfidf_240</td>\n",
       "      <td>0.000615</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>179</th>\n",
       "      <td>tfidf_179</td>\n",
       "      <td>0.000611</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>66</th>\n",
       "      <td>tfidf_66</td>\n",
       "      <td>0.000590</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>292</th>\n",
       "      <td>tfidf_292</td>\n",
       "      <td>0.000590</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>217</th>\n",
       "      <td>tfidf_217</td>\n",
       "      <td>0.000589</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>373</th>\n",
       "      <td>tfidf_373</td>\n",
       "      <td>0.000586</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>152</th>\n",
       "      <td>tfidf_152</td>\n",
       "      <td>0.000585</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>196</th>\n",
       "      <td>tfidf_196</td>\n",
       "      <td>0.000584</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>450</th>\n",
       "      <td>pepper</td>\n",
       "      <td>0.000580</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>187</th>\n",
       "      <td>tfidf_187</td>\n",
       "      <td>0.000577</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>438</th>\n",
       "      <td>grapefruit</td>\n",
       "      <td>0.000575</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>184</th>\n",
       "      <td>tfidf_184</td>\n",
       "      <td>0.000572</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>tfidf_19</td>\n",
       "      <td>0.000562</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52</th>\n",
       "      <td>tfidf_52</td>\n",
       "      <td>0.000548</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>320</th>\n",
       "      <td>tfidf_320</td>\n",
       "      <td>0.000543</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>138</th>\n",
       "      <td>tfidf_138</td>\n",
       "      <td>0.000542</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>183</th>\n",
       "      <td>tfidf_183</td>\n",
       "      <td>0.000539</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>tfidf_1</td>\n",
       "      <td>0.000539</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>408</th>\n",
       "      <td>headache</td>\n",
       "      <td>0.000538</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>227</th>\n",
       "      <td>tfidf_227</td>\n",
       "      <td>0.000537</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>180</th>\n",
       "      <td>tfidf_180</td>\n",
       "      <td>0.000536</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>tfidf_44</td>\n",
       "      <td>0.000523</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>tfidf_28</td>\n",
       "      <td>0.000518</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>232</th>\n",
       "      <td>tfidf_232</td>\n",
       "      <td>0.000516</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>317</th>\n",
       "      <td>tfidf_317</td>\n",
       "      <td>0.000516</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>349</th>\n",
       "      <td>tfidf_349</td>\n",
       "      <td>0.000508</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>429</th>\n",
       "      <td>chemical</td>\n",
       "      <td>0.000506</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>356</th>\n",
       "      <td>tfidf_356</td>\n",
       "      <td>0.000504</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>363</th>\n",
       "      <td>tfidf_363</td>\n",
       "      <td>0.000503</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>228</th>\n",
       "      <td>tfidf_228</td>\n",
       "      <td>0.000498</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>311</th>\n",
       "      <td>tfidf_311</td>\n",
       "      <td>0.000493</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>297</th>\n",
       "      <td>tfidf_297</td>\n",
       "      <td>0.000487</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>tfidf_14</td>\n",
       "      <td>0.000484</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>270</th>\n",
       "      <td>tfidf_270</td>\n",
       "      <td>0.000481</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>110</th>\n",
       "      <td>tfidf_110</td>\n",
       "      <td>0.000479</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>435</th>\n",
       "      <td>flowery</td>\n",
       "      <td>0.000477</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>243</th>\n",
       "      <td>tfidf_243</td>\n",
       "      <td>0.000476</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>202</th>\n",
       "      <td>tfidf_202</td>\n",
       "      <td>0.000473</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>tfidf_31</td>\n",
       "      <td>0.000473</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>159</th>\n",
       "      <td>tfidf_159</td>\n",
       "      <td>0.000471</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>169</th>\n",
       "      <td>tfidf_169</td>\n",
       "      <td>0.000469</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>201</th>\n",
       "      <td>tfidf_201</td>\n",
       "      <td>0.000465</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>tfidf_45</td>\n",
       "      <td>0.000463</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>tfidf_39</td>\n",
       "      <td>0.000461</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>120</th>\n",
       "      <td>tfidf_120</td>\n",
       "      <td>0.000453</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>301</th>\n",
       "      <td>tfidf_301</td>\n",
       "      <td>0.000450</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>387</th>\n",
       "      <td>tfidf_387</td>\n",
       "      <td>0.000450</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>372</th>\n",
       "      <td>tfidf_372</td>\n",
       "      <td>0.000438</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>332</th>\n",
       "      <td>tfidf_332</td>\n",
       "      <td>0.000433</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>308</th>\n",
       "      <td>tfidf_308</td>\n",
       "      <td>0.000432</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>90</th>\n",
       "      <td>tfidf_90</td>\n",
       "      <td>0.000431</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>255</th>\n",
       "      <td>tfidf_255</td>\n",
       "      <td>0.000425</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>147</th>\n",
       "      <td>tfidf_147</td>\n",
       "      <td>0.000424</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>tfidf_6</td>\n",
       "      <td>0.000418</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>247</th>\n",
       "      <td>tfidf_247</td>\n",
       "      <td>0.000418</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>242</th>\n",
       "      <td>tfidf_242</td>\n",
       "      <td>0.000415</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>461</th>\n",
       "      <td>tar</td>\n",
       "      <td>0.000415</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>458</th>\n",
       "      <td>spicy/herbal</td>\n",
       "      <td>0.000414</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>tfidf_40</td>\n",
       "      <td>0.000413</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>215</th>\n",
       "      <td>tfidf_215</td>\n",
       "      <td>0.000410</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>368</th>\n",
       "      <td>tfidf_368</td>\n",
       "      <td>0.000410</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>316</th>\n",
       "      <td>tfidf_316</td>\n",
       "      <td>0.000408</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>62</th>\n",
       "      <td>tfidf_62</td>\n",
       "      <td>0.000408</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>269</th>\n",
       "      <td>tfidf_269</td>\n",
       "      <td>0.000407</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>131</th>\n",
       "      <td>tfidf_131</td>\n",
       "      <td>0.000400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>307</th>\n",
       "      <td>tfidf_307</td>\n",
       "      <td>0.000397</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>444</th>\n",
       "      <td>menthol</td>\n",
       "      <td>0.000395</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>280</th>\n",
       "      <td>tfidf_280</td>\n",
       "      <td>0.000392</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>260</th>\n",
       "      <td>tfidf_260</td>\n",
       "      <td>0.000392</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>198</th>\n",
       "      <td>tfidf_198</td>\n",
       "      <td>0.000392</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>439</th>\n",
       "      <td>honey</td>\n",
       "      <td>0.000392</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>79</th>\n",
       "      <td>tfidf_79</td>\n",
       "      <td>0.000390</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>tfidf_10</td>\n",
       "      <td>0.000386</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>160</th>\n",
       "      <td>tfidf_160</td>\n",
       "      <td>0.000384</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>108</th>\n",
       "      <td>tfidf_108</td>\n",
       "      <td>0.000382</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>440</th>\n",
       "      <td>lavender</td>\n",
       "      <td>0.000374</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>223</th>\n",
       "      <td>tfidf_223</td>\n",
       "      <td>0.000374</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>379</th>\n",
       "      <td>tfidf_379</td>\n",
       "      <td>0.000369</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>346</th>\n",
       "      <td>tfidf_346</td>\n",
       "      <td>0.000369</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>148</th>\n",
       "      <td>tfidf_148</td>\n",
       "      <td>0.000368</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>56</th>\n",
       "      <td>tfidf_56</td>\n",
       "      <td>0.000364</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>310</th>\n",
       "      <td>tfidf_310</td>\n",
       "      <td>0.000362</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>436</th>\n",
       "      <td>fruit</td>\n",
       "      <td>0.000359</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>185</th>\n",
       "      <td>tfidf_185</td>\n",
       "      <td>0.000343</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>265</th>\n",
       "      <td>tfidf_265</td>\n",
       "      <td>0.000341</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>290</th>\n",
       "      <td>tfidf_290</td>\n",
       "      <td>0.000336</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>383</th>\n",
       "      <td>tfidf_383</td>\n",
       "      <td>0.000335</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>315</th>\n",
       "      <td>tfidf_315</td>\n",
       "      <td>0.000334</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>182</th>\n",
       "      <td>tfidf_182</td>\n",
       "      <td>0.000329</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>197</th>\n",
       "      <td>tfidf_197</td>\n",
       "      <td>0.000326</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>256</th>\n",
       "      <td>tfidf_256</td>\n",
       "      <td>0.000322</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>68</th>\n",
       "      <td>tfidf_68</td>\n",
       "      <td>0.000321</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>76</th>\n",
       "      <td>tfidf_76</td>\n",
       "      <td>0.000321</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>219</th>\n",
       "      <td>tfidf_219</td>\n",
       "      <td>0.000319</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>125</th>\n",
       "      <td>tfidf_125</td>\n",
       "      <td>0.000319</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>164</th>\n",
       "      <td>tfidf_164</td>\n",
       "      <td>0.000316</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>192</th>\n",
       "      <td>tfidf_192</td>\n",
       "      <td>0.000315</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>102</th>\n",
       "      <td>tfidf_102</td>\n",
       "      <td>0.000312</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>389</th>\n",
       "      <td>indica</td>\n",
       "      <td>0.000311</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>298</th>\n",
       "      <td>tfidf_298</td>\n",
       "      <td>0.000308</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>tfidf_15</td>\n",
       "      <td>0.000308</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>55</th>\n",
       "      <td>tfidf_55</td>\n",
       "      <td>0.000307</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>359</th>\n",
       "      <td>tfidf_359</td>\n",
       "      <td>0.000304</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>364</th>\n",
       "      <td>tfidf_364</td>\n",
       "      <td>0.000303</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>299</th>\n",
       "      <td>tfidf_299</td>\n",
       "      <td>0.000302</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>463</th>\n",
       "      <td>tobacco</td>\n",
       "      <td>0.000299</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>331</th>\n",
       "      <td>tfidf_331</td>\n",
       "      <td>0.000298</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>213</th>\n",
       "      <td>tfidf_213</td>\n",
       "      <td>0.000297</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>294</th>\n",
       "      <td>tfidf_294</td>\n",
       "      <td>0.000297</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>263</th>\n",
       "      <td>tfidf_263</td>\n",
       "      <td>0.000296</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>271</th>\n",
       "      <td>tfidf_271</td>\n",
       "      <td>0.000295</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>252</th>\n",
       "      <td>tfidf_252</td>\n",
       "      <td>0.000292</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>259</th>\n",
       "      <td>tfidf_259</td>\n",
       "      <td>0.000289</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>81</th>\n",
       "      <td>tfidf_81</td>\n",
       "      <td>0.000289</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>432</th>\n",
       "      <td>coffee</td>\n",
       "      <td>0.000287</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>421</th>\n",
       "      <td>ammonia</td>\n",
       "      <td>0.000287</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>392</th>\n",
       "      <td>anxious</td>\n",
       "      <td>0.000282</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>326</th>\n",
       "      <td>tfidf_326</td>\n",
       "      <td>0.000280</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>446</th>\n",
       "      <td>nutty</td>\n",
       "      <td>0.000279</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>282</th>\n",
       "      <td>tfidf_282</td>\n",
       "      <td>0.000276</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>352</th>\n",
       "      <td>tfidf_352</td>\n",
       "      <td>0.000270</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>430</th>\n",
       "      <td>chestnut</td>\n",
       "      <td>0.000270</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>268</th>\n",
       "      <td>tfidf_268</td>\n",
       "      <td>0.000268</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>135</th>\n",
       "      <td>tfidf_135</td>\n",
       "      <td>0.000267</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>231</th>\n",
       "      <td>tfidf_231</td>\n",
       "      <td>0.000266</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>212</th>\n",
       "      <td>tfidf_212</td>\n",
       "      <td>0.000266</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>293</th>\n",
       "      <td>tfidf_293</td>\n",
       "      <td>0.000266</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>220</th>\n",
       "      <td>tfidf_220</td>\n",
       "      <td>0.000264</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>443</th>\n",
       "      <td>mango</td>\n",
       "      <td>0.000262</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>tfidf_29</td>\n",
       "      <td>0.000262</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>257</th>\n",
       "      <td>tfidf_257</td>\n",
       "      <td>0.000262</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>177</th>\n",
       "      <td>tfidf_177</td>\n",
       "      <td>0.000259</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>tfidf_8</td>\n",
       "      <td>0.000259</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>459</th>\n",
       "      <td>strawberry</td>\n",
       "      <td>0.000257</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>249</th>\n",
       "      <td>tfidf_249</td>\n",
       "      <td>0.000252</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>155</th>\n",
       "      <td>tfidf_155</td>\n",
       "      <td>0.000251</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>tfidf_12</td>\n",
       "      <td>0.000250</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>313</th>\n",
       "      <td>tfidf_313</td>\n",
       "      <td>0.000250</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>143</th>\n",
       "      <td>tfidf_143</td>\n",
       "      <td>0.000250</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>113</th>\n",
       "      <td>tfidf_113</td>\n",
       "      <td>0.000250</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>274</th>\n",
       "      <td>tfidf_274</td>\n",
       "      <td>0.000247</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>tfidf_35</td>\n",
       "      <td>0.000241</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>448</th>\n",
       "      <td>peach</td>\n",
       "      <td>0.000240</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>70</th>\n",
       "      <td>tfidf_70</td>\n",
       "      <td>0.000238</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>287</th>\n",
       "      <td>tfidf_287</td>\n",
       "      <td>0.000237</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>335</th>\n",
       "      <td>tfidf_335</td>\n",
       "      <td>0.000233</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>361</th>\n",
       "      <td>tfidf_361</td>\n",
       "      <td>0.000232</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>127</th>\n",
       "      <td>tfidf_127</td>\n",
       "      <td>0.000230</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>302</th>\n",
       "      <td>tfidf_302</td>\n",
       "      <td>0.000224</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>109</th>\n",
       "      <td>tfidf_109</td>\n",
       "      <td>0.000223</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>324</th>\n",
       "      <td>tfidf_324</td>\n",
       "      <td>0.000223</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>465</th>\n",
       "      <td>tropical</td>\n",
       "      <td>0.000223</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>455</th>\n",
       "      <td>rose</td>\n",
       "      <td>0.000222</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>60</th>\n",
       "      <td>tfidf_60</td>\n",
       "      <td>0.000222</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>tfidf_33</td>\n",
       "      <td>0.000222</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>377</th>\n",
       "      <td>tfidf_377</td>\n",
       "      <td>0.000220</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>67</th>\n",
       "      <td>tfidf_67</td>\n",
       "      <td>0.000220</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>118</th>\n",
       "      <td>tfidf_118</td>\n",
       "      <td>0.000213</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>279</th>\n",
       "      <td>tfidf_279</td>\n",
       "      <td>0.000213</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>140</th>\n",
       "      <td>tfidf_140</td>\n",
       "      <td>0.000212</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>137</th>\n",
       "      <td>tfidf_137</td>\n",
       "      <td>0.000207</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>77</th>\n",
       "      <td>tfidf_77</td>\n",
       "      <td>0.000206</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>214</th>\n",
       "      <td>tfidf_214</td>\n",
       "      <td>0.000206</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>63</th>\n",
       "      <td>tfidf_63</td>\n",
       "      <td>0.000205</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>84</th>\n",
       "      <td>tfidf_84</td>\n",
       "      <td>0.000203</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>328</th>\n",
       "      <td>tfidf_328</td>\n",
       "      <td>0.000196</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>275</th>\n",
       "      <td>tfidf_275</td>\n",
       "      <td>0.000194</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>176</th>\n",
       "      <td>tfidf_176</td>\n",
       "      <td>0.000192</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>248</th>\n",
       "      <td>tfidf_248</td>\n",
       "      <td>0.000188</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>tfidf_99</td>\n",
       "      <td>0.000186</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>295</th>\n",
       "      <td>tfidf_295</td>\n",
       "      <td>0.000183</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>238</th>\n",
       "      <td>tfidf_238</td>\n",
       "      <td>0.000182</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>384</th>\n",
       "      <td>tfidf_384</td>\n",
       "      <td>0.000182</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50</th>\n",
       "      <td>tfidf_50</td>\n",
       "      <td>0.000180</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59</th>\n",
       "      <td>tfidf_59</td>\n",
       "      <td>0.000176</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>tfidf_47</td>\n",
       "      <td>0.000173</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>204</th>\n",
       "      <td>tfidf_204</td>\n",
       "      <td>0.000170</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>330</th>\n",
       "      <td>tfidf_330</td>\n",
       "      <td>0.000168</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>254</th>\n",
       "      <td>tfidf_254</td>\n",
       "      <td>0.000166</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>172</th>\n",
       "      <td>tfidf_172</td>\n",
       "      <td>0.000165</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>100</th>\n",
       "      <td>tfidf_100</td>\n",
       "      <td>0.000164</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>tfidf_25</td>\n",
       "      <td>0.000159</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>87</th>\n",
       "      <td>tfidf_87</td>\n",
       "      <td>0.000157</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>tfidf_38</td>\n",
       "      <td>0.000151</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>229</th>\n",
       "      <td>tfidf_229</td>\n",
       "      <td>0.000150</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>244</th>\n",
       "      <td>tfidf_244</td>\n",
       "      <td>0.000149</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>134</th>\n",
       "      <td>tfidf_134</td>\n",
       "      <td>0.000140</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>378</th>\n",
       "      <td>tfidf_378</td>\n",
       "      <td>0.000138</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>tfidf_42</td>\n",
       "      <td>0.000137</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>261</th>\n",
       "      <td>tfidf_261</td>\n",
       "      <td>0.000134</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>tfidf_36</td>\n",
       "      <td>0.000133</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>339</th>\n",
       "      <td>tfidf_339</td>\n",
       "      <td>0.000129</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>305</th>\n",
       "      <td>tfidf_305</td>\n",
       "      <td>0.000129</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>115</th>\n",
       "      <td>tfidf_115</td>\n",
       "      <td>0.000121</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>327</th>\n",
       "      <td>tfidf_327</td>\n",
       "      <td>0.000121</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>284</th>\n",
       "      <td>tfidf_284</td>\n",
       "      <td>0.000119</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>142</th>\n",
       "      <td>tfidf_142</td>\n",
       "      <td>0.000116</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>tfidf_13</td>\n",
       "      <td>0.000113</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>tfidf_18</td>\n",
       "      <td>0.000111</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>114</th>\n",
       "      <td>tfidf_114</td>\n",
       "      <td>0.000111</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>266</th>\n",
       "      <td>tfidf_266</td>\n",
       "      <td>0.000110</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>322</th>\n",
       "      <td>tfidf_322</td>\n",
       "      <td>0.000108</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>92</th>\n",
       "      <td>tfidf_92</td>\n",
       "      <td>0.000097</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>296</th>\n",
       "      <td>tfidf_296</td>\n",
       "      <td>0.000094</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>422</th>\n",
       "      <td>apple</td>\n",
       "      <td>0.000094</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>462</th>\n",
       "      <td>tea</td>\n",
       "      <td>0.000086</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>452</th>\n",
       "      <td>pineapple</td>\n",
       "      <td>0.000075</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>74</th>\n",
       "      <td>tfidf_74</td>\n",
       "      <td>0.000074</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>241</th>\n",
       "      <td>tfidf_241</td>\n",
       "      <td>0.000067</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>174</th>\n",
       "      <td>tfidf_174</td>\n",
       "      <td>0.000064</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>250</th>\n",
       "      <td>tfidf_250</td>\n",
       "      <td>0.000060</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>453</th>\n",
       "      <td>plum</td>\n",
       "      <td>0.000049</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>306</th>\n",
       "      <td>tfidf_306</td>\n",
       "      <td>0.000048</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>427</th>\n",
       "      <td>butter</td>\n",
       "      <td>0.000038</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>396</th>\n",
       "      <td>depression</td>\n",
       "      <td>0.000033</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>449</th>\n",
       "      <td>pear</td>\n",
       "      <td>0.000027</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>423</th>\n",
       "      <td>apricot</td>\n",
       "      <td>0.000024</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>410</th>\n",
       "      <td>migraines</td>\n",
       "      <td>0.000020</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>391</th>\n",
       "      <td>anxiety</td>\n",
       "      <td>0.000016</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>467</th>\n",
       "      <td>violet</td>\n",
       "      <td>0.000007</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>394</th>\n",
       "      <td>arthritis</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>417</th>\n",
       "      <td>stress</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>416</th>\n",
       "      <td>spasticity</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>414</th>\n",
       "      <td>seizures</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>401</th>\n",
       "      <td>epilepsy</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>403</th>\n",
       "      <td>eye pressure</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>411</th>\n",
       "      <td>pain</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>404</th>\n",
       "      <td>fatigue</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         features     score\n",
       "390        sativa  0.209317\n",
       "466       vanilla  0.036270\n",
       "388        hybrid  0.029427\n",
       "288     tfidf_288  0.014485\n",
       "329     tfidf_329  0.013169\n",
       "149     tfidf_149  0.013019\n",
       "447        orange  0.012127\n",
       "312     tfidf_312  0.011865\n",
       "145     tfidf_145  0.011202\n",
       "345     tfidf_345  0.009993\n",
       "161     tfidf_161  0.009905\n",
       "165     tfidf_165  0.009605\n",
       "168     tfidf_168  0.009546\n",
       "97       tfidf_97  0.008829\n",
       "141     tfidf_141  0.008448\n",
       "121     tfidf_121  0.007916\n",
       "218     tfidf_218  0.007844\n",
       "78       tfidf_78  0.007750\n",
       "163     tfidf_163  0.007605\n",
       "355     tfidf_355  0.007531\n",
       "175     tfidf_175  0.006981\n",
       "309     tfidf_309  0.006891\n",
       "239     tfidf_239  0.006684\n",
       "357     tfidf_357  0.006631\n",
       "157     tfidf_157  0.006567\n",
       "245     tfidf_245  0.006146\n",
       "32       tfidf_32  0.006009\n",
       "236     tfidf_236  0.005724\n",
       "210     tfidf_210  0.005680\n",
       "235     tfidf_235  0.005539\n",
       "441         lemon  0.005489\n",
       "433        diesel  0.005460\n",
       "151     tfidf_151  0.005333\n",
       "156     tfidf_156  0.005231\n",
       "460         sweet  0.005178\n",
       "362     tfidf_362  0.005170\n",
       "93       tfidf_93  0.005137\n",
       "424         berry  0.005091\n",
       "323     tfidf_323  0.004968\n",
       "358     tfidf_358  0.004886\n",
       "340     tfidf_340  0.004718\n",
       "23       tfidf_23  0.004647\n",
       "409        hungry  0.004628\n",
       "234     tfidf_234  0.004608\n",
       "200     tfidf_200  0.004408\n",
       "285     tfidf_285  0.004325\n",
       "418     talkative  0.004308\n",
       "80       tfidf_80  0.004205\n",
       "376     tfidf_376  0.004174\n",
       "69       tfidf_69  0.004091\n",
       "199     tfidf_199  0.004066\n",
       "413       relaxed  0.004062\n",
       "105     tfidf_105  0.003941\n",
       "300     tfidf_300  0.003926\n",
       "4         tfidf_4  0.003924\n",
       "144     tfidf_144  0.003767\n",
       "405       focused  0.003721\n",
       "281     tfidf_281  0.003579\n",
       "366     tfidf_366  0.003578\n",
       "207     tfidf_207  0.003557\n",
       "402      euphoric  0.003509\n",
       "272     tfidf_272  0.003494\n",
       "400     energetic  0.003482\n",
       "415        sleepy  0.003479\n",
       "7         tfidf_7  0.003477\n",
       "431        citrus  0.003457\n",
       "351     tfidf_351  0.003335\n",
       "428        cheese  0.003252\n",
       "162     tfidf_162  0.003200\n",
       "420      uplifted  0.003181\n",
       "150     tfidf_150  0.003166\n",
       "30       tfidf_30  0.003127\n",
       "380     tfidf_380  0.003121\n",
       "193     tfidf_193  0.003055\n",
       "395      creative  0.003049\n",
       "222     tfidf_222  0.002993\n",
       "442          lime  0.002913\n",
       "251     tfidf_251  0.002902\n",
       "181     tfidf_181  0.002816\n",
       "407         happy  0.002790\n",
       "338     tfidf_338  0.002761\n",
       "253     tfidf_253  0.002746\n",
       "276     tfidf_276  0.002708\n",
       "319     tfidf_319  0.002670\n",
       "386     tfidf_386  0.002634\n",
       "111     tfidf_111  0.002610\n",
       "128     tfidf_128  0.002566\n",
       "277     tfidf_277  0.002545\n",
       "158     tfidf_158  0.002531\n",
       "434        earthy  0.002449\n",
       "119     tfidf_119  0.002405\n",
       "371     tfidf_371  0.002398\n",
       "26       tfidf_26  0.002358\n",
       "375     tfidf_375  0.002343\n",
       "333     tfidf_333  0.002342\n",
       "167     tfidf_167  0.002325\n",
       "51       tfidf_51  0.002321\n",
       "86       tfidf_86  0.002320\n",
       "37       tfidf_37  0.002286\n",
       "399     dry mouth  0.002275\n",
       "258     tfidf_258  0.002259\n",
       "342     tfidf_342  0.002256\n",
       "73       tfidf_73  0.002213\n",
       "445          mint  0.002199\n",
       "48       tfidf_48  0.002145\n",
       "314     tfidf_314  0.002097\n",
       "291     tfidf_291  0.002095\n",
       "426     blueberry  0.002081\n",
       "437         grape  0.002062\n",
       "53       tfidf_53  0.002060\n",
       "226     tfidf_226  0.002055\n",
       "34       tfidf_34  0.002038\n",
       "337     tfidf_337  0.002002\n",
       "457         skunk  0.001986\n",
       "21       tfidf_21  0.001954\n",
       "173     tfidf_173  0.001950\n",
       "46       tfidf_46  0.001933\n",
       "350     tfidf_350  0.001922\n",
       "336     tfidf_336  0.001860\n",
       "43       tfidf_43  0.001847\n",
       "126     tfidf_126  0.001845\n",
       "211     tfidf_211  0.001798\n",
       "451          pine  0.001796\n",
       "189     tfidf_189  0.001795\n",
       "117     tfidf_117  0.001794\n",
       "347     tfidf_347  0.001786\n",
       "246     tfidf_246  0.001783\n",
       "91       tfidf_91  0.001782\n",
       "267     tfidf_267  0.001774\n",
       "398      dry eyes  0.001758\n",
       "0         tfidf_0  0.001745\n",
       "170     tfidf_170  0.001724\n",
       "456          sage  0.001715\n",
       "283     tfidf_283  0.001691\n",
       "406        giggly  0.001671\n",
       "353     tfidf_353  0.001599\n",
       "146     tfidf_146  0.001576\n",
       "419        tingly  0.001544\n",
       "225     tfidf_225  0.001533\n",
       "205     tfidf_205  0.001500\n",
       "325     tfidf_325  0.001484\n",
       "82       tfidf_82  0.001481\n",
       "17       tfidf_17  0.001474\n",
       "75       tfidf_75  0.001435\n",
       "101     tfidf_101  0.001432\n",
       "89       tfidf_89  0.001429\n",
       "166     tfidf_166  0.001423\n",
       "367     tfidf_367  0.001423\n",
       "122     tfidf_122  0.001414\n",
       "343     tfidf_343  0.001381\n",
       "22       tfidf_22  0.001376\n",
       "278     tfidf_278  0.001363\n",
       "96       tfidf_96  0.001350\n",
       "58       tfidf_58  0.001340\n",
       "106     tfidf_106  0.001333\n",
       "98       tfidf_98  0.001324\n",
       "178     tfidf_178  0.001321\n",
       "321     tfidf_321  0.001308\n",
       "72       tfidf_72  0.001297\n",
       "233     tfidf_233  0.001293\n",
       "382     tfidf_382  0.001258\n",
       "190     tfidf_190  0.001248\n",
       "318     tfidf_318  0.001240\n",
       "171     tfidf_171  0.001232\n",
       "133     tfidf_133  0.001219\n",
       "64       tfidf_64  0.001214\n",
       "41       tfidf_41  0.001211\n",
       "11       tfidf_11  0.001210\n",
       "221     tfidf_221  0.001206\n",
       "303     tfidf_303  0.001202\n",
       "286     tfidf_286  0.001191\n",
       "381     tfidf_381  0.001164\n",
       "3         tfidf_3  0.001158\n",
       "123     tfidf_123  0.001157\n",
       "374     tfidf_374  0.001143\n",
       "20       tfidf_20  0.001137\n",
       "154     tfidf_154  0.001103\n",
       "454       pungent  0.001072\n",
       "61       tfidf_61  0.001070\n",
       "88       tfidf_88  0.001038\n",
       "264     tfidf_264  0.001037\n",
       "203     tfidf_203  0.001035\n",
       "370     tfidf_370  0.001033\n",
       "85       tfidf_85  0.001025\n",
       "209     tfidf_209  0.001024\n",
       "65       tfidf_65  0.001019\n",
       "425   blue cheese  0.001007\n",
       "24       tfidf_24  0.001004\n",
       "9         tfidf_9  0.000998\n",
       "95       tfidf_95  0.000998\n",
       "334     tfidf_334  0.000988\n",
       "230     tfidf_230  0.000953\n",
       "5         tfidf_5  0.000950\n",
       "130     tfidf_130  0.000949\n",
       "107     tfidf_107  0.000945\n",
       "262     tfidf_262  0.000939\n",
       "273     tfidf_273  0.000921\n",
       "191     tfidf_191  0.000912\n",
       "393       aroused  0.000908\n",
       "188     tfidf_188  0.000903\n",
       "369     tfidf_369  0.000876\n",
       "71       tfidf_71  0.000863\n",
       "124     tfidf_124  0.000861\n",
       "304     tfidf_304  0.000860\n",
       "104     tfidf_104  0.000839\n",
       "206     tfidf_206  0.000833\n",
       "289     tfidf_289  0.000833\n",
       "94       tfidf_94  0.000819\n",
       "385     tfidf_385  0.000814\n",
       "112     tfidf_112  0.000814\n",
       "139     tfidf_139  0.000805\n",
       "354     tfidf_354  0.000788\n",
       "57       tfidf_57  0.000787\n",
       "468         woody  0.000785\n",
       "348     tfidf_348  0.000783\n",
       "237     tfidf_237  0.000765\n",
       "224     tfidf_224  0.000750\n",
       "132     tfidf_132  0.000741\n",
       "208     tfidf_208  0.000738\n",
       "136     tfidf_136  0.000729\n",
       "397         dizzy  0.000714\n",
       "412      paranoid  0.000711\n",
       "103     tfidf_103  0.000706\n",
       "195     tfidf_195  0.000705\n",
       "365     tfidf_365  0.000705\n",
       "464          tree  0.000700\n",
       "344     tfidf_344  0.000690\n",
       "116     tfidf_116  0.000690\n",
       "54       tfidf_54  0.000682\n",
       "129     tfidf_129  0.000674\n",
       "16       tfidf_16  0.000672\n",
       "27       tfidf_27  0.000669\n",
       "2         tfidf_2  0.000669\n",
       "83       tfidf_83  0.000667\n",
       "216     tfidf_216  0.000658\n",
       "341     tfidf_341  0.000651\n",
       "360     tfidf_360  0.000644\n",
       "186     tfidf_186  0.000629\n",
       "194     tfidf_194  0.000629\n",
       "49       tfidf_49  0.000628\n",
       "153     tfidf_153  0.000627\n",
       "240     tfidf_240  0.000615\n",
       "179     tfidf_179  0.000611\n",
       "66       tfidf_66  0.000590\n",
       "292     tfidf_292  0.000590\n",
       "217     tfidf_217  0.000589\n",
       "373     tfidf_373  0.000586\n",
       "152     tfidf_152  0.000585\n",
       "196     tfidf_196  0.000584\n",
       "450        pepper  0.000580\n",
       "187     tfidf_187  0.000577\n",
       "438    grapefruit  0.000575\n",
       "184     tfidf_184  0.000572\n",
       "19       tfidf_19  0.000562\n",
       "52       tfidf_52  0.000548\n",
       "320     tfidf_320  0.000543\n",
       "138     tfidf_138  0.000542\n",
       "183     tfidf_183  0.000539\n",
       "1         tfidf_1  0.000539\n",
       "408      headache  0.000538\n",
       "227     tfidf_227  0.000537\n",
       "180     tfidf_180  0.000536\n",
       "44       tfidf_44  0.000523\n",
       "28       tfidf_28  0.000518\n",
       "232     tfidf_232  0.000516\n",
       "317     tfidf_317  0.000516\n",
       "349     tfidf_349  0.000508\n",
       "429      chemical  0.000506\n",
       "356     tfidf_356  0.000504\n",
       "363     tfidf_363  0.000503\n",
       "228     tfidf_228  0.000498\n",
       "311     tfidf_311  0.000493\n",
       "297     tfidf_297  0.000487\n",
       "14       tfidf_14  0.000484\n",
       "270     tfidf_270  0.000481\n",
       "110     tfidf_110  0.000479\n",
       "435       flowery  0.000477\n",
       "243     tfidf_243  0.000476\n",
       "202     tfidf_202  0.000473\n",
       "31       tfidf_31  0.000473\n",
       "159     tfidf_159  0.000471\n",
       "169     tfidf_169  0.000469\n",
       "201     tfidf_201  0.000465\n",
       "45       tfidf_45  0.000463\n",
       "39       tfidf_39  0.000461\n",
       "120     tfidf_120  0.000453\n",
       "301     tfidf_301  0.000450\n",
       "387     tfidf_387  0.000450\n",
       "372     tfidf_372  0.000438\n",
       "332     tfidf_332  0.000433\n",
       "308     tfidf_308  0.000432\n",
       "90       tfidf_90  0.000431\n",
       "255     tfidf_255  0.000425\n",
       "147     tfidf_147  0.000424\n",
       "6         tfidf_6  0.000418\n",
       "247     tfidf_247  0.000418\n",
       "242     tfidf_242  0.000415\n",
       "461           tar  0.000415\n",
       "458  spicy/herbal  0.000414\n",
       "40       tfidf_40  0.000413\n",
       "215     tfidf_215  0.000410\n",
       "368     tfidf_368  0.000410\n",
       "316     tfidf_316  0.000408\n",
       "62       tfidf_62  0.000408\n",
       "269     tfidf_269  0.000407\n",
       "131     tfidf_131  0.000400\n",
       "307     tfidf_307  0.000397\n",
       "444       menthol  0.000395\n",
       "280     tfidf_280  0.000392\n",
       "260     tfidf_260  0.000392\n",
       "198     tfidf_198  0.000392\n",
       "439         honey  0.000392\n",
       "79       tfidf_79  0.000390\n",
       "10       tfidf_10  0.000386\n",
       "160     tfidf_160  0.000384\n",
       "108     tfidf_108  0.000382\n",
       "440      lavender  0.000374\n",
       "223     tfidf_223  0.000374\n",
       "379     tfidf_379  0.000369\n",
       "346     tfidf_346  0.000369\n",
       "148     tfidf_148  0.000368\n",
       "56       tfidf_56  0.000364\n",
       "310     tfidf_310  0.000362\n",
       "436         fruit  0.000359\n",
       "185     tfidf_185  0.000343\n",
       "265     tfidf_265  0.000341\n",
       "290     tfidf_290  0.000336\n",
       "383     tfidf_383  0.000335\n",
       "315     tfidf_315  0.000334\n",
       "182     tfidf_182  0.000329\n",
       "197     tfidf_197  0.000326\n",
       "256     tfidf_256  0.000322\n",
       "68       tfidf_68  0.000321\n",
       "76       tfidf_76  0.000321\n",
       "219     tfidf_219  0.000319\n",
       "125     tfidf_125  0.000319\n",
       "164     tfidf_164  0.000316\n",
       "192     tfidf_192  0.000315\n",
       "102     tfidf_102  0.000312\n",
       "389        indica  0.000311\n",
       "298     tfidf_298  0.000308\n",
       "15       tfidf_15  0.000308\n",
       "55       tfidf_55  0.000307\n",
       "359     tfidf_359  0.000304\n",
       "364     tfidf_364  0.000303\n",
       "299     tfidf_299  0.000302\n",
       "463       tobacco  0.000299\n",
       "331     tfidf_331  0.000298\n",
       "213     tfidf_213  0.000297\n",
       "294     tfidf_294  0.000297\n",
       "263     tfidf_263  0.000296\n",
       "271     tfidf_271  0.000295\n",
       "252     tfidf_252  0.000292\n",
       "259     tfidf_259  0.000289\n",
       "81       tfidf_81  0.000289\n",
       "432        coffee  0.000287\n",
       "421       ammonia  0.000287\n",
       "392       anxious  0.000282\n",
       "326     tfidf_326  0.000280\n",
       "446         nutty  0.000279\n",
       "282     tfidf_282  0.000276\n",
       "352     tfidf_352  0.000270\n",
       "430      chestnut  0.000270\n",
       "268     tfidf_268  0.000268\n",
       "135     tfidf_135  0.000267\n",
       "231     tfidf_231  0.000266\n",
       "212     tfidf_212  0.000266\n",
       "293     tfidf_293  0.000266\n",
       "220     tfidf_220  0.000264\n",
       "443         mango  0.000262\n",
       "29       tfidf_29  0.000262\n",
       "257     tfidf_257  0.000262\n",
       "177     tfidf_177  0.000259\n",
       "8         tfidf_8  0.000259\n",
       "459    strawberry  0.000257\n",
       "249     tfidf_249  0.000252\n",
       "155     tfidf_155  0.000251\n",
       "12       tfidf_12  0.000250\n",
       "313     tfidf_313  0.000250\n",
       "143     tfidf_143  0.000250\n",
       "113     tfidf_113  0.000250\n",
       "274     tfidf_274  0.000247\n",
       "35       tfidf_35  0.000241\n",
       "448         peach  0.000240\n",
       "70       tfidf_70  0.000238\n",
       "287     tfidf_287  0.000237\n",
       "335     tfidf_335  0.000233\n",
       "361     tfidf_361  0.000232\n",
       "127     tfidf_127  0.000230\n",
       "302     tfidf_302  0.000224\n",
       "109     tfidf_109  0.000223\n",
       "324     tfidf_324  0.000223\n",
       "465      tropical  0.000223\n",
       "455          rose  0.000222\n",
       "60       tfidf_60  0.000222\n",
       "33       tfidf_33  0.000222\n",
       "377     tfidf_377  0.000220\n",
       "67       tfidf_67  0.000220\n",
       "118     tfidf_118  0.000213\n",
       "279     tfidf_279  0.000213\n",
       "140     tfidf_140  0.000212\n",
       "137     tfidf_137  0.000207\n",
       "77       tfidf_77  0.000206\n",
       "214     tfidf_214  0.000206\n",
       "63       tfidf_63  0.000205\n",
       "84       tfidf_84  0.000203\n",
       "328     tfidf_328  0.000196\n",
       "275     tfidf_275  0.000194\n",
       "176     tfidf_176  0.000192\n",
       "248     tfidf_248  0.000188\n",
       "99       tfidf_99  0.000186\n",
       "295     tfidf_295  0.000183\n",
       "238     tfidf_238  0.000182\n",
       "384     tfidf_384  0.000182\n",
       "50       tfidf_50  0.000180\n",
       "59       tfidf_59  0.000176\n",
       "47       tfidf_47  0.000173\n",
       "204     tfidf_204  0.000170\n",
       "330     tfidf_330  0.000168\n",
       "254     tfidf_254  0.000166\n",
       "172     tfidf_172  0.000165\n",
       "100     tfidf_100  0.000164\n",
       "25       tfidf_25  0.000159\n",
       "87       tfidf_87  0.000157\n",
       "38       tfidf_38  0.000151\n",
       "229     tfidf_229  0.000150\n",
       "244     tfidf_244  0.000149\n",
       "134     tfidf_134  0.000140\n",
       "378     tfidf_378  0.000138\n",
       "42       tfidf_42  0.000137\n",
       "261     tfidf_261  0.000134\n",
       "36       tfidf_36  0.000133\n",
       "339     tfidf_339  0.000129\n",
       "305     tfidf_305  0.000129\n",
       "115     tfidf_115  0.000121\n",
       "327     tfidf_327  0.000121\n",
       "284     tfidf_284  0.000119\n",
       "142     tfidf_142  0.000116\n",
       "13       tfidf_13  0.000113\n",
       "18       tfidf_18  0.000111\n",
       "114     tfidf_114  0.000111\n",
       "266     tfidf_266  0.000110\n",
       "322     tfidf_322  0.000108\n",
       "92       tfidf_92  0.000097\n",
       "296     tfidf_296  0.000094\n",
       "422         apple  0.000094\n",
       "462           tea  0.000086\n",
       "452     pineapple  0.000075\n",
       "74       tfidf_74  0.000074\n",
       "241     tfidf_241  0.000067\n",
       "174     tfidf_174  0.000064\n",
       "250     tfidf_250  0.000060\n",
       "453          plum  0.000049\n",
       "306     tfidf_306  0.000048\n",
       "427        butter  0.000038\n",
       "396    depression  0.000033\n",
       "449          pear  0.000027\n",
       "423       apricot  0.000024\n",
       "410     migraines  0.000020\n",
       "391       anxiety  0.000016\n",
       "467        violet  0.000007\n",
       "394     arthritis  0.000000\n",
       "417        stress  0.000000\n",
       "416    spasticity  0.000000\n",
       "414      seizures  0.000000\n",
       "401      epilepsy  0.000000\n",
       "403  eye pressure  0.000000\n",
       "411          pain  0.000000\n",
       "404       fatigue  0.000000"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.set_option('display.max_rows', df_feat_ranked.shape[0]+1)\n",
    "df_feat_ranked"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/louispandu/anaconda3/lib/python3.10/site-packages/sklearn/feature_selection/_from_model.py:357: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  self.estimator_.fit(X, y, **fit_params)\n"
     ]
    }
   ],
   "source": [
    "selector = SelectFromModel(rfreg).fit(X_train1, y_train1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([2.05243380e-03, 6.29905328e-04, 6.40327957e-04, 9.22825656e-04,\n",
       "       3.90117037e-03, 1.01444728e-03, 3.83583176e-04, 3.49374782e-03,\n",
       "       2.54943056e-04, 9.55593719e-04, 3.27648143e-04, 1.04322521e-03,\n",
       "       2.44949620e-04, 7.78870168e-05, 4.02810699e-04, 2.54590687e-04,\n",
       "       6.34460361e-04, 1.57387113e-03, 1.02035735e-04, 5.95895745e-04,\n",
       "       1.05249383e-03, 1.90170711e-03, 1.17537610e-03, 4.18909630e-03,\n",
       "       8.83333608e-04, 1.96987713e-04, 2.61930995e-03, 8.72032285e-04,\n",
       "       4.92148920e-04, 2.64794717e-04, 3.37771853e-03, 4.21130290e-04,\n",
       "       5.49907297e-03, 2.10262567e-04, 1.93463618e-03, 2.33548313e-04,\n",
       "       1.54702727e-04, 2.31797006e-03, 1.39704340e-04, 4.68846603e-04,\n",
       "       3.12773709e-04, 9.95596466e-04, 1.96397759e-04, 2.03125145e-03,\n",
       "       4.35646948e-04, 5.59139228e-04, 1.62081789e-03, 1.91018008e-04,\n",
       "       2.00342296e-03, 6.51416120e-04, 1.51870065e-04, 2.20393945e-03,\n",
       "       6.18062763e-04, 2.13468664e-03, 7.33428504e-04, 2.23360483e-04,\n",
       "       4.26177998e-04, 7.74219307e-04, 1.05589650e-03, 1.91804173e-04,\n",
       "       2.04873468e-04, 1.15096622e-03, 4.17617609e-04, 2.04307348e-04,\n",
       "       1.22935889e-03, 1.29363780e-03, 7.08593045e-04, 2.55483801e-04,\n",
       "       2.72441620e-04, 4.11541775e-03, 1.80273432e-04, 8.98941843e-04,\n",
       "       1.08922608e-03, 2.12540861e-03, 8.32447450e-05, 1.32359550e-03,\n",
       "       3.87051254e-04, 2.02966032e-04, 8.04970586e-03, 3.40932728e-04,\n",
       "       4.09374122e-03, 4.34402825e-04, 1.78894807e-03, 5.94871842e-04,\n",
       "       2.29651668e-04, 1.17579518e-03, 2.41063011e-03, 1.50803867e-04,\n",
       "       1.16967865e-03, 1.36775363e-03, 4.95393403e-04, 1.60078675e-03,\n",
       "       1.60903935e-04, 5.69600730e-03, 7.74374573e-04, 1.19846369e-03,\n",
       "       1.27876167e-03, 8.50385178e-03, 1.29736131e-03, 2.19393090e-04,\n",
       "       1.85105121e-04, 1.35949459e-03, 2.99257584e-04, 7.66890649e-04,\n",
       "       7.89429657e-04, 3.16800220e-03, 1.43989578e-03, 1.02566737e-03,\n",
       "       3.97853527e-04, 2.29870338e-04, 4.60118138e-04, 2.61497169e-03,\n",
       "       7.64815018e-04, 3.29378767e-04, 1.48162581e-04, 1.53406381e-04,\n",
       "       7.27152197e-04, 1.72328892e-03, 2.27357322e-04, 2.25340628e-03,\n",
       "       4.77793458e-04, 8.12183932e-03, 1.54915433e-03, 1.08204290e-03,\n",
       "       8.30988298e-04, 2.83649686e-04, 1.85499387e-03, 2.48555818e-04,\n",
       "       2.48780784e-03, 7.30282005e-04, 9.90760333e-04, 4.16177913e-04,\n",
       "       6.68566724e-04, 1.21842901e-03, 1.10275295e-04, 2.84114011e-04,\n",
       "       9.08324124e-04, 2.09843403e-04, 3.52432525e-04, 1.28477335e-03,\n",
       "       2.23131335e-04, 9.03763613e-03, 1.00920628e-04, 2.12146508e-04,\n",
       "       3.32542981e-03, 1.14902645e-02, 1.72627221e-03, 5.69506011e-04,\n",
       "       3.82566158e-04, 1.24510096e-02, 3.14059771e-03, 5.67766214e-03,\n",
       "       6.43982456e-04, 6.17027779e-04, 1.12951174e-03, 3.66472624e-04,\n",
       "       5.37577373e-03, 6.54640517e-03, 2.61055253e-03, 4.82383571e-04,\n",
       "       3.53675050e-04, 9.10875058e-03, 3.01079890e-03, 7.88418248e-03,\n",
       "       3.07143874e-04, 1.00277363e-02, 1.54745150e-03, 2.38477588e-03,\n",
       "       9.98945330e-03, 4.68263859e-04, 1.59437807e-03, 1.37916882e-03,\n",
       "       1.65523023e-04, 1.94157230e-03, 6.07368252e-05, 7.32181877e-03,\n",
       "       1.81668500e-04, 2.68630506e-04, 1.11329281e-03, 5.90336481e-04,\n",
       "       4.91568842e-04, 2.63357608e-03, 3.45184753e-04, 5.14634020e-04,\n",
       "       6.02432926e-04, 2.38295005e-04, 6.46189479e-04, 6.00411339e-04,\n",
       "       8.30918030e-04, 1.70109779e-03, 1.58373308e-03, 6.81494179e-04,\n",
       "       2.91523034e-04, 3.55805030e-03, 5.83742404e-04, 7.81680291e-04,\n",
       "       6.68698292e-04, 3.35990974e-04, 3.30512239e-04, 3.76963761e-03,\n",
       "       4.73702438e-03, 4.33829789e-04, 5.23676459e-04, 9.54100137e-04,\n",
       "       1.52849775e-04, 1.39899544e-03, 8.28093765e-04, 3.74758411e-03,\n",
       "       5.47547082e-04, 6.45306869e-04, 5.43181819e-03, 1.75375662e-03,\n",
       "       2.73310224e-04, 2.64041501e-04, 1.78988560e-04, 4.50872856e-04,\n",
       "       6.96509499e-04, 6.49171386e-04, 7.92273521e-03, 2.91862236e-04,\n",
       "       2.62862034e-04, 1.13335246e-03, 2.79659328e-03, 3.71524057e-04,\n",
       "       7.74254023e-04, 1.45901396e-03, 2.34442073e-03, 4.98698260e-04,\n",
       "       5.73211270e-04, 1.35794848e-04, 1.26072693e-03, 2.97910191e-04,\n",
       "       4.85607064e-04, 1.19747757e-03, 4.44093711e-03, 5.33473208e-03,\n",
       "       5.73296039e-03, 8.08163410e-04, 1.85840993e-04, 7.05465078e-03,\n",
       "       5.51042845e-04, 6.25657490e-05, 4.11441977e-04, 4.43168388e-04,\n",
       "       9.19936180e-05, 5.79852081e-03, 1.61153120e-03, 5.17130153e-04,\n",
       "       2.98732349e-04, 2.30397167e-04, 4.59457383e-05, 3.59408700e-03,\n",
       "       2.33537573e-04, 2.79354738e-03, 1.21133090e-04, 3.27180225e-04,\n",
       "       3.48511082e-04, 3.55588496e-04, 2.22552680e-03, 2.83501560e-04,\n",
       "       5.43787390e-04, 1.31419896e-04, 8.96353624e-04, 3.10983090e-04,\n",
       "       1.02305927e-03, 3.58139800e-04, 8.73131818e-05, 1.73490797e-03,\n",
       "       2.62719414e-04, 4.82694038e-04, 5.68881374e-04, 3.00133397e-04,\n",
       "       3.53912352e-03, 9.57556227e-04, 2.14988772e-04, 2.65087448e-04,\n",
       "       2.28455711e-03, 2.25635621e-03, 1.42726605e-03, 2.26692509e-04,\n",
       "       3.41164034e-04, 3.78490923e-03, 2.43119462e-04, 1.87409826e-03,\n",
       "       1.20426462e-04, 4.22483824e-03, 1.01301349e-03, 1.99292899e-04,\n",
       "       1.47942797e-02, 8.15674012e-04, 4.39818792e-04, 2.33964356e-03,\n",
       "       6.99833917e-04, 2.64217729e-04, 3.11437918e-04, 2.08804365e-04,\n",
       "       8.16664040e-05, 5.11754743e-04, 2.97758005e-04, 4.02019754e-04,\n",
       "       4.07785238e-03, 4.86398571e-04, 1.98311194e-04, 1.21586479e-03,\n",
       "       1.06649509e-03, 1.25019395e-04, 5.24849905e-05, 3.27580057e-04,\n",
       "       6.05526545e-04, 6.50959883e-03, 3.90971435e-04, 4.20242732e-04,\n",
       "       1.13178669e-02, 1.70943185e-04, 2.26127689e-03, 3.83339311e-04,\n",
       "       5.70397240e-04, 5.55703969e-04, 8.81568970e-04, 2.66324929e-03,\n",
       "       5.96187529e-04, 1.30988502e-03, 1.38814390e-04, 4.78241436e-03,\n",
       "       1.75449270e-04, 1.77788341e-03, 2.53015334e-04, 1.27002423e-04,\n",
       "       2.37598147e-04, 1.36559444e-02, 1.55816880e-04, 3.09138412e-04,\n",
       "       3.31955428e-04, 2.37222364e-03, 1.03792900e-03, 2.48203189e-04,\n",
       "       1.98695084e-03, 2.17177238e-03, 2.54573708e-03, 1.04266784e-04,\n",
       "       4.78648939e-03, 6.72615346e-04, 2.16823180e-03, 1.56032909e-03,\n",
       "       7.00036368e-04, 1.02590402e-02, 3.13402292e-04, 2.01141138e-03,\n",
       "       8.16261685e-04, 4.97458314e-04, 1.82321989e-03, 4.02706915e-03,\n",
       "       2.27147879e-04, 1.69204105e-03, 7.37162720e-04, 7.06514699e-03,\n",
       "       5.18111223e-04, 6.32067954e-03, 5.23209183e-03, 3.16626807e-04,\n",
       "       7.73885277e-04, 2.60202602e-04, 4.98267628e-03, 4.65342917e-04,\n",
       "       2.93443895e-04, 7.67402589e-04, 3.63060500e-03, 1.29454992e-03,\n",
       "       4.14806640e-04, 9.55756753e-04, 9.76626407e-04, 2.21979426e-03,\n",
       "       4.43984262e-04, 5.57360279e-04, 1.11922965e-03, 2.09623845e-03,\n",
       "       3.93892802e-03, 2.12450323e-04, 1.37528084e-04, 3.03102753e-04,\n",
       "       2.89929426e-03, 1.11921852e-03, 1.27688442e-03, 3.19868295e-04,\n",
       "       1.69563835e-04, 8.44569081e-04, 2.54198133e-03, 4.40253647e-04,\n",
       "       2.93257796e-02, 3.49088219e-04, 2.09065012e-01, 7.96454366e-05,\n",
       "       2.68603713e-04, 8.79730879e-04, 0.00000000e+00, 3.12407647e-03,\n",
       "       2.58198797e-05, 7.69293220e-04, 2.10742220e-03, 2.38777747e-03,\n",
       "       3.33569044e-03, 0.00000000e+00, 3.77572531e-03, 0.00000000e+00,\n",
       "       0.00000000e+00, 3.58784648e-03, 1.74834777e-03, 2.67177638e-03,\n",
       "       5.11222751e-04, 4.52315005e-03, 2.76630824e-05, 0.00000000e+00,\n",
       "       6.86244792e-04, 4.28717416e-03, 0.00000000e+00, 4.10062341e-03,\n",
       "       0.00000000e+00, 0.00000000e+00, 3.66371559e-03, 1.50133012e-03,\n",
       "       3.35741703e-03, 1.83317395e-04, 1.49224345e-04, 6.56774569e-05,\n",
       "       5.02343081e-03, 8.96361191e-04, 2.14283408e-03, 4.58534518e-05,\n",
       "       3.29659845e-03, 4.38724908e-04, 2.22202349e-04, 3.14055386e-03,\n",
       "       2.50348508e-04, 5.55959905e-03, 2.43277493e-03, 6.56662161e-04,\n",
       "       4.60855990e-04, 2.01682716e-03, 4.61624489e-04, 5.20183790e-04,\n",
       "       4.45075449e-04, 5.37813154e-03, 3.12193967e-03, 3.15121584e-04,\n",
       "       1.21372445e-04, 2.08181439e-03, 2.66265296e-04, 1.20482997e-02,\n",
       "       3.08488496e-04, 3.75645351e-05, 5.67386225e-04, 1.65318799e-03,\n",
       "       5.64287268e-05, 4.17726779e-05, 1.01224144e-03, 2.08234828e-04,\n",
       "       1.75427002e-03, 1.94481721e-03, 4.49051293e-04, 2.48050197e-04,\n",
       "       5.03297157e-03, 4.22008034e-04, 8.09860104e-05, 2.58690212e-04,\n",
       "       4.14020365e-04, 3.21150390e-04, 3.59308144e-02, 9.52831825e-06,\n",
       "       5.61726240e-04])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "selector.estimator_.feature_importances_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0021321961620469083"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "selector.threshold_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "mask = selector.get_support()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([False, False, False, False,  True, False, False,  True, False,\n",
       "       False, False, False, False, False, False, False, False, False,\n",
       "       False, False, False, False, False,  True, False, False,  True,\n",
       "       False, False, False,  True, False,  True, False, False, False,\n",
       "       False,  True, False, False, False, False, False, False, False,\n",
       "       False, False, False, False, False, False,  True, False,  True,\n",
       "       False, False, False, False, False, False, False, False, False,\n",
       "       False, False, False, False, False, False,  True, False, False,\n",
       "       False, False, False, False, False, False,  True, False,  True,\n",
       "       False, False, False, False, False,  True, False, False, False,\n",
       "       False, False, False,  True, False, False, False,  True, False,\n",
       "       False, False, False, False, False, False,  True, False, False,\n",
       "       False, False, False,  True, False, False, False, False, False,\n",
       "       False, False,  True, False,  True, False, False, False, False,\n",
       "       False, False,  True, False, False, False, False, False, False,\n",
       "       False, False, False, False, False, False,  True, False, False,\n",
       "        True,  True, False, False, False,  True,  True,  True, False,\n",
       "       False, False, False,  True,  True,  True, False, False,  True,\n",
       "        True,  True, False,  True, False,  True,  True, False, False,\n",
       "       False, False, False, False,  True, False, False, False, False,\n",
       "       False,  True, False, False, False, False, False, False, False,\n",
       "       False, False, False, False,  True, False, False, False, False,\n",
       "       False,  True,  True, False, False, False, False, False, False,\n",
       "        True, False, False,  True, False, False, False, False, False,\n",
       "       False, False,  True, False, False, False,  True, False, False,\n",
       "       False,  True, False, False, False, False, False, False, False,\n",
       "        True,  True,  True, False, False,  True, False, False, False,\n",
       "       False, False,  True, False, False, False, False, False,  True,\n",
       "       False,  True, False, False, False, False,  True, False, False,\n",
       "       False, False, False, False, False, False, False, False, False,\n",
       "       False, False,  True, False, False, False,  True,  True, False,\n",
       "       False, False,  True, False, False, False,  True, False, False,\n",
       "        True, False, False,  True, False, False, False, False, False,\n",
       "       False, False, False,  True, False, False, False, False, False,\n",
       "       False, False, False,  True, False, False,  True, False,  True,\n",
       "       False, False, False, False,  True, False, False, False,  True,\n",
       "       False, False, False, False, False,  True, False, False, False,\n",
       "        True, False, False, False,  True,  True, False,  True, False,\n",
       "        True, False, False,  True, False, False, False, False, False,\n",
       "        True, False, False, False,  True, False,  True,  True, False,\n",
       "       False, False,  True, False, False, False,  True, False, False,\n",
       "       False, False,  True, False, False, False, False,  True, False,\n",
       "       False, False,  True, False, False, False, False, False,  True,\n",
       "       False,  True, False,  True, False, False, False, False,  True,\n",
       "       False, False, False,  True,  True, False,  True, False, False,\n",
       "        True, False,  True, False,  True, False, False, False,  True,\n",
       "       False,  True, False, False,  True, False,  True, False, False,\n",
       "       False,  True, False,  True, False,  True, False, False,  True,\n",
       "       False,  True,  True, False, False, False, False, False, False,\n",
       "        True,  True, False, False, False, False,  True, False, False,\n",
       "       False, False, False, False, False, False, False, False, False,\n",
       "       False,  True, False, False, False, False, False,  True, False,\n",
       "       False])"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "selected_features = X.columns[mask]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tfidf_4</th>\n",
       "      <th>tfidf_7</th>\n",
       "      <th>tfidf_23</th>\n",
       "      <th>tfidf_26</th>\n",
       "      <th>tfidf_30</th>\n",
       "      <th>tfidf_32</th>\n",
       "      <th>tfidf_37</th>\n",
       "      <th>tfidf_51</th>\n",
       "      <th>tfidf_53</th>\n",
       "      <th>tfidf_69</th>\n",
       "      <th>...</th>\n",
       "      <th>blueberry</th>\n",
       "      <th>cheese</th>\n",
       "      <th>citrus</th>\n",
       "      <th>diesel</th>\n",
       "      <th>earthy</th>\n",
       "      <th>lemon</th>\n",
       "      <th>lime</th>\n",
       "      <th>orange</th>\n",
       "      <th>sweet</th>\n",
       "      <th>vanilla</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.14162</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.14162</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.14162</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.14162</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.14162</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>74995</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>74996</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>74997</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>74998</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>74999</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>75000 rows × 107 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       tfidf_4  tfidf_7  tfidf_23  tfidf_26  tfidf_30  tfidf_32  tfidf_37  \\\n",
       "0          0.0      0.0       0.0       0.0       0.0       0.0   0.14162   \n",
       "1          0.0      0.0       0.0       0.0       0.0       0.0   0.14162   \n",
       "2          0.0      0.0       0.0       0.0       0.0       0.0   0.14162   \n",
       "3          0.0      0.0       0.0       0.0       0.0       0.0   0.14162   \n",
       "4          0.0      0.0       0.0       0.0       0.0       0.0   0.14162   \n",
       "...        ...      ...       ...       ...       ...       ...       ...   \n",
       "74995      0.0      0.0       0.0       0.0       0.0       0.0   0.00000   \n",
       "74996      0.0      0.0       0.0       0.0       0.0       0.0   0.00000   \n",
       "74997      0.0      0.0       0.0       0.0       0.0       0.0   0.00000   \n",
       "74998      0.0      0.0       0.0       0.0       0.0       0.0   0.00000   \n",
       "74999      0.0      0.0       0.0       0.0       0.0       0.0   0.00000   \n",
       "\n",
       "       tfidf_51  tfidf_53  tfidf_69  ...  blueberry  cheese  citrus  diesel  \\\n",
       "0           0.0       0.0       0.0  ...          0       0       0       0   \n",
       "1           0.0       0.0       0.0  ...          0       0       0       0   \n",
       "2           0.0       0.0       0.0  ...          0       0       0       0   \n",
       "3           0.0       0.0       0.0  ...          0       0       0       0   \n",
       "4           0.0       0.0       0.0  ...          0       0       0       0   \n",
       "...         ...       ...       ...  ...        ...     ...     ...     ...   \n",
       "74995       0.0       0.0       0.0  ...          0       0       0       0   \n",
       "74996       0.0       0.0       0.0  ...          0       0       0       0   \n",
       "74997       0.0       0.0       0.0  ...          0       0       0       0   \n",
       "74998       0.0       0.0       0.0  ...          0       0       0       0   \n",
       "74999       0.0       0.0       0.0  ...          0       0       0       0   \n",
       "\n",
       "       earthy  lemon  lime  orange  sweet  vanilla  \n",
       "0           0      0     0       0      0        0  \n",
       "1           0      0     0       0      0        0  \n",
       "2           0      0     0       0      0        0  \n",
       "3           0      0     0       0      0        0  \n",
       "4           0      0     0       0      0        0  \n",
       "...       ...    ...   ...     ...    ...      ...  \n",
       "74995       0      0     0       0      0        0  \n",
       "74996       0      0     0       0      0        0  \n",
       "74997       0      0     0       0      0        0  \n",
       "74998       0      0     0       0      0        0  \n",
       "74999       0      0     0       0      0        0  \n",
       "\n",
       "[75000 rows x 107 columns]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "selected_X = df_rf[selected_features]\n",
    "selected_X"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train test split (after Feature Selection)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['selected_X_rf_tfidf_bocim.pkl']"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import joblib\n",
    "\n",
    "joblib.dump(selector, \"selector_rf_tfidf_bocim.pkl\")\n",
    "joblib.dump(selected_X, \"selected_X_rf_tfidf_bocim.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(selected_X, y, random_state=1, test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train1, X_val, y_train1, y_val = train_test_split(X_train, y_train, random_state=1, test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/ns/m5pnr0211w91v02hpv22958m0000gn/T/ipykernel_86350/3758305.py:1: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  rfreg.fit(X_train1, y_train1)\n"
     ]
    }
   ],
   "source": [
    "rfreg.fit(X_train1, y_train1)\n",
    "y_pred_rfreg = rfreg.predict(X_val)\n",
    "y_pred_rfreg_r2 = rfreg.predict(X_train1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.03193548146909978"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mean_absolute_error(y_val, y_pred_rfreg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.005755289069158384"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mean_squared_error(y_val, y_pred_rfreg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.07586362151359757"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mean_squared_error(y_val, y_pred_rfreg, squared = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9807493144149841"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#train\n",
    "r2_score(y_train1, y_pred_rfreg_r2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9356160025164403"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#val\n",
    "r2_score(y_val, y_pred_rfreg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hyperparameter Tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "parameters = {'max_depth': [None, 10, 50, 100],\n",
    "              'max_features': ['auto', 'sqrt'],\n",
    "              'min_samples_leaf': [1, 2, 4],\n",
    "              'min_samples_split': [2, 5, 10],\n",
    "              'n_estimators': [100, 300, 500]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "rscv = RandomizedSearchCV(rfreg,  \n",
    "                     parameters,   \n",
    "                     cv=5, \n",
    "                     scoring='neg_mean_absolute_error',\n",
    "                     n_jobs = -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/louispandu/anaconda3/lib/python3.10/site-packages/sklearn/model_selection/_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/Users/louispandu/anaconda3/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
      "  warn(\n",
      "/Users/louispandu/anaconda3/lib/python3.10/site-packages/sklearn/model_selection/_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/Users/louispandu/anaconda3/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
      "  warn(\n",
      "/Users/louispandu/anaconda3/lib/python3.10/site-packages/sklearn/model_selection/_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/Users/louispandu/anaconda3/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
      "  warn(\n",
      "/Users/louispandu/anaconda3/lib/python3.10/site-packages/sklearn/model_selection/_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/Users/louispandu/anaconda3/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
      "  warn(\n",
      "/Users/louispandu/anaconda3/lib/python3.10/site-packages/sklearn/model_selection/_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/Users/louispandu/anaconda3/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
      "  warn(\n",
      "/Users/louispandu/anaconda3/lib/python3.10/site-packages/sklearn/model_selection/_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/Users/louispandu/anaconda3/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
      "  warn(\n",
      "/Users/louispandu/anaconda3/lib/python3.10/site-packages/sklearn/model_selection/_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/Users/louispandu/anaconda3/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
      "  warn(\n",
      "/Users/louispandu/anaconda3/lib/python3.10/site-packages/sklearn/model_selection/_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/Users/louispandu/anaconda3/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
      "  warn(\n",
      "/Users/louispandu/anaconda3/lib/python3.10/site-packages/sklearn/model_selection/_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/Users/louispandu/anaconda3/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
      "  warn(\n",
      "/Users/louispandu/anaconda3/lib/python3.10/site-packages/sklearn/model_selection/_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/Users/louispandu/anaconda3/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
      "  warn(\n",
      "/Users/louispandu/anaconda3/lib/python3.10/site-packages/sklearn/model_selection/_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/Users/louispandu/anaconda3/lib/python3.10/site-packages/sklearn/model_selection/_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/Users/louispandu/anaconda3/lib/python3.10/site-packages/sklearn/model_selection/_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/Users/louispandu/anaconda3/lib/python3.10/site-packages/sklearn/model_selection/_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/Users/louispandu/anaconda3/lib/python3.10/site-packages/sklearn/model_selection/_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/Users/louispandu/anaconda3/lib/python3.10/site-packages/sklearn/model_selection/_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/Users/louispandu/anaconda3/lib/python3.10/site-packages/sklearn/model_selection/_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/Users/louispandu/anaconda3/lib/python3.10/site-packages/sklearn/model_selection/_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/Users/louispandu/anaconda3/lib/python3.10/site-packages/sklearn/model_selection/_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/Users/louispandu/anaconda3/lib/python3.10/site-packages/sklearn/model_selection/_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/Users/louispandu/anaconda3/lib/python3.10/site-packages/sklearn/model_selection/_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/Users/louispandu/anaconda3/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
      "  warn(\n",
      "/Users/louispandu/anaconda3/lib/python3.10/site-packages/sklearn/model_selection/_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/Users/louispandu/anaconda3/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
      "  warn(\n",
      "/Users/louispandu/anaconda3/lib/python3.10/site-packages/sklearn/model_selection/_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/Users/louispandu/anaconda3/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
      "  warn(\n",
      "/Users/louispandu/anaconda3/lib/python3.10/site-packages/sklearn/model_selection/_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/Users/louispandu/anaconda3/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
      "  warn(\n",
      "/Users/louispandu/anaconda3/lib/python3.10/site-packages/sklearn/model_selection/_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/Users/louispandu/anaconda3/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
      "  warn(\n",
      "/Users/louispandu/anaconda3/lib/python3.10/site-packages/sklearn/model_selection/_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/Users/louispandu/anaconda3/lib/python3.10/site-packages/sklearn/model_selection/_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/Users/louispandu/anaconda3/lib/python3.10/site-packages/sklearn/model_selection/_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/Users/louispandu/anaconda3/lib/python3.10/site-packages/sklearn/model_selection/_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/Users/louispandu/anaconda3/lib/python3.10/site-packages/sklearn/model_selection/_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/Users/louispandu/anaconda3/lib/python3.10/site-packages/sklearn/model_selection/_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/Users/louispandu/anaconda3/lib/python3.10/site-packages/sklearn/model_selection/_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/Users/louispandu/anaconda3/lib/python3.10/site-packages/sklearn/model_selection/_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/Users/louispandu/anaconda3/lib/python3.10/site-packages/sklearn/model_selection/_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/Users/louispandu/anaconda3/lib/python3.10/site-packages/sklearn/model_selection/_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/Users/louispandu/anaconda3/lib/python3.10/site-packages/sklearn/model_selection/_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/Users/louispandu/anaconda3/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
      "  warn(\n",
      "/Users/louispandu/anaconda3/lib/python3.10/site-packages/sklearn/model_selection/_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/Users/louispandu/anaconda3/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
      "  warn(\n",
      "/Users/louispandu/anaconda3/lib/python3.10/site-packages/sklearn/model_selection/_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/Users/louispandu/anaconda3/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
      "  warn(\n",
      "/Users/louispandu/anaconda3/lib/python3.10/site-packages/sklearn/model_selection/_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/Users/louispandu/anaconda3/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
      "  warn(\n",
      "/Users/louispandu/anaconda3/lib/python3.10/site-packages/sklearn/model_selection/_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/Users/louispandu/anaconda3/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
      "  warn(\n",
      "/Users/louispandu/anaconda3/lib/python3.10/site-packages/sklearn/model_selection/_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/Users/louispandu/anaconda3/lib/python3.10/site-packages/sklearn/model_selection/_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/Users/louispandu/anaconda3/lib/python3.10/site-packages/sklearn/model_selection/_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/Users/louispandu/anaconda3/lib/python3.10/site-packages/sklearn/model_selection/_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/Users/louispandu/anaconda3/lib/python3.10/site-packages/sklearn/model_selection/_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/Users/louispandu/anaconda3/lib/python3.10/site-packages/sklearn/model_selection/_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/Users/louispandu/anaconda3/lib/python3.10/site-packages/sklearn/model_selection/_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/Users/louispandu/anaconda3/lib/python3.10/site-packages/sklearn/model_selection/_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/Users/louispandu/anaconda3/lib/python3.10/site-packages/sklearn/model_selection/_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/Users/louispandu/anaconda3/lib/python3.10/site-packages/sklearn/model_selection/_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/Users/louispandu/anaconda3/lib/python3.10/site-packages/sklearn/model_selection/_search.py:909: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  self.best_estimator_.fit(X, y, **fit_params)\n",
      "/Users/louispandu/anaconda3/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
      "  warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-2 {color: black;background-color: white;}#sk-container-id-2 pre{padding: 0;}#sk-container-id-2 div.sk-toggleable {background-color: white;}#sk-container-id-2 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-2 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-2 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-2 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-2 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-2 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-2 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-2 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-2 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-2 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-2 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-2 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-2 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-2 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-2 div.sk-item {position: relative;z-index: 1;}#sk-container-id-2 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-2 div.sk-item::before, #sk-container-id-2 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-2 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-2 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-2 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-2 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-2 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-2 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-2 div.sk-label-container {text-align: center;}#sk-container-id-2 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-2 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-2\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>RandomizedSearchCV(cv=5, estimator=RandomForestRegressor(), n_jobs=-1,\n",
       "                   param_distributions={&#x27;max_depth&#x27;: [None, 10, 50, 100],\n",
       "                                        &#x27;max_features&#x27;: [&#x27;auto&#x27;, &#x27;sqrt&#x27;],\n",
       "                                        &#x27;min_samples_leaf&#x27;: [1, 2, 4],\n",
       "                                        &#x27;min_samples_split&#x27;: [2, 5, 10],\n",
       "                                        &#x27;n_estimators&#x27;: [100, 300, 500]},\n",
       "                   scoring=&#x27;neg_mean_absolute_error&#x27;)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" ><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">RandomizedSearchCV</label><div class=\"sk-toggleable__content\"><pre>RandomizedSearchCV(cv=5, estimator=RandomForestRegressor(), n_jobs=-1,\n",
       "                   param_distributions={&#x27;max_depth&#x27;: [None, 10, 50, 100],\n",
       "                                        &#x27;max_features&#x27;: [&#x27;auto&#x27;, &#x27;sqrt&#x27;],\n",
       "                                        &#x27;min_samples_leaf&#x27;: [1, 2, 4],\n",
       "                                        &#x27;min_samples_split&#x27;: [2, 5, 10],\n",
       "                                        &#x27;n_estimators&#x27;: [100, 300, 500]},\n",
       "                   scoring=&#x27;neg_mean_absolute_error&#x27;)</pre></div></div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-3\" type=\"checkbox\" ><label for=\"sk-estimator-id-3\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">estimator: RandomForestRegressor</label><div class=\"sk-toggleable__content\"><pre>RandomForestRegressor()</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-4\" type=\"checkbox\" ><label for=\"sk-estimator-id-4\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">RandomForestRegressor</label><div class=\"sk-toggleable__content\"><pre>RandomForestRegressor()</pre></div></div></div></div></div></div></div></div></div></div>"
      ],
      "text/plain": [
       "RandomizedSearchCV(cv=5, estimator=RandomForestRegressor(), n_jobs=-1,\n",
       "                   param_distributions={'max_depth': [None, 10, 50, 100],\n",
       "                                        'max_features': ['auto', 'sqrt'],\n",
       "                                        'min_samples_leaf': [1, 2, 4],\n",
       "                                        'min_samples_split': [2, 5, 10],\n",
       "                                        'n_estimators': [100, 300, 500]},\n",
       "                   scoring='neg_mean_absolute_error')"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rscv.fit(X_train1, y_train1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'n_estimators': 500,\n",
       " 'min_samples_split': 5,\n",
       " 'min_samples_leaf': 1,\n",
       " 'max_features': 'auto',\n",
       " 'max_depth': 100}"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rscv.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['rscv_rf_tfidf_best_params_bocim.pkl']"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "joblib.dump(rscv, \"rscv_rf_tfidf_bocim.pkl\")\n",
    "joblib.dump(rscv.best_params_, \"rscv_rf_tfidf_best_params_bocim.pkl\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "RF (after Hyperparameter Tuning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/ns/m5pnr0211w91v02hpv22958m0000gn/T/ipykernel_86350/531738641.py:2: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  rfreg_ht.fit(X_train1, y_train1)\n",
      "/Users/louispandu/anaconda3/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
      "  warn(\n"
     ]
    }
   ],
   "source": [
    "rfreg_ht = RandomForestRegressor(n_estimators = 500, min_samples_split = 5, min_samples_leaf = 1, max_features = 'auto', max_depth = 100)\n",
    "rfreg_ht.fit(X_train1, y_train1)\n",
    "y_pred_rfreg = rfreg_ht.predict(X_val)\n",
    "y_pred_rfreg_r2 = rfreg_ht.predict(X_train1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.03386420693917133"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mean_absolute_error(y_val, y_pred_rfreg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.005879837902378983"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mean_squared_error(y_val, y_pred_rfreg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.07668010108482502"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mean_squared_error(y_val, y_pred_rfreg, squared = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9778755253009022"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#train\n",
    "r2_score(y_train1, y_pred_rfreg_r2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9342226838371706"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#val\n",
    "r2_score(y_val, y_pred_rfreg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Residual plots after Hyperparameter Tuning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Predicting model on the test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_rfreg_test = rfreg_ht.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['y_test_rfreg_tfidf_bocim.pkl']"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "joblib.dump(y_pred_rfreg_test, \"y_pred_rfreg_test_tfidf_bocim.pkl\")\n",
    "joblib.dump(y_test, \"y_test_rfreg_tfidf_bocim.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.03371169909892066"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mean_absolute_error(y_test, y_pred_rfreg_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.005683742649763477"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mean_squared_error(y_test, y_pred_rfreg_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.07539060053987816"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mean_squared_error(y_test, y_pred_rfreg_test, squared = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9355632206094642"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "r2_score(y_test, y_pred_rfreg_test)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Error analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 800x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# assume y_pred is a numpy array and y_true is a pandas dataframe\n",
    "fig, ax = plt.subplots(figsize=(8, 6))\n",
    "\n",
    "column = \"X..Beta-Ocimene\"  # specify the target variable name\n",
    "ax.hist(y_pred_rfreg_test, alpha=0.5, label='y_pred', bins=20)\n",
    "ax.hist(y_test[column], alpha=0.5, label='y_true', bins=20)\n",
    "ax.legend(loc='upper right')\n",
    "ax.set_title(column)\n",
    "\n",
    "plt.show()\n",
    "plt.savefig('error_hist_knn_tfidf_bocim.png')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pearson R"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pearson correlation coefficient: 0.969\n",
      "P-value: 0.000\n"
     ]
    }
   ],
   "source": [
    "corr_coef, p_value = pearsonr(y_pred_rfreg_test.flatten(), y_test.values.ravel())\n",
    "\n",
    "print(f\"Pearson correlation coefficient: {corr_coef:.3f}\")\n",
    "print(f\"P-value: {p_value:.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Axes: >"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "corr_matrix = y_test.corr()\n",
    "sns.heatmap(corr_matrix, annot=True, cmap='coolwarm', center=0)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
