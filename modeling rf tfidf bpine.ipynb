{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn import preprocessing\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.neural_network import MLPRegressor\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "from sklearn.metrics import r2_score\n",
    "from scipy.stats import pearsonr\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.feature_selection import SelectFromModel\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compiling complete dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_rf = pd.read_csv(\"df_bpine_tfidf.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['index',\n",
       " 'tfidf_0',\n",
       " 'tfidf_1',\n",
       " 'tfidf_2',\n",
       " 'tfidf_3',\n",
       " 'tfidf_4',\n",
       " 'tfidf_5',\n",
       " 'tfidf_6',\n",
       " 'tfidf_7',\n",
       " 'tfidf_8',\n",
       " 'tfidf_9',\n",
       " 'tfidf_10',\n",
       " 'tfidf_11',\n",
       " 'tfidf_12',\n",
       " 'tfidf_13',\n",
       " 'tfidf_14',\n",
       " 'tfidf_15',\n",
       " 'tfidf_16',\n",
       " 'tfidf_17',\n",
       " 'tfidf_18',\n",
       " 'tfidf_19',\n",
       " 'tfidf_20',\n",
       " 'tfidf_21',\n",
       " 'tfidf_22',\n",
       " 'tfidf_23',\n",
       " 'tfidf_24',\n",
       " 'tfidf_25',\n",
       " 'tfidf_26',\n",
       " 'tfidf_27',\n",
       " 'tfidf_28',\n",
       " 'tfidf_29',\n",
       " 'tfidf_30',\n",
       " 'tfidf_31',\n",
       " 'tfidf_32',\n",
       " 'tfidf_33',\n",
       " 'tfidf_34',\n",
       " 'tfidf_35',\n",
       " 'tfidf_36',\n",
       " 'tfidf_37',\n",
       " 'tfidf_38',\n",
       " 'tfidf_39',\n",
       " 'tfidf_40',\n",
       " 'tfidf_41',\n",
       " 'tfidf_42',\n",
       " 'tfidf_43',\n",
       " 'tfidf_44',\n",
       " 'tfidf_45',\n",
       " 'tfidf_46',\n",
       " 'tfidf_47',\n",
       " 'tfidf_48',\n",
       " 'tfidf_49',\n",
       " 'tfidf_50',\n",
       " 'tfidf_51',\n",
       " 'tfidf_52',\n",
       " 'tfidf_53',\n",
       " 'tfidf_54',\n",
       " 'tfidf_55',\n",
       " 'tfidf_56',\n",
       " 'tfidf_57',\n",
       " 'tfidf_58',\n",
       " 'tfidf_59',\n",
       " 'tfidf_60',\n",
       " 'tfidf_61',\n",
       " 'tfidf_62',\n",
       " 'tfidf_63',\n",
       " 'tfidf_64',\n",
       " 'tfidf_65',\n",
       " 'tfidf_66',\n",
       " 'tfidf_67',\n",
       " 'tfidf_68',\n",
       " 'tfidf_69',\n",
       " 'tfidf_70',\n",
       " 'tfidf_71',\n",
       " 'tfidf_72',\n",
       " 'tfidf_73',\n",
       " 'tfidf_74',\n",
       " 'tfidf_75',\n",
       " 'tfidf_76',\n",
       " 'tfidf_77',\n",
       " 'tfidf_78',\n",
       " 'tfidf_79',\n",
       " 'tfidf_80',\n",
       " 'tfidf_81',\n",
       " 'tfidf_82',\n",
       " 'tfidf_83',\n",
       " 'tfidf_84',\n",
       " 'tfidf_85',\n",
       " 'tfidf_86',\n",
       " 'tfidf_87',\n",
       " 'tfidf_88',\n",
       " 'tfidf_89',\n",
       " 'tfidf_90',\n",
       " 'tfidf_91',\n",
       " 'tfidf_92',\n",
       " 'tfidf_93',\n",
       " 'tfidf_94',\n",
       " 'tfidf_95',\n",
       " 'tfidf_96',\n",
       " 'tfidf_97',\n",
       " 'tfidf_98',\n",
       " 'tfidf_99',\n",
       " 'tfidf_100',\n",
       " 'tfidf_101',\n",
       " 'tfidf_102',\n",
       " 'tfidf_103',\n",
       " 'tfidf_104',\n",
       " 'tfidf_105',\n",
       " 'tfidf_106',\n",
       " 'tfidf_107',\n",
       " 'tfidf_108',\n",
       " 'tfidf_109',\n",
       " 'tfidf_110',\n",
       " 'tfidf_111',\n",
       " 'tfidf_112',\n",
       " 'tfidf_113',\n",
       " 'tfidf_114',\n",
       " 'tfidf_115',\n",
       " 'tfidf_116',\n",
       " 'tfidf_117',\n",
       " 'tfidf_118',\n",
       " 'tfidf_119',\n",
       " 'tfidf_120',\n",
       " 'tfidf_121',\n",
       " 'tfidf_122',\n",
       " 'tfidf_123',\n",
       " 'tfidf_124',\n",
       " 'tfidf_125',\n",
       " 'tfidf_126',\n",
       " 'tfidf_127',\n",
       " 'tfidf_128',\n",
       " 'tfidf_129',\n",
       " 'tfidf_130',\n",
       " 'tfidf_131',\n",
       " 'tfidf_132',\n",
       " 'tfidf_133',\n",
       " 'tfidf_134',\n",
       " 'tfidf_135',\n",
       " 'tfidf_136',\n",
       " 'tfidf_137',\n",
       " 'tfidf_138',\n",
       " 'tfidf_139',\n",
       " 'tfidf_140',\n",
       " 'tfidf_141',\n",
       " 'tfidf_142',\n",
       " 'tfidf_143',\n",
       " 'tfidf_144',\n",
       " 'tfidf_145',\n",
       " 'tfidf_146',\n",
       " 'tfidf_147',\n",
       " 'tfidf_148',\n",
       " 'tfidf_149',\n",
       " 'tfidf_150',\n",
       " 'tfidf_151',\n",
       " 'tfidf_152',\n",
       " 'tfidf_153',\n",
       " 'tfidf_154',\n",
       " 'tfidf_155',\n",
       " 'tfidf_156',\n",
       " 'tfidf_157',\n",
       " 'tfidf_158',\n",
       " 'tfidf_159',\n",
       " 'tfidf_160',\n",
       " 'tfidf_161',\n",
       " 'tfidf_162',\n",
       " 'tfidf_163',\n",
       " 'tfidf_164',\n",
       " 'tfidf_165',\n",
       " 'tfidf_166',\n",
       " 'tfidf_167',\n",
       " 'tfidf_168',\n",
       " 'tfidf_169',\n",
       " 'tfidf_170',\n",
       " 'tfidf_171',\n",
       " 'tfidf_172',\n",
       " 'tfidf_173',\n",
       " 'tfidf_174',\n",
       " 'tfidf_175',\n",
       " 'tfidf_176',\n",
       " 'tfidf_177',\n",
       " 'tfidf_178',\n",
       " 'tfidf_179',\n",
       " 'tfidf_180',\n",
       " 'tfidf_181',\n",
       " 'tfidf_182',\n",
       " 'tfidf_183',\n",
       " 'tfidf_184',\n",
       " 'tfidf_185',\n",
       " 'tfidf_186',\n",
       " 'tfidf_187',\n",
       " 'tfidf_188',\n",
       " 'tfidf_189',\n",
       " 'tfidf_190',\n",
       " 'tfidf_191',\n",
       " 'tfidf_192',\n",
       " 'tfidf_193',\n",
       " 'tfidf_194',\n",
       " 'tfidf_195',\n",
       " 'tfidf_196',\n",
       " 'tfidf_197',\n",
       " 'tfidf_198',\n",
       " 'tfidf_199',\n",
       " 'tfidf_200',\n",
       " 'tfidf_201',\n",
       " 'tfidf_202',\n",
       " 'tfidf_203',\n",
       " 'tfidf_204',\n",
       " 'tfidf_205',\n",
       " 'tfidf_206',\n",
       " 'tfidf_207',\n",
       " 'tfidf_208',\n",
       " 'tfidf_209',\n",
       " 'tfidf_210',\n",
       " 'tfidf_211',\n",
       " 'tfidf_212',\n",
       " 'tfidf_213',\n",
       " 'tfidf_214',\n",
       " 'tfidf_215',\n",
       " 'tfidf_216',\n",
       " 'tfidf_217',\n",
       " 'tfidf_218',\n",
       " 'tfidf_219',\n",
       " 'tfidf_220',\n",
       " 'tfidf_221',\n",
       " 'tfidf_222',\n",
       " 'tfidf_223',\n",
       " 'tfidf_224',\n",
       " 'tfidf_225',\n",
       " 'tfidf_226',\n",
       " 'tfidf_227',\n",
       " 'tfidf_228',\n",
       " 'tfidf_229',\n",
       " 'tfidf_230',\n",
       " 'tfidf_231',\n",
       " 'tfidf_232',\n",
       " 'tfidf_233',\n",
       " 'tfidf_234',\n",
       " 'tfidf_235',\n",
       " 'tfidf_236',\n",
       " 'tfidf_237',\n",
       " 'tfidf_238',\n",
       " 'tfidf_239',\n",
       " 'tfidf_240',\n",
       " 'tfidf_241',\n",
       " 'tfidf_242',\n",
       " 'tfidf_243',\n",
       " 'tfidf_244',\n",
       " 'tfidf_245',\n",
       " 'tfidf_246',\n",
       " 'tfidf_247',\n",
       " 'tfidf_248',\n",
       " 'tfidf_249',\n",
       " 'tfidf_250',\n",
       " 'tfidf_251',\n",
       " 'tfidf_252',\n",
       " 'tfidf_253',\n",
       " 'tfidf_254',\n",
       " 'tfidf_255',\n",
       " 'tfidf_256',\n",
       " 'tfidf_257',\n",
       " 'tfidf_258',\n",
       " 'tfidf_259',\n",
       " 'tfidf_260',\n",
       " 'tfidf_261',\n",
       " 'tfidf_262',\n",
       " 'tfidf_263',\n",
       " 'tfidf_264',\n",
       " 'tfidf_265',\n",
       " 'tfidf_266',\n",
       " 'tfidf_267',\n",
       " 'tfidf_268',\n",
       " 'tfidf_269',\n",
       " 'tfidf_270',\n",
       " 'tfidf_271',\n",
       " 'tfidf_272',\n",
       " 'tfidf_273',\n",
       " 'tfidf_274',\n",
       " 'tfidf_275',\n",
       " 'tfidf_276',\n",
       " 'tfidf_277',\n",
       " 'tfidf_278',\n",
       " 'tfidf_279',\n",
       " 'tfidf_280',\n",
       " 'tfidf_281',\n",
       " 'tfidf_282',\n",
       " 'tfidf_283',\n",
       " 'tfidf_284',\n",
       " 'tfidf_285',\n",
       " 'tfidf_286',\n",
       " 'tfidf_287',\n",
       " 'tfidf_288',\n",
       " 'tfidf_289',\n",
       " 'tfidf_290',\n",
       " 'tfidf_291',\n",
       " 'tfidf_292',\n",
       " 'tfidf_293',\n",
       " 'tfidf_294',\n",
       " 'tfidf_295',\n",
       " 'tfidf_296',\n",
       " 'tfidf_297',\n",
       " 'tfidf_298',\n",
       " 'tfidf_299',\n",
       " 'tfidf_300',\n",
       " 'tfidf_301',\n",
       " 'tfidf_302',\n",
       " 'tfidf_303',\n",
       " 'tfidf_304',\n",
       " 'tfidf_305',\n",
       " 'tfidf_306',\n",
       " 'tfidf_307',\n",
       " 'tfidf_308',\n",
       " 'tfidf_309',\n",
       " 'tfidf_310',\n",
       " 'tfidf_311',\n",
       " 'tfidf_312',\n",
       " 'tfidf_313',\n",
       " 'tfidf_314',\n",
       " 'tfidf_315',\n",
       " 'tfidf_316',\n",
       " 'tfidf_317',\n",
       " 'tfidf_318',\n",
       " 'tfidf_319',\n",
       " 'tfidf_320',\n",
       " 'tfidf_321',\n",
       " 'tfidf_322',\n",
       " 'tfidf_323',\n",
       " 'tfidf_324',\n",
       " 'tfidf_325',\n",
       " 'tfidf_326',\n",
       " 'tfidf_327',\n",
       " 'tfidf_328',\n",
       " 'tfidf_329',\n",
       " 'tfidf_330',\n",
       " 'tfidf_331',\n",
       " 'tfidf_332',\n",
       " 'tfidf_333',\n",
       " 'tfidf_334',\n",
       " 'tfidf_335',\n",
       " 'tfidf_336',\n",
       " 'tfidf_337',\n",
       " 'tfidf_338',\n",
       " 'tfidf_339',\n",
       " 'tfidf_340',\n",
       " 'tfidf_341',\n",
       " 'tfidf_342',\n",
       " 'tfidf_343',\n",
       " 'tfidf_344',\n",
       " 'tfidf_345',\n",
       " 'tfidf_346',\n",
       " 'tfidf_347',\n",
       " 'tfidf_348',\n",
       " 'tfidf_349',\n",
       " 'tfidf_350',\n",
       " 'tfidf_351',\n",
       " 'tfidf_352',\n",
       " 'tfidf_353',\n",
       " 'tfidf_354',\n",
       " 'tfidf_355',\n",
       " 'tfidf_356',\n",
       " 'tfidf_357',\n",
       " 'tfidf_358',\n",
       " 'tfidf_359',\n",
       " 'tfidf_360',\n",
       " 'tfidf_361',\n",
       " 'tfidf_362',\n",
       " 'tfidf_363',\n",
       " 'tfidf_364',\n",
       " 'tfidf_365',\n",
       " 'tfidf_366',\n",
       " 'tfidf_367',\n",
       " 'tfidf_368',\n",
       " 'tfidf_369',\n",
       " 'tfidf_370',\n",
       " 'tfidf_371',\n",
       " 'tfidf_372',\n",
       " 'tfidf_373',\n",
       " 'tfidf_374',\n",
       " 'tfidf_375',\n",
       " 'tfidf_376',\n",
       " 'tfidf_377',\n",
       " 'tfidf_378',\n",
       " 'tfidf_379',\n",
       " 'tfidf_380',\n",
       " 'tfidf_381',\n",
       " 'tfidf_382',\n",
       " 'tfidf_383',\n",
       " 'tfidf_384',\n",
       " 'tfidf_385',\n",
       " 'tfidf_386',\n",
       " 'tfidf_387',\n",
       " 'hybrid',\n",
       " 'indica',\n",
       " 'sativa',\n",
       " 'anxiety',\n",
       " 'anxious',\n",
       " 'aroused',\n",
       " 'arthritis',\n",
       " 'creative',\n",
       " 'depression',\n",
       " 'dizzy',\n",
       " 'dry eyes',\n",
       " 'dry mouth',\n",
       " 'energetic',\n",
       " 'epilepsy',\n",
       " 'euphoric',\n",
       " 'eye pressure',\n",
       " 'fatigue',\n",
       " 'focused',\n",
       " 'giggly',\n",
       " 'happy',\n",
       " 'headache',\n",
       " 'hungry',\n",
       " 'migraines',\n",
       " 'pain',\n",
       " 'paranoid',\n",
       " 'relaxed',\n",
       " 'seizures',\n",
       " 'sleepy',\n",
       " 'spasticity',\n",
       " 'stress',\n",
       " 'talkative',\n",
       " 'tingly',\n",
       " 'uplifted',\n",
       " 'ammonia',\n",
       " 'apple',\n",
       " 'apricot',\n",
       " 'berry',\n",
       " 'blue cheese',\n",
       " 'blueberry',\n",
       " 'butter',\n",
       " 'cheese',\n",
       " 'chemical',\n",
       " 'chestnut',\n",
       " 'citrus',\n",
       " 'coffee',\n",
       " 'diesel',\n",
       " 'earthy',\n",
       " 'flowery',\n",
       " 'fruit',\n",
       " 'grape',\n",
       " 'grapefruit',\n",
       " 'honey',\n",
       " 'lavender',\n",
       " 'lemon',\n",
       " 'lime',\n",
       " 'mango',\n",
       " 'menthol',\n",
       " 'mint',\n",
       " 'nutty',\n",
       " 'orange',\n",
       " 'peach',\n",
       " 'pear',\n",
       " 'pepper',\n",
       " 'pine',\n",
       " 'pineapple',\n",
       " 'plum',\n",
       " 'pungent',\n",
       " 'rose',\n",
       " 'sage',\n",
       " 'skunk',\n",
       " 'spicy/herbal',\n",
       " 'strawberry',\n",
       " 'sweet',\n",
       " 'tar',\n",
       " 'tea',\n",
       " 'tobacco',\n",
       " 'tree',\n",
       " 'tropical',\n",
       " 'vanilla',\n",
       " 'violet',\n",
       " 'woody',\n",
       " 'X..Beta-Pinene']"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_rf.columns.to_list()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Splitting dependent and independent variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df_rf.drop(['index', 'X..Beta-Pinene'], axis = 1)\n",
    "y = df_rf[['X..Beta-Pinene']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plotting histograms on target variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.01666667],\n",
       "       [0.01666667],\n",
       "       [0.01666667],\n",
       "       ...,\n",
       "       [0.00333333],\n",
       "       [0.00333333],\n",
       "       [0.00333333]])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_array = y.to_numpy()\n",
    "y_array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Axes: ylabel='Count'>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "sns.histplot(y, bins = 10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train test split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=1, test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train1, X_val, y_train1, y_val = train_test_split(X_train, y_train, random_state=1, test_size=0.25)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "RF modeling (before Feature selection and Hyperparameter Tuning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/ns/m5pnr0211w91v02hpv22958m0000gn/T/ipykernel_87785/350139188.py:2: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  rfreg.fit(X_train1, y_train1)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;background-color: white;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>RandomForestRegressor()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">RandomForestRegressor</label><div class=\"sk-toggleable__content\"><pre>RandomForestRegressor()</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "RandomForestRegressor()"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rfreg = RandomForestRegressor()\n",
    "rfreg.fit(X_train1, y_train1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_rfreg = rfreg.predict(X_val)\n",
    "y_pred_rfreg_r2 = rfreg.predict(X_train1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.019634595212711353"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mean_absolute_error(y_val, y_pred_rfreg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.008715950124610676"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mean_squared_error(y_val, y_pred_rfreg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.09335925302084778"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mean_squared_error(y_val, y_pred_rfreg, squared = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9904601455440815"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#train\n",
    "r2_score(y_train1, y_pred_rfreg_r2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9646302446249839"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#val\n",
    "r2_score(y_val, y_pred_rfreg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Residual plots for each target variable"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Feature Selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_feat = pd.DataFrame({\n",
    "    \"features\": X_train1.columns,\n",
    "    \"score\": rfreg.feature_importances_\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>features</th>\n",
       "      <th>score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>tfidf_0</td>\n",
       "      <td>0.000035</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>tfidf_1</td>\n",
       "      <td>0.000276</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>tfidf_2</td>\n",
       "      <td>0.000855</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>tfidf_3</td>\n",
       "      <td>0.000034</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>tfidf_4</td>\n",
       "      <td>0.000118</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>464</th>\n",
       "      <td>tree</td>\n",
       "      <td>0.000340</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>465</th>\n",
       "      <td>tropical</td>\n",
       "      <td>0.000267</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>466</th>\n",
       "      <td>vanilla</td>\n",
       "      <td>0.001693</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>467</th>\n",
       "      <td>violet</td>\n",
       "      <td>0.000116</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>468</th>\n",
       "      <td>woody</td>\n",
       "      <td>0.002662</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>469 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     features     score\n",
       "0     tfidf_0  0.000035\n",
       "1     tfidf_1  0.000276\n",
       "2     tfidf_2  0.000855\n",
       "3     tfidf_3  0.000034\n",
       "4     tfidf_4  0.000118\n",
       "..        ...       ...\n",
       "464      tree  0.000340\n",
       "465  tropical  0.000267\n",
       "466   vanilla  0.001693\n",
       "467    violet  0.000116\n",
       "468     woody  0.002662\n",
       "\n",
       "[469 rows x 2 columns]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_feat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_feat_ranked = df_feat.sort_values(\"score\", ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>features</th>\n",
       "      <th>score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>389</th>\n",
       "      <td>indica</td>\n",
       "      <td>5.912507e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>426</th>\n",
       "      <td>blueberry</td>\n",
       "      <td>4.268550e-02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>309</th>\n",
       "      <td>tfidf_309</td>\n",
       "      <td>1.130450e-02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>tfidf_29</td>\n",
       "      <td>7.991770e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>270</th>\n",
       "      <td>tfidf_270</td>\n",
       "      <td>6.188045e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>329</th>\n",
       "      <td>tfidf_329</td>\n",
       "      <td>5.184732e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>181</th>\n",
       "      <td>tfidf_181</td>\n",
       "      <td>4.905887e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>tfidf_39</td>\n",
       "      <td>4.075168e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>333</th>\n",
       "      <td>tfidf_333</td>\n",
       "      <td>3.755611e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>340</th>\n",
       "      <td>tfidf_340</td>\n",
       "      <td>3.744376e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>310</th>\n",
       "      <td>tfidf_310</td>\n",
       "      <td>3.600043e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>285</th>\n",
       "      <td>tfidf_285</td>\n",
       "      <td>3.535282e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>264</th>\n",
       "      <td>tfidf_264</td>\n",
       "      <td>3.292573e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>121</th>\n",
       "      <td>tfidf_121</td>\n",
       "      <td>3.290212e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>437</th>\n",
       "      <td>grape</td>\n",
       "      <td>3.283758e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>197</th>\n",
       "      <td>tfidf_197</td>\n",
       "      <td>3.227394e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>tfidf_7</td>\n",
       "      <td>3.183797e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>302</th>\n",
       "      <td>tfidf_302</td>\n",
       "      <td>3.158932e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>119</th>\n",
       "      <td>tfidf_119</td>\n",
       "      <td>3.112183e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>198</th>\n",
       "      <td>tfidf_198</td>\n",
       "      <td>2.970235e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>265</th>\n",
       "      <td>tfidf_265</td>\n",
       "      <td>2.858327e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>132</th>\n",
       "      <td>tfidf_132</td>\n",
       "      <td>2.765220e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>125</th>\n",
       "      <td>tfidf_125</td>\n",
       "      <td>2.731943e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>254</th>\n",
       "      <td>tfidf_254</td>\n",
       "      <td>2.713630e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>168</th>\n",
       "      <td>tfidf_168</td>\n",
       "      <td>2.681737e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>468</th>\n",
       "      <td>woody</td>\n",
       "      <td>2.661698e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>105</th>\n",
       "      <td>tfidf_105</td>\n",
       "      <td>2.582859e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>145</th>\n",
       "      <td>tfidf_145</td>\n",
       "      <td>2.555922e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>157</th>\n",
       "      <td>tfidf_157</td>\n",
       "      <td>2.499061e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>260</th>\n",
       "      <td>tfidf_260</td>\n",
       "      <td>2.451840e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>193</th>\n",
       "      <td>tfidf_193</td>\n",
       "      <td>2.441902e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>175</th>\n",
       "      <td>tfidf_175</td>\n",
       "      <td>2.409674e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>135</th>\n",
       "      <td>tfidf_135</td>\n",
       "      <td>2.401830e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>84</th>\n",
       "      <td>tfidf_84</td>\n",
       "      <td>2.379887e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>347</th>\n",
       "      <td>tfidf_347</td>\n",
       "      <td>2.315689e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>101</th>\n",
       "      <td>tfidf_101</td>\n",
       "      <td>2.313360e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>154</th>\n",
       "      <td>tfidf_154</td>\n",
       "      <td>2.272451e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>224</th>\n",
       "      <td>tfidf_224</td>\n",
       "      <td>2.269716e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>200</th>\n",
       "      <td>tfidf_200</td>\n",
       "      <td>2.231193e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>237</th>\n",
       "      <td>tfidf_237</td>\n",
       "      <td>2.201401e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>244</th>\n",
       "      <td>tfidf_244</td>\n",
       "      <td>2.173946e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>179</th>\n",
       "      <td>tfidf_179</td>\n",
       "      <td>2.149059e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>150</th>\n",
       "      <td>tfidf_150</td>\n",
       "      <td>2.089532e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>369</th>\n",
       "      <td>tfidf_369</td>\n",
       "      <td>2.055757e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>tfidf_32</td>\n",
       "      <td>2.036855e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>207</th>\n",
       "      <td>tfidf_207</td>\n",
       "      <td>1.995014e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>57</th>\n",
       "      <td>tfidf_57</td>\n",
       "      <td>1.963283e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>344</th>\n",
       "      <td>tfidf_344</td>\n",
       "      <td>1.944182e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>312</th>\n",
       "      <td>tfidf_312</td>\n",
       "      <td>1.937301e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>273</th>\n",
       "      <td>tfidf_273</td>\n",
       "      <td>1.928296e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>368</th>\n",
       "      <td>tfidf_368</td>\n",
       "      <td>1.908974e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>294</th>\n",
       "      <td>tfidf_294</td>\n",
       "      <td>1.887907e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>117</th>\n",
       "      <td>tfidf_117</td>\n",
       "      <td>1.879860e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>238</th>\n",
       "      <td>tfidf_238</td>\n",
       "      <td>1.869467e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>74</th>\n",
       "      <td>tfidf_74</td>\n",
       "      <td>1.859193e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>278</th>\n",
       "      <td>tfidf_278</td>\n",
       "      <td>1.847166e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>327</th>\n",
       "      <td>tfidf_327</td>\n",
       "      <td>1.822465e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>341</th>\n",
       "      <td>tfidf_341</td>\n",
       "      <td>1.821527e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>205</th>\n",
       "      <td>tfidf_205</td>\n",
       "      <td>1.800666e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>149</th>\n",
       "      <td>tfidf_149</td>\n",
       "      <td>1.765791e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>289</th>\n",
       "      <td>tfidf_289</td>\n",
       "      <td>1.727937e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>313</th>\n",
       "      <td>tfidf_313</td>\n",
       "      <td>1.726957e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>138</th>\n",
       "      <td>tfidf_138</td>\n",
       "      <td>1.724151e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>466</th>\n",
       "      <td>vanilla</td>\n",
       "      <td>1.692715e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>214</th>\n",
       "      <td>tfidf_214</td>\n",
       "      <td>1.692228e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>357</th>\n",
       "      <td>tfidf_357</td>\n",
       "      <td>1.631326e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>345</th>\n",
       "      <td>tfidf_345</td>\n",
       "      <td>1.630553e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>253</th>\n",
       "      <td>tfidf_253</td>\n",
       "      <td>1.622244e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>338</th>\n",
       "      <td>tfidf_338</td>\n",
       "      <td>1.612501e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>tfidf_20</td>\n",
       "      <td>1.610512e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>407</th>\n",
       "      <td>happy</td>\n",
       "      <td>1.606392e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>tfidf_24</td>\n",
       "      <td>1.591498e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>325</th>\n",
       "      <td>tfidf_325</td>\n",
       "      <td>1.562662e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>112</th>\n",
       "      <td>tfidf_112</td>\n",
       "      <td>1.534985e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>206</th>\n",
       "      <td>tfidf_206</td>\n",
       "      <td>1.534513e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>110</th>\n",
       "      <td>tfidf_110</td>\n",
       "      <td>1.524587e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>128</th>\n",
       "      <td>tfidf_128</td>\n",
       "      <td>1.504737e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>376</th>\n",
       "      <td>tfidf_376</td>\n",
       "      <td>1.491665e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>222</th>\n",
       "      <td>tfidf_222</td>\n",
       "      <td>1.456654e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>337</th>\n",
       "      <td>tfidf_337</td>\n",
       "      <td>1.456626e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>354</th>\n",
       "      <td>tfidf_354</td>\n",
       "      <td>1.442934e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>55</th>\n",
       "      <td>tfidf_55</td>\n",
       "      <td>1.414034e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>406</th>\n",
       "      <td>giggly</td>\n",
       "      <td>1.411947e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>413</th>\n",
       "      <td>relaxed</td>\n",
       "      <td>1.389872e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>348</th>\n",
       "      <td>tfidf_348</td>\n",
       "      <td>1.386727e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>283</th>\n",
       "      <td>tfidf_283</td>\n",
       "      <td>1.366759e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>304</th>\n",
       "      <td>tfidf_304</td>\n",
       "      <td>1.352139e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>tfidf_46</td>\n",
       "      <td>1.325692e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>tfidf_6</td>\n",
       "      <td>1.312057e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>241</th>\n",
       "      <td>tfidf_241</td>\n",
       "      <td>1.308914e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>199</th>\n",
       "      <td>tfidf_199</td>\n",
       "      <td>1.294379e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>232</th>\n",
       "      <td>tfidf_232</td>\n",
       "      <td>1.291856e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>tfidf_17</td>\n",
       "      <td>1.259566e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>336</th>\n",
       "      <td>tfidf_336</td>\n",
       "      <td>1.233782e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>tfidf_37</td>\n",
       "      <td>1.219618e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>320</th>\n",
       "      <td>tfidf_320</td>\n",
       "      <td>1.201545e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>409</th>\n",
       "      <td>hungry</td>\n",
       "      <td>1.198319e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>307</th>\n",
       "      <td>tfidf_307</td>\n",
       "      <td>1.189975e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>382</th>\n",
       "      <td>tfidf_382</td>\n",
       "      <td>1.185838e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>360</th>\n",
       "      <td>tfidf_360</td>\n",
       "      <td>1.180555e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>314</th>\n",
       "      <td>tfidf_314</td>\n",
       "      <td>1.178794e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>93</th>\n",
       "      <td>tfidf_93</td>\n",
       "      <td>1.176519e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>362</th>\n",
       "      <td>tfidf_362</td>\n",
       "      <td>1.176466e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>89</th>\n",
       "      <td>tfidf_89</td>\n",
       "      <td>1.150125e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>tfidf_14</td>\n",
       "      <td>1.142302e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>186</th>\n",
       "      <td>tfidf_186</td>\n",
       "      <td>1.138400e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>463</th>\n",
       "      <td>tobacco</td>\n",
       "      <td>1.115733e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>104</th>\n",
       "      <td>tfidf_104</td>\n",
       "      <td>1.109640e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>155</th>\n",
       "      <td>tfidf_155</td>\n",
       "      <td>1.101674e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>287</th>\n",
       "      <td>tfidf_287</td>\n",
       "      <td>1.090206e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>399</th>\n",
       "      <td>dry mouth</td>\n",
       "      <td>1.059359e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>375</th>\n",
       "      <td>tfidf_375</td>\n",
       "      <td>1.056703e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>290</th>\n",
       "      <td>tfidf_290</td>\n",
       "      <td>1.043012e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>343</th>\n",
       "      <td>tfidf_343</td>\n",
       "      <td>1.036751e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>217</th>\n",
       "      <td>tfidf_217</td>\n",
       "      <td>1.033714e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>163</th>\n",
       "      <td>tfidf_163</td>\n",
       "      <td>1.033567e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>187</th>\n",
       "      <td>tfidf_187</td>\n",
       "      <td>1.022033e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>251</th>\n",
       "      <td>tfidf_251</td>\n",
       "      <td>1.016085e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>60</th>\n",
       "      <td>tfidf_60</td>\n",
       "      <td>1.014915e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>415</th>\n",
       "      <td>sleepy</td>\n",
       "      <td>1.013770e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>324</th>\n",
       "      <td>tfidf_324</td>\n",
       "      <td>1.008794e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>tfidf_97</td>\n",
       "      <td>9.960693e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>tfidf_30</td>\n",
       "      <td>9.942827e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>166</th>\n",
       "      <td>tfidf_166</td>\n",
       "      <td>9.845424e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>405</th>\n",
       "      <td>focused</td>\n",
       "      <td>9.773014e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>239</th>\n",
       "      <td>tfidf_239</td>\n",
       "      <td>9.716645e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>230</th>\n",
       "      <td>tfidf_230</td>\n",
       "      <td>9.613996e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>79</th>\n",
       "      <td>tfidf_79</td>\n",
       "      <td>9.579818e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>245</th>\n",
       "      <td>tfidf_245</td>\n",
       "      <td>9.505687e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>107</th>\n",
       "      <td>tfidf_107</td>\n",
       "      <td>9.463041e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>402</th>\n",
       "      <td>euphoric</td>\n",
       "      <td>9.442861e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>tfidf_5</td>\n",
       "      <td>9.426859e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>115</th>\n",
       "      <td>tfidf_115</td>\n",
       "      <td>9.404567e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>tfidf_22</td>\n",
       "      <td>9.356126e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>215</th>\n",
       "      <td>tfidf_215</td>\n",
       "      <td>9.213639e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>218</th>\n",
       "      <td>tfidf_218</td>\n",
       "      <td>9.193919e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>180</th>\n",
       "      <td>tfidf_180</td>\n",
       "      <td>9.189089e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>210</th>\n",
       "      <td>tfidf_210</td>\n",
       "      <td>9.186428e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59</th>\n",
       "      <td>tfidf_59</td>\n",
       "      <td>9.113226e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>171</th>\n",
       "      <td>tfidf_171</td>\n",
       "      <td>8.826368e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>301</th>\n",
       "      <td>tfidf_301</td>\n",
       "      <td>8.567987e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>tfidf_2</td>\n",
       "      <td>8.552375e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>281</th>\n",
       "      <td>tfidf_281</td>\n",
       "      <td>8.470965e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>118</th>\n",
       "      <td>tfidf_118</td>\n",
       "      <td>8.426248e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>tfidf_40</td>\n",
       "      <td>8.353593e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>109</th>\n",
       "      <td>tfidf_109</td>\n",
       "      <td>8.292937e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51</th>\n",
       "      <td>tfidf_51</td>\n",
       "      <td>8.284440e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>258</th>\n",
       "      <td>tfidf_258</td>\n",
       "      <td>8.215418e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>342</th>\n",
       "      <td>tfidf_342</td>\n",
       "      <td>8.205203e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>317</th>\n",
       "      <td>tfidf_317</td>\n",
       "      <td>8.036835e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>165</th>\n",
       "      <td>tfidf_165</td>\n",
       "      <td>8.014632e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>252</th>\n",
       "      <td>tfidf_252</td>\n",
       "      <td>7.866664e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>151</th>\n",
       "      <td>tfidf_151</td>\n",
       "      <td>7.791547e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>311</th>\n",
       "      <td>tfidf_311</td>\n",
       "      <td>7.659643e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>tfidf_44</td>\n",
       "      <td>7.646067e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>346</th>\n",
       "      <td>tfidf_346</td>\n",
       "      <td>7.569983e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>tfidf_36</td>\n",
       "      <td>7.543717e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>235</th>\n",
       "      <td>tfidf_235</td>\n",
       "      <td>7.511171e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>tfidf_43</td>\n",
       "      <td>7.503191e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>291</th>\n",
       "      <td>tfidf_291</td>\n",
       "      <td>7.495872e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>72</th>\n",
       "      <td>tfidf_72</td>\n",
       "      <td>7.393173e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>tfidf_41</td>\n",
       "      <td>7.354364e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>279</th>\n",
       "      <td>tfidf_279</td>\n",
       "      <td>7.338649e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>420</th>\n",
       "      <td>uplifted</td>\n",
       "      <td>7.231225e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>373</th>\n",
       "      <td>tfidf_373</td>\n",
       "      <td>7.203852e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>91</th>\n",
       "      <td>tfidf_91</td>\n",
       "      <td>7.175702e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>352</th>\n",
       "      <td>tfidf_352</td>\n",
       "      <td>7.125453e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>141</th>\n",
       "      <td>tfidf_141</td>\n",
       "      <td>7.115907e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>242</th>\n",
       "      <td>tfidf_242</td>\n",
       "      <td>7.070899e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>114</th>\n",
       "      <td>tfidf_114</td>\n",
       "      <td>7.013964e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>321</th>\n",
       "      <td>tfidf_321</td>\n",
       "      <td>6.861986e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>457</th>\n",
       "      <td>skunk</td>\n",
       "      <td>6.766380e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>400</th>\n",
       "      <td>energetic</td>\n",
       "      <td>6.688555e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>272</th>\n",
       "      <td>tfidf_272</td>\n",
       "      <td>6.655156e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>370</th>\n",
       "      <td>tfidf_370</td>\n",
       "      <td>6.654645e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>367</th>\n",
       "      <td>tfidf_367</td>\n",
       "      <td>6.560496e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>tfidf_35</td>\n",
       "      <td>6.495930e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>434</th>\n",
       "      <td>earthy</td>\n",
       "      <td>6.454571e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>66</th>\n",
       "      <td>tfidf_66</td>\n",
       "      <td>6.322646e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>164</th>\n",
       "      <td>tfidf_164</td>\n",
       "      <td>6.316221e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>275</th>\n",
       "      <td>tfidf_275</td>\n",
       "      <td>6.304688e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>248</th>\n",
       "      <td>tfidf_248</td>\n",
       "      <td>6.301651e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>385</th>\n",
       "      <td>tfidf_385</td>\n",
       "      <td>6.287091e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>303</th>\n",
       "      <td>tfidf_303</td>\n",
       "      <td>6.282791e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>379</th>\n",
       "      <td>tfidf_379</td>\n",
       "      <td>6.257027e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>228</th>\n",
       "      <td>tfidf_228</td>\n",
       "      <td>6.249780e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54</th>\n",
       "      <td>tfidf_54</td>\n",
       "      <td>6.246932e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>351</th>\n",
       "      <td>tfidf_351</td>\n",
       "      <td>6.143835e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>71</th>\n",
       "      <td>tfidf_71</td>\n",
       "      <td>6.096041e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>433</th>\n",
       "      <td>diesel</td>\n",
       "      <td>6.063907e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>tfidf_23</td>\n",
       "      <td>6.031695e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>387</th>\n",
       "      <td>tfidf_387</td>\n",
       "      <td>5.981942e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>tfidf_99</td>\n",
       "      <td>5.949558e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>308</th>\n",
       "      <td>tfidf_308</td>\n",
       "      <td>5.925878e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>106</th>\n",
       "      <td>tfidf_106</td>\n",
       "      <td>5.717377e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>tfidf_9</td>\n",
       "      <td>5.578042e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>328</th>\n",
       "      <td>tfidf_328</td>\n",
       "      <td>5.499452e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>tfidf_96</td>\n",
       "      <td>5.485329e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>455</th>\n",
       "      <td>rose</td>\n",
       "      <td>5.483056e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>tfidf_34</td>\n",
       "      <td>5.473685e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>73</th>\n",
       "      <td>tfidf_73</td>\n",
       "      <td>5.433613e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>219</th>\n",
       "      <td>tfidf_219</td>\n",
       "      <td>5.417044e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>299</th>\n",
       "      <td>tfidf_299</td>\n",
       "      <td>5.409150e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>tfidf_48</td>\n",
       "      <td>5.383841e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>221</th>\n",
       "      <td>tfidf_221</td>\n",
       "      <td>5.380439e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>129</th>\n",
       "      <td>tfidf_129</td>\n",
       "      <td>5.327914e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>445</th>\n",
       "      <td>mint</td>\n",
       "      <td>5.284587e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>408</th>\n",
       "      <td>headache</td>\n",
       "      <td>5.279182e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>123</th>\n",
       "      <td>tfidf_123</td>\n",
       "      <td>5.224985e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>tfidf_11</td>\n",
       "      <td>5.170742e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>194</th>\n",
       "      <td>tfidf_194</td>\n",
       "      <td>5.032906e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>113</th>\n",
       "      <td>tfidf_113</td>\n",
       "      <td>4.972656e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>331</th>\n",
       "      <td>tfidf_331</td>\n",
       "      <td>4.958627e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>334</th>\n",
       "      <td>tfidf_334</td>\n",
       "      <td>4.952626e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>335</th>\n",
       "      <td>tfidf_335</td>\n",
       "      <td>4.938496e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>58</th>\n",
       "      <td>tfidf_58</td>\n",
       "      <td>4.922760e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>142</th>\n",
       "      <td>tfidf_142</td>\n",
       "      <td>4.877244e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>188</th>\n",
       "      <td>tfidf_188</td>\n",
       "      <td>4.860844e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>297</th>\n",
       "      <td>tfidf_297</td>\n",
       "      <td>4.845014e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>286</th>\n",
       "      <td>tfidf_286</td>\n",
       "      <td>4.826940e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>86</th>\n",
       "      <td>tfidf_86</td>\n",
       "      <td>4.823632e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>202</th>\n",
       "      <td>tfidf_202</td>\n",
       "      <td>4.791735e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>247</th>\n",
       "      <td>tfidf_247</td>\n",
       "      <td>4.789019e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>127</th>\n",
       "      <td>tfidf_127</td>\n",
       "      <td>4.788051e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>398</th>\n",
       "      <td>dry eyes</td>\n",
       "      <td>4.715249e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>454</th>\n",
       "      <td>pungent</td>\n",
       "      <td>4.700118e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>236</th>\n",
       "      <td>tfidf_236</td>\n",
       "      <td>4.585226e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>460</th>\n",
       "      <td>sweet</td>\n",
       "      <td>4.537023e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>196</th>\n",
       "      <td>tfidf_196</td>\n",
       "      <td>4.503390e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>153</th>\n",
       "      <td>tfidf_153</td>\n",
       "      <td>4.483172e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>tfidf_15</td>\n",
       "      <td>4.468690e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>tfidf_98</td>\n",
       "      <td>4.452903e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>77</th>\n",
       "      <td>tfidf_77</td>\n",
       "      <td>4.449743e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>419</th>\n",
       "      <td>tingly</td>\n",
       "      <td>4.426531e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>332</th>\n",
       "      <td>tfidf_332</td>\n",
       "      <td>4.353305e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>292</th>\n",
       "      <td>tfidf_292</td>\n",
       "      <td>4.352097e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>190</th>\n",
       "      <td>tfidf_190</td>\n",
       "      <td>4.338192e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>349</th>\n",
       "      <td>tfidf_349</td>\n",
       "      <td>4.305856e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>223</th>\n",
       "      <td>tfidf_223</td>\n",
       "      <td>4.294044e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>tfidf_21</td>\n",
       "      <td>4.285982e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>431</th>\n",
       "      <td>citrus</td>\n",
       "      <td>4.272571e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>162</th>\n",
       "      <td>tfidf_162</td>\n",
       "      <td>4.263703e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>158</th>\n",
       "      <td>tfidf_158</td>\n",
       "      <td>4.208848e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>213</th>\n",
       "      <td>tfidf_213</td>\n",
       "      <td>4.198175e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>146</th>\n",
       "      <td>tfidf_146</td>\n",
       "      <td>4.144332e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>67</th>\n",
       "      <td>tfidf_67</td>\n",
       "      <td>4.135565e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>257</th>\n",
       "      <td>tfidf_257</td>\n",
       "      <td>4.126037e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>395</th>\n",
       "      <td>creative</td>\n",
       "      <td>4.109092e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>306</th>\n",
       "      <td>tfidf_306</td>\n",
       "      <td>4.009934e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>167</th>\n",
       "      <td>tfidf_167</td>\n",
       "      <td>4.004037e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>424</th>\n",
       "      <td>berry</td>\n",
       "      <td>3.876795e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>tfidf_26</td>\n",
       "      <td>3.858295e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>136</th>\n",
       "      <td>tfidf_136</td>\n",
       "      <td>3.843977e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>386</th>\n",
       "      <td>tfidf_386</td>\n",
       "      <td>3.753322e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>418</th>\n",
       "      <td>talkative</td>\n",
       "      <td>3.746960e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>267</th>\n",
       "      <td>tfidf_267</td>\n",
       "      <td>3.713216e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>372</th>\n",
       "      <td>tfidf_372</td>\n",
       "      <td>3.709925e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>234</th>\n",
       "      <td>tfidf_234</td>\n",
       "      <td>3.703366e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>393</th>\n",
       "      <td>aroused</td>\n",
       "      <td>3.698454e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>288</th>\n",
       "      <td>tfidf_288</td>\n",
       "      <td>3.672972e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>78</th>\n",
       "      <td>tfidf_78</td>\n",
       "      <td>3.636279e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>tfidf_16</td>\n",
       "      <td>3.622290e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>220</th>\n",
       "      <td>tfidf_220</td>\n",
       "      <td>3.574166e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>255</th>\n",
       "      <td>tfidf_255</td>\n",
       "      <td>3.512450e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>350</th>\n",
       "      <td>tfidf_350</td>\n",
       "      <td>3.410935e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>464</th>\n",
       "      <td>tree</td>\n",
       "      <td>3.402485e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>87</th>\n",
       "      <td>tfidf_87</td>\n",
       "      <td>3.386864e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>208</th>\n",
       "      <td>tfidf_208</td>\n",
       "      <td>3.380924e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>133</th>\n",
       "      <td>tfidf_133</td>\n",
       "      <td>3.375078e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>211</th>\n",
       "      <td>tfidf_211</td>\n",
       "      <td>3.374080e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>63</th>\n",
       "      <td>tfidf_63</td>\n",
       "      <td>3.341605e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52</th>\n",
       "      <td>tfidf_52</td>\n",
       "      <td>3.306836e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>173</th>\n",
       "      <td>tfidf_173</td>\n",
       "      <td>3.298923e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>tfidf_28</td>\n",
       "      <td>3.263509e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>427</th>\n",
       "      <td>butter</td>\n",
       "      <td>3.222791e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>444</th>\n",
       "      <td>menthol</td>\n",
       "      <td>3.033093e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>tfidf_33</td>\n",
       "      <td>3.029613e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>192</th>\n",
       "      <td>tfidf_192</td>\n",
       "      <td>3.013861e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>280</th>\n",
       "      <td>tfidf_280</td>\n",
       "      <td>2.986698e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>62</th>\n",
       "      <td>tfidf_62</td>\n",
       "      <td>2.961328e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>441</th>\n",
       "      <td>lemon</td>\n",
       "      <td>2.876426e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>277</th>\n",
       "      <td>tfidf_277</td>\n",
       "      <td>2.864932e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>383</th>\n",
       "      <td>tfidf_383</td>\n",
       "      <td>2.834899e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>358</th>\n",
       "      <td>tfidf_358</td>\n",
       "      <td>2.810402e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>229</th>\n",
       "      <td>tfidf_229</td>\n",
       "      <td>2.791865e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>126</th>\n",
       "      <td>tfidf_126</td>\n",
       "      <td>2.768851e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>tfidf_1</td>\n",
       "      <td>2.760318e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>100</th>\n",
       "      <td>tfidf_100</td>\n",
       "      <td>2.735819e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>tfidf_27</td>\n",
       "      <td>2.689358e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>216</th>\n",
       "      <td>tfidf_216</td>\n",
       "      <td>2.687472e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>268</th>\n",
       "      <td>tfidf_268</td>\n",
       "      <td>2.676725e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>465</th>\n",
       "      <td>tropical</td>\n",
       "      <td>2.672641e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>124</th>\n",
       "      <td>tfidf_124</td>\n",
       "      <td>2.668199e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>120</th>\n",
       "      <td>tfidf_120</td>\n",
       "      <td>2.656683e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>356</th>\n",
       "      <td>tfidf_356</td>\n",
       "      <td>2.655285e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>191</th>\n",
       "      <td>tfidf_191</td>\n",
       "      <td>2.645641e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>90</th>\n",
       "      <td>tfidf_90</td>\n",
       "      <td>2.626200e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>374</th>\n",
       "      <td>tfidf_374</td>\n",
       "      <td>2.608990e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>435</th>\n",
       "      <td>flowery</td>\n",
       "      <td>2.595125e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>330</th>\n",
       "      <td>tfidf_330</td>\n",
       "      <td>2.579825e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>355</th>\n",
       "      <td>tfidf_355</td>\n",
       "      <td>2.523824e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>271</th>\n",
       "      <td>tfidf_271</td>\n",
       "      <td>2.495064e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>326</th>\n",
       "      <td>tfidf_326</td>\n",
       "      <td>2.494329e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50</th>\n",
       "      <td>tfidf_50</td>\n",
       "      <td>2.493505e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>284</th>\n",
       "      <td>tfidf_284</td>\n",
       "      <td>2.455733e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>446</th>\n",
       "      <td>nutty</td>\n",
       "      <td>2.438852e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>296</th>\n",
       "      <td>tfidf_296</td>\n",
       "      <td>2.399536e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>261</th>\n",
       "      <td>tfidf_261</td>\n",
       "      <td>2.390044e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>116</th>\n",
       "      <td>tfidf_116</td>\n",
       "      <td>2.373332e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>176</th>\n",
       "      <td>tfidf_176</td>\n",
       "      <td>2.364336e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>144</th>\n",
       "      <td>tfidf_144</td>\n",
       "      <td>2.346857e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>384</th>\n",
       "      <td>tfidf_384</td>\n",
       "      <td>2.343925e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>377</th>\n",
       "      <td>tfidf_377</td>\n",
       "      <td>2.333283e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>182</th>\n",
       "      <td>tfidf_182</td>\n",
       "      <td>2.329043e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>231</th>\n",
       "      <td>tfidf_231</td>\n",
       "      <td>2.302846e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>240</th>\n",
       "      <td>tfidf_240</td>\n",
       "      <td>2.272717e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>195</th>\n",
       "      <td>tfidf_195</td>\n",
       "      <td>2.267281e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>451</th>\n",
       "      <td>pine</td>\n",
       "      <td>2.231118e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>293</th>\n",
       "      <td>tfidf_293</td>\n",
       "      <td>2.208561e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>443</th>\n",
       "      <td>mango</td>\n",
       "      <td>2.170928e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>397</th>\n",
       "      <td>dizzy</td>\n",
       "      <td>2.165295e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75</th>\n",
       "      <td>tfidf_75</td>\n",
       "      <td>2.131689e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>tfidf_13</td>\n",
       "      <td>2.068969e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>305</th>\n",
       "      <td>tfidf_305</td>\n",
       "      <td>2.044590e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>429</th>\n",
       "      <td>chemical</td>\n",
       "      <td>2.033446e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>tfidf_42</td>\n",
       "      <td>2.008437e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>319</th>\n",
       "      <td>tfidf_319</td>\n",
       "      <td>2.002399e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>170</th>\n",
       "      <td>tfidf_170</td>\n",
       "      <td>1.992340e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>430</th>\n",
       "      <td>chestnut</td>\n",
       "      <td>1.990197e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>64</th>\n",
       "      <td>tfidf_64</td>\n",
       "      <td>1.980071e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>tfidf_49</td>\n",
       "      <td>1.967135e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>189</th>\n",
       "      <td>tfidf_189</td>\n",
       "      <td>1.958661e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>174</th>\n",
       "      <td>tfidf_174</td>\n",
       "      <td>1.956798e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>361</th>\n",
       "      <td>tfidf_361</td>\n",
       "      <td>1.931993e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>298</th>\n",
       "      <td>tfidf_298</td>\n",
       "      <td>1.920200e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>353</th>\n",
       "      <td>tfidf_353</td>\n",
       "      <td>1.898696e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>300</th>\n",
       "      <td>tfidf_300</td>\n",
       "      <td>1.888456e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>246</th>\n",
       "      <td>tfidf_246</td>\n",
       "      <td>1.881095e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>65</th>\n",
       "      <td>tfidf_65</td>\n",
       "      <td>1.859690e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>378</th>\n",
       "      <td>tfidf_378</td>\n",
       "      <td>1.788903e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>323</th>\n",
       "      <td>tfidf_323</td>\n",
       "      <td>1.769057e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>371</th>\n",
       "      <td>tfidf_371</td>\n",
       "      <td>1.689909e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>88</th>\n",
       "      <td>tfidf_88</td>\n",
       "      <td>1.681465e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>178</th>\n",
       "      <td>tfidf_178</td>\n",
       "      <td>1.658866e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>85</th>\n",
       "      <td>tfidf_85</td>\n",
       "      <td>1.650620e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>274</th>\n",
       "      <td>tfidf_274</td>\n",
       "      <td>1.624569e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>318</th>\n",
       "      <td>tfidf_318</td>\n",
       "      <td>1.620448e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>169</th>\n",
       "      <td>tfidf_169</td>\n",
       "      <td>1.609894e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>134</th>\n",
       "      <td>tfidf_134</td>\n",
       "      <td>1.582984e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>364</th>\n",
       "      <td>tfidf_364</td>\n",
       "      <td>1.550268e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>tfidf_38</td>\n",
       "      <td>1.543866e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>322</th>\n",
       "      <td>tfidf_322</td>\n",
       "      <td>1.535235e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>83</th>\n",
       "      <td>tfidf_83</td>\n",
       "      <td>1.521203e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>143</th>\n",
       "      <td>tfidf_143</td>\n",
       "      <td>1.512796e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>137</th>\n",
       "      <td>tfidf_137</td>\n",
       "      <td>1.436068e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>94</th>\n",
       "      <td>tfidf_94</td>\n",
       "      <td>1.435636e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>177</th>\n",
       "      <td>tfidf_177</td>\n",
       "      <td>1.424688e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>249</th>\n",
       "      <td>tfidf_249</td>\n",
       "      <td>1.401301e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>152</th>\n",
       "      <td>tfidf_152</td>\n",
       "      <td>1.387238e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>366</th>\n",
       "      <td>tfidf_366</td>\n",
       "      <td>1.377809e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>432</th>\n",
       "      <td>coffee</td>\n",
       "      <td>1.373819e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>131</th>\n",
       "      <td>tfidf_131</td>\n",
       "      <td>1.355866e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>439</th>\n",
       "      <td>honey</td>\n",
       "      <td>1.343250e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>139</th>\n",
       "      <td>tfidf_139</td>\n",
       "      <td>1.336754e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>tfidf_45</td>\n",
       "      <td>1.322071e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>209</th>\n",
       "      <td>tfidf_209</td>\n",
       "      <td>1.320295e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>316</th>\n",
       "      <td>tfidf_316</td>\n",
       "      <td>1.316265e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>103</th>\n",
       "      <td>tfidf_103</td>\n",
       "      <td>1.292752e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>122</th>\n",
       "      <td>tfidf_122</td>\n",
       "      <td>1.273837e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>tfidf_12</td>\n",
       "      <td>1.256963e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>269</th>\n",
       "      <td>tfidf_269</td>\n",
       "      <td>1.253037e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>203</th>\n",
       "      <td>tfidf_203</td>\n",
       "      <td>1.249040e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>108</th>\n",
       "      <td>tfidf_108</td>\n",
       "      <td>1.213145e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>130</th>\n",
       "      <td>tfidf_130</td>\n",
       "      <td>1.212331e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>259</th>\n",
       "      <td>tfidf_259</td>\n",
       "      <td>1.210118e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>80</th>\n",
       "      <td>tfidf_80</td>\n",
       "      <td>1.203882e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>tfidf_4</td>\n",
       "      <td>1.180633e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>467</th>\n",
       "      <td>violet</td>\n",
       "      <td>1.161689e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>295</th>\n",
       "      <td>tfidf_295</td>\n",
       "      <td>1.127655e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>159</th>\n",
       "      <td>tfidf_159</td>\n",
       "      <td>1.114889e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>184</th>\n",
       "      <td>tfidf_184</td>\n",
       "      <td>1.109500e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>282</th>\n",
       "      <td>tfidf_282</td>\n",
       "      <td>1.089884e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>263</th>\n",
       "      <td>tfidf_263</td>\n",
       "      <td>1.050872e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>tfidf_10</td>\n",
       "      <td>1.021286e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>81</th>\n",
       "      <td>tfidf_81</td>\n",
       "      <td>1.014364e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>tfidf_95</td>\n",
       "      <td>1.002652e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>276</th>\n",
       "      <td>tfidf_276</td>\n",
       "      <td>9.901859e-05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>tfidf_31</td>\n",
       "      <td>9.838845e-05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>70</th>\n",
       "      <td>tfidf_70</td>\n",
       "      <td>9.817207e-05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>456</th>\n",
       "      <td>sage</td>\n",
       "      <td>9.667124e-05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>160</th>\n",
       "      <td>tfidf_160</td>\n",
       "      <td>9.635981e-05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>438</th>\n",
       "      <td>grapefruit</td>\n",
       "      <td>9.214810e-05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>61</th>\n",
       "      <td>tfidf_61</td>\n",
       "      <td>9.071962e-05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53</th>\n",
       "      <td>tfidf_53</td>\n",
       "      <td>8.751300e-05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>315</th>\n",
       "      <td>tfidf_315</td>\n",
       "      <td>8.723952e-05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>tfidf_25</td>\n",
       "      <td>8.682066e-05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>363</th>\n",
       "      <td>tfidf_363</td>\n",
       "      <td>8.567324e-05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>412</th>\n",
       "      <td>paranoid</td>\n",
       "      <td>8.561921e-05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>243</th>\n",
       "      <td>tfidf_243</td>\n",
       "      <td>8.491824e-05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>250</th>\n",
       "      <td>tfidf_250</td>\n",
       "      <td>8.025684e-05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>102</th>\n",
       "      <td>tfidf_102</td>\n",
       "      <td>7.955770e-05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>448</th>\n",
       "      <td>peach</td>\n",
       "      <td>7.697833e-05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>365</th>\n",
       "      <td>tfidf_365</td>\n",
       "      <td>7.444695e-05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>82</th>\n",
       "      <td>tfidf_82</td>\n",
       "      <td>7.305303e-05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>423</th>\n",
       "      <td>apricot</td>\n",
       "      <td>7.288783e-05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>442</th>\n",
       "      <td>lime</td>\n",
       "      <td>6.945623e-05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>381</th>\n",
       "      <td>tfidf_381</td>\n",
       "      <td>6.924545e-05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>tfidf_18</td>\n",
       "      <td>6.880936e-05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>227</th>\n",
       "      <td>tfidf_227</td>\n",
       "      <td>6.797913e-05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>380</th>\n",
       "      <td>tfidf_380</td>\n",
       "      <td>6.256047e-05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>111</th>\n",
       "      <td>tfidf_111</td>\n",
       "      <td>6.183699e-05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>tfidf_19</td>\n",
       "      <td>6.178402e-05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>428</th>\n",
       "      <td>cheese</td>\n",
       "      <td>5.994296e-05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>147</th>\n",
       "      <td>tfidf_147</td>\n",
       "      <td>5.966682e-05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>140</th>\n",
       "      <td>tfidf_140</td>\n",
       "      <td>5.676071e-05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>92</th>\n",
       "      <td>tfidf_92</td>\n",
       "      <td>5.330263e-05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>185</th>\n",
       "      <td>tfidf_185</td>\n",
       "      <td>4.946428e-05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>161</th>\n",
       "      <td>tfidf_161</td>\n",
       "      <td>4.867374e-05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>69</th>\n",
       "      <td>tfidf_69</td>\n",
       "      <td>4.653081e-05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>462</th>\n",
       "      <td>tea</td>\n",
       "      <td>4.517054e-05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>204</th>\n",
       "      <td>tfidf_204</td>\n",
       "      <td>4.393060e-05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>68</th>\n",
       "      <td>tfidf_68</td>\n",
       "      <td>4.347114e-05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>262</th>\n",
       "      <td>tfidf_262</td>\n",
       "      <td>4.090405e-05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>459</th>\n",
       "      <td>strawberry</td>\n",
       "      <td>3.910429e-05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>436</th>\n",
       "      <td>fruit</td>\n",
       "      <td>3.556470e-05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>450</th>\n",
       "      <td>pepper</td>\n",
       "      <td>3.505077e-05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>tfidf_0</td>\n",
       "      <td>3.483435e-05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>339</th>\n",
       "      <td>tfidf_339</td>\n",
       "      <td>3.472235e-05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>tfidf_3</td>\n",
       "      <td>3.406207e-05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>56</th>\n",
       "      <td>tfidf_56</td>\n",
       "      <td>3.260443e-05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>148</th>\n",
       "      <td>tfidf_148</td>\n",
       "      <td>3.167510e-05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>392</th>\n",
       "      <td>anxious</td>\n",
       "      <td>3.109705e-05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>tfidf_8</td>\n",
       "      <td>2.872361e-05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>453</th>\n",
       "      <td>plum</td>\n",
       "      <td>2.783231e-05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>172</th>\n",
       "      <td>tfidf_172</td>\n",
       "      <td>2.777675e-05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>233</th>\n",
       "      <td>tfidf_233</td>\n",
       "      <td>2.503070e-05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>458</th>\n",
       "      <td>spicy/herbal</td>\n",
       "      <td>2.366178e-05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>226</th>\n",
       "      <td>tfidf_226</td>\n",
       "      <td>2.333523e-05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>410</th>\n",
       "      <td>migraines</td>\n",
       "      <td>2.034912e-05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>212</th>\n",
       "      <td>tfidf_212</td>\n",
       "      <td>1.925569e-05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>156</th>\n",
       "      <td>tfidf_156</td>\n",
       "      <td>1.836075e-05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>256</th>\n",
       "      <td>tfidf_256</td>\n",
       "      <td>1.747920e-05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>266</th>\n",
       "      <td>tfidf_266</td>\n",
       "      <td>1.701011e-05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>359</th>\n",
       "      <td>tfidf_359</td>\n",
       "      <td>1.675329e-05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>440</th>\n",
       "      <td>lavender</td>\n",
       "      <td>1.493501e-05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>tfidf_47</td>\n",
       "      <td>1.454619e-05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>422</th>\n",
       "      <td>apple</td>\n",
       "      <td>1.277328e-05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>183</th>\n",
       "      <td>tfidf_183</td>\n",
       "      <td>1.108744e-05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>76</th>\n",
       "      <td>tfidf_76</td>\n",
       "      <td>1.003782e-05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>396</th>\n",
       "      <td>depression</td>\n",
       "      <td>8.230024e-06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>225</th>\n",
       "      <td>tfidf_225</td>\n",
       "      <td>6.805544e-06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>452</th>\n",
       "      <td>pineapple</td>\n",
       "      <td>6.606424e-06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>201</th>\n",
       "      <td>tfidf_201</td>\n",
       "      <td>4.229085e-06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>449</th>\n",
       "      <td>pear</td>\n",
       "      <td>2.182001e-06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>391</th>\n",
       "      <td>anxiety</td>\n",
       "      <td>2.147644e-06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>388</th>\n",
       "      <td>hybrid</td>\n",
       "      <td>7.112495e-07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>447</th>\n",
       "      <td>orange</td>\n",
       "      <td>5.997784e-07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>390</th>\n",
       "      <td>sativa</td>\n",
       "      <td>1.109166e-07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>421</th>\n",
       "      <td>ammonia</td>\n",
       "      <td>2.850179e-08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>425</th>\n",
       "      <td>blue cheese</td>\n",
       "      <td>3.525457e-09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>461</th>\n",
       "      <td>tar</td>\n",
       "      <td>2.851225e-09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>414</th>\n",
       "      <td>seizures</td>\n",
       "      <td>2.359033e-10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>401</th>\n",
       "      <td>epilepsy</td>\n",
       "      <td>1.974443e-12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>404</th>\n",
       "      <td>fatigue</td>\n",
       "      <td>1.613149e-12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>394</th>\n",
       "      <td>arthritis</td>\n",
       "      <td>1.189681e-12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>403</th>\n",
       "      <td>eye pressure</td>\n",
       "      <td>0.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>411</th>\n",
       "      <td>pain</td>\n",
       "      <td>0.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>416</th>\n",
       "      <td>spasticity</td>\n",
       "      <td>0.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>417</th>\n",
       "      <td>stress</td>\n",
       "      <td>0.000000e+00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         features         score\n",
       "389        indica  5.912507e-01\n",
       "426     blueberry  4.268550e-02\n",
       "309     tfidf_309  1.130450e-02\n",
       "29       tfidf_29  7.991770e-03\n",
       "270     tfidf_270  6.188045e-03\n",
       "329     tfidf_329  5.184732e-03\n",
       "181     tfidf_181  4.905887e-03\n",
       "39       tfidf_39  4.075168e-03\n",
       "333     tfidf_333  3.755611e-03\n",
       "340     tfidf_340  3.744376e-03\n",
       "310     tfidf_310  3.600043e-03\n",
       "285     tfidf_285  3.535282e-03\n",
       "264     tfidf_264  3.292573e-03\n",
       "121     tfidf_121  3.290212e-03\n",
       "437         grape  3.283758e-03\n",
       "197     tfidf_197  3.227394e-03\n",
       "7         tfidf_7  3.183797e-03\n",
       "302     tfidf_302  3.158932e-03\n",
       "119     tfidf_119  3.112183e-03\n",
       "198     tfidf_198  2.970235e-03\n",
       "265     tfidf_265  2.858327e-03\n",
       "132     tfidf_132  2.765220e-03\n",
       "125     tfidf_125  2.731943e-03\n",
       "254     tfidf_254  2.713630e-03\n",
       "168     tfidf_168  2.681737e-03\n",
       "468         woody  2.661698e-03\n",
       "105     tfidf_105  2.582859e-03\n",
       "145     tfidf_145  2.555922e-03\n",
       "157     tfidf_157  2.499061e-03\n",
       "260     tfidf_260  2.451840e-03\n",
       "193     tfidf_193  2.441902e-03\n",
       "175     tfidf_175  2.409674e-03\n",
       "135     tfidf_135  2.401830e-03\n",
       "84       tfidf_84  2.379887e-03\n",
       "347     tfidf_347  2.315689e-03\n",
       "101     tfidf_101  2.313360e-03\n",
       "154     tfidf_154  2.272451e-03\n",
       "224     tfidf_224  2.269716e-03\n",
       "200     tfidf_200  2.231193e-03\n",
       "237     tfidf_237  2.201401e-03\n",
       "244     tfidf_244  2.173946e-03\n",
       "179     tfidf_179  2.149059e-03\n",
       "150     tfidf_150  2.089532e-03\n",
       "369     tfidf_369  2.055757e-03\n",
       "32       tfidf_32  2.036855e-03\n",
       "207     tfidf_207  1.995014e-03\n",
       "57       tfidf_57  1.963283e-03\n",
       "344     tfidf_344  1.944182e-03\n",
       "312     tfidf_312  1.937301e-03\n",
       "273     tfidf_273  1.928296e-03\n",
       "368     tfidf_368  1.908974e-03\n",
       "294     tfidf_294  1.887907e-03\n",
       "117     tfidf_117  1.879860e-03\n",
       "238     tfidf_238  1.869467e-03\n",
       "74       tfidf_74  1.859193e-03\n",
       "278     tfidf_278  1.847166e-03\n",
       "327     tfidf_327  1.822465e-03\n",
       "341     tfidf_341  1.821527e-03\n",
       "205     tfidf_205  1.800666e-03\n",
       "149     tfidf_149  1.765791e-03\n",
       "289     tfidf_289  1.727937e-03\n",
       "313     tfidf_313  1.726957e-03\n",
       "138     tfidf_138  1.724151e-03\n",
       "466       vanilla  1.692715e-03\n",
       "214     tfidf_214  1.692228e-03\n",
       "357     tfidf_357  1.631326e-03\n",
       "345     tfidf_345  1.630553e-03\n",
       "253     tfidf_253  1.622244e-03\n",
       "338     tfidf_338  1.612501e-03\n",
       "20       tfidf_20  1.610512e-03\n",
       "407         happy  1.606392e-03\n",
       "24       tfidf_24  1.591498e-03\n",
       "325     tfidf_325  1.562662e-03\n",
       "112     tfidf_112  1.534985e-03\n",
       "206     tfidf_206  1.534513e-03\n",
       "110     tfidf_110  1.524587e-03\n",
       "128     tfidf_128  1.504737e-03\n",
       "376     tfidf_376  1.491665e-03\n",
       "222     tfidf_222  1.456654e-03\n",
       "337     tfidf_337  1.456626e-03\n",
       "354     tfidf_354  1.442934e-03\n",
       "55       tfidf_55  1.414034e-03\n",
       "406        giggly  1.411947e-03\n",
       "413       relaxed  1.389872e-03\n",
       "348     tfidf_348  1.386727e-03\n",
       "283     tfidf_283  1.366759e-03\n",
       "304     tfidf_304  1.352139e-03\n",
       "46       tfidf_46  1.325692e-03\n",
       "6         tfidf_6  1.312057e-03\n",
       "241     tfidf_241  1.308914e-03\n",
       "199     tfidf_199  1.294379e-03\n",
       "232     tfidf_232  1.291856e-03\n",
       "17       tfidf_17  1.259566e-03\n",
       "336     tfidf_336  1.233782e-03\n",
       "37       tfidf_37  1.219618e-03\n",
       "320     tfidf_320  1.201545e-03\n",
       "409        hungry  1.198319e-03\n",
       "307     tfidf_307  1.189975e-03\n",
       "382     tfidf_382  1.185838e-03\n",
       "360     tfidf_360  1.180555e-03\n",
       "314     tfidf_314  1.178794e-03\n",
       "93       tfidf_93  1.176519e-03\n",
       "362     tfidf_362  1.176466e-03\n",
       "89       tfidf_89  1.150125e-03\n",
       "14       tfidf_14  1.142302e-03\n",
       "186     tfidf_186  1.138400e-03\n",
       "463       tobacco  1.115733e-03\n",
       "104     tfidf_104  1.109640e-03\n",
       "155     tfidf_155  1.101674e-03\n",
       "287     tfidf_287  1.090206e-03\n",
       "399     dry mouth  1.059359e-03\n",
       "375     tfidf_375  1.056703e-03\n",
       "290     tfidf_290  1.043012e-03\n",
       "343     tfidf_343  1.036751e-03\n",
       "217     tfidf_217  1.033714e-03\n",
       "163     tfidf_163  1.033567e-03\n",
       "187     tfidf_187  1.022033e-03\n",
       "251     tfidf_251  1.016085e-03\n",
       "60       tfidf_60  1.014915e-03\n",
       "415        sleepy  1.013770e-03\n",
       "324     tfidf_324  1.008794e-03\n",
       "97       tfidf_97  9.960693e-04\n",
       "30       tfidf_30  9.942827e-04\n",
       "166     tfidf_166  9.845424e-04\n",
       "405       focused  9.773014e-04\n",
       "239     tfidf_239  9.716645e-04\n",
       "230     tfidf_230  9.613996e-04\n",
       "79       tfidf_79  9.579818e-04\n",
       "245     tfidf_245  9.505687e-04\n",
       "107     tfidf_107  9.463041e-04\n",
       "402      euphoric  9.442861e-04\n",
       "5         tfidf_5  9.426859e-04\n",
       "115     tfidf_115  9.404567e-04\n",
       "22       tfidf_22  9.356126e-04\n",
       "215     tfidf_215  9.213639e-04\n",
       "218     tfidf_218  9.193919e-04\n",
       "180     tfidf_180  9.189089e-04\n",
       "210     tfidf_210  9.186428e-04\n",
       "59       tfidf_59  9.113226e-04\n",
       "171     tfidf_171  8.826368e-04\n",
       "301     tfidf_301  8.567987e-04\n",
       "2         tfidf_2  8.552375e-04\n",
       "281     tfidf_281  8.470965e-04\n",
       "118     tfidf_118  8.426248e-04\n",
       "40       tfidf_40  8.353593e-04\n",
       "109     tfidf_109  8.292937e-04\n",
       "51       tfidf_51  8.284440e-04\n",
       "258     tfidf_258  8.215418e-04\n",
       "342     tfidf_342  8.205203e-04\n",
       "317     tfidf_317  8.036835e-04\n",
       "165     tfidf_165  8.014632e-04\n",
       "252     tfidf_252  7.866664e-04\n",
       "151     tfidf_151  7.791547e-04\n",
       "311     tfidf_311  7.659643e-04\n",
       "44       tfidf_44  7.646067e-04\n",
       "346     tfidf_346  7.569983e-04\n",
       "36       tfidf_36  7.543717e-04\n",
       "235     tfidf_235  7.511171e-04\n",
       "43       tfidf_43  7.503191e-04\n",
       "291     tfidf_291  7.495872e-04\n",
       "72       tfidf_72  7.393173e-04\n",
       "41       tfidf_41  7.354364e-04\n",
       "279     tfidf_279  7.338649e-04\n",
       "420      uplifted  7.231225e-04\n",
       "373     tfidf_373  7.203852e-04\n",
       "91       tfidf_91  7.175702e-04\n",
       "352     tfidf_352  7.125453e-04\n",
       "141     tfidf_141  7.115907e-04\n",
       "242     tfidf_242  7.070899e-04\n",
       "114     tfidf_114  7.013964e-04\n",
       "321     tfidf_321  6.861986e-04\n",
       "457         skunk  6.766380e-04\n",
       "400     energetic  6.688555e-04\n",
       "272     tfidf_272  6.655156e-04\n",
       "370     tfidf_370  6.654645e-04\n",
       "367     tfidf_367  6.560496e-04\n",
       "35       tfidf_35  6.495930e-04\n",
       "434        earthy  6.454571e-04\n",
       "66       tfidf_66  6.322646e-04\n",
       "164     tfidf_164  6.316221e-04\n",
       "275     tfidf_275  6.304688e-04\n",
       "248     tfidf_248  6.301651e-04\n",
       "385     tfidf_385  6.287091e-04\n",
       "303     tfidf_303  6.282791e-04\n",
       "379     tfidf_379  6.257027e-04\n",
       "228     tfidf_228  6.249780e-04\n",
       "54       tfidf_54  6.246932e-04\n",
       "351     tfidf_351  6.143835e-04\n",
       "71       tfidf_71  6.096041e-04\n",
       "433        diesel  6.063907e-04\n",
       "23       tfidf_23  6.031695e-04\n",
       "387     tfidf_387  5.981942e-04\n",
       "99       tfidf_99  5.949558e-04\n",
       "308     tfidf_308  5.925878e-04\n",
       "106     tfidf_106  5.717377e-04\n",
       "9         tfidf_9  5.578042e-04\n",
       "328     tfidf_328  5.499452e-04\n",
       "96       tfidf_96  5.485329e-04\n",
       "455          rose  5.483056e-04\n",
       "34       tfidf_34  5.473685e-04\n",
       "73       tfidf_73  5.433613e-04\n",
       "219     tfidf_219  5.417044e-04\n",
       "299     tfidf_299  5.409150e-04\n",
       "48       tfidf_48  5.383841e-04\n",
       "221     tfidf_221  5.380439e-04\n",
       "129     tfidf_129  5.327914e-04\n",
       "445          mint  5.284587e-04\n",
       "408      headache  5.279182e-04\n",
       "123     tfidf_123  5.224985e-04\n",
       "11       tfidf_11  5.170742e-04\n",
       "194     tfidf_194  5.032906e-04\n",
       "113     tfidf_113  4.972656e-04\n",
       "331     tfidf_331  4.958627e-04\n",
       "334     tfidf_334  4.952626e-04\n",
       "335     tfidf_335  4.938496e-04\n",
       "58       tfidf_58  4.922760e-04\n",
       "142     tfidf_142  4.877244e-04\n",
       "188     tfidf_188  4.860844e-04\n",
       "297     tfidf_297  4.845014e-04\n",
       "286     tfidf_286  4.826940e-04\n",
       "86       tfidf_86  4.823632e-04\n",
       "202     tfidf_202  4.791735e-04\n",
       "247     tfidf_247  4.789019e-04\n",
       "127     tfidf_127  4.788051e-04\n",
       "398      dry eyes  4.715249e-04\n",
       "454       pungent  4.700118e-04\n",
       "236     tfidf_236  4.585226e-04\n",
       "460         sweet  4.537023e-04\n",
       "196     tfidf_196  4.503390e-04\n",
       "153     tfidf_153  4.483172e-04\n",
       "15       tfidf_15  4.468690e-04\n",
       "98       tfidf_98  4.452903e-04\n",
       "77       tfidf_77  4.449743e-04\n",
       "419        tingly  4.426531e-04\n",
       "332     tfidf_332  4.353305e-04\n",
       "292     tfidf_292  4.352097e-04\n",
       "190     tfidf_190  4.338192e-04\n",
       "349     tfidf_349  4.305856e-04\n",
       "223     tfidf_223  4.294044e-04\n",
       "21       tfidf_21  4.285982e-04\n",
       "431        citrus  4.272571e-04\n",
       "162     tfidf_162  4.263703e-04\n",
       "158     tfidf_158  4.208848e-04\n",
       "213     tfidf_213  4.198175e-04\n",
       "146     tfidf_146  4.144332e-04\n",
       "67       tfidf_67  4.135565e-04\n",
       "257     tfidf_257  4.126037e-04\n",
       "395      creative  4.109092e-04\n",
       "306     tfidf_306  4.009934e-04\n",
       "167     tfidf_167  4.004037e-04\n",
       "424         berry  3.876795e-04\n",
       "26       tfidf_26  3.858295e-04\n",
       "136     tfidf_136  3.843977e-04\n",
       "386     tfidf_386  3.753322e-04\n",
       "418     talkative  3.746960e-04\n",
       "267     tfidf_267  3.713216e-04\n",
       "372     tfidf_372  3.709925e-04\n",
       "234     tfidf_234  3.703366e-04\n",
       "393       aroused  3.698454e-04\n",
       "288     tfidf_288  3.672972e-04\n",
       "78       tfidf_78  3.636279e-04\n",
       "16       tfidf_16  3.622290e-04\n",
       "220     tfidf_220  3.574166e-04\n",
       "255     tfidf_255  3.512450e-04\n",
       "350     tfidf_350  3.410935e-04\n",
       "464          tree  3.402485e-04\n",
       "87       tfidf_87  3.386864e-04\n",
       "208     tfidf_208  3.380924e-04\n",
       "133     tfidf_133  3.375078e-04\n",
       "211     tfidf_211  3.374080e-04\n",
       "63       tfidf_63  3.341605e-04\n",
       "52       tfidf_52  3.306836e-04\n",
       "173     tfidf_173  3.298923e-04\n",
       "28       tfidf_28  3.263509e-04\n",
       "427        butter  3.222791e-04\n",
       "444       menthol  3.033093e-04\n",
       "33       tfidf_33  3.029613e-04\n",
       "192     tfidf_192  3.013861e-04\n",
       "280     tfidf_280  2.986698e-04\n",
       "62       tfidf_62  2.961328e-04\n",
       "441         lemon  2.876426e-04\n",
       "277     tfidf_277  2.864932e-04\n",
       "383     tfidf_383  2.834899e-04\n",
       "358     tfidf_358  2.810402e-04\n",
       "229     tfidf_229  2.791865e-04\n",
       "126     tfidf_126  2.768851e-04\n",
       "1         tfidf_1  2.760318e-04\n",
       "100     tfidf_100  2.735819e-04\n",
       "27       tfidf_27  2.689358e-04\n",
       "216     tfidf_216  2.687472e-04\n",
       "268     tfidf_268  2.676725e-04\n",
       "465      tropical  2.672641e-04\n",
       "124     tfidf_124  2.668199e-04\n",
       "120     tfidf_120  2.656683e-04\n",
       "356     tfidf_356  2.655285e-04\n",
       "191     tfidf_191  2.645641e-04\n",
       "90       tfidf_90  2.626200e-04\n",
       "374     tfidf_374  2.608990e-04\n",
       "435       flowery  2.595125e-04\n",
       "330     tfidf_330  2.579825e-04\n",
       "355     tfidf_355  2.523824e-04\n",
       "271     tfidf_271  2.495064e-04\n",
       "326     tfidf_326  2.494329e-04\n",
       "50       tfidf_50  2.493505e-04\n",
       "284     tfidf_284  2.455733e-04\n",
       "446         nutty  2.438852e-04\n",
       "296     tfidf_296  2.399536e-04\n",
       "261     tfidf_261  2.390044e-04\n",
       "116     tfidf_116  2.373332e-04\n",
       "176     tfidf_176  2.364336e-04\n",
       "144     tfidf_144  2.346857e-04\n",
       "384     tfidf_384  2.343925e-04\n",
       "377     tfidf_377  2.333283e-04\n",
       "182     tfidf_182  2.329043e-04\n",
       "231     tfidf_231  2.302846e-04\n",
       "240     tfidf_240  2.272717e-04\n",
       "195     tfidf_195  2.267281e-04\n",
       "451          pine  2.231118e-04\n",
       "293     tfidf_293  2.208561e-04\n",
       "443         mango  2.170928e-04\n",
       "397         dizzy  2.165295e-04\n",
       "75       tfidf_75  2.131689e-04\n",
       "13       tfidf_13  2.068969e-04\n",
       "305     tfidf_305  2.044590e-04\n",
       "429      chemical  2.033446e-04\n",
       "42       tfidf_42  2.008437e-04\n",
       "319     tfidf_319  2.002399e-04\n",
       "170     tfidf_170  1.992340e-04\n",
       "430      chestnut  1.990197e-04\n",
       "64       tfidf_64  1.980071e-04\n",
       "49       tfidf_49  1.967135e-04\n",
       "189     tfidf_189  1.958661e-04\n",
       "174     tfidf_174  1.956798e-04\n",
       "361     tfidf_361  1.931993e-04\n",
       "298     tfidf_298  1.920200e-04\n",
       "353     tfidf_353  1.898696e-04\n",
       "300     tfidf_300  1.888456e-04\n",
       "246     tfidf_246  1.881095e-04\n",
       "65       tfidf_65  1.859690e-04\n",
       "378     tfidf_378  1.788903e-04\n",
       "323     tfidf_323  1.769057e-04\n",
       "371     tfidf_371  1.689909e-04\n",
       "88       tfidf_88  1.681465e-04\n",
       "178     tfidf_178  1.658866e-04\n",
       "85       tfidf_85  1.650620e-04\n",
       "274     tfidf_274  1.624569e-04\n",
       "318     tfidf_318  1.620448e-04\n",
       "169     tfidf_169  1.609894e-04\n",
       "134     tfidf_134  1.582984e-04\n",
       "364     tfidf_364  1.550268e-04\n",
       "38       tfidf_38  1.543866e-04\n",
       "322     tfidf_322  1.535235e-04\n",
       "83       tfidf_83  1.521203e-04\n",
       "143     tfidf_143  1.512796e-04\n",
       "137     tfidf_137  1.436068e-04\n",
       "94       tfidf_94  1.435636e-04\n",
       "177     tfidf_177  1.424688e-04\n",
       "249     tfidf_249  1.401301e-04\n",
       "152     tfidf_152  1.387238e-04\n",
       "366     tfidf_366  1.377809e-04\n",
       "432        coffee  1.373819e-04\n",
       "131     tfidf_131  1.355866e-04\n",
       "439         honey  1.343250e-04\n",
       "139     tfidf_139  1.336754e-04\n",
       "45       tfidf_45  1.322071e-04\n",
       "209     tfidf_209  1.320295e-04\n",
       "316     tfidf_316  1.316265e-04\n",
       "103     tfidf_103  1.292752e-04\n",
       "122     tfidf_122  1.273837e-04\n",
       "12       tfidf_12  1.256963e-04\n",
       "269     tfidf_269  1.253037e-04\n",
       "203     tfidf_203  1.249040e-04\n",
       "108     tfidf_108  1.213145e-04\n",
       "130     tfidf_130  1.212331e-04\n",
       "259     tfidf_259  1.210118e-04\n",
       "80       tfidf_80  1.203882e-04\n",
       "4         tfidf_4  1.180633e-04\n",
       "467        violet  1.161689e-04\n",
       "295     tfidf_295  1.127655e-04\n",
       "159     tfidf_159  1.114889e-04\n",
       "184     tfidf_184  1.109500e-04\n",
       "282     tfidf_282  1.089884e-04\n",
       "263     tfidf_263  1.050872e-04\n",
       "10       tfidf_10  1.021286e-04\n",
       "81       tfidf_81  1.014364e-04\n",
       "95       tfidf_95  1.002652e-04\n",
       "276     tfidf_276  9.901859e-05\n",
       "31       tfidf_31  9.838845e-05\n",
       "70       tfidf_70  9.817207e-05\n",
       "456          sage  9.667124e-05\n",
       "160     tfidf_160  9.635981e-05\n",
       "438    grapefruit  9.214810e-05\n",
       "61       tfidf_61  9.071962e-05\n",
       "53       tfidf_53  8.751300e-05\n",
       "315     tfidf_315  8.723952e-05\n",
       "25       tfidf_25  8.682066e-05\n",
       "363     tfidf_363  8.567324e-05\n",
       "412      paranoid  8.561921e-05\n",
       "243     tfidf_243  8.491824e-05\n",
       "250     tfidf_250  8.025684e-05\n",
       "102     tfidf_102  7.955770e-05\n",
       "448         peach  7.697833e-05\n",
       "365     tfidf_365  7.444695e-05\n",
       "82       tfidf_82  7.305303e-05\n",
       "423       apricot  7.288783e-05\n",
       "442          lime  6.945623e-05\n",
       "381     tfidf_381  6.924545e-05\n",
       "18       tfidf_18  6.880936e-05\n",
       "227     tfidf_227  6.797913e-05\n",
       "380     tfidf_380  6.256047e-05\n",
       "111     tfidf_111  6.183699e-05\n",
       "19       tfidf_19  6.178402e-05\n",
       "428        cheese  5.994296e-05\n",
       "147     tfidf_147  5.966682e-05\n",
       "140     tfidf_140  5.676071e-05\n",
       "92       tfidf_92  5.330263e-05\n",
       "185     tfidf_185  4.946428e-05\n",
       "161     tfidf_161  4.867374e-05\n",
       "69       tfidf_69  4.653081e-05\n",
       "462           tea  4.517054e-05\n",
       "204     tfidf_204  4.393060e-05\n",
       "68       tfidf_68  4.347114e-05\n",
       "262     tfidf_262  4.090405e-05\n",
       "459    strawberry  3.910429e-05\n",
       "436         fruit  3.556470e-05\n",
       "450        pepper  3.505077e-05\n",
       "0         tfidf_0  3.483435e-05\n",
       "339     tfidf_339  3.472235e-05\n",
       "3         tfidf_3  3.406207e-05\n",
       "56       tfidf_56  3.260443e-05\n",
       "148     tfidf_148  3.167510e-05\n",
       "392       anxious  3.109705e-05\n",
       "8         tfidf_8  2.872361e-05\n",
       "453          plum  2.783231e-05\n",
       "172     tfidf_172  2.777675e-05\n",
       "233     tfidf_233  2.503070e-05\n",
       "458  spicy/herbal  2.366178e-05\n",
       "226     tfidf_226  2.333523e-05\n",
       "410     migraines  2.034912e-05\n",
       "212     tfidf_212  1.925569e-05\n",
       "156     tfidf_156  1.836075e-05\n",
       "256     tfidf_256  1.747920e-05\n",
       "266     tfidf_266  1.701011e-05\n",
       "359     tfidf_359  1.675329e-05\n",
       "440      lavender  1.493501e-05\n",
       "47       tfidf_47  1.454619e-05\n",
       "422         apple  1.277328e-05\n",
       "183     tfidf_183  1.108744e-05\n",
       "76       tfidf_76  1.003782e-05\n",
       "396    depression  8.230024e-06\n",
       "225     tfidf_225  6.805544e-06\n",
       "452     pineapple  6.606424e-06\n",
       "201     tfidf_201  4.229085e-06\n",
       "449          pear  2.182001e-06\n",
       "391       anxiety  2.147644e-06\n",
       "388        hybrid  7.112495e-07\n",
       "447        orange  5.997784e-07\n",
       "390        sativa  1.109166e-07\n",
       "421       ammonia  2.850179e-08\n",
       "425   blue cheese  3.525457e-09\n",
       "461           tar  2.851225e-09\n",
       "414      seizures  2.359033e-10\n",
       "401      epilepsy  1.974443e-12\n",
       "404       fatigue  1.613149e-12\n",
       "394     arthritis  1.189681e-12\n",
       "403  eye pressure  0.000000e+00\n",
       "411          pain  0.000000e+00\n",
       "416    spasticity  0.000000e+00\n",
       "417        stress  0.000000e+00"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.set_option('display.max_rows', df_feat_ranked.shape[0]+1)\n",
    "df_feat_ranked"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/louispandu/anaconda3/lib/python3.10/site-packages/sklearn/feature_selection/_from_model.py:357: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  self.estimator_.fit(X, y, **fit_params)\n"
     ]
    }
   ],
   "source": [
    "selector = SelectFromModel(rfreg).fit(X_train1, y_train1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([5.70884334e-05, 3.16618255e-04, 9.13401215e-04, 2.23135022e-05,\n",
       "       9.04077317e-05, 8.30241912e-04, 1.31780560e-03, 3.24411874e-03,\n",
       "       1.97813995e-05, 6.01454040e-04, 1.38274223e-04, 5.27651138e-04,\n",
       "       1.22350624e-04, 1.51994360e-04, 1.46381746e-03, 4.76309514e-04,\n",
       "       6.84021216e-04, 1.03226698e-03, 1.37861641e-04, 1.38247263e-05,\n",
       "       1.45299067e-03, 4.57089101e-04, 8.83535705e-04, 3.52699985e-04,\n",
       "       1.64888500e-03, 1.21388764e-04, 3.94280998e-04, 3.25922653e-04,\n",
       "       5.30940927e-04, 7.92940674e-03, 1.16527542e-03, 1.01545206e-04,\n",
       "       2.11109537e-03, 3.62335380e-04, 6.30078424e-04, 6.85670128e-04,\n",
       "       7.90413336e-04, 1.27558722e-03, 1.85834675e-04, 4.08089064e-03,\n",
       "       9.19625282e-04, 7.72742151e-04, 1.16770348e-04, 9.72040584e-04,\n",
       "       7.16865160e-04, 1.63876550e-04, 1.11508893e-03, 2.38928928e-05,\n",
       "       6.31063933e-04, 1.74708380e-04, 2.12346878e-04, 8.92051125e-04,\n",
       "       2.80622241e-04, 8.33205755e-05, 5.84217781e-04, 1.42857759e-03,\n",
       "       4.15655275e-05, 2.13943933e-03, 4.46415337e-04, 8.95362223e-04,\n",
       "       8.15733619e-04, 1.64616164e-04, 3.02726388e-04, 2.33862460e-04,\n",
       "       1.23992830e-04, 1.44999700e-04, 5.53111084e-04, 5.00724589e-04,\n",
       "       1.74463897e-05, 5.45275272e-05, 5.87492666e-05, 7.16566865e-04,\n",
       "       7.82058868e-04, 4.80672531e-04, 1.71594673e-03, 9.89230373e-05,\n",
       "       9.37857857e-06, 3.18257204e-04, 4.31916402e-04, 8.87833103e-04,\n",
       "       1.05619663e-04, 8.35063876e-05, 9.60067423e-05, 1.42579877e-04,\n",
       "       2.30551013e-03, 3.10031815e-04, 4.31555330e-04, 3.15455245e-04,\n",
       "       1.93665725e-04, 1.31958362e-03, 1.31605349e-04, 9.01660759e-04,\n",
       "       6.52380515e-05, 1.07259990e-03, 1.41471917e-04, 1.59380020e-04,\n",
       "       6.60540178e-04, 1.01891259e-03, 3.18996795e-04, 4.63661521e-04,\n",
       "       2.03352964e-04, 1.99204031e-03, 3.79837827e-05, 1.53082495e-04,\n",
       "       1.30569626e-03, 2.25687518e-03, 5.94008767e-04, 1.09192284e-03,\n",
       "       8.96739160e-05, 9.44082907e-04, 1.49644790e-03, 1.19851118e-05,\n",
       "       1.59561640e-03, 4.33991790e-04, 7.07374797e-04, 8.42025195e-04,\n",
       "       1.63491537e-04, 2.27486751e-03, 6.66326729e-04, 2.51875822e-03,\n",
       "       4.94546681e-04, 3.57097244e-03, 1.00730769e-04, 4.89635689e-04,\n",
       "       3.01318393e-04, 2.88514164e-03, 3.15651212e-04, 4.72388430e-04,\n",
       "       1.38745894e-03, 7.39092619e-04, 2.03038103e-04, 1.41247645e-04,\n",
       "       2.49703983e-03, 3.87660117e-04, 1.79073138e-04, 1.85845796e-03,\n",
       "       3.87365203e-04, 2.49388691e-04, 1.63892810e-03, 1.65524709e-04,\n",
       "       8.58703756e-05, 5.92080735e-04, 4.71925850e-04, 1.55745031e-04,\n",
       "       3.17962696e-04, 2.50942200e-03, 3.46780033e-04, 5.64343946e-05,\n",
       "       6.57312874e-05, 2.17776241e-03, 2.08273369e-03, 8.21636103e-04,\n",
       "       9.21085469e-05, 4.20376758e-04, 1.81019501e-03, 1.00475797e-03,\n",
       "       2.54350363e-05, 2.26893109e-03, 3.03247898e-04, 1.25803611e-04,\n",
       "       1.24725823e-04, 5.28419145e-05, 4.53977428e-04, 1.05065696e-03,\n",
       "       7.20389969e-04, 9.54561519e-04, 1.02088774e-03, 6.09262350e-04,\n",
       "       2.99415988e-03, 1.22227576e-04, 1.02558815e-04, 8.44157262e-04,\n",
       "       2.38540172e-05, 2.01372720e-04, 2.19250497e-04, 2.32284244e-03,\n",
       "       2.95030179e-04, 7.93664612e-05, 1.19287900e-04, 2.22651158e-03,\n",
       "       9.39521016e-04, 5.00970341e-03, 2.19785002e-04, 1.51228951e-05,\n",
       "       2.51703012e-04, 6.82204411e-05, 1.03829107e-03, 8.89912961e-04,\n",
       "       6.62813119e-04, 1.37545762e-04, 3.58604607e-04, 2.74495161e-04,\n",
       "       2.05641177e-04, 2.00099405e-03, 4.56978731e-04, 2.05725831e-04,\n",
       "       3.53875897e-04, 3.44949397e-03, 2.36453096e-03, 1.18921538e-03,\n",
       "       1.80766761e-03, 4.39785592e-06, 4.46945084e-04, 1.75345628e-04,\n",
       "       7.69816018e-05, 2.01693338e-03, 1.52945493e-03, 1.75256345e-03,\n",
       "       3.53476404e-04, 9.61544935e-05, 9.16557863e-04, 2.66818557e-04,\n",
       "       2.75734555e-05, 4.11260910e-04, 1.98513712e-03, 9.10866836e-04,\n",
       "       3.35407194e-04, 9.78872763e-04, 8.43409436e-04, 6.41110484e-04,\n",
       "       1.92976896e-04, 5.80793279e-04, 1.45372871e-03, 3.36377290e-04,\n",
       "       2.26347589e-03, 1.38994682e-05, 1.65214022e-05, 6.53572071e-05,\n",
       "       5.51209347e-04, 3.32777475e-04, 9.89725809e-04, 1.22138378e-04,\n",
       "       1.19178340e-03, 1.55010017e-05, 2.62220996e-04, 7.59275407e-04,\n",
       "       5.99649142e-04, 2.56198634e-03, 1.93462673e-03, 9.79532486e-04,\n",
       "       2.37834212e-04, 1.33335469e-03, 8.37814262e-04, 1.04938506e-04,\n",
       "       2.19019393e-03, 1.40290448e-03, 1.64502121e-04, 6.71481129e-04,\n",
       "       5.22178815e-04, 1.95670052e-04, 1.66219226e-04, 9.93336106e-04,\n",
       "       8.18776636e-04, 1.75820880e-03, 2.41984458e-03, 4.30214847e-04,\n",
       "       4.00652676e-05, 4.83953600e-04, 1.10131324e-03, 2.10438883e-05,\n",
       "       2.33167291e-03, 2.59266706e-04, 6.39023428e-05, 1.53139089e-04,\n",
       "       3.05767948e-03, 3.08517319e-03, 8.65722398e-06, 3.66211417e-04,\n",
       "       1.61810748e-04, 9.56308584e-05, 6.28685933e-03, 2.00375890e-04,\n",
       "       6.15804589e-04, 1.59096659e-03, 2.51509615e-04, 5.79387425e-04,\n",
       "       1.90457849e-04, 1.98265552e-04, 1.75800919e-03, 8.11258661e-04,\n",
       "       2.67569442e-04, 9.08859694e-04, 1.44009544e-04, 1.44082251e-03,\n",
       "       2.52242134e-04, 3.33429764e-03, 4.67446876e-04, 1.12684998e-03,\n",
       "       3.36733536e-04, 1.26234060e-03, 1.13082398e-03, 6.43806368e-04,\n",
       "       3.24392354e-04, 3.07824771e-04, 1.54881815e-03, 1.63175863e-04,\n",
       "       2.77181731e-04, 4.75491509e-04, 2.15273381e-04, 5.02715837e-04,\n",
       "       2.09246554e-04, 9.01001292e-04, 3.18115522e-03, 8.07517080e-04,\n",
       "       1.19470562e-03, 2.60488563e-04, 4.82831153e-04, 1.16830106e-03,\n",
       "       6.58748159e-04, 1.11608042e-02, 3.93631479e-03, 6.53689429e-04,\n",
       "       2.21409709e-03, 1.91117641e-03, 1.02834896e-03, 8.12645924e-05,\n",
       "       1.47348053e-04, 7.23401084e-04, 2.45845645e-04, 2.24185567e-04,\n",
       "       1.67864349e-03, 5.76337411e-04, 1.48873867e-04, 1.51761820e-04,\n",
       "       8.29922996e-04, 1.37367099e-03, 2.74260819e-04, 1.85883611e-03,\n",
       "       4.79749303e-04, 5.39508270e-03, 3.07984981e-04, 5.68333532e-04,\n",
       "       4.44969773e-04, 3.76092165e-03, 4.35937671e-04, 5.91422839e-04,\n",
       "       1.29346476e-03, 1.57933909e-03, 1.57730119e-03, 4.98842667e-05,\n",
       "       2.67108012e-03, 1.13975046e-03, 9.85118733e-04, 1.10065701e-03,\n",
       "       2.08097507e-03, 1.96157724e-03, 7.14628531e-04, 2.39967653e-03,\n",
       "       1.29345980e-03, 3.47602832e-04, 3.63612372e-04, 6.45679601e-04,\n",
       "       6.89763195e-04, 1.65216167e-04, 1.26276776e-03, 2.07232765e-04,\n",
       "       2.96732555e-04, 1.86695671e-03, 3.46087882e-04, 1.83419499e-05,\n",
       "       1.14655129e-03, 2.21650859e-04, 1.17944143e-03, 3.87754500e-05,\n",
       "       1.38430039e-04, 7.40315968e-05, 1.93579154e-04, 6.07041942e-04,\n",
       "       2.01981193e-03, 1.89888038e-03, 6.17412924e-04, 1.10645770e-04,\n",
       "       2.43681997e-04, 6.60450291e-04, 2.76328349e-04, 7.89063851e-04,\n",
       "       1.52531308e-03, 2.23789159e-04, 1.96826515e-04, 9.19919321e-04,\n",
       "       9.14667781e-05, 5.49798520e-05, 1.39699290e-03, 2.67547837e-04,\n",
       "       2.22152306e-04, 7.51131187e-04, 5.48243278e-04, 5.94885006e-04,\n",
       "       6.95276091e-07, 5.92020275e-01, 1.10893189e-07, 6.41607642e-06,\n",
       "       3.42235261e-05, 3.83493435e-04, 1.38265066e-12, 5.20173595e-04,\n",
       "       6.48061404e-06, 2.24505817e-04, 5.03555437e-04, 1.12151029e-03,\n",
       "       6.08246771e-04, 0.00000000e+00, 1.40034490e-03, 0.00000000e+00,\n",
       "       1.82060540e-12, 1.50337816e-03, 1.32861847e-03, 1.61325029e-03,\n",
       "       4.99649986e-04, 1.04559756e-03, 6.38477940e-06, 2.40735154e-13,\n",
       "       1.49490577e-04, 1.36712492e-03, 1.68414533e-12, 1.06577824e-03,\n",
       "       0.00000000e+00, 0.00000000e+00, 3.91397217e-04, 4.86919092e-04,\n",
       "       7.46744114e-04, 2.18309120e-06, 2.15062731e-06, 6.51384939e-05,\n",
       "       6.23356913e-04, 3.69511900e-09, 4.27214886e-02, 1.90122840e-04,\n",
       "       1.00533050e-04, 2.01071660e-04, 2.01256975e-04, 5.53012091e-04,\n",
       "       1.83246200e-04, 5.03769372e-04, 7.45326669e-04, 2.69170636e-04,\n",
       "       2.25274366e-05, 2.75597122e-03, 8.62950764e-05, 1.14952970e-04,\n",
       "       5.62231462e-05, 2.93968183e-04, 8.22940150e-05, 2.04602581e-04,\n",
       "       3.17451333e-04, 7.44843568e-04, 1.50420978e-04, 6.07493511e-07,\n",
       "       2.58185569e-05, 6.62200574e-09, 6.20835502e-05, 2.78540123e-04,\n",
       "       8.05699508e-05, 3.09814696e-05, 6.26449846e-04, 6.48083315e-04,\n",
       "       5.31972996e-05, 4.42016792e-04, 7.66436005e-05, 3.38388308e-05,\n",
       "       4.27934107e-04, 8.16087427e-06, 5.04044382e-05, 1.31744713e-03,\n",
       "       3.12577355e-04, 2.48582191e-04, 1.64220942e-03, 1.12677112e-04,\n",
       "       2.15426769e-03])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "selector.estimator_.feature_importances_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0021321961620469083"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "selector.threshold_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "mask = selector.get_support()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([False, False, False, False, False, False, False,  True, False,\n",
       "       False, False, False, False, False, False, False, False, False,\n",
       "       False, False, False, False, False, False, False, False, False,\n",
       "       False, False,  True, False, False, False, False, False, False,\n",
       "       False, False, False,  True, False, False, False, False, False,\n",
       "       False, False, False, False, False, False, False, False, False,\n",
       "       False, False, False,  True, False, False, False, False, False,\n",
       "       False, False, False, False, False, False, False, False, False,\n",
       "       False, False, False, False, False, False, False, False, False,\n",
       "       False, False, False,  True, False, False, False, False, False,\n",
       "       False, False, False, False, False, False, False, False, False,\n",
       "       False, False, False, False, False, False,  True, False, False,\n",
       "       False, False, False, False, False, False, False, False, False,\n",
       "        True, False,  True, False,  True, False, False, False,  True,\n",
       "       False, False, False, False, False, False,  True, False, False,\n",
       "       False, False, False, False, False, False, False, False, False,\n",
       "       False,  True, False, False, False,  True, False, False, False,\n",
       "       False, False, False, False,  True, False, False, False, False,\n",
       "       False, False, False, False, False, False,  True, False, False,\n",
       "       False, False, False, False,  True, False, False, False,  True,\n",
       "       False,  True, False, False, False, False, False, False, False,\n",
       "       False, False, False, False, False, False, False, False,  True,\n",
       "        True, False, False, False, False, False, False, False, False,\n",
       "       False, False, False, False, False, False, False, False, False,\n",
       "       False, False, False, False, False, False, False, False,  True,\n",
       "       False, False, False, False, False, False, False, False, False,\n",
       "       False, False, False,  True, False, False, False, False, False,\n",
       "       False,  True, False, False, False, False, False, False, False,\n",
       "       False, False,  True, False, False, False, False, False,  True,\n",
       "       False, False, False,  True,  True, False, False, False, False,\n",
       "        True, False, False, False, False, False, False, False, False,\n",
       "       False, False, False, False, False, False,  True, False, False,\n",
       "       False, False, False, False, False, False, False, False, False,\n",
       "       False, False, False, False, False,  True, False, False, False,\n",
       "       False, False, False,  True,  True, False,  True, False, False,\n",
       "       False, False, False, False, False, False, False, False, False,\n",
       "       False, False, False, False, False,  True, False, False, False,\n",
       "        True, False, False, False, False, False, False,  True, False,\n",
       "       False, False, False, False, False,  True, False, False, False,\n",
       "       False, False, False, False, False, False, False, False, False,\n",
       "       False, False, False, False, False, False, False, False, False,\n",
       "       False, False, False, False, False, False, False, False, False,\n",
       "       False, False, False, False, False, False, False, False, False,\n",
       "       False, False,  True, False, False, False, False, False, False,\n",
       "       False, False, False, False, False, False, False, False, False,\n",
       "       False, False, False, False, False, False, False, False, False,\n",
       "       False, False, False, False, False, False, False, False, False,\n",
       "       False, False, False,  True, False, False, False, False, False,\n",
       "       False, False, False, False, False,  True, False, False, False,\n",
       "       False, False, False, False, False, False, False, False, False,\n",
       "       False, False, False, False, False, False, False, False, False,\n",
       "       False, False, False, False, False, False, False, False, False,\n",
       "        True])"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "selected_features = X.columns[mask]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tfidf_7</th>\n",
       "      <th>tfidf_29</th>\n",
       "      <th>tfidf_39</th>\n",
       "      <th>tfidf_57</th>\n",
       "      <th>tfidf_84</th>\n",
       "      <th>tfidf_105</th>\n",
       "      <th>tfidf_117</th>\n",
       "      <th>tfidf_119</th>\n",
       "      <th>tfidf_121</th>\n",
       "      <th>tfidf_125</th>\n",
       "      <th>...</th>\n",
       "      <th>tfidf_310</th>\n",
       "      <th>tfidf_312</th>\n",
       "      <th>tfidf_329</th>\n",
       "      <th>tfidf_333</th>\n",
       "      <th>tfidf_340</th>\n",
       "      <th>tfidf_347</th>\n",
       "      <th>indica</th>\n",
       "      <th>blueberry</th>\n",
       "      <th>grape</th>\n",
       "      <th>woody</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.165248</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.208564</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.077150</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.104649</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.117085</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.178640</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.163848</td>\n",
       "      <td>0.120848</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29995</th>\n",
       "      <td>0.261458</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.179750</td>\n",
       "      <td>0.132576</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29996</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.46193</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.288772</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29997</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29998</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29999</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>30000 rows × 41 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        tfidf_7  tfidf_29  tfidf_39  tfidf_57  tfidf_84  tfidf_105  tfidf_117  \\\n",
       "0      0.000000       0.0       0.0       0.0   0.00000        0.0        0.0   \n",
       "1      0.000000       0.0       0.0       0.0   0.00000        0.0        0.0   \n",
       "2      0.000000       0.0       0.0       0.0   0.00000        0.0        0.0   \n",
       "3      0.000000       0.0       0.0       0.0   0.00000        0.0        0.0   \n",
       "4      0.000000       0.0       0.0       0.0   0.00000        0.0        0.0   \n",
       "...         ...       ...       ...       ...       ...        ...        ...   \n",
       "29995  0.261458       0.0       0.0       0.0   0.00000        0.0        0.0   \n",
       "29996  0.000000       0.0       0.0       0.0   0.46193        0.0        0.0   \n",
       "29997  0.000000       0.0       0.0       0.0   0.00000        0.0        0.0   \n",
       "29998  0.000000       0.0       0.0       0.0   0.00000        0.0        0.0   \n",
       "29999  0.000000       0.0       0.0       0.0   0.00000        0.0        0.0   \n",
       "\n",
       "       tfidf_119  tfidf_121  tfidf_125  ...  tfidf_310  tfidf_312  tfidf_329  \\\n",
       "0       0.000000   0.165248        0.0  ...   0.000000   0.000000   0.000000   \n",
       "1       0.000000   0.000000        0.0  ...   0.208564   0.000000   0.077150   \n",
       "2       0.000000   0.000000        0.0  ...   0.000000   0.104649   0.000000   \n",
       "3       0.000000   0.000000        0.0  ...   0.000000   0.000000   0.117085   \n",
       "4       0.000000   0.178640        0.0  ...   0.000000   0.163848   0.120848   \n",
       "...          ...        ...        ...  ...        ...        ...        ...   \n",
       "29995   0.000000   0.000000        0.0  ...   0.000000   0.179750   0.132576   \n",
       "29996   0.288772   0.000000        0.0  ...   0.000000   0.000000   0.000000   \n",
       "29997   0.000000   0.000000        0.0  ...   0.000000   0.000000   0.000000   \n",
       "29998   0.000000   0.000000        0.0  ...   0.000000   0.000000   0.000000   \n",
       "29999   0.000000   0.000000        0.0  ...   0.000000   0.000000   0.000000   \n",
       "\n",
       "       tfidf_333  tfidf_340  tfidf_347  indica  blueberry  grape  woody  \n",
       "0            0.0        0.0        0.0       0          0      0      0  \n",
       "1            0.0        0.0        0.0       0          0      0      0  \n",
       "2            0.0        0.0        0.0       0          0      0      0  \n",
       "3            0.0        0.0        0.0       0          0      0      0  \n",
       "4            0.0        0.0        0.0       0          0      0      0  \n",
       "...          ...        ...        ...     ...        ...    ...    ...  \n",
       "29995        0.0        0.0        0.0       1          0      0      0  \n",
       "29996        0.0        0.0        0.0       1          0      0      0  \n",
       "29997        0.0        0.0        0.0       1          0      0      0  \n",
       "29998        0.0        0.0        0.0       1          0      0      0  \n",
       "29999        0.0        0.0        0.0       1          0      0      0  \n",
       "\n",
       "[30000 rows x 41 columns]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "selected_X = df_rf[selected_features]\n",
    "selected_X"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train test split (after Feature Selection)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['selected_X_rf_tfidf_bpine.pkl']"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import joblib\n",
    "\n",
    "joblib.dump(selector, \"selector_rf_tfidf_bpine.pkl\")\n",
    "joblib.dump(selected_X, \"selected_X_rf_tfidf_bpine.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(selected_X, y, random_state=1, test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train1, X_val, y_train1, y_val = train_test_split(X_train, y_train, random_state=1, test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/ns/m5pnr0211w91v02hpv22958m0000gn/T/ipykernel_87785/3758305.py:1: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  rfreg.fit(X_train1, y_train1)\n"
     ]
    }
   ],
   "source": [
    "rfreg.fit(X_train1, y_train1)\n",
    "y_pred_rfreg = rfreg.predict(X_val)\n",
    "y_pred_rfreg_r2 = rfreg.predict(X_train1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.038469457028765475"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mean_absolute_error(y_val, y_pred_rfreg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.019610779665691542"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mean_squared_error(y_val, y_pred_rfreg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.1400384935140747"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mean_squared_error(y_val, y_pred_rfreg, squared = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9470996999272758"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#train\n",
    "r2_score(y_train1, y_pred_rfreg_r2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9204150016458742"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#val\n",
    "r2_score(y_val, y_pred_rfreg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hyperparameter Tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "parameters = {'max_depth': [None, 10, 50, 100],\n",
    "              'max_features': ['auto', 'sqrt'],\n",
    "              'min_samples_leaf': [1, 2, 4],\n",
    "              'min_samples_split': [2, 5, 10],\n",
    "              'n_estimators': [100, 300, 500]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "rscv = RandomizedSearchCV(rfreg,  \n",
    "                     parameters,   \n",
    "                     cv=5, \n",
    "                     scoring='neg_mean_absolute_error',\n",
    "                     n_jobs = -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/louispandu/anaconda3/lib/python3.10/site-packages/sklearn/model_selection/_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/Users/louispandu/anaconda3/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
      "  warn(\n",
      "/Users/louispandu/anaconda3/lib/python3.10/site-packages/sklearn/model_selection/_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/Users/louispandu/anaconda3/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
      "  warn(\n",
      "/Users/louispandu/anaconda3/lib/python3.10/site-packages/sklearn/model_selection/_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/Users/louispandu/anaconda3/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
      "  warn(\n",
      "/Users/louispandu/anaconda3/lib/python3.10/site-packages/sklearn/model_selection/_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/Users/louispandu/anaconda3/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
      "  warn(\n",
      "/Users/louispandu/anaconda3/lib/python3.10/site-packages/sklearn/model_selection/_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/Users/louispandu/anaconda3/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
      "  warn(\n",
      "/Users/louispandu/anaconda3/lib/python3.10/site-packages/sklearn/model_selection/_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/Users/louispandu/anaconda3/lib/python3.10/site-packages/sklearn/model_selection/_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/Users/louispandu/anaconda3/lib/python3.10/site-packages/sklearn/model_selection/_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/Users/louispandu/anaconda3/lib/python3.10/site-packages/sklearn/model_selection/_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/Users/louispandu/anaconda3/lib/python3.10/site-packages/sklearn/model_selection/_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/Users/louispandu/anaconda3/lib/python3.10/site-packages/sklearn/model_selection/_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/Users/louispandu/anaconda3/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
      "  warn(\n",
      "/Users/louispandu/anaconda3/lib/python3.10/site-packages/sklearn/model_selection/_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/Users/louispandu/anaconda3/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
      "  warn(\n",
      "/Users/louispandu/anaconda3/lib/python3.10/site-packages/sklearn/model_selection/_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/Users/louispandu/anaconda3/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
      "  warn(\n",
      "/Users/louispandu/anaconda3/lib/python3.10/site-packages/sklearn/model_selection/_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/Users/louispandu/anaconda3/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
      "  warn(\n",
      "/Users/louispandu/anaconda3/lib/python3.10/site-packages/sklearn/model_selection/_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/Users/louispandu/anaconda3/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
      "  warn(\n",
      "/Users/louispandu/anaconda3/lib/python3.10/site-packages/sklearn/model_selection/_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/Users/louispandu/anaconda3/lib/python3.10/site-packages/sklearn/model_selection/_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/Users/louispandu/anaconda3/lib/python3.10/site-packages/sklearn/model_selection/_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/Users/louispandu/anaconda3/lib/python3.10/site-packages/sklearn/model_selection/_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/Users/louispandu/anaconda3/lib/python3.10/site-packages/sklearn/model_selection/_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/Users/louispandu/anaconda3/lib/python3.10/site-packages/sklearn/model_selection/_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/Users/louispandu/anaconda3/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
      "  warn(\n",
      "/Users/louispandu/anaconda3/lib/python3.10/site-packages/sklearn/model_selection/_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/Users/louispandu/anaconda3/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
      "  warn(\n",
      "/Users/louispandu/anaconda3/lib/python3.10/site-packages/sklearn/model_selection/_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/Users/louispandu/anaconda3/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
      "  warn(\n",
      "/Users/louispandu/anaconda3/lib/python3.10/site-packages/sklearn/model_selection/_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/Users/louispandu/anaconda3/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
      "  warn(\n",
      "/Users/louispandu/anaconda3/lib/python3.10/site-packages/sklearn/model_selection/_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/Users/louispandu/anaconda3/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
      "  warn(\n",
      "/Users/louispandu/anaconda3/lib/python3.10/site-packages/sklearn/model_selection/_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/Users/louispandu/anaconda3/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
      "  warn(\n",
      "/Users/louispandu/anaconda3/lib/python3.10/site-packages/sklearn/model_selection/_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/Users/louispandu/anaconda3/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
      "  warn(\n",
      "/Users/louispandu/anaconda3/lib/python3.10/site-packages/sklearn/model_selection/_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/Users/louispandu/anaconda3/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
      "  warn(\n",
      "/Users/louispandu/anaconda3/lib/python3.10/site-packages/sklearn/model_selection/_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/Users/louispandu/anaconda3/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
      "  warn(\n",
      "/Users/louispandu/anaconda3/lib/python3.10/site-packages/sklearn/model_selection/_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/Users/louispandu/anaconda3/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
      "  warn(\n",
      "/Users/louispandu/anaconda3/lib/python3.10/site-packages/sklearn/model_selection/_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/Users/louispandu/anaconda3/lib/python3.10/site-packages/sklearn/model_selection/_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/Users/louispandu/anaconda3/lib/python3.10/site-packages/sklearn/model_selection/_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/Users/louispandu/anaconda3/lib/python3.10/site-packages/sklearn/model_selection/_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/Users/louispandu/anaconda3/lib/python3.10/site-packages/sklearn/model_selection/_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/Users/louispandu/anaconda3/lib/python3.10/site-packages/sklearn/model_selection/_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/Users/louispandu/anaconda3/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
      "  warn(\n",
      "/Users/louispandu/anaconda3/lib/python3.10/site-packages/sklearn/model_selection/_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/Users/louispandu/anaconda3/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
      "  warn(\n",
      "/Users/louispandu/anaconda3/lib/python3.10/site-packages/sklearn/model_selection/_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/Users/louispandu/anaconda3/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
      "  warn(\n",
      "/Users/louispandu/anaconda3/lib/python3.10/site-packages/sklearn/model_selection/_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/Users/louispandu/anaconda3/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
      "  warn(\n",
      "/Users/louispandu/anaconda3/lib/python3.10/site-packages/sklearn/model_selection/_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/Users/louispandu/anaconda3/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
      "  warn(\n",
      "/Users/louispandu/anaconda3/lib/python3.10/site-packages/sklearn/model_selection/_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/Users/louispandu/anaconda3/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
      "  warn(\n",
      "/Users/louispandu/anaconda3/lib/python3.10/site-packages/sklearn/model_selection/_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/Users/louispandu/anaconda3/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
      "  warn(\n",
      "/Users/louispandu/anaconda3/lib/python3.10/site-packages/sklearn/model_selection/_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/Users/louispandu/anaconda3/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
      "  warn(\n",
      "/Users/louispandu/anaconda3/lib/python3.10/site-packages/sklearn/model_selection/_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/Users/louispandu/anaconda3/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
      "  warn(\n",
      "/Users/louispandu/anaconda3/lib/python3.10/site-packages/sklearn/model_selection/_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/Users/louispandu/anaconda3/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
      "  warn(\n",
      "/Users/louispandu/anaconda3/lib/python3.10/site-packages/sklearn/model_selection/_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/Users/louispandu/anaconda3/lib/python3.10/site-packages/sklearn/model_selection/_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/Users/louispandu/anaconda3/lib/python3.10/site-packages/sklearn/model_selection/_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/Users/louispandu/anaconda3/lib/python3.10/site-packages/sklearn/model_selection/_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/Users/louispandu/anaconda3/lib/python3.10/site-packages/sklearn/model_selection/_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/Users/louispandu/anaconda3/lib/python3.10/site-packages/sklearn/model_selection/_search.py:909: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  self.best_estimator_.fit(X, y, **fit_params)\n",
      "/Users/louispandu/anaconda3/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
      "  warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-2 {color: black;background-color: white;}#sk-container-id-2 pre{padding: 0;}#sk-container-id-2 div.sk-toggleable {background-color: white;}#sk-container-id-2 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-2 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-2 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-2 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-2 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-2 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-2 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-2 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-2 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-2 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-2 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-2 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-2 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-2 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-2 div.sk-item {position: relative;z-index: 1;}#sk-container-id-2 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-2 div.sk-item::before, #sk-container-id-2 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-2 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-2 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-2 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-2 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-2 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-2 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-2 div.sk-label-container {text-align: center;}#sk-container-id-2 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-2 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-2\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>RandomizedSearchCV(cv=5, estimator=RandomForestRegressor(), n_jobs=-1,\n",
       "                   param_distributions={&#x27;max_depth&#x27;: [None, 10, 50, 100],\n",
       "                                        &#x27;max_features&#x27;: [&#x27;auto&#x27;, &#x27;sqrt&#x27;],\n",
       "                                        &#x27;min_samples_leaf&#x27;: [1, 2, 4],\n",
       "                                        &#x27;min_samples_split&#x27;: [2, 5, 10],\n",
       "                                        &#x27;n_estimators&#x27;: [100, 300, 500]},\n",
       "                   scoring=&#x27;neg_mean_absolute_error&#x27;)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" ><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">RandomizedSearchCV</label><div class=\"sk-toggleable__content\"><pre>RandomizedSearchCV(cv=5, estimator=RandomForestRegressor(), n_jobs=-1,\n",
       "                   param_distributions={&#x27;max_depth&#x27;: [None, 10, 50, 100],\n",
       "                                        &#x27;max_features&#x27;: [&#x27;auto&#x27;, &#x27;sqrt&#x27;],\n",
       "                                        &#x27;min_samples_leaf&#x27;: [1, 2, 4],\n",
       "                                        &#x27;min_samples_split&#x27;: [2, 5, 10],\n",
       "                                        &#x27;n_estimators&#x27;: [100, 300, 500]},\n",
       "                   scoring=&#x27;neg_mean_absolute_error&#x27;)</pre></div></div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-3\" type=\"checkbox\" ><label for=\"sk-estimator-id-3\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">estimator: RandomForestRegressor</label><div class=\"sk-toggleable__content\"><pre>RandomForestRegressor()</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-4\" type=\"checkbox\" ><label for=\"sk-estimator-id-4\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">RandomForestRegressor</label><div class=\"sk-toggleable__content\"><pre>RandomForestRegressor()</pre></div></div></div></div></div></div></div></div></div></div>"
      ],
      "text/plain": [
       "RandomizedSearchCV(cv=5, estimator=RandomForestRegressor(), n_jobs=-1,\n",
       "                   param_distributions={'max_depth': [None, 10, 50, 100],\n",
       "                                        'max_features': ['auto', 'sqrt'],\n",
       "                                        'min_samples_leaf': [1, 2, 4],\n",
       "                                        'min_samples_split': [2, 5, 10],\n",
       "                                        'n_estimators': [100, 300, 500]},\n",
       "                   scoring='neg_mean_absolute_error')"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rscv.fit(X_train1, y_train1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'n_estimators': 500,\n",
       " 'min_samples_split': 2,\n",
       " 'min_samples_leaf': 1,\n",
       " 'max_features': 'auto',\n",
       " 'max_depth': None}"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rscv.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['rscv_rf_tfidf_best_params_bpine.pkl']"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "joblib.dump(rscv, \"rscv_rf_tfidf_bpine.pkl\")\n",
    "joblib.dump(rscv.best_params_, \"rscv_rf_tfidf_best_params_bpine.pkl\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "RF (after Hyperparameter Tuning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/ns/m5pnr0211w91v02hpv22958m0000gn/T/ipykernel_87785/2891017253.py:2: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  rfreg_ht.fit(X_train1, y_train1)\n",
      "/Users/louispandu/anaconda3/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
      "  warn(\n"
     ]
    }
   ],
   "source": [
    "rfreg_ht = RandomForestRegressor(n_estimators = 500, min_samples_split = 2, min_samples_leaf = 1, max_features = 'auto', max_depth = None)\n",
    "rfreg_ht.fit(X_train1, y_train1)\n",
    "y_pred_rfreg = rfreg_ht.predict(X_val)\n",
    "y_pred_rfreg_r2 = rfreg_ht.predict(X_train1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.038352897158034756"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mean_absolute_error(y_val, y_pred_rfreg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.019499274001835206"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mean_squared_error(y_val, y_pred_rfreg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.1396398009230721"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mean_squared_error(y_val, y_pred_rfreg, squared = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9471844916270884"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#train\n",
    "r2_score(y_train1, y_pred_rfreg_r2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9208675169576447"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#val\n",
    "r2_score(y_val, y_pred_rfreg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Residual plots after Hyperparameter Tuning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Predicting model on the test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_rfreg_test = rfreg_ht.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['y_test_rfreg_tfidf_bpine.pkl']"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "joblib.dump(y_pred_rfreg_test, \"y_pred_rfreg_test_tfidf_bpine.pkl\")\n",
    "joblib.dump(y_test, \"y_test_rfreg_tfidf_bpine.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.03980838126485927"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mean_absolute_error(y_test, y_pred_rfreg_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.019501204295620432"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mean_squared_error(y_test, y_pred_rfreg_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.13964671244114713"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mean_squared_error(y_test, y_pred_rfreg_test, squared = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9208369357291618"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "r2_score(y_test, y_pred_rfreg_test)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Error analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 800x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# assume y_pred is a numpy array and y_true is a pandas dataframe\n",
    "fig, ax = plt.subplots(figsize=(8, 6))\n",
    "\n",
    "column = \"X..Beta-Pinene\"  # specify the target variable name\n",
    "ax.hist(y_pred_rfreg_test, alpha=0.5, label='y_pred', bins=20)\n",
    "ax.hist(y_test[column], alpha=0.5, label='y_true', bins=20)\n",
    "ax.legend(loc='upper right')\n",
    "ax.set_title(column)\n",
    "\n",
    "plt.show()\n",
    "plt.savefig('error_hist_knn_tfidf_bpine.png')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pearson R"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pearson correlation coefficient: 0.960\n",
      "P-value: 0.000\n"
     ]
    }
   ],
   "source": [
    "corr_coef, p_value = pearsonr(y_pred_rfreg_test.flatten(), y_test.values.ravel())\n",
    "\n",
    "print(f\"Pearson correlation coefficient: {corr_coef:.3f}\")\n",
    "print(f\"P-value: {p_value:.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Axes: >"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "corr_matrix = y_test.corr()\n",
    "sns.heatmap(corr_matrix, annot=True, cmap='coolwarm', center=0)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
