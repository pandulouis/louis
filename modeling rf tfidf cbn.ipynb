{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn import preprocessing\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.neural_network import MLPRegressor\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "from sklearn.metrics import r2_score\n",
    "from scipy.stats import pearsonr\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.feature_selection import SelectFromModel\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compiling complete dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_rf = pd.read_csv(\"df_cbn_tfidf.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['index',\n",
       " 'tfidf_0',\n",
       " 'tfidf_1',\n",
       " 'tfidf_2',\n",
       " 'tfidf_3',\n",
       " 'tfidf_4',\n",
       " 'tfidf_5',\n",
       " 'tfidf_6',\n",
       " 'tfidf_7',\n",
       " 'tfidf_8',\n",
       " 'tfidf_9',\n",
       " 'tfidf_10',\n",
       " 'tfidf_11',\n",
       " 'tfidf_12',\n",
       " 'tfidf_13',\n",
       " 'tfidf_14',\n",
       " 'tfidf_15',\n",
       " 'tfidf_16',\n",
       " 'tfidf_17',\n",
       " 'tfidf_18',\n",
       " 'tfidf_19',\n",
       " 'tfidf_20',\n",
       " 'tfidf_21',\n",
       " 'tfidf_22',\n",
       " 'tfidf_23',\n",
       " 'tfidf_24',\n",
       " 'tfidf_25',\n",
       " 'tfidf_26',\n",
       " 'tfidf_27',\n",
       " 'tfidf_28',\n",
       " 'tfidf_29',\n",
       " 'tfidf_30',\n",
       " 'tfidf_31',\n",
       " 'tfidf_32',\n",
       " 'tfidf_33',\n",
       " 'tfidf_34',\n",
       " 'tfidf_35',\n",
       " 'tfidf_36',\n",
       " 'tfidf_37',\n",
       " 'tfidf_38',\n",
       " 'tfidf_39',\n",
       " 'tfidf_40',\n",
       " 'tfidf_41',\n",
       " 'tfidf_42',\n",
       " 'tfidf_43',\n",
       " 'tfidf_44',\n",
       " 'tfidf_45',\n",
       " 'tfidf_46',\n",
       " 'tfidf_47',\n",
       " 'tfidf_48',\n",
       " 'tfidf_49',\n",
       " 'tfidf_50',\n",
       " 'tfidf_51',\n",
       " 'tfidf_52',\n",
       " 'tfidf_53',\n",
       " 'tfidf_54',\n",
       " 'tfidf_55',\n",
       " 'tfidf_56',\n",
       " 'tfidf_57',\n",
       " 'tfidf_58',\n",
       " 'tfidf_59',\n",
       " 'tfidf_60',\n",
       " 'tfidf_61',\n",
       " 'tfidf_62',\n",
       " 'tfidf_63',\n",
       " 'tfidf_64',\n",
       " 'tfidf_65',\n",
       " 'tfidf_66',\n",
       " 'tfidf_67',\n",
       " 'tfidf_68',\n",
       " 'tfidf_69',\n",
       " 'tfidf_70',\n",
       " 'tfidf_71',\n",
       " 'tfidf_72',\n",
       " 'tfidf_73',\n",
       " 'tfidf_74',\n",
       " 'tfidf_75',\n",
       " 'tfidf_76',\n",
       " 'tfidf_77',\n",
       " 'tfidf_78',\n",
       " 'tfidf_79',\n",
       " 'tfidf_80',\n",
       " 'tfidf_81',\n",
       " 'tfidf_82',\n",
       " 'tfidf_83',\n",
       " 'tfidf_84',\n",
       " 'tfidf_85',\n",
       " 'tfidf_86',\n",
       " 'tfidf_87',\n",
       " 'tfidf_88',\n",
       " 'tfidf_89',\n",
       " 'tfidf_90',\n",
       " 'tfidf_91',\n",
       " 'tfidf_92',\n",
       " 'tfidf_93',\n",
       " 'tfidf_94',\n",
       " 'tfidf_95',\n",
       " 'tfidf_96',\n",
       " 'tfidf_97',\n",
       " 'tfidf_98',\n",
       " 'tfidf_99',\n",
       " 'tfidf_100',\n",
       " 'tfidf_101',\n",
       " 'tfidf_102',\n",
       " 'tfidf_103',\n",
       " 'tfidf_104',\n",
       " 'tfidf_105',\n",
       " 'tfidf_106',\n",
       " 'tfidf_107',\n",
       " 'tfidf_108',\n",
       " 'tfidf_109',\n",
       " 'tfidf_110',\n",
       " 'tfidf_111',\n",
       " 'tfidf_112',\n",
       " 'tfidf_113',\n",
       " 'tfidf_114',\n",
       " 'tfidf_115',\n",
       " 'tfidf_116',\n",
       " 'tfidf_117',\n",
       " 'tfidf_118',\n",
       " 'tfidf_119',\n",
       " 'tfidf_120',\n",
       " 'tfidf_121',\n",
       " 'tfidf_122',\n",
       " 'tfidf_123',\n",
       " 'tfidf_124',\n",
       " 'tfidf_125',\n",
       " 'tfidf_126',\n",
       " 'tfidf_127',\n",
       " 'tfidf_128',\n",
       " 'tfidf_129',\n",
       " 'tfidf_130',\n",
       " 'tfidf_131',\n",
       " 'tfidf_132',\n",
       " 'tfidf_133',\n",
       " 'tfidf_134',\n",
       " 'tfidf_135',\n",
       " 'tfidf_136',\n",
       " 'tfidf_137',\n",
       " 'tfidf_138',\n",
       " 'tfidf_139',\n",
       " 'tfidf_140',\n",
       " 'tfidf_141',\n",
       " 'tfidf_142',\n",
       " 'tfidf_143',\n",
       " 'tfidf_144',\n",
       " 'tfidf_145',\n",
       " 'tfidf_146',\n",
       " 'tfidf_147',\n",
       " 'tfidf_148',\n",
       " 'tfidf_149',\n",
       " 'tfidf_150',\n",
       " 'tfidf_151',\n",
       " 'tfidf_152',\n",
       " 'tfidf_153',\n",
       " 'tfidf_154',\n",
       " 'tfidf_155',\n",
       " 'tfidf_156',\n",
       " 'tfidf_157',\n",
       " 'tfidf_158',\n",
       " 'tfidf_159',\n",
       " 'tfidf_160',\n",
       " 'tfidf_161',\n",
       " 'tfidf_162',\n",
       " 'tfidf_163',\n",
       " 'tfidf_164',\n",
       " 'tfidf_165',\n",
       " 'tfidf_166',\n",
       " 'tfidf_167',\n",
       " 'tfidf_168',\n",
       " 'tfidf_169',\n",
       " 'tfidf_170',\n",
       " 'tfidf_171',\n",
       " 'tfidf_172',\n",
       " 'tfidf_173',\n",
       " 'tfidf_174',\n",
       " 'tfidf_175',\n",
       " 'tfidf_176',\n",
       " 'tfidf_177',\n",
       " 'tfidf_178',\n",
       " 'tfidf_179',\n",
       " 'tfidf_180',\n",
       " 'tfidf_181',\n",
       " 'tfidf_182',\n",
       " 'tfidf_183',\n",
       " 'tfidf_184',\n",
       " 'tfidf_185',\n",
       " 'tfidf_186',\n",
       " 'tfidf_187',\n",
       " 'tfidf_188',\n",
       " 'tfidf_189',\n",
       " 'tfidf_190',\n",
       " 'tfidf_191',\n",
       " 'tfidf_192',\n",
       " 'tfidf_193',\n",
       " 'tfidf_194',\n",
       " 'tfidf_195',\n",
       " 'tfidf_196',\n",
       " 'tfidf_197',\n",
       " 'tfidf_198',\n",
       " 'tfidf_199',\n",
       " 'tfidf_200',\n",
       " 'tfidf_201',\n",
       " 'tfidf_202',\n",
       " 'tfidf_203',\n",
       " 'tfidf_204',\n",
       " 'tfidf_205',\n",
       " 'tfidf_206',\n",
       " 'tfidf_207',\n",
       " 'tfidf_208',\n",
       " 'tfidf_209',\n",
       " 'tfidf_210',\n",
       " 'tfidf_211',\n",
       " 'tfidf_212',\n",
       " 'tfidf_213',\n",
       " 'tfidf_214',\n",
       " 'tfidf_215',\n",
       " 'tfidf_216',\n",
       " 'tfidf_217',\n",
       " 'tfidf_218',\n",
       " 'tfidf_219',\n",
       " 'tfidf_220',\n",
       " 'tfidf_221',\n",
       " 'tfidf_222',\n",
       " 'tfidf_223',\n",
       " 'tfidf_224',\n",
       " 'tfidf_225',\n",
       " 'tfidf_226',\n",
       " 'tfidf_227',\n",
       " 'tfidf_228',\n",
       " 'tfidf_229',\n",
       " 'tfidf_230',\n",
       " 'tfidf_231',\n",
       " 'tfidf_232',\n",
       " 'tfidf_233',\n",
       " 'tfidf_234',\n",
       " 'tfidf_235',\n",
       " 'tfidf_236',\n",
       " 'tfidf_237',\n",
       " 'tfidf_238',\n",
       " 'tfidf_239',\n",
       " 'tfidf_240',\n",
       " 'tfidf_241',\n",
       " 'tfidf_242',\n",
       " 'tfidf_243',\n",
       " 'tfidf_244',\n",
       " 'tfidf_245',\n",
       " 'tfidf_246',\n",
       " 'tfidf_247',\n",
       " 'tfidf_248',\n",
       " 'tfidf_249',\n",
       " 'tfidf_250',\n",
       " 'tfidf_251',\n",
       " 'tfidf_252',\n",
       " 'tfidf_253',\n",
       " 'tfidf_254',\n",
       " 'tfidf_255',\n",
       " 'tfidf_256',\n",
       " 'tfidf_257',\n",
       " 'tfidf_258',\n",
       " 'tfidf_259',\n",
       " 'tfidf_260',\n",
       " 'tfidf_261',\n",
       " 'tfidf_262',\n",
       " 'tfidf_263',\n",
       " 'tfidf_264',\n",
       " 'tfidf_265',\n",
       " 'tfidf_266',\n",
       " 'tfidf_267',\n",
       " 'tfidf_268',\n",
       " 'tfidf_269',\n",
       " 'tfidf_270',\n",
       " 'tfidf_271',\n",
       " 'tfidf_272',\n",
       " 'tfidf_273',\n",
       " 'tfidf_274',\n",
       " 'tfidf_275',\n",
       " 'tfidf_276',\n",
       " 'tfidf_277',\n",
       " 'tfidf_278',\n",
       " 'tfidf_279',\n",
       " 'tfidf_280',\n",
       " 'tfidf_281',\n",
       " 'tfidf_282',\n",
       " 'tfidf_283',\n",
       " 'tfidf_284',\n",
       " 'tfidf_285',\n",
       " 'tfidf_286',\n",
       " 'tfidf_287',\n",
       " 'tfidf_288',\n",
       " 'tfidf_289',\n",
       " 'tfidf_290',\n",
       " 'tfidf_291',\n",
       " 'tfidf_292',\n",
       " 'tfidf_293',\n",
       " 'tfidf_294',\n",
       " 'tfidf_295',\n",
       " 'tfidf_296',\n",
       " 'tfidf_297',\n",
       " 'tfidf_298',\n",
       " 'tfidf_299',\n",
       " 'tfidf_300',\n",
       " 'tfidf_301',\n",
       " 'tfidf_302',\n",
       " 'tfidf_303',\n",
       " 'tfidf_304',\n",
       " 'tfidf_305',\n",
       " 'tfidf_306',\n",
       " 'tfidf_307',\n",
       " 'tfidf_308',\n",
       " 'tfidf_309',\n",
       " 'tfidf_310',\n",
       " 'tfidf_311',\n",
       " 'tfidf_312',\n",
       " 'tfidf_313',\n",
       " 'tfidf_314',\n",
       " 'tfidf_315',\n",
       " 'tfidf_316',\n",
       " 'tfidf_317',\n",
       " 'tfidf_318',\n",
       " 'tfidf_319',\n",
       " 'tfidf_320',\n",
       " 'tfidf_321',\n",
       " 'tfidf_322',\n",
       " 'tfidf_323',\n",
       " 'tfidf_324',\n",
       " 'tfidf_325',\n",
       " 'tfidf_326',\n",
       " 'tfidf_327',\n",
       " 'tfidf_328',\n",
       " 'tfidf_329',\n",
       " 'tfidf_330',\n",
       " 'tfidf_331',\n",
       " 'tfidf_332',\n",
       " 'tfidf_333',\n",
       " 'tfidf_334',\n",
       " 'tfidf_335',\n",
       " 'tfidf_336',\n",
       " 'tfidf_337',\n",
       " 'tfidf_338',\n",
       " 'tfidf_339',\n",
       " 'tfidf_340',\n",
       " 'tfidf_341',\n",
       " 'tfidf_342',\n",
       " 'tfidf_343',\n",
       " 'tfidf_344',\n",
       " 'tfidf_345',\n",
       " 'tfidf_346',\n",
       " 'tfidf_347',\n",
       " 'tfidf_348',\n",
       " 'tfidf_349',\n",
       " 'tfidf_350',\n",
       " 'tfidf_351',\n",
       " 'tfidf_352',\n",
       " 'tfidf_353',\n",
       " 'tfidf_354',\n",
       " 'tfidf_355',\n",
       " 'tfidf_356',\n",
       " 'tfidf_357',\n",
       " 'tfidf_358',\n",
       " 'tfidf_359',\n",
       " 'tfidf_360',\n",
       " 'tfidf_361',\n",
       " 'tfidf_362',\n",
       " 'tfidf_363',\n",
       " 'tfidf_364',\n",
       " 'tfidf_365',\n",
       " 'tfidf_366',\n",
       " 'tfidf_367',\n",
       " 'tfidf_368',\n",
       " 'tfidf_369',\n",
       " 'tfidf_370',\n",
       " 'tfidf_371',\n",
       " 'tfidf_372',\n",
       " 'tfidf_373',\n",
       " 'tfidf_374',\n",
       " 'tfidf_375',\n",
       " 'tfidf_376',\n",
       " 'tfidf_377',\n",
       " 'tfidf_378',\n",
       " 'tfidf_379',\n",
       " 'tfidf_380',\n",
       " 'tfidf_381',\n",
       " 'tfidf_382',\n",
       " 'tfidf_383',\n",
       " 'tfidf_384',\n",
       " 'tfidf_385',\n",
       " 'tfidf_386',\n",
       " 'tfidf_387',\n",
       " 'hybrid',\n",
       " 'indica',\n",
       " 'sativa',\n",
       " 'anxiety',\n",
       " 'anxious',\n",
       " 'aroused',\n",
       " 'arthritis',\n",
       " 'creative',\n",
       " 'depression',\n",
       " 'dizzy',\n",
       " 'dry eyes',\n",
       " 'dry mouth',\n",
       " 'energetic',\n",
       " 'epilepsy',\n",
       " 'euphoric',\n",
       " 'eye pressure',\n",
       " 'fatigue',\n",
       " 'focused',\n",
       " 'giggly',\n",
       " 'happy',\n",
       " 'headache',\n",
       " 'hungry',\n",
       " 'migraines',\n",
       " 'pain',\n",
       " 'paranoid',\n",
       " 'relaxed',\n",
       " 'seizures',\n",
       " 'sleepy',\n",
       " 'spasticity',\n",
       " 'stress',\n",
       " 'talkative',\n",
       " 'tingly',\n",
       " 'uplifted',\n",
       " 'ammonia',\n",
       " 'apple',\n",
       " 'apricot',\n",
       " 'berry',\n",
       " 'blue cheese',\n",
       " 'blueberry',\n",
       " 'butter',\n",
       " 'cheese',\n",
       " 'chemical',\n",
       " 'chestnut',\n",
       " 'citrus',\n",
       " 'coffee',\n",
       " 'diesel',\n",
       " 'earthy',\n",
       " 'flowery',\n",
       " 'fruit',\n",
       " 'grape',\n",
       " 'grapefruit',\n",
       " 'honey',\n",
       " 'lavender',\n",
       " 'lemon',\n",
       " 'lime',\n",
       " 'mango',\n",
       " 'menthol',\n",
       " 'mint',\n",
       " 'nutty',\n",
       " 'orange',\n",
       " 'peach',\n",
       " 'pear',\n",
       " 'pepper',\n",
       " 'pine',\n",
       " 'pineapple',\n",
       " 'plum',\n",
       " 'pungent',\n",
       " 'rose',\n",
       " 'sage',\n",
       " 'skunk',\n",
       " 'spicy/herbal',\n",
       " 'strawberry',\n",
       " 'sweet',\n",
       " 'tar',\n",
       " 'tea',\n",
       " 'tobacco',\n",
       " 'tree',\n",
       " 'tropical',\n",
       " 'vanilla',\n",
       " 'violet',\n",
       " 'woody',\n",
       " 'X..CBN']"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_rf.columns.to_list()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Splitting dependent and independent variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df_rf.drop(['index', 'X..CBN'], axis = 1)\n",
    "y = df_rf[['X..CBN']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plotting histograms on target variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.13793103],\n",
       "       [0.13793103],\n",
       "       [0.13793103],\n",
       "       ...,\n",
       "       [0.10344828],\n",
       "       [0.10344828],\n",
       "       [0.10344828]])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_array = y.to_numpy()\n",
    "y_array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:ylabel='Count'>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "sns.histplot(y, bins = 10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train test split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=1, test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train1, X_val, y_train1, y_val = train_test_split(X_train, y_train, random_state=1, test_size=0.25)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "RF modeling (before Feature selection and Hyperparameter Tuning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/y1/pjvjlkjn5gl846rnyzr53p340000gn/T/ipykernel_7227/350139188.py:2: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  rfreg.fit(X_train1, y_train1)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;background-color: white;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>RandomForestRegressor()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">RandomForestRegressor</label><div class=\"sk-toggleable__content\"><pre>RandomForestRegressor()</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "RandomForestRegressor()"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rfreg = RandomForestRegressor()\n",
    "rfreg.fit(X_train1, y_train1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_rfreg = rfreg.predict(X_val)\n",
    "y_pred_rfreg_r2 = rfreg.predict(X_train1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.037539601870602776"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mean_absolute_error(y_val, y_pred_rfreg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.007582203860294488"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mean_squared_error(y_val, y_pred_rfreg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.08707585118903224"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mean_squared_error(y_val, y_pred_rfreg, squared = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9844635008428732"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#train\n",
    "r2_score(y_train1, y_pred_rfreg_r2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9231659629476835"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#val\n",
    "r2_score(y_val, y_pred_rfreg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Residual plots for each target variable"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Feature Selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_feat = pd.DataFrame({\n",
    "    \"features\": X_train1.columns,\n",
    "    \"score\": rfreg.feature_importances_\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>features</th>\n",
       "      <th>score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>tfidf_0</td>\n",
       "      <td>0.000328</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>tfidf_1</td>\n",
       "      <td>0.000831</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>tfidf_2</td>\n",
       "      <td>0.000311</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>tfidf_3</td>\n",
       "      <td>0.000300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>tfidf_4</td>\n",
       "      <td>0.000483</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>464</th>\n",
       "      <td>tree</td>\n",
       "      <td>0.000355</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>465</th>\n",
       "      <td>tropical</td>\n",
       "      <td>0.000402</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>466</th>\n",
       "      <td>vanilla</td>\n",
       "      <td>0.002914</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>467</th>\n",
       "      <td>violet</td>\n",
       "      <td>0.000016</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>468</th>\n",
       "      <td>woody</td>\n",
       "      <td>0.000780</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>469 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     features     score\n",
       "0     tfidf_0  0.000328\n",
       "1     tfidf_1  0.000831\n",
       "2     tfidf_2  0.000311\n",
       "3     tfidf_3  0.000300\n",
       "4     tfidf_4  0.000483\n",
       "..        ...       ...\n",
       "464      tree  0.000355\n",
       "465  tropical  0.000402\n",
       "466   vanilla  0.002914\n",
       "467    violet  0.000016\n",
       "468     woody  0.000780\n",
       "\n",
       "[469 rows x 2 columns]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_feat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_feat_ranked = df_feat.sort_values(\"score\", ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>features</th>\n",
       "      <th>score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>428</th>\n",
       "      <td>cheese</td>\n",
       "      <td>2.347916e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>390</th>\n",
       "      <td>sativa</td>\n",
       "      <td>4.798605e-02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>426</th>\n",
       "      <td>blueberry</td>\n",
       "      <td>2.176872e-02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>388</th>\n",
       "      <td>hybrid</td>\n",
       "      <td>2.125812e-02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>433</th>\n",
       "      <td>diesel</td>\n",
       "      <td>1.854841e-02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>145</th>\n",
       "      <td>tfidf_145</td>\n",
       "      <td>1.788623e-02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>447</th>\n",
       "      <td>orange</td>\n",
       "      <td>1.765932e-02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>329</th>\n",
       "      <td>tfidf_329</td>\n",
       "      <td>1.247164e-02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>210</th>\n",
       "      <td>tfidf_210</td>\n",
       "      <td>1.190771e-02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>422</th>\n",
       "      <td>apple</td>\n",
       "      <td>1.093112e-02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>170</th>\n",
       "      <td>tfidf_170</td>\n",
       "      <td>1.080447e-02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>72</th>\n",
       "      <td>tfidf_72</td>\n",
       "      <td>9.497330e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>316</th>\n",
       "      <td>tfidf_316</td>\n",
       "      <td>9.428395e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>299</th>\n",
       "      <td>tfidf_299</td>\n",
       "      <td>9.257443e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>350</th>\n",
       "      <td>tfidf_350</td>\n",
       "      <td>9.001828e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>294</th>\n",
       "      <td>tfidf_294</td>\n",
       "      <td>8.882568e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>245</th>\n",
       "      <td>tfidf_245</td>\n",
       "      <td>8.469232e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>80</th>\n",
       "      <td>tfidf_80</td>\n",
       "      <td>7.888026e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>445</th>\n",
       "      <td>mint</td>\n",
       "      <td>7.672922e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>168</th>\n",
       "      <td>tfidf_168</td>\n",
       "      <td>7.535297e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>81</th>\n",
       "      <td>tfidf_81</td>\n",
       "      <td>7.521751e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>312</th>\n",
       "      <td>tfidf_312</td>\n",
       "      <td>7.434115e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>135</th>\n",
       "      <td>tfidf_135</td>\n",
       "      <td>6.798141e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>149</th>\n",
       "      <td>tfidf_149</td>\n",
       "      <td>6.593973e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>121</th>\n",
       "      <td>tfidf_121</td>\n",
       "      <td>6.465389e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>129</th>\n",
       "      <td>tfidf_129</td>\n",
       "      <td>6.443078e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>141</th>\n",
       "      <td>tfidf_141</td>\n",
       "      <td>6.193136e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>460</th>\n",
       "      <td>sweet</td>\n",
       "      <td>6.071321e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>66</th>\n",
       "      <td>tfidf_66</td>\n",
       "      <td>5.921587e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>222</th>\n",
       "      <td>tfidf_222</td>\n",
       "      <td>5.700160e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>345</th>\n",
       "      <td>tfidf_345</td>\n",
       "      <td>5.372504e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>120</th>\n",
       "      <td>tfidf_120</td>\n",
       "      <td>5.231496e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>285</th>\n",
       "      <td>tfidf_285</td>\n",
       "      <td>5.173082e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>402</th>\n",
       "      <td>euphoric</td>\n",
       "      <td>5.072128e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>337</th>\n",
       "      <td>tfidf_337</td>\n",
       "      <td>5.062409e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>205</th>\n",
       "      <td>tfidf_205</td>\n",
       "      <td>4.870453e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>330</th>\n",
       "      <td>tfidf_330</td>\n",
       "      <td>4.674633e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>253</th>\n",
       "      <td>tfidf_253</td>\n",
       "      <td>4.552060e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>424</th>\n",
       "      <td>berry</td>\n",
       "      <td>4.549895e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>203</th>\n",
       "      <td>tfidf_203</td>\n",
       "      <td>4.192273e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>173</th>\n",
       "      <td>tfidf_173</td>\n",
       "      <td>4.164018e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>315</th>\n",
       "      <td>tfidf_315</td>\n",
       "      <td>4.072965e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>413</th>\n",
       "      <td>relaxed</td>\n",
       "      <td>4.039186e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>119</th>\n",
       "      <td>tfidf_119</td>\n",
       "      <td>4.037583e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>309</th>\n",
       "      <td>tfidf_309</td>\n",
       "      <td>4.005215e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>tfidf_43</td>\n",
       "      <td>3.908259e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>tfidf_30</td>\n",
       "      <td>3.906035e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>407</th>\n",
       "      <td>happy</td>\n",
       "      <td>3.854115e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>357</th>\n",
       "      <td>tfidf_357</td>\n",
       "      <td>3.801129e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>tfidf_33</td>\n",
       "      <td>3.753795e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>138</th>\n",
       "      <td>tfidf_138</td>\n",
       "      <td>3.712162e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>239</th>\n",
       "      <td>tfidf_239</td>\n",
       "      <td>3.642839e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>199</th>\n",
       "      <td>tfidf_199</td>\n",
       "      <td>3.638495e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>349</th>\n",
       "      <td>tfidf_349</td>\n",
       "      <td>3.612917e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>207</th>\n",
       "      <td>tfidf_207</td>\n",
       "      <td>3.423377e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>441</th>\n",
       "      <td>lemon</td>\n",
       "      <td>3.335557e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>190</th>\n",
       "      <td>tfidf_190</td>\n",
       "      <td>3.323687e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>362</th>\n",
       "      <td>tfidf_362</td>\n",
       "      <td>3.309782e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>389</th>\n",
       "      <td>indica</td>\n",
       "      <td>3.016159e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>340</th>\n",
       "      <td>tfidf_340</td>\n",
       "      <td>2.999856e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>103</th>\n",
       "      <td>tfidf_103</td>\n",
       "      <td>2.936020e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>101</th>\n",
       "      <td>tfidf_101</td>\n",
       "      <td>2.935644e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>202</th>\n",
       "      <td>tfidf_202</td>\n",
       "      <td>2.918039e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>466</th>\n",
       "      <td>vanilla</td>\n",
       "      <td>2.913871e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>232</th>\n",
       "      <td>tfidf_232</td>\n",
       "      <td>2.913621e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>tfidf_95</td>\n",
       "      <td>2.862881e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>395</th>\n",
       "      <td>creative</td>\n",
       "      <td>2.855434e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>223</th>\n",
       "      <td>tfidf_223</td>\n",
       "      <td>2.829542e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>65</th>\n",
       "      <td>tfidf_65</td>\n",
       "      <td>2.811714e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>78</th>\n",
       "      <td>tfidf_78</td>\n",
       "      <td>2.786495e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>tfidf_5</td>\n",
       "      <td>2.707919e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>tfidf_21</td>\n",
       "      <td>2.703272e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>117</th>\n",
       "      <td>tfidf_117</td>\n",
       "      <td>2.680608e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>231</th>\n",
       "      <td>tfidf_231</td>\n",
       "      <td>2.661123e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54</th>\n",
       "      <td>tfidf_54</td>\n",
       "      <td>2.637954e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>301</th>\n",
       "      <td>tfidf_301</td>\n",
       "      <td>2.533977e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>291</th>\n",
       "      <td>tfidf_291</td>\n",
       "      <td>2.488134e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>431</th>\n",
       "      <td>citrus</td>\n",
       "      <td>2.472213e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>303</th>\n",
       "      <td>tfidf_303</td>\n",
       "      <td>2.454677e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>178</th>\n",
       "      <td>tfidf_178</td>\n",
       "      <td>2.434587e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>338</th>\n",
       "      <td>tfidf_338</td>\n",
       "      <td>2.429305e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>tfidf_11</td>\n",
       "      <td>2.424142e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>360</th>\n",
       "      <td>tfidf_360</td>\n",
       "      <td>2.355721e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>454</th>\n",
       "      <td>pungent</td>\n",
       "      <td>2.340613e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52</th>\n",
       "      <td>tfidf_52</td>\n",
       "      <td>2.329086e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>399</th>\n",
       "      <td>dry mouth</td>\n",
       "      <td>2.286115e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>93</th>\n",
       "      <td>tfidf_93</td>\n",
       "      <td>2.107525e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>283</th>\n",
       "      <td>tfidf_283</td>\n",
       "      <td>2.100209e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>tfidf_37</td>\n",
       "      <td>2.048138e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>tfidf_6</td>\n",
       "      <td>2.034516e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>73</th>\n",
       "      <td>tfidf_73</td>\n",
       "      <td>2.005938e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>87</th>\n",
       "      <td>tfidf_87</td>\n",
       "      <td>1.995072e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>281</th>\n",
       "      <td>tfidf_281</td>\n",
       "      <td>1.929938e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>251</th>\n",
       "      <td>tfidf_251</td>\n",
       "      <td>1.870774e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>90</th>\n",
       "      <td>tfidf_90</td>\n",
       "      <td>1.865312e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>318</th>\n",
       "      <td>tfidf_318</td>\n",
       "      <td>1.861896e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>244</th>\n",
       "      <td>tfidf_244</td>\n",
       "      <td>1.852955e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>128</th>\n",
       "      <td>tfidf_128</td>\n",
       "      <td>1.844929e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>167</th>\n",
       "      <td>tfidf_167</td>\n",
       "      <td>1.803383e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>tfidf_32</td>\n",
       "      <td>1.772028e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>tfidf_7</td>\n",
       "      <td>1.765835e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>420</th>\n",
       "      <td>uplifted</td>\n",
       "      <td>1.755345e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>434</th>\n",
       "      <td>earthy</td>\n",
       "      <td>1.718987e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>409</th>\n",
       "      <td>hungry</td>\n",
       "      <td>1.690508e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>319</th>\n",
       "      <td>tfidf_319</td>\n",
       "      <td>1.685791e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>122</th>\n",
       "      <td>tfidf_122</td>\n",
       "      <td>1.667154e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>198</th>\n",
       "      <td>tfidf_198</td>\n",
       "      <td>1.660063e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>158</th>\n",
       "      <td>tfidf_158</td>\n",
       "      <td>1.654189e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>162</th>\n",
       "      <td>tfidf_162</td>\n",
       "      <td>1.630972e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>437</th>\n",
       "      <td>grape</td>\n",
       "      <td>1.606232e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>267</th>\n",
       "      <td>tfidf_267</td>\n",
       "      <td>1.567699e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>415</th>\n",
       "      <td>sleepy</td>\n",
       "      <td>1.555428e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>336</th>\n",
       "      <td>tfidf_336</td>\n",
       "      <td>1.528185e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>85</th>\n",
       "      <td>tfidf_85</td>\n",
       "      <td>1.526404e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>408</th>\n",
       "      <td>headache</td>\n",
       "      <td>1.520017e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>166</th>\n",
       "      <td>tfidf_166</td>\n",
       "      <td>1.489786e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>195</th>\n",
       "      <td>tfidf_195</td>\n",
       "      <td>1.483590e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>123</th>\n",
       "      <td>tfidf_123</td>\n",
       "      <td>1.482286e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>126</th>\n",
       "      <td>tfidf_126</td>\n",
       "      <td>1.477110e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>400</th>\n",
       "      <td>energetic</td>\n",
       "      <td>1.461751e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>385</th>\n",
       "      <td>tfidf_385</td>\n",
       "      <td>1.453469e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>61</th>\n",
       "      <td>tfidf_61</td>\n",
       "      <td>1.453361e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>406</th>\n",
       "      <td>giggly</td>\n",
       "      <td>1.433448e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>144</th>\n",
       "      <td>tfidf_144</td>\n",
       "      <td>1.428128e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>366</th>\n",
       "      <td>tfidf_366</td>\n",
       "      <td>1.425472e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>418</th>\n",
       "      <td>talkative</td>\n",
       "      <td>1.413764e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>405</th>\n",
       "      <td>focused</td>\n",
       "      <td>1.389677e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>151</th>\n",
       "      <td>tfidf_151</td>\n",
       "      <td>1.347449e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>115</th>\n",
       "      <td>tfidf_115</td>\n",
       "      <td>1.345305e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>302</th>\n",
       "      <td>tfidf_302</td>\n",
       "      <td>1.332208e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>457</th>\n",
       "      <td>skunk</td>\n",
       "      <td>1.313247e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>221</th>\n",
       "      <td>tfidf_221</td>\n",
       "      <td>1.308325e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>374</th>\n",
       "      <td>tfidf_374</td>\n",
       "      <td>1.293091e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>240</th>\n",
       "      <td>tfidf_240</td>\n",
       "      <td>1.290895e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>tfidf_41</td>\n",
       "      <td>1.288500e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>tfidf_99</td>\n",
       "      <td>1.266492e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>163</th>\n",
       "      <td>tfidf_163</td>\n",
       "      <td>1.244366e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>342</th>\n",
       "      <td>tfidf_342</td>\n",
       "      <td>1.232693e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>137</th>\n",
       "      <td>tfidf_137</td>\n",
       "      <td>1.220866e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>217</th>\n",
       "      <td>tfidf_217</td>\n",
       "      <td>1.219929e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>146</th>\n",
       "      <td>tfidf_146</td>\n",
       "      <td>1.192351e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>314</th>\n",
       "      <td>tfidf_314</td>\n",
       "      <td>1.186646e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>130</th>\n",
       "      <td>tfidf_130</td>\n",
       "      <td>1.184479e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>tfidf_26</td>\n",
       "      <td>1.166852e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>208</th>\n",
       "      <td>tfidf_208</td>\n",
       "      <td>1.161928e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>438</th>\n",
       "      <td>grapefruit</td>\n",
       "      <td>1.160755e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>230</th>\n",
       "      <td>tfidf_230</td>\n",
       "      <td>1.153146e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>295</th>\n",
       "      <td>tfidf_295</td>\n",
       "      <td>1.149040e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>tfidf_16</td>\n",
       "      <td>1.131110e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>419</th>\n",
       "      <td>tingly</td>\n",
       "      <td>1.123353e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>tfidf_14</td>\n",
       "      <td>1.120571e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>376</th>\n",
       "      <td>tfidf_376</td>\n",
       "      <td>1.111390e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>189</th>\n",
       "      <td>tfidf_189</td>\n",
       "      <td>1.110579e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>343</th>\n",
       "      <td>tfidf_343</td>\n",
       "      <td>1.091851e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>192</th>\n",
       "      <td>tfidf_192</td>\n",
       "      <td>1.086318e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>109</th>\n",
       "      <td>tfidf_109</td>\n",
       "      <td>1.077039e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>200</th>\n",
       "      <td>tfidf_200</td>\n",
       "      <td>1.064439e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>258</th>\n",
       "      <td>tfidf_258</td>\n",
       "      <td>1.047828e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>304</th>\n",
       "      <td>tfidf_304</td>\n",
       "      <td>1.039731e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>tfidf_31</td>\n",
       "      <td>1.033251e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>320</th>\n",
       "      <td>tfidf_320</td>\n",
       "      <td>1.031511e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>237</th>\n",
       "      <td>tfidf_237</td>\n",
       "      <td>1.000316e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>264</th>\n",
       "      <td>tfidf_264</td>\n",
       "      <td>9.980630e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>105</th>\n",
       "      <td>tfidf_105</td>\n",
       "      <td>9.908330e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>325</th>\n",
       "      <td>tfidf_325</td>\n",
       "      <td>9.735032e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>177</th>\n",
       "      <td>tfidf_177</td>\n",
       "      <td>9.716212e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>326</th>\n",
       "      <td>tfidf_326</td>\n",
       "      <td>9.620583e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>188</th>\n",
       "      <td>tfidf_188</td>\n",
       "      <td>9.597369e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>384</th>\n",
       "      <td>tfidf_384</td>\n",
       "      <td>9.561730e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>268</th>\n",
       "      <td>tfidf_268</td>\n",
       "      <td>9.530318e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>451</th>\n",
       "      <td>pine</td>\n",
       "      <td>9.453932e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>215</th>\n",
       "      <td>tfidf_215</td>\n",
       "      <td>9.361784e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>398</th>\n",
       "      <td>dry eyes</td>\n",
       "      <td>9.264566e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>355</th>\n",
       "      <td>tfidf_355</td>\n",
       "      <td>9.231794e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>387</th>\n",
       "      <td>tfidf_387</td>\n",
       "      <td>9.158201e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>368</th>\n",
       "      <td>tfidf_368</td>\n",
       "      <td>9.095436e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>104</th>\n",
       "      <td>tfidf_104</td>\n",
       "      <td>9.047594e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>380</th>\n",
       "      <td>tfidf_380</td>\n",
       "      <td>9.014705e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>69</th>\n",
       "      <td>tfidf_69</td>\n",
       "      <td>9.002247e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>tfidf_34</td>\n",
       "      <td>8.981405e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>288</th>\n",
       "      <td>tfidf_288</td>\n",
       "      <td>8.844757e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>371</th>\n",
       "      <td>tfidf_371</td>\n",
       "      <td>8.735883e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>354</th>\n",
       "      <td>tfidf_354</td>\n",
       "      <td>8.707108e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>153</th>\n",
       "      <td>tfidf_153</td>\n",
       "      <td>8.594209e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>64</th>\n",
       "      <td>tfidf_64</td>\n",
       "      <td>8.586201e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>234</th>\n",
       "      <td>tfidf_234</td>\n",
       "      <td>8.530635e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>124</th>\n",
       "      <td>tfidf_124</td>\n",
       "      <td>8.506436e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>108</th>\n",
       "      <td>tfidf_108</td>\n",
       "      <td>8.504343e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>79</th>\n",
       "      <td>tfidf_79</td>\n",
       "      <td>8.461867e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>271</th>\n",
       "      <td>tfidf_271</td>\n",
       "      <td>8.458277e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>382</th>\n",
       "      <td>tfidf_382</td>\n",
       "      <td>8.454220e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>tfidf_1</td>\n",
       "      <td>8.305319e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>71</th>\n",
       "      <td>tfidf_71</td>\n",
       "      <td>8.227150e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>206</th>\n",
       "      <td>tfidf_206</td>\n",
       "      <td>8.196533e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>383</th>\n",
       "      <td>tfidf_383</td>\n",
       "      <td>8.180271e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>381</th>\n",
       "      <td>tfidf_381</td>\n",
       "      <td>8.178898e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>175</th>\n",
       "      <td>tfidf_175</td>\n",
       "      <td>8.149570e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>tfidf_29</td>\n",
       "      <td>8.144172e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>107</th>\n",
       "      <td>tfidf_107</td>\n",
       "      <td>8.081241e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>260</th>\n",
       "      <td>tfidf_260</td>\n",
       "      <td>8.062974e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>tfidf_20</td>\n",
       "      <td>7.892310e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>tfidf_98</td>\n",
       "      <td>7.846661e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>211</th>\n",
       "      <td>tfidf_211</td>\n",
       "      <td>7.805542e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>468</th>\n",
       "      <td>woody</td>\n",
       "      <td>7.803266e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>278</th>\n",
       "      <td>tfidf_278</td>\n",
       "      <td>7.798244e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>tfidf_48</td>\n",
       "      <td>7.785660e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>280</th>\n",
       "      <td>tfidf_280</td>\n",
       "      <td>7.776626e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>367</th>\n",
       "      <td>tfidf_367</td>\n",
       "      <td>7.718974e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>236</th>\n",
       "      <td>tfidf_236</td>\n",
       "      <td>7.692364e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>286</th>\n",
       "      <td>tfidf_286</td>\n",
       "      <td>7.564831e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>tfidf_28</td>\n",
       "      <td>7.557890e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>154</th>\n",
       "      <td>tfidf_154</td>\n",
       "      <td>7.546234e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>112</th>\n",
       "      <td>tfidf_112</td>\n",
       "      <td>7.471522e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>159</th>\n",
       "      <td>tfidf_159</td>\n",
       "      <td>7.394243e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>393</th>\n",
       "      <td>aroused</td>\n",
       "      <td>7.118466e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>272</th>\n",
       "      <td>tfidf_272</td>\n",
       "      <td>7.039561e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>125</th>\n",
       "      <td>tfidf_125</td>\n",
       "      <td>6.979331e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>432</th>\n",
       "      <td>coffee</td>\n",
       "      <td>6.975864e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>83</th>\n",
       "      <td>tfidf_83</td>\n",
       "      <td>6.938881e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>263</th>\n",
       "      <td>tfidf_263</td>\n",
       "      <td>6.931974e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>229</th>\n",
       "      <td>tfidf_229</td>\n",
       "      <td>6.869054e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>196</th>\n",
       "      <td>tfidf_196</td>\n",
       "      <td>6.860331e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>127</th>\n",
       "      <td>tfidf_127</td>\n",
       "      <td>6.821678e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>tfidf_49</td>\n",
       "      <td>6.766905e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>317</th>\n",
       "      <td>tfidf_317</td>\n",
       "      <td>6.765429e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>347</th>\n",
       "      <td>tfidf_347</td>\n",
       "      <td>6.746937e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>341</th>\n",
       "      <td>tfidf_341</td>\n",
       "      <td>6.739921e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>86</th>\n",
       "      <td>tfidf_86</td>\n",
       "      <td>6.739125e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>161</th>\n",
       "      <td>tfidf_161</td>\n",
       "      <td>6.707111e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>273</th>\n",
       "      <td>tfidf_273</td>\n",
       "      <td>6.681037e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>184</th>\n",
       "      <td>tfidf_184</td>\n",
       "      <td>6.641564e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>tfidf_46</td>\n",
       "      <td>6.617695e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>tfidf_22</td>\n",
       "      <td>6.611326e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>297</th>\n",
       "      <td>tfidf_297</td>\n",
       "      <td>6.606849e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>439</th>\n",
       "      <td>honey</td>\n",
       "      <td>6.531043e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>tfidf_39</td>\n",
       "      <td>6.466089e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>305</th>\n",
       "      <td>tfidf_305</td>\n",
       "      <td>6.462749e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>212</th>\n",
       "      <td>tfidf_212</td>\n",
       "      <td>6.402829e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>68</th>\n",
       "      <td>tfidf_68</td>\n",
       "      <td>6.275887e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>270</th>\n",
       "      <td>tfidf_270</td>\n",
       "      <td>6.243213e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>363</th>\n",
       "      <td>tfidf_363</td>\n",
       "      <td>6.230410e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>311</th>\n",
       "      <td>tfidf_311</td>\n",
       "      <td>6.219404e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>tfidf_24</td>\n",
       "      <td>6.180012e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>197</th>\n",
       "      <td>tfidf_197</td>\n",
       "      <td>6.146176e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50</th>\n",
       "      <td>tfidf_50</td>\n",
       "      <td>6.132136e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>375</th>\n",
       "      <td>tfidf_375</td>\n",
       "      <td>6.107338e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>353</th>\n",
       "      <td>tfidf_353</td>\n",
       "      <td>5.954880e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>60</th>\n",
       "      <td>tfidf_60</td>\n",
       "      <td>5.945082e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>tfidf_47</td>\n",
       "      <td>5.929158e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>436</th>\n",
       "      <td>fruit</td>\n",
       "      <td>5.928349e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>370</th>\n",
       "      <td>tfidf_370</td>\n",
       "      <td>5.900633e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>397</th>\n",
       "      <td>dizzy</td>\n",
       "      <td>5.868205e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>58</th>\n",
       "      <td>tfidf_58</td>\n",
       "      <td>5.861067e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>373</th>\n",
       "      <td>tfidf_373</td>\n",
       "      <td>5.724822e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>364</th>\n",
       "      <td>tfidf_364</td>\n",
       "      <td>5.688229e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>tfidf_9</td>\n",
       "      <td>5.680123e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>56</th>\n",
       "      <td>tfidf_56</td>\n",
       "      <td>5.653914e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>333</th>\n",
       "      <td>tfidf_333</td>\n",
       "      <td>5.652950e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>369</th>\n",
       "      <td>tfidf_369</td>\n",
       "      <td>5.590915e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>tfidf_19</td>\n",
       "      <td>5.531443e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>186</th>\n",
       "      <td>tfidf_186</td>\n",
       "      <td>5.454842e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>265</th>\n",
       "      <td>tfidf_265</td>\n",
       "      <td>5.437647e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>164</th>\n",
       "      <td>tfidf_164</td>\n",
       "      <td>5.416938e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>116</th>\n",
       "      <td>tfidf_116</td>\n",
       "      <td>5.375035e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>427</th>\n",
       "      <td>butter</td>\n",
       "      <td>5.363323e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>435</th>\n",
       "      <td>flowery</td>\n",
       "      <td>5.360492e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>308</th>\n",
       "      <td>tfidf_308</td>\n",
       "      <td>5.304210e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>tfidf_97</td>\n",
       "      <td>5.246720e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>254</th>\n",
       "      <td>tfidf_254</td>\n",
       "      <td>5.245633e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>219</th>\n",
       "      <td>tfidf_219</td>\n",
       "      <td>5.139370e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>136</th>\n",
       "      <td>tfidf_136</td>\n",
       "      <td>5.131358e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59</th>\n",
       "      <td>tfidf_59</td>\n",
       "      <td>5.104213e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>187</th>\n",
       "      <td>tfidf_187</td>\n",
       "      <td>5.088770e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>348</th>\n",
       "      <td>tfidf_348</td>\n",
       "      <td>5.086031e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>172</th>\n",
       "      <td>tfidf_172</td>\n",
       "      <td>5.043720e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>113</th>\n",
       "      <td>tfidf_113</td>\n",
       "      <td>4.925888e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>150</th>\n",
       "      <td>tfidf_150</td>\n",
       "      <td>4.865851e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>tfidf_4</td>\n",
       "      <td>4.831639e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>276</th>\n",
       "      <td>tfidf_276</td>\n",
       "      <td>4.786791e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>307</th>\n",
       "      <td>tfidf_307</td>\n",
       "      <td>4.674358e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>76</th>\n",
       "      <td>tfidf_76</td>\n",
       "      <td>4.635727e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>282</th>\n",
       "      <td>tfidf_282</td>\n",
       "      <td>4.568241e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>227</th>\n",
       "      <td>tfidf_227</td>\n",
       "      <td>4.567851e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>321</th>\n",
       "      <td>tfidf_321</td>\n",
       "      <td>4.550421e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>446</th>\n",
       "      <td>nutty</td>\n",
       "      <td>4.538357e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>351</th>\n",
       "      <td>tfidf_351</td>\n",
       "      <td>4.508653e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>118</th>\n",
       "      <td>tfidf_118</td>\n",
       "      <td>4.501981e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>292</th>\n",
       "      <td>tfidf_292</td>\n",
       "      <td>4.492035e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>194</th>\n",
       "      <td>tfidf_194</td>\n",
       "      <td>4.445822e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>455</th>\n",
       "      <td>rose</td>\n",
       "      <td>4.419788e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>91</th>\n",
       "      <td>tfidf_91</td>\n",
       "      <td>4.391064e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>tfidf_17</td>\n",
       "      <td>4.369893e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>392</th>\n",
       "      <td>anxious</td>\n",
       "      <td>4.332349e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>82</th>\n",
       "      <td>tfidf_82</td>\n",
       "      <td>4.320625e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>250</th>\n",
       "      <td>tfidf_250</td>\n",
       "      <td>4.279766e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>tfidf_45</td>\n",
       "      <td>4.243061e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>255</th>\n",
       "      <td>tfidf_255</td>\n",
       "      <td>4.231621e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>220</th>\n",
       "      <td>tfidf_220</td>\n",
       "      <td>4.221496e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>313</th>\n",
       "      <td>tfidf_313</td>\n",
       "      <td>4.177530e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>359</th>\n",
       "      <td>tfidf_359</td>\n",
       "      <td>4.165381e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>328</th>\n",
       "      <td>tfidf_328</td>\n",
       "      <td>4.135634e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>tfidf_96</td>\n",
       "      <td>4.095584e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>180</th>\n",
       "      <td>tfidf_180</td>\n",
       "      <td>4.050581e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>183</th>\n",
       "      <td>tfidf_183</td>\n",
       "      <td>4.023290e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>465</th>\n",
       "      <td>tropical</td>\n",
       "      <td>4.022909e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>241</th>\n",
       "      <td>tfidf_241</td>\n",
       "      <td>3.938648e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>92</th>\n",
       "      <td>tfidf_92</td>\n",
       "      <td>3.937292e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>tfidf_40</td>\n",
       "      <td>3.930058e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>300</th>\n",
       "      <td>tfidf_300</td>\n",
       "      <td>3.907921e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>243</th>\n",
       "      <td>tfidf_243</td>\n",
       "      <td>3.857038e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>247</th>\n",
       "      <td>tfidf_247</td>\n",
       "      <td>3.855747e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>tfidf_27</td>\n",
       "      <td>3.834167e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>111</th>\n",
       "      <td>tfidf_111</td>\n",
       "      <td>3.799369e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>tfidf_25</td>\n",
       "      <td>3.777404e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>456</th>\n",
       "      <td>sage</td>\n",
       "      <td>3.721953e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>193</th>\n",
       "      <td>tfidf_193</td>\n",
       "      <td>3.656207e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>102</th>\n",
       "      <td>tfidf_102</td>\n",
       "      <td>3.644689e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>310</th>\n",
       "      <td>tfidf_310</td>\n",
       "      <td>3.640985e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>352</th>\n",
       "      <td>tfidf_352</td>\n",
       "      <td>3.635390e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>62</th>\n",
       "      <td>tfidf_62</td>\n",
       "      <td>3.614020e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>322</th>\n",
       "      <td>tfidf_322</td>\n",
       "      <td>3.594731e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>139</th>\n",
       "      <td>tfidf_139</td>\n",
       "      <td>3.567169e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>327</th>\n",
       "      <td>tfidf_327</td>\n",
       "      <td>3.556886e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>386</th>\n",
       "      <td>tfidf_386</td>\n",
       "      <td>3.547471e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>464</th>\n",
       "      <td>tree</td>\n",
       "      <td>3.546103e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>171</th>\n",
       "      <td>tfidf_171</td>\n",
       "      <td>3.524737e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>179</th>\n",
       "      <td>tfidf_179</td>\n",
       "      <td>3.515433e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>458</th>\n",
       "      <td>spicy/herbal</td>\n",
       "      <td>3.500262e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>289</th>\n",
       "      <td>tfidf_289</td>\n",
       "      <td>3.468727e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>257</th>\n",
       "      <td>tfidf_257</td>\n",
       "      <td>3.441463e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>165</th>\n",
       "      <td>tfidf_165</td>\n",
       "      <td>3.378861e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>365</th>\n",
       "      <td>tfidf_365</td>\n",
       "      <td>3.373348e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75</th>\n",
       "      <td>tfidf_75</td>\n",
       "      <td>3.371278e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>169</th>\n",
       "      <td>tfidf_169</td>\n",
       "      <td>3.362328e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>182</th>\n",
       "      <td>tfidf_182</td>\n",
       "      <td>3.345227e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>tfidf_23</td>\n",
       "      <td>3.336214e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>412</th>\n",
       "      <td>paranoid</td>\n",
       "      <td>3.328728e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>246</th>\n",
       "      <td>tfidf_246</td>\n",
       "      <td>3.320613e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>358</th>\n",
       "      <td>tfidf_358</td>\n",
       "      <td>3.315527e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>344</th>\n",
       "      <td>tfidf_344</td>\n",
       "      <td>3.294648e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>181</th>\n",
       "      <td>tfidf_181</td>\n",
       "      <td>3.290229e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>tfidf_0</td>\n",
       "      <td>3.283774e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>224</th>\n",
       "      <td>tfidf_224</td>\n",
       "      <td>3.256456e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>88</th>\n",
       "      <td>tfidf_88</td>\n",
       "      <td>3.254900e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>228</th>\n",
       "      <td>tfidf_228</td>\n",
       "      <td>3.243724e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>57</th>\n",
       "      <td>tfidf_57</td>\n",
       "      <td>3.240134e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>106</th>\n",
       "      <td>tfidf_106</td>\n",
       "      <td>3.128156e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>218</th>\n",
       "      <td>tfidf_218</td>\n",
       "      <td>3.121842e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>tfidf_2</td>\n",
       "      <td>3.113212e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>67</th>\n",
       "      <td>tfidf_67</td>\n",
       "      <td>3.102735e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>147</th>\n",
       "      <td>tfidf_147</td>\n",
       "      <td>3.101101e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>216</th>\n",
       "      <td>tfidf_216</td>\n",
       "      <td>3.050459e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>tfidf_3</td>\n",
       "      <td>2.999653e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>277</th>\n",
       "      <td>tfidf_277</td>\n",
       "      <td>2.995225e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>238</th>\n",
       "      <td>tfidf_238</td>\n",
       "      <td>2.913955e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>293</th>\n",
       "      <td>tfidf_293</td>\n",
       "      <td>2.894216e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>143</th>\n",
       "      <td>tfidf_143</td>\n",
       "      <td>2.889797e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>249</th>\n",
       "      <td>tfidf_249</td>\n",
       "      <td>2.868722e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>114</th>\n",
       "      <td>tfidf_114</td>\n",
       "      <td>2.850475e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>259</th>\n",
       "      <td>tfidf_259</td>\n",
       "      <td>2.821020e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>176</th>\n",
       "      <td>tfidf_176</td>\n",
       "      <td>2.804887e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>110</th>\n",
       "      <td>tfidf_110</td>\n",
       "      <td>2.789640e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>185</th>\n",
       "      <td>tfidf_185</td>\n",
       "      <td>2.765062e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51</th>\n",
       "      <td>tfidf_51</td>\n",
       "      <td>2.748652e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>296</th>\n",
       "      <td>tfidf_296</td>\n",
       "      <td>2.747735e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>tfidf_10</td>\n",
       "      <td>2.747466e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>372</th>\n",
       "      <td>tfidf_372</td>\n",
       "      <td>2.746597e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>152</th>\n",
       "      <td>tfidf_152</td>\n",
       "      <td>2.728005e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>148</th>\n",
       "      <td>tfidf_148</td>\n",
       "      <td>2.664427e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>262</th>\n",
       "      <td>tfidf_262</td>\n",
       "      <td>2.662233e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>94</th>\n",
       "      <td>tfidf_94</td>\n",
       "      <td>2.662005e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>346</th>\n",
       "      <td>tfidf_346</td>\n",
       "      <td>2.654200e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>225</th>\n",
       "      <td>tfidf_225</td>\n",
       "      <td>2.626939e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>298</th>\n",
       "      <td>tfidf_298</td>\n",
       "      <td>2.620962e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>442</th>\n",
       "      <td>lime</td>\n",
       "      <td>2.550356e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>332</th>\n",
       "      <td>tfidf_332</td>\n",
       "      <td>2.513173e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>443</th>\n",
       "      <td>mango</td>\n",
       "      <td>2.501613e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>77</th>\n",
       "      <td>tfidf_77</td>\n",
       "      <td>2.486558e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>201</th>\n",
       "      <td>tfidf_201</td>\n",
       "      <td>2.364522e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>214</th>\n",
       "      <td>tfidf_214</td>\n",
       "      <td>2.353608e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>191</th>\n",
       "      <td>tfidf_191</td>\n",
       "      <td>2.344959e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>160</th>\n",
       "      <td>tfidf_160</td>\n",
       "      <td>2.287046e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>174</th>\n",
       "      <td>tfidf_174</td>\n",
       "      <td>2.261068e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>63</th>\n",
       "      <td>tfidf_63</td>\n",
       "      <td>2.257944e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>155</th>\n",
       "      <td>tfidf_155</td>\n",
       "      <td>2.253377e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>290</th>\n",
       "      <td>tfidf_290</td>\n",
       "      <td>2.218030e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53</th>\n",
       "      <td>tfidf_53</td>\n",
       "      <td>2.197874e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>261</th>\n",
       "      <td>tfidf_261</td>\n",
       "      <td>2.195105e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>157</th>\n",
       "      <td>tfidf_157</td>\n",
       "      <td>2.188000e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>55</th>\n",
       "      <td>tfidf_55</td>\n",
       "      <td>2.182971e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>440</th>\n",
       "      <td>lavender</td>\n",
       "      <td>2.171727e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>140</th>\n",
       "      <td>tfidf_140</td>\n",
       "      <td>2.154222e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>429</th>\n",
       "      <td>chemical</td>\n",
       "      <td>2.143187e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>287</th>\n",
       "      <td>tfidf_287</td>\n",
       "      <td>2.086296e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>324</th>\n",
       "      <td>tfidf_324</td>\n",
       "      <td>2.054496e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>209</th>\n",
       "      <td>tfidf_209</td>\n",
       "      <td>2.050636e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>213</th>\n",
       "      <td>tfidf_213</td>\n",
       "      <td>2.042226e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>142</th>\n",
       "      <td>tfidf_142</td>\n",
       "      <td>2.032643e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>450</th>\n",
       "      <td>pepper</td>\n",
       "      <td>2.017082e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>306</th>\n",
       "      <td>tfidf_306</td>\n",
       "      <td>2.010434e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>235</th>\n",
       "      <td>tfidf_235</td>\n",
       "      <td>2.009014e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>279</th>\n",
       "      <td>tfidf_279</td>\n",
       "      <td>2.006691e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>323</th>\n",
       "      <td>tfidf_323</td>\n",
       "      <td>1.962518e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>226</th>\n",
       "      <td>tfidf_226</td>\n",
       "      <td>1.949689e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>361</th>\n",
       "      <td>tfidf_361</td>\n",
       "      <td>1.892241e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>335</th>\n",
       "      <td>tfidf_335</td>\n",
       "      <td>1.889888e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>242</th>\n",
       "      <td>tfidf_242</td>\n",
       "      <td>1.858170e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>tfidf_18</td>\n",
       "      <td>1.840981e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>tfidf_12</td>\n",
       "      <td>1.817584e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>70</th>\n",
       "      <td>tfidf_70</td>\n",
       "      <td>1.787939e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>356</th>\n",
       "      <td>tfidf_356</td>\n",
       "      <td>1.737503e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>274</th>\n",
       "      <td>tfidf_274</td>\n",
       "      <td>1.711499e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>459</th>\n",
       "      <td>strawberry</td>\n",
       "      <td>1.686110e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>334</th>\n",
       "      <td>tfidf_334</td>\n",
       "      <td>1.682726e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>tfidf_44</td>\n",
       "      <td>1.643187e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>156</th>\n",
       "      <td>tfidf_156</td>\n",
       "      <td>1.614775e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>tfidf_15</td>\n",
       "      <td>1.593169e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>256</th>\n",
       "      <td>tfidf_256</td>\n",
       "      <td>1.588096e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>tfidf_13</td>\n",
       "      <td>1.515404e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>339</th>\n",
       "      <td>tfidf_339</td>\n",
       "      <td>1.501631e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>100</th>\n",
       "      <td>tfidf_100</td>\n",
       "      <td>1.464863e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>84</th>\n",
       "      <td>tfidf_84</td>\n",
       "      <td>1.462821e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>132</th>\n",
       "      <td>tfidf_132</td>\n",
       "      <td>1.391200e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>284</th>\n",
       "      <td>tfidf_284</td>\n",
       "      <td>1.374366e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>378</th>\n",
       "      <td>tfidf_378</td>\n",
       "      <td>1.359147e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>269</th>\n",
       "      <td>tfidf_269</td>\n",
       "      <td>1.354850e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>275</th>\n",
       "      <td>tfidf_275</td>\n",
       "      <td>1.337967e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>133</th>\n",
       "      <td>tfidf_133</td>\n",
       "      <td>1.292964e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>377</th>\n",
       "      <td>tfidf_377</td>\n",
       "      <td>1.292381e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>tfidf_38</td>\n",
       "      <td>1.246951e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>204</th>\n",
       "      <td>tfidf_204</td>\n",
       "      <td>1.138678e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>448</th>\n",
       "      <td>peach</td>\n",
       "      <td>1.071714e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>462</th>\n",
       "      <td>tea</td>\n",
       "      <td>1.068381e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>331</th>\n",
       "      <td>tfidf_331</td>\n",
       "      <td>1.061359e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>421</th>\n",
       "      <td>ammonia</td>\n",
       "      <td>1.056667e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>tfidf_35</td>\n",
       "      <td>1.028739e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>233</th>\n",
       "      <td>tfidf_233</td>\n",
       "      <td>1.026145e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>252</th>\n",
       "      <td>tfidf_252</td>\n",
       "      <td>9.891820e-05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>379</th>\n",
       "      <td>tfidf_379</td>\n",
       "      <td>9.457903e-05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>89</th>\n",
       "      <td>tfidf_89</td>\n",
       "      <td>8.886585e-05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>425</th>\n",
       "      <td>blue cheese</td>\n",
       "      <td>8.342183e-05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>248</th>\n",
       "      <td>tfidf_248</td>\n",
       "      <td>8.159075e-05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>131</th>\n",
       "      <td>tfidf_131</td>\n",
       "      <td>7.595305e-05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>tfidf_36</td>\n",
       "      <td>7.580688e-05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>tfidf_42</td>\n",
       "      <td>7.120799e-05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>74</th>\n",
       "      <td>tfidf_74</td>\n",
       "      <td>6.408712e-05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>430</th>\n",
       "      <td>chestnut</td>\n",
       "      <td>6.322949e-05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>tfidf_8</td>\n",
       "      <td>6.062427e-05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>134</th>\n",
       "      <td>tfidf_134</td>\n",
       "      <td>5.942542e-05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>453</th>\n",
       "      <td>plum</td>\n",
       "      <td>5.911961e-05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>452</th>\n",
       "      <td>pineapple</td>\n",
       "      <td>5.678713e-05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>266</th>\n",
       "      <td>tfidf_266</td>\n",
       "      <td>5.395248e-05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>449</th>\n",
       "      <td>pear</td>\n",
       "      <td>3.707643e-05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>410</th>\n",
       "      <td>migraines</td>\n",
       "      <td>2.861895e-05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>444</th>\n",
       "      <td>menthol</td>\n",
       "      <td>2.654275e-05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>463</th>\n",
       "      <td>tobacco</td>\n",
       "      <td>2.623261e-05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>391</th>\n",
       "      <td>anxiety</td>\n",
       "      <td>2.521689e-05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>396</th>\n",
       "      <td>depression</td>\n",
       "      <td>2.073062e-05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>423</th>\n",
       "      <td>apricot</td>\n",
       "      <td>1.747381e-05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>461</th>\n",
       "      <td>tar</td>\n",
       "      <td>1.669090e-05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>467</th>\n",
       "      <td>violet</td>\n",
       "      <td>1.573898e-05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>417</th>\n",
       "      <td>stress</td>\n",
       "      <td>3.280260e-08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>414</th>\n",
       "      <td>seizures</td>\n",
       "      <td>4.374765e-09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>401</th>\n",
       "      <td>epilepsy</td>\n",
       "      <td>2.341016e-09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>404</th>\n",
       "      <td>fatigue</td>\n",
       "      <td>2.264651e-09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>394</th>\n",
       "      <td>arthritis</td>\n",
       "      <td>1.468414e-09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>411</th>\n",
       "      <td>pain</td>\n",
       "      <td>6.642752e-10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>416</th>\n",
       "      <td>spasticity</td>\n",
       "      <td>0.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>403</th>\n",
       "      <td>eye pressure</td>\n",
       "      <td>0.000000e+00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         features         score\n",
       "428        cheese  2.347916e-01\n",
       "390        sativa  4.798605e-02\n",
       "426     blueberry  2.176872e-02\n",
       "388        hybrid  2.125812e-02\n",
       "433        diesel  1.854841e-02\n",
       "145     tfidf_145  1.788623e-02\n",
       "447        orange  1.765932e-02\n",
       "329     tfidf_329  1.247164e-02\n",
       "210     tfidf_210  1.190771e-02\n",
       "422         apple  1.093112e-02\n",
       "170     tfidf_170  1.080447e-02\n",
       "72       tfidf_72  9.497330e-03\n",
       "316     tfidf_316  9.428395e-03\n",
       "299     tfidf_299  9.257443e-03\n",
       "350     tfidf_350  9.001828e-03\n",
       "294     tfidf_294  8.882568e-03\n",
       "245     tfidf_245  8.469232e-03\n",
       "80       tfidf_80  7.888026e-03\n",
       "445          mint  7.672922e-03\n",
       "168     tfidf_168  7.535297e-03\n",
       "81       tfidf_81  7.521751e-03\n",
       "312     tfidf_312  7.434115e-03\n",
       "135     tfidf_135  6.798141e-03\n",
       "149     tfidf_149  6.593973e-03\n",
       "121     tfidf_121  6.465389e-03\n",
       "129     tfidf_129  6.443078e-03\n",
       "141     tfidf_141  6.193136e-03\n",
       "460         sweet  6.071321e-03\n",
       "66       tfidf_66  5.921587e-03\n",
       "222     tfidf_222  5.700160e-03\n",
       "345     tfidf_345  5.372504e-03\n",
       "120     tfidf_120  5.231496e-03\n",
       "285     tfidf_285  5.173082e-03\n",
       "402      euphoric  5.072128e-03\n",
       "337     tfidf_337  5.062409e-03\n",
       "205     tfidf_205  4.870453e-03\n",
       "330     tfidf_330  4.674633e-03\n",
       "253     tfidf_253  4.552060e-03\n",
       "424         berry  4.549895e-03\n",
       "203     tfidf_203  4.192273e-03\n",
       "173     tfidf_173  4.164018e-03\n",
       "315     tfidf_315  4.072965e-03\n",
       "413       relaxed  4.039186e-03\n",
       "119     tfidf_119  4.037583e-03\n",
       "309     tfidf_309  4.005215e-03\n",
       "43       tfidf_43  3.908259e-03\n",
       "30       tfidf_30  3.906035e-03\n",
       "407         happy  3.854115e-03\n",
       "357     tfidf_357  3.801129e-03\n",
       "33       tfidf_33  3.753795e-03\n",
       "138     tfidf_138  3.712162e-03\n",
       "239     tfidf_239  3.642839e-03\n",
       "199     tfidf_199  3.638495e-03\n",
       "349     tfidf_349  3.612917e-03\n",
       "207     tfidf_207  3.423377e-03\n",
       "441         lemon  3.335557e-03\n",
       "190     tfidf_190  3.323687e-03\n",
       "362     tfidf_362  3.309782e-03\n",
       "389        indica  3.016159e-03\n",
       "340     tfidf_340  2.999856e-03\n",
       "103     tfidf_103  2.936020e-03\n",
       "101     tfidf_101  2.935644e-03\n",
       "202     tfidf_202  2.918039e-03\n",
       "466       vanilla  2.913871e-03\n",
       "232     tfidf_232  2.913621e-03\n",
       "95       tfidf_95  2.862881e-03\n",
       "395      creative  2.855434e-03\n",
       "223     tfidf_223  2.829542e-03\n",
       "65       tfidf_65  2.811714e-03\n",
       "78       tfidf_78  2.786495e-03\n",
       "5         tfidf_5  2.707919e-03\n",
       "21       tfidf_21  2.703272e-03\n",
       "117     tfidf_117  2.680608e-03\n",
       "231     tfidf_231  2.661123e-03\n",
       "54       tfidf_54  2.637954e-03\n",
       "301     tfidf_301  2.533977e-03\n",
       "291     tfidf_291  2.488134e-03\n",
       "431        citrus  2.472213e-03\n",
       "303     tfidf_303  2.454677e-03\n",
       "178     tfidf_178  2.434587e-03\n",
       "338     tfidf_338  2.429305e-03\n",
       "11       tfidf_11  2.424142e-03\n",
       "360     tfidf_360  2.355721e-03\n",
       "454       pungent  2.340613e-03\n",
       "52       tfidf_52  2.329086e-03\n",
       "399     dry mouth  2.286115e-03\n",
       "93       tfidf_93  2.107525e-03\n",
       "283     tfidf_283  2.100209e-03\n",
       "37       tfidf_37  2.048138e-03\n",
       "6         tfidf_6  2.034516e-03\n",
       "73       tfidf_73  2.005938e-03\n",
       "87       tfidf_87  1.995072e-03\n",
       "281     tfidf_281  1.929938e-03\n",
       "251     tfidf_251  1.870774e-03\n",
       "90       tfidf_90  1.865312e-03\n",
       "318     tfidf_318  1.861896e-03\n",
       "244     tfidf_244  1.852955e-03\n",
       "128     tfidf_128  1.844929e-03\n",
       "167     tfidf_167  1.803383e-03\n",
       "32       tfidf_32  1.772028e-03\n",
       "7         tfidf_7  1.765835e-03\n",
       "420      uplifted  1.755345e-03\n",
       "434        earthy  1.718987e-03\n",
       "409        hungry  1.690508e-03\n",
       "319     tfidf_319  1.685791e-03\n",
       "122     tfidf_122  1.667154e-03\n",
       "198     tfidf_198  1.660063e-03\n",
       "158     tfidf_158  1.654189e-03\n",
       "162     tfidf_162  1.630972e-03\n",
       "437         grape  1.606232e-03\n",
       "267     tfidf_267  1.567699e-03\n",
       "415        sleepy  1.555428e-03\n",
       "336     tfidf_336  1.528185e-03\n",
       "85       tfidf_85  1.526404e-03\n",
       "408      headache  1.520017e-03\n",
       "166     tfidf_166  1.489786e-03\n",
       "195     tfidf_195  1.483590e-03\n",
       "123     tfidf_123  1.482286e-03\n",
       "126     tfidf_126  1.477110e-03\n",
       "400     energetic  1.461751e-03\n",
       "385     tfidf_385  1.453469e-03\n",
       "61       tfidf_61  1.453361e-03\n",
       "406        giggly  1.433448e-03\n",
       "144     tfidf_144  1.428128e-03\n",
       "366     tfidf_366  1.425472e-03\n",
       "418     talkative  1.413764e-03\n",
       "405       focused  1.389677e-03\n",
       "151     tfidf_151  1.347449e-03\n",
       "115     tfidf_115  1.345305e-03\n",
       "302     tfidf_302  1.332208e-03\n",
       "457         skunk  1.313247e-03\n",
       "221     tfidf_221  1.308325e-03\n",
       "374     tfidf_374  1.293091e-03\n",
       "240     tfidf_240  1.290895e-03\n",
       "41       tfidf_41  1.288500e-03\n",
       "99       tfidf_99  1.266492e-03\n",
       "163     tfidf_163  1.244366e-03\n",
       "342     tfidf_342  1.232693e-03\n",
       "137     tfidf_137  1.220866e-03\n",
       "217     tfidf_217  1.219929e-03\n",
       "146     tfidf_146  1.192351e-03\n",
       "314     tfidf_314  1.186646e-03\n",
       "130     tfidf_130  1.184479e-03\n",
       "26       tfidf_26  1.166852e-03\n",
       "208     tfidf_208  1.161928e-03\n",
       "438    grapefruit  1.160755e-03\n",
       "230     tfidf_230  1.153146e-03\n",
       "295     tfidf_295  1.149040e-03\n",
       "16       tfidf_16  1.131110e-03\n",
       "419        tingly  1.123353e-03\n",
       "14       tfidf_14  1.120571e-03\n",
       "376     tfidf_376  1.111390e-03\n",
       "189     tfidf_189  1.110579e-03\n",
       "343     tfidf_343  1.091851e-03\n",
       "192     tfidf_192  1.086318e-03\n",
       "109     tfidf_109  1.077039e-03\n",
       "200     tfidf_200  1.064439e-03\n",
       "258     tfidf_258  1.047828e-03\n",
       "304     tfidf_304  1.039731e-03\n",
       "31       tfidf_31  1.033251e-03\n",
       "320     tfidf_320  1.031511e-03\n",
       "237     tfidf_237  1.000316e-03\n",
       "264     tfidf_264  9.980630e-04\n",
       "105     tfidf_105  9.908330e-04\n",
       "325     tfidf_325  9.735032e-04\n",
       "177     tfidf_177  9.716212e-04\n",
       "326     tfidf_326  9.620583e-04\n",
       "188     tfidf_188  9.597369e-04\n",
       "384     tfidf_384  9.561730e-04\n",
       "268     tfidf_268  9.530318e-04\n",
       "451          pine  9.453932e-04\n",
       "215     tfidf_215  9.361784e-04\n",
       "398      dry eyes  9.264566e-04\n",
       "355     tfidf_355  9.231794e-04\n",
       "387     tfidf_387  9.158201e-04\n",
       "368     tfidf_368  9.095436e-04\n",
       "104     tfidf_104  9.047594e-04\n",
       "380     tfidf_380  9.014705e-04\n",
       "69       tfidf_69  9.002247e-04\n",
       "34       tfidf_34  8.981405e-04\n",
       "288     tfidf_288  8.844757e-04\n",
       "371     tfidf_371  8.735883e-04\n",
       "354     tfidf_354  8.707108e-04\n",
       "153     tfidf_153  8.594209e-04\n",
       "64       tfidf_64  8.586201e-04\n",
       "234     tfidf_234  8.530635e-04\n",
       "124     tfidf_124  8.506436e-04\n",
       "108     tfidf_108  8.504343e-04\n",
       "79       tfidf_79  8.461867e-04\n",
       "271     tfidf_271  8.458277e-04\n",
       "382     tfidf_382  8.454220e-04\n",
       "1         tfidf_1  8.305319e-04\n",
       "71       tfidf_71  8.227150e-04\n",
       "206     tfidf_206  8.196533e-04\n",
       "383     tfidf_383  8.180271e-04\n",
       "381     tfidf_381  8.178898e-04\n",
       "175     tfidf_175  8.149570e-04\n",
       "29       tfidf_29  8.144172e-04\n",
       "107     tfidf_107  8.081241e-04\n",
       "260     tfidf_260  8.062974e-04\n",
       "20       tfidf_20  7.892310e-04\n",
       "98       tfidf_98  7.846661e-04\n",
       "211     tfidf_211  7.805542e-04\n",
       "468         woody  7.803266e-04\n",
       "278     tfidf_278  7.798244e-04\n",
       "48       tfidf_48  7.785660e-04\n",
       "280     tfidf_280  7.776626e-04\n",
       "367     tfidf_367  7.718974e-04\n",
       "236     tfidf_236  7.692364e-04\n",
       "286     tfidf_286  7.564831e-04\n",
       "28       tfidf_28  7.557890e-04\n",
       "154     tfidf_154  7.546234e-04\n",
       "112     tfidf_112  7.471522e-04\n",
       "159     tfidf_159  7.394243e-04\n",
       "393       aroused  7.118466e-04\n",
       "272     tfidf_272  7.039561e-04\n",
       "125     tfidf_125  6.979331e-04\n",
       "432        coffee  6.975864e-04\n",
       "83       tfidf_83  6.938881e-04\n",
       "263     tfidf_263  6.931974e-04\n",
       "229     tfidf_229  6.869054e-04\n",
       "196     tfidf_196  6.860331e-04\n",
       "127     tfidf_127  6.821678e-04\n",
       "49       tfidf_49  6.766905e-04\n",
       "317     tfidf_317  6.765429e-04\n",
       "347     tfidf_347  6.746937e-04\n",
       "341     tfidf_341  6.739921e-04\n",
       "86       tfidf_86  6.739125e-04\n",
       "161     tfidf_161  6.707111e-04\n",
       "273     tfidf_273  6.681037e-04\n",
       "184     tfidf_184  6.641564e-04\n",
       "46       tfidf_46  6.617695e-04\n",
       "22       tfidf_22  6.611326e-04\n",
       "297     tfidf_297  6.606849e-04\n",
       "439         honey  6.531043e-04\n",
       "39       tfidf_39  6.466089e-04\n",
       "305     tfidf_305  6.462749e-04\n",
       "212     tfidf_212  6.402829e-04\n",
       "68       tfidf_68  6.275887e-04\n",
       "270     tfidf_270  6.243213e-04\n",
       "363     tfidf_363  6.230410e-04\n",
       "311     tfidf_311  6.219404e-04\n",
       "24       tfidf_24  6.180012e-04\n",
       "197     tfidf_197  6.146176e-04\n",
       "50       tfidf_50  6.132136e-04\n",
       "375     tfidf_375  6.107338e-04\n",
       "353     tfidf_353  5.954880e-04\n",
       "60       tfidf_60  5.945082e-04\n",
       "47       tfidf_47  5.929158e-04\n",
       "436         fruit  5.928349e-04\n",
       "370     tfidf_370  5.900633e-04\n",
       "397         dizzy  5.868205e-04\n",
       "58       tfidf_58  5.861067e-04\n",
       "373     tfidf_373  5.724822e-04\n",
       "364     tfidf_364  5.688229e-04\n",
       "9         tfidf_9  5.680123e-04\n",
       "56       tfidf_56  5.653914e-04\n",
       "333     tfidf_333  5.652950e-04\n",
       "369     tfidf_369  5.590915e-04\n",
       "19       tfidf_19  5.531443e-04\n",
       "186     tfidf_186  5.454842e-04\n",
       "265     tfidf_265  5.437647e-04\n",
       "164     tfidf_164  5.416938e-04\n",
       "116     tfidf_116  5.375035e-04\n",
       "427        butter  5.363323e-04\n",
       "435       flowery  5.360492e-04\n",
       "308     tfidf_308  5.304210e-04\n",
       "97       tfidf_97  5.246720e-04\n",
       "254     tfidf_254  5.245633e-04\n",
       "219     tfidf_219  5.139370e-04\n",
       "136     tfidf_136  5.131358e-04\n",
       "59       tfidf_59  5.104213e-04\n",
       "187     tfidf_187  5.088770e-04\n",
       "348     tfidf_348  5.086031e-04\n",
       "172     tfidf_172  5.043720e-04\n",
       "113     tfidf_113  4.925888e-04\n",
       "150     tfidf_150  4.865851e-04\n",
       "4         tfidf_4  4.831639e-04\n",
       "276     tfidf_276  4.786791e-04\n",
       "307     tfidf_307  4.674358e-04\n",
       "76       tfidf_76  4.635727e-04\n",
       "282     tfidf_282  4.568241e-04\n",
       "227     tfidf_227  4.567851e-04\n",
       "321     tfidf_321  4.550421e-04\n",
       "446         nutty  4.538357e-04\n",
       "351     tfidf_351  4.508653e-04\n",
       "118     tfidf_118  4.501981e-04\n",
       "292     tfidf_292  4.492035e-04\n",
       "194     tfidf_194  4.445822e-04\n",
       "455          rose  4.419788e-04\n",
       "91       tfidf_91  4.391064e-04\n",
       "17       tfidf_17  4.369893e-04\n",
       "392       anxious  4.332349e-04\n",
       "82       tfidf_82  4.320625e-04\n",
       "250     tfidf_250  4.279766e-04\n",
       "45       tfidf_45  4.243061e-04\n",
       "255     tfidf_255  4.231621e-04\n",
       "220     tfidf_220  4.221496e-04\n",
       "313     tfidf_313  4.177530e-04\n",
       "359     tfidf_359  4.165381e-04\n",
       "328     tfidf_328  4.135634e-04\n",
       "96       tfidf_96  4.095584e-04\n",
       "180     tfidf_180  4.050581e-04\n",
       "183     tfidf_183  4.023290e-04\n",
       "465      tropical  4.022909e-04\n",
       "241     tfidf_241  3.938648e-04\n",
       "92       tfidf_92  3.937292e-04\n",
       "40       tfidf_40  3.930058e-04\n",
       "300     tfidf_300  3.907921e-04\n",
       "243     tfidf_243  3.857038e-04\n",
       "247     tfidf_247  3.855747e-04\n",
       "27       tfidf_27  3.834167e-04\n",
       "111     tfidf_111  3.799369e-04\n",
       "25       tfidf_25  3.777404e-04\n",
       "456          sage  3.721953e-04\n",
       "193     tfidf_193  3.656207e-04\n",
       "102     tfidf_102  3.644689e-04\n",
       "310     tfidf_310  3.640985e-04\n",
       "352     tfidf_352  3.635390e-04\n",
       "62       tfidf_62  3.614020e-04\n",
       "322     tfidf_322  3.594731e-04\n",
       "139     tfidf_139  3.567169e-04\n",
       "327     tfidf_327  3.556886e-04\n",
       "386     tfidf_386  3.547471e-04\n",
       "464          tree  3.546103e-04\n",
       "171     tfidf_171  3.524737e-04\n",
       "179     tfidf_179  3.515433e-04\n",
       "458  spicy/herbal  3.500262e-04\n",
       "289     tfidf_289  3.468727e-04\n",
       "257     tfidf_257  3.441463e-04\n",
       "165     tfidf_165  3.378861e-04\n",
       "365     tfidf_365  3.373348e-04\n",
       "75       tfidf_75  3.371278e-04\n",
       "169     tfidf_169  3.362328e-04\n",
       "182     tfidf_182  3.345227e-04\n",
       "23       tfidf_23  3.336214e-04\n",
       "412      paranoid  3.328728e-04\n",
       "246     tfidf_246  3.320613e-04\n",
       "358     tfidf_358  3.315527e-04\n",
       "344     tfidf_344  3.294648e-04\n",
       "181     tfidf_181  3.290229e-04\n",
       "0         tfidf_0  3.283774e-04\n",
       "224     tfidf_224  3.256456e-04\n",
       "88       tfidf_88  3.254900e-04\n",
       "228     tfidf_228  3.243724e-04\n",
       "57       tfidf_57  3.240134e-04\n",
       "106     tfidf_106  3.128156e-04\n",
       "218     tfidf_218  3.121842e-04\n",
       "2         tfidf_2  3.113212e-04\n",
       "67       tfidf_67  3.102735e-04\n",
       "147     tfidf_147  3.101101e-04\n",
       "216     tfidf_216  3.050459e-04\n",
       "3         tfidf_3  2.999653e-04\n",
       "277     tfidf_277  2.995225e-04\n",
       "238     tfidf_238  2.913955e-04\n",
       "293     tfidf_293  2.894216e-04\n",
       "143     tfidf_143  2.889797e-04\n",
       "249     tfidf_249  2.868722e-04\n",
       "114     tfidf_114  2.850475e-04\n",
       "259     tfidf_259  2.821020e-04\n",
       "176     tfidf_176  2.804887e-04\n",
       "110     tfidf_110  2.789640e-04\n",
       "185     tfidf_185  2.765062e-04\n",
       "51       tfidf_51  2.748652e-04\n",
       "296     tfidf_296  2.747735e-04\n",
       "10       tfidf_10  2.747466e-04\n",
       "372     tfidf_372  2.746597e-04\n",
       "152     tfidf_152  2.728005e-04\n",
       "148     tfidf_148  2.664427e-04\n",
       "262     tfidf_262  2.662233e-04\n",
       "94       tfidf_94  2.662005e-04\n",
       "346     tfidf_346  2.654200e-04\n",
       "225     tfidf_225  2.626939e-04\n",
       "298     tfidf_298  2.620962e-04\n",
       "442          lime  2.550356e-04\n",
       "332     tfidf_332  2.513173e-04\n",
       "443         mango  2.501613e-04\n",
       "77       tfidf_77  2.486558e-04\n",
       "201     tfidf_201  2.364522e-04\n",
       "214     tfidf_214  2.353608e-04\n",
       "191     tfidf_191  2.344959e-04\n",
       "160     tfidf_160  2.287046e-04\n",
       "174     tfidf_174  2.261068e-04\n",
       "63       tfidf_63  2.257944e-04\n",
       "155     tfidf_155  2.253377e-04\n",
       "290     tfidf_290  2.218030e-04\n",
       "53       tfidf_53  2.197874e-04\n",
       "261     tfidf_261  2.195105e-04\n",
       "157     tfidf_157  2.188000e-04\n",
       "55       tfidf_55  2.182971e-04\n",
       "440      lavender  2.171727e-04\n",
       "140     tfidf_140  2.154222e-04\n",
       "429      chemical  2.143187e-04\n",
       "287     tfidf_287  2.086296e-04\n",
       "324     tfidf_324  2.054496e-04\n",
       "209     tfidf_209  2.050636e-04\n",
       "213     tfidf_213  2.042226e-04\n",
       "142     tfidf_142  2.032643e-04\n",
       "450        pepper  2.017082e-04\n",
       "306     tfidf_306  2.010434e-04\n",
       "235     tfidf_235  2.009014e-04\n",
       "279     tfidf_279  2.006691e-04\n",
       "323     tfidf_323  1.962518e-04\n",
       "226     tfidf_226  1.949689e-04\n",
       "361     tfidf_361  1.892241e-04\n",
       "335     tfidf_335  1.889888e-04\n",
       "242     tfidf_242  1.858170e-04\n",
       "18       tfidf_18  1.840981e-04\n",
       "12       tfidf_12  1.817584e-04\n",
       "70       tfidf_70  1.787939e-04\n",
       "356     tfidf_356  1.737503e-04\n",
       "274     tfidf_274  1.711499e-04\n",
       "459    strawberry  1.686110e-04\n",
       "334     tfidf_334  1.682726e-04\n",
       "44       tfidf_44  1.643187e-04\n",
       "156     tfidf_156  1.614775e-04\n",
       "15       tfidf_15  1.593169e-04\n",
       "256     tfidf_256  1.588096e-04\n",
       "13       tfidf_13  1.515404e-04\n",
       "339     tfidf_339  1.501631e-04\n",
       "100     tfidf_100  1.464863e-04\n",
       "84       tfidf_84  1.462821e-04\n",
       "132     tfidf_132  1.391200e-04\n",
       "284     tfidf_284  1.374366e-04\n",
       "378     tfidf_378  1.359147e-04\n",
       "269     tfidf_269  1.354850e-04\n",
       "275     tfidf_275  1.337967e-04\n",
       "133     tfidf_133  1.292964e-04\n",
       "377     tfidf_377  1.292381e-04\n",
       "38       tfidf_38  1.246951e-04\n",
       "204     tfidf_204  1.138678e-04\n",
       "448         peach  1.071714e-04\n",
       "462           tea  1.068381e-04\n",
       "331     tfidf_331  1.061359e-04\n",
       "421       ammonia  1.056667e-04\n",
       "35       tfidf_35  1.028739e-04\n",
       "233     tfidf_233  1.026145e-04\n",
       "252     tfidf_252  9.891820e-05\n",
       "379     tfidf_379  9.457903e-05\n",
       "89       tfidf_89  8.886585e-05\n",
       "425   blue cheese  8.342183e-05\n",
       "248     tfidf_248  8.159075e-05\n",
       "131     tfidf_131  7.595305e-05\n",
       "36       tfidf_36  7.580688e-05\n",
       "42       tfidf_42  7.120799e-05\n",
       "74       tfidf_74  6.408712e-05\n",
       "430      chestnut  6.322949e-05\n",
       "8         tfidf_8  6.062427e-05\n",
       "134     tfidf_134  5.942542e-05\n",
       "453          plum  5.911961e-05\n",
       "452     pineapple  5.678713e-05\n",
       "266     tfidf_266  5.395248e-05\n",
       "449          pear  3.707643e-05\n",
       "410     migraines  2.861895e-05\n",
       "444       menthol  2.654275e-05\n",
       "463       tobacco  2.623261e-05\n",
       "391       anxiety  2.521689e-05\n",
       "396    depression  2.073062e-05\n",
       "423       apricot  1.747381e-05\n",
       "461           tar  1.669090e-05\n",
       "467        violet  1.573898e-05\n",
       "417        stress  3.280260e-08\n",
       "414      seizures  4.374765e-09\n",
       "401      epilepsy  2.341016e-09\n",
       "404       fatigue  2.264651e-09\n",
       "394     arthritis  1.468414e-09\n",
       "411          pain  6.642752e-10\n",
       "416    spasticity  0.000000e+00\n",
       "403  eye pressure  0.000000e+00"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.set_option('display.max_rows', df_feat_ranked.shape[0]+1)\n",
    "df_feat_ranked"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/andalanputra/opt/anaconda3/lib/python3.9/site-packages/sklearn/feature_selection/_from_model.py:357: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  self.estimator_.fit(X, y, **fit_params)\n"
     ]
    }
   ],
   "source": [
    "selector = SelectFromModel(rfreg).fit(X_train1, y_train1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([3.10975717e-04, 7.23440504e-04, 2.97584816e-04, 2.78994358e-04,\n",
       "       4.87680751e-04, 2.35766452e-03, 1.78529624e-03, 1.94074543e-03,\n",
       "       6.87155669e-05, 6.32156103e-04, 2.65217245e-04, 2.30030839e-03,\n",
       "       1.62010203e-04, 1.11118565e-04, 1.27811273e-03, 1.25997365e-04,\n",
       "       9.63697011e-04, 4.83493016e-04, 1.55133061e-04, 6.13051793e-04,\n",
       "       9.31310185e-04, 2.64266948e-03, 6.70443399e-04, 3.56033552e-04,\n",
       "       7.33719242e-04, 3.81486050e-04, 1.16943992e-03, 4.82428974e-04,\n",
       "       8.34212968e-04, 7.60163733e-04, 3.79116670e-03, 9.47833742e-04,\n",
       "       1.58389015e-03, 3.64204201e-03, 1.04176798e-03, 7.63401971e-05,\n",
       "       9.80249990e-05, 2.02477540e-03, 9.83128910e-05, 7.51054122e-04,\n",
       "       4.09830456e-04, 9.81434807e-04, 5.72047130e-05, 4.30777050e-03,\n",
       "       1.54601910e-04, 5.39924244e-04, 7.20453899e-04, 5.18522896e-04,\n",
       "       8.06416203e-04, 7.63697639e-04, 4.20521689e-04, 2.62559121e-04,\n",
       "       2.39528387e-03, 2.70465185e-04, 2.56633793e-03, 2.41134166e-04,\n",
       "       5.75259155e-04, 3.57800380e-04, 5.20620403e-04, 4.71998228e-04,\n",
       "       5.00504591e-04, 2.06236203e-03, 4.01121401e-04, 3.22167266e-04,\n",
       "       9.32648075e-04, 2.76898431e-03, 5.85781700e-03, 3.95899131e-04,\n",
       "       7.16476504e-04, 8.95186997e-04, 1.70174168e-04, 9.25747394e-04,\n",
       "       9.26915273e-03, 2.07981925e-03, 7.97723005e-05, 3.32695700e-04,\n",
       "       4.61701503e-04, 2.29827050e-04, 2.86648470e-03, 7.89904203e-04,\n",
       "       7.24560523e-03, 8.51583302e-03, 3.84978689e-04, 5.22952966e-04,\n",
       "       1.55885995e-04, 1.54223284e-03, 7.23396910e-04, 1.90076611e-03,\n",
       "       4.04278365e-04, 1.06353759e-04, 1.73246383e-03, 4.28504233e-04,\n",
       "       3.29366198e-04, 2.02620973e-03, 2.92623493e-04, 2.77816193e-03,\n",
       "       4.01373865e-04, 4.40670703e-04, 8.49086703e-04, 1.10468438e-03,\n",
       "       1.76173023e-04, 3.27316571e-03, 3.21279782e-04, 3.08537420e-03,\n",
       "       9.47010585e-04, 1.02237799e-03, 3.58367268e-04, 7.63566510e-04,\n",
       "       9.63575155e-04, 1.02209233e-03, 2.82957208e-04, 3.90582531e-04,\n",
       "       6.46439515e-04, 5.71391431e-04, 3.73659836e-04, 1.45274475e-03,\n",
       "       5.44613480e-04, 2.53739951e-03, 2.37793238e-04, 4.47208607e-03,\n",
       "       5.13014650e-03, 6.40006605e-03, 1.63003202e-03, 1.65437651e-03,\n",
       "       9.04725587e-04, 6.44950679e-04, 1.37869530e-03, 6.74727645e-04,\n",
       "       1.85861962e-03, 6.05314317e-03, 1.36696090e-03, 7.82297040e-05,\n",
       "       1.15244558e-04, 1.23432996e-04, 5.22319866e-05, 7.71472398e-03,\n",
       "       5.29395282e-04, 1.07953096e-03, 3.69631660e-03, 3.51829582e-04,\n",
       "       2.12081492e-04, 5.67552345e-03, 2.09036344e-04, 2.90056474e-04,\n",
       "       1.44323862e-03, 1.62906729e-02, 1.57354939e-03, 3.11501351e-04,\n",
       "       3.06926506e-04, 6.59794395e-03, 4.46766058e-04, 1.36968542e-03,\n",
       "       2.94523927e-04, 8.55384960e-04, 7.27062574e-04, 1.54301774e-04,\n",
       "       1.93256823e-04, 2.44437968e-04, 1.58119888e-03, 8.96287499e-04,\n",
       "       2.39629364e-04, 7.36259218e-04, 1.66468837e-03, 1.21576889e-03,\n",
       "       5.18708910e-04, 3.27922371e-04, 1.70625723e-03, 1.81297965e-03,\n",
       "       7.99715997e-03, 3.41965395e-04, 1.00545773e-02, 2.71655828e-04,\n",
       "       5.18626921e-04, 3.74483771e-03, 2.40937484e-04, 8.25821684e-04,\n",
       "       2.84970569e-04, 1.07757057e-03, 2.07770478e-03, 3.43087672e-04,\n",
       "       4.04707834e-04, 3.78970003e-04, 3.17811167e-04, 4.17045859e-04,\n",
       "       7.06434315e-04, 2.71327157e-04, 5.39926110e-04, 4.72280351e-04,\n",
       "       8.41518305e-04, 1.07073409e-03, 3.00552016e-03, 2.32750764e-04,\n",
       "       8.86119920e-04, 3.40540918e-04, 4.37907890e-04, 1.69575456e-03,\n",
       "       6.79543567e-04, 6.07760464e-04, 1.40506686e-03, 3.78939975e-03,\n",
       "       1.16716255e-03, 3.07645570e-04, 2.87102934e-03, 4.55733312e-03,\n",
       "       1.20897376e-04, 4.74123374e-03, 9.05744967e-04, 3.86274029e-03,\n",
       "       1.16422745e-03, 1.91383467e-04, 1.08102945e-02, 6.27064684e-04,\n",
       "       6.11947645e-04, 1.73441635e-04, 2.20752689e-04, 8.76920900e-04,\n",
       "       3.16268355e-04, 1.19472571e-03, 3.09964971e-04, 5.23569518e-04,\n",
       "       4.35779646e-04, 1.31991524e-03, 5.07939746e-03, 2.39562204e-03,\n",
       "       3.59017368e-04, 2.80505742e-04, 1.42842072e-04, 4.50636617e-04,\n",
       "       3.00709283e-04, 6.60588146e-04, 1.10448886e-03, 2.91710442e-03,\n",
       "       3.20549885e-03, 1.02055308e-04, 8.10944195e-04, 2.06757868e-04,\n",
       "       8.18830772e-04, 1.05834201e-03, 2.87277105e-04, 3.27205181e-03,\n",
       "       1.17440457e-03, 4.59161605e-04, 2.10152258e-04, 3.80618270e-04,\n",
       "       1.85852244e-03, 8.60644417e-03, 4.92224401e-04, 4.16494983e-04,\n",
       "       1.14207916e-04, 1.74237814e-04, 7.59308010e-04, 1.70752973e-03,\n",
       "       1.22779723e-04, 4.24212864e-03, 5.44275721e-04, 4.06778489e-04,\n",
       "       2.03895892e-04, 4.11387551e-04, 9.15669752e-04, 2.12646264e-04,\n",
       "       7.20247669e-04, 1.91718446e-04, 2.74429386e-04, 7.39132824e-04,\n",
       "       1.00604709e-03, 5.53686283e-04, 5.37609979e-05, 1.46828143e-03,\n",
       "       1.66140539e-03, 1.78349212e-04, 7.00947778e-04, 1.09656763e-03,\n",
       "       7.20362376e-04, 5.48338404e-04, 1.47793564e-04, 1.30064076e-04,\n",
       "       4.46692269e-04, 3.22682074e-04, 7.80914667e-04, 1.48453608e-04,\n",
       "       6.93415404e-04, 1.93653126e-03, 2.87565034e-04, 2.31157818e-03,\n",
       "       1.37336583e-04, 5.17914525e-03, 7.07668154e-04, 2.38813446e-04,\n",
       "       9.53784270e-04, 3.82804306e-04, 2.12038738e-04, 2.78371271e-03,\n",
       "       3.87060967e-04, 3.11022803e-04, 9.34523421e-03, 8.39596853e-04,\n",
       "       2.62581003e-04, 7.86033764e-04, 2.49601098e-04, 9.28021165e-03,\n",
       "       4.17145200e-04, 2.55918779e-03, 1.13207644e-03, 2.29021046e-03,\n",
       "       9.57914365e-04, 7.10919161e-04, 2.07498928e-04, 3.48088295e-04,\n",
       "       6.13671464e-04, 4.25042355e-03, 4.39867634e-04, 1.00155954e-03,\n",
       "       7.43038342e-03, 3.66448969e-04, 1.18470490e-03, 4.79567145e-03,\n",
       "       9.04264485e-03, 7.13090189e-04, 2.09158114e-03, 1.72613118e-03,\n",
       "       8.40258467e-04, 4.15047826e-04, 3.98876359e-04, 1.99256063e-04,\n",
       "       2.24769603e-04, 1.02692636e-03, 9.57068090e-04, 3.35813964e-04,\n",
       "       4.01431306e-04, 1.21969785e-02, 4.67698312e-03, 1.20869998e-04,\n",
       "       2.48975882e-04, 4.76038245e-04, 1.85684298e-04, 1.79790648e-04,\n",
       "       1.25309703e-03, 5.11260266e-03, 2.49063227e-03, 1.88762303e-04,\n",
       "       3.09350292e-03, 7.26504238e-04, 1.22782959e-03, 1.15365795e-03,\n",
       "       2.74352254e-04, 5.83614972e-03, 2.50570851e-04, 5.64617877e-04,\n",
       "       4.34623553e-04, 3.64251008e-03, 8.58912580e-03, 4.43008606e-04,\n",
       "       5.15669172e-04, 5.46538335e-04, 9.79362502e-04, 1.07448337e-03,\n",
       "       2.18274399e-04, 3.50429902e-03, 2.96340355e-04, 3.47877947e-04,\n",
       "       2.60050097e-03, 2.22660397e-04, 3.63087754e-03, 5.92161701e-04,\n",
       "       4.44483324e-04, 3.03988432e-04, 1.53213604e-03, 7.72404607e-04,\n",
       "       8.05207498e-04, 5.63075422e-04, 5.71418641e-04, 8.91608483e-04,\n",
       "       3.18021295e-04, 6.09982421e-04, 1.41615185e-03, 5.69455506e-04,\n",
       "       1.12662721e-03, 1.25505414e-04, 1.31807150e-04, 1.13041624e-04,\n",
       "       8.70433205e-04, 8.35538492e-04, 7.54971357e-04, 7.00248570e-04,\n",
       "       9.88693163e-04, 1.56529335e-03, 3.19769588e-04, 1.33204731e-03,\n",
       "       2.06790535e-02, 3.48794297e-03, 4.78782892e-02, 3.53570412e-05,\n",
       "       4.79800522e-04, 7.70216878e-04, 1.71829995e-09, 2.41666941e-03,\n",
       "       2.59370272e-05, 4.96885083e-04, 9.93635247e-04, 2.57976362e-03,\n",
       "       1.69862894e-03, 2.18556302e-09, 5.54536181e-03, 7.89633074e-10,\n",
       "       1.66310059e-09, 1.38426059e-03, 1.42450719e-03, 3.57769176e-03,\n",
       "       1.37259992e-03, 1.48466923e-03, 3.88145793e-05, 0.00000000e+00,\n",
       "       3.52504166e-04, 4.62870038e-03, 0.00000000e+00, 1.63353732e-03,\n",
       "       0.00000000e+00, 0.00000000e+00, 1.45988791e-03, 1.10123942e-03,\n",
       "       1.64522937e-03, 1.13807195e-04, 1.09856872e-02, 2.71134185e-05,\n",
       "       4.48543331e-03, 7.35968217e-05, 2.17979363e-02, 7.03789289e-04,\n",
       "       2.34828089e-01, 2.67287468e-04, 6.29959252e-05, 2.49548874e-03,\n",
       "       6.76526681e-04, 1.85128908e-02, 1.87513250e-03, 5.76512285e-04,\n",
       "       6.64650326e-04, 1.59421702e-03, 1.11519160e-03, 6.86225916e-04,\n",
       "       2.43154048e-04, 2.88315603e-03, 3.14400424e-04, 2.30733108e-04,\n",
       "       2.31336836e-05, 7.41466846e-03, 4.69109897e-04, 1.76941503e-02,\n",
       "       1.17055909e-04, 4.41925437e-05, 2.01115140e-04, 1.00065201e-03,\n",
       "       5.72097856e-05, 5.24721903e-05, 2.27718899e-03, 4.18517151e-04,\n",
       "       3.81425543e-04, 1.33582219e-03, 3.75826296e-04, 1.80017054e-04,\n",
       "       6.25268010e-03, 4.77997362e-05, 1.13254620e-04, 4.02144690e-05,\n",
       "       3.57266069e-04, 3.51787243e-04, 2.86579108e-03, 1.65337786e-05,\n",
       "       8.19289300e-04])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "selector.estimator_.feature_importances_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0021321961620469083"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "selector.threshold_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "mask = selector.get_support()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([False, False, False, False, False,  True, False, False, False,\n",
       "       False, False,  True, False, False, False, False, False, False,\n",
       "       False, False, False,  True, False, False, False, False, False,\n",
       "       False, False, False,  True, False, False,  True, False, False,\n",
       "       False, False, False, False, False, False, False,  True, False,\n",
       "       False, False, False, False, False, False, False,  True, False,\n",
       "        True, False, False, False, False, False, False, False, False,\n",
       "       False, False,  True,  True, False, False, False, False, False,\n",
       "        True, False, False, False, False, False,  True, False,  True,\n",
       "        True, False, False, False, False, False, False, False, False,\n",
       "       False, False, False, False, False,  True, False, False, False,\n",
       "       False, False,  True, False,  True, False, False, False, False,\n",
       "       False, False, False, False, False, False, False, False, False,\n",
       "        True, False,  True,  True,  True, False, False, False, False,\n",
       "       False, False, False,  True, False, False, False, False, False,\n",
       "        True, False, False,  True, False, False,  True, False, False,\n",
       "       False,  True, False, False, False,  True, False, False, False,\n",
       "       False, False, False, False, False, False, False, False, False,\n",
       "       False, False, False, False, False, False,  True, False,  True,\n",
       "       False, False,  True, False, False, False, False, False, False,\n",
       "       False, False, False, False, False, False, False, False, False,\n",
       "       False,  True, False, False, False, False, False, False, False,\n",
       "       False,  True, False, False,  True,  True, False,  True, False,\n",
       "        True, False, False,  True, False, False, False, False, False,\n",
       "       False, False, False, False, False, False,  True,  True, False,\n",
       "       False, False, False, False, False, False,  True,  True, False,\n",
       "       False, False, False, False, False,  True, False, False, False,\n",
       "       False, False,  True, False, False, False, False, False, False,\n",
       "       False,  True, False, False, False, False, False, False, False,\n",
       "       False, False, False, False, False, False, False, False, False,\n",
       "       False, False, False, False, False, False, False, False, False,\n",
       "       False, False, False, False,  True, False,  True, False, False,\n",
       "       False, False, False,  True, False, False,  True, False, False,\n",
       "       False, False,  True, False,  True, False,  True, False, False,\n",
       "       False, False, False,  True, False, False,  True, False, False,\n",
       "        True,  True, False, False, False, False, False, False, False,\n",
       "       False, False, False, False, False,  True,  True, False, False,\n",
       "       False, False, False, False,  True,  True, False,  True, False,\n",
       "       False, False, False,  True, False, False, False,  True,  True,\n",
       "       False, False, False, False, False, False,  True, False, False,\n",
       "        True, False,  True, False, False, False, False, False, False,\n",
       "       False, False, False, False, False, False, False, False, False,\n",
       "       False, False, False, False, False, False, False, False, False,\n",
       "       False,  True,  True,  True, False, False, False, False,  True,\n",
       "       False, False, False,  True, False, False,  True, False, False,\n",
       "       False, False,  True, False, False, False, False, False,  True,\n",
       "       False, False, False, False, False, False, False, False,  True,\n",
       "       False,  True, False,  True, False,  True, False, False,  True,\n",
       "       False,  True, False, False, False, False, False, False, False,\n",
       "        True, False, False, False,  True, False,  True, False, False,\n",
       "       False, False, False, False,  True, False, False, False, False,\n",
       "       False,  True, False, False, False, False, False,  True, False,\n",
       "       False])"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "selected_features = X.columns[mask]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tfidf_5</th>\n",
       "      <th>tfidf_11</th>\n",
       "      <th>tfidf_21</th>\n",
       "      <th>tfidf_30</th>\n",
       "      <th>tfidf_33</th>\n",
       "      <th>tfidf_43</th>\n",
       "      <th>tfidf_52</th>\n",
       "      <th>tfidf_54</th>\n",
       "      <th>tfidf_65</th>\n",
       "      <th>tfidf_66</th>\n",
       "      <th>...</th>\n",
       "      <th>blueberry</th>\n",
       "      <th>cheese</th>\n",
       "      <th>citrus</th>\n",
       "      <th>diesel</th>\n",
       "      <th>lemon</th>\n",
       "      <th>mint</th>\n",
       "      <th>orange</th>\n",
       "      <th>pungent</th>\n",
       "      <th>sweet</th>\n",
       "      <th>vanilla</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.206994</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.206994</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>74995</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>74996</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.638774</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>74997</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>74998</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>74999</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>75000 rows × 86 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       tfidf_5  tfidf_11  tfidf_21  tfidf_30  tfidf_33  tfidf_43  tfidf_52  \\\n",
       "0          0.0       0.0       0.0       0.0       0.0       0.0       0.0   \n",
       "1          0.0       0.0       0.0       0.0       0.0       0.0       0.0   \n",
       "2          0.0       0.0       0.0       0.0       0.0       0.0       0.0   \n",
       "3          0.0       0.0       0.0       0.0       0.0       0.0       0.0   \n",
       "4          0.0       0.0       0.0       0.0       0.0       0.0       0.0   \n",
       "...        ...       ...       ...       ...       ...       ...       ...   \n",
       "74995      0.0       0.0       0.0       0.0       0.0       0.0       0.0   \n",
       "74996      0.0       0.0       0.0       0.0       0.0       0.0       0.0   \n",
       "74997      0.0       0.0       0.0       0.0       0.0       0.0       0.0   \n",
       "74998      0.0       0.0       0.0       0.0       0.0       0.0       0.0   \n",
       "74999      0.0       0.0       0.0       0.0       0.0       0.0       0.0   \n",
       "\n",
       "       tfidf_54  tfidf_65  tfidf_66  ...  blueberry  cheese  citrus  diesel  \\\n",
       "0           0.0  0.206994  0.000000  ...          0       0       0       0   \n",
       "1           0.0  0.206994  0.000000  ...          0       0       0       0   \n",
       "2           0.0  0.000000  0.000000  ...          0       1       0       0   \n",
       "3           0.0  0.000000  0.000000  ...          0       1       0       0   \n",
       "4           0.0  0.000000  0.000000  ...          0       1       0       0   \n",
       "...         ...       ...       ...  ...        ...     ...     ...     ...   \n",
       "74995       0.0  0.000000  0.000000  ...          0       0       0       0   \n",
       "74996       0.0  0.000000  0.638774  ...          0       0       0       0   \n",
       "74997       0.0  0.000000  0.000000  ...          0       0       0       0   \n",
       "74998       0.0  0.000000  0.000000  ...          0       0       0       0   \n",
       "74999       0.0  0.000000  0.000000  ...          0       0       0       0   \n",
       "\n",
       "       lemon  mint  orange  pungent  sweet  vanilla  \n",
       "0          0     0       0        0      0        0  \n",
       "1          0     0       0        0      0        0  \n",
       "2          0     0       0        0      0        1  \n",
       "3          0     0       0        0      0        1  \n",
       "4          0     0       0        0      0        1  \n",
       "...      ...   ...     ...      ...    ...      ...  \n",
       "74995      0     0       0        0      0        0  \n",
       "74996      0     0       0        0      0        0  \n",
       "74997      0     0       0        0      0        0  \n",
       "74998      0     0       0        0      0        0  \n",
       "74999      0     0       0        0      0        0  \n",
       "\n",
       "[75000 rows x 86 columns]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "selected_X = df_rf[selected_features]\n",
    "selected_X"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train test split (after Feature Selection)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['selected_X_rf_tfidf_cbn.pkl']"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import joblib\n",
    "\n",
    "joblib.dump(selector, \"selector_rf_tfidf_cbn.pkl\")\n",
    "joblib.dump(selected_X, \"selected_X_rf_tfidf_cbn.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(selected_X, y, random_state=1, test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train1, X_val, y_train1, y_val = train_test_split(X_train, y_train, random_state=1, test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/y1/pjvjlkjn5gl846rnyzr53p340000gn/T/ipykernel_7227/3758305.py:1: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  rfreg.fit(X_train1, y_train1)\n"
     ]
    }
   ],
   "source": [
    "rfreg.fit(X_train1, y_train1)\n",
    "y_pred_rfreg = rfreg.predict(X_val)\n",
    "y_pred_rfreg_r2 = rfreg.predict(X_train1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.03986485496514241"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mean_absolute_error(y_val, y_pred_rfreg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.008244919772468915"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mean_squared_error(y_val, y_pred_rfreg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0908015405842264"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mean_squared_error(y_val, y_pred_rfreg, squared = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9774015441943171"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#train\n",
    "r2_score(y_train1, y_pred_rfreg_r2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9158623819825014"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#val\n",
    "r2_score(y_val, y_pred_rfreg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hyperparameter Tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "parameters = {'max_depth': [None, 10, 50, 100],\n",
    "              'max_features': ['auto', 'sqrt'],\n",
    "              'min_samples_leaf': [1, 2, 4],\n",
    "              'min_samples_split': [2, 5, 10],\n",
    "              'n_estimators': [100, 300, 500]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "rscv = RandomizedSearchCV(rfreg,  \n",
    "                     parameters,   \n",
    "                     cv=5, \n",
    "                     scoring='neg_mean_absolute_error',\n",
    "                     n_jobs = -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/andalanputra/opt/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/Users/andalanputra/opt/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/Users/andalanputra/opt/anaconda3/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
      "  warn(\n",
      "/Users/andalanputra/opt/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/Users/andalanputra/opt/anaconda3/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
      "  warn(\n",
      "/Users/andalanputra/opt/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/Users/andalanputra/opt/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/Users/andalanputra/opt/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/Users/andalanputra/opt/anaconda3/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
      "  warn(\n",
      "/Users/andalanputra/opt/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/Users/andalanputra/opt/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/Users/andalanputra/opt/anaconda3/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
      "  warn(\n",
      "/Users/andalanputra/opt/anaconda3/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
      "  warn(\n",
      "/Users/andalanputra/opt/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/Users/andalanputra/opt/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/Users/andalanputra/opt/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/Users/andalanputra/opt/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/Users/andalanputra/opt/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/Users/andalanputra/opt/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/Users/andalanputra/opt/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/Users/andalanputra/opt/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/Users/andalanputra/opt/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/Users/andalanputra/opt/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/Users/andalanputra/opt/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/Users/andalanputra/opt/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/Users/andalanputra/opt/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/Users/andalanputra/opt/anaconda3/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
      "  warn(\n",
      "/Users/andalanputra/opt/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/Users/andalanputra/opt/anaconda3/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
      "  warn(\n",
      "/Users/andalanputra/opt/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/Users/andalanputra/opt/anaconda3/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
      "  warn(\n",
      "/Users/andalanputra/opt/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/Users/andalanputra/opt/anaconda3/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
      "  warn(\n",
      "/Users/andalanputra/opt/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/Users/andalanputra/opt/anaconda3/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
      "  warn(\n",
      "/Users/andalanputra/opt/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/Users/andalanputra/opt/anaconda3/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
      "  warn(\n",
      "/Users/andalanputra/opt/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/Users/andalanputra/opt/anaconda3/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
      "  warn(\n",
      "/Users/andalanputra/opt/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/Users/andalanputra/opt/anaconda3/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
      "  warn(\n",
      "/Users/andalanputra/opt/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/Users/andalanputra/opt/anaconda3/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
      "  warn(\n",
      "/Users/andalanputra/opt/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/Users/andalanputra/opt/anaconda3/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
      "  warn(\n",
      "/Users/andalanputra/opt/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/Users/andalanputra/opt/anaconda3/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
      "  warn(\n",
      "/Users/andalanputra/opt/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/Users/andalanputra/opt/anaconda3/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
      "  warn(\n",
      "/Users/andalanputra/opt/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/Users/andalanputra/opt/anaconda3/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
      "  warn(\n",
      "/Users/andalanputra/opt/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/Users/andalanputra/opt/anaconda3/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
      "  warn(\n",
      "/Users/andalanputra/opt/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/Users/andalanputra/opt/anaconda3/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
      "  warn(\n",
      "/Users/andalanputra/opt/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/Users/andalanputra/opt/anaconda3/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
      "  warn(\n",
      "/Users/andalanputra/opt/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/Users/andalanputra/opt/anaconda3/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
      "  warn(\n",
      "/Users/andalanputra/opt/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/Users/andalanputra/opt/anaconda3/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
      "  warn(\n",
      "/Users/andalanputra/opt/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/Users/andalanputra/opt/anaconda3/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
      "  warn(\n",
      "/Users/andalanputra/opt/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/Users/andalanputra/opt/anaconda3/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
      "  warn(\n",
      "/Users/andalanputra/opt/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/Users/andalanputra/opt/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/Users/andalanputra/opt/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/Users/andalanputra/opt/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/Users/andalanputra/opt/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/Users/andalanputra/opt/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/Users/andalanputra/opt/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/Users/andalanputra/opt/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/Users/andalanputra/opt/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/Users/andalanputra/opt/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/Users/andalanputra/opt/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_search.py:909: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  self.best_estimator_.fit(X, y, **fit_params)\n",
      "/Users/andalanputra/opt/anaconda3/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
      "  warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-2 {color: black;background-color: white;}#sk-container-id-2 pre{padding: 0;}#sk-container-id-2 div.sk-toggleable {background-color: white;}#sk-container-id-2 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-2 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-2 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-2 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-2 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-2 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-2 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-2 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-2 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-2 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-2 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-2 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-2 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-2 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-2 div.sk-item {position: relative;z-index: 1;}#sk-container-id-2 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-2 div.sk-item::before, #sk-container-id-2 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-2 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-2 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-2 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-2 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-2 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-2 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-2 div.sk-label-container {text-align: center;}#sk-container-id-2 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-2 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-2\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>RandomizedSearchCV(cv=5, estimator=RandomForestRegressor(), n_jobs=-1,\n",
       "                   param_distributions={&#x27;max_depth&#x27;: [None, 10, 50, 100],\n",
       "                                        &#x27;max_features&#x27;: [&#x27;auto&#x27;, &#x27;sqrt&#x27;],\n",
       "                                        &#x27;min_samples_leaf&#x27;: [1, 2, 4],\n",
       "                                        &#x27;min_samples_split&#x27;: [2, 5, 10],\n",
       "                                        &#x27;n_estimators&#x27;: [100, 300, 500]},\n",
       "                   scoring=&#x27;neg_mean_absolute_error&#x27;)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" ><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">RandomizedSearchCV</label><div class=\"sk-toggleable__content\"><pre>RandomizedSearchCV(cv=5, estimator=RandomForestRegressor(), n_jobs=-1,\n",
       "                   param_distributions={&#x27;max_depth&#x27;: [None, 10, 50, 100],\n",
       "                                        &#x27;max_features&#x27;: [&#x27;auto&#x27;, &#x27;sqrt&#x27;],\n",
       "                                        &#x27;min_samples_leaf&#x27;: [1, 2, 4],\n",
       "                                        &#x27;min_samples_split&#x27;: [2, 5, 10],\n",
       "                                        &#x27;n_estimators&#x27;: [100, 300, 500]},\n",
       "                   scoring=&#x27;neg_mean_absolute_error&#x27;)</pre></div></div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-3\" type=\"checkbox\" ><label for=\"sk-estimator-id-3\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">estimator: RandomForestRegressor</label><div class=\"sk-toggleable__content\"><pre>RandomForestRegressor()</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-4\" type=\"checkbox\" ><label for=\"sk-estimator-id-4\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">RandomForestRegressor</label><div class=\"sk-toggleable__content\"><pre>RandomForestRegressor()</pre></div></div></div></div></div></div></div></div></div></div>"
      ],
      "text/plain": [
       "RandomizedSearchCV(cv=5, estimator=RandomForestRegressor(), n_jobs=-1,\n",
       "                   param_distributions={'max_depth': [None, 10, 50, 100],\n",
       "                                        'max_features': ['auto', 'sqrt'],\n",
       "                                        'min_samples_leaf': [1, 2, 4],\n",
       "                                        'min_samples_split': [2, 5, 10],\n",
       "                                        'n_estimators': [100, 300, 500]},\n",
       "                   scoring='neg_mean_absolute_error')"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rscv.fit(X_train1, y_train1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'n_estimators': 300,\n",
       " 'min_samples_split': 10,\n",
       " 'min_samples_leaf': 1,\n",
       " 'max_features': 'auto',\n",
       " 'max_depth': None}"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rscv.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['rscv_rf_tfidf_best_params_cbn.pkl']"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "joblib.dump(rscv, \"rscv_rf_tfidf_cbn.pkl\")\n",
    "joblib.dump(rscv.best_params_, \"rscv_rf_tfidf_best_params_cbn.pkl\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "RF (after Hyperparameter Tuning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/y1/pjvjlkjn5gl846rnyzr53p340000gn/T/ipykernel_7227/4198016399.py:2: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  rfreg_ht.fit(X_train1, y_train1)\n",
      "/Users/andalanputra/opt/anaconda3/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
      "  warn(\n"
     ]
    }
   ],
   "source": [
    "rfreg_ht = RandomForestRegressor(n_estimators = 300, min_samples_split = 10, min_samples_leaf = 1, max_features = 'auto', max_depth = None)\n",
    "rfreg_ht.fit(X_train1, y_train1)\n",
    "y_pred_rfreg = rfreg_ht.predict(X_val)\n",
    "y_pred_rfreg_r2 = rfreg_ht.predict(X_train1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.04784739106829041"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mean_absolute_error(y_val, y_pred_rfreg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.009130876066277972"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mean_squared_error(y_val, y_pred_rfreg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.09555561765944466"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mean_squared_error(y_val, y_pred_rfreg, squared = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9663607424425537"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#train\n",
    "r2_score(y_train1, y_pred_rfreg_r2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9068213901613785"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#val\n",
    "r2_score(y_val, y_pred_rfreg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Residual plots after Hyperparameter Tuning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Predicting model on the test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_rfreg_test = rfreg_ht.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['y_test_rfreg_tfidf_cbn.pkl']"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "joblib.dump(y_pred_rfreg_test, \"y_pred_rfreg_test_tfidf_cbn.pkl\")\n",
    "joblib.dump(y_test, \"y_test_rfreg_tfidf_cbn.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.04536307661477879"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mean_absolute_error(y_test, y_pred_rfreg_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.008335479732625052"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mean_squared_error(y_test, y_pred_rfreg_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.09129884847370777"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mean_squared_error(y_test, y_pred_rfreg_test, squared = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9155348846204162"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "r2_score(y_test, y_pred_rfreg_test)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Error analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 576x432 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 432x288 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# assume y_pred is a numpy array and y_true is a pandas dataframe\n",
    "fig, ax = plt.subplots(figsize=(8, 6))\n",
    "\n",
    "column = \"X..CBN\"  # specify the target variable name\n",
    "ax.hist(y_pred_rfreg_test, alpha=0.5, label='y_pred', bins=20)\n",
    "ax.hist(y_test[column], alpha=0.5, label='y_true', bins=20)\n",
    "ax.legend(loc='upper right')\n",
    "ax.set_title(column)\n",
    "\n",
    "plt.show()\n",
    "plt.savefig('error_hist_knn_tfidf_cbn.png')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pearson R"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pearson correlation coefficient: 0.959\n",
      "P-value: 0.000\n"
     ]
    }
   ],
   "source": [
    "corr_coef, p_value = pearsonr(y_pred_rfreg_test.flatten(), y_test.values.ravel())\n",
    "\n",
    "print(f\"Pearson correlation coefficient: {corr_coef:.3f}\")\n",
    "print(f\"P-value: {p_value:.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:>"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "corr_matrix = y_test.corr()\n",
    "sns.heatmap(corr_matrix, annot=True, cmap='coolwarm', center=0)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
