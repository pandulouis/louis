{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn import preprocessing\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.neural_network import MLPRegressor\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "from sklearn.metrics import r2_score\n",
    "from scipy.stats import pearsonr\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.feature_selection import SelectFromModel\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compiling complete dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_rf = pd.read_csv(\"df_linalol_tfidf.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['index',\n",
       " 'tfidf_0',\n",
       " 'tfidf_1',\n",
       " 'tfidf_2',\n",
       " 'tfidf_3',\n",
       " 'tfidf_4',\n",
       " 'tfidf_5',\n",
       " 'tfidf_6',\n",
       " 'tfidf_7',\n",
       " 'tfidf_8',\n",
       " 'tfidf_9',\n",
       " 'tfidf_10',\n",
       " 'tfidf_11',\n",
       " 'tfidf_12',\n",
       " 'tfidf_13',\n",
       " 'tfidf_14',\n",
       " 'tfidf_15',\n",
       " 'tfidf_16',\n",
       " 'tfidf_17',\n",
       " 'tfidf_18',\n",
       " 'tfidf_19',\n",
       " 'tfidf_20',\n",
       " 'tfidf_21',\n",
       " 'tfidf_22',\n",
       " 'tfidf_23',\n",
       " 'tfidf_24',\n",
       " 'tfidf_25',\n",
       " 'tfidf_26',\n",
       " 'tfidf_27',\n",
       " 'tfidf_28',\n",
       " 'tfidf_29',\n",
       " 'tfidf_30',\n",
       " 'tfidf_31',\n",
       " 'tfidf_32',\n",
       " 'tfidf_33',\n",
       " 'tfidf_34',\n",
       " 'tfidf_35',\n",
       " 'tfidf_36',\n",
       " 'tfidf_37',\n",
       " 'tfidf_38',\n",
       " 'tfidf_39',\n",
       " 'tfidf_40',\n",
       " 'tfidf_41',\n",
       " 'tfidf_42',\n",
       " 'tfidf_43',\n",
       " 'tfidf_44',\n",
       " 'tfidf_45',\n",
       " 'tfidf_46',\n",
       " 'tfidf_47',\n",
       " 'tfidf_48',\n",
       " 'tfidf_49',\n",
       " 'tfidf_50',\n",
       " 'tfidf_51',\n",
       " 'tfidf_52',\n",
       " 'tfidf_53',\n",
       " 'tfidf_54',\n",
       " 'tfidf_55',\n",
       " 'tfidf_56',\n",
       " 'tfidf_57',\n",
       " 'tfidf_58',\n",
       " 'tfidf_59',\n",
       " 'tfidf_60',\n",
       " 'tfidf_61',\n",
       " 'tfidf_62',\n",
       " 'tfidf_63',\n",
       " 'tfidf_64',\n",
       " 'tfidf_65',\n",
       " 'tfidf_66',\n",
       " 'tfidf_67',\n",
       " 'tfidf_68',\n",
       " 'tfidf_69',\n",
       " 'tfidf_70',\n",
       " 'tfidf_71',\n",
       " 'tfidf_72',\n",
       " 'tfidf_73',\n",
       " 'tfidf_74',\n",
       " 'tfidf_75',\n",
       " 'tfidf_76',\n",
       " 'tfidf_77',\n",
       " 'tfidf_78',\n",
       " 'tfidf_79',\n",
       " 'tfidf_80',\n",
       " 'tfidf_81',\n",
       " 'tfidf_82',\n",
       " 'tfidf_83',\n",
       " 'tfidf_84',\n",
       " 'tfidf_85',\n",
       " 'tfidf_86',\n",
       " 'tfidf_87',\n",
       " 'tfidf_88',\n",
       " 'tfidf_89',\n",
       " 'tfidf_90',\n",
       " 'tfidf_91',\n",
       " 'tfidf_92',\n",
       " 'tfidf_93',\n",
       " 'tfidf_94',\n",
       " 'tfidf_95',\n",
       " 'tfidf_96',\n",
       " 'tfidf_97',\n",
       " 'tfidf_98',\n",
       " 'tfidf_99',\n",
       " 'tfidf_100',\n",
       " 'tfidf_101',\n",
       " 'tfidf_102',\n",
       " 'tfidf_103',\n",
       " 'tfidf_104',\n",
       " 'tfidf_105',\n",
       " 'tfidf_106',\n",
       " 'tfidf_107',\n",
       " 'tfidf_108',\n",
       " 'tfidf_109',\n",
       " 'tfidf_110',\n",
       " 'tfidf_111',\n",
       " 'tfidf_112',\n",
       " 'tfidf_113',\n",
       " 'tfidf_114',\n",
       " 'tfidf_115',\n",
       " 'tfidf_116',\n",
       " 'tfidf_117',\n",
       " 'tfidf_118',\n",
       " 'tfidf_119',\n",
       " 'tfidf_120',\n",
       " 'tfidf_121',\n",
       " 'tfidf_122',\n",
       " 'tfidf_123',\n",
       " 'tfidf_124',\n",
       " 'tfidf_125',\n",
       " 'tfidf_126',\n",
       " 'tfidf_127',\n",
       " 'tfidf_128',\n",
       " 'tfidf_129',\n",
       " 'tfidf_130',\n",
       " 'tfidf_131',\n",
       " 'tfidf_132',\n",
       " 'tfidf_133',\n",
       " 'tfidf_134',\n",
       " 'tfidf_135',\n",
       " 'tfidf_136',\n",
       " 'tfidf_137',\n",
       " 'tfidf_138',\n",
       " 'tfidf_139',\n",
       " 'tfidf_140',\n",
       " 'tfidf_141',\n",
       " 'tfidf_142',\n",
       " 'tfidf_143',\n",
       " 'tfidf_144',\n",
       " 'tfidf_145',\n",
       " 'tfidf_146',\n",
       " 'tfidf_147',\n",
       " 'tfidf_148',\n",
       " 'tfidf_149',\n",
       " 'tfidf_150',\n",
       " 'tfidf_151',\n",
       " 'tfidf_152',\n",
       " 'tfidf_153',\n",
       " 'tfidf_154',\n",
       " 'tfidf_155',\n",
       " 'tfidf_156',\n",
       " 'tfidf_157',\n",
       " 'tfidf_158',\n",
       " 'tfidf_159',\n",
       " 'tfidf_160',\n",
       " 'tfidf_161',\n",
       " 'tfidf_162',\n",
       " 'tfidf_163',\n",
       " 'tfidf_164',\n",
       " 'tfidf_165',\n",
       " 'tfidf_166',\n",
       " 'tfidf_167',\n",
       " 'tfidf_168',\n",
       " 'tfidf_169',\n",
       " 'tfidf_170',\n",
       " 'tfidf_171',\n",
       " 'tfidf_172',\n",
       " 'tfidf_173',\n",
       " 'tfidf_174',\n",
       " 'tfidf_175',\n",
       " 'tfidf_176',\n",
       " 'tfidf_177',\n",
       " 'tfidf_178',\n",
       " 'tfidf_179',\n",
       " 'tfidf_180',\n",
       " 'tfidf_181',\n",
       " 'tfidf_182',\n",
       " 'tfidf_183',\n",
       " 'tfidf_184',\n",
       " 'tfidf_185',\n",
       " 'tfidf_186',\n",
       " 'tfidf_187',\n",
       " 'tfidf_188',\n",
       " 'tfidf_189',\n",
       " 'tfidf_190',\n",
       " 'tfidf_191',\n",
       " 'tfidf_192',\n",
       " 'tfidf_193',\n",
       " 'tfidf_194',\n",
       " 'tfidf_195',\n",
       " 'tfidf_196',\n",
       " 'tfidf_197',\n",
       " 'tfidf_198',\n",
       " 'tfidf_199',\n",
       " 'tfidf_200',\n",
       " 'tfidf_201',\n",
       " 'tfidf_202',\n",
       " 'tfidf_203',\n",
       " 'tfidf_204',\n",
       " 'tfidf_205',\n",
       " 'tfidf_206',\n",
       " 'tfidf_207',\n",
       " 'tfidf_208',\n",
       " 'tfidf_209',\n",
       " 'tfidf_210',\n",
       " 'tfidf_211',\n",
       " 'tfidf_212',\n",
       " 'tfidf_213',\n",
       " 'tfidf_214',\n",
       " 'tfidf_215',\n",
       " 'tfidf_216',\n",
       " 'tfidf_217',\n",
       " 'tfidf_218',\n",
       " 'tfidf_219',\n",
       " 'tfidf_220',\n",
       " 'tfidf_221',\n",
       " 'tfidf_222',\n",
       " 'tfidf_223',\n",
       " 'tfidf_224',\n",
       " 'tfidf_225',\n",
       " 'tfidf_226',\n",
       " 'tfidf_227',\n",
       " 'tfidf_228',\n",
       " 'tfidf_229',\n",
       " 'tfidf_230',\n",
       " 'tfidf_231',\n",
       " 'tfidf_232',\n",
       " 'tfidf_233',\n",
       " 'tfidf_234',\n",
       " 'tfidf_235',\n",
       " 'tfidf_236',\n",
       " 'tfidf_237',\n",
       " 'tfidf_238',\n",
       " 'tfidf_239',\n",
       " 'tfidf_240',\n",
       " 'tfidf_241',\n",
       " 'tfidf_242',\n",
       " 'tfidf_243',\n",
       " 'tfidf_244',\n",
       " 'tfidf_245',\n",
       " 'tfidf_246',\n",
       " 'tfidf_247',\n",
       " 'tfidf_248',\n",
       " 'tfidf_249',\n",
       " 'tfidf_250',\n",
       " 'tfidf_251',\n",
       " 'tfidf_252',\n",
       " 'tfidf_253',\n",
       " 'tfidf_254',\n",
       " 'tfidf_255',\n",
       " 'tfidf_256',\n",
       " 'tfidf_257',\n",
       " 'tfidf_258',\n",
       " 'tfidf_259',\n",
       " 'tfidf_260',\n",
       " 'tfidf_261',\n",
       " 'tfidf_262',\n",
       " 'tfidf_263',\n",
       " 'tfidf_264',\n",
       " 'tfidf_265',\n",
       " 'tfidf_266',\n",
       " 'tfidf_267',\n",
       " 'tfidf_268',\n",
       " 'tfidf_269',\n",
       " 'tfidf_270',\n",
       " 'tfidf_271',\n",
       " 'tfidf_272',\n",
       " 'tfidf_273',\n",
       " 'tfidf_274',\n",
       " 'tfidf_275',\n",
       " 'tfidf_276',\n",
       " 'tfidf_277',\n",
       " 'tfidf_278',\n",
       " 'tfidf_279',\n",
       " 'tfidf_280',\n",
       " 'tfidf_281',\n",
       " 'tfidf_282',\n",
       " 'tfidf_283',\n",
       " 'tfidf_284',\n",
       " 'tfidf_285',\n",
       " 'tfidf_286',\n",
       " 'tfidf_287',\n",
       " 'tfidf_288',\n",
       " 'tfidf_289',\n",
       " 'tfidf_290',\n",
       " 'tfidf_291',\n",
       " 'tfidf_292',\n",
       " 'tfidf_293',\n",
       " 'tfidf_294',\n",
       " 'tfidf_295',\n",
       " 'tfidf_296',\n",
       " 'tfidf_297',\n",
       " 'tfidf_298',\n",
       " 'tfidf_299',\n",
       " 'tfidf_300',\n",
       " 'tfidf_301',\n",
       " 'tfidf_302',\n",
       " 'tfidf_303',\n",
       " 'tfidf_304',\n",
       " 'tfidf_305',\n",
       " 'tfidf_306',\n",
       " 'tfidf_307',\n",
       " 'tfidf_308',\n",
       " 'tfidf_309',\n",
       " 'tfidf_310',\n",
       " 'tfidf_311',\n",
       " 'tfidf_312',\n",
       " 'tfidf_313',\n",
       " 'tfidf_314',\n",
       " 'tfidf_315',\n",
       " 'tfidf_316',\n",
       " 'tfidf_317',\n",
       " 'tfidf_318',\n",
       " 'tfidf_319',\n",
       " 'tfidf_320',\n",
       " 'tfidf_321',\n",
       " 'tfidf_322',\n",
       " 'tfidf_323',\n",
       " 'tfidf_324',\n",
       " 'tfidf_325',\n",
       " 'tfidf_326',\n",
       " 'tfidf_327',\n",
       " 'tfidf_328',\n",
       " 'tfidf_329',\n",
       " 'tfidf_330',\n",
       " 'tfidf_331',\n",
       " 'tfidf_332',\n",
       " 'tfidf_333',\n",
       " 'tfidf_334',\n",
       " 'tfidf_335',\n",
       " 'tfidf_336',\n",
       " 'tfidf_337',\n",
       " 'tfidf_338',\n",
       " 'tfidf_339',\n",
       " 'tfidf_340',\n",
       " 'tfidf_341',\n",
       " 'tfidf_342',\n",
       " 'tfidf_343',\n",
       " 'tfidf_344',\n",
       " 'tfidf_345',\n",
       " 'tfidf_346',\n",
       " 'tfidf_347',\n",
       " 'tfidf_348',\n",
       " 'tfidf_349',\n",
       " 'tfidf_350',\n",
       " 'tfidf_351',\n",
       " 'tfidf_352',\n",
       " 'tfidf_353',\n",
       " 'tfidf_354',\n",
       " 'tfidf_355',\n",
       " 'tfidf_356',\n",
       " 'tfidf_357',\n",
       " 'tfidf_358',\n",
       " 'tfidf_359',\n",
       " 'tfidf_360',\n",
       " 'tfidf_361',\n",
       " 'tfidf_362',\n",
       " 'tfidf_363',\n",
       " 'tfidf_364',\n",
       " 'tfidf_365',\n",
       " 'tfidf_366',\n",
       " 'tfidf_367',\n",
       " 'tfidf_368',\n",
       " 'tfidf_369',\n",
       " 'tfidf_370',\n",
       " 'tfidf_371',\n",
       " 'tfidf_372',\n",
       " 'tfidf_373',\n",
       " 'tfidf_374',\n",
       " 'tfidf_375',\n",
       " 'tfidf_376',\n",
       " 'tfidf_377',\n",
       " 'tfidf_378',\n",
       " 'tfidf_379',\n",
       " 'tfidf_380',\n",
       " 'tfidf_381',\n",
       " 'tfidf_382',\n",
       " 'tfidf_383',\n",
       " 'tfidf_384',\n",
       " 'tfidf_385',\n",
       " 'tfidf_386',\n",
       " 'tfidf_387',\n",
       " 'hybrid',\n",
       " 'indica',\n",
       " 'sativa',\n",
       " 'anxiety',\n",
       " 'anxious',\n",
       " 'aroused',\n",
       " 'arthritis',\n",
       " 'creative',\n",
       " 'depression',\n",
       " 'dizzy',\n",
       " 'dry eyes',\n",
       " 'dry mouth',\n",
       " 'energetic',\n",
       " 'epilepsy',\n",
       " 'euphoric',\n",
       " 'eye pressure',\n",
       " 'fatigue',\n",
       " 'focused',\n",
       " 'giggly',\n",
       " 'happy',\n",
       " 'headache',\n",
       " 'hungry',\n",
       " 'migraines',\n",
       " 'pain',\n",
       " 'paranoid',\n",
       " 'relaxed',\n",
       " 'seizures',\n",
       " 'sleepy',\n",
       " 'spasticity',\n",
       " 'stress',\n",
       " 'talkative',\n",
       " 'tingly',\n",
       " 'uplifted',\n",
       " 'ammonia',\n",
       " 'apple',\n",
       " 'apricot',\n",
       " 'berry',\n",
       " 'blue cheese',\n",
       " 'blueberry',\n",
       " 'butter',\n",
       " 'cheese',\n",
       " 'chemical',\n",
       " 'chestnut',\n",
       " 'citrus',\n",
       " 'coffee',\n",
       " 'diesel',\n",
       " 'earthy',\n",
       " 'flowery',\n",
       " 'fruit',\n",
       " 'grape',\n",
       " 'grapefruit',\n",
       " 'honey',\n",
       " 'lavender',\n",
       " 'lemon',\n",
       " 'lime',\n",
       " 'mango',\n",
       " 'menthol',\n",
       " 'mint',\n",
       " 'nutty',\n",
       " 'orange',\n",
       " 'peach',\n",
       " 'pear',\n",
       " 'pepper',\n",
       " 'pine',\n",
       " 'pineapple',\n",
       " 'plum',\n",
       " 'pungent',\n",
       " 'rose',\n",
       " 'sage',\n",
       " 'skunk',\n",
       " 'spicy/herbal',\n",
       " 'strawberry',\n",
       " 'sweet',\n",
       " 'tar',\n",
       " 'tea',\n",
       " 'tobacco',\n",
       " 'tree',\n",
       " 'tropical',\n",
       " 'vanilla',\n",
       " 'violet',\n",
       " 'woody',\n",
       " 'X..Linalool']"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_rf.columns.to_list()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Splitting dependent and independent variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df_rf.drop(['index', 'X..Linalool'], axis = 1)\n",
    "y = df_rf[['X..Linalool']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plotting histograms on target variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.5   ],\n",
       "       [0.5   ],\n",
       "       [0.5   ],\n",
       "       ...,\n",
       "       [0.0625],\n",
       "       [0.0625],\n",
       "       [0.0625]])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_array = y.to_numpy()\n",
    "y_array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:ylabel='Count'>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAZIAAAD4CAYAAADGmmByAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjQuMywgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/MnkTPAAAACXBIWXMAAAsTAAALEwEAmpwYAAAZm0lEQVR4nO3dfZBV9Z3n8fcngGASITy0LqG76XbCOoKlpXSQibMTDBMl6gbcwlkyTiBZsh3RcTVuHDGpWje1RaKJpayZlRRRF8xmIQzjRLIzZGAw0UmFB5tIeAxjGxTuwEj7MNGKwQh+94/7I167b3ff7tP3Xi79eVXduud+z/md8/spdT99Hq8iAjMzs/56T7U7YGZmtc1BYmZmmThIzMwsEweJmZll4iAxM7NMhla7A5U2bty4aGpqqnY3zMxqyvbt21+KiLpi8wZdkDQ1NdHW1lbtbpiZ1RRJL3Q3z4e2zMwsEweJmZll4iAxM7NMBt05kmLeeustcrkcx44dq3ZXTjsjRoygvr6eYcOGVbsrZlYmDhIgl8tx1lln0dTUhKRqd+e0ERG8/PLL5HI5mpubq90dMysTH9oCjh07xtixYx0iA0wSY8eO9Z6e2WnOQZI4RMrD/13NTn8OEjMzy8RBUkRD40QkDdiroXFij9s7dOgQzc3NvPLKKwC8+uqrNDc388IL3d7/w2c+8xnWrl37rtrhw4eZO3duv8c9Y8aMft+s2dTUxEsvvdTvbZtZ7fLJ9iJyhw5y34b9A7a+2644r8f5DQ0NLFq0iMWLF7N8+XIWL15Ma2srEyf2HECdffCDH+wSLmZ2amlonEju0MGqbLu+oZFDB7v/A7W/HCSniC984QtMnTqVpUuX8pOf/IRvfvObfV7H888/zzXXXMPu3btZsWIF69at44033uC5557j2muv5etf/zoAixYt4umnn+Y3v/kNc+fO5Stf+UqXda1atYqvfvWrRARXX30199xzT491MyvNQP+h2he9/VHbXw6SU8SwYcP4xje+waxZs9iwYQNnnHFG5nXu2LGDZ555huHDh3Peeedx880309DQwJIlSxgzZgwnTpxg5syZ7Ny5kwsvvPB37Q4fPswdd9zB9u3bGT16NFdccQXf//73mTZtWtH6nDlzMvfVzGqXz5GcQtavX8/48ePZvXv3gKxv5syZjBo1ihEjRjB58uTfnXNZs2YNl1xyCRdffDF79uxh796972r39NNPM2PGDOrq6hg6dCjXX389Tz31VLd1MxvcHCSniB07drBx40a2bNnC/fffz5EjRzKvc/jw4b+bHjJkCMePH+fAgQPce++9bNq0iZ07d3L11Vd3uc8jIoqur7u6mQ1uDpJTQESwaNEili5dSmNjI7fffjtf/OIXy7Kt1157jfe9732MGjWKF198kfXr13dZ5tJLL+XJJ5/kpZde4sSJE6xatYqPfvSj3dbNbHDzOZIi6hsaB/SkVH1DY4/zv/3tb9PY2MjHP/5xAG688UZWrFjBk08+yS233MKOHTsA+NznPscNN9xAS0sLAJ///Oe59dZbgfyVX6tWreq1LxdddBEXX3wxU6ZM4dxzz+Wyyy7rssz48eP52te+xuWXX05EcNVVVzF79myAbutmNnhpsB2uaGlpic73Suzbt4/zzz+/Sj06/fm/r9k7JFX1qq3+fudL2h4RLcXm+dCWmZll4iAxM7NMyhYkkh6RdFRSl2tZJX1RUkgaV1C7U1K7pP2SriyoT5W0K817QOkpgJKGS/peqm+V1JSlv4PtEF+l+L+r2emvnHskK4BZnYuSGoCPAwcLapOBecCU1OZBSUPS7GVAKzApvU6ucyHwakR8CLgf6Pct1iNGjODll1/2l94AO/l7JCNGjKh2V8ysjMp21VZEPNXNXsL9wF8AjxfUZgOrI+JN4ICkdmCapOeBkRGxGUDSo8AcYH1q899T+7XAX0pS9CMN6uvryeVydHR09LWp9eLkLySa2emropf/Svok8M8R8fNOv1MxAdhS8DmXam+l6c71k20OAUTEcUm/AsYCfX4E7bBhw/wLfmZm/VSxIJH0XuDLwBXFZhepRQ/1ntoU23Yr+cNjNDb2fE+HmZn1TSWv2vo9oBn4eTpkVQ/8TNK/Ib+n0VCwbD1wONXri9QpbCNpKDAKeKXYhiNieUS0RERLXV3dgA3IzMwqGCQRsSsizo6IpohoIh8El0TEvwDrgHnpSqxm8ifVt0XEEeB1SdPT1VrzeefcyjpgQZqeCzzRn/MjZmaWTTkv/10FbAbOk5STtLC7ZSNiD7AG2Av8ELgpIk6k2YuAh4B24DnyJ9oBHgbGphPztwGLyzIQMzPrUTmv2vpUL/ObOn1eAiwpslwbcEGR+jHgumy9NDOzrHxnu5mZZeIgMTOzTBwkZmaWiYPEzMwycZCYmVkmDhIzM8vEQWJmZpk4SMzMLBMHiZmZZeIgMTOzTBwkZmaWiYPEzMwycZCYmVkmDhIzM8vEQWJmZpk4SMzMLBMHiZmZZeIgMTOzTBwkZmaWSdmCRNIjko5K2l1Q+4akX0jaKelvJH2gYN6dktol7Zd0ZUF9qqRdad4DkpTqwyV9L9W3Smoq11jMzKx75dwjWQHM6lTbCFwQERcC/wTcCSBpMjAPmJLaPChpSGqzDGgFJqXXyXUuBF6NiA8B9wP3lG0kZmbWrbIFSUQ8BbzSqbYhIo6nj1uA+jQ9G1gdEW9GxAGgHZgmaTwwMiI2R0QAjwJzCtqsTNNrgZkn91bMzKxyqnmO5D8B69P0BOBQwbxcqk1I053r72qTwulXwNhiG5LUKqlNUltHR8eADcDMzKoUJJK+DBwHvnuyVGSx6KHeU5uuxYjlEdESES11dXV97a6ZmfWg4kEiaQFwDXB9OlwF+T2NhoLF6oHDqV5fpP6uNpKGAqPodCjNzMzKr6JBImkWcAfwyYh4o2DWOmBeuhKrmfxJ9W0RcQR4XdL0dP5jPvB4QZsFaXou8ERBMJmZWYUMLdeKJa0CZgDjJOWAu8hfpTUc2JjOi2+JiBsiYo+kNcBe8oe8boqIE2lVi8hfAXYm+XMqJ8+rPAx8R1I7+T2ReeUai5mZda9sQRIRnypSfriH5ZcAS4rU24ALitSPAddl6aOZmWXnO9vNzCwTB4mZmWXiIDEzs0wcJGZmlomDxMzMMnGQmJlZJg4SMzPLxEFiZmaZOEjMzCwTB4mZmWXiIDEzs0wcJGZmlomDxMzMMnGQmJlZJg4SMzPLxEFiZmaZOEjMzCwTB4mZmWXiIDEzs0zKFiSSHpF0VNLugtoYSRslPZveRxfMu1NSu6T9kq4sqE+VtCvNe0CSUn24pO+l+lZJTeUai5mZda+ceyQrgFmdaouBTRExCdiUPiNpMjAPmJLaPChpSGqzDGgFJqXXyXUuBF6NiA8B9wP3lG0kZmbWrbIFSUQ8BbzSqTwbWJmmVwJzCuqrI+LNiDgAtAPTJI0HRkbE5ogI4NFObU6uay0w8+TeipmZVU6lz5GcExFHANL72ak+AThUsFwu1Sak6c71d7WJiOPAr4CxxTYqqVVSm6S2jo6OARqKmZnBqXOyvdieRPRQ76lN12LE8ohoiYiWurq6fnbRzMyKqXSQvJgOV5Hej6Z6DmgoWK4eOJzq9UXq72ojaSgwiq6H0szMrMwqHSTrgAVpegHweEF9XroSq5n8SfVt6fDX65Kmp/Mf8zu1ObmuucAT6TyKDaCGxolIqsqroXFitYdvZiUYWq4VS1oFzADGScoBdwF3A2skLQQOAtcBRMQeSWuAvcBx4KaIOJFWtYj8FWBnAuvTC+Bh4DuS2snvicwr11gGs9yhg9y3YX9Vtn3bFedVZbtm1jdlC5KI+FQ3s2Z2s/wSYEmRehtwQZH6MVIQmZlZ9ZwqJ9vNzKxGOUjMzCwTB4mZmWXiIDEzs0wcJGZmlomDxMzMMnGQmJlZJg4SMzPLxEFiZmaZOEjMzCwTB4mZmWVSUpBIuqyUmpmZDT6l7pF8s8SamZkNMj0+/VfSHwAfAeok3VYwayQwpJwdMzOz2tDbY+TPAN6fljuroP4a+R+TMjOzQa7HIImIJ4EnJa2IiBcq1CczM6shpf6w1XBJy4GmwjYR8bFydMrMzGpHqUHyV8C3gIeAE70sa2Zmg0ipV20dj4hlEbEtIraffPV3o5K+IGmPpN2SVkkaIWmMpI2Snk3vowuWv1NSu6T9kq4sqE+VtCvNe0CS+tsnMzPrn1KD5AeSbpQ0Pn3hj5E0pj8blDQB+C9AS0RcQP7qr3nAYmBTREwCNqXPSJqc5k8BZgEPSjp5xdgyoBWYlF6z+tMnMzPrv1KDZAFwO/BTYHt6tWXY7lDgTElDgfcCh4HZwMo0fyUwJ03PBlZHxJsRcQBoB6ZJGg+MjIjNERHAowVtyqKhcSKSqvJqaJxYzqGZmfVbSedIIqJ5oDYYEf8s6V7gIPAbYENEbJB0TkQcScsckXR2ajIB2FKwilyqvZWmO9e7kNRKfs+FxsbGfvc9d+gg923Y3+/2Wdx2xXlV2a6ZWW9KChJJ84vVI+LRvm4wnfuYDTQD/wr8laQ/66lJsU33UO9ajFgOLAdoaWkpuoyZmfVPqVdtfbhgegQwE/gZ+cNJffXHwIGI6ACQ9Bj5u+dflDQ+7Y2MB46m5XNAQ0H7evKHwnJpunPdzPqooXEiuUMHK77d+oZGDh30LWq1rtRDWzcXfpY0CvhOP7d5EJgu6b3kD23NJH++5dfkz8Xcnd4fT8uvA/6vpPuAD5I/qb4tIk5Iel3SdGArMB8//8usX6p12NaHbE8Ppe6RdPYG+S/0PouIrZLWkt+jOQ48Q/6w0/uBNZIWkg+b69LyeyStAfam5W+KiJP3siwCVgBnAuvTy8zMKqjUcyQ/4J3zD0OA84E1/d1oRNwF3NWp/Cb5vZNiyy8BlhSptwEX9LcfZqeSah1eMsuq1D2SewumjwMvRESuu4XNrO98VaDVqpLuI0kPb/wF+ScAjwZ+W85OmZlZ7Sj1FxL/BNhG/rzFnwBbJfkx8mZmVvKhrS8DH46IowCS6oB/ANaWq2NmZlYbSn1EyntOhkjych/amtWUaj0Kx6xWlbpH8kNJfw+sSp//I/B35emSWXX5ngqzvuntN9s/BJwTEbdL+g/AH5J/NMlm4LsV6J+Znc70nqrtjfmu+oHT2x7JUuBLABHxGPAYgKSWNO/fl7FvZna6i7d9yfNpoLfzHE0RsbNzMd0I2FSWHpmZWU3pLUhG9DDvzIHsiJmZ1abeguRpSf+5czE9D6vfP7Vr/ZCOJftKIjM71fR2juRW4G8kXc87wdECnAFcW8Z+WWdVOpbs48hm1psegyQiXgQ+Iuly3nk44t9GxBNl75mZmdWEUn+P5EfAj8rcFzMzq0G+O93MzDJxkJiZWSYOEjMzy8RBYmZmmThIzMwsk6oEiaQPSFor6ReS9kn6A0ljJG2U9Gx6H12w/J2S2iXtl3RlQX2qpF1p3gPyHXRmZhVXrT2S/wn8MCJ+H7gI2AcsBjZFxCRgU/qMpMnAPGAKMAt4UNKQtJ5lQCswKb1mVXIQZmZWhSCRNBL4I+BhgIj4bUT8KzAbWJkWWwnMSdOzgdUR8WZEHADagWmSxgMjI2JzRATwaEEbMzOrkGrskZwLdAD/W9Izkh6S9D7yv3tyBCC9n52WnwAcKmifS7UJabpzvQtJrZLaJLV1dHQM7GjMzAa5agTJUOASYFlEXAz8mnQYqxvFzntED/WuxYjlEdESES11dXV97a+ZmfWgGkGSA3IRsTV9Xks+WF5Mh6tI70cLlm8oaF8PHE71+iJ1MzOroIoHSUT8C3BI0snHys4E9gLrgAWptgB4PE2vA+ZJGi6pmfxJ9W3p8Nfrkqanq7XmF7QxM7MKKemhjWVwM/BdSWcAvwQ+Sz7U1qTfOjkIXAcQEXskrSEfNseBmyLiRFrPImAF+R/ZWp9eZmZWQVUJkojYQf53TTqb2c3yS4AlReptvPN4ezMzqwLf2W5mZpk4SMzMLBMHiZmZZeIgMTOzTBwkZmaWSbUu/zXrnd6DH+hsdupzkNipK97mvg37K77Z2644r/eFzOx3fGjLzMwycZCYmVkmDhIzM8vEQWJmZpk4SMzMLBMHiZmZZeIgMTOzTBwkZmaWiYPEzMwycZCYmVkmDhIzM8ukakEiaYikZyT9v/R5jKSNkp5N76MLlr1TUruk/ZKuLKhPlbQrzXtAfsKfmVnFVXOP5BZgX8HnxcCmiJgEbEqfkTQZmAdMAWYBD0oaktosA1qBSek1qzJdNzOzk6oSJJLqgauBhwrKs4GVaXolMKegvjoi3oyIA0A7ME3SeGBkRGyOiAAeLWhjZmYVUq09kqXAXwBvF9TOiYgjAOn97FSfABwqWC6XahPSdOe6mZlVUMWDRNI1wNGI2F5qkyK16KFebJutktoktXV0dJS4WTMzK0U19kguAz4p6XlgNfAxSf8HeDEdriK9H03L54CGgvb1wOFUry9S7yIilkdES0S01NXVDeRYzMwGvYoHSUTcGRH1EdFE/iT6ExHxZ8A6YEFabAHweJpeB8yTNFxSM/mT6tvS4a/XJU1PV2vNL2hjZmYVcir91O7dwBpJC4GDwHUAEbFH0hpgL3AcuCkiTqQ2i4AVwJnA+vQyM7MKqmqQRMSPgR+n6ZeBmd0stwRYUqTeBlxQvh6amVlvfGe7mZll4iAxM7NMHCRmZpaJg8TMzDJxkJiZWSYOEjMzy8RBYmZmmThIzMwsEweJmZll4iAxM7NMHCRmZpaJg8TMzDJxkJiZWSYOEjMzy8RBYmZmmThIzMwsEweJmZll4iAxM7NMHCRmZpZJxYNEUoOkH0naJ2mPpFtSfYykjZKeTe+jC9rcKald0n5JVxbUp0raleY9IEmVHo+Z2WBXjT2S48B/jYjzgenATZImA4uBTRExCdiUPpPmzQOmALOAByUNSetaBrQCk9JrViUHYmZmVQiSiDgSET9L068D+4AJwGxgZVpsJTAnTc8GVkfEmxFxAGgHpkkaD4yMiM0REcCjBW3MzKxCqnqORFITcDGwFTgnIo5APmyAs9NiE4BDBc1yqTYhTXeuF9tOq6Q2SW0dHR0DOgYzs8GuakEi6f3AXwO3RsRrPS1apBY91LsWI5ZHREtEtNTV1fW9s2Zm1q2qBImkYeRD5LsR8Vgqv5gOV5Hej6Z6DmgoaF4PHE71+iJ1MzOroGpctSXgYWBfRNxXMGsdsCBNLwAeL6jPkzRcUjP5k+rb0uGv1yVNT+ucX9DGzMwqZGgVtnkZ8Glgl6QdqfYl4G5gjaSFwEHgOoCI2CNpDbCX/BVfN0XEidRuEbACOBNYn15mZlZBFQ+SiPgJxc9vAMzsps0SYEmRehtwwcD1zszM+sp3tpuZWSYOEjMzy8RBYmZmmThIzMwsEweJmZll4iAxM7NMHCRmZpaJg8TMzDJxkJiZWSYOEjMzy8RBYmZmmThIzMwsEweJmZll4iAxM7NMHCRmZpaJg8TMzDJxkJiZWSYOEjMzy8RBYmZmmdR8kEiaJWm/pHZJi6vdHzOzwaamg0TSEOB/AZ8AJgOfkjS5ur0yMxtcajpIgGlAe0T8MiJ+C6wGZle5T2Zmg4oiotp96DdJc4FZEfG59PnTwKUR8eedlmsFWtPH84D9/dzkOOClfratVR7z4OAxDw5ZxjwxIuqKzRja//6cElSk1iUZI2I5sDzzxqS2iGjJup5a4jEPDh7z4FCuMdf6oa0c0FDwuR44XKW+mJkNSrUeJE8DkyQ1SzoDmAesq3KfzMwGlZo+tBURxyX9OfD3wBDgkYjYU8ZNZj48VoM85sHBYx4cyjLmmj7ZbmZm1Vfrh7bMzKzKHCRmZpaJg6SI3h67orwH0vydki6pRj8HUgljvj6Ndaekn0q6qBr9HEilPl5H0oclnUj3LdW0UsYsaYakHZL2SHqy0n0cSCX8ux4l6QeSfp7G+9lq9HMgSXpE0lFJu7uZP/DfXxHhV8GL/En754BzgTOAnwOTOy1zFbCe/H0s04Gt1e53Bcb8EWB0mv7EYBhzwXJPAH8HzK12vyvw//kDwF6gMX0+u9r9LvN4vwTck6brgFeAM6rd94zj/iPgEmB3N/MH/PvLeyRdlfLYldnAo5G3BfiApPGV7ugA6nXMEfHTiHg1fdxC/p6dWlbq43VuBv4aOFrJzpVJKWP+U+CxiDgIEBG1PO5SxhvAWZIEvJ98kByvbDcHVkQ8RX4c3Rnw7y8HSVcTgEMFn3Op1tdlaklfx7OQ/F80tazXMUuaAFwLfKuC/SqnUv4//1tgtKQfS9ouaX7FejfwShnvXwLnk7+ReRdwS0S8XZnuVc2Af3/V9H0kZVLKY1dKejRLDSl5PJIuJx8kf1jWHpVfKWNeCtwRESfyf7DWvFLGPBSYCswEzgQ2S9oSEf9U7s6VQSnjvRLYAXwM+D1go6R/jIjXyty3ahrw7y8HSVelPHbldHs0S0njkXQh8BDwiYh4uUJ9K5dSxtwCrE4hMg64StLxiPh+RXo48Er9t/1SRPwa+LWkp4CLgFoMklLG+1ng7sifPGiXdAD4fWBbZbpYFQP+/eVDW12V8tiVdcD8dPXDdOBXEXGk0h0dQL2OWVIj8Bjw6Rr967SzXsccEc0R0RQRTcBa4MYaDhEo7d/248C/kzRU0nuBS4F9Fe7nQCllvAfJ730h6RzyTwf/ZUV7WXkD/v3lPZJOopvHrki6Ic3/FvkreK4C2oE3yP9VU7NKHPN/A8YCD6a/0I9HDT85tcQxn1ZKGXNE7JP0Q2An8DbwUEQUvYz0VFfi/+P/AayQtIv8IZ87IqKmHy0vaRUwAxgnKQfcBQyD8n1/+REpZmaWiQ9tmZlZJg4SMzPLxEFiZmaZOEjMzCwTB4mZmWXiIDEzs0wcJGZmlsn/B25XO3rNV39kAAAAAElFTkSuQmCC",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "sns.histplot(y, bins = 10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train test split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=1, test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train1, X_val, y_train1, y_val = train_test_split(X_train, y_train, random_state=1, test_size=0.25)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "RF modeling (before Feature selection and Hyperparameter Tuning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/y1/pjvjlkjn5gl846rnyzr53p340000gn/T/ipykernel_11392/350139188.py:2: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  rfreg.fit(X_train1, y_train1)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;background-color: white;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>RandomForestRegressor()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">RandomForestRegressor</label><div class=\"sk-toggleable__content\"><pre>RandomForestRegressor()</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "RandomForestRegressor()"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rfreg = RandomForestRegressor()\n",
    "rfreg.fit(X_train1, y_train1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_rfreg = rfreg.predict(X_val)\n",
    "y_pred_rfreg_r2 = rfreg.predict(X_train1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.03783331697686353"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mean_absolute_error(y_val, y_pred_rfreg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0068319635696874196"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mean_squared_error(y_val, y_pred_rfreg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.08265569290549453"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mean_squared_error(y_val, y_pred_rfreg, squared = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9819094879986113"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#train\n",
    "r2_score(y_train1, y_pred_rfreg_r2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9314732644890071"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#val\n",
    "r2_score(y_val, y_pred_rfreg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Residual plots for each target variable"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Feature Selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_feat = pd.DataFrame({\n",
    "    \"features\": X_train1.columns,\n",
    "    \"score\": rfreg.feature_importances_\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>features</th>\n",
       "      <th>score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>tfidf_0</td>\n",
       "      <td>0.004829</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>tfidf_1</td>\n",
       "      <td>0.000898</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>tfidf_2</td>\n",
       "      <td>0.000171</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>tfidf_3</td>\n",
       "      <td>0.000239</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>tfidf_4</td>\n",
       "      <td>0.000489</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>464</th>\n",
       "      <td>tree</td>\n",
       "      <td>0.000098</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>465</th>\n",
       "      <td>tropical</td>\n",
       "      <td>0.000274</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>466</th>\n",
       "      <td>vanilla</td>\n",
       "      <td>0.001207</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>467</th>\n",
       "      <td>violet</td>\n",
       "      <td>0.000020</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>468</th>\n",
       "      <td>woody</td>\n",
       "      <td>0.000434</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>469 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     features     score\n",
       "0     tfidf_0  0.004829\n",
       "1     tfidf_1  0.000898\n",
       "2     tfidf_2  0.000171\n",
       "3     tfidf_3  0.000239\n",
       "4     tfidf_4  0.000489\n",
       "..        ...       ...\n",
       "464      tree  0.000098\n",
       "465  tropical  0.000274\n",
       "466   vanilla  0.001207\n",
       "467    violet  0.000020\n",
       "468     woody  0.000434\n",
       "\n",
       "[469 rows x 2 columns]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_feat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_feat_ranked = df_feat.sort_values(\"score\", ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>features</th>\n",
       "      <th>score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>388</th>\n",
       "      <td>hybrid</td>\n",
       "      <td>2.317947e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>265</th>\n",
       "      <td>tfidf_265</td>\n",
       "      <td>2.948499e-02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>329</th>\n",
       "      <td>tfidf_329</td>\n",
       "      <td>2.757780e-02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>451</th>\n",
       "      <td>pine</td>\n",
       "      <td>2.534950e-02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>428</th>\n",
       "      <td>cheese</td>\n",
       "      <td>2.383988e-02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>168</th>\n",
       "      <td>tfidf_168</td>\n",
       "      <td>1.593202e-02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>447</th>\n",
       "      <td>orange</td>\n",
       "      <td>1.480374e-02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>145</th>\n",
       "      <td>tfidf_145</td>\n",
       "      <td>1.429457e-02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>312</th>\n",
       "      <td>tfidf_312</td>\n",
       "      <td>1.368945e-02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>78</th>\n",
       "      <td>tfidf_78</td>\n",
       "      <td>1.346955e-02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>90</th>\n",
       "      <td>tfidf_90</td>\n",
       "      <td>1.112299e-02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>101</th>\n",
       "      <td>tfidf_101</td>\n",
       "      <td>1.039040e-02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>207</th>\n",
       "      <td>tfidf_207</td>\n",
       "      <td>1.029136e-02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>93</th>\n",
       "      <td>tfidf_93</td>\n",
       "      <td>1.025517e-02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>247</th>\n",
       "      <td>tfidf_247</td>\n",
       "      <td>9.288137e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>149</th>\n",
       "      <td>tfidf_149</td>\n",
       "      <td>8.994027e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>439</th>\n",
       "      <td>honey</td>\n",
       "      <td>8.716900e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>199</th>\n",
       "      <td>tfidf_199</td>\n",
       "      <td>8.713203e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>337</th>\n",
       "      <td>tfidf_337</td>\n",
       "      <td>8.403137e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>426</th>\n",
       "      <td>blueberry</td>\n",
       "      <td>8.390953e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>460</th>\n",
       "      <td>sweet</td>\n",
       "      <td>8.127868e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>345</th>\n",
       "      <td>tfidf_345</td>\n",
       "      <td>8.024269e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>303</th>\n",
       "      <td>tfidf_303</td>\n",
       "      <td>7.882792e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>419</th>\n",
       "      <td>tingly</td>\n",
       "      <td>7.866658e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>tfidf_5</td>\n",
       "      <td>7.540010e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>400</th>\n",
       "      <td>energetic</td>\n",
       "      <td>7.389724e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>285</th>\n",
       "      <td>tfidf_285</td>\n",
       "      <td>7.192997e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>91</th>\n",
       "      <td>tfidf_91</td>\n",
       "      <td>7.093246e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>210</th>\n",
       "      <td>tfidf_210</td>\n",
       "      <td>6.845179e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>433</th>\n",
       "      <td>diesel</td>\n",
       "      <td>6.762598e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>121</th>\n",
       "      <td>tfidf_121</td>\n",
       "      <td>6.586717e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>105</th>\n",
       "      <td>tfidf_105</td>\n",
       "      <td>6.308043e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>154</th>\n",
       "      <td>tfidf_154</td>\n",
       "      <td>6.293928e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>454</th>\n",
       "      <td>pungent</td>\n",
       "      <td>6.128854e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>173</th>\n",
       "      <td>tfidf_173</td>\n",
       "      <td>6.023986e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>385</th>\n",
       "      <td>tfidf_385</td>\n",
       "      <td>5.816422e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>395</th>\n",
       "      <td>creative</td>\n",
       "      <td>5.730880e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>313</th>\n",
       "      <td>tfidf_313</td>\n",
       "      <td>5.684884e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>434</th>\n",
       "      <td>earthy</td>\n",
       "      <td>5.333262e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>189</th>\n",
       "      <td>tfidf_189</td>\n",
       "      <td>5.319822e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>tfidf_20</td>\n",
       "      <td>5.171677e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>tfidf_0</td>\n",
       "      <td>4.828969e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>357</th>\n",
       "      <td>tfidf_357</td>\n",
       "      <td>4.704395e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>407</th>\n",
       "      <td>happy</td>\n",
       "      <td>4.638460e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>166</th>\n",
       "      <td>tfidf_166</td>\n",
       "      <td>4.637811e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>235</th>\n",
       "      <td>tfidf_235</td>\n",
       "      <td>4.568050e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>413</th>\n",
       "      <td>relaxed</td>\n",
       "      <td>4.540796e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>335</th>\n",
       "      <td>tfidf_335</td>\n",
       "      <td>4.482096e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>141</th>\n",
       "      <td>tfidf_141</td>\n",
       "      <td>4.378849e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>348</th>\n",
       "      <td>tfidf_348</td>\n",
       "      <td>4.369225e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>239</th>\n",
       "      <td>tfidf_239</td>\n",
       "      <td>4.194095e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>309</th>\n",
       "      <td>tfidf_309</td>\n",
       "      <td>4.109986e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>245</th>\n",
       "      <td>tfidf_245</td>\n",
       "      <td>4.100112e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>344</th>\n",
       "      <td>tfidf_344</td>\n",
       "      <td>4.022442e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>tfidf_43</td>\n",
       "      <td>3.950554e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>376</th>\n",
       "      <td>tfidf_376</td>\n",
       "      <td>3.754151e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>399</th>\n",
       "      <td>dry mouth</td>\n",
       "      <td>3.636493e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>73</th>\n",
       "      <td>tfidf_73</td>\n",
       "      <td>3.615196e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>415</th>\n",
       "      <td>sleepy</td>\n",
       "      <td>3.557599e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>137</th>\n",
       "      <td>tfidf_137</td>\n",
       "      <td>3.377258e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>402</th>\n",
       "      <td>euphoric</td>\n",
       "      <td>3.368356e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>tfidf_15</td>\n",
       "      <td>3.356288e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>441</th>\n",
       "      <td>lemon</td>\n",
       "      <td>3.311203e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>373</th>\n",
       "      <td>tfidf_373</td>\n",
       "      <td>3.308778e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>tfidf_7</td>\n",
       "      <td>3.301002e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>409</th>\n",
       "      <td>hungry</td>\n",
       "      <td>3.186973e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>111</th>\n",
       "      <td>tfidf_111</td>\n",
       "      <td>2.944759e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>tfidf_30</td>\n",
       "      <td>2.806368e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>263</th>\n",
       "      <td>tfidf_263</td>\n",
       "      <td>2.707210e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>283</th>\n",
       "      <td>tfidf_283</td>\n",
       "      <td>2.704248e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>420</th>\n",
       "      <td>uplifted</td>\n",
       "      <td>2.676452e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>163</th>\n",
       "      <td>tfidf_163</td>\n",
       "      <td>2.672019e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>382</th>\n",
       "      <td>tfidf_382</td>\n",
       "      <td>2.590154e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>334</th>\n",
       "      <td>tfidf_334</td>\n",
       "      <td>2.587466e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>230</th>\n",
       "      <td>tfidf_230</td>\n",
       "      <td>2.570398e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>70</th>\n",
       "      <td>tfidf_70</td>\n",
       "      <td>2.447145e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>452</th>\n",
       "      <td>pineapple</td>\n",
       "      <td>2.442119e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>276</th>\n",
       "      <td>tfidf_276</td>\n",
       "      <td>2.421653e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>253</th>\n",
       "      <td>tfidf_253</td>\n",
       "      <td>2.410049e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>190</th>\n",
       "      <td>tfidf_190</td>\n",
       "      <td>2.401667e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>277</th>\n",
       "      <td>tfidf_277</td>\n",
       "      <td>2.383829e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>406</th>\n",
       "      <td>giggly</td>\n",
       "      <td>2.378990e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>tfidf_45</td>\n",
       "      <td>2.301904e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>291</th>\n",
       "      <td>tfidf_291</td>\n",
       "      <td>2.285431e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>119</th>\n",
       "      <td>tfidf_119</td>\n",
       "      <td>2.281631e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>273</th>\n",
       "      <td>tfidf_273</td>\n",
       "      <td>2.191512e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>tfidf_37</td>\n",
       "      <td>2.172686e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>364</th>\n",
       "      <td>tfidf_364</td>\n",
       "      <td>2.153325e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>tfidf_29</td>\n",
       "      <td>2.129864e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>tfidf_11</td>\n",
       "      <td>2.041025e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>362</th>\n",
       "      <td>tfidf_362</td>\n",
       "      <td>2.022383e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>398</th>\n",
       "      <td>dry eyes</td>\n",
       "      <td>1.983186e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>437</th>\n",
       "      <td>grape</td>\n",
       "      <td>1.972452e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>432</th>\n",
       "      <td>coffee</td>\n",
       "      <td>1.939432e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>158</th>\n",
       "      <td>tfidf_158</td>\n",
       "      <td>1.895064e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>162</th>\n",
       "      <td>tfidf_162</td>\n",
       "      <td>1.887405e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>319</th>\n",
       "      <td>tfidf_319</td>\n",
       "      <td>1.883072e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>457</th>\n",
       "      <td>skunk</td>\n",
       "      <td>1.858015e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>240</th>\n",
       "      <td>tfidf_240</td>\n",
       "      <td>1.827117e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>280</th>\n",
       "      <td>tfidf_280</td>\n",
       "      <td>1.799345e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>360</th>\n",
       "      <td>tfidf_360</td>\n",
       "      <td>1.774861e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>258</th>\n",
       "      <td>tfidf_258</td>\n",
       "      <td>1.760628e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>128</th>\n",
       "      <td>tfidf_128</td>\n",
       "      <td>1.755940e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>350</th>\n",
       "      <td>tfidf_350</td>\n",
       "      <td>1.742407e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>342</th>\n",
       "      <td>tfidf_342</td>\n",
       "      <td>1.736611e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>324</th>\n",
       "      <td>tfidf_324</td>\n",
       "      <td>1.640887e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>314</th>\n",
       "      <td>tfidf_314</td>\n",
       "      <td>1.607987e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>318</th>\n",
       "      <td>tfidf_318</td>\n",
       "      <td>1.605828e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>200</th>\n",
       "      <td>tfidf_200</td>\n",
       "      <td>1.580954e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>418</th>\n",
       "      <td>talkative</td>\n",
       "      <td>1.522543e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>109</th>\n",
       "      <td>tfidf_109</td>\n",
       "      <td>1.511468e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>tfidf_96</td>\n",
       "      <td>1.504484e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>310</th>\n",
       "      <td>tfidf_310</td>\n",
       "      <td>1.440647e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>343</th>\n",
       "      <td>tfidf_343</td>\n",
       "      <td>1.439016e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>424</th>\n",
       "      <td>berry</td>\n",
       "      <td>1.436326e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>144</th>\n",
       "      <td>tfidf_144</td>\n",
       "      <td>1.421504e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>462</th>\n",
       "      <td>tea</td>\n",
       "      <td>1.415154e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>371</th>\n",
       "      <td>tfidf_371</td>\n",
       "      <td>1.401014e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>126</th>\n",
       "      <td>tfidf_126</td>\n",
       "      <td>1.386460e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>281</th>\n",
       "      <td>tfidf_281</td>\n",
       "      <td>1.383797e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>341</th>\n",
       "      <td>tfidf_341</td>\n",
       "      <td>1.374782e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>367</th>\n",
       "      <td>tfidf_367</td>\n",
       "      <td>1.367606e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>377</th>\n",
       "      <td>tfidf_377</td>\n",
       "      <td>1.352225e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>tfidf_42</td>\n",
       "      <td>1.304248e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>286</th>\n",
       "      <td>tfidf_286</td>\n",
       "      <td>1.287055e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>159</th>\n",
       "      <td>tfidf_159</td>\n",
       "      <td>1.283147e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>129</th>\n",
       "      <td>tfidf_129</td>\n",
       "      <td>1.269674e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54</th>\n",
       "      <td>tfidf_54</td>\n",
       "      <td>1.249015e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>340</th>\n",
       "      <td>tfidf_340</td>\n",
       "      <td>1.237056e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>405</th>\n",
       "      <td>focused</td>\n",
       "      <td>1.209615e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>466</th>\n",
       "      <td>vanilla</td>\n",
       "      <td>1.206956e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>182</th>\n",
       "      <td>tfidf_182</td>\n",
       "      <td>1.185610e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>325</th>\n",
       "      <td>tfidf_325</td>\n",
       "      <td>1.151686e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>57</th>\n",
       "      <td>tfidf_57</td>\n",
       "      <td>1.149255e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>206</th>\n",
       "      <td>tfidf_206</td>\n",
       "      <td>1.148598e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>tfidf_32</td>\n",
       "      <td>1.137411e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>tfidf_98</td>\n",
       "      <td>1.131940e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>435</th>\n",
       "      <td>flowery</td>\n",
       "      <td>1.127746e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>390</th>\n",
       "      <td>sativa</td>\n",
       "      <td>1.103816e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>366</th>\n",
       "      <td>tfidf_366</td>\n",
       "      <td>1.094730e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>205</th>\n",
       "      <td>tfidf_205</td>\n",
       "      <td>1.088919e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>tfidf_6</td>\n",
       "      <td>1.080744e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>tfidf_34</td>\n",
       "      <td>1.063481e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>293</th>\n",
       "      <td>tfidf_293</td>\n",
       "      <td>1.059840e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>223</th>\n",
       "      <td>tfidf_223</td>\n",
       "      <td>1.048519e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>151</th>\n",
       "      <td>tfidf_151</td>\n",
       "      <td>1.043186e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>289</th>\n",
       "      <td>tfidf_289</td>\n",
       "      <td>1.003755e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>120</th>\n",
       "      <td>tfidf_120</td>\n",
       "      <td>1.001898e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>tfidf_46</td>\n",
       "      <td>9.949650e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>167</th>\n",
       "      <td>tfidf_167</td>\n",
       "      <td>9.679323e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>110</th>\n",
       "      <td>tfidf_110</td>\n",
       "      <td>9.604414e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>267</th>\n",
       "      <td>tfidf_267</td>\n",
       "      <td>9.586713e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>tfidf_27</td>\n",
       "      <td>9.550562e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>338</th>\n",
       "      <td>tfidf_338</td>\n",
       "      <td>9.535169e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>112</th>\n",
       "      <td>tfidf_112</td>\n",
       "      <td>9.526037e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>188</th>\n",
       "      <td>tfidf_188</td>\n",
       "      <td>9.496512e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>tfidf_26</td>\n",
       "      <td>9.480785e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>86</th>\n",
       "      <td>tfidf_86</td>\n",
       "      <td>9.478616e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>269</th>\n",
       "      <td>tfidf_269</td>\n",
       "      <td>9.401430e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>64</th>\n",
       "      <td>tfidf_64</td>\n",
       "      <td>9.385953e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>82</th>\n",
       "      <td>tfidf_82</td>\n",
       "      <td>9.340344e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>76</th>\n",
       "      <td>tfidf_76</td>\n",
       "      <td>9.294761e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>217</th>\n",
       "      <td>tfidf_217</td>\n",
       "      <td>9.291742e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>177</th>\n",
       "      <td>tfidf_177</td>\n",
       "      <td>9.260887e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>tfidf_24</td>\n",
       "      <td>9.218256e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>272</th>\n",
       "      <td>tfidf_272</td>\n",
       "      <td>8.992534e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>tfidf_1</td>\n",
       "      <td>8.975732e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>369</th>\n",
       "      <td>tfidf_369</td>\n",
       "      <td>8.948300e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>397</th>\n",
       "      <td>dizzy</td>\n",
       "      <td>8.948108e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>431</th>\n",
       "      <td>citrus</td>\n",
       "      <td>8.911820e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>275</th>\n",
       "      <td>tfidf_275</td>\n",
       "      <td>8.883206e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>445</th>\n",
       "      <td>mint</td>\n",
       "      <td>8.794037e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>124</th>\n",
       "      <td>tfidf_124</td>\n",
       "      <td>8.779203e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>107</th>\n",
       "      <td>tfidf_107</td>\n",
       "      <td>8.778133e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>157</th>\n",
       "      <td>tfidf_157</td>\n",
       "      <td>8.735842e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>213</th>\n",
       "      <td>tfidf_213</td>\n",
       "      <td>8.632959e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>198</th>\n",
       "      <td>tfidf_198</td>\n",
       "      <td>8.586641e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>55</th>\n",
       "      <td>tfidf_55</td>\n",
       "      <td>8.569824e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>69</th>\n",
       "      <td>tfidf_69</td>\n",
       "      <td>8.539553e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>430</th>\n",
       "      <td>chestnut</td>\n",
       "      <td>8.531286e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>311</th>\n",
       "      <td>tfidf_311</td>\n",
       "      <td>8.468218e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>270</th>\n",
       "      <td>tfidf_270</td>\n",
       "      <td>8.409271e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>288</th>\n",
       "      <td>tfidf_288</td>\n",
       "      <td>8.382843e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>tfidf_36</td>\n",
       "      <td>8.306664e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>178</th>\n",
       "      <td>tfidf_178</td>\n",
       "      <td>8.113670e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>278</th>\n",
       "      <td>tfidf_278</td>\n",
       "      <td>7.759473e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>191</th>\n",
       "      <td>tfidf_191</td>\n",
       "      <td>7.445279e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>103</th>\n",
       "      <td>tfidf_103</td>\n",
       "      <td>7.350251e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75</th>\n",
       "      <td>tfidf_75</td>\n",
       "      <td>7.343237e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>tfidf_48</td>\n",
       "      <td>7.208059e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>79</th>\n",
       "      <td>tfidf_79</td>\n",
       "      <td>7.194351e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>243</th>\n",
       "      <td>tfidf_243</td>\n",
       "      <td>7.094185e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>tfidf_39</td>\n",
       "      <td>7.073375e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>123</th>\n",
       "      <td>tfidf_123</td>\n",
       "      <td>7.059750e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>56</th>\n",
       "      <td>tfidf_56</td>\n",
       "      <td>6.950982e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>215</th>\n",
       "      <td>tfidf_215</td>\n",
       "      <td>6.925873e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>429</th>\n",
       "      <td>chemical</td>\n",
       "      <td>6.817417e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>tfidf_41</td>\n",
       "      <td>6.786367e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>tfidf_17</td>\n",
       "      <td>6.750535e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>193</th>\n",
       "      <td>tfidf_193</td>\n",
       "      <td>6.562204e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>266</th>\n",
       "      <td>tfidf_266</td>\n",
       "      <td>6.515095e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>122</th>\n",
       "      <td>tfidf_122</td>\n",
       "      <td>6.510597e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>264</th>\n",
       "      <td>tfidf_264</td>\n",
       "      <td>6.501131e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>67</th>\n",
       "      <td>tfidf_67</td>\n",
       "      <td>6.367679e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>104</th>\n",
       "      <td>tfidf_104</td>\n",
       "      <td>6.366840e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>393</th>\n",
       "      <td>aroused</td>\n",
       "      <td>6.356963e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>tfidf_21</td>\n",
       "      <td>6.297083e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>354</th>\n",
       "      <td>tfidf_354</td>\n",
       "      <td>6.275908e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>138</th>\n",
       "      <td>tfidf_138</td>\n",
       "      <td>6.272949e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>389</th>\n",
       "      <td>indica</td>\n",
       "      <td>6.268117e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>320</th>\n",
       "      <td>tfidf_320</td>\n",
       "      <td>6.262078e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>184</th>\n",
       "      <td>tfidf_184</td>\n",
       "      <td>6.201735e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>299</th>\n",
       "      <td>tfidf_299</td>\n",
       "      <td>6.158955e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>61</th>\n",
       "      <td>tfidf_61</td>\n",
       "      <td>6.151020e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>tfidf_22</td>\n",
       "      <td>6.112030e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>92</th>\n",
       "      <td>tfidf_92</td>\n",
       "      <td>5.962398e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>353</th>\n",
       "      <td>tfidf_353</td>\n",
       "      <td>5.925387e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>380</th>\n",
       "      <td>tfidf_380</td>\n",
       "      <td>5.890342e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>326</th>\n",
       "      <td>tfidf_326</td>\n",
       "      <td>5.773707e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>339</th>\n",
       "      <td>tfidf_339</td>\n",
       "      <td>5.659852e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>231</th>\n",
       "      <td>tfidf_231</td>\n",
       "      <td>5.631476e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>336</th>\n",
       "      <td>tfidf_336</td>\n",
       "      <td>5.629572e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>153</th>\n",
       "      <td>tfidf_153</td>\n",
       "      <td>5.615077e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>321</th>\n",
       "      <td>tfidf_321</td>\n",
       "      <td>5.556907e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>271</th>\n",
       "      <td>tfidf_271</td>\n",
       "      <td>5.555415e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>233</th>\n",
       "      <td>tfidf_233</td>\n",
       "      <td>5.491583e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>130</th>\n",
       "      <td>tfidf_130</td>\n",
       "      <td>5.460366e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>160</th>\n",
       "      <td>tfidf_160</td>\n",
       "      <td>5.378740e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>226</th>\n",
       "      <td>tfidf_226</td>\n",
       "      <td>5.299050e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>tfidf_8</td>\n",
       "      <td>5.210888e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51</th>\n",
       "      <td>tfidf_51</td>\n",
       "      <td>5.174644e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>161</th>\n",
       "      <td>tfidf_161</td>\n",
       "      <td>5.173317e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>125</th>\n",
       "      <td>tfidf_125</td>\n",
       "      <td>5.119496e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>268</th>\n",
       "      <td>tfidf_268</td>\n",
       "      <td>5.118607e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>316</th>\n",
       "      <td>tfidf_316</td>\n",
       "      <td>5.079161e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>152</th>\n",
       "      <td>tfidf_152</td>\n",
       "      <td>5.060699e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>297</th>\n",
       "      <td>tfidf_297</td>\n",
       "      <td>4.935151e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>tfidf_4</td>\n",
       "      <td>4.886874e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>203</th>\n",
       "      <td>tfidf_203</td>\n",
       "      <td>4.868769e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>221</th>\n",
       "      <td>tfidf_221</td>\n",
       "      <td>4.834292e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>209</th>\n",
       "      <td>tfidf_209</td>\n",
       "      <td>4.832463e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>180</th>\n",
       "      <td>tfidf_180</td>\n",
       "      <td>4.818497e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>381</th>\n",
       "      <td>tfidf_381</td>\n",
       "      <td>4.803170e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>421</th>\n",
       "      <td>ammonia</td>\n",
       "      <td>4.803165e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>80</th>\n",
       "      <td>tfidf_80</td>\n",
       "      <td>4.773861e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>tfidf_16</td>\n",
       "      <td>4.707453e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>219</th>\n",
       "      <td>tfidf_219</td>\n",
       "      <td>4.672391e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>146</th>\n",
       "      <td>tfidf_146</td>\n",
       "      <td>4.627085e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>176</th>\n",
       "      <td>tfidf_176</td>\n",
       "      <td>4.566029e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>186</th>\n",
       "      <td>tfidf_186</td>\n",
       "      <td>4.523779e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>60</th>\n",
       "      <td>tfidf_60</td>\n",
       "      <td>4.473307e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>365</th>\n",
       "      <td>tfidf_365</td>\n",
       "      <td>4.472740e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>tfidf_49</td>\n",
       "      <td>4.462453e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>179</th>\n",
       "      <td>tfidf_179</td>\n",
       "      <td>4.440256e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>202</th>\n",
       "      <td>tfidf_202</td>\n",
       "      <td>4.432122e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>468</th>\n",
       "      <td>woody</td>\n",
       "      <td>4.340982e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>374</th>\n",
       "      <td>tfidf_374</td>\n",
       "      <td>4.316739e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>tfidf_31</td>\n",
       "      <td>4.247415e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53</th>\n",
       "      <td>tfidf_53</td>\n",
       "      <td>4.232591e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>172</th>\n",
       "      <td>tfidf_172</td>\n",
       "      <td>4.211210e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>236</th>\n",
       "      <td>tfidf_236</td>\n",
       "      <td>4.197908e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>195</th>\n",
       "      <td>tfidf_195</td>\n",
       "      <td>4.193103e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>175</th>\n",
       "      <td>tfidf_175</td>\n",
       "      <td>4.179153e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>259</th>\n",
       "      <td>tfidf_259</td>\n",
       "      <td>4.090774e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>222</th>\n",
       "      <td>tfidf_222</td>\n",
       "      <td>4.033323e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>tfidf_9</td>\n",
       "      <td>4.023530e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>139</th>\n",
       "      <td>tfidf_139</td>\n",
       "      <td>3.886369e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>294</th>\n",
       "      <td>tfidf_294</td>\n",
       "      <td>3.795279e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>208</th>\n",
       "      <td>tfidf_208</td>\n",
       "      <td>3.714703e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>248</th>\n",
       "      <td>tfidf_248</td>\n",
       "      <td>3.659834e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>260</th>\n",
       "      <td>tfidf_260</td>\n",
       "      <td>3.648767e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>302</th>\n",
       "      <td>tfidf_302</td>\n",
       "      <td>3.604877e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>71</th>\n",
       "      <td>tfidf_71</td>\n",
       "      <td>3.584536e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>458</th>\n",
       "      <td>spicy/herbal</td>\n",
       "      <td>3.560824e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>tfidf_14</td>\n",
       "      <td>3.553061e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>127</th>\n",
       "      <td>tfidf_127</td>\n",
       "      <td>3.437434e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>tfidf_19</td>\n",
       "      <td>3.432302e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>422</th>\n",
       "      <td>apple</td>\n",
       "      <td>3.431517e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>459</th>\n",
       "      <td>strawberry</td>\n",
       "      <td>3.409970e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>306</th>\n",
       "      <td>tfidf_306</td>\n",
       "      <td>3.340526e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>234</th>\n",
       "      <td>tfidf_234</td>\n",
       "      <td>3.308048e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>tfidf_23</td>\n",
       "      <td>3.260788e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>164</th>\n",
       "      <td>tfidf_164</td>\n",
       "      <td>3.221929e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>387</th>\n",
       "      <td>tfidf_387</td>\n",
       "      <td>3.168310e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>216</th>\n",
       "      <td>tfidf_216</td>\n",
       "      <td>3.125801e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>88</th>\n",
       "      <td>tfidf_88</td>\n",
       "      <td>3.116948e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>194</th>\n",
       "      <td>tfidf_194</td>\n",
       "      <td>3.073129e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>133</th>\n",
       "      <td>tfidf_133</td>\n",
       "      <td>3.068736e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>412</th>\n",
       "      <td>paranoid</td>\n",
       "      <td>3.049523e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>237</th>\n",
       "      <td>tfidf_237</td>\n",
       "      <td>3.044918e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>201</th>\n",
       "      <td>tfidf_201</td>\n",
       "      <td>3.015371e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>171</th>\n",
       "      <td>tfidf_171</td>\n",
       "      <td>2.993547e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>300</th>\n",
       "      <td>tfidf_300</td>\n",
       "      <td>2.990508e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>81</th>\n",
       "      <td>tfidf_81</td>\n",
       "      <td>2.944121e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>392</th>\n",
       "      <td>anxious</td>\n",
       "      <td>2.942053e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>456</th>\n",
       "      <td>sage</td>\n",
       "      <td>2.936674e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>tfidf_13</td>\n",
       "      <td>2.912883e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>298</th>\n",
       "      <td>tfidf_298</td>\n",
       "      <td>2.882650e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>148</th>\n",
       "      <td>tfidf_148</td>\n",
       "      <td>2.864671e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>355</th>\n",
       "      <td>tfidf_355</td>\n",
       "      <td>2.858194e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>386</th>\n",
       "      <td>tfidf_386</td>\n",
       "      <td>2.840079e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>tfidf_99</td>\n",
       "      <td>2.837199e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>136</th>\n",
       "      <td>tfidf_136</td>\n",
       "      <td>2.814469e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>85</th>\n",
       "      <td>tfidf_85</td>\n",
       "      <td>2.803127e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>225</th>\n",
       "      <td>tfidf_225</td>\n",
       "      <td>2.795277e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>tfidf_97</td>\n",
       "      <td>2.791044e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>372</th>\n",
       "      <td>tfidf_372</td>\n",
       "      <td>2.759489e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>115</th>\n",
       "      <td>tfidf_115</td>\n",
       "      <td>2.749182e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>465</th>\n",
       "      <td>tropical</td>\n",
       "      <td>2.743971e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>181</th>\n",
       "      <td>tfidf_181</td>\n",
       "      <td>2.728321e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>117</th>\n",
       "      <td>tfidf_117</td>\n",
       "      <td>2.708926e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>58</th>\n",
       "      <td>tfidf_58</td>\n",
       "      <td>2.705195e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>170</th>\n",
       "      <td>tfidf_170</td>\n",
       "      <td>2.705070e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>255</th>\n",
       "      <td>tfidf_255</td>\n",
       "      <td>2.699753e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>361</th>\n",
       "      <td>tfidf_361</td>\n",
       "      <td>2.690530e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>254</th>\n",
       "      <td>tfidf_254</td>\n",
       "      <td>2.678275e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>304</th>\n",
       "      <td>tfidf_304</td>\n",
       "      <td>2.672724e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>227</th>\n",
       "      <td>tfidf_227</td>\n",
       "      <td>2.662845e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>261</th>\n",
       "      <td>tfidf_261</td>\n",
       "      <td>2.642980e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>351</th>\n",
       "      <td>tfidf_351</td>\n",
       "      <td>2.600038e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>116</th>\n",
       "      <td>tfidf_116</td>\n",
       "      <td>2.557033e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>384</th>\n",
       "      <td>tfidf_384</td>\n",
       "      <td>2.524569e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>359</th>\n",
       "      <td>tfidf_359</td>\n",
       "      <td>2.516148e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>443</th>\n",
       "      <td>mango</td>\n",
       "      <td>2.510853e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>102</th>\n",
       "      <td>tfidf_102</td>\n",
       "      <td>2.478659e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>135</th>\n",
       "      <td>tfidf_135</td>\n",
       "      <td>2.477729e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>251</th>\n",
       "      <td>tfidf_251</td>\n",
       "      <td>2.453017e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>185</th>\n",
       "      <td>tfidf_185</td>\n",
       "      <td>2.435667e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>356</th>\n",
       "      <td>tfidf_356</td>\n",
       "      <td>2.413664e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>118</th>\n",
       "      <td>tfidf_118</td>\n",
       "      <td>2.405578e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>tfidf_28</td>\n",
       "      <td>2.405233e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>tfidf_3</td>\n",
       "      <td>2.389548e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>370</th>\n",
       "      <td>tfidf_370</td>\n",
       "      <td>2.355081e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>108</th>\n",
       "      <td>tfidf_108</td>\n",
       "      <td>2.349638e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>292</th>\n",
       "      <td>tfidf_292</td>\n",
       "      <td>2.340707e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>244</th>\n",
       "      <td>tfidf_244</td>\n",
       "      <td>2.299201e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>257</th>\n",
       "      <td>tfidf_257</td>\n",
       "      <td>2.270699e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>282</th>\n",
       "      <td>tfidf_282</td>\n",
       "      <td>2.266814e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>147</th>\n",
       "      <td>tfidf_147</td>\n",
       "      <td>2.262483e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>142</th>\n",
       "      <td>tfidf_142</td>\n",
       "      <td>2.192271e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>62</th>\n",
       "      <td>tfidf_62</td>\n",
       "      <td>2.146934e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>65</th>\n",
       "      <td>tfidf_65</td>\n",
       "      <td>2.146554e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>274</th>\n",
       "      <td>tfidf_274</td>\n",
       "      <td>2.138746e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>211</th>\n",
       "      <td>tfidf_211</td>\n",
       "      <td>2.119075e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>94</th>\n",
       "      <td>tfidf_94</td>\n",
       "      <td>2.112064e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>tfidf_44</td>\n",
       "      <td>2.092009e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>287</th>\n",
       "      <td>tfidf_287</td>\n",
       "      <td>2.065664e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>113</th>\n",
       "      <td>tfidf_113</td>\n",
       "      <td>2.065549e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52</th>\n",
       "      <td>tfidf_52</td>\n",
       "      <td>2.056787e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>tfidf_40</td>\n",
       "      <td>2.047519e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>224</th>\n",
       "      <td>tfidf_224</td>\n",
       "      <td>2.041784e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>143</th>\n",
       "      <td>tfidf_143</td>\n",
       "      <td>2.029720e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>358</th>\n",
       "      <td>tfidf_358</td>\n",
       "      <td>1.986463e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>150</th>\n",
       "      <td>tfidf_150</td>\n",
       "      <td>1.958603e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>363</th>\n",
       "      <td>tfidf_363</td>\n",
       "      <td>1.951122e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>438</th>\n",
       "      <td>grapefruit</td>\n",
       "      <td>1.938467e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>252</th>\n",
       "      <td>tfidf_252</td>\n",
       "      <td>1.919726e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>63</th>\n",
       "      <td>tfidf_63</td>\n",
       "      <td>1.909667e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>446</th>\n",
       "      <td>nutty</td>\n",
       "      <td>1.892335e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>246</th>\n",
       "      <td>tfidf_246</td>\n",
       "      <td>1.880848e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>214</th>\n",
       "      <td>tfidf_214</td>\n",
       "      <td>1.823981e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>tfidf_10</td>\n",
       "      <td>1.810967e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>330</th>\n",
       "      <td>tfidf_330</td>\n",
       "      <td>1.786652e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>106</th>\n",
       "      <td>tfidf_106</td>\n",
       "      <td>1.779936e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>450</th>\n",
       "      <td>pepper</td>\n",
       "      <td>1.766559e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>408</th>\n",
       "      <td>headache</td>\n",
       "      <td>1.733546e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>212</th>\n",
       "      <td>tfidf_212</td>\n",
       "      <td>1.726852e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>279</th>\n",
       "      <td>tfidf_279</td>\n",
       "      <td>1.726549e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>220</th>\n",
       "      <td>tfidf_220</td>\n",
       "      <td>1.713470e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>tfidf_2</td>\n",
       "      <td>1.710858e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>tfidf_25</td>\n",
       "      <td>1.708087e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>187</th>\n",
       "      <td>tfidf_187</td>\n",
       "      <td>1.696638e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>74</th>\n",
       "      <td>tfidf_74</td>\n",
       "      <td>1.674801e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>383</th>\n",
       "      <td>tfidf_383</td>\n",
       "      <td>1.657119e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>352</th>\n",
       "      <td>tfidf_352</td>\n",
       "      <td>1.651152e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>427</th>\n",
       "      <td>butter</td>\n",
       "      <td>1.650688e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>301</th>\n",
       "      <td>tfidf_301</td>\n",
       "      <td>1.642271e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>87</th>\n",
       "      <td>tfidf_87</td>\n",
       "      <td>1.621854e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59</th>\n",
       "      <td>tfidf_59</td>\n",
       "      <td>1.620560e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>192</th>\n",
       "      <td>tfidf_192</td>\n",
       "      <td>1.596217e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>155</th>\n",
       "      <td>tfidf_155</td>\n",
       "      <td>1.595883e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>83</th>\n",
       "      <td>tfidf_83</td>\n",
       "      <td>1.584377e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>328</th>\n",
       "      <td>tfidf_328</td>\n",
       "      <td>1.555389e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>375</th>\n",
       "      <td>tfidf_375</td>\n",
       "      <td>1.540499e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>368</th>\n",
       "      <td>tfidf_368</td>\n",
       "      <td>1.537696e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>169</th>\n",
       "      <td>tfidf_169</td>\n",
       "      <td>1.510340e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>290</th>\n",
       "      <td>tfidf_290</td>\n",
       "      <td>1.460551e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>436</th>\n",
       "      <td>fruit</td>\n",
       "      <td>1.459774e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>68</th>\n",
       "      <td>tfidf_68</td>\n",
       "      <td>1.455144e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>183</th>\n",
       "      <td>tfidf_183</td>\n",
       "      <td>1.452781e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>77</th>\n",
       "      <td>tfidf_77</td>\n",
       "      <td>1.419306e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>308</th>\n",
       "      <td>tfidf_308</td>\n",
       "      <td>1.411551e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>284</th>\n",
       "      <td>tfidf_284</td>\n",
       "      <td>1.388405e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>323</th>\n",
       "      <td>tfidf_323</td>\n",
       "      <td>1.369980e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>165</th>\n",
       "      <td>tfidf_165</td>\n",
       "      <td>1.368948e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>295</th>\n",
       "      <td>tfidf_295</td>\n",
       "      <td>1.352507e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>tfidf_95</td>\n",
       "      <td>1.336393e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>174</th>\n",
       "      <td>tfidf_174</td>\n",
       "      <td>1.311257e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>442</th>\n",
       "      <td>lime</td>\n",
       "      <td>1.307964e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>66</th>\n",
       "      <td>tfidf_66</td>\n",
       "      <td>1.307456e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>347</th>\n",
       "      <td>tfidf_347</td>\n",
       "      <td>1.300103e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>tfidf_47</td>\n",
       "      <td>1.295017e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>232</th>\n",
       "      <td>tfidf_232</td>\n",
       "      <td>1.258038e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>tfidf_33</td>\n",
       "      <td>1.250920e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>132</th>\n",
       "      <td>tfidf_132</td>\n",
       "      <td>1.228716e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>tfidf_38</td>\n",
       "      <td>1.204341e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>305</th>\n",
       "      <td>tfidf_305</td>\n",
       "      <td>1.200599e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>349</th>\n",
       "      <td>tfidf_349</td>\n",
       "      <td>1.178057e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>332</th>\n",
       "      <td>tfidf_332</td>\n",
       "      <td>1.170227e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>315</th>\n",
       "      <td>tfidf_315</td>\n",
       "      <td>1.140118e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>327</th>\n",
       "      <td>tfidf_327</td>\n",
       "      <td>1.130439e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>379</th>\n",
       "      <td>tfidf_379</td>\n",
       "      <td>1.128230e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>140</th>\n",
       "      <td>tfidf_140</td>\n",
       "      <td>1.123637e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>228</th>\n",
       "      <td>tfidf_228</td>\n",
       "      <td>1.117134e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>tfidf_12</td>\n",
       "      <td>1.084142e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>tfidf_35</td>\n",
       "      <td>1.077853e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>262</th>\n",
       "      <td>tfidf_262</td>\n",
       "      <td>1.077759e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>229</th>\n",
       "      <td>tfidf_229</td>\n",
       "      <td>1.076054e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>197</th>\n",
       "      <td>tfidf_197</td>\n",
       "      <td>1.074870e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>196</th>\n",
       "      <td>tfidf_196</td>\n",
       "      <td>1.065876e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>249</th>\n",
       "      <td>tfidf_249</td>\n",
       "      <td>1.056799e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>131</th>\n",
       "      <td>tfidf_131</td>\n",
       "      <td>1.025714e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>455</th>\n",
       "      <td>rose</td>\n",
       "      <td>9.926312e-05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>464</th>\n",
       "      <td>tree</td>\n",
       "      <td>9.769596e-05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50</th>\n",
       "      <td>tfidf_50</td>\n",
       "      <td>9.647247e-05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>134</th>\n",
       "      <td>tfidf_134</td>\n",
       "      <td>9.611476e-05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>84</th>\n",
       "      <td>tfidf_84</td>\n",
       "      <td>9.221678e-05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>218</th>\n",
       "      <td>tfidf_218</td>\n",
       "      <td>9.095110e-05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>322</th>\n",
       "      <td>tfidf_322</td>\n",
       "      <td>9.071471e-05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>238</th>\n",
       "      <td>tfidf_238</td>\n",
       "      <td>9.014450e-05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>307</th>\n",
       "      <td>tfidf_307</td>\n",
       "      <td>8.739971e-05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>461</th>\n",
       "      <td>tar</td>\n",
       "      <td>8.722893e-05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>331</th>\n",
       "      <td>tfidf_331</td>\n",
       "      <td>8.720079e-05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>100</th>\n",
       "      <td>tfidf_100</td>\n",
       "      <td>8.634720e-05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>tfidf_18</td>\n",
       "      <td>8.567563e-05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>256</th>\n",
       "      <td>tfidf_256</td>\n",
       "      <td>8.462937e-05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>440</th>\n",
       "      <td>lavender</td>\n",
       "      <td>8.404762e-05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>156</th>\n",
       "      <td>tfidf_156</td>\n",
       "      <td>8.332941e-05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>296</th>\n",
       "      <td>tfidf_296</td>\n",
       "      <td>8.255241e-05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>333</th>\n",
       "      <td>tfidf_333</td>\n",
       "      <td>8.039076e-05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>317</th>\n",
       "      <td>tfidf_317</td>\n",
       "      <td>7.975740e-05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>114</th>\n",
       "      <td>tfidf_114</td>\n",
       "      <td>7.613787e-05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>242</th>\n",
       "      <td>tfidf_242</td>\n",
       "      <td>7.556148e-05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>346</th>\n",
       "      <td>tfidf_346</td>\n",
       "      <td>7.169941e-05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>204</th>\n",
       "      <td>tfidf_204</td>\n",
       "      <td>5.863351e-05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>378</th>\n",
       "      <td>tfidf_378</td>\n",
       "      <td>5.477676e-05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>449</th>\n",
       "      <td>pear</td>\n",
       "      <td>5.342057e-05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>453</th>\n",
       "      <td>plum</td>\n",
       "      <td>5.118443e-05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>89</th>\n",
       "      <td>tfidf_89</td>\n",
       "      <td>4.887673e-05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>444</th>\n",
       "      <td>menthol</td>\n",
       "      <td>4.720845e-05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>241</th>\n",
       "      <td>tfidf_241</td>\n",
       "      <td>4.553424e-05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>72</th>\n",
       "      <td>tfidf_72</td>\n",
       "      <td>4.525108e-05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>463</th>\n",
       "      <td>tobacco</td>\n",
       "      <td>3.974587e-05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>250</th>\n",
       "      <td>tfidf_250</td>\n",
       "      <td>2.665532e-05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>448</th>\n",
       "      <td>peach</td>\n",
       "      <td>2.141595e-05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>425</th>\n",
       "      <td>blue cheese</td>\n",
       "      <td>2.026013e-05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>467</th>\n",
       "      <td>violet</td>\n",
       "      <td>2.016538e-05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>423</th>\n",
       "      <td>apricot</td>\n",
       "      <td>1.561635e-05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>396</th>\n",
       "      <td>depression</td>\n",
       "      <td>6.060078e-06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>391</th>\n",
       "      <td>anxiety</td>\n",
       "      <td>5.986459e-06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>410</th>\n",
       "      <td>migraines</td>\n",
       "      <td>4.153994e-06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>403</th>\n",
       "      <td>eye pressure</td>\n",
       "      <td>4.581619e-08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>401</th>\n",
       "      <td>epilepsy</td>\n",
       "      <td>1.577801e-09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>411</th>\n",
       "      <td>pain</td>\n",
       "      <td>1.464560e-09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>414</th>\n",
       "      <td>seizures</td>\n",
       "      <td>0.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>394</th>\n",
       "      <td>arthritis</td>\n",
       "      <td>0.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>404</th>\n",
       "      <td>fatigue</td>\n",
       "      <td>0.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>416</th>\n",
       "      <td>spasticity</td>\n",
       "      <td>0.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>417</th>\n",
       "      <td>stress</td>\n",
       "      <td>0.000000e+00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         features         score\n",
       "388        hybrid  2.317947e-01\n",
       "265     tfidf_265  2.948499e-02\n",
       "329     tfidf_329  2.757780e-02\n",
       "451          pine  2.534950e-02\n",
       "428        cheese  2.383988e-02\n",
       "168     tfidf_168  1.593202e-02\n",
       "447        orange  1.480374e-02\n",
       "145     tfidf_145  1.429457e-02\n",
       "312     tfidf_312  1.368945e-02\n",
       "78       tfidf_78  1.346955e-02\n",
       "90       tfidf_90  1.112299e-02\n",
       "101     tfidf_101  1.039040e-02\n",
       "207     tfidf_207  1.029136e-02\n",
       "93       tfidf_93  1.025517e-02\n",
       "247     tfidf_247  9.288137e-03\n",
       "149     tfidf_149  8.994027e-03\n",
       "439         honey  8.716900e-03\n",
       "199     tfidf_199  8.713203e-03\n",
       "337     tfidf_337  8.403137e-03\n",
       "426     blueberry  8.390953e-03\n",
       "460         sweet  8.127868e-03\n",
       "345     tfidf_345  8.024269e-03\n",
       "303     tfidf_303  7.882792e-03\n",
       "419        tingly  7.866658e-03\n",
       "5         tfidf_5  7.540010e-03\n",
       "400     energetic  7.389724e-03\n",
       "285     tfidf_285  7.192997e-03\n",
       "91       tfidf_91  7.093246e-03\n",
       "210     tfidf_210  6.845179e-03\n",
       "433        diesel  6.762598e-03\n",
       "121     tfidf_121  6.586717e-03\n",
       "105     tfidf_105  6.308043e-03\n",
       "154     tfidf_154  6.293928e-03\n",
       "454       pungent  6.128854e-03\n",
       "173     tfidf_173  6.023986e-03\n",
       "385     tfidf_385  5.816422e-03\n",
       "395      creative  5.730880e-03\n",
       "313     tfidf_313  5.684884e-03\n",
       "434        earthy  5.333262e-03\n",
       "189     tfidf_189  5.319822e-03\n",
       "20       tfidf_20  5.171677e-03\n",
       "0         tfidf_0  4.828969e-03\n",
       "357     tfidf_357  4.704395e-03\n",
       "407         happy  4.638460e-03\n",
       "166     tfidf_166  4.637811e-03\n",
       "235     tfidf_235  4.568050e-03\n",
       "413       relaxed  4.540796e-03\n",
       "335     tfidf_335  4.482096e-03\n",
       "141     tfidf_141  4.378849e-03\n",
       "348     tfidf_348  4.369225e-03\n",
       "239     tfidf_239  4.194095e-03\n",
       "309     tfidf_309  4.109986e-03\n",
       "245     tfidf_245  4.100112e-03\n",
       "344     tfidf_344  4.022442e-03\n",
       "43       tfidf_43  3.950554e-03\n",
       "376     tfidf_376  3.754151e-03\n",
       "399     dry mouth  3.636493e-03\n",
       "73       tfidf_73  3.615196e-03\n",
       "415        sleepy  3.557599e-03\n",
       "137     tfidf_137  3.377258e-03\n",
       "402      euphoric  3.368356e-03\n",
       "15       tfidf_15  3.356288e-03\n",
       "441         lemon  3.311203e-03\n",
       "373     tfidf_373  3.308778e-03\n",
       "7         tfidf_7  3.301002e-03\n",
       "409        hungry  3.186973e-03\n",
       "111     tfidf_111  2.944759e-03\n",
       "30       tfidf_30  2.806368e-03\n",
       "263     tfidf_263  2.707210e-03\n",
       "283     tfidf_283  2.704248e-03\n",
       "420      uplifted  2.676452e-03\n",
       "163     tfidf_163  2.672019e-03\n",
       "382     tfidf_382  2.590154e-03\n",
       "334     tfidf_334  2.587466e-03\n",
       "230     tfidf_230  2.570398e-03\n",
       "70       tfidf_70  2.447145e-03\n",
       "452     pineapple  2.442119e-03\n",
       "276     tfidf_276  2.421653e-03\n",
       "253     tfidf_253  2.410049e-03\n",
       "190     tfidf_190  2.401667e-03\n",
       "277     tfidf_277  2.383829e-03\n",
       "406        giggly  2.378990e-03\n",
       "45       tfidf_45  2.301904e-03\n",
       "291     tfidf_291  2.285431e-03\n",
       "119     tfidf_119  2.281631e-03\n",
       "273     tfidf_273  2.191512e-03\n",
       "37       tfidf_37  2.172686e-03\n",
       "364     tfidf_364  2.153325e-03\n",
       "29       tfidf_29  2.129864e-03\n",
       "11       tfidf_11  2.041025e-03\n",
       "362     tfidf_362  2.022383e-03\n",
       "398      dry eyes  1.983186e-03\n",
       "437         grape  1.972452e-03\n",
       "432        coffee  1.939432e-03\n",
       "158     tfidf_158  1.895064e-03\n",
       "162     tfidf_162  1.887405e-03\n",
       "319     tfidf_319  1.883072e-03\n",
       "457         skunk  1.858015e-03\n",
       "240     tfidf_240  1.827117e-03\n",
       "280     tfidf_280  1.799345e-03\n",
       "360     tfidf_360  1.774861e-03\n",
       "258     tfidf_258  1.760628e-03\n",
       "128     tfidf_128  1.755940e-03\n",
       "350     tfidf_350  1.742407e-03\n",
       "342     tfidf_342  1.736611e-03\n",
       "324     tfidf_324  1.640887e-03\n",
       "314     tfidf_314  1.607987e-03\n",
       "318     tfidf_318  1.605828e-03\n",
       "200     tfidf_200  1.580954e-03\n",
       "418     talkative  1.522543e-03\n",
       "109     tfidf_109  1.511468e-03\n",
       "96       tfidf_96  1.504484e-03\n",
       "310     tfidf_310  1.440647e-03\n",
       "343     tfidf_343  1.439016e-03\n",
       "424         berry  1.436326e-03\n",
       "144     tfidf_144  1.421504e-03\n",
       "462           tea  1.415154e-03\n",
       "371     tfidf_371  1.401014e-03\n",
       "126     tfidf_126  1.386460e-03\n",
       "281     tfidf_281  1.383797e-03\n",
       "341     tfidf_341  1.374782e-03\n",
       "367     tfidf_367  1.367606e-03\n",
       "377     tfidf_377  1.352225e-03\n",
       "42       tfidf_42  1.304248e-03\n",
       "286     tfidf_286  1.287055e-03\n",
       "159     tfidf_159  1.283147e-03\n",
       "129     tfidf_129  1.269674e-03\n",
       "54       tfidf_54  1.249015e-03\n",
       "340     tfidf_340  1.237056e-03\n",
       "405       focused  1.209615e-03\n",
       "466       vanilla  1.206956e-03\n",
       "182     tfidf_182  1.185610e-03\n",
       "325     tfidf_325  1.151686e-03\n",
       "57       tfidf_57  1.149255e-03\n",
       "206     tfidf_206  1.148598e-03\n",
       "32       tfidf_32  1.137411e-03\n",
       "98       tfidf_98  1.131940e-03\n",
       "435       flowery  1.127746e-03\n",
       "390        sativa  1.103816e-03\n",
       "366     tfidf_366  1.094730e-03\n",
       "205     tfidf_205  1.088919e-03\n",
       "6         tfidf_6  1.080744e-03\n",
       "34       tfidf_34  1.063481e-03\n",
       "293     tfidf_293  1.059840e-03\n",
       "223     tfidf_223  1.048519e-03\n",
       "151     tfidf_151  1.043186e-03\n",
       "289     tfidf_289  1.003755e-03\n",
       "120     tfidf_120  1.001898e-03\n",
       "46       tfidf_46  9.949650e-04\n",
       "167     tfidf_167  9.679323e-04\n",
       "110     tfidf_110  9.604414e-04\n",
       "267     tfidf_267  9.586713e-04\n",
       "27       tfidf_27  9.550562e-04\n",
       "338     tfidf_338  9.535169e-04\n",
       "112     tfidf_112  9.526037e-04\n",
       "188     tfidf_188  9.496512e-04\n",
       "26       tfidf_26  9.480785e-04\n",
       "86       tfidf_86  9.478616e-04\n",
       "269     tfidf_269  9.401430e-04\n",
       "64       tfidf_64  9.385953e-04\n",
       "82       tfidf_82  9.340344e-04\n",
       "76       tfidf_76  9.294761e-04\n",
       "217     tfidf_217  9.291742e-04\n",
       "177     tfidf_177  9.260887e-04\n",
       "24       tfidf_24  9.218256e-04\n",
       "272     tfidf_272  8.992534e-04\n",
       "1         tfidf_1  8.975732e-04\n",
       "369     tfidf_369  8.948300e-04\n",
       "397         dizzy  8.948108e-04\n",
       "431        citrus  8.911820e-04\n",
       "275     tfidf_275  8.883206e-04\n",
       "445          mint  8.794037e-04\n",
       "124     tfidf_124  8.779203e-04\n",
       "107     tfidf_107  8.778133e-04\n",
       "157     tfidf_157  8.735842e-04\n",
       "213     tfidf_213  8.632959e-04\n",
       "198     tfidf_198  8.586641e-04\n",
       "55       tfidf_55  8.569824e-04\n",
       "69       tfidf_69  8.539553e-04\n",
       "430      chestnut  8.531286e-04\n",
       "311     tfidf_311  8.468218e-04\n",
       "270     tfidf_270  8.409271e-04\n",
       "288     tfidf_288  8.382843e-04\n",
       "36       tfidf_36  8.306664e-04\n",
       "178     tfidf_178  8.113670e-04\n",
       "278     tfidf_278  7.759473e-04\n",
       "191     tfidf_191  7.445279e-04\n",
       "103     tfidf_103  7.350251e-04\n",
       "75       tfidf_75  7.343237e-04\n",
       "48       tfidf_48  7.208059e-04\n",
       "79       tfidf_79  7.194351e-04\n",
       "243     tfidf_243  7.094185e-04\n",
       "39       tfidf_39  7.073375e-04\n",
       "123     tfidf_123  7.059750e-04\n",
       "56       tfidf_56  6.950982e-04\n",
       "215     tfidf_215  6.925873e-04\n",
       "429      chemical  6.817417e-04\n",
       "41       tfidf_41  6.786367e-04\n",
       "17       tfidf_17  6.750535e-04\n",
       "193     tfidf_193  6.562204e-04\n",
       "266     tfidf_266  6.515095e-04\n",
       "122     tfidf_122  6.510597e-04\n",
       "264     tfidf_264  6.501131e-04\n",
       "67       tfidf_67  6.367679e-04\n",
       "104     tfidf_104  6.366840e-04\n",
       "393       aroused  6.356963e-04\n",
       "21       tfidf_21  6.297083e-04\n",
       "354     tfidf_354  6.275908e-04\n",
       "138     tfidf_138  6.272949e-04\n",
       "389        indica  6.268117e-04\n",
       "320     tfidf_320  6.262078e-04\n",
       "184     tfidf_184  6.201735e-04\n",
       "299     tfidf_299  6.158955e-04\n",
       "61       tfidf_61  6.151020e-04\n",
       "22       tfidf_22  6.112030e-04\n",
       "92       tfidf_92  5.962398e-04\n",
       "353     tfidf_353  5.925387e-04\n",
       "380     tfidf_380  5.890342e-04\n",
       "326     tfidf_326  5.773707e-04\n",
       "339     tfidf_339  5.659852e-04\n",
       "231     tfidf_231  5.631476e-04\n",
       "336     tfidf_336  5.629572e-04\n",
       "153     tfidf_153  5.615077e-04\n",
       "321     tfidf_321  5.556907e-04\n",
       "271     tfidf_271  5.555415e-04\n",
       "233     tfidf_233  5.491583e-04\n",
       "130     tfidf_130  5.460366e-04\n",
       "160     tfidf_160  5.378740e-04\n",
       "226     tfidf_226  5.299050e-04\n",
       "8         tfidf_8  5.210888e-04\n",
       "51       tfidf_51  5.174644e-04\n",
       "161     tfidf_161  5.173317e-04\n",
       "125     tfidf_125  5.119496e-04\n",
       "268     tfidf_268  5.118607e-04\n",
       "316     tfidf_316  5.079161e-04\n",
       "152     tfidf_152  5.060699e-04\n",
       "297     tfidf_297  4.935151e-04\n",
       "4         tfidf_4  4.886874e-04\n",
       "203     tfidf_203  4.868769e-04\n",
       "221     tfidf_221  4.834292e-04\n",
       "209     tfidf_209  4.832463e-04\n",
       "180     tfidf_180  4.818497e-04\n",
       "381     tfidf_381  4.803170e-04\n",
       "421       ammonia  4.803165e-04\n",
       "80       tfidf_80  4.773861e-04\n",
       "16       tfidf_16  4.707453e-04\n",
       "219     tfidf_219  4.672391e-04\n",
       "146     tfidf_146  4.627085e-04\n",
       "176     tfidf_176  4.566029e-04\n",
       "186     tfidf_186  4.523779e-04\n",
       "60       tfidf_60  4.473307e-04\n",
       "365     tfidf_365  4.472740e-04\n",
       "49       tfidf_49  4.462453e-04\n",
       "179     tfidf_179  4.440256e-04\n",
       "202     tfidf_202  4.432122e-04\n",
       "468         woody  4.340982e-04\n",
       "374     tfidf_374  4.316739e-04\n",
       "31       tfidf_31  4.247415e-04\n",
       "53       tfidf_53  4.232591e-04\n",
       "172     tfidf_172  4.211210e-04\n",
       "236     tfidf_236  4.197908e-04\n",
       "195     tfidf_195  4.193103e-04\n",
       "175     tfidf_175  4.179153e-04\n",
       "259     tfidf_259  4.090774e-04\n",
       "222     tfidf_222  4.033323e-04\n",
       "9         tfidf_9  4.023530e-04\n",
       "139     tfidf_139  3.886369e-04\n",
       "294     tfidf_294  3.795279e-04\n",
       "208     tfidf_208  3.714703e-04\n",
       "248     tfidf_248  3.659834e-04\n",
       "260     tfidf_260  3.648767e-04\n",
       "302     tfidf_302  3.604877e-04\n",
       "71       tfidf_71  3.584536e-04\n",
       "458  spicy/herbal  3.560824e-04\n",
       "14       tfidf_14  3.553061e-04\n",
       "127     tfidf_127  3.437434e-04\n",
       "19       tfidf_19  3.432302e-04\n",
       "422         apple  3.431517e-04\n",
       "459    strawberry  3.409970e-04\n",
       "306     tfidf_306  3.340526e-04\n",
       "234     tfidf_234  3.308048e-04\n",
       "23       tfidf_23  3.260788e-04\n",
       "164     tfidf_164  3.221929e-04\n",
       "387     tfidf_387  3.168310e-04\n",
       "216     tfidf_216  3.125801e-04\n",
       "88       tfidf_88  3.116948e-04\n",
       "194     tfidf_194  3.073129e-04\n",
       "133     tfidf_133  3.068736e-04\n",
       "412      paranoid  3.049523e-04\n",
       "237     tfidf_237  3.044918e-04\n",
       "201     tfidf_201  3.015371e-04\n",
       "171     tfidf_171  2.993547e-04\n",
       "300     tfidf_300  2.990508e-04\n",
       "81       tfidf_81  2.944121e-04\n",
       "392       anxious  2.942053e-04\n",
       "456          sage  2.936674e-04\n",
       "13       tfidf_13  2.912883e-04\n",
       "298     tfidf_298  2.882650e-04\n",
       "148     tfidf_148  2.864671e-04\n",
       "355     tfidf_355  2.858194e-04\n",
       "386     tfidf_386  2.840079e-04\n",
       "99       tfidf_99  2.837199e-04\n",
       "136     tfidf_136  2.814469e-04\n",
       "85       tfidf_85  2.803127e-04\n",
       "225     tfidf_225  2.795277e-04\n",
       "97       tfidf_97  2.791044e-04\n",
       "372     tfidf_372  2.759489e-04\n",
       "115     tfidf_115  2.749182e-04\n",
       "465      tropical  2.743971e-04\n",
       "181     tfidf_181  2.728321e-04\n",
       "117     tfidf_117  2.708926e-04\n",
       "58       tfidf_58  2.705195e-04\n",
       "170     tfidf_170  2.705070e-04\n",
       "255     tfidf_255  2.699753e-04\n",
       "361     tfidf_361  2.690530e-04\n",
       "254     tfidf_254  2.678275e-04\n",
       "304     tfidf_304  2.672724e-04\n",
       "227     tfidf_227  2.662845e-04\n",
       "261     tfidf_261  2.642980e-04\n",
       "351     tfidf_351  2.600038e-04\n",
       "116     tfidf_116  2.557033e-04\n",
       "384     tfidf_384  2.524569e-04\n",
       "359     tfidf_359  2.516148e-04\n",
       "443         mango  2.510853e-04\n",
       "102     tfidf_102  2.478659e-04\n",
       "135     tfidf_135  2.477729e-04\n",
       "251     tfidf_251  2.453017e-04\n",
       "185     tfidf_185  2.435667e-04\n",
       "356     tfidf_356  2.413664e-04\n",
       "118     tfidf_118  2.405578e-04\n",
       "28       tfidf_28  2.405233e-04\n",
       "3         tfidf_3  2.389548e-04\n",
       "370     tfidf_370  2.355081e-04\n",
       "108     tfidf_108  2.349638e-04\n",
       "292     tfidf_292  2.340707e-04\n",
       "244     tfidf_244  2.299201e-04\n",
       "257     tfidf_257  2.270699e-04\n",
       "282     tfidf_282  2.266814e-04\n",
       "147     tfidf_147  2.262483e-04\n",
       "142     tfidf_142  2.192271e-04\n",
       "62       tfidf_62  2.146934e-04\n",
       "65       tfidf_65  2.146554e-04\n",
       "274     tfidf_274  2.138746e-04\n",
       "211     tfidf_211  2.119075e-04\n",
       "94       tfidf_94  2.112064e-04\n",
       "44       tfidf_44  2.092009e-04\n",
       "287     tfidf_287  2.065664e-04\n",
       "113     tfidf_113  2.065549e-04\n",
       "52       tfidf_52  2.056787e-04\n",
       "40       tfidf_40  2.047519e-04\n",
       "224     tfidf_224  2.041784e-04\n",
       "143     tfidf_143  2.029720e-04\n",
       "358     tfidf_358  1.986463e-04\n",
       "150     tfidf_150  1.958603e-04\n",
       "363     tfidf_363  1.951122e-04\n",
       "438    grapefruit  1.938467e-04\n",
       "252     tfidf_252  1.919726e-04\n",
       "63       tfidf_63  1.909667e-04\n",
       "446         nutty  1.892335e-04\n",
       "246     tfidf_246  1.880848e-04\n",
       "214     tfidf_214  1.823981e-04\n",
       "10       tfidf_10  1.810967e-04\n",
       "330     tfidf_330  1.786652e-04\n",
       "106     tfidf_106  1.779936e-04\n",
       "450        pepper  1.766559e-04\n",
       "408      headache  1.733546e-04\n",
       "212     tfidf_212  1.726852e-04\n",
       "279     tfidf_279  1.726549e-04\n",
       "220     tfidf_220  1.713470e-04\n",
       "2         tfidf_2  1.710858e-04\n",
       "25       tfidf_25  1.708087e-04\n",
       "187     tfidf_187  1.696638e-04\n",
       "74       tfidf_74  1.674801e-04\n",
       "383     tfidf_383  1.657119e-04\n",
       "352     tfidf_352  1.651152e-04\n",
       "427        butter  1.650688e-04\n",
       "301     tfidf_301  1.642271e-04\n",
       "87       tfidf_87  1.621854e-04\n",
       "59       tfidf_59  1.620560e-04\n",
       "192     tfidf_192  1.596217e-04\n",
       "155     tfidf_155  1.595883e-04\n",
       "83       tfidf_83  1.584377e-04\n",
       "328     tfidf_328  1.555389e-04\n",
       "375     tfidf_375  1.540499e-04\n",
       "368     tfidf_368  1.537696e-04\n",
       "169     tfidf_169  1.510340e-04\n",
       "290     tfidf_290  1.460551e-04\n",
       "436         fruit  1.459774e-04\n",
       "68       tfidf_68  1.455144e-04\n",
       "183     tfidf_183  1.452781e-04\n",
       "77       tfidf_77  1.419306e-04\n",
       "308     tfidf_308  1.411551e-04\n",
       "284     tfidf_284  1.388405e-04\n",
       "323     tfidf_323  1.369980e-04\n",
       "165     tfidf_165  1.368948e-04\n",
       "295     tfidf_295  1.352507e-04\n",
       "95       tfidf_95  1.336393e-04\n",
       "174     tfidf_174  1.311257e-04\n",
       "442          lime  1.307964e-04\n",
       "66       tfidf_66  1.307456e-04\n",
       "347     tfidf_347  1.300103e-04\n",
       "47       tfidf_47  1.295017e-04\n",
       "232     tfidf_232  1.258038e-04\n",
       "33       tfidf_33  1.250920e-04\n",
       "132     tfidf_132  1.228716e-04\n",
       "38       tfidf_38  1.204341e-04\n",
       "305     tfidf_305  1.200599e-04\n",
       "349     tfidf_349  1.178057e-04\n",
       "332     tfidf_332  1.170227e-04\n",
       "315     tfidf_315  1.140118e-04\n",
       "327     tfidf_327  1.130439e-04\n",
       "379     tfidf_379  1.128230e-04\n",
       "140     tfidf_140  1.123637e-04\n",
       "228     tfidf_228  1.117134e-04\n",
       "12       tfidf_12  1.084142e-04\n",
       "35       tfidf_35  1.077853e-04\n",
       "262     tfidf_262  1.077759e-04\n",
       "229     tfidf_229  1.076054e-04\n",
       "197     tfidf_197  1.074870e-04\n",
       "196     tfidf_196  1.065876e-04\n",
       "249     tfidf_249  1.056799e-04\n",
       "131     tfidf_131  1.025714e-04\n",
       "455          rose  9.926312e-05\n",
       "464          tree  9.769596e-05\n",
       "50       tfidf_50  9.647247e-05\n",
       "134     tfidf_134  9.611476e-05\n",
       "84       tfidf_84  9.221678e-05\n",
       "218     tfidf_218  9.095110e-05\n",
       "322     tfidf_322  9.071471e-05\n",
       "238     tfidf_238  9.014450e-05\n",
       "307     tfidf_307  8.739971e-05\n",
       "461           tar  8.722893e-05\n",
       "331     tfidf_331  8.720079e-05\n",
       "100     tfidf_100  8.634720e-05\n",
       "18       tfidf_18  8.567563e-05\n",
       "256     tfidf_256  8.462937e-05\n",
       "440      lavender  8.404762e-05\n",
       "156     tfidf_156  8.332941e-05\n",
       "296     tfidf_296  8.255241e-05\n",
       "333     tfidf_333  8.039076e-05\n",
       "317     tfidf_317  7.975740e-05\n",
       "114     tfidf_114  7.613787e-05\n",
       "242     tfidf_242  7.556148e-05\n",
       "346     tfidf_346  7.169941e-05\n",
       "204     tfidf_204  5.863351e-05\n",
       "378     tfidf_378  5.477676e-05\n",
       "449          pear  5.342057e-05\n",
       "453          plum  5.118443e-05\n",
       "89       tfidf_89  4.887673e-05\n",
       "444       menthol  4.720845e-05\n",
       "241     tfidf_241  4.553424e-05\n",
       "72       tfidf_72  4.525108e-05\n",
       "463       tobacco  3.974587e-05\n",
       "250     tfidf_250  2.665532e-05\n",
       "448         peach  2.141595e-05\n",
       "425   blue cheese  2.026013e-05\n",
       "467        violet  2.016538e-05\n",
       "423       apricot  1.561635e-05\n",
       "396    depression  6.060078e-06\n",
       "391       anxiety  5.986459e-06\n",
       "410     migraines  4.153994e-06\n",
       "403  eye pressure  4.581619e-08\n",
       "401      epilepsy  1.577801e-09\n",
       "411          pain  1.464560e-09\n",
       "414      seizures  0.000000e+00\n",
       "394     arthritis  0.000000e+00\n",
       "404       fatigue  0.000000e+00\n",
       "416    spasticity  0.000000e+00\n",
       "417        stress  0.000000e+00"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.set_option('display.max_rows', df_feat_ranked.shape[0]+1)\n",
    "df_feat_ranked"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/andalanputra/opt/anaconda3/lib/python3.9/site-packages/sklearn/feature_selection/_from_model.py:357: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  self.estimator_.fit(X, y, **fit_params)\n"
     ]
    }
   ],
   "source": [
    "selector = SelectFromModel(rfreg).fit(X_train1, y_train1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([4.76699946e-03, 1.06090383e-03, 1.71271944e-04, 4.36178623e-04,\n",
       "       5.33474132e-04, 7.97860303e-03, 1.29609285e-03, 3.30401004e-03,\n",
       "       4.79452554e-04, 4.67481066e-04, 1.71078142e-04, 1.96874625e-03,\n",
       "       1.03204671e-04, 3.19854227e-04, 3.96335922e-04, 3.04831478e-03,\n",
       "       4.38208210e-04, 6.66538045e-04, 6.64990268e-05, 3.61341829e-04,\n",
       "       4.88802760e-03, 6.60876368e-04, 6.15951761e-04, 3.17790961e-04,\n",
       "       1.03267726e-03, 1.43162478e-04, 9.48985072e-04, 1.47264787e-03,\n",
       "       2.57595325e-04, 2.33111966e-03, 2.80711745e-03, 4.05114839e-04,\n",
       "       9.36011084e-04, 1.00268159e-04, 1.19556742e-03, 1.05421828e-04,\n",
       "       6.95777759e-04, 2.24349634e-03, 1.19440157e-04, 9.80268173e-04,\n",
       "       1.95565808e-04, 6.75311303e-04, 1.61469984e-03, 4.04161723e-03,\n",
       "       2.13623904e-04, 1.99173516e-03, 1.06957269e-03, 1.59608086e-04,\n",
       "       7.52303917e-04, 6.81391915e-04, 1.09558741e-04, 3.87382275e-04,\n",
       "       2.26678685e-04, 4.16850070e-04, 1.04447511e-03, 8.82613261e-04,\n",
       "       5.54260668e-04, 1.47485825e-03, 2.61080163e-04, 2.23601650e-04,\n",
       "       5.32579646e-04, 5.46432290e-04, 2.24036026e-04, 2.78844402e-04,\n",
       "       7.67801049e-04, 2.01241300e-04, 1.35561897e-04, 8.87891915e-04,\n",
       "       1.23584610e-04, 8.35283699e-04, 2.57204191e-03, 3.46178292e-04,\n",
       "       5.12226056e-05, 3.48035337e-03, 1.69110718e-04, 9.63934380e-04,\n",
       "       8.54220331e-04, 1.45294095e-04, 1.40955661e-02, 7.95937714e-04,\n",
       "       4.62036610e-04, 3.42898115e-04, 1.02070745e-03, 1.37968665e-04,\n",
       "       1.17313426e-04, 2.84149738e-04, 9.22986122e-04, 1.37426614e-04,\n",
       "       2.14315950e-04, 5.51191162e-05, 1.03566134e-02, 7.18339229e-03,\n",
       "       5.33453540e-04, 1.03299291e-02, 2.05471152e-04, 1.54683370e-04,\n",
       "       1.32424672e-03, 2.26786736e-04, 1.12392961e-03, 3.93467340e-04,\n",
       "       1.15326178e-04, 1.00434728e-02, 2.30906284e-04, 6.97602934e-04,\n",
       "       6.18853043e-04, 5.90546153e-03, 1.69455578e-04, 8.83910578e-04,\n",
       "       2.41237938e-04, 1.39832552e-03, 1.06757605e-03, 3.14340555e-03,\n",
       "       1.12614392e-03, 1.92994675e-04, 7.75370810e-05, 4.96796321e-04,\n",
       "       2.53633169e-04, 3.00620894e-04, 2.20712294e-04, 2.18524839e-03,\n",
       "       9.98074795e-04, 6.38184812e-03, 4.67400476e-04, 8.27040546e-04,\n",
       "       7.63965467e-04, 5.32660284e-04, 1.35552369e-03, 3.21088941e-04,\n",
       "       2.01617942e-03, 1.20660140e-03, 6.84731133e-04, 1.27791541e-04,\n",
       "       1.85870168e-04, 4.04472737e-04, 1.26719075e-04, 2.42005841e-04,\n",
       "       3.09933651e-04, 2.98781034e-03, 7.13003102e-04, 2.99791921e-04,\n",
       "       1.16073859e-04, 4.52989439e-03, 1.68902883e-04, 2.01835502e-04,\n",
       "       1.60535355e-03, 1.38513388e-02, 3.31972116e-04, 2.77725964e-04,\n",
       "       6.39236795e-04, 8.60217257e-03, 2.01199675e-04, 1.10093212e-03,\n",
       "       4.88022016e-04, 6.13480856e-04, 6.10357737e-03, 1.76295518e-04,\n",
       "       7.50530958e-05, 8.96147371e-04, 2.25072535e-03, 1.31320342e-03,\n",
       "       5.96729611e-04, 5.29013075e-04, 1.82403995e-03, 2.79522615e-03,\n",
       "       4.45966223e-04, 1.38848454e-04, 5.00925844e-03, 9.58561859e-04,\n",
       "       1.67936190e-02, 1.77574107e-04, 3.19457549e-04, 3.10083355e-04,\n",
       "       4.82009562e-04, 6.21537821e-03, 1.64671728e-04, 4.32819209e-04,\n",
       "       4.74383933e-04, 8.11795916e-04, 8.10562534e-04, 5.35772832e-04,\n",
       "       4.94179586e-04, 2.87430568e-04, 1.38739426e-03, 1.40821585e-04,\n",
       "       7.27826524e-04, 2.07948922e-04, 4.24946772e-04, 1.62104383e-04,\n",
       "       2.73704575e-04, 6.18547317e-03, 2.39105107e-03, 7.72782893e-04,\n",
       "       1.78627199e-04, 6.73827452e-04, 2.95377696e-04, 3.92923782e-04,\n",
       "       9.08146294e-05, 1.21353229e-04, 7.01115696e-04, 7.80369547e-03,\n",
       "       1.41400806e-03, 2.01010872e-04, 4.20851985e-04, 4.35216006e-04,\n",
       "       6.77774094e-05, 1.38829570e-03, 1.14921817e-03, 1.03472041e-02,\n",
       "       2.93736820e-04, 3.93146607e-04, 6.28688392e-03, 2.36363661e-04,\n",
       "       2.10847094e-04, 5.12723348e-04, 1.75331093e-04, 7.47087139e-04,\n",
       "       3.24710788e-04, 6.84504344e-04, 9.27803417e-05, 5.54819508e-04,\n",
       "       1.74220932e-04, 5.06167167e-04, 4.37567124e-04, 1.01327617e-03,\n",
       "       2.34678940e-04, 2.78603121e-04, 5.37167725e-04, 2.42761294e-04,\n",
       "       1.25693435e-04, 1.14162175e-04, 2.76535186e-03, 5.15176076e-04,\n",
       "       1.19728609e-04, 5.87406198e-04, 3.05364243e-04, 4.50013701e-03,\n",
       "       4.03170478e-04, 3.09726935e-04, 7.70441293e-05, 4.50796209e-03,\n",
       "       1.89923668e-03, 4.23385471e-05, 8.41417211e-05, 7.03563621e-04,\n",
       "       2.19811818e-04, 4.17061214e-03, 1.70787435e-04, 9.12730918e-03,\n",
       "       4.23741085e-04, 1.42548647e-04, 2.77709782e-05, 2.29880725e-04,\n",
       "       2.00578273e-04, 2.49628058e-03, 3.11767788e-04, 4.21748960e-04,\n",
       "       8.88491317e-05, 2.37894590e-04, 1.68484059e-03, 3.33642964e-04,\n",
       "       3.78292957e-04, 2.80117687e-04, 8.65432156e-05, 2.92701540e-03,\n",
       "       6.56810370e-04, 2.90889077e-02, 5.57870878e-04, 9.26553095e-04,\n",
       "       4.51769203e-04, 6.82418916e-04, 9.07876616e-04, 5.74922311e-04,\n",
       "       8.99432739e-04, 2.31725330e-03, 2.15534021e-04, 9.60432333e-04,\n",
       "       2.05316244e-03, 2.51652313e-03, 1.01849060e-03, 1.81611660e-04,\n",
       "       9.77573339e-04, 1.52774546e-03, 3.02238685e-04, 2.51252351e-03,\n",
       "       1.16984644e-04, 6.77640242e-03, 1.14073507e-03, 1.98628332e-04,\n",
       "       9.60578136e-04, 1.02397474e-03, 1.30124708e-04, 1.83640229e-03,\n",
       "       1.83636977e-04, 8.90376208e-04, 3.11587127e-04, 1.48067907e-04,\n",
       "       8.80733880e-05, 4.69530132e-04, 2.93201158e-04, 6.27575367e-04,\n",
       "       3.91328807e-04, 1.49401667e-04, 3.03157313e-04, 7.89810833e-03,\n",
       "       2.75692861e-04, 1.11605642e-04, 3.81683872e-04, 1.13516563e-04,\n",
       "       2.01723351e-04, 4.33947410e-03, 1.36477785e-03, 8.53803621e-04,\n",
       "       1.38819860e-02, 6.29482346e-03, 1.62061782e-03, 1.12273857e-04,\n",
       "       3.74175246e-04, 7.87536375e-05, 1.61396406e-03, 1.03293921e-03,\n",
       "       5.47727562e-04, 5.23177695e-04, 9.29357534e-05, 1.52530706e-04,\n",
       "       1.32483435e-03, 1.08606987e-03, 7.90580634e-04, 9.75025397e-05,\n",
       "       1.46471589e-04, 2.63153901e-02, 1.73876718e-04, 9.85542631e-05,\n",
       "       1.10121515e-04, 9.30287929e-05, 2.50935440e-03, 3.94725732e-03,\n",
       "       6.07901094e-04, 8.42001726e-03, 8.09870471e-04, 2.86001369e-04,\n",
       "       1.23798169e-03, 1.09724504e-03, 1.90156380e-03, 1.49642469e-03,\n",
       "       3.71196404e-03, 8.86001404e-03, 8.14872933e-05, 1.48254445e-04,\n",
       "       4.98182394e-03, 9.97758367e-05, 1.72221568e-03, 2.09822870e-04,\n",
       "       1.53937212e-04, 5.81987045e-04, 5.95688901e-04, 2.77505480e-04,\n",
       "       3.06081533e-04, 4.97619750e-03, 1.98824289e-04, 2.24000335e-04,\n",
       "       1.76762539e-03, 3.30507912e-04, 1.86859480e-03, 1.90256951e-04,\n",
       "       1.60325475e-03, 4.52263244e-04, 1.09154099e-03, 1.39960847e-03,\n",
       "       1.52282787e-04, 7.97530144e-04, 2.64436749e-04, 1.41959437e-03,\n",
       "       3.11693495e-04, 3.05213215e-03, 4.32822980e-04, 1.02062872e-04,\n",
       "       3.35891997e-03, 1.39797477e-03, 4.80122293e-05, 1.08185170e-04,\n",
       "       5.63791544e-04, 4.28390368e-04, 2.91282607e-03, 2.08423946e-04,\n",
       "       1.99426879e-04, 5.91321108e-03, 3.21955906e-04, 4.26562829e-04,\n",
       "       2.32490389e-01, 6.15027872e-04, 1.04119411e-03, 4.68603137e-06,\n",
       "       3.65226573e-04, 6.85427030e-04, 0.00000000e+00, 5.40602950e-03,\n",
       "       5.13435628e-06, 8.74290207e-04, 2.09636512e-03, 3.99170000e-03,\n",
       "       7.52399027e-03, 3.84489949e-08, 3.34751296e-03, 4.12738362e-08,\n",
       "       8.81007369e-10, 1.26823077e-03, 2.07595896e-03, 4.43108170e-03,\n",
       "       1.62196127e-04, 4.29375112e-03, 4.13998511e-06, 0.00000000e+00,\n",
       "       2.82060459e-04, 4.75526601e-03, 2.07500509e-08, 3.60947693e-03,\n",
       "       0.00000000e+00, 0.00000000e+00, 1.34547363e-03, 7.95514090e-03,\n",
       "       2.92438320e-03, 4.41312825e-04, 3.06682499e-04, 1.30553907e-05,\n",
       "       1.32816217e-03, 2.44793092e-05, 8.66075885e-03, 1.23759886e-04,\n",
       "       2.36426866e-02, 4.93624780e-04, 8.83168261e-04, 9.11561589e-04,\n",
       "       1.99171213e-03, 7.35510037e-03, 5.19776666e-03, 1.32121842e-03,\n",
       "       1.25867728e-04, 1.96325314e-03, 2.13573185e-04, 8.61797794e-03,\n",
       "       8.98094062e-05, 2.76904377e-03, 1.33926729e-04, 3.06225911e-04,\n",
       "       5.19041665e-05, 9.49001427e-04, 1.69278051e-04, 1.47564473e-02,\n",
       "       2.16065914e-05, 6.70750473e-05, 1.67841945e-04, 2.48973673e-02,\n",
       "       2.75237191e-03, 4.45246738e-05, 6.26016802e-03, 6.95875208e-05,\n",
       "       3.25166627e-04, 2.10408078e-03, 2.93013396e-04, 3.35729772e-04,\n",
       "       8.37033226e-03, 9.02378775e-05, 1.21764258e-03, 4.06850883e-05,\n",
       "       1.05030036e-04, 2.31980462e-04, 1.08947330e-03, 1.74217090e-05,\n",
       "       4.75894029e-04])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "selector.estimator_.feature_importances_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0021321961620469083"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "selector.threshold_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "mask = selector.get_support()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ True, False, False, False, False,  True, False,  True, False,\n",
       "       False, False, False, False, False, False,  True, False, False,\n",
       "       False, False,  True, False, False, False, False, False, False,\n",
       "       False, False,  True,  True, False, False, False, False, False,\n",
       "       False,  True, False, False, False, False, False,  True, False,\n",
       "       False, False, False, False, False, False, False, False, False,\n",
       "       False, False, False, False, False, False, False, False, False,\n",
       "       False, False, False, False, False, False, False,  True, False,\n",
       "       False,  True, False, False, False, False,  True, False, False,\n",
       "       False, False, False, False, False, False, False, False, False,\n",
       "        True,  True, False,  True, False, False, False, False, False,\n",
       "       False, False,  True, False, False, False,  True, False, False,\n",
       "       False, False, False,  True, False, False, False, False, False,\n",
       "       False, False,  True, False,  True, False, False, False, False,\n",
       "       False, False, False, False, False, False, False, False, False,\n",
       "       False, False,  True, False, False, False,  True, False, False,\n",
       "       False,  True, False, False, False,  True, False, False, False,\n",
       "       False,  True, False, False, False,  True, False, False, False,\n",
       "       False,  True, False, False,  True, False,  True, False, False,\n",
       "       False, False,  True, False, False, False, False, False, False,\n",
       "       False, False, False, False, False, False, False, False, False,\n",
       "        True,  True, False, False, False, False, False, False, False,\n",
       "       False,  True, False, False, False, False, False, False, False,\n",
       "        True, False, False,  True, False, False, False, False, False,\n",
       "       False, False, False, False, False, False, False, False, False,\n",
       "       False, False, False, False, False,  True, False, False, False,\n",
       "       False,  True, False, False, False,  True, False, False, False,\n",
       "       False, False,  True, False,  True, False, False, False, False,\n",
       "       False,  True, False, False, False, False, False, False, False,\n",
       "       False, False,  True, False,  True, False, False, False, False,\n",
       "       False, False, False,  True, False, False, False,  True, False,\n",
       "       False, False, False, False,  True, False,  True, False, False,\n",
       "       False, False, False, False, False, False, False, False, False,\n",
       "       False, False, False, False, False, False,  True, False, False,\n",
       "       False, False, False,  True, False, False,  True,  True, False,\n",
       "       False, False, False, False, False, False, False, False, False,\n",
       "       False, False, False, False, False,  True, False, False, False,\n",
       "       False,  True,  True, False,  True, False, False, False, False,\n",
       "       False, False,  True,  True, False, False,  True, False, False,\n",
       "       False, False, False, False, False, False,  True, False, False,\n",
       "       False, False, False, False, False, False, False, False, False,\n",
       "       False, False, False, False,  True, False, False,  True, False,\n",
       "       False, False, False, False,  True, False, False,  True, False,\n",
       "       False,  True, False, False, False, False, False, False,  True,\n",
       "       False, False, False,  True,  True, False,  True, False, False,\n",
       "       False, False,  True, False,  True, False, False, False,  True,\n",
       "       False,  True, False, False, False,  True,  True, False, False,\n",
       "       False, False, False,  True, False,  True, False, False, False,\n",
       "       False,  True,  True, False, False, False, False,  True, False,\n",
       "        True, False, False, False, False, False,  True, False, False,\n",
       "       False,  True,  True, False,  True, False, False, False, False,\n",
       "       False,  True, False, False, False, False, False, False, False,\n",
       "       False])"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "selected_features = X.columns[mask]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tfidf_0</th>\n",
       "      <th>tfidf_5</th>\n",
       "      <th>tfidf_7</th>\n",
       "      <th>tfidf_15</th>\n",
       "      <th>tfidf_20</th>\n",
       "      <th>tfidf_29</th>\n",
       "      <th>tfidf_30</th>\n",
       "      <th>tfidf_37</th>\n",
       "      <th>tfidf_43</th>\n",
       "      <th>tfidf_70</th>\n",
       "      <th>...</th>\n",
       "      <th>cheese</th>\n",
       "      <th>diesel</th>\n",
       "      <th>earthy</th>\n",
       "      <th>honey</th>\n",
       "      <th>lemon</th>\n",
       "      <th>orange</th>\n",
       "      <th>pine</th>\n",
       "      <th>pineapple</th>\n",
       "      <th>pungent</th>\n",
       "      <th>sweet</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.14162</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.14162</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>74995</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.322452</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>74996</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>74997</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>74998</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>74999</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>75000 rows × 85 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       tfidf_0   tfidf_5  tfidf_7  tfidf_15  tfidf_20  tfidf_29  tfidf_30  \\\n",
       "0          0.0  0.000000      0.0       0.0       0.0       0.0       0.0   \n",
       "1          0.0  0.000000      0.0       0.0       0.0       0.0       0.0   \n",
       "2          0.0  0.000000      0.0       0.0       0.0       0.0       0.0   \n",
       "3          0.0  0.000000      0.0       0.0       0.0       0.0       0.0   \n",
       "4          0.0  0.000000      0.0       0.0       0.0       0.0       0.0   \n",
       "...        ...       ...      ...       ...       ...       ...       ...   \n",
       "74995      0.0  0.322452      0.0       0.0       0.0       0.0       0.0   \n",
       "74996      0.0  0.000000      0.0       0.0       0.0       0.0       0.0   \n",
       "74997      0.0  0.000000      0.0       0.0       0.0       0.0       0.0   \n",
       "74998      0.0  0.000000      0.0       0.0       0.0       0.0       0.0   \n",
       "74999      0.0  0.000000      0.0       0.0       0.0       0.0       0.0   \n",
       "\n",
       "       tfidf_37  tfidf_43  tfidf_70  ...  cheese  diesel  earthy  honey  \\\n",
       "0       0.14162       0.0       0.0  ...       0       0       0      0   \n",
       "1       0.14162       0.0       0.0  ...       0       0       0      0   \n",
       "2       0.00000       0.0       0.0  ...       1       0       0      0   \n",
       "3       0.00000       0.0       0.0  ...       1       0       0      0   \n",
       "4       0.00000       0.0       0.0  ...       1       0       0      0   \n",
       "...         ...       ...       ...  ...     ...     ...     ...    ...   \n",
       "74995   0.00000       0.0       0.0  ...       0       0       0      0   \n",
       "74996   0.00000       0.0       0.0  ...       0       0       0      0   \n",
       "74997   0.00000       0.0       0.0  ...       0       0       0      0   \n",
       "74998   0.00000       0.0       0.0  ...       0       0       0      0   \n",
       "74999   0.00000       0.0       0.0  ...       1       1       1      1   \n",
       "\n",
       "       lemon  orange  pine  pineapple  pungent  sweet  \n",
       "0          0       0     0          0        0      0  \n",
       "1          0       0     0          0        0      0  \n",
       "2          0       0     0          0        0      0  \n",
       "3          0       0     0          0        0      0  \n",
       "4          0       0     0          0        0      0  \n",
       "...      ...     ...   ...        ...      ...    ...  \n",
       "74995      0       0     0          0        0      0  \n",
       "74996      0       0     0          0        0      0  \n",
       "74997      0       0     0          0        0      0  \n",
       "74998      0       0     0          0        0      0  \n",
       "74999      1       1     1          1        1      1  \n",
       "\n",
       "[75000 rows x 85 columns]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "selected_X = df_rf[selected_features]\n",
    "selected_X"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train test split (after Feature Selection)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['selected_X_rf_tfidf_linalol.pkl']"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import joblib\n",
    "\n",
    "joblib.dump(selector, \"selector_rf_tfidf_linalol.pkl\")\n",
    "joblib.dump(selected_X, \"selected_X_rf_tfidf_linalol.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "import joblib\n",
    "\n",
    "selected_X = joblib.load(\"selected_X_rf_tfidf_linalol.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(selected_X, y, random_state=1, test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train1, X_val, y_train1, y_val = train_test_split(X_train, y_train, random_state=1, test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/y1/pjvjlkjn5gl846rnyzr53p340000gn/T/ipykernel_11392/3758305.py:1: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  rfreg.fit(X_train1, y_train1)\n"
     ]
    }
   ],
   "source": [
    "rfreg.fit(X_train1, y_train1)\n",
    "y_pred_rfreg = rfreg.predict(X_val)\n",
    "y_pred_rfreg_r2 = rfreg.predict(X_train1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.03856700365281105"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mean_absolute_error(y_val, y_pred_rfreg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.006879632749237326"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mean_squared_error(y_val, y_pred_rfreg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.08294355158321427"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mean_squared_error(y_val, y_pred_rfreg, squared = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9755168731523437"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#train\n",
    "r2_score(y_train1, y_pred_rfreg_r2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9312689438446768"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#val\n",
    "r2_score(y_val, y_pred_rfreg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hyperparameter Tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "parameters = {'max_depth': [None, 10, 50, 100],\n",
    "              'max_features': ['auto', 'sqrt'],\n",
    "              'min_samples_leaf': [1, 2, 4],\n",
    "              'min_samples_split': [2, 5, 10],\n",
    "              'n_estimators': [100, 300, 500]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "rscv = RandomizedSearchCV(rfreg,  \n",
    "                     parameters,   \n",
    "                     cv=5, \n",
    "                     scoring='neg_mean_absolute_error',\n",
    "                     n_jobs = -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/andalanputra/opt/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/Users/andalanputra/opt/anaconda3/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
      "  warn(\n",
      "/Users/andalanputra/opt/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/Users/andalanputra/opt/anaconda3/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
      "  warn(\n",
      "/Users/andalanputra/opt/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/Users/andalanputra/opt/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/Users/andalanputra/opt/anaconda3/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
      "  warn(\n",
      "/Users/andalanputra/opt/anaconda3/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
      "  warn(\n",
      "/Users/andalanputra/opt/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/Users/andalanputra/opt/anaconda3/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
      "  warn(\n",
      "/Users/andalanputra/opt/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/Users/andalanputra/opt/anaconda3/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
      "  warn(\n",
      "/Users/andalanputra/opt/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/Users/andalanputra/opt/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/Users/andalanputra/opt/anaconda3/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
      "  warn(\n",
      "/Users/andalanputra/opt/anaconda3/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
      "  warn(\n",
      "/Users/andalanputra/opt/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/Users/andalanputra/opt/anaconda3/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
      "  warn(\n",
      "/Users/andalanputra/opt/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/Users/andalanputra/opt/anaconda3/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
      "  warn(\n",
      "/Users/andalanputra/opt/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/Users/andalanputra/opt/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/Users/andalanputra/opt/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/Users/andalanputra/opt/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/Users/andalanputra/opt/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/Users/andalanputra/opt/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/Users/andalanputra/opt/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/Users/andalanputra/opt/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/Users/andalanputra/opt/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/Users/andalanputra/opt/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/Users/andalanputra/opt/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/Users/andalanputra/opt/anaconda3/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
      "  warn(\n",
      "/Users/andalanputra/opt/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/Users/andalanputra/opt/anaconda3/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
      "  warn(\n",
      "/Users/andalanputra/opt/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/Users/andalanputra/opt/anaconda3/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
      "  warn(\n",
      "/Users/andalanputra/opt/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/Users/andalanputra/opt/anaconda3/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
      "  warn(\n",
      "/Users/andalanputra/opt/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/Users/andalanputra/opt/anaconda3/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
      "  warn(\n",
      "/Users/andalanputra/opt/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/Users/andalanputra/opt/anaconda3/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
      "  warn(\n",
      "/Users/andalanputra/opt/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/Users/andalanputra/opt/anaconda3/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
      "  warn(\n",
      "/Users/andalanputra/opt/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/Users/andalanputra/opt/anaconda3/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
      "  warn(\n",
      "/Users/andalanputra/opt/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/Users/andalanputra/opt/anaconda3/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
      "  warn(\n",
      "/Users/andalanputra/opt/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/Users/andalanputra/opt/anaconda3/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
      "  warn(\n",
      "/Users/andalanputra/opt/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/Users/andalanputra/opt/anaconda3/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
      "  warn(\n",
      "/Users/andalanputra/opt/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/Users/andalanputra/opt/anaconda3/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
      "  warn(\n",
      "/Users/andalanputra/opt/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/Users/andalanputra/opt/anaconda3/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
      "  warn(\n",
      "/Users/andalanputra/opt/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/Users/andalanputra/opt/anaconda3/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
      "  warn(\n",
      "/Users/andalanputra/opt/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/Users/andalanputra/opt/anaconda3/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
      "  warn(\n",
      "/Users/andalanputra/opt/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/Users/andalanputra/opt/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/Users/andalanputra/opt/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/Users/andalanputra/opt/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/Users/andalanputra/opt/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/Users/andalanputra/opt/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/Users/andalanputra/opt/anaconda3/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
      "  warn(\n",
      "/Users/andalanputra/opt/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/Users/andalanputra/opt/anaconda3/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
      "  warn(\n",
      "/Users/andalanputra/opt/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/Users/andalanputra/opt/anaconda3/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
      "  warn(\n",
      "/Users/andalanputra/opt/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/Users/andalanputra/opt/anaconda3/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
      "  warn(\n",
      "/Users/andalanputra/opt/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/Users/andalanputra/opt/anaconda3/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
      "  warn(\n",
      "/Users/andalanputra/opt/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/Users/andalanputra/opt/anaconda3/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
      "  warn(\n",
      "/Users/andalanputra/opt/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/Users/andalanputra/opt/anaconda3/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
      "  warn(\n",
      "/Users/andalanputra/opt/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/Users/andalanputra/opt/anaconda3/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
      "  warn(\n",
      "/Users/andalanputra/opt/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/Users/andalanputra/opt/anaconda3/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
      "  warn(\n",
      "/Users/andalanputra/opt/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/Users/andalanputra/opt/anaconda3/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
      "  warn(\n",
      "/Users/andalanputra/opt/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_search.py:909: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  self.best_estimator_.fit(X, y, **fit_params)\n",
      "/Users/andalanputra/opt/anaconda3/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
      "  warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-2 {color: black;background-color: white;}#sk-container-id-2 pre{padding: 0;}#sk-container-id-2 div.sk-toggleable {background-color: white;}#sk-container-id-2 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-2 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-2 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-2 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-2 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-2 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-2 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-2 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-2 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-2 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-2 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-2 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-2 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-2 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-2 div.sk-item {position: relative;z-index: 1;}#sk-container-id-2 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-2 div.sk-item::before, #sk-container-id-2 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-2 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-2 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-2 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-2 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-2 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-2 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-2 div.sk-label-container {text-align: center;}#sk-container-id-2 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-2 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-2\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>RandomizedSearchCV(cv=5, estimator=RandomForestRegressor(), n_jobs=-1,\n",
       "                   param_distributions={&#x27;max_depth&#x27;: [None, 10, 50, 100],\n",
       "                                        &#x27;max_features&#x27;: [&#x27;auto&#x27;, &#x27;sqrt&#x27;],\n",
       "                                        &#x27;min_samples_leaf&#x27;: [1, 2, 4],\n",
       "                                        &#x27;min_samples_split&#x27;: [2, 5, 10],\n",
       "                                        &#x27;n_estimators&#x27;: [100, 300, 500]},\n",
       "                   scoring=&#x27;neg_mean_absolute_error&#x27;)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" ><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">RandomizedSearchCV</label><div class=\"sk-toggleable__content\"><pre>RandomizedSearchCV(cv=5, estimator=RandomForestRegressor(), n_jobs=-1,\n",
       "                   param_distributions={&#x27;max_depth&#x27;: [None, 10, 50, 100],\n",
       "                                        &#x27;max_features&#x27;: [&#x27;auto&#x27;, &#x27;sqrt&#x27;],\n",
       "                                        &#x27;min_samples_leaf&#x27;: [1, 2, 4],\n",
       "                                        &#x27;min_samples_split&#x27;: [2, 5, 10],\n",
       "                                        &#x27;n_estimators&#x27;: [100, 300, 500]},\n",
       "                   scoring=&#x27;neg_mean_absolute_error&#x27;)</pre></div></div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-3\" type=\"checkbox\" ><label for=\"sk-estimator-id-3\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">estimator: RandomForestRegressor</label><div class=\"sk-toggleable__content\"><pre>RandomForestRegressor()</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-4\" type=\"checkbox\" ><label for=\"sk-estimator-id-4\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">RandomForestRegressor</label><div class=\"sk-toggleable__content\"><pre>RandomForestRegressor()</pre></div></div></div></div></div></div></div></div></div></div>"
      ],
      "text/plain": [
       "RandomizedSearchCV(cv=5, estimator=RandomForestRegressor(), n_jobs=-1,\n",
       "                   param_distributions={'max_depth': [None, 10, 50, 100],\n",
       "                                        'max_features': ['auto', 'sqrt'],\n",
       "                                        'min_samples_leaf': [1, 2, 4],\n",
       "                                        'min_samples_split': [2, 5, 10],\n",
       "                                        'n_estimators': [100, 300, 500]},\n",
       "                   scoring='neg_mean_absolute_error')"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rscv.fit(X_train1, y_train1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'n_estimators': 300,\n",
       " 'min_samples_split': 10,\n",
       " 'min_samples_leaf': 2,\n",
       " 'max_features': 'auto',\n",
       " 'max_depth': None}"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rscv.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['rscv_rf_tfidf_best_params_linalol.pkl']"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "joblib.dump(rscv, \"rscv_rf_tfidf_linalol.pkl\")\n",
    "joblib.dump(rscv.best_params_, \"rscv_rf_tfidf_best_params_linalol.pkl\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "RF (after Hyperparameter Tuning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/y1/pjvjlkjn5gl846rnyzr53p340000gn/T/ipykernel_11392/4262949887.py:2: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  rfreg_ht.fit(X_train1, y_train1)\n",
      "/Users/andalanputra/opt/anaconda3/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
      "  warn(\n"
     ]
    }
   ],
   "source": [
    "rfreg_ht = RandomForestRegressor(n_estimators = 300, min_samples_split = 10, min_samples_leaf = 2, max_features = 'auto', max_depth = None)\n",
    "rfreg_ht.fit(X_train1, y_train1)\n",
    "y_pred_rfreg = rfreg_ht.predict(X_val)\n",
    "y_pred_rfreg_r2 = rfreg_ht.predict(X_train1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.04937701613735408"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mean_absolute_error(y_val, y_pred_rfreg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.00824334602459783"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mean_squared_error(y_val, y_pred_rfreg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0907928743051889"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mean_squared_error(y_val, y_pred_rfreg, squared = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9595071048058225"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#train\n",
    "r2_score(y_train1, y_pred_rfreg_r2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.917644749483582"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#val\n",
    "r2_score(y_val, y_pred_rfreg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Residual plots after Hyperparameter Tuning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Predicting model on the test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_rfreg_test = rfreg_ht.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['y_test_rfreg_tfidf_linalol.pkl']"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "joblib.dump(y_pred_rfreg_test, \"y_pred_rfreg_test_tfidf_linalol.pkl\")\n",
    "joblib.dump(y_test, \"y_test_rfreg_tfidf_linalol.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.048609766789712884"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mean_absolute_error(y_test, y_pred_rfreg_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.008304475437463366"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mean_squared_error(y_test, y_pred_rfreg_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.09112889463536451"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mean_squared_error(y_test, y_pred_rfreg_test, squared = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9174493353568425"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "r2_score(y_test, y_pred_rfreg_test)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Error analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 576x432 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 432x288 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# assume y_pred is a numpy array and y_true is a pandas dataframe\n",
    "fig, ax = plt.subplots(figsize=(8, 6))\n",
    "\n",
    "column = \"X..Linalool\"  # specify the target variable name\n",
    "ax.hist(y_pred_rfreg_test, alpha=0.5, label='y_pred', bins=20)\n",
    "ax.hist(y_test[column], alpha=0.5, label='y_true', bins=20)\n",
    "ax.legend(loc='upper right')\n",
    "ax.set_title(column)\n",
    "\n",
    "plt.show()\n",
    "plt.savefig('error_hist_knn_tfidf_linalol.png')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pearson R"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pearson correlation coefficient: 0.959\n",
      "P-value: 0.000\n"
     ]
    }
   ],
   "source": [
    "corr_coef, p_value = pearsonr(y_pred_rfreg_test.flatten(), y_test.values.ravel())\n",
    "\n",
    "print(f\"Pearson correlation coefficient: {corr_coef:.3f}\")\n",
    "print(f\"P-value: {p_value:.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:>"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "corr_matrix = y_test.corr()\n",
    "sns.heatmap(corr_matrix, annot=True, cmap='coolwarm', center=0)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
