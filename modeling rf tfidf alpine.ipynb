{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn import preprocessing\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.neural_network import MLPRegressor\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "from sklearn.metrics import r2_score\n",
    "from scipy.stats import pearsonr\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.feature_selection import SelectFromModel\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compiling complete dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_rf = pd.read_csv(\"df_alpine_tfidf.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['index',\n",
       " 'tfidf_0',\n",
       " 'tfidf_1',\n",
       " 'tfidf_2',\n",
       " 'tfidf_3',\n",
       " 'tfidf_4',\n",
       " 'tfidf_5',\n",
       " 'tfidf_6',\n",
       " 'tfidf_7',\n",
       " 'tfidf_8',\n",
       " 'tfidf_9',\n",
       " 'tfidf_10',\n",
       " 'tfidf_11',\n",
       " 'tfidf_12',\n",
       " 'tfidf_13',\n",
       " 'tfidf_14',\n",
       " 'tfidf_15',\n",
       " 'tfidf_16',\n",
       " 'tfidf_17',\n",
       " 'tfidf_18',\n",
       " 'tfidf_19',\n",
       " 'tfidf_20',\n",
       " 'tfidf_21',\n",
       " 'tfidf_22',\n",
       " 'tfidf_23',\n",
       " 'tfidf_24',\n",
       " 'tfidf_25',\n",
       " 'tfidf_26',\n",
       " 'tfidf_27',\n",
       " 'tfidf_28',\n",
       " 'tfidf_29',\n",
       " 'tfidf_30',\n",
       " 'tfidf_31',\n",
       " 'tfidf_32',\n",
       " 'tfidf_33',\n",
       " 'tfidf_34',\n",
       " 'tfidf_35',\n",
       " 'tfidf_36',\n",
       " 'tfidf_37',\n",
       " 'tfidf_38',\n",
       " 'tfidf_39',\n",
       " 'tfidf_40',\n",
       " 'tfidf_41',\n",
       " 'tfidf_42',\n",
       " 'tfidf_43',\n",
       " 'tfidf_44',\n",
       " 'tfidf_45',\n",
       " 'tfidf_46',\n",
       " 'tfidf_47',\n",
       " 'tfidf_48',\n",
       " 'tfidf_49',\n",
       " 'tfidf_50',\n",
       " 'tfidf_51',\n",
       " 'tfidf_52',\n",
       " 'tfidf_53',\n",
       " 'tfidf_54',\n",
       " 'tfidf_55',\n",
       " 'tfidf_56',\n",
       " 'tfidf_57',\n",
       " 'tfidf_58',\n",
       " 'tfidf_59',\n",
       " 'tfidf_60',\n",
       " 'tfidf_61',\n",
       " 'tfidf_62',\n",
       " 'tfidf_63',\n",
       " 'tfidf_64',\n",
       " 'tfidf_65',\n",
       " 'tfidf_66',\n",
       " 'tfidf_67',\n",
       " 'tfidf_68',\n",
       " 'tfidf_69',\n",
       " 'tfidf_70',\n",
       " 'tfidf_71',\n",
       " 'tfidf_72',\n",
       " 'tfidf_73',\n",
       " 'tfidf_74',\n",
       " 'tfidf_75',\n",
       " 'tfidf_76',\n",
       " 'tfidf_77',\n",
       " 'tfidf_78',\n",
       " 'tfidf_79',\n",
       " 'tfidf_80',\n",
       " 'tfidf_81',\n",
       " 'tfidf_82',\n",
       " 'tfidf_83',\n",
       " 'tfidf_84',\n",
       " 'tfidf_85',\n",
       " 'tfidf_86',\n",
       " 'tfidf_87',\n",
       " 'tfidf_88',\n",
       " 'tfidf_89',\n",
       " 'tfidf_90',\n",
       " 'tfidf_91',\n",
       " 'tfidf_92',\n",
       " 'tfidf_93',\n",
       " 'tfidf_94',\n",
       " 'tfidf_95',\n",
       " 'tfidf_96',\n",
       " 'tfidf_97',\n",
       " 'tfidf_98',\n",
       " 'tfidf_99',\n",
       " 'tfidf_100',\n",
       " 'tfidf_101',\n",
       " 'tfidf_102',\n",
       " 'tfidf_103',\n",
       " 'tfidf_104',\n",
       " 'tfidf_105',\n",
       " 'tfidf_106',\n",
       " 'tfidf_107',\n",
       " 'tfidf_108',\n",
       " 'tfidf_109',\n",
       " 'tfidf_110',\n",
       " 'tfidf_111',\n",
       " 'tfidf_112',\n",
       " 'tfidf_113',\n",
       " 'tfidf_114',\n",
       " 'tfidf_115',\n",
       " 'tfidf_116',\n",
       " 'tfidf_117',\n",
       " 'tfidf_118',\n",
       " 'tfidf_119',\n",
       " 'tfidf_120',\n",
       " 'tfidf_121',\n",
       " 'tfidf_122',\n",
       " 'tfidf_123',\n",
       " 'tfidf_124',\n",
       " 'tfidf_125',\n",
       " 'tfidf_126',\n",
       " 'tfidf_127',\n",
       " 'tfidf_128',\n",
       " 'tfidf_129',\n",
       " 'tfidf_130',\n",
       " 'tfidf_131',\n",
       " 'tfidf_132',\n",
       " 'tfidf_133',\n",
       " 'tfidf_134',\n",
       " 'tfidf_135',\n",
       " 'tfidf_136',\n",
       " 'tfidf_137',\n",
       " 'tfidf_138',\n",
       " 'tfidf_139',\n",
       " 'tfidf_140',\n",
       " 'tfidf_141',\n",
       " 'tfidf_142',\n",
       " 'tfidf_143',\n",
       " 'tfidf_144',\n",
       " 'tfidf_145',\n",
       " 'tfidf_146',\n",
       " 'tfidf_147',\n",
       " 'tfidf_148',\n",
       " 'tfidf_149',\n",
       " 'tfidf_150',\n",
       " 'tfidf_151',\n",
       " 'tfidf_152',\n",
       " 'tfidf_153',\n",
       " 'tfidf_154',\n",
       " 'tfidf_155',\n",
       " 'tfidf_156',\n",
       " 'tfidf_157',\n",
       " 'tfidf_158',\n",
       " 'tfidf_159',\n",
       " 'tfidf_160',\n",
       " 'tfidf_161',\n",
       " 'tfidf_162',\n",
       " 'tfidf_163',\n",
       " 'tfidf_164',\n",
       " 'tfidf_165',\n",
       " 'tfidf_166',\n",
       " 'tfidf_167',\n",
       " 'tfidf_168',\n",
       " 'tfidf_169',\n",
       " 'tfidf_170',\n",
       " 'tfidf_171',\n",
       " 'tfidf_172',\n",
       " 'tfidf_173',\n",
       " 'tfidf_174',\n",
       " 'tfidf_175',\n",
       " 'tfidf_176',\n",
       " 'tfidf_177',\n",
       " 'tfidf_178',\n",
       " 'tfidf_179',\n",
       " 'tfidf_180',\n",
       " 'tfidf_181',\n",
       " 'tfidf_182',\n",
       " 'tfidf_183',\n",
       " 'tfidf_184',\n",
       " 'tfidf_185',\n",
       " 'tfidf_186',\n",
       " 'tfidf_187',\n",
       " 'tfidf_188',\n",
       " 'tfidf_189',\n",
       " 'tfidf_190',\n",
       " 'tfidf_191',\n",
       " 'tfidf_192',\n",
       " 'tfidf_193',\n",
       " 'tfidf_194',\n",
       " 'tfidf_195',\n",
       " 'tfidf_196',\n",
       " 'tfidf_197',\n",
       " 'tfidf_198',\n",
       " 'tfidf_199',\n",
       " 'tfidf_200',\n",
       " 'tfidf_201',\n",
       " 'tfidf_202',\n",
       " 'tfidf_203',\n",
       " 'tfidf_204',\n",
       " 'tfidf_205',\n",
       " 'tfidf_206',\n",
       " 'tfidf_207',\n",
       " 'tfidf_208',\n",
       " 'tfidf_209',\n",
       " 'tfidf_210',\n",
       " 'tfidf_211',\n",
       " 'tfidf_212',\n",
       " 'tfidf_213',\n",
       " 'tfidf_214',\n",
       " 'tfidf_215',\n",
       " 'tfidf_216',\n",
       " 'tfidf_217',\n",
       " 'tfidf_218',\n",
       " 'tfidf_219',\n",
       " 'tfidf_220',\n",
       " 'tfidf_221',\n",
       " 'tfidf_222',\n",
       " 'tfidf_223',\n",
       " 'tfidf_224',\n",
       " 'tfidf_225',\n",
       " 'tfidf_226',\n",
       " 'tfidf_227',\n",
       " 'tfidf_228',\n",
       " 'tfidf_229',\n",
       " 'tfidf_230',\n",
       " 'tfidf_231',\n",
       " 'tfidf_232',\n",
       " 'tfidf_233',\n",
       " 'tfidf_234',\n",
       " 'tfidf_235',\n",
       " 'tfidf_236',\n",
       " 'tfidf_237',\n",
       " 'tfidf_238',\n",
       " 'tfidf_239',\n",
       " 'tfidf_240',\n",
       " 'tfidf_241',\n",
       " 'tfidf_242',\n",
       " 'tfidf_243',\n",
       " 'tfidf_244',\n",
       " 'tfidf_245',\n",
       " 'tfidf_246',\n",
       " 'tfidf_247',\n",
       " 'tfidf_248',\n",
       " 'tfidf_249',\n",
       " 'tfidf_250',\n",
       " 'tfidf_251',\n",
       " 'tfidf_252',\n",
       " 'tfidf_253',\n",
       " 'tfidf_254',\n",
       " 'tfidf_255',\n",
       " 'tfidf_256',\n",
       " 'tfidf_257',\n",
       " 'tfidf_258',\n",
       " 'tfidf_259',\n",
       " 'tfidf_260',\n",
       " 'tfidf_261',\n",
       " 'tfidf_262',\n",
       " 'tfidf_263',\n",
       " 'tfidf_264',\n",
       " 'tfidf_265',\n",
       " 'tfidf_266',\n",
       " 'tfidf_267',\n",
       " 'tfidf_268',\n",
       " 'tfidf_269',\n",
       " 'tfidf_270',\n",
       " 'tfidf_271',\n",
       " 'tfidf_272',\n",
       " 'tfidf_273',\n",
       " 'tfidf_274',\n",
       " 'tfidf_275',\n",
       " 'tfidf_276',\n",
       " 'tfidf_277',\n",
       " 'tfidf_278',\n",
       " 'tfidf_279',\n",
       " 'tfidf_280',\n",
       " 'tfidf_281',\n",
       " 'tfidf_282',\n",
       " 'tfidf_283',\n",
       " 'tfidf_284',\n",
       " 'tfidf_285',\n",
       " 'tfidf_286',\n",
       " 'tfidf_287',\n",
       " 'tfidf_288',\n",
       " 'tfidf_289',\n",
       " 'tfidf_290',\n",
       " 'tfidf_291',\n",
       " 'tfidf_292',\n",
       " 'tfidf_293',\n",
       " 'tfidf_294',\n",
       " 'tfidf_295',\n",
       " 'tfidf_296',\n",
       " 'tfidf_297',\n",
       " 'tfidf_298',\n",
       " 'tfidf_299',\n",
       " 'tfidf_300',\n",
       " 'tfidf_301',\n",
       " 'tfidf_302',\n",
       " 'tfidf_303',\n",
       " 'tfidf_304',\n",
       " 'tfidf_305',\n",
       " 'tfidf_306',\n",
       " 'tfidf_307',\n",
       " 'tfidf_308',\n",
       " 'tfidf_309',\n",
       " 'tfidf_310',\n",
       " 'tfidf_311',\n",
       " 'tfidf_312',\n",
       " 'tfidf_313',\n",
       " 'tfidf_314',\n",
       " 'tfidf_315',\n",
       " 'tfidf_316',\n",
       " 'tfidf_317',\n",
       " 'tfidf_318',\n",
       " 'tfidf_319',\n",
       " 'tfidf_320',\n",
       " 'tfidf_321',\n",
       " 'tfidf_322',\n",
       " 'tfidf_323',\n",
       " 'tfidf_324',\n",
       " 'tfidf_325',\n",
       " 'tfidf_326',\n",
       " 'tfidf_327',\n",
       " 'tfidf_328',\n",
       " 'tfidf_329',\n",
       " 'tfidf_330',\n",
       " 'tfidf_331',\n",
       " 'tfidf_332',\n",
       " 'tfidf_333',\n",
       " 'tfidf_334',\n",
       " 'tfidf_335',\n",
       " 'tfidf_336',\n",
       " 'tfidf_337',\n",
       " 'tfidf_338',\n",
       " 'tfidf_339',\n",
       " 'tfidf_340',\n",
       " 'tfidf_341',\n",
       " 'tfidf_342',\n",
       " 'tfidf_343',\n",
       " 'tfidf_344',\n",
       " 'tfidf_345',\n",
       " 'tfidf_346',\n",
       " 'tfidf_347',\n",
       " 'tfidf_348',\n",
       " 'tfidf_349',\n",
       " 'tfidf_350',\n",
       " 'tfidf_351',\n",
       " 'tfidf_352',\n",
       " 'tfidf_353',\n",
       " 'tfidf_354',\n",
       " 'tfidf_355',\n",
       " 'tfidf_356',\n",
       " 'tfidf_357',\n",
       " 'tfidf_358',\n",
       " 'tfidf_359',\n",
       " 'tfidf_360',\n",
       " 'tfidf_361',\n",
       " 'tfidf_362',\n",
       " 'tfidf_363',\n",
       " 'tfidf_364',\n",
       " 'tfidf_365',\n",
       " 'tfidf_366',\n",
       " 'tfidf_367',\n",
       " 'tfidf_368',\n",
       " 'tfidf_369',\n",
       " 'tfidf_370',\n",
       " 'tfidf_371',\n",
       " 'tfidf_372',\n",
       " 'tfidf_373',\n",
       " 'tfidf_374',\n",
       " 'tfidf_375',\n",
       " 'tfidf_376',\n",
       " 'tfidf_377',\n",
       " 'tfidf_378',\n",
       " 'tfidf_379',\n",
       " 'tfidf_380',\n",
       " 'tfidf_381',\n",
       " 'tfidf_382',\n",
       " 'tfidf_383',\n",
       " 'tfidf_384',\n",
       " 'tfidf_385',\n",
       " 'tfidf_386',\n",
       " 'tfidf_387',\n",
       " 'hybrid',\n",
       " 'indica',\n",
       " 'sativa',\n",
       " 'anxiety',\n",
       " 'anxious',\n",
       " 'aroused',\n",
       " 'arthritis',\n",
       " 'creative',\n",
       " 'depression',\n",
       " 'dizzy',\n",
       " 'dry eyes',\n",
       " 'dry mouth',\n",
       " 'energetic',\n",
       " 'epilepsy',\n",
       " 'euphoric',\n",
       " 'eye pressure',\n",
       " 'fatigue',\n",
       " 'focused',\n",
       " 'giggly',\n",
       " 'happy',\n",
       " 'headache',\n",
       " 'hungry',\n",
       " 'migraines',\n",
       " 'pain',\n",
       " 'paranoid',\n",
       " 'relaxed',\n",
       " 'seizures',\n",
       " 'sleepy',\n",
       " 'spasticity',\n",
       " 'stress',\n",
       " 'talkative',\n",
       " 'tingly',\n",
       " 'uplifted',\n",
       " 'ammonia',\n",
       " 'apple',\n",
       " 'apricot',\n",
       " 'berry',\n",
       " 'blue cheese',\n",
       " 'blueberry',\n",
       " 'butter',\n",
       " 'cheese',\n",
       " 'chemical',\n",
       " 'chestnut',\n",
       " 'citrus',\n",
       " 'coffee',\n",
       " 'diesel',\n",
       " 'earthy',\n",
       " 'flowery',\n",
       " 'fruit',\n",
       " 'grape',\n",
       " 'grapefruit',\n",
       " 'honey',\n",
       " 'lavender',\n",
       " 'lemon',\n",
       " 'lime',\n",
       " 'mango',\n",
       " 'menthol',\n",
       " 'mint',\n",
       " 'nutty',\n",
       " 'orange',\n",
       " 'peach',\n",
       " 'pear',\n",
       " 'pepper',\n",
       " 'pine',\n",
       " 'pineapple',\n",
       " 'plum',\n",
       " 'pungent',\n",
       " 'rose',\n",
       " 'sage',\n",
       " 'skunk',\n",
       " 'spicy/herbal',\n",
       " 'strawberry',\n",
       " 'sweet',\n",
       " 'tar',\n",
       " 'tea',\n",
       " 'tobacco',\n",
       " 'tree',\n",
       " 'tropical',\n",
       " 'vanilla',\n",
       " 'violet',\n",
       " 'woody',\n",
       " 'X..Alpha-Pinene']"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_rf.columns.to_list()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Splitting dependent and independent variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df_rf.drop(['index', 'X..Alpha-Pinene'], axis = 1)\n",
    "y = df_rf[['X..Alpha-Pinene']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plotting histograms on target variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.10695187],\n",
       "       [0.10695187],\n",
       "       [0.10695187],\n",
       "       ...,\n",
       "       [0.02139037],\n",
       "       [0.02139037],\n",
       "       [0.02139037]])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_array = y.to_numpy()\n",
    "y_array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Axes: ylabel='Count'>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "sns.histplot(y, bins = 10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train test split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=1, test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train1, X_val, y_train1, y_val = train_test_split(X_train, y_train, random_state=1, test_size=0.25)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "RF modeling (before Feature selection and Hyperparameter Tuning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/ns/m5pnr0211w91v02hpv22958m0000gn/T/ipykernel_85342/350139188.py:2: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  rfreg.fit(X_train1, y_train1)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;background-color: white;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>RandomForestRegressor()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">RandomForestRegressor</label><div class=\"sk-toggleable__content\"><pre>RandomForestRegressor()</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "RandomForestRegressor()"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rfreg = RandomForestRegressor()\n",
    "rfreg.fit(X_train1, y_train1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_rfreg = rfreg.predict(X_val)\n",
    "y_pred_rfreg_r2 = rfreg.predict(X_train1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.025985433811447127"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mean_absolute_error(y_val, y_pred_rfreg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.004157339748803121"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mean_squared_error(y_val, y_pred_rfreg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.06447743596641481"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mean_squared_error(y_val, y_pred_rfreg, squared = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9904002441055253"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#train\n",
    "r2_score(y_train1, y_pred_rfreg_r2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9691105142548053"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#val\n",
    "r2_score(y_val, y_pred_rfreg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Residual plots for each target variable"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Feature Selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_feat = pd.DataFrame({\n",
    "    \"features\": X_train1.columns,\n",
    "    \"score\": rfreg.feature_importances_\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>features</th>\n",
       "      <th>score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>tfidf_0</td>\n",
       "      <td>0.000465</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>tfidf_1</td>\n",
       "      <td>0.001650</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>tfidf_2</td>\n",
       "      <td>0.000086</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>tfidf_3</td>\n",
       "      <td>0.000220</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>tfidf_4</td>\n",
       "      <td>0.000209</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>464</th>\n",
       "      <td>tree</td>\n",
       "      <td>0.000116</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>465</th>\n",
       "      <td>tropical</td>\n",
       "      <td>0.000153</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>466</th>\n",
       "      <td>vanilla</td>\n",
       "      <td>0.000487</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>467</th>\n",
       "      <td>violet</td>\n",
       "      <td>0.000002</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>468</th>\n",
       "      <td>woody</td>\n",
       "      <td>0.000339</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>469 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     features     score\n",
       "0     tfidf_0  0.000465\n",
       "1     tfidf_1  0.001650\n",
       "2     tfidf_2  0.000086\n",
       "3     tfidf_3  0.000220\n",
       "4     tfidf_4  0.000209\n",
       "..        ...       ...\n",
       "464      tree  0.000116\n",
       "465  tropical  0.000153\n",
       "466   vanilla  0.000487\n",
       "467    violet  0.000002\n",
       "468     woody  0.000339\n",
       "\n",
       "[469 rows x 2 columns]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_feat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_feat_ranked = df_feat.sort_values(\"score\", ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>features</th>\n",
       "      <th>score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>389</th>\n",
       "      <td>indica</td>\n",
       "      <td>3.624423e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>443</th>\n",
       "      <td>mango</td>\n",
       "      <td>9.597552e-02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>141</th>\n",
       "      <td>tfidf_141</td>\n",
       "      <td>3.037551e-02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>426</th>\n",
       "      <td>blueberry</td>\n",
       "      <td>3.014558e-02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>434</th>\n",
       "      <td>earthy</td>\n",
       "      <td>2.659452e-02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>253</th>\n",
       "      <td>tfidf_253</td>\n",
       "      <td>1.823066e-02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>168</th>\n",
       "      <td>tfidf_168</td>\n",
       "      <td>1.765265e-02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>345</th>\n",
       "      <td>tfidf_345</td>\n",
       "      <td>1.738846e-02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>210</th>\n",
       "      <td>tfidf_210</td>\n",
       "      <td>1.465557e-02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>285</th>\n",
       "      <td>tfidf_285</td>\n",
       "      <td>1.259075e-02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>tfidf_30</td>\n",
       "      <td>1.251227e-02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>402</th>\n",
       "      <td>euphoric</td>\n",
       "      <td>1.241404e-02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>145</th>\n",
       "      <td>tfidf_145</td>\n",
       "      <td>1.135147e-02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>tfidf_43</td>\n",
       "      <td>9.942689e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>281</th>\n",
       "      <td>tfidf_281</td>\n",
       "      <td>9.356456e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>312</th>\n",
       "      <td>tfidf_312</td>\n",
       "      <td>7.941212e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>306</th>\n",
       "      <td>tfidf_306</td>\n",
       "      <td>7.864755e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>121</th>\n",
       "      <td>tfidf_121</td>\n",
       "      <td>6.610208e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>149</th>\n",
       "      <td>tfidf_149</td>\n",
       "      <td>5.693723e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>245</th>\n",
       "      <td>tfidf_245</td>\n",
       "      <td>5.646254e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>151</th>\n",
       "      <td>tfidf_151</td>\n",
       "      <td>5.282113e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>390</th>\n",
       "      <td>sativa</td>\n",
       "      <td>5.240649e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>329</th>\n",
       "      <td>tfidf_329</td>\n",
       "      <td>5.192644e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>433</th>\n",
       "      <td>diesel</td>\n",
       "      <td>5.166715e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>319</th>\n",
       "      <td>tfidf_319</td>\n",
       "      <td>4.896509e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>362</th>\n",
       "      <td>tfidf_362</td>\n",
       "      <td>4.729775e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>199</th>\n",
       "      <td>tfidf_199</td>\n",
       "      <td>4.712798e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>78</th>\n",
       "      <td>tfidf_78</td>\n",
       "      <td>4.455422e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>207</th>\n",
       "      <td>tfidf_207</td>\n",
       "      <td>4.372944e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>357</th>\n",
       "      <td>tfidf_357</td>\n",
       "      <td>3.996997e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>309</th>\n",
       "      <td>tfidf_309</td>\n",
       "      <td>3.993459e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>tfidf_7</td>\n",
       "      <td>3.945276e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>413</th>\n",
       "      <td>relaxed</td>\n",
       "      <td>3.905410e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>393</th>\n",
       "      <td>aroused</td>\n",
       "      <td>3.846627e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>tfidf_21</td>\n",
       "      <td>3.832644e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>273</th>\n",
       "      <td>tfidf_273</td>\n",
       "      <td>3.605175e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>303</th>\n",
       "      <td>tfidf_303</td>\n",
       "      <td>3.548193e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>119</th>\n",
       "      <td>tfidf_119</td>\n",
       "      <td>3.455383e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>136</th>\n",
       "      <td>tfidf_136</td>\n",
       "      <td>3.446911e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>233</th>\n",
       "      <td>tfidf_233</td>\n",
       "      <td>3.308295e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>205</th>\n",
       "      <td>tfidf_205</td>\n",
       "      <td>3.304178e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>267</th>\n",
       "      <td>tfidf_267</td>\n",
       "      <td>3.150903e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>280</th>\n",
       "      <td>tfidf_280</td>\n",
       "      <td>3.142808e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>82</th>\n",
       "      <td>tfidf_82</td>\n",
       "      <td>3.068097e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>418</th>\n",
       "      <td>talkative</td>\n",
       "      <td>3.067031e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>336</th>\n",
       "      <td>tfidf_336</td>\n",
       "      <td>3.032505e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>304</th>\n",
       "      <td>tfidf_304</td>\n",
       "      <td>2.955500e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>109</th>\n",
       "      <td>tfidf_109</td>\n",
       "      <td>2.934543e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>405</th>\n",
       "      <td>focused</td>\n",
       "      <td>2.889729e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>128</th>\n",
       "      <td>tfidf_128</td>\n",
       "      <td>2.860944e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>tfidf_46</td>\n",
       "      <td>2.835231e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>93</th>\n",
       "      <td>tfidf_93</td>\n",
       "      <td>2.627759e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>173</th>\n",
       "      <td>tfidf_173</td>\n",
       "      <td>2.595129e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>409</th>\n",
       "      <td>hungry</td>\n",
       "      <td>2.470958e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>406</th>\n",
       "      <td>giggly</td>\n",
       "      <td>2.444092e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>343</th>\n",
       "      <td>tfidf_343</td>\n",
       "      <td>2.288466e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>340</th>\n",
       "      <td>tfidf_340</td>\n",
       "      <td>2.211194e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>370</th>\n",
       "      <td>tfidf_370</td>\n",
       "      <td>2.161762e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>tfidf_23</td>\n",
       "      <td>2.149596e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54</th>\n",
       "      <td>tfidf_54</td>\n",
       "      <td>2.143516e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>457</th>\n",
       "      <td>skunk</td>\n",
       "      <td>2.140238e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>137</th>\n",
       "      <td>tfidf_137</td>\n",
       "      <td>2.123428e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>353</th>\n",
       "      <td>tfidf_353</td>\n",
       "      <td>2.116287e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>tfidf_97</td>\n",
       "      <td>2.104031e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>73</th>\n",
       "      <td>tfidf_73</td>\n",
       "      <td>2.064193e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>239</th>\n",
       "      <td>tfidf_239</td>\n",
       "      <td>1.999203e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>349</th>\n",
       "      <td>tfidf_349</td>\n",
       "      <td>1.941839e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>265</th>\n",
       "      <td>tfidf_265</td>\n",
       "      <td>1.901751e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>388</th>\n",
       "      <td>hybrid</td>\n",
       "      <td>1.890062e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>314</th>\n",
       "      <td>tfidf_314</td>\n",
       "      <td>1.835867e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>407</th>\n",
       "      <td>happy</td>\n",
       "      <td>1.767421e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>381</th>\n",
       "      <td>tfidf_381</td>\n",
       "      <td>1.762457e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>187</th>\n",
       "      <td>tfidf_187</td>\n",
       "      <td>1.741345e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>158</th>\n",
       "      <td>tfidf_158</td>\n",
       "      <td>1.721663e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>174</th>\n",
       "      <td>tfidf_174</td>\n",
       "      <td>1.704288e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>337</th>\n",
       "      <td>tfidf_337</td>\n",
       "      <td>1.661407e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>tfidf_1</td>\n",
       "      <td>1.649808e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>tfidf_11</td>\n",
       "      <td>1.648947e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>83</th>\n",
       "      <td>tfidf_83</td>\n",
       "      <td>1.623868e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>66</th>\n",
       "      <td>tfidf_66</td>\n",
       "      <td>1.612247e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>399</th>\n",
       "      <td>dry mouth</td>\n",
       "      <td>1.598080e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75</th>\n",
       "      <td>tfidf_75</td>\n",
       "      <td>1.586259e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>230</th>\n",
       "      <td>tfidf_230</td>\n",
       "      <td>1.570560e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>217</th>\n",
       "      <td>tfidf_217</td>\n",
       "      <td>1.522690e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>364</th>\n",
       "      <td>tfidf_364</td>\n",
       "      <td>1.514263e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>162</th>\n",
       "      <td>tfidf_162</td>\n",
       "      <td>1.509922e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>460</th>\n",
       "      <td>sweet</td>\n",
       "      <td>1.509680e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>104</th>\n",
       "      <td>tfidf_104</td>\n",
       "      <td>1.504623e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>395</th>\n",
       "      <td>creative</td>\n",
       "      <td>1.452082e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>166</th>\n",
       "      <td>tfidf_166</td>\n",
       "      <td>1.436635e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>420</th>\n",
       "      <td>uplifted</td>\n",
       "      <td>1.380725e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>415</th>\n",
       "      <td>sleepy</td>\n",
       "      <td>1.322396e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>258</th>\n",
       "      <td>tfidf_258</td>\n",
       "      <td>1.321770e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>297</th>\n",
       "      <td>tfidf_297</td>\n",
       "      <td>1.299227e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>tfidf_98</td>\n",
       "      <td>1.256140e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>424</th>\n",
       "      <td>berry</td>\n",
       "      <td>1.250484e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>291</th>\n",
       "      <td>tfidf_291</td>\n",
       "      <td>1.204532e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>215</th>\n",
       "      <td>tfidf_215</td>\n",
       "      <td>1.152580e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>366</th>\n",
       "      <td>tfidf_366</td>\n",
       "      <td>1.147262e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>269</th>\n",
       "      <td>tfidf_269</td>\n",
       "      <td>1.090104e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>278</th>\n",
       "      <td>tfidf_278</td>\n",
       "      <td>1.071671e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>454</th>\n",
       "      <td>pungent</td>\n",
       "      <td>1.035155e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>125</th>\n",
       "      <td>tfidf_125</td>\n",
       "      <td>1.030408e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>451</th>\n",
       "      <td>pine</td>\n",
       "      <td>1.022988e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>282</th>\n",
       "      <td>tfidf_282</td>\n",
       "      <td>9.681002e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>299</th>\n",
       "      <td>tfidf_299</td>\n",
       "      <td>9.668313e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>250</th>\n",
       "      <td>tfidf_250</td>\n",
       "      <td>9.603703e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>294</th>\n",
       "      <td>tfidf_294</td>\n",
       "      <td>9.455706e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>270</th>\n",
       "      <td>tfidf_270</td>\n",
       "      <td>9.264436e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>419</th>\n",
       "      <td>tingly</td>\n",
       "      <td>9.109824e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>tfidf_15</td>\n",
       "      <td>9.065333e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>tfidf_37</td>\n",
       "      <td>9.048770e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>202</th>\n",
       "      <td>tfidf_202</td>\n",
       "      <td>9.008287e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>64</th>\n",
       "      <td>tfidf_64</td>\n",
       "      <td>8.603170e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>350</th>\n",
       "      <td>tfidf_350</td>\n",
       "      <td>8.393182e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>120</th>\n",
       "      <td>tfidf_120</td>\n",
       "      <td>8.267806e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>tfidf_5</td>\n",
       "      <td>8.170400e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>376</th>\n",
       "      <td>tfidf_376</td>\n",
       "      <td>7.854181e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>326</th>\n",
       "      <td>tfidf_326</td>\n",
       "      <td>7.820910e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>374</th>\n",
       "      <td>tfidf_374</td>\n",
       "      <td>7.780784e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>441</th>\n",
       "      <td>lemon</td>\n",
       "      <td>7.774149e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>342</th>\n",
       "      <td>tfidf_342</td>\n",
       "      <td>7.564987e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>tfidf_20</td>\n",
       "      <td>7.534283e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>400</th>\n",
       "      <td>energetic</td>\n",
       "      <td>7.413046e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>169</th>\n",
       "      <td>tfidf_169</td>\n",
       "      <td>7.410459e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>150</th>\n",
       "      <td>tfidf_150</td>\n",
       "      <td>7.226595e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>107</th>\n",
       "      <td>tfidf_107</td>\n",
       "      <td>7.071764e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>459</th>\n",
       "      <td>strawberry</td>\n",
       "      <td>6.989761e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>144</th>\n",
       "      <td>tfidf_144</td>\n",
       "      <td>6.866891e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>398</th>\n",
       "      <td>dry eyes</td>\n",
       "      <td>6.720806e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>181</th>\n",
       "      <td>tfidf_181</td>\n",
       "      <td>6.452309e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>383</th>\n",
       "      <td>tfidf_383</td>\n",
       "      <td>6.350969e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>124</th>\n",
       "      <td>tfidf_124</td>\n",
       "      <td>6.142887e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>320</th>\n",
       "      <td>tfidf_320</td>\n",
       "      <td>6.120594e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>360</th>\n",
       "      <td>tfidf_360</td>\n",
       "      <td>6.085444e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>432</th>\n",
       "      <td>coffee</td>\n",
       "      <td>6.050190e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>tfidf_18</td>\n",
       "      <td>5.862086e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>447</th>\n",
       "      <td>orange</td>\n",
       "      <td>5.770814e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>167</th>\n",
       "      <td>tfidf_167</td>\n",
       "      <td>5.769369e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>114</th>\n",
       "      <td>tfidf_114</td>\n",
       "      <td>5.764972e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>103</th>\n",
       "      <td>tfidf_103</td>\n",
       "      <td>5.708962e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>198</th>\n",
       "      <td>tfidf_198</td>\n",
       "      <td>5.682869e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>387</th>\n",
       "      <td>tfidf_387</td>\n",
       "      <td>5.669010e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>164</th>\n",
       "      <td>tfidf_164</td>\n",
       "      <td>5.613981e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>203</th>\n",
       "      <td>tfidf_203</td>\n",
       "      <td>5.553699e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>371</th>\n",
       "      <td>tfidf_371</td>\n",
       "      <td>5.348351e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>290</th>\n",
       "      <td>tfidf_290</td>\n",
       "      <td>5.318226e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>130</th>\n",
       "      <td>tfidf_130</td>\n",
       "      <td>5.274545e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>431</th>\n",
       "      <td>citrus</td>\n",
       "      <td>5.160573e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>101</th>\n",
       "      <td>tfidf_101</td>\n",
       "      <td>5.052095e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52</th>\n",
       "      <td>tfidf_52</td>\n",
       "      <td>5.024872e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>208</th>\n",
       "      <td>tfidf_208</td>\n",
       "      <td>4.974079e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>367</th>\n",
       "      <td>tfidf_367</td>\n",
       "      <td>4.921476e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>466</th>\n",
       "      <td>vanilla</td>\n",
       "      <td>4.865805e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>77</th>\n",
       "      <td>tfidf_77</td>\n",
       "      <td>4.844178e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>56</th>\n",
       "      <td>tfidf_56</td>\n",
       "      <td>4.757838e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>tfidf_0</td>\n",
       "      <td>4.652445e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>325</th>\n",
       "      <td>tfidf_325</td>\n",
       "      <td>4.546171e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>tfidf_34</td>\n",
       "      <td>4.434996e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>240</th>\n",
       "      <td>tfidf_240</td>\n",
       "      <td>4.313476e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>tfidf_48</td>\n",
       "      <td>4.212687e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>412</th>\n",
       "      <td>paranoid</td>\n",
       "      <td>4.073599e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>224</th>\n",
       "      <td>tfidf_224</td>\n",
       "      <td>4.028112e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>186</th>\n",
       "      <td>tfidf_186</td>\n",
       "      <td>3.948505e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>146</th>\n",
       "      <td>tfidf_146</td>\n",
       "      <td>3.911197e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>375</th>\n",
       "      <td>tfidf_375</td>\n",
       "      <td>3.877253e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>368</th>\n",
       "      <td>tfidf_368</td>\n",
       "      <td>3.873197e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>85</th>\n",
       "      <td>tfidf_85</td>\n",
       "      <td>3.838307e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>263</th>\n",
       "      <td>tfidf_263</td>\n",
       "      <td>3.827074e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>135</th>\n",
       "      <td>tfidf_135</td>\n",
       "      <td>3.785531e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>274</th>\n",
       "      <td>tfidf_274</td>\n",
       "      <td>3.758650e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>88</th>\n",
       "      <td>tfidf_88</td>\n",
       "      <td>3.728204e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>tfidf_22</td>\n",
       "      <td>3.699430e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>154</th>\n",
       "      <td>tfidf_154</td>\n",
       "      <td>3.648378e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>61</th>\n",
       "      <td>tfidf_61</td>\n",
       "      <td>3.647379e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>231</th>\n",
       "      <td>tfidf_231</td>\n",
       "      <td>3.635621e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>283</th>\n",
       "      <td>tfidf_283</td>\n",
       "      <td>3.613363e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>155</th>\n",
       "      <td>tfidf_155</td>\n",
       "      <td>3.599172e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>351</th>\n",
       "      <td>tfidf_351</td>\n",
       "      <td>3.587620e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>397</th>\n",
       "      <td>dizzy</td>\n",
       "      <td>3.549937e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>190</th>\n",
       "      <td>tfidf_190</td>\n",
       "      <td>3.534695e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>tfidf_41</td>\n",
       "      <td>3.477505e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>331</th>\n",
       "      <td>tfidf_331</td>\n",
       "      <td>3.475548e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>300</th>\n",
       "      <td>tfidf_300</td>\n",
       "      <td>3.442218e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>272</th>\n",
       "      <td>tfidf_272</td>\n",
       "      <td>3.418034e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>468</th>\n",
       "      <td>woody</td>\n",
       "      <td>3.390170e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>67</th>\n",
       "      <td>tfidf_67</td>\n",
       "      <td>3.297375e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>455</th>\n",
       "      <td>rose</td>\n",
       "      <td>3.234854e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>352</th>\n",
       "      <td>tfidf_352</td>\n",
       "      <td>3.177799e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>408</th>\n",
       "      <td>headache</td>\n",
       "      <td>3.170234e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>437</th>\n",
       "      <td>grape</td>\n",
       "      <td>3.107697e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>341</th>\n",
       "      <td>tfidf_341</td>\n",
       "      <td>3.105897e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>338</th>\n",
       "      <td>tfidf_338</td>\n",
       "      <td>3.102014e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>428</th>\n",
       "      <td>cheese</td>\n",
       "      <td>3.059789e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>200</th>\n",
       "      <td>tfidf_200</td>\n",
       "      <td>2.992413e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>80</th>\n",
       "      <td>tfidf_80</td>\n",
       "      <td>2.942535e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>tfidf_19</td>\n",
       "      <td>2.890743e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>117</th>\n",
       "      <td>tfidf_117</td>\n",
       "      <td>2.859134e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>152</th>\n",
       "      <td>tfidf_152</td>\n",
       "      <td>2.829960e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>363</th>\n",
       "      <td>tfidf_363</td>\n",
       "      <td>2.804443e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>347</th>\n",
       "      <td>tfidf_347</td>\n",
       "      <td>2.788488e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>262</th>\n",
       "      <td>tfidf_262</td>\n",
       "      <td>2.778543e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>259</th>\n",
       "      <td>tfidf_259</td>\n",
       "      <td>2.675090e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>tfidf_16</td>\n",
       "      <td>2.667125e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>385</th>\n",
       "      <td>tfidf_385</td>\n",
       "      <td>2.659263e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>221</th>\n",
       "      <td>tfidf_221</td>\n",
       "      <td>2.654959e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>108</th>\n",
       "      <td>tfidf_108</td>\n",
       "      <td>2.624206e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>116</th>\n",
       "      <td>tfidf_116</td>\n",
       "      <td>2.522841e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>139</th>\n",
       "      <td>tfidf_139</td>\n",
       "      <td>2.495878e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>112</th>\n",
       "      <td>tfidf_112</td>\n",
       "      <td>2.482599e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>382</th>\n",
       "      <td>tfidf_382</td>\n",
       "      <td>2.481766e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>tfidf_28</td>\n",
       "      <td>2.466732e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>188</th>\n",
       "      <td>tfidf_188</td>\n",
       "      <td>2.414166e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>264</th>\n",
       "      <td>tfidf_264</td>\n",
       "      <td>2.400809e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>94</th>\n",
       "      <td>tfidf_94</td>\n",
       "      <td>2.386607e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>129</th>\n",
       "      <td>tfidf_129</td>\n",
       "      <td>2.380922e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>tfidf_32</td>\n",
       "      <td>2.373712e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>147</th>\n",
       "      <td>tfidf_147</td>\n",
       "      <td>2.342239e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>55</th>\n",
       "      <td>tfidf_55</td>\n",
       "      <td>2.267952e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>tfidf_96</td>\n",
       "      <td>2.258479e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>91</th>\n",
       "      <td>tfidf_91</td>\n",
       "      <td>2.256533e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>58</th>\n",
       "      <td>tfidf_58</td>\n",
       "      <td>2.214869e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>90</th>\n",
       "      <td>tfidf_90</td>\n",
       "      <td>2.207162e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>392</th>\n",
       "      <td>anxious</td>\n",
       "      <td>2.203760e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>307</th>\n",
       "      <td>tfidf_307</td>\n",
       "      <td>2.199817e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>tfidf_3</td>\n",
       "      <td>2.198533e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>423</th>\n",
       "      <td>apricot</td>\n",
       "      <td>2.197597e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>159</th>\n",
       "      <td>tfidf_159</td>\n",
       "      <td>2.150276e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>234</th>\n",
       "      <td>tfidf_234</td>\n",
       "      <td>2.125176e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>tfidf_26</td>\n",
       "      <td>2.122235e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>178</th>\n",
       "      <td>tfidf_178</td>\n",
       "      <td>2.112113e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>tfidf_39</td>\n",
       "      <td>2.090402e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>339</th>\n",
       "      <td>tfidf_339</td>\n",
       "      <td>2.086446e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>tfidf_4</td>\n",
       "      <td>2.085869e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>65</th>\n",
       "      <td>tfidf_65</td>\n",
       "      <td>2.073160e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>71</th>\n",
       "      <td>tfidf_71</td>\n",
       "      <td>2.039041e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>442</th>\n",
       "      <td>lime</td>\n",
       "      <td>2.020397e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>286</th>\n",
       "      <td>tfidf_286</td>\n",
       "      <td>1.985679e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>435</th>\n",
       "      <td>flowery</td>\n",
       "      <td>1.970026e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>126</th>\n",
       "      <td>tfidf_126</td>\n",
       "      <td>1.949629e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>373</th>\n",
       "      <td>tfidf_373</td>\n",
       "      <td>1.929855e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>243</th>\n",
       "      <td>tfidf_243</td>\n",
       "      <td>1.888868e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>204</th>\n",
       "      <td>tfidf_204</td>\n",
       "      <td>1.881786e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>214</th>\n",
       "      <td>tfidf_214</td>\n",
       "      <td>1.877596e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>185</th>\n",
       "      <td>tfidf_185</td>\n",
       "      <td>1.867316e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>62</th>\n",
       "      <td>tfidf_62</td>\n",
       "      <td>1.865467e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>355</th>\n",
       "      <td>tfidf_355</td>\n",
       "      <td>1.847547e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>tfidf_44</td>\n",
       "      <td>1.824800e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>321</th>\n",
       "      <td>tfidf_321</td>\n",
       "      <td>1.805900e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>450</th>\n",
       "      <td>pepper</td>\n",
       "      <td>1.780417e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>227</th>\n",
       "      <td>tfidf_227</td>\n",
       "      <td>1.773123e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>333</th>\n",
       "      <td>tfidf_333</td>\n",
       "      <td>1.719919e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>316</th>\n",
       "      <td>tfidf_316</td>\n",
       "      <td>1.703449e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>195</th>\n",
       "      <td>tfidf_195</td>\n",
       "      <td>1.698804e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>142</th>\n",
       "      <td>tfidf_142</td>\n",
       "      <td>1.695097e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>175</th>\n",
       "      <td>tfidf_175</td>\n",
       "      <td>1.682796e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>237</th>\n",
       "      <td>tfidf_237</td>\n",
       "      <td>1.679714e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>251</th>\n",
       "      <td>tfidf_251</td>\n",
       "      <td>1.678972e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>111</th>\n",
       "      <td>tfidf_111</td>\n",
       "      <td>1.675265e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>436</th>\n",
       "      <td>fruit</td>\n",
       "      <td>1.668446e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>445</th>\n",
       "      <td>mint</td>\n",
       "      <td>1.659201e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>170</th>\n",
       "      <td>tfidf_170</td>\n",
       "      <td>1.655214e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>163</th>\n",
       "      <td>tfidf_163</td>\n",
       "      <td>1.601129e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>463</th>\n",
       "      <td>tobacco</td>\n",
       "      <td>1.579247e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>465</th>\n",
       "      <td>tropical</td>\n",
       "      <td>1.528894e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>317</th>\n",
       "      <td>tfidf_317</td>\n",
       "      <td>1.506114e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>153</th>\n",
       "      <td>tfidf_153</td>\n",
       "      <td>1.489048e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>tfidf_6</td>\n",
       "      <td>1.471784e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>354</th>\n",
       "      <td>tfidf_354</td>\n",
       "      <td>1.411273e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>110</th>\n",
       "      <td>tfidf_110</td>\n",
       "      <td>1.374763e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>315</th>\n",
       "      <td>tfidf_315</td>\n",
       "      <td>1.365407e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>348</th>\n",
       "      <td>tfidf_348</td>\n",
       "      <td>1.359520e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>183</th>\n",
       "      <td>tfidf_183</td>\n",
       "      <td>1.341317e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>453</th>\n",
       "      <td>plum</td>\n",
       "      <td>1.331923e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>189</th>\n",
       "      <td>tfidf_189</td>\n",
       "      <td>1.320567e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>105</th>\n",
       "      <td>tfidf_105</td>\n",
       "      <td>1.303445e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>222</th>\n",
       "      <td>tfidf_222</td>\n",
       "      <td>1.300583e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>196</th>\n",
       "      <td>tfidf_196</td>\n",
       "      <td>1.294557e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>100</th>\n",
       "      <td>tfidf_100</td>\n",
       "      <td>1.267740e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>276</th>\n",
       "      <td>tfidf_276</td>\n",
       "      <td>1.255224e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>tfidf_14</td>\n",
       "      <td>1.233770e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>372</th>\n",
       "      <td>tfidf_372</td>\n",
       "      <td>1.232093e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>tfidf_9</td>\n",
       "      <td>1.222829e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50</th>\n",
       "      <td>tfidf_50</td>\n",
       "      <td>1.194036e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>260</th>\n",
       "      <td>tfidf_260</td>\n",
       "      <td>1.167383e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>301</th>\n",
       "      <td>tfidf_301</td>\n",
       "      <td>1.157441e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>464</th>\n",
       "      <td>tree</td>\n",
       "      <td>1.157230e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>tfidf_17</td>\n",
       "      <td>1.157217e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>138</th>\n",
       "      <td>tfidf_138</td>\n",
       "      <td>1.135730e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>69</th>\n",
       "      <td>tfidf_69</td>\n",
       "      <td>1.123488e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>tfidf_24</td>\n",
       "      <td>1.091629e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>232</th>\n",
       "      <td>tfidf_232</td>\n",
       "      <td>1.090944e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>tfidf_49</td>\n",
       "      <td>1.071590e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>118</th>\n",
       "      <td>tfidf_118</td>\n",
       "      <td>1.053744e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>226</th>\n",
       "      <td>tfidf_226</td>\n",
       "      <td>1.040987e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>161</th>\n",
       "      <td>tfidf_161</td>\n",
       "      <td>1.032810e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>289</th>\n",
       "      <td>tfidf_289</td>\n",
       "      <td>1.031330e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>271</th>\n",
       "      <td>tfidf_271</td>\n",
       "      <td>1.016019e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>330</th>\n",
       "      <td>tfidf_330</td>\n",
       "      <td>1.008614e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>252</th>\n",
       "      <td>tfidf_252</td>\n",
       "      <td>1.006402e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>206</th>\n",
       "      <td>tfidf_206</td>\n",
       "      <td>9.918510e-05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>305</th>\n",
       "      <td>tfidf_305</td>\n",
       "      <td>9.917566e-05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>184</th>\n",
       "      <td>tfidf_184</td>\n",
       "      <td>9.671756e-05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>tfidf_10</td>\n",
       "      <td>9.410079e-05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>tfidf_31</td>\n",
       "      <td>9.387784e-05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>60</th>\n",
       "      <td>tfidf_60</td>\n",
       "      <td>9.260249e-05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>tfidf_27</td>\n",
       "      <td>9.177584e-05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>193</th>\n",
       "      <td>tfidf_193</td>\n",
       "      <td>9.061611e-05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>287</th>\n",
       "      <td>tfidf_287</td>\n",
       "      <td>9.049361e-05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>318</th>\n",
       "      <td>tfidf_318</td>\n",
       "      <td>9.047349e-05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>tfidf_45</td>\n",
       "      <td>8.900911e-05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>123</th>\n",
       "      <td>tfidf_123</td>\n",
       "      <td>8.866387e-05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>275</th>\n",
       "      <td>tfidf_275</td>\n",
       "      <td>8.735721e-05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>256</th>\n",
       "      <td>tfidf_256</td>\n",
       "      <td>8.708073e-05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>tfidf_2</td>\n",
       "      <td>8.635287e-05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>tfidf_99</td>\n",
       "      <td>8.483436e-05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>295</th>\n",
       "      <td>tfidf_295</td>\n",
       "      <td>8.317590e-05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>171</th>\n",
       "      <td>tfidf_171</td>\n",
       "      <td>8.258757e-05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>277</th>\n",
       "      <td>tfidf_277</td>\n",
       "      <td>8.196309e-05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>63</th>\n",
       "      <td>tfidf_63</td>\n",
       "      <td>8.119720e-05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>288</th>\n",
       "      <td>tfidf_288</td>\n",
       "      <td>8.028753e-05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>223</th>\n",
       "      <td>tfidf_223</td>\n",
       "      <td>7.922171e-05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>247</th>\n",
       "      <td>tfidf_247</td>\n",
       "      <td>7.879064e-05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>380</th>\n",
       "      <td>tfidf_380</td>\n",
       "      <td>7.743664e-05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>220</th>\n",
       "      <td>tfidf_220</td>\n",
       "      <td>7.729707e-05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>132</th>\n",
       "      <td>tfidf_132</td>\n",
       "      <td>7.678215e-05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>81</th>\n",
       "      <td>tfidf_81</td>\n",
       "      <td>7.677491e-05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>219</th>\n",
       "      <td>tfidf_219</td>\n",
       "      <td>7.584382e-05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>106</th>\n",
       "      <td>tfidf_106</td>\n",
       "      <td>7.559153e-05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>446</th>\n",
       "      <td>nutty</td>\n",
       "      <td>7.556623e-05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>213</th>\n",
       "      <td>tfidf_213</td>\n",
       "      <td>7.474112e-05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>tfidf_36</td>\n",
       "      <td>7.376266e-05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>194</th>\n",
       "      <td>tfidf_194</td>\n",
       "      <td>7.369875e-05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>378</th>\n",
       "      <td>tfidf_378</td>\n",
       "      <td>7.345270e-05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>157</th>\n",
       "      <td>tfidf_157</td>\n",
       "      <td>7.292745e-05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>tfidf_40</td>\n",
       "      <td>7.284198e-05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>344</th>\n",
       "      <td>tfidf_344</td>\n",
       "      <td>7.263125e-05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53</th>\n",
       "      <td>tfidf_53</td>\n",
       "      <td>7.032627e-05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>84</th>\n",
       "      <td>tfidf_84</td>\n",
       "      <td>6.979083e-05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>323</th>\n",
       "      <td>tfidf_323</td>\n",
       "      <td>6.948492e-05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>tfidf_35</td>\n",
       "      <td>6.895086e-05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>211</th>\n",
       "      <td>tfidf_211</td>\n",
       "      <td>6.762137e-05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>310</th>\n",
       "      <td>tfidf_310</td>\n",
       "      <td>6.675694e-05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>377</th>\n",
       "      <td>tfidf_377</td>\n",
       "      <td>6.587395e-05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>458</th>\n",
       "      <td>spicy/herbal</td>\n",
       "      <td>6.584428e-05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>421</th>\n",
       "      <td>ammonia</td>\n",
       "      <td>6.283705e-05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>346</th>\n",
       "      <td>tfidf_346</td>\n",
       "      <td>6.195531e-05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>180</th>\n",
       "      <td>tfidf_180</td>\n",
       "      <td>6.156216e-05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>313</th>\n",
       "      <td>tfidf_313</td>\n",
       "      <td>6.055049e-05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>384</th>\n",
       "      <td>tfidf_384</td>\n",
       "      <td>5.979248e-05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>70</th>\n",
       "      <td>tfidf_70</td>\n",
       "      <td>5.890790e-05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>448</th>\n",
       "      <td>peach</td>\n",
       "      <td>5.872697e-05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>57</th>\n",
       "      <td>tfidf_57</td>\n",
       "      <td>5.807938e-05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>76</th>\n",
       "      <td>tfidf_76</td>\n",
       "      <td>5.702129e-05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>386</th>\n",
       "      <td>tfidf_386</td>\n",
       "      <td>5.580795e-05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>246</th>\n",
       "      <td>tfidf_246</td>\n",
       "      <td>5.535617e-05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>122</th>\n",
       "      <td>tfidf_122</td>\n",
       "      <td>5.477164e-05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>86</th>\n",
       "      <td>tfidf_86</td>\n",
       "      <td>5.374024e-05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>361</th>\n",
       "      <td>tfidf_361</td>\n",
       "      <td>5.307592e-05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>79</th>\n",
       "      <td>tfidf_79</td>\n",
       "      <td>5.278021e-05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>429</th>\n",
       "      <td>chemical</td>\n",
       "      <td>5.275113e-05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>tfidf_33</td>\n",
       "      <td>5.196071e-05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>328</th>\n",
       "      <td>tfidf_328</td>\n",
       "      <td>5.191267e-05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>249</th>\n",
       "      <td>tfidf_249</td>\n",
       "      <td>4.980904e-05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>102</th>\n",
       "      <td>tfidf_102</td>\n",
       "      <td>4.927935e-05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>tfidf_12</td>\n",
       "      <td>4.872758e-05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>201</th>\n",
       "      <td>tfidf_201</td>\n",
       "      <td>4.815172e-05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>332</th>\n",
       "      <td>tfidf_332</td>\n",
       "      <td>4.438701e-05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>156</th>\n",
       "      <td>tfidf_156</td>\n",
       "      <td>4.262351e-05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>191</th>\n",
       "      <td>tfidf_191</td>\n",
       "      <td>4.260219e-05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>tfidf_13</td>\n",
       "      <td>4.232455e-05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>87</th>\n",
       "      <td>tfidf_87</td>\n",
       "      <td>4.162895e-05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>148</th>\n",
       "      <td>tfidf_148</td>\n",
       "      <td>4.131173e-05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>140</th>\n",
       "      <td>tfidf_140</td>\n",
       "      <td>4.044660e-05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>369</th>\n",
       "      <td>tfidf_369</td>\n",
       "      <td>4.028358e-05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>335</th>\n",
       "      <td>tfidf_335</td>\n",
       "      <td>4.023247e-05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>tfidf_38</td>\n",
       "      <td>4.002174e-05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>266</th>\n",
       "      <td>tfidf_266</td>\n",
       "      <td>3.991581e-05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>236</th>\n",
       "      <td>tfidf_236</td>\n",
       "      <td>3.907815e-05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>456</th>\n",
       "      <td>sage</td>\n",
       "      <td>3.789205e-05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>358</th>\n",
       "      <td>tfidf_358</td>\n",
       "      <td>3.724652e-05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>tfidf_47</td>\n",
       "      <td>3.711948e-05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>298</th>\n",
       "      <td>tfidf_298</td>\n",
       "      <td>3.625457e-05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>tfidf_29</td>\n",
       "      <td>3.505192e-05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>292</th>\n",
       "      <td>tfidf_292</td>\n",
       "      <td>3.453284e-05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>115</th>\n",
       "      <td>tfidf_115</td>\n",
       "      <td>3.451392e-05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>255</th>\n",
       "      <td>tfidf_255</td>\n",
       "      <td>3.421368e-05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>113</th>\n",
       "      <td>tfidf_113</td>\n",
       "      <td>3.396861e-05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>359</th>\n",
       "      <td>tfidf_359</td>\n",
       "      <td>3.380387e-05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>197</th>\n",
       "      <td>tfidf_197</td>\n",
       "      <td>3.335155e-05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>324</th>\n",
       "      <td>tfidf_324</td>\n",
       "      <td>3.325133e-05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>127</th>\n",
       "      <td>tfidf_127</td>\n",
       "      <td>3.265252e-05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>438</th>\n",
       "      <td>grapefruit</td>\n",
       "      <td>3.247805e-05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>427</th>\n",
       "      <td>butter</td>\n",
       "      <td>3.222229e-05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>tfidf_25</td>\n",
       "      <td>3.198132e-05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>241</th>\n",
       "      <td>tfidf_241</td>\n",
       "      <td>3.152130e-05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>334</th>\n",
       "      <td>tfidf_334</td>\n",
       "      <td>3.124619e-05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>216</th>\n",
       "      <td>tfidf_216</td>\n",
       "      <td>3.111428e-05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>279</th>\n",
       "      <td>tfidf_279</td>\n",
       "      <td>3.080572e-05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>68</th>\n",
       "      <td>tfidf_68</td>\n",
       "      <td>3.058752e-05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>311</th>\n",
       "      <td>tfidf_311</td>\n",
       "      <td>3.004702e-05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>160</th>\n",
       "      <td>tfidf_160</td>\n",
       "      <td>2.949155e-05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>365</th>\n",
       "      <td>tfidf_365</td>\n",
       "      <td>2.947635e-05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59</th>\n",
       "      <td>tfidf_59</td>\n",
       "      <td>2.858415e-05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>268</th>\n",
       "      <td>tfidf_268</td>\n",
       "      <td>2.746948e-05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>284</th>\n",
       "      <td>tfidf_284</td>\n",
       "      <td>2.739031e-05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>257</th>\n",
       "      <td>tfidf_257</td>\n",
       "      <td>2.737002e-05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>452</th>\n",
       "      <td>pineapple</td>\n",
       "      <td>2.726917e-05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>244</th>\n",
       "      <td>tfidf_244</td>\n",
       "      <td>2.697993e-05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>229</th>\n",
       "      <td>tfidf_229</td>\n",
       "      <td>2.688839e-05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>177</th>\n",
       "      <td>tfidf_177</td>\n",
       "      <td>2.682665e-05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>439</th>\n",
       "      <td>honey</td>\n",
       "      <td>2.649137e-05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>430</th>\n",
       "      <td>chestnut</td>\n",
       "      <td>2.629562e-05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>165</th>\n",
       "      <td>tfidf_165</td>\n",
       "      <td>2.513065e-05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>422</th>\n",
       "      <td>apple</td>\n",
       "      <td>2.493427e-05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>192</th>\n",
       "      <td>tfidf_192</td>\n",
       "      <td>2.473289e-05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>228</th>\n",
       "      <td>tfidf_228</td>\n",
       "      <td>2.469687e-05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>172</th>\n",
       "      <td>tfidf_172</td>\n",
       "      <td>2.465950e-05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>131</th>\n",
       "      <td>tfidf_131</td>\n",
       "      <td>2.461476e-05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>296</th>\n",
       "      <td>tfidf_296</td>\n",
       "      <td>2.449296e-05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>235</th>\n",
       "      <td>tfidf_235</td>\n",
       "      <td>2.441368e-05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>327</th>\n",
       "      <td>tfidf_327</td>\n",
       "      <td>2.430767e-05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>302</th>\n",
       "      <td>tfidf_302</td>\n",
       "      <td>2.397775e-05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>143</th>\n",
       "      <td>tfidf_143</td>\n",
       "      <td>2.395568e-05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>225</th>\n",
       "      <td>tfidf_225</td>\n",
       "      <td>2.379855e-05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>462</th>\n",
       "      <td>tea</td>\n",
       "      <td>2.359634e-05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>461</th>\n",
       "      <td>tar</td>\n",
       "      <td>2.342041e-05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>261</th>\n",
       "      <td>tfidf_261</td>\n",
       "      <td>2.336428e-05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>254</th>\n",
       "      <td>tfidf_254</td>\n",
       "      <td>2.278321e-05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>182</th>\n",
       "      <td>tfidf_182</td>\n",
       "      <td>2.239212e-05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>134</th>\n",
       "      <td>tfidf_134</td>\n",
       "      <td>2.232657e-05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51</th>\n",
       "      <td>tfidf_51</td>\n",
       "      <td>2.128760e-05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>242</th>\n",
       "      <td>tfidf_242</td>\n",
       "      <td>2.075735e-05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>440</th>\n",
       "      <td>lavender</td>\n",
       "      <td>2.071434e-05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>72</th>\n",
       "      <td>tfidf_72</td>\n",
       "      <td>2.034994e-05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>308</th>\n",
       "      <td>tfidf_308</td>\n",
       "      <td>1.991417e-05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>322</th>\n",
       "      <td>tfidf_322</td>\n",
       "      <td>1.989381e-05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>92</th>\n",
       "      <td>tfidf_92</td>\n",
       "      <td>1.969211e-05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>209</th>\n",
       "      <td>tfidf_209</td>\n",
       "      <td>1.900011e-05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>tfidf_8</td>\n",
       "      <td>1.837257e-05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>238</th>\n",
       "      <td>tfidf_238</td>\n",
       "      <td>1.776894e-05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>tfidf_95</td>\n",
       "      <td>1.746417e-05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>89</th>\n",
       "      <td>tfidf_89</td>\n",
       "      <td>1.664240e-05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>248</th>\n",
       "      <td>tfidf_248</td>\n",
       "      <td>1.651985e-05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>356</th>\n",
       "      <td>tfidf_356</td>\n",
       "      <td>1.530317e-05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>212</th>\n",
       "      <td>tfidf_212</td>\n",
       "      <td>1.406033e-05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>179</th>\n",
       "      <td>tfidf_179</td>\n",
       "      <td>1.312613e-05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>133</th>\n",
       "      <td>tfidf_133</td>\n",
       "      <td>1.234784e-05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>293</th>\n",
       "      <td>tfidf_293</td>\n",
       "      <td>1.204492e-05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>176</th>\n",
       "      <td>tfidf_176</td>\n",
       "      <td>1.120363e-05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>379</th>\n",
       "      <td>tfidf_379</td>\n",
       "      <td>1.077285e-05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>74</th>\n",
       "      <td>tfidf_74</td>\n",
       "      <td>1.053719e-05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>tfidf_42</td>\n",
       "      <td>8.974868e-06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>218</th>\n",
       "      <td>tfidf_218</td>\n",
       "      <td>7.821803e-06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>444</th>\n",
       "      <td>menthol</td>\n",
       "      <td>7.759558e-06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>425</th>\n",
       "      <td>blue cheese</td>\n",
       "      <td>6.974757e-06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>449</th>\n",
       "      <td>pear</td>\n",
       "      <td>6.616264e-06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>467</th>\n",
       "      <td>violet</td>\n",
       "      <td>2.466468e-06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>391</th>\n",
       "      <td>anxiety</td>\n",
       "      <td>1.395412e-06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>410</th>\n",
       "      <td>migraines</td>\n",
       "      <td>1.137504e-06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>396</th>\n",
       "      <td>depression</td>\n",
       "      <td>1.051706e-06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>411</th>\n",
       "      <td>pain</td>\n",
       "      <td>2.837155e-09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>414</th>\n",
       "      <td>seizures</td>\n",
       "      <td>1.767121e-09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>416</th>\n",
       "      <td>spasticity</td>\n",
       "      <td>0.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>403</th>\n",
       "      <td>eye pressure</td>\n",
       "      <td>0.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>404</th>\n",
       "      <td>fatigue</td>\n",
       "      <td>0.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>401</th>\n",
       "      <td>epilepsy</td>\n",
       "      <td>0.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>394</th>\n",
       "      <td>arthritis</td>\n",
       "      <td>0.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>417</th>\n",
       "      <td>stress</td>\n",
       "      <td>0.000000e+00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         features         score\n",
       "389        indica  3.624423e-01\n",
       "443         mango  9.597552e-02\n",
       "141     tfidf_141  3.037551e-02\n",
       "426     blueberry  3.014558e-02\n",
       "434        earthy  2.659452e-02\n",
       "253     tfidf_253  1.823066e-02\n",
       "168     tfidf_168  1.765265e-02\n",
       "345     tfidf_345  1.738846e-02\n",
       "210     tfidf_210  1.465557e-02\n",
       "285     tfidf_285  1.259075e-02\n",
       "30       tfidf_30  1.251227e-02\n",
       "402      euphoric  1.241404e-02\n",
       "145     tfidf_145  1.135147e-02\n",
       "43       tfidf_43  9.942689e-03\n",
       "281     tfidf_281  9.356456e-03\n",
       "312     tfidf_312  7.941212e-03\n",
       "306     tfidf_306  7.864755e-03\n",
       "121     tfidf_121  6.610208e-03\n",
       "149     tfidf_149  5.693723e-03\n",
       "245     tfidf_245  5.646254e-03\n",
       "151     tfidf_151  5.282113e-03\n",
       "390        sativa  5.240649e-03\n",
       "329     tfidf_329  5.192644e-03\n",
       "433        diesel  5.166715e-03\n",
       "319     tfidf_319  4.896509e-03\n",
       "362     tfidf_362  4.729775e-03\n",
       "199     tfidf_199  4.712798e-03\n",
       "78       tfidf_78  4.455422e-03\n",
       "207     tfidf_207  4.372944e-03\n",
       "357     tfidf_357  3.996997e-03\n",
       "309     tfidf_309  3.993459e-03\n",
       "7         tfidf_7  3.945276e-03\n",
       "413       relaxed  3.905410e-03\n",
       "393       aroused  3.846627e-03\n",
       "21       tfidf_21  3.832644e-03\n",
       "273     tfidf_273  3.605175e-03\n",
       "303     tfidf_303  3.548193e-03\n",
       "119     tfidf_119  3.455383e-03\n",
       "136     tfidf_136  3.446911e-03\n",
       "233     tfidf_233  3.308295e-03\n",
       "205     tfidf_205  3.304178e-03\n",
       "267     tfidf_267  3.150903e-03\n",
       "280     tfidf_280  3.142808e-03\n",
       "82       tfidf_82  3.068097e-03\n",
       "418     talkative  3.067031e-03\n",
       "336     tfidf_336  3.032505e-03\n",
       "304     tfidf_304  2.955500e-03\n",
       "109     tfidf_109  2.934543e-03\n",
       "405       focused  2.889729e-03\n",
       "128     tfidf_128  2.860944e-03\n",
       "46       tfidf_46  2.835231e-03\n",
       "93       tfidf_93  2.627759e-03\n",
       "173     tfidf_173  2.595129e-03\n",
       "409        hungry  2.470958e-03\n",
       "406        giggly  2.444092e-03\n",
       "343     tfidf_343  2.288466e-03\n",
       "340     tfidf_340  2.211194e-03\n",
       "370     tfidf_370  2.161762e-03\n",
       "23       tfidf_23  2.149596e-03\n",
       "54       tfidf_54  2.143516e-03\n",
       "457         skunk  2.140238e-03\n",
       "137     tfidf_137  2.123428e-03\n",
       "353     tfidf_353  2.116287e-03\n",
       "97       tfidf_97  2.104031e-03\n",
       "73       tfidf_73  2.064193e-03\n",
       "239     tfidf_239  1.999203e-03\n",
       "349     tfidf_349  1.941839e-03\n",
       "265     tfidf_265  1.901751e-03\n",
       "388        hybrid  1.890062e-03\n",
       "314     tfidf_314  1.835867e-03\n",
       "407         happy  1.767421e-03\n",
       "381     tfidf_381  1.762457e-03\n",
       "187     tfidf_187  1.741345e-03\n",
       "158     tfidf_158  1.721663e-03\n",
       "174     tfidf_174  1.704288e-03\n",
       "337     tfidf_337  1.661407e-03\n",
       "1         tfidf_1  1.649808e-03\n",
       "11       tfidf_11  1.648947e-03\n",
       "83       tfidf_83  1.623868e-03\n",
       "66       tfidf_66  1.612247e-03\n",
       "399     dry mouth  1.598080e-03\n",
       "75       tfidf_75  1.586259e-03\n",
       "230     tfidf_230  1.570560e-03\n",
       "217     tfidf_217  1.522690e-03\n",
       "364     tfidf_364  1.514263e-03\n",
       "162     tfidf_162  1.509922e-03\n",
       "460         sweet  1.509680e-03\n",
       "104     tfidf_104  1.504623e-03\n",
       "395      creative  1.452082e-03\n",
       "166     tfidf_166  1.436635e-03\n",
       "420      uplifted  1.380725e-03\n",
       "415        sleepy  1.322396e-03\n",
       "258     tfidf_258  1.321770e-03\n",
       "297     tfidf_297  1.299227e-03\n",
       "98       tfidf_98  1.256140e-03\n",
       "424         berry  1.250484e-03\n",
       "291     tfidf_291  1.204532e-03\n",
       "215     tfidf_215  1.152580e-03\n",
       "366     tfidf_366  1.147262e-03\n",
       "269     tfidf_269  1.090104e-03\n",
       "278     tfidf_278  1.071671e-03\n",
       "454       pungent  1.035155e-03\n",
       "125     tfidf_125  1.030408e-03\n",
       "451          pine  1.022988e-03\n",
       "282     tfidf_282  9.681002e-04\n",
       "299     tfidf_299  9.668313e-04\n",
       "250     tfidf_250  9.603703e-04\n",
       "294     tfidf_294  9.455706e-04\n",
       "270     tfidf_270  9.264436e-04\n",
       "419        tingly  9.109824e-04\n",
       "15       tfidf_15  9.065333e-04\n",
       "37       tfidf_37  9.048770e-04\n",
       "202     tfidf_202  9.008287e-04\n",
       "64       tfidf_64  8.603170e-04\n",
       "350     tfidf_350  8.393182e-04\n",
       "120     tfidf_120  8.267806e-04\n",
       "5         tfidf_5  8.170400e-04\n",
       "376     tfidf_376  7.854181e-04\n",
       "326     tfidf_326  7.820910e-04\n",
       "374     tfidf_374  7.780784e-04\n",
       "441         lemon  7.774149e-04\n",
       "342     tfidf_342  7.564987e-04\n",
       "20       tfidf_20  7.534283e-04\n",
       "400     energetic  7.413046e-04\n",
       "169     tfidf_169  7.410459e-04\n",
       "150     tfidf_150  7.226595e-04\n",
       "107     tfidf_107  7.071764e-04\n",
       "459    strawberry  6.989761e-04\n",
       "144     tfidf_144  6.866891e-04\n",
       "398      dry eyes  6.720806e-04\n",
       "181     tfidf_181  6.452309e-04\n",
       "383     tfidf_383  6.350969e-04\n",
       "124     tfidf_124  6.142887e-04\n",
       "320     tfidf_320  6.120594e-04\n",
       "360     tfidf_360  6.085444e-04\n",
       "432        coffee  6.050190e-04\n",
       "18       tfidf_18  5.862086e-04\n",
       "447        orange  5.770814e-04\n",
       "167     tfidf_167  5.769369e-04\n",
       "114     tfidf_114  5.764972e-04\n",
       "103     tfidf_103  5.708962e-04\n",
       "198     tfidf_198  5.682869e-04\n",
       "387     tfidf_387  5.669010e-04\n",
       "164     tfidf_164  5.613981e-04\n",
       "203     tfidf_203  5.553699e-04\n",
       "371     tfidf_371  5.348351e-04\n",
       "290     tfidf_290  5.318226e-04\n",
       "130     tfidf_130  5.274545e-04\n",
       "431        citrus  5.160573e-04\n",
       "101     tfidf_101  5.052095e-04\n",
       "52       tfidf_52  5.024872e-04\n",
       "208     tfidf_208  4.974079e-04\n",
       "367     tfidf_367  4.921476e-04\n",
       "466       vanilla  4.865805e-04\n",
       "77       tfidf_77  4.844178e-04\n",
       "56       tfidf_56  4.757838e-04\n",
       "0         tfidf_0  4.652445e-04\n",
       "325     tfidf_325  4.546171e-04\n",
       "34       tfidf_34  4.434996e-04\n",
       "240     tfidf_240  4.313476e-04\n",
       "48       tfidf_48  4.212687e-04\n",
       "412      paranoid  4.073599e-04\n",
       "224     tfidf_224  4.028112e-04\n",
       "186     tfidf_186  3.948505e-04\n",
       "146     tfidf_146  3.911197e-04\n",
       "375     tfidf_375  3.877253e-04\n",
       "368     tfidf_368  3.873197e-04\n",
       "85       tfidf_85  3.838307e-04\n",
       "263     tfidf_263  3.827074e-04\n",
       "135     tfidf_135  3.785531e-04\n",
       "274     tfidf_274  3.758650e-04\n",
       "88       tfidf_88  3.728204e-04\n",
       "22       tfidf_22  3.699430e-04\n",
       "154     tfidf_154  3.648378e-04\n",
       "61       tfidf_61  3.647379e-04\n",
       "231     tfidf_231  3.635621e-04\n",
       "283     tfidf_283  3.613363e-04\n",
       "155     tfidf_155  3.599172e-04\n",
       "351     tfidf_351  3.587620e-04\n",
       "397         dizzy  3.549937e-04\n",
       "190     tfidf_190  3.534695e-04\n",
       "41       tfidf_41  3.477505e-04\n",
       "331     tfidf_331  3.475548e-04\n",
       "300     tfidf_300  3.442218e-04\n",
       "272     tfidf_272  3.418034e-04\n",
       "468         woody  3.390170e-04\n",
       "67       tfidf_67  3.297375e-04\n",
       "455          rose  3.234854e-04\n",
       "352     tfidf_352  3.177799e-04\n",
       "408      headache  3.170234e-04\n",
       "437         grape  3.107697e-04\n",
       "341     tfidf_341  3.105897e-04\n",
       "338     tfidf_338  3.102014e-04\n",
       "428        cheese  3.059789e-04\n",
       "200     tfidf_200  2.992413e-04\n",
       "80       tfidf_80  2.942535e-04\n",
       "19       tfidf_19  2.890743e-04\n",
       "117     tfidf_117  2.859134e-04\n",
       "152     tfidf_152  2.829960e-04\n",
       "363     tfidf_363  2.804443e-04\n",
       "347     tfidf_347  2.788488e-04\n",
       "262     tfidf_262  2.778543e-04\n",
       "259     tfidf_259  2.675090e-04\n",
       "16       tfidf_16  2.667125e-04\n",
       "385     tfidf_385  2.659263e-04\n",
       "221     tfidf_221  2.654959e-04\n",
       "108     tfidf_108  2.624206e-04\n",
       "116     tfidf_116  2.522841e-04\n",
       "139     tfidf_139  2.495878e-04\n",
       "112     tfidf_112  2.482599e-04\n",
       "382     tfidf_382  2.481766e-04\n",
       "28       tfidf_28  2.466732e-04\n",
       "188     tfidf_188  2.414166e-04\n",
       "264     tfidf_264  2.400809e-04\n",
       "94       tfidf_94  2.386607e-04\n",
       "129     tfidf_129  2.380922e-04\n",
       "32       tfidf_32  2.373712e-04\n",
       "147     tfidf_147  2.342239e-04\n",
       "55       tfidf_55  2.267952e-04\n",
       "96       tfidf_96  2.258479e-04\n",
       "91       tfidf_91  2.256533e-04\n",
       "58       tfidf_58  2.214869e-04\n",
       "90       tfidf_90  2.207162e-04\n",
       "392       anxious  2.203760e-04\n",
       "307     tfidf_307  2.199817e-04\n",
       "3         tfidf_3  2.198533e-04\n",
       "423       apricot  2.197597e-04\n",
       "159     tfidf_159  2.150276e-04\n",
       "234     tfidf_234  2.125176e-04\n",
       "26       tfidf_26  2.122235e-04\n",
       "178     tfidf_178  2.112113e-04\n",
       "39       tfidf_39  2.090402e-04\n",
       "339     tfidf_339  2.086446e-04\n",
       "4         tfidf_4  2.085869e-04\n",
       "65       tfidf_65  2.073160e-04\n",
       "71       tfidf_71  2.039041e-04\n",
       "442          lime  2.020397e-04\n",
       "286     tfidf_286  1.985679e-04\n",
       "435       flowery  1.970026e-04\n",
       "126     tfidf_126  1.949629e-04\n",
       "373     tfidf_373  1.929855e-04\n",
       "243     tfidf_243  1.888868e-04\n",
       "204     tfidf_204  1.881786e-04\n",
       "214     tfidf_214  1.877596e-04\n",
       "185     tfidf_185  1.867316e-04\n",
       "62       tfidf_62  1.865467e-04\n",
       "355     tfidf_355  1.847547e-04\n",
       "44       tfidf_44  1.824800e-04\n",
       "321     tfidf_321  1.805900e-04\n",
       "450        pepper  1.780417e-04\n",
       "227     tfidf_227  1.773123e-04\n",
       "333     tfidf_333  1.719919e-04\n",
       "316     tfidf_316  1.703449e-04\n",
       "195     tfidf_195  1.698804e-04\n",
       "142     tfidf_142  1.695097e-04\n",
       "175     tfidf_175  1.682796e-04\n",
       "237     tfidf_237  1.679714e-04\n",
       "251     tfidf_251  1.678972e-04\n",
       "111     tfidf_111  1.675265e-04\n",
       "436         fruit  1.668446e-04\n",
       "445          mint  1.659201e-04\n",
       "170     tfidf_170  1.655214e-04\n",
       "163     tfidf_163  1.601129e-04\n",
       "463       tobacco  1.579247e-04\n",
       "465      tropical  1.528894e-04\n",
       "317     tfidf_317  1.506114e-04\n",
       "153     tfidf_153  1.489048e-04\n",
       "6         tfidf_6  1.471784e-04\n",
       "354     tfidf_354  1.411273e-04\n",
       "110     tfidf_110  1.374763e-04\n",
       "315     tfidf_315  1.365407e-04\n",
       "348     tfidf_348  1.359520e-04\n",
       "183     tfidf_183  1.341317e-04\n",
       "453          plum  1.331923e-04\n",
       "189     tfidf_189  1.320567e-04\n",
       "105     tfidf_105  1.303445e-04\n",
       "222     tfidf_222  1.300583e-04\n",
       "196     tfidf_196  1.294557e-04\n",
       "100     tfidf_100  1.267740e-04\n",
       "276     tfidf_276  1.255224e-04\n",
       "14       tfidf_14  1.233770e-04\n",
       "372     tfidf_372  1.232093e-04\n",
       "9         tfidf_9  1.222829e-04\n",
       "50       tfidf_50  1.194036e-04\n",
       "260     tfidf_260  1.167383e-04\n",
       "301     tfidf_301  1.157441e-04\n",
       "464          tree  1.157230e-04\n",
       "17       tfidf_17  1.157217e-04\n",
       "138     tfidf_138  1.135730e-04\n",
       "69       tfidf_69  1.123488e-04\n",
       "24       tfidf_24  1.091629e-04\n",
       "232     tfidf_232  1.090944e-04\n",
       "49       tfidf_49  1.071590e-04\n",
       "118     tfidf_118  1.053744e-04\n",
       "226     tfidf_226  1.040987e-04\n",
       "161     tfidf_161  1.032810e-04\n",
       "289     tfidf_289  1.031330e-04\n",
       "271     tfidf_271  1.016019e-04\n",
       "330     tfidf_330  1.008614e-04\n",
       "252     tfidf_252  1.006402e-04\n",
       "206     tfidf_206  9.918510e-05\n",
       "305     tfidf_305  9.917566e-05\n",
       "184     tfidf_184  9.671756e-05\n",
       "10       tfidf_10  9.410079e-05\n",
       "31       tfidf_31  9.387784e-05\n",
       "60       tfidf_60  9.260249e-05\n",
       "27       tfidf_27  9.177584e-05\n",
       "193     tfidf_193  9.061611e-05\n",
       "287     tfidf_287  9.049361e-05\n",
       "318     tfidf_318  9.047349e-05\n",
       "45       tfidf_45  8.900911e-05\n",
       "123     tfidf_123  8.866387e-05\n",
       "275     tfidf_275  8.735721e-05\n",
       "256     tfidf_256  8.708073e-05\n",
       "2         tfidf_2  8.635287e-05\n",
       "99       tfidf_99  8.483436e-05\n",
       "295     tfidf_295  8.317590e-05\n",
       "171     tfidf_171  8.258757e-05\n",
       "277     tfidf_277  8.196309e-05\n",
       "63       tfidf_63  8.119720e-05\n",
       "288     tfidf_288  8.028753e-05\n",
       "223     tfidf_223  7.922171e-05\n",
       "247     tfidf_247  7.879064e-05\n",
       "380     tfidf_380  7.743664e-05\n",
       "220     tfidf_220  7.729707e-05\n",
       "132     tfidf_132  7.678215e-05\n",
       "81       tfidf_81  7.677491e-05\n",
       "219     tfidf_219  7.584382e-05\n",
       "106     tfidf_106  7.559153e-05\n",
       "446         nutty  7.556623e-05\n",
       "213     tfidf_213  7.474112e-05\n",
       "36       tfidf_36  7.376266e-05\n",
       "194     tfidf_194  7.369875e-05\n",
       "378     tfidf_378  7.345270e-05\n",
       "157     tfidf_157  7.292745e-05\n",
       "40       tfidf_40  7.284198e-05\n",
       "344     tfidf_344  7.263125e-05\n",
       "53       tfidf_53  7.032627e-05\n",
       "84       tfidf_84  6.979083e-05\n",
       "323     tfidf_323  6.948492e-05\n",
       "35       tfidf_35  6.895086e-05\n",
       "211     tfidf_211  6.762137e-05\n",
       "310     tfidf_310  6.675694e-05\n",
       "377     tfidf_377  6.587395e-05\n",
       "458  spicy/herbal  6.584428e-05\n",
       "421       ammonia  6.283705e-05\n",
       "346     tfidf_346  6.195531e-05\n",
       "180     tfidf_180  6.156216e-05\n",
       "313     tfidf_313  6.055049e-05\n",
       "384     tfidf_384  5.979248e-05\n",
       "70       tfidf_70  5.890790e-05\n",
       "448         peach  5.872697e-05\n",
       "57       tfidf_57  5.807938e-05\n",
       "76       tfidf_76  5.702129e-05\n",
       "386     tfidf_386  5.580795e-05\n",
       "246     tfidf_246  5.535617e-05\n",
       "122     tfidf_122  5.477164e-05\n",
       "86       tfidf_86  5.374024e-05\n",
       "361     tfidf_361  5.307592e-05\n",
       "79       tfidf_79  5.278021e-05\n",
       "429      chemical  5.275113e-05\n",
       "33       tfidf_33  5.196071e-05\n",
       "328     tfidf_328  5.191267e-05\n",
       "249     tfidf_249  4.980904e-05\n",
       "102     tfidf_102  4.927935e-05\n",
       "12       tfidf_12  4.872758e-05\n",
       "201     tfidf_201  4.815172e-05\n",
       "332     tfidf_332  4.438701e-05\n",
       "156     tfidf_156  4.262351e-05\n",
       "191     tfidf_191  4.260219e-05\n",
       "13       tfidf_13  4.232455e-05\n",
       "87       tfidf_87  4.162895e-05\n",
       "148     tfidf_148  4.131173e-05\n",
       "140     tfidf_140  4.044660e-05\n",
       "369     tfidf_369  4.028358e-05\n",
       "335     tfidf_335  4.023247e-05\n",
       "38       tfidf_38  4.002174e-05\n",
       "266     tfidf_266  3.991581e-05\n",
       "236     tfidf_236  3.907815e-05\n",
       "456          sage  3.789205e-05\n",
       "358     tfidf_358  3.724652e-05\n",
       "47       tfidf_47  3.711948e-05\n",
       "298     tfidf_298  3.625457e-05\n",
       "29       tfidf_29  3.505192e-05\n",
       "292     tfidf_292  3.453284e-05\n",
       "115     tfidf_115  3.451392e-05\n",
       "255     tfidf_255  3.421368e-05\n",
       "113     tfidf_113  3.396861e-05\n",
       "359     tfidf_359  3.380387e-05\n",
       "197     tfidf_197  3.335155e-05\n",
       "324     tfidf_324  3.325133e-05\n",
       "127     tfidf_127  3.265252e-05\n",
       "438    grapefruit  3.247805e-05\n",
       "427        butter  3.222229e-05\n",
       "25       tfidf_25  3.198132e-05\n",
       "241     tfidf_241  3.152130e-05\n",
       "334     tfidf_334  3.124619e-05\n",
       "216     tfidf_216  3.111428e-05\n",
       "279     tfidf_279  3.080572e-05\n",
       "68       tfidf_68  3.058752e-05\n",
       "311     tfidf_311  3.004702e-05\n",
       "160     tfidf_160  2.949155e-05\n",
       "365     tfidf_365  2.947635e-05\n",
       "59       tfidf_59  2.858415e-05\n",
       "268     tfidf_268  2.746948e-05\n",
       "284     tfidf_284  2.739031e-05\n",
       "257     tfidf_257  2.737002e-05\n",
       "452     pineapple  2.726917e-05\n",
       "244     tfidf_244  2.697993e-05\n",
       "229     tfidf_229  2.688839e-05\n",
       "177     tfidf_177  2.682665e-05\n",
       "439         honey  2.649137e-05\n",
       "430      chestnut  2.629562e-05\n",
       "165     tfidf_165  2.513065e-05\n",
       "422         apple  2.493427e-05\n",
       "192     tfidf_192  2.473289e-05\n",
       "228     tfidf_228  2.469687e-05\n",
       "172     tfidf_172  2.465950e-05\n",
       "131     tfidf_131  2.461476e-05\n",
       "296     tfidf_296  2.449296e-05\n",
       "235     tfidf_235  2.441368e-05\n",
       "327     tfidf_327  2.430767e-05\n",
       "302     tfidf_302  2.397775e-05\n",
       "143     tfidf_143  2.395568e-05\n",
       "225     tfidf_225  2.379855e-05\n",
       "462           tea  2.359634e-05\n",
       "461           tar  2.342041e-05\n",
       "261     tfidf_261  2.336428e-05\n",
       "254     tfidf_254  2.278321e-05\n",
       "182     tfidf_182  2.239212e-05\n",
       "134     tfidf_134  2.232657e-05\n",
       "51       tfidf_51  2.128760e-05\n",
       "242     tfidf_242  2.075735e-05\n",
       "440      lavender  2.071434e-05\n",
       "72       tfidf_72  2.034994e-05\n",
       "308     tfidf_308  1.991417e-05\n",
       "322     tfidf_322  1.989381e-05\n",
       "92       tfidf_92  1.969211e-05\n",
       "209     tfidf_209  1.900011e-05\n",
       "8         tfidf_8  1.837257e-05\n",
       "238     tfidf_238  1.776894e-05\n",
       "95       tfidf_95  1.746417e-05\n",
       "89       tfidf_89  1.664240e-05\n",
       "248     tfidf_248  1.651985e-05\n",
       "356     tfidf_356  1.530317e-05\n",
       "212     tfidf_212  1.406033e-05\n",
       "179     tfidf_179  1.312613e-05\n",
       "133     tfidf_133  1.234784e-05\n",
       "293     tfidf_293  1.204492e-05\n",
       "176     tfidf_176  1.120363e-05\n",
       "379     tfidf_379  1.077285e-05\n",
       "74       tfidf_74  1.053719e-05\n",
       "42       tfidf_42  8.974868e-06\n",
       "218     tfidf_218  7.821803e-06\n",
       "444       menthol  7.759558e-06\n",
       "425   blue cheese  6.974757e-06\n",
       "449          pear  6.616264e-06\n",
       "467        violet  2.466468e-06\n",
       "391       anxiety  1.395412e-06\n",
       "410     migraines  1.137504e-06\n",
       "396    depression  1.051706e-06\n",
       "411          pain  2.837155e-09\n",
       "414      seizures  1.767121e-09\n",
       "416    spasticity  0.000000e+00\n",
       "403  eye pressure  0.000000e+00\n",
       "404       fatigue  0.000000e+00\n",
       "401      epilepsy  0.000000e+00\n",
       "394     arthritis  0.000000e+00\n",
       "417        stress  0.000000e+00"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.set_option('display.max_rows', df_feat_ranked.shape[0]+1)\n",
    "df_feat_ranked"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/louispandu/anaconda3/lib/python3.10/site-packages/sklearn/feature_selection/_from_model.py:357: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  self.estimator_.fit(X, y, **fit_params)\n"
     ]
    }
   ],
   "source": [
    "selector = SelectFromModel(rfreg).fit(X_train1, y_train1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([5.91754582e-04, 1.72533519e-03, 7.31549083e-05, 3.66680975e-04,\n",
       "       2.07867204e-04, 9.54798606e-04, 9.57826776e-05, 3.91864106e-03,\n",
       "       1.58112150e-05, 1.03120522e-04, 7.14032274e-05, 1.73923789e-03,\n",
       "       3.82078350e-05, 6.76459987e-05, 1.44370624e-04, 8.11853796e-04,\n",
       "       2.22281876e-04, 1.65014759e-04, 7.40757751e-04, 2.58960675e-04,\n",
       "       7.27204415e-04, 3.66578422e-03, 3.64353148e-04, 2.82838257e-03,\n",
       "       1.23792960e-04, 3.81033474e-05, 1.84862969e-04, 7.58924019e-05,\n",
       "       2.20748443e-04, 4.50155053e-05, 1.26326229e-02, 8.00661003e-05,\n",
       "       2.46281778e-04, 4.85778117e-05, 4.68735105e-04, 7.32691012e-05,\n",
       "       7.88038145e-05, 1.25892686e-03, 4.63037921e-05, 1.99971115e-04,\n",
       "       8.40320265e-05, 1.47495297e-04, 9.75079039e-06, 9.79164484e-03,\n",
       "       2.02037892e-04, 8.37166698e-05, 2.71226623e-03, 4.95602360e-05,\n",
       "       3.17129457e-04, 1.13953444e-04, 1.31581056e-04, 1.83058735e-05,\n",
       "       6.65561454e-04, 7.46274228e-05, 1.84849806e-03, 2.43373317e-04,\n",
       "       2.10379769e-04, 8.11150008e-05, 1.96444373e-04, 2.43311251e-05,\n",
       "       9.21039943e-05, 3.87579535e-04, 9.98946614e-05, 8.99382162e-05,\n",
       "       4.78567848e-04, 1.68878772e-04, 1.55142735e-03, 1.76644737e-04,\n",
       "       3.06159138e-05, 1.04334571e-04, 4.70607957e-05, 2.10362011e-04,\n",
       "       2.04222602e-05, 1.90383819e-03, 1.21468252e-05, 1.67997805e-03,\n",
       "       4.42386519e-05, 1.36320407e-03, 4.63802106e-03, 4.57629394e-05,\n",
       "       3.38406503e-04, 6.92871904e-05, 3.88718110e-03, 1.52606977e-03,\n",
       "       7.93606555e-05, 2.70770524e-05, 6.12033935e-05, 4.97597679e-05,\n",
       "       3.45584224e-04, 3.21970712e-05, 1.92091954e-04, 1.86381503e-04,\n",
       "       1.51222483e-05, 2.58138907e-03, 1.11511009e-04, 1.69867734e-05,\n",
       "       1.77498087e-04, 2.25584679e-03, 1.60148723e-03, 1.00020747e-04,\n",
       "       1.04246647e-04, 3.87832065e-04, 4.10768040e-05, 6.78624862e-04,\n",
       "       1.45011847e-03, 1.09479680e-04, 8.28556883e-05, 6.45023759e-04,\n",
       "       2.26820422e-04, 2.71629929e-03, 2.02535196e-04, 9.40344490e-05,\n",
       "       1.98622034e-04, 3.47411036e-05, 5.76716832e-04, 4.67454033e-05,\n",
       "       2.05286429e-04, 2.45730562e-04, 9.59815432e-05, 3.28631703e-03,\n",
       "       7.57874735e-04, 8.19322196e-03, 4.11045897e-05, 8.66299918e-05,\n",
       "       5.52033845e-04, 8.80054917e-04, 2.25558698e-04, 4.34081630e-05,\n",
       "       3.79112878e-03, 1.79799065e-04, 4.41197982e-04, 3.29683833e-05,\n",
       "       1.11231569e-04, 1.23539010e-05, 2.25195465e-05, 2.86147573e-04,\n",
       "       3.58449960e-03, 1.52821495e-03, 1.26498960e-04, 1.44615952e-04,\n",
       "       5.03941106e-05, 2.98346486e-02, 1.49416184e-04, 2.06938285e-05,\n",
       "       6.23742620e-04, 1.21544437e-02, 3.25007071e-04, 2.44263396e-04,\n",
       "       1.18340358e-04, 5.94183238e-03, 5.73155889e-04, 6.03008072e-03,\n",
       "       2.71606954e-04, 1.43953896e-04, 3.94758369e-04, 3.25944491e-04,\n",
       "       4.18355579e-05, 7.30808001e-05, 1.37066800e-03, 1.84675596e-04,\n",
       "       4.47321267e-05, 1.19697204e-04, 1.73291268e-03, 1.75713211e-04,\n",
       "       2.74171969e-04, 2.28939516e-05, 1.13738994e-03, 5.28578392e-04,\n",
       "       1.83127425e-02, 9.16098416e-04, 1.30873682e-04, 6.64306056e-05,\n",
       "       2.09326245e-05, 2.39828601e-03, 1.39063662e-03, 1.18572026e-04,\n",
       "       1.51686243e-05, 2.23722970e-05, 2.59368767e-04, 1.36379105e-05,\n",
       "       6.96713220e-05, 6.33535221e-04, 2.20791499e-05, 1.22043520e-04,\n",
       "       7.53356119e-05, 1.36548223e-04, 2.25763660e-04, 1.83937376e-03,\n",
       "       2.14062726e-04, 1.42949799e-04, 3.98626234e-04, 6.09821178e-05,\n",
       "       4.22262275e-05, 1.03890069e-04, 6.79101496e-05, 1.28108548e-04,\n",
       "       2.67203047e-04, 3.09220742e-05, 4.98737834e-04, 4.94626644e-03,\n",
       "       2.50172285e-04, 5.11743252e-05, 1.00258056e-03, 5.05861577e-04,\n",
       "       2.81147869e-04, 3.07215277e-03, 1.15702525e-04, 4.19067284e-03,\n",
       "       5.91950982e-04, 2.00758499e-05, 1.34282307e-02, 7.55591271e-05,\n",
       "       1.86821169e-05, 3.24449066e-05, 2.18321131e-04, 3.19039010e-04,\n",
       "       5.21852533e-05, 1.45054033e-03, 1.24432107e-05, 7.98220485e-05,\n",
       "       9.80891087e-05, 2.37331264e-04, 1.19709781e-04, 7.93170472e-05,\n",
       "       3.67904605e-04, 2.81654812e-05, 5.11409736e-05, 1.22329129e-04,\n",
       "       2.39846657e-05, 2.99012266e-05, 2.03886687e-03, 3.44583156e-04,\n",
       "       7.32614426e-05, 3.28427433e-03, 1.57203388e-04, 2.95694520e-05,\n",
       "       6.62040195e-05, 1.77345252e-04, 1.29562991e-05, 2.37617232e-03,\n",
       "       5.76924545e-04, 2.41265035e-05, 2.12830556e-05, 1.94735493e-04,\n",
       "       2.55394384e-05, 5.96250918e-03, 7.87690176e-05, 5.92452817e-05,\n",
       "       1.44844134e-05, 2.73068953e-04, 7.12183484e-04, 1.06861623e-04,\n",
       "       1.20508139e-04, 1.81104320e-02, 2.23515212e-05, 9.60611888e-05,\n",
       "       8.61924842e-05, 2.59263098e-05, 1.22648575e-03, 2.14289732e-04,\n",
       "       1.17154991e-04, 2.19306604e-05, 1.94443533e-04, 6.61226932e-04,\n",
       "       3.12337045e-04, 1.77327833e-03, 4.17280273e-05, 2.66184777e-03,\n",
       "       3.94629173e-05, 1.09404205e-03, 5.95325685e-05, 1.14707360e-04,\n",
       "       2.01918523e-04, 4.01345032e-03, 4.33324113e-04, 7.00697458e-05,\n",
       "       1.02175069e-04, 8.29274091e-05, 8.94368138e-04, 6.67490382e-05,\n",
       "       3.21050243e-03, 9.74189096e-03, 3.16458102e-04, 3.43961996e-04,\n",
       "       2.11395841e-05, 1.31505802e-02, 1.32394272e-04, 7.89293317e-05,\n",
       "       7.37585902e-05, 8.76133921e-05, 6.23241274e-04, 1.38354227e-03,\n",
       "       4.56590605e-05, 1.22511460e-05, 8.31808877e-04, 9.18573894e-05,\n",
       "       2.82040863e-05, 1.20400893e-03, 3.27096271e-05, 9.85127265e-04,\n",
       "       3.81609760e-04, 1.94806686e-04, 2.94743707e-05, 3.31070320e-03,\n",
       "       2.40169936e-03, 1.41964806e-04, 8.00376109e-03, 2.10620711e-04,\n",
       "       2.47014960e-05, 4.36217017e-03, 4.84714362e-05, 2.47026592e-05,\n",
       "       8.01368416e-03, 3.27062744e-05, 1.38188199e-03, 1.28036027e-04,\n",
       "       1.65195217e-04, 1.35735242e-04, 5.61051637e-05, 4.82093049e-03,\n",
       "       7.18604303e-04, 2.07946038e-04, 1.36735529e-05, 9.65266783e-05,\n",
       "       2.94540927e-05, 4.00638408e-04, 4.91420596e-04, 2.38883525e-05,\n",
       "       2.80197798e-05, 5.94804476e-03, 7.45672176e-05, 2.93172012e-04,\n",
       "       7.03769138e-05, 1.03046937e-04, 4.39338625e-05, 1.22794496e-04,\n",
       "       2.92955540e-03, 1.32005240e-03, 2.63193554e-04, 2.37975807e-04,\n",
       "       2.16166600e-03, 2.44236530e-04, 8.04950346e-04, 1.88883302e-03,\n",
       "       7.33278029e-05, 1.73083933e-02, 8.19454235e-05, 2.83739574e-04,\n",
       "       1.28106247e-04, 1.26671821e-03, 7.30917277e-04, 3.64927959e-04,\n",
       "       2.89072972e-04, 1.59342544e-03, 1.49109790e-04, 1.44767817e-04,\n",
       "       1.59460454e-05, 3.73283152e-03, 5.04422000e-05, 3.42946151e-05,\n",
       "       6.20356810e-04, 5.50720674e-05, 4.72968685e-03, 2.90423836e-04,\n",
       "       1.51462242e-03, 2.82808744e-05, 1.35448935e-03, 4.98459681e-04,\n",
       "       3.08468512e-04, 4.10433577e-05, 2.87806065e-03, 6.17433396e-04,\n",
       "       1.02204858e-04, 2.42117412e-04, 6.66140201e-04, 2.71162501e-04,\n",
       "       6.23472159e-04, 4.15318458e-05, 6.10258475e-05, 1.16626618e-05,\n",
       "       6.29893063e-05, 1.90312430e-03, 1.82342129e-04, 5.73338524e-04,\n",
       "       5.14771123e-05, 2.97250196e-04, 4.66914957e-05, 4.80707071e-04,\n",
       "       2.04011927e-03, 3.62988726e-01, 5.11854004e-03, 1.31994684e-06,\n",
       "       8.99600551e-05, 3.64009945e-03, 7.39663595e-09, 1.69042992e-03,\n",
       "       1.04852916e-06, 3.33144903e-04, 7.14614218e-04, 1.72223716e-03,\n",
       "       8.23106253e-04, 9.99690621e-10, 1.24768142e-02, 1.19375853e-09,\n",
       "       1.93737933e-08, 3.04989298e-03, 3.19327793e-03, 1.78046041e-03,\n",
       "       1.65008907e-04, 3.49042515e-03, 1.59960333e-06, 7.86584155e-09,\n",
       "       4.04148625e-04, 3.87418347e-03, 0.00000000e+00, 1.60098842e-03,\n",
       "       8.97535415e-09, 9.22628615e-09, 3.11915976e-03, 1.79591376e-03,\n",
       "       1.50081372e-03, 7.09930184e-05, 1.81383026e-05, 2.57599673e-04,\n",
       "       1.11094891e-03, 6.37663716e-06, 2.86041157e-02, 3.03964479e-05,\n",
       "       2.99566553e-04, 5.04243608e-05, 5.08297695e-05, 4.74638490e-04,\n",
       "       7.86612971e-04, 5.16168424e-03, 2.61239513e-02, 2.40234724e-04,\n",
       "       1.48616351e-04, 2.72315176e-04, 4.26266647e-05, 3.33700297e-05,\n",
       "       1.29957614e-05, 8.48111547e-04, 2.08156169e-04, 9.54725461e-02,\n",
       "       8.73790532e-06, 1.54900548e-04, 1.07474089e-04, 6.46046625e-04,\n",
       "       3.37546931e-05, 1.24552122e-06, 2.60346011e-04, 1.06374577e-03,\n",
       "       2.52014470e-05, 1.47318888e-04, 7.18927436e-04, 2.47803577e-04,\n",
       "       3.14548877e-05, 1.97135605e-03, 8.16575953e-05, 7.76606073e-04,\n",
       "       1.74755002e-03, 2.53450730e-05, 2.96935597e-05, 3.18723216e-04,\n",
       "       1.67041724e-04, 1.59322559e-04, 3.93434878e-04, 3.30797488e-06,\n",
       "       3.63367774e-04])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "selector.estimator_.feature_importances_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0021321961620469083"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "selector.threshold_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "mask = selector.get_support()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([False, False, False, False, False, False, False,  True, False,\n",
       "       False, False, False, False, False, False, False, False, False,\n",
       "       False, False, False,  True, False,  True, False, False, False,\n",
       "       False, False, False,  True, False, False, False, False, False,\n",
       "       False, False, False, False, False, False, False,  True, False,\n",
       "       False,  True, False, False, False, False, False, False, False,\n",
       "       False, False, False, False, False, False, False, False, False,\n",
       "       False, False, False, False, False, False, False, False, False,\n",
       "       False, False, False, False, False, False,  True, False, False,\n",
       "       False,  True, False, False, False, False, False, False, False,\n",
       "       False, False, False,  True, False, False, False,  True, False,\n",
       "       False, False, False, False, False, False, False, False, False,\n",
       "       False,  True, False, False, False, False, False, False, False,\n",
       "       False, False,  True, False,  True, False, False, False, False,\n",
       "       False, False,  True, False, False, False, False, False, False,\n",
       "       False,  True, False, False, False, False,  True, False, False,\n",
       "       False,  True, False, False, False,  True, False,  True, False,\n",
       "       False, False, False, False, False, False, False, False, False,\n",
       "       False, False, False, False, False, False,  True, False, False,\n",
       "       False, False,  True, False, False, False, False, False, False,\n",
       "       False, False, False, False, False, False, False, False, False,\n",
       "       False, False, False, False, False, False, False, False, False,\n",
       "       False,  True, False, False, False, False, False,  True, False,\n",
       "        True, False, False,  True, False, False, False, False, False,\n",
       "       False, False, False, False, False, False, False, False, False,\n",
       "       False, False, False, False, False, False, False, False,  True,\n",
       "       False, False, False, False, False,  True, False, False, False,\n",
       "       False, False,  True, False, False, False, False, False, False,\n",
       "       False,  True, False, False, False, False, False, False, False,\n",
       "       False, False, False, False, False, False,  True, False, False,\n",
       "       False, False, False,  True, False, False, False, False, False,\n",
       "       False,  True,  True, False, False, False,  True, False, False,\n",
       "       False, False, False, False, False, False, False, False, False,\n",
       "       False, False, False, False, False, False,  True,  True, False,\n",
       "        True, False, False,  True, False, False,  True, False, False,\n",
       "       False, False, False, False,  True, False, False, False, False,\n",
       "       False, False, False, False, False,  True, False, False, False,\n",
       "       False, False, False,  True, False, False, False,  True, False,\n",
       "       False, False, False,  True, False, False, False, False, False,\n",
       "       False, False, False, False, False, False,  True, False, False,\n",
       "       False, False,  True, False, False, False, False, False, False,\n",
       "       False,  True, False, False, False, False, False, False, False,\n",
       "       False, False, False, False, False, False, False, False, False,\n",
       "       False, False,  True,  True, False, False,  True, False, False,\n",
       "       False, False, False, False, False, False,  True, False, False,\n",
       "        True,  True, False, False,  True, False, False, False,  True,\n",
       "       False, False, False, False,  True, False, False, False, False,\n",
       "       False, False, False,  True, False, False, False, False, False,\n",
       "       False,  True,  True, False, False, False, False, False, False,\n",
       "       False, False,  True, False, False, False, False, False, False,\n",
       "       False, False, False, False, False, False, False, False, False,\n",
       "       False, False, False, False, False, False, False, False, False,\n",
       "       False])"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "selected_features = X.columns[mask]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tfidf_7</th>\n",
       "      <th>tfidf_21</th>\n",
       "      <th>tfidf_23</th>\n",
       "      <th>tfidf_30</th>\n",
       "      <th>tfidf_43</th>\n",
       "      <th>tfidf_46</th>\n",
       "      <th>tfidf_78</th>\n",
       "      <th>tfidf_82</th>\n",
       "      <th>tfidf_93</th>\n",
       "      <th>tfidf_97</th>\n",
       "      <th>...</th>\n",
       "      <th>euphoric</th>\n",
       "      <th>focused</th>\n",
       "      <th>giggly</th>\n",
       "      <th>hungry</th>\n",
       "      <th>relaxed</th>\n",
       "      <th>talkative</th>\n",
       "      <th>blueberry</th>\n",
       "      <th>diesel</th>\n",
       "      <th>earthy</th>\n",
       "      <th>mango</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.152565</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.152565</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.253181</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.198545</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.204993</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59995</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.312348</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59996</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.108601</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59997</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.349629</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59998</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59999</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>60000 rows × 60 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       tfidf_7  tfidf_21  tfidf_23  tfidf_30  tfidf_43  tfidf_46  tfidf_78  \\\n",
       "0          0.0  0.000000       0.0       0.0  0.000000       0.0  0.152565   \n",
       "1          0.0  0.000000       0.0       0.0  0.000000       0.0  0.152565   \n",
       "2          0.0  0.000000       0.0       0.0  0.000000       0.0  0.000000   \n",
       "3          0.0  0.000000       0.0       0.0  0.198545       0.0  0.204993   \n",
       "4          0.0  0.000000       0.0       0.0  0.000000       0.0  0.000000   \n",
       "...        ...       ...       ...       ...       ...       ...       ...   \n",
       "59995      0.0  0.000000       0.0       0.0  0.000000       0.0  0.312348   \n",
       "59996      0.0  0.000000       0.0       0.0  0.000000       0.0  0.000000   \n",
       "59997      0.0  0.349629       0.0       0.0  0.000000       0.0  0.000000   \n",
       "59998      0.0  0.000000       0.0       0.0  0.000000       0.0  0.000000   \n",
       "59999      0.0  0.000000       0.0       0.0  0.000000       0.0  0.000000   \n",
       "\n",
       "       tfidf_82  tfidf_93  tfidf_97  ...  euphoric  focused  giggly  hungry  \\\n",
       "0           0.0  0.000000       0.0  ...         1        0       0       1   \n",
       "1           0.0  0.000000       0.0  ...         1        0       0       1   \n",
       "2           0.0  0.253181       0.0  ...         1        1       0       0   \n",
       "3           0.0  0.000000       0.0  ...         1        1       0       1   \n",
       "4           0.0  0.000000       0.0  ...         1        0       0       0   \n",
       "...         ...       ...       ...  ...       ...      ...     ...     ...   \n",
       "59995       0.0  0.000000       0.0  ...         0        0       0       0   \n",
       "59996       0.0  0.108601       0.0  ...         0        0       0       0   \n",
       "59997       0.0  0.000000       0.0  ...         0        0       1       0   \n",
       "59998       0.0  0.000000       0.0  ...         0        0       0       0   \n",
       "59999       0.0  0.000000       0.0  ...         1        0       0       0   \n",
       "\n",
       "       relaxed  talkative  blueberry  diesel  earthy  mango  \n",
       "0            1          0          0       0       0      0  \n",
       "1            1          0          0       0       0      0  \n",
       "2            1          0          0       0       0      0  \n",
       "3            0          0          0       0       0      0  \n",
       "4            1          0          0       0       0      0  \n",
       "...        ...        ...        ...     ...     ...    ...  \n",
       "59995        1          0          0       0       0      0  \n",
       "59996        0          0          0       0       0      0  \n",
       "59997        0          0          0       0       0      0  \n",
       "59998        0          0          0       0       0      0  \n",
       "59999        0          0          0       0       0      0  \n",
       "\n",
       "[60000 rows x 60 columns]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "selected_X = df_rf[selected_features]\n",
    "selected_X"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train test split (after Feature Selection)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['selected_X_rf_tfidf_alpine.pkl']"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import joblib\n",
    "\n",
    "joblib.dump(selector, \"selector_rf_tfidf_alpine.pkl\")\n",
    "joblib.dump(selected_X, \"selected_X_rf_tfidf_alpine.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(selected_X, y, random_state=1, test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train1, X_val, y_train1, y_val = train_test_split(X_train, y_train, random_state=1, test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/ns/m5pnr0211w91v02hpv22958m0000gn/T/ipykernel_85342/3758305.py:1: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  rfreg.fit(X_train1, y_train1)\n"
     ]
    }
   ],
   "source": [
    "rfreg.fit(X_train1, y_train1)\n",
    "y_pred_rfreg = rfreg.predict(X_val)\n",
    "y_pred_rfreg_r2 = rfreg.predict(X_train1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.028258370633502897"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mean_absolute_error(y_val, y_pred_rfreg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.004692621490617391"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mean_squared_error(y_val, y_pred_rfreg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.06850271155667774"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mean_squared_error(y_val, y_pred_rfreg, squared = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9814439518093024"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#train\n",
    "r2_score(y_train1, y_pred_rfreg_r2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9650050595312505"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#val\n",
    "r2_score(y_val, y_pred_rfreg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hyperparameter Tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "parameters = {'max_depth': [None, 10, 50, 100],\n",
    "              'max_features': ['auto', 'sqrt'],\n",
    "              'min_samples_leaf': [1, 2, 4],\n",
    "              'min_samples_split': [2, 5, 10],\n",
    "              'n_estimators': [100, 300, 500]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "rscv = RandomizedSearchCV(rfreg,  \n",
    "                     parameters,   \n",
    "                     cv=5, \n",
    "                     scoring='neg_mean_absolute_error',\n",
    "                     n_jobs = -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/louispandu/anaconda3/lib/python3.10/site-packages/sklearn/model_selection/_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/Users/louispandu/anaconda3/lib/python3.10/site-packages/sklearn/model_selection/_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/Users/louispandu/anaconda3/lib/python3.10/site-packages/sklearn/model_selection/_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/Users/louispandu/anaconda3/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
      "  warn(\n",
      "/Users/louispandu/anaconda3/lib/python3.10/site-packages/sklearn/model_selection/_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/Users/louispandu/anaconda3/lib/python3.10/site-packages/sklearn/model_selection/_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/Users/louispandu/anaconda3/lib/python3.10/site-packages/sklearn/model_selection/_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/Users/louispandu/anaconda3/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
      "  warn(\n",
      "/Users/louispandu/anaconda3/lib/python3.10/site-packages/sklearn/model_selection/_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/Users/louispandu/anaconda3/lib/python3.10/site-packages/sklearn/model_selection/_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/Users/louispandu/anaconda3/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
      "  warn(\n",
      "/Users/louispandu/anaconda3/lib/python3.10/site-packages/sklearn/model_selection/_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/Users/louispandu/anaconda3/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
      "  warn(\n",
      "/Users/louispandu/anaconda3/lib/python3.10/site-packages/sklearn/model_selection/_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/Users/louispandu/anaconda3/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
      "  warn(\n",
      "/Users/louispandu/anaconda3/lib/python3.10/site-packages/sklearn/model_selection/_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/Users/louispandu/anaconda3/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
      "  warn(\n",
      "/Users/louispandu/anaconda3/lib/python3.10/site-packages/sklearn/model_selection/_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/Users/louispandu/anaconda3/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
      "  warn(\n",
      "/Users/louispandu/anaconda3/lib/python3.10/site-packages/sklearn/model_selection/_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/Users/louispandu/anaconda3/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
      "  warn(\n",
      "/Users/louispandu/anaconda3/lib/python3.10/site-packages/sklearn/model_selection/_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/Users/louispandu/anaconda3/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
      "  warn(\n",
      "/Users/louispandu/anaconda3/lib/python3.10/site-packages/sklearn/model_selection/_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/Users/louispandu/anaconda3/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
      "  warn(\n",
      "/Users/louispandu/anaconda3/lib/python3.10/site-packages/sklearn/model_selection/_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/Users/louispandu/anaconda3/lib/python3.10/site-packages/sklearn/model_selection/_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/Users/louispandu/anaconda3/lib/python3.10/site-packages/sklearn/model_selection/_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/Users/louispandu/anaconda3/lib/python3.10/site-packages/sklearn/model_selection/_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/Users/louispandu/anaconda3/lib/python3.10/site-packages/sklearn/model_selection/_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/Users/louispandu/anaconda3/lib/python3.10/site-packages/sklearn/model_selection/_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/Users/louispandu/anaconda3/lib/python3.10/site-packages/sklearn/model_selection/_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/Users/louispandu/anaconda3/lib/python3.10/site-packages/sklearn/model_selection/_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/Users/louispandu/anaconda3/lib/python3.10/site-packages/sklearn/model_selection/_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/Users/louispandu/anaconda3/lib/python3.10/site-packages/sklearn/model_selection/_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/Users/louispandu/anaconda3/lib/python3.10/site-packages/sklearn/model_selection/_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/Users/louispandu/anaconda3/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
      "  warn(\n",
      "/Users/louispandu/anaconda3/lib/python3.10/site-packages/sklearn/model_selection/_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/Users/louispandu/anaconda3/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
      "  warn(\n",
      "/Users/louispandu/anaconda3/lib/python3.10/site-packages/sklearn/model_selection/_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/Users/louispandu/anaconda3/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
      "  warn(\n",
      "/Users/louispandu/anaconda3/lib/python3.10/site-packages/sklearn/model_selection/_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/Users/louispandu/anaconda3/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
      "  warn(\n",
      "/Users/louispandu/anaconda3/lib/python3.10/site-packages/sklearn/model_selection/_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/Users/louispandu/anaconda3/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
      "  warn(\n",
      "/Users/louispandu/anaconda3/lib/python3.10/site-packages/sklearn/model_selection/_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/Users/louispandu/anaconda3/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
      "  warn(\n",
      "/Users/louispandu/anaconda3/lib/python3.10/site-packages/sklearn/model_selection/_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/Users/louispandu/anaconda3/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
      "  warn(\n",
      "/Users/louispandu/anaconda3/lib/python3.10/site-packages/sklearn/model_selection/_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/Users/louispandu/anaconda3/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
      "  warn(\n",
      "/Users/louispandu/anaconda3/lib/python3.10/site-packages/sklearn/model_selection/_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/Users/louispandu/anaconda3/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
      "  warn(\n",
      "/Users/louispandu/anaconda3/lib/python3.10/site-packages/sklearn/model_selection/_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/Users/louispandu/anaconda3/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
      "  warn(\n",
      "/Users/louispandu/anaconda3/lib/python3.10/site-packages/sklearn/model_selection/_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/Users/louispandu/anaconda3/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
      "  warn(\n",
      "/Users/louispandu/anaconda3/lib/python3.10/site-packages/sklearn/model_selection/_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/Users/louispandu/anaconda3/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
      "  warn(\n",
      "/Users/louispandu/anaconda3/lib/python3.10/site-packages/sklearn/model_selection/_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/Users/louispandu/anaconda3/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
      "  warn(\n",
      "/Users/louispandu/anaconda3/lib/python3.10/site-packages/sklearn/model_selection/_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/Users/louispandu/anaconda3/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
      "  warn(\n",
      "/Users/louispandu/anaconda3/lib/python3.10/site-packages/sklearn/model_selection/_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/Users/louispandu/anaconda3/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
      "  warn(\n",
      "/Users/louispandu/anaconda3/lib/python3.10/site-packages/sklearn/model_selection/_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/Users/louispandu/anaconda3/lib/python3.10/site-packages/sklearn/model_selection/_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/Users/louispandu/anaconda3/lib/python3.10/site-packages/sklearn/model_selection/_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/Users/louispandu/anaconda3/lib/python3.10/site-packages/sklearn/model_selection/_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/Users/louispandu/anaconda3/lib/python3.10/site-packages/sklearn/model_selection/_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/Users/louispandu/anaconda3/lib/python3.10/site-packages/sklearn/model_selection/_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/Users/louispandu/anaconda3/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
      "  warn(\n",
      "/Users/louispandu/anaconda3/lib/python3.10/site-packages/sklearn/model_selection/_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/Users/louispandu/anaconda3/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
      "  warn(\n",
      "/Users/louispandu/anaconda3/lib/python3.10/site-packages/sklearn/model_selection/_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/Users/louispandu/anaconda3/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
      "  warn(\n",
      "/Users/louispandu/anaconda3/lib/python3.10/site-packages/sklearn/model_selection/_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/Users/louispandu/anaconda3/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
      "  warn(\n",
      "/Users/louispandu/anaconda3/lib/python3.10/site-packages/sklearn/model_selection/_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/Users/louispandu/anaconda3/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
      "  warn(\n",
      "/Users/louispandu/anaconda3/lib/python3.10/site-packages/sklearn/model_selection/_search.py:909: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  self.best_estimator_.fit(X, y, **fit_params)\n",
      "/Users/louispandu/anaconda3/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
      "  warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-2 {color: black;background-color: white;}#sk-container-id-2 pre{padding: 0;}#sk-container-id-2 div.sk-toggleable {background-color: white;}#sk-container-id-2 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-2 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-2 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-2 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-2 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-2 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-2 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-2 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-2 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-2 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-2 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-2 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-2 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-2 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-2 div.sk-item {position: relative;z-index: 1;}#sk-container-id-2 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-2 div.sk-item::before, #sk-container-id-2 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-2 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-2 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-2 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-2 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-2 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-2 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-2 div.sk-label-container {text-align: center;}#sk-container-id-2 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-2 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-2\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>RandomizedSearchCV(cv=5, estimator=RandomForestRegressor(), n_jobs=-1,\n",
       "                   param_distributions={&#x27;max_depth&#x27;: [None, 10, 50, 100],\n",
       "                                        &#x27;max_features&#x27;: [&#x27;auto&#x27;, &#x27;sqrt&#x27;],\n",
       "                                        &#x27;min_samples_leaf&#x27;: [1, 2, 4],\n",
       "                                        &#x27;min_samples_split&#x27;: [2, 5, 10],\n",
       "                                        &#x27;n_estimators&#x27;: [100, 300, 500]},\n",
       "                   scoring=&#x27;neg_mean_absolute_error&#x27;)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" ><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">RandomizedSearchCV</label><div class=\"sk-toggleable__content\"><pre>RandomizedSearchCV(cv=5, estimator=RandomForestRegressor(), n_jobs=-1,\n",
       "                   param_distributions={&#x27;max_depth&#x27;: [None, 10, 50, 100],\n",
       "                                        &#x27;max_features&#x27;: [&#x27;auto&#x27;, &#x27;sqrt&#x27;],\n",
       "                                        &#x27;min_samples_leaf&#x27;: [1, 2, 4],\n",
       "                                        &#x27;min_samples_split&#x27;: [2, 5, 10],\n",
       "                                        &#x27;n_estimators&#x27;: [100, 300, 500]},\n",
       "                   scoring=&#x27;neg_mean_absolute_error&#x27;)</pre></div></div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-3\" type=\"checkbox\" ><label for=\"sk-estimator-id-3\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">estimator: RandomForestRegressor</label><div class=\"sk-toggleable__content\"><pre>RandomForestRegressor()</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-4\" type=\"checkbox\" ><label for=\"sk-estimator-id-4\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">RandomForestRegressor</label><div class=\"sk-toggleable__content\"><pre>RandomForestRegressor()</pre></div></div></div></div></div></div></div></div></div></div>"
      ],
      "text/plain": [
       "RandomizedSearchCV(cv=5, estimator=RandomForestRegressor(), n_jobs=-1,\n",
       "                   param_distributions={'max_depth': [None, 10, 50, 100],\n",
       "                                        'max_features': ['auto', 'sqrt'],\n",
       "                                        'min_samples_leaf': [1, 2, 4],\n",
       "                                        'min_samples_split': [2, 5, 10],\n",
       "                                        'n_estimators': [100, 300, 500]},\n",
       "                   scoring='neg_mean_absolute_error')"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rscv.fit(X_train1, y_train1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'n_estimators': 500,\n",
       " 'min_samples_split': 2,\n",
       " 'min_samples_leaf': 2,\n",
       " 'max_features': 'auto',\n",
       " 'max_depth': 100}"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rscv.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['rscv_rf_tfidf_best_params_alpine.pkl']"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "joblib.dump(rscv, \"rscv_rf_tfidf_alpine.pkl\")\n",
    "joblib.dump(rscv.best_params_, \"rscv_rf_tfidf_best_params_alpine.pkl\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "RF (after Hyperparameter Tuning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/ns/m5pnr0211w91v02hpv22958m0000gn/T/ipykernel_85342/50916421.py:2: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  rfreg_ht.fit(X_train1, y_train1)\n",
      "/Users/louispandu/anaconda3/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
      "  warn(\n"
     ]
    }
   ],
   "source": [
    "rfreg_ht = RandomForestRegressor(n_estimators = 500, min_samples_split = 2, min_samples_leaf = 2, max_features = 'auto', max_depth = 100)\n",
    "rfreg_ht.fit(X_train1, y_train1)\n",
    "y_pred_rfreg = rfreg_ht.predict(X_val)\n",
    "y_pred_rfreg_r2 = rfreg_ht.predict(X_train1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.031027618938232665"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mean_absolute_error(y_val, y_pred_rfreg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.005003016622067619"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mean_squared_error(y_val, y_pred_rfreg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0707320056414889"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mean_squared_error(y_val, y_pred_rfreg, squared = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9775785478295905"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#train\n",
    "r2_score(y_train1, y_pred_rfreg_r2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9626903066434224"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#val\n",
    "r2_score(y_val, y_pred_rfreg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Residual plots after Hyperparameter Tuning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Predicting model on the test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_rfreg_test = rfreg_ht.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['y_test_rfreg_tfidf_alpine.pkl']"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "joblib.dump(y_pred_rfreg_test, \"y_pred_rfreg_test_tfidf_alpine.pkl\")\n",
    "joblib.dump(y_test, \"y_test_rfreg_tfidf_alpine.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.031099194426256065"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mean_absolute_error(y_test, y_pred_rfreg_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.004755934572407881"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mean_squared_error(y_test, y_pred_rfreg_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.06896328423449598"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mean_squared_error(y_test, y_pred_rfreg_test, squared = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9644312315311866"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "r2_score(y_test, y_pred_rfreg_test)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Error analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 800x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# assume y_pred is a numpy array and y_true is a pandas dataframe\n",
    "fig, ax = plt.subplots(figsize=(8, 6))\n",
    "\n",
    "column = \"X..Alpha-Pinene\"  # specify the target variable name\n",
    "ax.hist(y_pred_rfreg_test, alpha=0.5, label='y_pred', bins=20)\n",
    "ax.hist(y_test[column], alpha=0.5, label='y_true', bins=20)\n",
    "ax.legend(loc='upper right')\n",
    "ax.set_title(column)\n",
    "\n",
    "plt.show()\n",
    "plt.savefig('error_hist_knn_tfidf_alpine.png')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pearson R"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pearson correlation coefficient: 0.982\n",
      "P-value: 0.000\n"
     ]
    }
   ],
   "source": [
    "corr_coef, p_value = pearsonr(y_pred_rfreg_test.flatten(), y_test.values.ravel())\n",
    "\n",
    "print(f\"Pearson correlation coefficient: {corr_coef:.3f}\")\n",
    "print(f\"P-value: {p_value:.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Axes: >"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "corr_matrix = y_test.corr()\n",
    "sns.heatmap(corr_matrix, annot=True, cmap='coolwarm', center=0)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
