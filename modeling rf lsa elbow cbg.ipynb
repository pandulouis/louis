{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn import preprocessing\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.neural_network import MLPRegressor\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "from sklearn.metrics import r2_score\n",
    "from scipy.stats import pearsonr\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.feature_selection import SelectFromModel\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compiling complete dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_rf = pd.read_csv(\"df_cbg_lsa.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>lsa_0</th>\n",
       "      <th>lsa_1</th>\n",
       "      <th>lsa_2</th>\n",
       "      <th>lsa_3</th>\n",
       "      <th>lsa_4</th>\n",
       "      <th>hybrid</th>\n",
       "      <th>indica</th>\n",
       "      <th>sativa</th>\n",
       "      <th>anxiety</th>\n",
       "      <th>...</th>\n",
       "      <th>sweet</th>\n",
       "      <th>tar</th>\n",
       "      <th>tea</th>\n",
       "      <th>tobacco</th>\n",
       "      <th>tree</th>\n",
       "      <th>tropical</th>\n",
       "      <th>vanilla</th>\n",
       "      <th>violet</th>\n",
       "      <th>woody</th>\n",
       "      <th>X..CBG</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3</td>\n",
       "      <td>0.243491</td>\n",
       "      <td>0.034313</td>\n",
       "      <td>0.080290</td>\n",
       "      <td>-0.165609</td>\n",
       "      <td>0.019773</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.042471</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3</td>\n",
       "      <td>0.243491</td>\n",
       "      <td>0.034313</td>\n",
       "      <td>0.080290</td>\n",
       "      <td>-0.165609</td>\n",
       "      <td>0.019773</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.042471</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>7</td>\n",
       "      <td>0.401841</td>\n",
       "      <td>-0.062527</td>\n",
       "      <td>-0.018128</td>\n",
       "      <td>-0.104475</td>\n",
       "      <td>0.009215</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.042471</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>11</td>\n",
       "      <td>0.260672</td>\n",
       "      <td>-0.019644</td>\n",
       "      <td>0.215790</td>\n",
       "      <td>-0.106098</td>\n",
       "      <td>0.058930</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.042471</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>13</td>\n",
       "      <td>0.276418</td>\n",
       "      <td>-0.133986</td>\n",
       "      <td>0.116293</td>\n",
       "      <td>0.073694</td>\n",
       "      <td>0.041143</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.042471</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>74995</th>\n",
       "      <td>42972</td>\n",
       "      <td>0.181714</td>\n",
       "      <td>-0.045560</td>\n",
       "      <td>-0.055692</td>\n",
       "      <td>0.015649</td>\n",
       "      <td>-0.045585</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.335907</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>74996</th>\n",
       "      <td>42973</td>\n",
       "      <td>0.055494</td>\n",
       "      <td>0.003622</td>\n",
       "      <td>-0.050252</td>\n",
       "      <td>-0.024795</td>\n",
       "      <td>-0.031141</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.335907</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>74997</th>\n",
       "      <td>42975</td>\n",
       "      <td>0.324915</td>\n",
       "      <td>0.131823</td>\n",
       "      <td>-0.099424</td>\n",
       "      <td>0.065491</td>\n",
       "      <td>0.038437</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.335907</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>74998</th>\n",
       "      <td>42975</td>\n",
       "      <td>0.324915</td>\n",
       "      <td>0.131823</td>\n",
       "      <td>-0.099424</td>\n",
       "      <td>0.065491</td>\n",
       "      <td>0.038437</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.335907</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>74999</th>\n",
       "      <td>42976</td>\n",
       "      <td>0.270141</td>\n",
       "      <td>-0.004631</td>\n",
       "      <td>-0.151272</td>\n",
       "      <td>0.035538</td>\n",
       "      <td>0.083641</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.335907</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>75000 rows × 88 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       index     lsa_0     lsa_1     lsa_2     lsa_3     lsa_4  hybrid  \\\n",
       "0          3  0.243491  0.034313  0.080290 -0.165609  0.019773       1   \n",
       "1          3  0.243491  0.034313  0.080290 -0.165609  0.019773       1   \n",
       "2          7  0.401841 -0.062527 -0.018128 -0.104475  0.009215       1   \n",
       "3         11  0.260672 -0.019644  0.215790 -0.106098  0.058930       1   \n",
       "4         13  0.276418 -0.133986  0.116293  0.073694  0.041143       1   \n",
       "...      ...       ...       ...       ...       ...       ...     ...   \n",
       "74995  42972  0.181714 -0.045560 -0.055692  0.015649 -0.045585       0   \n",
       "74996  42973  0.055494  0.003622 -0.050252 -0.024795 -0.031141       0   \n",
       "74997  42975  0.324915  0.131823 -0.099424  0.065491  0.038437       0   \n",
       "74998  42975  0.324915  0.131823 -0.099424  0.065491  0.038437       0   \n",
       "74999  42976  0.270141 -0.004631 -0.151272  0.035538  0.083641       0   \n",
       "\n",
       "       indica  sativa  anxiety  ...  sweet  tar  tea  tobacco  tree  tropical  \\\n",
       "0           0       0        0  ...      0    1    0        0     0         0   \n",
       "1           0       0        0  ...      0    1    0        0     0         0   \n",
       "2           0       0        0  ...      0    1    0        0     0         0   \n",
       "3           0       0        0  ...      1    0    0        0     0         0   \n",
       "4           0       0        0  ...      0    0    0        0     0         0   \n",
       "...       ...     ...      ...  ...    ...  ...  ...      ...   ...       ...   \n",
       "74995       1       0        0  ...      0    0    0        0     0         0   \n",
       "74996       1       0        0  ...      0    0    0        0     0         0   \n",
       "74997       1       0        0  ...      0    0    0        0     0         0   \n",
       "74998       1       0        0  ...      0    0    0        0     0         0   \n",
       "74999       1       0        0  ...      1    1    1        1     1         1   \n",
       "\n",
       "       vanilla  violet  woody    X..CBG  \n",
       "0            0       0      0  0.042471  \n",
       "1            0       0      0  0.042471  \n",
       "2            1       1      1  0.042471  \n",
       "3            0       0      0  0.042471  \n",
       "4            0       0      0  0.042471  \n",
       "...        ...     ...    ...       ...  \n",
       "74995        0       0      0  0.335907  \n",
       "74996        0       0      0  0.335907  \n",
       "74997        0       0      0  0.335907  \n",
       "74998        0       0      0  0.335907  \n",
       "74999        1       1      1  0.335907  \n",
       "\n",
       "[75000 rows x 88 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_rf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['index',\n",
       " 'lsa_0',\n",
       " 'lsa_1',\n",
       " 'lsa_2',\n",
       " 'lsa_3',\n",
       " 'lsa_4',\n",
       " 'hybrid',\n",
       " 'indica',\n",
       " 'sativa',\n",
       " 'anxiety',\n",
       " 'anxious',\n",
       " 'aroused',\n",
       " 'arthritis',\n",
       " 'creative',\n",
       " 'depression',\n",
       " 'dizzy',\n",
       " 'dry eyes',\n",
       " 'dry mouth',\n",
       " 'energetic',\n",
       " 'epilepsy',\n",
       " 'euphoric',\n",
       " 'eye pressure',\n",
       " 'fatigue',\n",
       " 'focused',\n",
       " 'giggly',\n",
       " 'happy',\n",
       " 'headache',\n",
       " 'hungry',\n",
       " 'migraines',\n",
       " 'pain',\n",
       " 'paranoid',\n",
       " 'relaxed',\n",
       " 'seizures',\n",
       " 'sleepy',\n",
       " 'spasticity',\n",
       " 'stress',\n",
       " 'talkative',\n",
       " 'tingly',\n",
       " 'uplifted',\n",
       " 'ammonia',\n",
       " 'apple',\n",
       " 'apricot',\n",
       " 'berry',\n",
       " 'blue cheese',\n",
       " 'blueberry',\n",
       " 'butter',\n",
       " 'cheese',\n",
       " 'chemical',\n",
       " 'chestnut',\n",
       " 'citrus',\n",
       " 'coffee',\n",
       " 'diesel',\n",
       " 'earthy',\n",
       " 'flowery',\n",
       " 'fruit',\n",
       " 'grape',\n",
       " 'grapefruit',\n",
       " 'honey',\n",
       " 'lavender',\n",
       " 'lemon',\n",
       " 'lime',\n",
       " 'mango',\n",
       " 'menthol',\n",
       " 'mint',\n",
       " 'nutty',\n",
       " 'orange',\n",
       " 'peach',\n",
       " 'pear',\n",
       " 'pepper',\n",
       " 'pine',\n",
       " 'pineapple',\n",
       " 'plum',\n",
       " 'pungent',\n",
       " 'rose',\n",
       " 'sage',\n",
       " 'skunk',\n",
       " 'spicy/herbal',\n",
       " 'strawberry',\n",
       " 'sweet',\n",
       " 'tar',\n",
       " 'tea',\n",
       " 'tobacco',\n",
       " 'tree',\n",
       " 'tropical',\n",
       " 'vanilla',\n",
       " 'violet',\n",
       " 'woody',\n",
       " 'X..CBG']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_rf.columns.to_list()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Splitting dependent and independent variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df_rf.drop(['index', 'X..CBG'], axis = 1)\n",
    "y = df_rf[['X..CBG']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plotting histograms on target variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.04247104],\n",
       "       [0.04247104],\n",
       "       [0.04247104],\n",
       "       ...,\n",
       "       [0.33590734],\n",
       "       [0.33590734],\n",
       "       [0.33590734]])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_array = y.to_numpy()\n",
    "y_array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:ylabel='Count'>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "sns.histplot(y, bins = 10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train test split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=1, test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train1, X_val, y_train1, y_val = train_test_split(X_train, y_train, random_state=1, test_size=0.25)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "RF modeling (before Feature selection and Hyperparameter Tuning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/y1/pjvjlkjn5gl846rnyzr53p340000gn/T/ipykernel_13572/119766249.py:2: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  rfreg.fit(X_train1, y_train1)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;background-color: white;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>RandomForestRegressor(n_jobs=-1)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">RandomForestRegressor</label><div class=\"sk-toggleable__content\"><pre>RandomForestRegressor(n_jobs=-1)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "RandomForestRegressor(n_jobs=-1)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rfreg = RandomForestRegressor(n_jobs = -1)\n",
    "rfreg.fit(X_train1, y_train1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_rfreg = rfreg.predict(X_val)\n",
    "y_pred_rfreg_r2 = rfreg.predict(X_train1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.02591102119341499"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mean_absolute_error(y_val, y_pred_rfreg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.004270100429235825"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mean_squared_error(y_val, y_pred_rfreg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.06534600545737915"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mean_squared_error(y_val, y_pred_rfreg, squared = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9893017444447618"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#train\n",
    "r2_score(y_train1, y_pred_rfreg_r2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9408728580908643"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#val\n",
    "r2_score(y_val, y_pred_rfreg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Residual plots for each target variable"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Feature Selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_feat = pd.DataFrame({\n",
    "    \"features\": X_train1.columns,\n",
    "    \"score\": rfreg.feature_importances_\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>features</th>\n",
       "      <th>score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>lsa_0</td>\n",
       "      <td>0.086070</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>lsa_1</td>\n",
       "      <td>0.051088</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>lsa_2</td>\n",
       "      <td>0.046742</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>lsa_3</td>\n",
       "      <td>0.074858</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>lsa_4</td>\n",
       "      <td>0.045160</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>81</th>\n",
       "      <td>tree</td>\n",
       "      <td>0.001445</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>82</th>\n",
       "      <td>tropical</td>\n",
       "      <td>0.010783</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>83</th>\n",
       "      <td>vanilla</td>\n",
       "      <td>0.004101</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>84</th>\n",
       "      <td>violet</td>\n",
       "      <td>0.001420</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>85</th>\n",
       "      <td>woody</td>\n",
       "      <td>0.003635</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>86 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    features     score\n",
       "0      lsa_0  0.086070\n",
       "1      lsa_1  0.051088\n",
       "2      lsa_2  0.046742\n",
       "3      lsa_3  0.074858\n",
       "4      lsa_4  0.045160\n",
       "..       ...       ...\n",
       "81      tree  0.001445\n",
       "82  tropical  0.010783\n",
       "83   vanilla  0.004101\n",
       "84    violet  0.001420\n",
       "85     woody  0.003635\n",
       "\n",
       "[86 rows x 2 columns]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_feat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_feat_ranked = df_feat.sort_values(\"score\", ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>features</th>\n",
       "      <th>score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>berry</td>\n",
       "      <td>0.208172</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>76</th>\n",
       "      <td>strawberry</td>\n",
       "      <td>0.106375</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>indica</td>\n",
       "      <td>0.086147</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>lsa_0</td>\n",
       "      <td>0.086070</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>lsa_3</td>\n",
       "      <td>0.074858</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>lsa_1</td>\n",
       "      <td>0.051088</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>lsa_2</td>\n",
       "      <td>0.046742</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>lsa_4</td>\n",
       "      <td>0.045160</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>sativa</td>\n",
       "      <td>0.039672</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>blueberry</td>\n",
       "      <td>0.023507</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54</th>\n",
       "      <td>grape</td>\n",
       "      <td>0.013984</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50</th>\n",
       "      <td>diesel</td>\n",
       "      <td>0.012958</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>58</th>\n",
       "      <td>lemon</td>\n",
       "      <td>0.012290</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>hybrid</td>\n",
       "      <td>0.010916</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>82</th>\n",
       "      <td>tropical</td>\n",
       "      <td>0.010783</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>focused</td>\n",
       "      <td>0.010756</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>64</th>\n",
       "      <td>orange</td>\n",
       "      <td>0.009914</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>cheese</td>\n",
       "      <td>0.008967</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59</th>\n",
       "      <td>lime</td>\n",
       "      <td>0.007843</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>77</th>\n",
       "      <td>sweet</td>\n",
       "      <td>0.007797</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>citrus</td>\n",
       "      <td>0.007068</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>74</th>\n",
       "      <td>skunk</td>\n",
       "      <td>0.006595</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>relaxed</td>\n",
       "      <td>0.006364</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51</th>\n",
       "      <td>earthy</td>\n",
       "      <td>0.005815</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>hungry</td>\n",
       "      <td>0.005527</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>uplifted</td>\n",
       "      <td>0.005412</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>68</th>\n",
       "      <td>pine</td>\n",
       "      <td>0.004893</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>dry mouth</td>\n",
       "      <td>0.004414</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>talkative</td>\n",
       "      <td>0.004218</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>happy</td>\n",
       "      <td>0.004162</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>83</th>\n",
       "      <td>vanilla</td>\n",
       "      <td>0.004101</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>sleepy</td>\n",
       "      <td>0.003915</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>55</th>\n",
       "      <td>grapefruit</td>\n",
       "      <td>0.003866</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>euphoric</td>\n",
       "      <td>0.003765</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>85</th>\n",
       "      <td>woody</td>\n",
       "      <td>0.003635</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>creative</td>\n",
       "      <td>0.003540</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>giggly</td>\n",
       "      <td>0.003286</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>aroused</td>\n",
       "      <td>0.003092</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>71</th>\n",
       "      <td>pungent</td>\n",
       "      <td>0.003027</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>energetic</td>\n",
       "      <td>0.002815</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>80</th>\n",
       "      <td>tobacco</td>\n",
       "      <td>0.002652</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>tingly</td>\n",
       "      <td>0.002609</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>dry eyes</td>\n",
       "      <td>0.002588</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52</th>\n",
       "      <td>flowery</td>\n",
       "      <td>0.002583</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>62</th>\n",
       "      <td>mint</td>\n",
       "      <td>0.002415</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>paranoid</td>\n",
       "      <td>0.002294</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53</th>\n",
       "      <td>fruit</td>\n",
       "      <td>0.001574</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>81</th>\n",
       "      <td>tree</td>\n",
       "      <td>0.001445</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>84</th>\n",
       "      <td>violet</td>\n",
       "      <td>0.001420</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>dizzy</td>\n",
       "      <td>0.001329</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>63</th>\n",
       "      <td>nutty</td>\n",
       "      <td>0.001290</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>blue cheese</td>\n",
       "      <td>0.001263</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>apricot</td>\n",
       "      <td>0.001192</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>70</th>\n",
       "      <td>plum</td>\n",
       "      <td>0.001081</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>67</th>\n",
       "      <td>pepper</td>\n",
       "      <td>0.001060</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>73</th>\n",
       "      <td>sage</td>\n",
       "      <td>0.001053</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>chemical</td>\n",
       "      <td>0.001008</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>headache</td>\n",
       "      <td>0.000992</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>57</th>\n",
       "      <td>lavender</td>\n",
       "      <td>0.000936</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>anxious</td>\n",
       "      <td>0.000935</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75</th>\n",
       "      <td>spicy/herbal</td>\n",
       "      <td>0.000770</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>72</th>\n",
       "      <td>rose</td>\n",
       "      <td>0.000704</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>60</th>\n",
       "      <td>mango</td>\n",
       "      <td>0.000402</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>coffee</td>\n",
       "      <td>0.000393</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>69</th>\n",
       "      <td>pineapple</td>\n",
       "      <td>0.000385</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>56</th>\n",
       "      <td>honey</td>\n",
       "      <td>0.000300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>ammonia</td>\n",
       "      <td>0.000289</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>79</th>\n",
       "      <td>tea</td>\n",
       "      <td>0.000269</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>61</th>\n",
       "      <td>menthol</td>\n",
       "      <td>0.000233</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>apple</td>\n",
       "      <td>0.000208</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>butter</td>\n",
       "      <td>0.000176</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>chestnut</td>\n",
       "      <td>0.000149</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>migraines</td>\n",
       "      <td>0.000119</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>65</th>\n",
       "      <td>peach</td>\n",
       "      <td>0.000110</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>depression</td>\n",
       "      <td>0.000083</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>anxiety</td>\n",
       "      <td>0.000074</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>78</th>\n",
       "      <td>tar</td>\n",
       "      <td>0.000063</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>66</th>\n",
       "      <td>pear</td>\n",
       "      <td>0.000039</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>spasticity</td>\n",
       "      <td>0.000003</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>arthritis</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>seizures</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>eye pressure</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>pain</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>epilepsy</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>fatigue</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>stress</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        features     score\n",
       "41         berry  0.208172\n",
       "76    strawberry  0.106375\n",
       "6         indica  0.086147\n",
       "0          lsa_0  0.086070\n",
       "3          lsa_3  0.074858\n",
       "1          lsa_1  0.051088\n",
       "2          lsa_2  0.046742\n",
       "4          lsa_4  0.045160\n",
       "7         sativa  0.039672\n",
       "43     blueberry  0.023507\n",
       "54         grape  0.013984\n",
       "50        diesel  0.012958\n",
       "58         lemon  0.012290\n",
       "5         hybrid  0.010916\n",
       "82      tropical  0.010783\n",
       "22       focused  0.010756\n",
       "64        orange  0.009914\n",
       "45        cheese  0.008967\n",
       "59          lime  0.007843\n",
       "77         sweet  0.007797\n",
       "48        citrus  0.007068\n",
       "74         skunk  0.006595\n",
       "30       relaxed  0.006364\n",
       "51        earthy  0.005815\n",
       "26        hungry  0.005527\n",
       "37      uplifted  0.005412\n",
       "68          pine  0.004893\n",
       "16     dry mouth  0.004414\n",
       "35     talkative  0.004218\n",
       "24         happy  0.004162\n",
       "83       vanilla  0.004101\n",
       "32        sleepy  0.003915\n",
       "55    grapefruit  0.003866\n",
       "19      euphoric  0.003765\n",
       "85         woody  0.003635\n",
       "12      creative  0.003540\n",
       "23        giggly  0.003286\n",
       "10       aroused  0.003092\n",
       "71       pungent  0.003027\n",
       "17     energetic  0.002815\n",
       "80       tobacco  0.002652\n",
       "36        tingly  0.002609\n",
       "15      dry eyes  0.002588\n",
       "52       flowery  0.002583\n",
       "62          mint  0.002415\n",
       "29      paranoid  0.002294\n",
       "53         fruit  0.001574\n",
       "81          tree  0.001445\n",
       "84        violet  0.001420\n",
       "14         dizzy  0.001329\n",
       "63         nutty  0.001290\n",
       "42   blue cheese  0.001263\n",
       "40       apricot  0.001192\n",
       "70          plum  0.001081\n",
       "67        pepper  0.001060\n",
       "73          sage  0.001053\n",
       "46      chemical  0.001008\n",
       "25      headache  0.000992\n",
       "57      lavender  0.000936\n",
       "9        anxious  0.000935\n",
       "75  spicy/herbal  0.000770\n",
       "72          rose  0.000704\n",
       "60         mango  0.000402\n",
       "49        coffee  0.000393\n",
       "69     pineapple  0.000385\n",
       "56         honey  0.000300\n",
       "38       ammonia  0.000289\n",
       "79           tea  0.000269\n",
       "61       menthol  0.000233\n",
       "39         apple  0.000208\n",
       "44        butter  0.000176\n",
       "47      chestnut  0.000149\n",
       "27     migraines  0.000119\n",
       "65         peach  0.000110\n",
       "13    depression  0.000083\n",
       "8        anxiety  0.000074\n",
       "78           tar  0.000063\n",
       "66          pear  0.000039\n",
       "33    spasticity  0.000003\n",
       "11     arthritis  0.000000\n",
       "31      seizures  0.000000\n",
       "20  eye pressure  0.000000\n",
       "28          pain  0.000000\n",
       "18      epilepsy  0.000000\n",
       "21       fatigue  0.000000\n",
       "34        stress  0.000000"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.set_option('display.max_rows', df_feat_ranked.shape[0]+1)\n",
    "df_feat_ranked"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/andalanputra/opt/anaconda3/lib/python3.9/site-packages/sklearn/feature_selection/_from_model.py:357: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  self.estimator_.fit(X, y, **fit_params)\n"
     ]
    }
   ],
   "source": [
    "selector = SelectFromModel(rfreg).fit(X_train1, y_train1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([8.58182138e-02, 5.11167061e-02, 4.67329524e-02, 7.59930836e-02,\n",
       "       4.43731703e-02, 1.17643379e-02, 8.58040825e-02, 3.91530579e-02,\n",
       "       6.48769838e-05, 9.21470847e-04, 3.13181273e-03, 0.00000000e+00,\n",
       "       3.91534530e-03, 7.60537446e-05, 1.27950374e-03, 2.66155222e-03,\n",
       "       4.43950816e-03, 2.86572520e-03, 0.00000000e+00, 3.75580038e-03,\n",
       "       0.00000000e+00, 0.00000000e+00, 9.98716835e-03, 3.36110387e-03,\n",
       "       4.35413181e-03, 9.56402014e-04, 5.37157466e-03, 7.52796806e-05,\n",
       "       0.00000000e+00, 2.50793221e-03, 6.01455593e-03, 0.00000000e+00,\n",
       "       3.72736298e-03, 3.25243766e-06, 0.00000000e+00, 4.07014837e-03,\n",
       "       2.59693873e-03, 5.43531126e-03, 3.10353791e-04, 2.23800189e-04,\n",
       "       1.34609454e-03, 2.07802982e-01, 1.33060948e-03, 2.29065214e-02,\n",
       "       1.32645692e-04, 8.91327867e-03, 1.03297855e-03, 1.38756954e-04,\n",
       "       6.92160228e-03, 3.57163042e-04, 1.24846389e-02, 6.06906080e-03,\n",
       "       2.59401130e-03, 1.69631248e-03, 1.36897604e-02, 4.04938563e-03,\n",
       "       2.90816185e-04, 7.71845468e-04, 1.25318908e-02, 7.92088038e-03,\n",
       "       4.80908967e-04, 2.23928248e-04, 2.54856961e-03, 1.16426671e-03,\n",
       "       1.01035888e-02, 1.45756531e-04, 4.55141037e-05, 1.02891405e-03,\n",
       "       4.82625125e-03, 4.20586268e-04, 1.04343427e-03, 2.94765155e-03,\n",
       "       8.82739579e-04, 1.08834131e-03, 6.62639892e-03, 7.58643999e-04,\n",
       "       1.05947240e-01, 7.93696201e-03, 7.82655062e-05, 3.52153690e-04,\n",
       "       2.51826671e-03, 1.49139704e-03, 1.18201058e-02, 4.11787600e-03,\n",
       "       1.62704338e-03, 3.93139072e-03])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "selector.estimator_.feature_importances_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.011627906976744184"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "selector.threshold_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "mask = selector.get_support()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ True,  True,  True,  True,  True,  True,  True,  True, False,\n",
       "       False, False, False, False, False, False, False, False, False,\n",
       "       False, False, False, False, False, False, False, False, False,\n",
       "       False, False, False, False, False, False, False, False, False,\n",
       "       False, False, False, False, False,  True, False,  True, False,\n",
       "       False, False, False, False, False,  True, False, False, False,\n",
       "        True, False, False, False,  True, False, False, False, False,\n",
       "       False, False, False, False, False, False, False, False, False,\n",
       "       False, False, False, False,  True, False, False, False, False,\n",
       "       False,  True, False, False, False])"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "selected_features = X.columns[mask]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>lsa_0</th>\n",
       "      <th>lsa_1</th>\n",
       "      <th>lsa_2</th>\n",
       "      <th>lsa_3</th>\n",
       "      <th>lsa_4</th>\n",
       "      <th>hybrid</th>\n",
       "      <th>indica</th>\n",
       "      <th>sativa</th>\n",
       "      <th>berry</th>\n",
       "      <th>blueberry</th>\n",
       "      <th>diesel</th>\n",
       "      <th>grape</th>\n",
       "      <th>lemon</th>\n",
       "      <th>strawberry</th>\n",
       "      <th>tropical</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.243491</td>\n",
       "      <td>0.034313</td>\n",
       "      <td>0.080290</td>\n",
       "      <td>-0.165609</td>\n",
       "      <td>0.019773</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.243491</td>\n",
       "      <td>0.034313</td>\n",
       "      <td>0.080290</td>\n",
       "      <td>-0.165609</td>\n",
       "      <td>0.019773</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.401841</td>\n",
       "      <td>-0.062527</td>\n",
       "      <td>-0.018128</td>\n",
       "      <td>-0.104475</td>\n",
       "      <td>0.009215</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.260672</td>\n",
       "      <td>-0.019644</td>\n",
       "      <td>0.215790</td>\n",
       "      <td>-0.106098</td>\n",
       "      <td>0.058930</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.276418</td>\n",
       "      <td>-0.133986</td>\n",
       "      <td>0.116293</td>\n",
       "      <td>0.073694</td>\n",
       "      <td>0.041143</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>74995</th>\n",
       "      <td>0.181714</td>\n",
       "      <td>-0.045560</td>\n",
       "      <td>-0.055692</td>\n",
       "      <td>0.015649</td>\n",
       "      <td>-0.045585</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>74996</th>\n",
       "      <td>0.055494</td>\n",
       "      <td>0.003622</td>\n",
       "      <td>-0.050252</td>\n",
       "      <td>-0.024795</td>\n",
       "      <td>-0.031141</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>74997</th>\n",
       "      <td>0.324915</td>\n",
       "      <td>0.131823</td>\n",
       "      <td>-0.099424</td>\n",
       "      <td>0.065491</td>\n",
       "      <td>0.038437</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>74998</th>\n",
       "      <td>0.324915</td>\n",
       "      <td>0.131823</td>\n",
       "      <td>-0.099424</td>\n",
       "      <td>0.065491</td>\n",
       "      <td>0.038437</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>74999</th>\n",
       "      <td>0.270141</td>\n",
       "      <td>-0.004631</td>\n",
       "      <td>-0.151272</td>\n",
       "      <td>0.035538</td>\n",
       "      <td>0.083641</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>75000 rows × 15 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          lsa_0     lsa_1     lsa_2     lsa_3     lsa_4  hybrid  indica  \\\n",
       "0      0.243491  0.034313  0.080290 -0.165609  0.019773       1       0   \n",
       "1      0.243491  0.034313  0.080290 -0.165609  0.019773       1       0   \n",
       "2      0.401841 -0.062527 -0.018128 -0.104475  0.009215       1       0   \n",
       "3      0.260672 -0.019644  0.215790 -0.106098  0.058930       1       0   \n",
       "4      0.276418 -0.133986  0.116293  0.073694  0.041143       1       0   \n",
       "...         ...       ...       ...       ...       ...     ...     ...   \n",
       "74995  0.181714 -0.045560 -0.055692  0.015649 -0.045585       0       1   \n",
       "74996  0.055494  0.003622 -0.050252 -0.024795 -0.031141       0       1   \n",
       "74997  0.324915  0.131823 -0.099424  0.065491  0.038437       0       1   \n",
       "74998  0.324915  0.131823 -0.099424  0.065491  0.038437       0       1   \n",
       "74999  0.270141 -0.004631 -0.151272  0.035538  0.083641       0       1   \n",
       "\n",
       "       sativa  berry  blueberry  diesel  grape  lemon  strawberry  tropical  \n",
       "0           0      0          0       0      1      0           0         0  \n",
       "1           0      0          0       0      1      0           0         0  \n",
       "2           0      0          0       0      0      0           0         0  \n",
       "3           0      0          0       0      0      0           0         0  \n",
       "4           0      0          0       0      0      0           0         0  \n",
       "...       ...    ...        ...     ...    ...    ...         ...       ...  \n",
       "74995       0      0          0       0      0      0           0         0  \n",
       "74996       0      0          0       0      0      0           0         0  \n",
       "74997       0      0          0       0      0      0           0         0  \n",
       "74998       0      0          0       0      0      0           0         0  \n",
       "74999       0      1          1       1      1      1           1         1  \n",
       "\n",
       "[75000 rows x 15 columns]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "selected_X = df_rf[selected_features]\n",
    "selected_X"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train test split (after Feature Selection)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['selected_X_rf_lsa_elbow_cbg.pkl']"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import joblib\n",
    "\n",
    "joblib.dump(selector, \"selector_rf_lsa_elbow_cbg.pkl\")\n",
    "joblib.dump(selected_X, \"selected_X_rf_lsa_elbow_cbg.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(selected_X, y, random_state=1, test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train1, X_val, y_train1, y_val = train_test_split(X_train, y_train, random_state=1, test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/y1/pjvjlkjn5gl846rnyzr53p340000gn/T/ipykernel_13572/3758305.py:1: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  rfreg.fit(X_train1, y_train1)\n"
     ]
    }
   ],
   "source": [
    "rfreg.fit(X_train1, y_train1)\n",
    "y_pred_rfreg = rfreg.predict(X_val)\n",
    "y_pred_rfreg_r2 = rfreg.predict(X_train1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.02766457254357544"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mean_absolute_error(y_val, y_pred_rfreg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.004609821684973624"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mean_squared_error(y_val, y_pred_rfreg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.06789566764509812"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mean_squared_error(y_val, y_pred_rfreg, squared = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9832789787926216"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#train\n",
    "r2_score(y_train1, y_pred_rfreg_r2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9359968613062435"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#val\n",
    "r2_score(y_val, y_pred_rfreg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hyperparameter Tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "parameters = { 'max_depth': [None, 10, 50, 100],\n",
    "              'max_features': ['auto', 'sqrt'],\n",
    "              'min_samples_leaf': [1, 2, 4],\n",
    "              'min_samples_split': [2, 5, 10],\n",
    "              'n_estimators': [100, 300, 500]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "rscv = RandomizedSearchCV(rfreg,  \n",
    "                     parameters,   \n",
    "                     cv=5, \n",
    "                     scoring='neg_mean_absolute_error',\n",
    "                     n_jobs= -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/andalanputra/opt/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/Users/andalanputra/opt/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/Users/andalanputra/opt/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/Users/andalanputra/opt/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/Users/andalanputra/opt/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/Users/andalanputra/opt/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/Users/andalanputra/opt/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/Users/andalanputra/opt/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/Users/andalanputra/opt/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/Users/andalanputra/opt/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/Users/andalanputra/opt/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/Users/andalanputra/opt/anaconda3/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
      "  warn(\n",
      "/Users/andalanputra/opt/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/Users/andalanputra/opt/anaconda3/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
      "  warn(\n",
      "/Users/andalanputra/opt/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/Users/andalanputra/opt/anaconda3/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
      "  warn(\n",
      "/Users/andalanputra/opt/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/Users/andalanputra/opt/anaconda3/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
      "  warn(\n",
      "/Users/andalanputra/opt/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/Users/andalanputra/opt/anaconda3/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
      "  warn(\n",
      "/Users/andalanputra/opt/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/Users/andalanputra/opt/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/Users/andalanputra/opt/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/Users/andalanputra/opt/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/Users/andalanputra/opt/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/Users/andalanputra/opt/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/Users/andalanputra/opt/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/Users/andalanputra/opt/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/Users/andalanputra/opt/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/Users/andalanputra/opt/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/Users/andalanputra/opt/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/Users/andalanputra/opt/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/Users/andalanputra/opt/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/Users/andalanputra/opt/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/Users/andalanputra/opt/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/Users/andalanputra/opt/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/Users/andalanputra/opt/anaconda3/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
      "  warn(\n",
      "/Users/andalanputra/opt/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/Users/andalanputra/opt/anaconda3/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
      "  warn(\n",
      "/Users/andalanputra/opt/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/Users/andalanputra/opt/anaconda3/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
      "  warn(\n",
      "/Users/andalanputra/opt/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/Users/andalanputra/opt/anaconda3/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
      "  warn(\n",
      "/Users/andalanputra/opt/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/Users/andalanputra/opt/anaconda3/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
      "  warn(\n",
      "/Users/andalanputra/opt/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/Users/andalanputra/opt/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/Users/andalanputra/opt/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/Users/andalanputra/opt/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/Users/andalanputra/opt/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/Users/andalanputra/opt/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/Users/andalanputra/opt/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/Users/andalanputra/opt/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/Users/andalanputra/opt/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/Users/andalanputra/opt/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/Users/andalanputra/opt/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/Users/andalanputra/opt/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/Users/andalanputra/opt/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/Users/andalanputra/opt/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/Users/andalanputra/opt/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/Users/andalanputra/opt/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_search.py:909: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  self.best_estimator_.fit(X, y, **fit_params)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-2 {color: black;background-color: white;}#sk-container-id-2 pre{padding: 0;}#sk-container-id-2 div.sk-toggleable {background-color: white;}#sk-container-id-2 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-2 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-2 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-2 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-2 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-2 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-2 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-2 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-2 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-2 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-2 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-2 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-2 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-2 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-2 div.sk-item {position: relative;z-index: 1;}#sk-container-id-2 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-2 div.sk-item::before, #sk-container-id-2 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-2 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-2 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-2 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-2 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-2 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-2 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-2 div.sk-label-container {text-align: center;}#sk-container-id-2 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-2 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-2\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>RandomizedSearchCV(cv=5, estimator=RandomForestRegressor(n_jobs=-1), n_jobs=-1,\n",
       "                   param_distributions={&#x27;max_depth&#x27;: [None, 10, 50, 100],\n",
       "                                        &#x27;max_features&#x27;: [&#x27;auto&#x27;, &#x27;sqrt&#x27;],\n",
       "                                        &#x27;min_samples_leaf&#x27;: [1, 2, 4],\n",
       "                                        &#x27;min_samples_split&#x27;: [2, 5, 10],\n",
       "                                        &#x27;n_estimators&#x27;: [100, 300, 500]},\n",
       "                   scoring=&#x27;neg_mean_absolute_error&#x27;)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" ><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">RandomizedSearchCV</label><div class=\"sk-toggleable__content\"><pre>RandomizedSearchCV(cv=5, estimator=RandomForestRegressor(n_jobs=-1), n_jobs=-1,\n",
       "                   param_distributions={&#x27;max_depth&#x27;: [None, 10, 50, 100],\n",
       "                                        &#x27;max_features&#x27;: [&#x27;auto&#x27;, &#x27;sqrt&#x27;],\n",
       "                                        &#x27;min_samples_leaf&#x27;: [1, 2, 4],\n",
       "                                        &#x27;min_samples_split&#x27;: [2, 5, 10],\n",
       "                                        &#x27;n_estimators&#x27;: [100, 300, 500]},\n",
       "                   scoring=&#x27;neg_mean_absolute_error&#x27;)</pre></div></div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-3\" type=\"checkbox\" ><label for=\"sk-estimator-id-3\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">estimator: RandomForestRegressor</label><div class=\"sk-toggleable__content\"><pre>RandomForestRegressor(n_jobs=-1)</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-4\" type=\"checkbox\" ><label for=\"sk-estimator-id-4\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">RandomForestRegressor</label><div class=\"sk-toggleable__content\"><pre>RandomForestRegressor(n_jobs=-1)</pre></div></div></div></div></div></div></div></div></div></div>"
      ],
      "text/plain": [
       "RandomizedSearchCV(cv=5, estimator=RandomForestRegressor(n_jobs=-1), n_jobs=-1,\n",
       "                   param_distributions={'max_depth': [None, 10, 50, 100],\n",
       "                                        'max_features': ['auto', 'sqrt'],\n",
       "                                        'min_samples_leaf': [1, 2, 4],\n",
       "                                        'min_samples_split': [2, 5, 10],\n",
       "                                        'n_estimators': [100, 300, 500]},\n",
       "                   scoring='neg_mean_absolute_error')"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rscv.fit(X_train1, y_train1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'n_estimators': 300,\n",
       " 'min_samples_split': 5,\n",
       " 'min_samples_leaf': 1,\n",
       " 'max_features': 'sqrt',\n",
       " 'max_depth': 100}"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rscv.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['rscv_rf_lsa_elbow_best_params_cbg.pkl']"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "joblib.dump(rscv, \"rscv_rf_lsa_elbow_cbg.pkl\")\n",
    "joblib.dump(rscv.best_params_, \"rscv_rf_lsa_elbow_best_params_cbg.pkl\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "RF (after Hyperparameter Tuning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/y1/pjvjlkjn5gl846rnyzr53p340000gn/T/ipykernel_13572/387795715.py:2: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  rfreg_ht.fit(X_train1, y_train1)\n"
     ]
    }
   ],
   "source": [
    "rfreg_ht = RandomForestRegressor(n_estimators = 300, min_samples_split = 5, max_features = 'sqrt', min_samples_leaf = 1, max_depth = 100)\n",
    "rfreg_ht.fit(X_train1, y_train1)\n",
    "y_pred_rfreg = rfreg_ht.predict(X_val)\n",
    "y_pred_rfreg_r2 = rfreg_ht.predict(X_train1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.03151080194021649"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mean_absolute_error(y_val, y_pred_rfreg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.004663857107111929"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mean_squared_error(y_val, y_pred_rfreg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.06829243814004542"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mean_squared_error(y_val, y_pred_rfreg, squared = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9768724774616642"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#train\n",
    "r2_score(y_train1, y_pred_rfreg_r2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9352466291164027"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#val\n",
    "r2_score(y_val, y_pred_rfreg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Residual plots after Hyperparameter Tuning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Predicting model on the test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_rfreg_test = rfreg_ht.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['y_test_rfreg_lsa_elbow_cbg.pkl']"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "joblib.dump(y_pred_rfreg_test, \"y_pred_rfreg_test_lsa_elbow_cbg.pkl\")\n",
    "joblib.dump(y_test, \"y_test_rfreg_lsa_elbow_cbg.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.03165177006050512"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mean_absolute_error(y_test, y_pred_rfreg_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0047613704247683845"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mean_squared_error(y_test, y_pred_rfreg_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.069002684185243"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mean_squared_error(y_test, y_pred_rfreg_test, squared = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9345013040822776"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "r2_score(y_test, y_pred_rfreg_test)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Error analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 576x432 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 432x288 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# assume y_pred is a numpy array and y_true is a pandas dataframe\n",
    "fig, ax = plt.subplots(figsize=(8, 6))\n",
    "\n",
    "column = \"X..CBG\"  # specify the target variable name\n",
    "ax.hist(y_pred_rfreg_test, alpha=0.5, label='y_pred', bins=20)\n",
    "ax.hist(y_test[column], alpha=0.5, label='y_true', bins=20)\n",
    "ax.legend(loc='upper right')\n",
    "ax.set_title(column)\n",
    "\n",
    "plt.show()\n",
    "plt.savefig('error_hist_rf_lsa_elbow_cbg.png')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pearson R"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pearson correlation coefficient: 0.968\n",
      "P-value: 0.000\n"
     ]
    }
   ],
   "source": [
    "corr_coef, p_value = pearsonr(y_pred_rfreg_test.flatten(), y_test.values.ravel())\n",
    "\n",
    "print(f\"Pearson correlation coefficient: {corr_coef:.3f}\")\n",
    "print(f\"P-value: {p_value:.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:>"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "corr_matrix = y_test.corr()\n",
    "sns.heatmap(corr_matrix, annot=True, cmap='coolwarm', center=0)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
