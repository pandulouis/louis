{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn import preprocessing\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.neural_network import MLPRegressor\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "from sklearn.metrics import r2_score\n",
    "from scipy.stats import pearsonr\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.feature_selection import SelectFromModel\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_bert = pd.read_csv(\"df_alpine_bert.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>feature_0</th>\n",
       "      <th>feature_1</th>\n",
       "      <th>feature_2</th>\n",
       "      <th>feature_3</th>\n",
       "      <th>feature_4</th>\n",
       "      <th>feature_5</th>\n",
       "      <th>feature_6</th>\n",
       "      <th>feature_7</th>\n",
       "      <th>feature_8</th>\n",
       "      <th>...</th>\n",
       "      <th>feature_759</th>\n",
       "      <th>feature_760</th>\n",
       "      <th>feature_761</th>\n",
       "      <th>feature_762</th>\n",
       "      <th>feature_763</th>\n",
       "      <th>feature_764</th>\n",
       "      <th>feature_765</th>\n",
       "      <th>feature_766</th>\n",
       "      <th>feature_767</th>\n",
       "      <th>X..Alpha-Pinene</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0.144370</td>\n",
       "      <td>0.133683</td>\n",
       "      <td>0.558613</td>\n",
       "      <td>0.002472</td>\n",
       "      <td>0.064213</td>\n",
       "      <td>-0.297644</td>\n",
       "      <td>0.649253</td>\n",
       "      <td>0.156834</td>\n",
       "      <td>-0.075428</td>\n",
       "      <td>...</td>\n",
       "      <td>0.171215</td>\n",
       "      <td>0.197233</td>\n",
       "      <td>-0.131170</td>\n",
       "      <td>0.210236</td>\n",
       "      <td>-0.728103</td>\n",
       "      <td>0.027258</td>\n",
       "      <td>-0.683708</td>\n",
       "      <td>-0.160281</td>\n",
       "      <td>-0.718498</td>\n",
       "      <td>0.106952</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0.144370</td>\n",
       "      <td>0.133683</td>\n",
       "      <td>0.558613</td>\n",
       "      <td>0.002472</td>\n",
       "      <td>0.064213</td>\n",
       "      <td>-0.297644</td>\n",
       "      <td>0.649253</td>\n",
       "      <td>0.156834</td>\n",
       "      <td>-0.075428</td>\n",
       "      <td>...</td>\n",
       "      <td>0.171215</td>\n",
       "      <td>0.197233</td>\n",
       "      <td>-0.131170</td>\n",
       "      <td>0.210236</td>\n",
       "      <td>-0.728103</td>\n",
       "      <td>0.027258</td>\n",
       "      <td>-0.683708</td>\n",
       "      <td>-0.160281</td>\n",
       "      <td>-0.718498</td>\n",
       "      <td>0.106952</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>0.227606</td>\n",
       "      <td>0.089886</td>\n",
       "      <td>0.612133</td>\n",
       "      <td>0.085675</td>\n",
       "      <td>0.032208</td>\n",
       "      <td>-0.384907</td>\n",
       "      <td>0.724170</td>\n",
       "      <td>0.154984</td>\n",
       "      <td>-0.061544</td>\n",
       "      <td>...</td>\n",
       "      <td>0.149779</td>\n",
       "      <td>0.157919</td>\n",
       "      <td>-0.156806</td>\n",
       "      <td>0.295726</td>\n",
       "      <td>-0.734769</td>\n",
       "      <td>0.099060</td>\n",
       "      <td>-0.779045</td>\n",
       "      <td>-0.190468</td>\n",
       "      <td>-0.830595</td>\n",
       "      <td>0.106952</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2</td>\n",
       "      <td>0.127047</td>\n",
       "      <td>0.111979</td>\n",
       "      <td>0.549845</td>\n",
       "      <td>0.036660</td>\n",
       "      <td>0.026879</td>\n",
       "      <td>-0.309649</td>\n",
       "      <td>0.654963</td>\n",
       "      <td>0.205110</td>\n",
       "      <td>-0.097057</td>\n",
       "      <td>...</td>\n",
       "      <td>0.146141</td>\n",
       "      <td>0.174652</td>\n",
       "      <td>-0.146565</td>\n",
       "      <td>0.217158</td>\n",
       "      <td>-0.712819</td>\n",
       "      <td>0.046792</td>\n",
       "      <td>-0.744437</td>\n",
       "      <td>-0.214183</td>\n",
       "      <td>-0.707376</td>\n",
       "      <td>0.106952</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3</td>\n",
       "      <td>0.147638</td>\n",
       "      <td>0.127715</td>\n",
       "      <td>0.509446</td>\n",
       "      <td>0.032539</td>\n",
       "      <td>0.056278</td>\n",
       "      <td>-0.280844</td>\n",
       "      <td>0.527530</td>\n",
       "      <td>0.212648</td>\n",
       "      <td>0.050864</td>\n",
       "      <td>...</td>\n",
       "      <td>0.155563</td>\n",
       "      <td>0.164850</td>\n",
       "      <td>-0.106371</td>\n",
       "      <td>0.177229</td>\n",
       "      <td>-0.695585</td>\n",
       "      <td>0.023077</td>\n",
       "      <td>-0.674670</td>\n",
       "      <td>-0.076964</td>\n",
       "      <td>-0.590824</td>\n",
       "      <td>0.106952</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59995</th>\n",
       "      <td>42967</td>\n",
       "      <td>0.237772</td>\n",
       "      <td>0.120746</td>\n",
       "      <td>0.629375</td>\n",
       "      <td>0.104186</td>\n",
       "      <td>0.032603</td>\n",
       "      <td>-0.432701</td>\n",
       "      <td>0.764779</td>\n",
       "      <td>0.083739</td>\n",
       "      <td>-0.119063</td>\n",
       "      <td>...</td>\n",
       "      <td>0.171331</td>\n",
       "      <td>0.111348</td>\n",
       "      <td>-0.115894</td>\n",
       "      <td>0.320711</td>\n",
       "      <td>-0.736399</td>\n",
       "      <td>0.117869</td>\n",
       "      <td>-0.834123</td>\n",
       "      <td>-0.191543</td>\n",
       "      <td>-0.876954</td>\n",
       "      <td>0.021390</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59996</th>\n",
       "      <td>42970</td>\n",
       "      <td>0.109320</td>\n",
       "      <td>0.095256</td>\n",
       "      <td>0.523631</td>\n",
       "      <td>-0.007430</td>\n",
       "      <td>0.055264</td>\n",
       "      <td>-0.338708</td>\n",
       "      <td>0.570877</td>\n",
       "      <td>0.232808</td>\n",
       "      <td>-0.009438</td>\n",
       "      <td>...</td>\n",
       "      <td>0.124365</td>\n",
       "      <td>0.174935</td>\n",
       "      <td>-0.110914</td>\n",
       "      <td>0.197620</td>\n",
       "      <td>-0.678949</td>\n",
       "      <td>0.039182</td>\n",
       "      <td>-0.663883</td>\n",
       "      <td>-0.163899</td>\n",
       "      <td>-0.593018</td>\n",
       "      <td>0.021390</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59997</th>\n",
       "      <td>42971</td>\n",
       "      <td>0.219584</td>\n",
       "      <td>0.143236</td>\n",
       "      <td>0.539909</td>\n",
       "      <td>0.086895</td>\n",
       "      <td>-0.006281</td>\n",
       "      <td>-0.389946</td>\n",
       "      <td>0.806679</td>\n",
       "      <td>0.186327</td>\n",
       "      <td>-0.065521</td>\n",
       "      <td>...</td>\n",
       "      <td>0.142024</td>\n",
       "      <td>0.141072</td>\n",
       "      <td>-0.212327</td>\n",
       "      <td>0.300115</td>\n",
       "      <td>-0.697690</td>\n",
       "      <td>0.069458</td>\n",
       "      <td>-0.770859</td>\n",
       "      <td>-0.155446</td>\n",
       "      <td>-0.747328</td>\n",
       "      <td>0.021390</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59998</th>\n",
       "      <td>42973</td>\n",
       "      <td>0.233248</td>\n",
       "      <td>0.109718</td>\n",
       "      <td>0.598537</td>\n",
       "      <td>0.061358</td>\n",
       "      <td>0.088095</td>\n",
       "      <td>-0.390093</td>\n",
       "      <td>0.800446</td>\n",
       "      <td>0.077057</td>\n",
       "      <td>-0.104278</td>\n",
       "      <td>...</td>\n",
       "      <td>0.195909</td>\n",
       "      <td>0.095593</td>\n",
       "      <td>-0.109210</td>\n",
       "      <td>0.319783</td>\n",
       "      <td>-0.766471</td>\n",
       "      <td>0.119461</td>\n",
       "      <td>-0.819312</td>\n",
       "      <td>-0.167582</td>\n",
       "      <td>-0.830700</td>\n",
       "      <td>0.021390</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59999</th>\n",
       "      <td>42974</td>\n",
       "      <td>0.282075</td>\n",
       "      <td>0.149575</td>\n",
       "      <td>0.652933</td>\n",
       "      <td>0.145363</td>\n",
       "      <td>0.003963</td>\n",
       "      <td>-0.429747</td>\n",
       "      <td>0.819131</td>\n",
       "      <td>0.018761</td>\n",
       "      <td>-0.133602</td>\n",
       "      <td>...</td>\n",
       "      <td>0.133490</td>\n",
       "      <td>0.180182</td>\n",
       "      <td>-0.139251</td>\n",
       "      <td>0.378032</td>\n",
       "      <td>-0.731045</td>\n",
       "      <td>0.157516</td>\n",
       "      <td>-0.825618</td>\n",
       "      <td>-0.148141</td>\n",
       "      <td>-0.877954</td>\n",
       "      <td>0.021390</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>60000 rows × 770 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       index  feature_0  feature_1  feature_2  feature_3  feature_4  \\\n",
       "0          0   0.144370   0.133683   0.558613   0.002472   0.064213   \n",
       "1          0   0.144370   0.133683   0.558613   0.002472   0.064213   \n",
       "2          1   0.227606   0.089886   0.612133   0.085675   0.032208   \n",
       "3          2   0.127047   0.111979   0.549845   0.036660   0.026879   \n",
       "4          3   0.147638   0.127715   0.509446   0.032539   0.056278   \n",
       "...      ...        ...        ...        ...        ...        ...   \n",
       "59995  42967   0.237772   0.120746   0.629375   0.104186   0.032603   \n",
       "59996  42970   0.109320   0.095256   0.523631  -0.007430   0.055264   \n",
       "59997  42971   0.219584   0.143236   0.539909   0.086895  -0.006281   \n",
       "59998  42973   0.233248   0.109718   0.598537   0.061358   0.088095   \n",
       "59999  42974   0.282075   0.149575   0.652933   0.145363   0.003963   \n",
       "\n",
       "       feature_5  feature_6  feature_7  feature_8  ...  feature_759  \\\n",
       "0      -0.297644   0.649253   0.156834  -0.075428  ...     0.171215   \n",
       "1      -0.297644   0.649253   0.156834  -0.075428  ...     0.171215   \n",
       "2      -0.384907   0.724170   0.154984  -0.061544  ...     0.149779   \n",
       "3      -0.309649   0.654963   0.205110  -0.097057  ...     0.146141   \n",
       "4      -0.280844   0.527530   0.212648   0.050864  ...     0.155563   \n",
       "...          ...        ...        ...        ...  ...          ...   \n",
       "59995  -0.432701   0.764779   0.083739  -0.119063  ...     0.171331   \n",
       "59996  -0.338708   0.570877   0.232808  -0.009438  ...     0.124365   \n",
       "59997  -0.389946   0.806679   0.186327  -0.065521  ...     0.142024   \n",
       "59998  -0.390093   0.800446   0.077057  -0.104278  ...     0.195909   \n",
       "59999  -0.429747   0.819131   0.018761  -0.133602  ...     0.133490   \n",
       "\n",
       "       feature_760  feature_761  feature_762  feature_763  feature_764  \\\n",
       "0         0.197233    -0.131170     0.210236    -0.728103     0.027258   \n",
       "1         0.197233    -0.131170     0.210236    -0.728103     0.027258   \n",
       "2         0.157919    -0.156806     0.295726    -0.734769     0.099060   \n",
       "3         0.174652    -0.146565     0.217158    -0.712819     0.046792   \n",
       "4         0.164850    -0.106371     0.177229    -0.695585     0.023077   \n",
       "...            ...          ...          ...          ...          ...   \n",
       "59995     0.111348    -0.115894     0.320711    -0.736399     0.117869   \n",
       "59996     0.174935    -0.110914     0.197620    -0.678949     0.039182   \n",
       "59997     0.141072    -0.212327     0.300115    -0.697690     0.069458   \n",
       "59998     0.095593    -0.109210     0.319783    -0.766471     0.119461   \n",
       "59999     0.180182    -0.139251     0.378032    -0.731045     0.157516   \n",
       "\n",
       "       feature_765  feature_766  feature_767  X..Alpha-Pinene  \n",
       "0        -0.683708    -0.160281    -0.718498         0.106952  \n",
       "1        -0.683708    -0.160281    -0.718498         0.106952  \n",
       "2        -0.779045    -0.190468    -0.830595         0.106952  \n",
       "3        -0.744437    -0.214183    -0.707376         0.106952  \n",
       "4        -0.674670    -0.076964    -0.590824         0.106952  \n",
       "...            ...          ...          ...              ...  \n",
       "59995    -0.834123    -0.191543    -0.876954         0.021390  \n",
       "59996    -0.663883    -0.163899    -0.593018         0.021390  \n",
       "59997    -0.770859    -0.155446    -0.747328         0.021390  \n",
       "59998    -0.819312    -0.167582    -0.830700         0.021390  \n",
       "59999    -0.825618    -0.148141    -0.877954         0.021390  \n",
       "\n",
       "[60000 rows x 770 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_bert"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['index',\n",
       " 'feature_0',\n",
       " 'feature_1',\n",
       " 'feature_2',\n",
       " 'feature_3',\n",
       " 'feature_4',\n",
       " 'feature_5',\n",
       " 'feature_6',\n",
       " 'feature_7',\n",
       " 'feature_8',\n",
       " 'feature_9',\n",
       " 'feature_10',\n",
       " 'feature_11',\n",
       " 'feature_12',\n",
       " 'feature_13',\n",
       " 'feature_14',\n",
       " 'feature_15',\n",
       " 'feature_16',\n",
       " 'feature_17',\n",
       " 'feature_18',\n",
       " 'feature_19',\n",
       " 'feature_20',\n",
       " 'feature_21',\n",
       " 'feature_22',\n",
       " 'feature_23',\n",
       " 'feature_24',\n",
       " 'feature_25',\n",
       " 'feature_26',\n",
       " 'feature_27',\n",
       " 'feature_28',\n",
       " 'feature_29',\n",
       " 'feature_30',\n",
       " 'feature_31',\n",
       " 'feature_32',\n",
       " 'feature_33',\n",
       " 'feature_34',\n",
       " 'feature_35',\n",
       " 'feature_36',\n",
       " 'feature_37',\n",
       " 'feature_38',\n",
       " 'feature_39',\n",
       " 'feature_40',\n",
       " 'feature_41',\n",
       " 'feature_42',\n",
       " 'feature_43',\n",
       " 'feature_44',\n",
       " 'feature_45',\n",
       " 'feature_46',\n",
       " 'feature_47',\n",
       " 'feature_48',\n",
       " 'feature_49',\n",
       " 'feature_50',\n",
       " 'feature_51',\n",
       " 'feature_52',\n",
       " 'feature_53',\n",
       " 'feature_54',\n",
       " 'feature_55',\n",
       " 'feature_56',\n",
       " 'feature_57',\n",
       " 'feature_58',\n",
       " 'feature_59',\n",
       " 'feature_60',\n",
       " 'feature_61',\n",
       " 'feature_62',\n",
       " 'feature_63',\n",
       " 'feature_64',\n",
       " 'feature_65',\n",
       " 'feature_66',\n",
       " 'feature_67',\n",
       " 'feature_68',\n",
       " 'feature_69',\n",
       " 'feature_70',\n",
       " 'feature_71',\n",
       " 'feature_72',\n",
       " 'feature_73',\n",
       " 'feature_74',\n",
       " 'feature_75',\n",
       " 'feature_76',\n",
       " 'feature_77',\n",
       " 'feature_78',\n",
       " 'feature_79',\n",
       " 'feature_80',\n",
       " 'feature_81',\n",
       " 'feature_82',\n",
       " 'feature_83',\n",
       " 'feature_84',\n",
       " 'feature_85',\n",
       " 'feature_86',\n",
       " 'feature_87',\n",
       " 'feature_88',\n",
       " 'feature_89',\n",
       " 'feature_90',\n",
       " 'feature_91',\n",
       " 'feature_92',\n",
       " 'feature_93',\n",
       " 'feature_94',\n",
       " 'feature_95',\n",
       " 'feature_96',\n",
       " 'feature_97',\n",
       " 'feature_98',\n",
       " 'feature_99',\n",
       " 'feature_100',\n",
       " 'feature_101',\n",
       " 'feature_102',\n",
       " 'feature_103',\n",
       " 'feature_104',\n",
       " 'feature_105',\n",
       " 'feature_106',\n",
       " 'feature_107',\n",
       " 'feature_108',\n",
       " 'feature_109',\n",
       " 'feature_110',\n",
       " 'feature_111',\n",
       " 'feature_112',\n",
       " 'feature_113',\n",
       " 'feature_114',\n",
       " 'feature_115',\n",
       " 'feature_116',\n",
       " 'feature_117',\n",
       " 'feature_118',\n",
       " 'feature_119',\n",
       " 'feature_120',\n",
       " 'feature_121',\n",
       " 'feature_122',\n",
       " 'feature_123',\n",
       " 'feature_124',\n",
       " 'feature_125',\n",
       " 'feature_126',\n",
       " 'feature_127',\n",
       " 'feature_128',\n",
       " 'feature_129',\n",
       " 'feature_130',\n",
       " 'feature_131',\n",
       " 'feature_132',\n",
       " 'feature_133',\n",
       " 'feature_134',\n",
       " 'feature_135',\n",
       " 'feature_136',\n",
       " 'feature_137',\n",
       " 'feature_138',\n",
       " 'feature_139',\n",
       " 'feature_140',\n",
       " 'feature_141',\n",
       " 'feature_142',\n",
       " 'feature_143',\n",
       " 'feature_144',\n",
       " 'feature_145',\n",
       " 'feature_146',\n",
       " 'feature_147',\n",
       " 'feature_148',\n",
       " 'feature_149',\n",
       " 'feature_150',\n",
       " 'feature_151',\n",
       " 'feature_152',\n",
       " 'feature_153',\n",
       " 'feature_154',\n",
       " 'feature_155',\n",
       " 'feature_156',\n",
       " 'feature_157',\n",
       " 'feature_158',\n",
       " 'feature_159',\n",
       " 'feature_160',\n",
       " 'feature_161',\n",
       " 'feature_162',\n",
       " 'feature_163',\n",
       " 'feature_164',\n",
       " 'feature_165',\n",
       " 'feature_166',\n",
       " 'feature_167',\n",
       " 'feature_168',\n",
       " 'feature_169',\n",
       " 'feature_170',\n",
       " 'feature_171',\n",
       " 'feature_172',\n",
       " 'feature_173',\n",
       " 'feature_174',\n",
       " 'feature_175',\n",
       " 'feature_176',\n",
       " 'feature_177',\n",
       " 'feature_178',\n",
       " 'feature_179',\n",
       " 'feature_180',\n",
       " 'feature_181',\n",
       " 'feature_182',\n",
       " 'feature_183',\n",
       " 'feature_184',\n",
       " 'feature_185',\n",
       " 'feature_186',\n",
       " 'feature_187',\n",
       " 'feature_188',\n",
       " 'feature_189',\n",
       " 'feature_190',\n",
       " 'feature_191',\n",
       " 'feature_192',\n",
       " 'feature_193',\n",
       " 'feature_194',\n",
       " 'feature_195',\n",
       " 'feature_196',\n",
       " 'feature_197',\n",
       " 'feature_198',\n",
       " 'feature_199',\n",
       " 'feature_200',\n",
       " 'feature_201',\n",
       " 'feature_202',\n",
       " 'feature_203',\n",
       " 'feature_204',\n",
       " 'feature_205',\n",
       " 'feature_206',\n",
       " 'feature_207',\n",
       " 'feature_208',\n",
       " 'feature_209',\n",
       " 'feature_210',\n",
       " 'feature_211',\n",
       " 'feature_212',\n",
       " 'feature_213',\n",
       " 'feature_214',\n",
       " 'feature_215',\n",
       " 'feature_216',\n",
       " 'feature_217',\n",
       " 'feature_218',\n",
       " 'feature_219',\n",
       " 'feature_220',\n",
       " 'feature_221',\n",
       " 'feature_222',\n",
       " 'feature_223',\n",
       " 'feature_224',\n",
       " 'feature_225',\n",
       " 'feature_226',\n",
       " 'feature_227',\n",
       " 'feature_228',\n",
       " 'feature_229',\n",
       " 'feature_230',\n",
       " 'feature_231',\n",
       " 'feature_232',\n",
       " 'feature_233',\n",
       " 'feature_234',\n",
       " 'feature_235',\n",
       " 'feature_236',\n",
       " 'feature_237',\n",
       " 'feature_238',\n",
       " 'feature_239',\n",
       " 'feature_240',\n",
       " 'feature_241',\n",
       " 'feature_242',\n",
       " 'feature_243',\n",
       " 'feature_244',\n",
       " 'feature_245',\n",
       " 'feature_246',\n",
       " 'feature_247',\n",
       " 'feature_248',\n",
       " 'feature_249',\n",
       " 'feature_250',\n",
       " 'feature_251',\n",
       " 'feature_252',\n",
       " 'feature_253',\n",
       " 'feature_254',\n",
       " 'feature_255',\n",
       " 'feature_256',\n",
       " 'feature_257',\n",
       " 'feature_258',\n",
       " 'feature_259',\n",
       " 'feature_260',\n",
       " 'feature_261',\n",
       " 'feature_262',\n",
       " 'feature_263',\n",
       " 'feature_264',\n",
       " 'feature_265',\n",
       " 'feature_266',\n",
       " 'feature_267',\n",
       " 'feature_268',\n",
       " 'feature_269',\n",
       " 'feature_270',\n",
       " 'feature_271',\n",
       " 'feature_272',\n",
       " 'feature_273',\n",
       " 'feature_274',\n",
       " 'feature_275',\n",
       " 'feature_276',\n",
       " 'feature_277',\n",
       " 'feature_278',\n",
       " 'feature_279',\n",
       " 'feature_280',\n",
       " 'feature_281',\n",
       " 'feature_282',\n",
       " 'feature_283',\n",
       " 'feature_284',\n",
       " 'feature_285',\n",
       " 'feature_286',\n",
       " 'feature_287',\n",
       " 'feature_288',\n",
       " 'feature_289',\n",
       " 'feature_290',\n",
       " 'feature_291',\n",
       " 'feature_292',\n",
       " 'feature_293',\n",
       " 'feature_294',\n",
       " 'feature_295',\n",
       " 'feature_296',\n",
       " 'feature_297',\n",
       " 'feature_298',\n",
       " 'feature_299',\n",
       " 'feature_300',\n",
       " 'feature_301',\n",
       " 'feature_302',\n",
       " 'feature_303',\n",
       " 'feature_304',\n",
       " 'feature_305',\n",
       " 'feature_306',\n",
       " 'feature_307',\n",
       " 'feature_308',\n",
       " 'feature_309',\n",
       " 'feature_310',\n",
       " 'feature_311',\n",
       " 'feature_312',\n",
       " 'feature_313',\n",
       " 'feature_314',\n",
       " 'feature_315',\n",
       " 'feature_316',\n",
       " 'feature_317',\n",
       " 'feature_318',\n",
       " 'feature_319',\n",
       " 'feature_320',\n",
       " 'feature_321',\n",
       " 'feature_322',\n",
       " 'feature_323',\n",
       " 'feature_324',\n",
       " 'feature_325',\n",
       " 'feature_326',\n",
       " 'feature_327',\n",
       " 'feature_328',\n",
       " 'feature_329',\n",
       " 'feature_330',\n",
       " 'feature_331',\n",
       " 'feature_332',\n",
       " 'feature_333',\n",
       " 'feature_334',\n",
       " 'feature_335',\n",
       " 'feature_336',\n",
       " 'feature_337',\n",
       " 'feature_338',\n",
       " 'feature_339',\n",
       " 'feature_340',\n",
       " 'feature_341',\n",
       " 'feature_342',\n",
       " 'feature_343',\n",
       " 'feature_344',\n",
       " 'feature_345',\n",
       " 'feature_346',\n",
       " 'feature_347',\n",
       " 'feature_348',\n",
       " 'feature_349',\n",
       " 'feature_350',\n",
       " 'feature_351',\n",
       " 'feature_352',\n",
       " 'feature_353',\n",
       " 'feature_354',\n",
       " 'feature_355',\n",
       " 'feature_356',\n",
       " 'feature_357',\n",
       " 'feature_358',\n",
       " 'feature_359',\n",
       " 'feature_360',\n",
       " 'feature_361',\n",
       " 'feature_362',\n",
       " 'feature_363',\n",
       " 'feature_364',\n",
       " 'feature_365',\n",
       " 'feature_366',\n",
       " 'feature_367',\n",
       " 'feature_368',\n",
       " 'feature_369',\n",
       " 'feature_370',\n",
       " 'feature_371',\n",
       " 'feature_372',\n",
       " 'feature_373',\n",
       " 'feature_374',\n",
       " 'feature_375',\n",
       " 'feature_376',\n",
       " 'feature_377',\n",
       " 'feature_378',\n",
       " 'feature_379',\n",
       " 'feature_380',\n",
       " 'feature_381',\n",
       " 'feature_382',\n",
       " 'feature_383',\n",
       " 'feature_384',\n",
       " 'feature_385',\n",
       " 'feature_386',\n",
       " 'feature_387',\n",
       " 'feature_388',\n",
       " 'feature_389',\n",
       " 'feature_390',\n",
       " 'feature_391',\n",
       " 'feature_392',\n",
       " 'feature_393',\n",
       " 'feature_394',\n",
       " 'feature_395',\n",
       " 'feature_396',\n",
       " 'feature_397',\n",
       " 'feature_398',\n",
       " 'feature_399',\n",
       " 'feature_400',\n",
       " 'feature_401',\n",
       " 'feature_402',\n",
       " 'feature_403',\n",
       " 'feature_404',\n",
       " 'feature_405',\n",
       " 'feature_406',\n",
       " 'feature_407',\n",
       " 'feature_408',\n",
       " 'feature_409',\n",
       " 'feature_410',\n",
       " 'feature_411',\n",
       " 'feature_412',\n",
       " 'feature_413',\n",
       " 'feature_414',\n",
       " 'feature_415',\n",
       " 'feature_416',\n",
       " 'feature_417',\n",
       " 'feature_418',\n",
       " 'feature_419',\n",
       " 'feature_420',\n",
       " 'feature_421',\n",
       " 'feature_422',\n",
       " 'feature_423',\n",
       " 'feature_424',\n",
       " 'feature_425',\n",
       " 'feature_426',\n",
       " 'feature_427',\n",
       " 'feature_428',\n",
       " 'feature_429',\n",
       " 'feature_430',\n",
       " 'feature_431',\n",
       " 'feature_432',\n",
       " 'feature_433',\n",
       " 'feature_434',\n",
       " 'feature_435',\n",
       " 'feature_436',\n",
       " 'feature_437',\n",
       " 'feature_438',\n",
       " 'feature_439',\n",
       " 'feature_440',\n",
       " 'feature_441',\n",
       " 'feature_442',\n",
       " 'feature_443',\n",
       " 'feature_444',\n",
       " 'feature_445',\n",
       " 'feature_446',\n",
       " 'feature_447',\n",
       " 'feature_448',\n",
       " 'feature_449',\n",
       " 'feature_450',\n",
       " 'feature_451',\n",
       " 'feature_452',\n",
       " 'feature_453',\n",
       " 'feature_454',\n",
       " 'feature_455',\n",
       " 'feature_456',\n",
       " 'feature_457',\n",
       " 'feature_458',\n",
       " 'feature_459',\n",
       " 'feature_460',\n",
       " 'feature_461',\n",
       " 'feature_462',\n",
       " 'feature_463',\n",
       " 'feature_464',\n",
       " 'feature_465',\n",
       " 'feature_466',\n",
       " 'feature_467',\n",
       " 'feature_468',\n",
       " 'feature_469',\n",
       " 'feature_470',\n",
       " 'feature_471',\n",
       " 'feature_472',\n",
       " 'feature_473',\n",
       " 'feature_474',\n",
       " 'feature_475',\n",
       " 'feature_476',\n",
       " 'feature_477',\n",
       " 'feature_478',\n",
       " 'feature_479',\n",
       " 'feature_480',\n",
       " 'feature_481',\n",
       " 'feature_482',\n",
       " 'feature_483',\n",
       " 'feature_484',\n",
       " 'feature_485',\n",
       " 'feature_486',\n",
       " 'feature_487',\n",
       " 'feature_488',\n",
       " 'feature_489',\n",
       " 'feature_490',\n",
       " 'feature_491',\n",
       " 'feature_492',\n",
       " 'feature_493',\n",
       " 'feature_494',\n",
       " 'feature_495',\n",
       " 'feature_496',\n",
       " 'feature_497',\n",
       " 'feature_498',\n",
       " 'feature_499',\n",
       " 'feature_500',\n",
       " 'feature_501',\n",
       " 'feature_502',\n",
       " 'feature_503',\n",
       " 'feature_504',\n",
       " 'feature_505',\n",
       " 'feature_506',\n",
       " 'feature_507',\n",
       " 'feature_508',\n",
       " 'feature_509',\n",
       " 'feature_510',\n",
       " 'feature_511',\n",
       " 'feature_512',\n",
       " 'feature_513',\n",
       " 'feature_514',\n",
       " 'feature_515',\n",
       " 'feature_516',\n",
       " 'feature_517',\n",
       " 'feature_518',\n",
       " 'feature_519',\n",
       " 'feature_520',\n",
       " 'feature_521',\n",
       " 'feature_522',\n",
       " 'feature_523',\n",
       " 'feature_524',\n",
       " 'feature_525',\n",
       " 'feature_526',\n",
       " 'feature_527',\n",
       " 'feature_528',\n",
       " 'feature_529',\n",
       " 'feature_530',\n",
       " 'feature_531',\n",
       " 'feature_532',\n",
       " 'feature_533',\n",
       " 'feature_534',\n",
       " 'feature_535',\n",
       " 'feature_536',\n",
       " 'feature_537',\n",
       " 'feature_538',\n",
       " 'feature_539',\n",
       " 'feature_540',\n",
       " 'feature_541',\n",
       " 'feature_542',\n",
       " 'feature_543',\n",
       " 'feature_544',\n",
       " 'feature_545',\n",
       " 'feature_546',\n",
       " 'feature_547',\n",
       " 'feature_548',\n",
       " 'feature_549',\n",
       " 'feature_550',\n",
       " 'feature_551',\n",
       " 'feature_552',\n",
       " 'feature_553',\n",
       " 'feature_554',\n",
       " 'feature_555',\n",
       " 'feature_556',\n",
       " 'feature_557',\n",
       " 'feature_558',\n",
       " 'feature_559',\n",
       " 'feature_560',\n",
       " 'feature_561',\n",
       " 'feature_562',\n",
       " 'feature_563',\n",
       " 'feature_564',\n",
       " 'feature_565',\n",
       " 'feature_566',\n",
       " 'feature_567',\n",
       " 'feature_568',\n",
       " 'feature_569',\n",
       " 'feature_570',\n",
       " 'feature_571',\n",
       " 'feature_572',\n",
       " 'feature_573',\n",
       " 'feature_574',\n",
       " 'feature_575',\n",
       " 'feature_576',\n",
       " 'feature_577',\n",
       " 'feature_578',\n",
       " 'feature_579',\n",
       " 'feature_580',\n",
       " 'feature_581',\n",
       " 'feature_582',\n",
       " 'feature_583',\n",
       " 'feature_584',\n",
       " 'feature_585',\n",
       " 'feature_586',\n",
       " 'feature_587',\n",
       " 'feature_588',\n",
       " 'feature_589',\n",
       " 'feature_590',\n",
       " 'feature_591',\n",
       " 'feature_592',\n",
       " 'feature_593',\n",
       " 'feature_594',\n",
       " 'feature_595',\n",
       " 'feature_596',\n",
       " 'feature_597',\n",
       " 'feature_598',\n",
       " 'feature_599',\n",
       " 'feature_600',\n",
       " 'feature_601',\n",
       " 'feature_602',\n",
       " 'feature_603',\n",
       " 'feature_604',\n",
       " 'feature_605',\n",
       " 'feature_606',\n",
       " 'feature_607',\n",
       " 'feature_608',\n",
       " 'feature_609',\n",
       " 'feature_610',\n",
       " 'feature_611',\n",
       " 'feature_612',\n",
       " 'feature_613',\n",
       " 'feature_614',\n",
       " 'feature_615',\n",
       " 'feature_616',\n",
       " 'feature_617',\n",
       " 'feature_618',\n",
       " 'feature_619',\n",
       " 'feature_620',\n",
       " 'feature_621',\n",
       " 'feature_622',\n",
       " 'feature_623',\n",
       " 'feature_624',\n",
       " 'feature_625',\n",
       " 'feature_626',\n",
       " 'feature_627',\n",
       " 'feature_628',\n",
       " 'feature_629',\n",
       " 'feature_630',\n",
       " 'feature_631',\n",
       " 'feature_632',\n",
       " 'feature_633',\n",
       " 'feature_634',\n",
       " 'feature_635',\n",
       " 'feature_636',\n",
       " 'feature_637',\n",
       " 'feature_638',\n",
       " 'feature_639',\n",
       " 'feature_640',\n",
       " 'feature_641',\n",
       " 'feature_642',\n",
       " 'feature_643',\n",
       " 'feature_644',\n",
       " 'feature_645',\n",
       " 'feature_646',\n",
       " 'feature_647',\n",
       " 'feature_648',\n",
       " 'feature_649',\n",
       " 'feature_650',\n",
       " 'feature_651',\n",
       " 'feature_652',\n",
       " 'feature_653',\n",
       " 'feature_654',\n",
       " 'feature_655',\n",
       " 'feature_656',\n",
       " 'feature_657',\n",
       " 'feature_658',\n",
       " 'feature_659',\n",
       " 'feature_660',\n",
       " 'feature_661',\n",
       " 'feature_662',\n",
       " 'feature_663',\n",
       " 'feature_664',\n",
       " 'feature_665',\n",
       " 'feature_666',\n",
       " 'feature_667',\n",
       " 'feature_668',\n",
       " 'feature_669',\n",
       " 'feature_670',\n",
       " 'feature_671',\n",
       " 'feature_672',\n",
       " 'feature_673',\n",
       " 'feature_674',\n",
       " 'feature_675',\n",
       " 'feature_676',\n",
       " 'feature_677',\n",
       " 'feature_678',\n",
       " 'feature_679',\n",
       " 'feature_680',\n",
       " 'feature_681',\n",
       " 'feature_682',\n",
       " 'feature_683',\n",
       " 'feature_684',\n",
       " 'feature_685',\n",
       " 'feature_686',\n",
       " 'feature_687',\n",
       " 'feature_688',\n",
       " 'feature_689',\n",
       " 'feature_690',\n",
       " 'feature_691',\n",
       " 'feature_692',\n",
       " 'feature_693',\n",
       " 'feature_694',\n",
       " 'feature_695',\n",
       " 'feature_696',\n",
       " 'feature_697',\n",
       " 'feature_698',\n",
       " 'feature_699',\n",
       " 'feature_700',\n",
       " 'feature_701',\n",
       " 'feature_702',\n",
       " 'feature_703',\n",
       " 'feature_704',\n",
       " 'feature_705',\n",
       " 'feature_706',\n",
       " 'feature_707',\n",
       " 'feature_708',\n",
       " 'feature_709',\n",
       " 'feature_710',\n",
       " 'feature_711',\n",
       " 'feature_712',\n",
       " 'feature_713',\n",
       " 'feature_714',\n",
       " 'feature_715',\n",
       " 'feature_716',\n",
       " 'feature_717',\n",
       " 'feature_718',\n",
       " 'feature_719',\n",
       " 'feature_720',\n",
       " 'feature_721',\n",
       " 'feature_722',\n",
       " 'feature_723',\n",
       " 'feature_724',\n",
       " 'feature_725',\n",
       " 'feature_726',\n",
       " 'feature_727',\n",
       " 'feature_728',\n",
       " 'feature_729',\n",
       " 'feature_730',\n",
       " 'feature_731',\n",
       " 'feature_732',\n",
       " 'feature_733',\n",
       " 'feature_734',\n",
       " 'feature_735',\n",
       " 'feature_736',\n",
       " 'feature_737',\n",
       " 'feature_738',\n",
       " 'feature_739',\n",
       " 'feature_740',\n",
       " 'feature_741',\n",
       " 'feature_742',\n",
       " 'feature_743',\n",
       " 'feature_744',\n",
       " 'feature_745',\n",
       " 'feature_746',\n",
       " 'feature_747',\n",
       " 'feature_748',\n",
       " 'feature_749',\n",
       " 'feature_750',\n",
       " 'feature_751',\n",
       " 'feature_752',\n",
       " 'feature_753',\n",
       " 'feature_754',\n",
       " 'feature_755',\n",
       " 'feature_756',\n",
       " 'feature_757',\n",
       " 'feature_758',\n",
       " 'feature_759',\n",
       " 'feature_760',\n",
       " 'feature_761',\n",
       " 'feature_762',\n",
       " 'feature_763',\n",
       " 'feature_764',\n",
       " 'feature_765',\n",
       " 'feature_766',\n",
       " 'feature_767',\n",
       " 'X..Alpha-Pinene']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_bert.columns.to_list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df_bert.drop(['X..Alpha-Pinene', 'index'], axis = 1)\n",
    "y = df_bert[['X..Alpha-Pinene']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:ylabel='Count'>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "sns.histplot(y, bins = 10)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "pca = PCA()\n",
    "pca_comps = pca.fit_transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 1.72445382e+00, -6.10912187e-01, -2.74417797e-01, ...,\n",
       "        -2.56365376e-03,  5.24716301e-04, -2.32476012e-08],\n",
       "       [ 1.72445382e+00, -6.10912187e-01, -2.74417797e-01, ...,\n",
       "        -2.56365376e-03,  5.24716301e-04, -2.32476079e-08],\n",
       "       [-6.67419650e-01, -1.63826940e-01,  4.62091127e-01, ...,\n",
       "         4.77574936e-04, -1.95786212e-03, -4.77250001e-08],\n",
       "       ...,\n",
       "       [-7.18483656e-01, -2.26408253e-01,  1.13179451e-01, ...,\n",
       "         2.16486900e-03, -7.76386063e-04, -2.43678514e-08],\n",
       "       [-1.60392496e+00,  3.98935142e-01, -2.72050637e-01, ...,\n",
       "         3.04857414e-03,  3.63112169e-03, -2.75712020e-08],\n",
       "       [-2.51735411e+00,  1.12599550e+00, -9.46549815e-02, ...,\n",
       "         4.06109998e-04, -9.49540613e-04,  5.89113878e-08]])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pca_comps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "numpy.ndarray"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(pca_comps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "explained_variance = pca.explained_variance_ratio_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(range(1, len(explained_variance)+1), explained_variance, 'bo-', linewidth=2)\n",
    "plt.xlabel('Number of components')\n",
    "plt.ylabel('Explained variance ratio')\n",
    "plt.title('Scree Plot')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the second derivative of the explained variance ratio curve\n",
    "second_der = np.diff(explained_variance, 2)\n",
    "\n",
    "# Find the index of the maximum value of the second derivative\n",
    "elbow_index = np.argmax(second_der) + 1\n",
    "\n",
    "# The optimal number of components is the index of the elbow point\n",
    "n_components_optimal = elbow_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n_components_optimal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_reduced = pca.transform(X)[:, :n_components_optimal]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 1.72445382],\n",
       "       [ 1.72445382],\n",
       "       [-0.66741965],\n",
       "       ...,\n",
       "       [-0.71848366],\n",
       "       [-1.60392496],\n",
       "       [-2.51735411]])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_reduced"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pca_0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.724454</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.724454</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-0.667420</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.145692</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2.245212</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59995</th>\n",
       "      <td>-1.589623</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59996</th>\n",
       "      <td>2.929105</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59997</th>\n",
       "      <td>-0.718484</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59998</th>\n",
       "      <td>-1.603925</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59999</th>\n",
       "      <td>-2.517354</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>60000 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          pca_0\n",
       "0      1.724454\n",
       "1      1.724454\n",
       "2     -0.667420\n",
       "3      1.145692\n",
       "4      2.245212\n",
       "...         ...\n",
       "59995 -1.589623\n",
       "59996  2.929105\n",
       "59997 -0.718484\n",
       "59998 -1.603925\n",
       "59999 -2.517354\n",
       "\n",
       "[60000 rows x 1 columns]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_reduced = pd.DataFrame(X_reduced)\n",
    "X_reduced = X_reduced.add_prefix('pca_')\n",
    "X_reduced"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "train test split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X_reduced, y, random_state=1, test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train1, X_val, y_train1, y_val = train_test_split(X_train, y_train, random_state=1, test_size=0.2)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "kNN (before feature selection and hyperparameter tuning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "knreg = KNeighborsRegressor()\n",
    "knreg.fit(X_train1, y_train1)\n",
    "y_pred_knreg = knreg.predict(X_val)\n",
    "y_pred_knreg_r2 = knreg.predict(X_train1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.042206690007976784"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mean_absolute_error(y_val, y_pred_knreg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.007533217020400851"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mean_squared_error(y_val, y_pred_knreg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.08679410706033476"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mean_squared_error(y_val, y_pred_knreg, squared = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9634594236132371"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#train\n",
    "r2_score(y_train1, y_pred_knreg_r2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9438214904623781"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#val\n",
    "r2_score(y_val, y_pred_knreg)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "RF (before feature selection and hyperparameter tuning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/y1/pjvjlkjn5gl846rnyzr53p340000gn/T/ipykernel_4187/2685114911.py:2: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  rfreg.fit(X_train1, y_train1)\n"
     ]
    }
   ],
   "source": [
    "rfreg = RandomForestRegressor()\n",
    "rfreg.fit(X_train1, y_train1)\n",
    "y_pred_rfreg = rfreg.predict(X_val)\n",
    "y_pred_rfreg_r2 = rfreg.predict(X_train1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.029974320605479523"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mean_absolute_error(y_val, y_pred_rfreg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.005091456063506476"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mean_squared_error(y_val, y_pred_rfreg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.07135443969022864"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mean_squared_error(y_val, y_pred_rfreg, squared = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9941647153482395"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#train\n",
    "r2_score(y_train1, y_pred_rfreg_r2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9620307748669025"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#val\n",
    "r2_score(y_val, y_pred_rfreg)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hyperparameter tuning (kNN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "parameters_knn = {'n_neighbors' : [5, 7, 9, 11, 13, 15], \n",
    "              'weights': ['uniform', 'distance']}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "rscv_knn = RandomizedSearchCV(knreg,  \n",
    "                     parameters_knn,   \n",
    "                     cv=5, \n",
    "                     scoring='neg_mean_absolute_error')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;background-color: white;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>RandomizedSearchCV(cv=5, estimator=KNeighborsRegressor(),\n",
       "                   param_distributions={&#x27;n_neighbors&#x27;: [5, 7, 9, 11, 13, 15],\n",
       "                                        &#x27;weights&#x27;: [&#x27;uniform&#x27;, &#x27;distance&#x27;]},\n",
       "                   scoring=&#x27;neg_mean_absolute_error&#x27;)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" ><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">RandomizedSearchCV</label><div class=\"sk-toggleable__content\"><pre>RandomizedSearchCV(cv=5, estimator=KNeighborsRegressor(),\n",
       "                   param_distributions={&#x27;n_neighbors&#x27;: [5, 7, 9, 11, 13, 15],\n",
       "                                        &#x27;weights&#x27;: [&#x27;uniform&#x27;, &#x27;distance&#x27;]},\n",
       "                   scoring=&#x27;neg_mean_absolute_error&#x27;)</pre></div></div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" ><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">estimator: KNeighborsRegressor</label><div class=\"sk-toggleable__content\"><pre>KNeighborsRegressor()</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-3\" type=\"checkbox\" ><label for=\"sk-estimator-id-3\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">KNeighborsRegressor</label><div class=\"sk-toggleable__content\"><pre>KNeighborsRegressor()</pre></div></div></div></div></div></div></div></div></div></div>"
      ],
      "text/plain": [
       "RandomizedSearchCV(cv=5, estimator=KNeighborsRegressor(),\n",
       "                   param_distributions={'n_neighbors': [5, 7, 9, 11, 13, 15],\n",
       "                                        'weights': ['uniform', 'distance']},\n",
       "                   scoring='neg_mean_absolute_error')"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rscv_knn.fit(X_train1, y_train1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'weights': 'distance', 'n_neighbors': 5}"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rscv_knn.best_params_"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "kNN (after hyperparameter tuning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "knreg_ht = KNeighborsRegressor(n_neighbors=5, weights='distance')\n",
    "knreg_ht.fit(X_train1, y_train1)\n",
    "y_pred_knreg_ht = knreg_ht.predict(X_val)\n",
    "y_pred_knreg_ht_r2 = knreg_ht.predict(X_train1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.023262477504589936"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mean_absolute_error(y_val, y_pred_knreg_ht)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.004740871118027097"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mean_squared_error(y_val, y_pred_knreg_ht)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.06885398403888549"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mean_squared_error(y_val, y_pred_knreg_ht, squared = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9999562175401843"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#train\n",
    "r2_score(y_train1, y_pred_knreg_ht_r2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9646452408579954"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#val\n",
    "r2_score(y_val, y_pred_knreg_ht)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hyperparameter tuning (RF)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "parameters_rf = {'max_depth': [None, 10, 50, 100],\n",
    "              'max_features': ['auto', 'sqrt'],\n",
    "              'min_samples_leaf': [1, 2, 4],\n",
    "              'min_samples_split': [2, 5, 10],\n",
    "              'n_estimators': [100, 300, 500]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "rscv_rf = RandomizedSearchCV(rfreg,  \n",
    "                     parameters_rf,   \n",
    "                     cv=5, \n",
    "                     scoring='neg_mean_absolute_error',\n",
    "                     n_jobs = -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/andalanputra/opt/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/Users/andalanputra/opt/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/Users/andalanputra/opt/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/Users/andalanputra/opt/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/Users/andalanputra/opt/anaconda3/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
      "  warn(\n",
      "/Users/andalanputra/opt/anaconda3/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
      "  warn(\n",
      "/Users/andalanputra/opt/anaconda3/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
      "  warn(\n",
      "/Users/andalanputra/opt/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/Users/andalanputra/opt/anaconda3/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
      "  warn(\n",
      "/Users/andalanputra/opt/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/Users/andalanputra/opt/anaconda3/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
      "  warn(\n",
      "/Users/andalanputra/opt/anaconda3/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
      "  warn(\n",
      "/Users/andalanputra/opt/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/Users/andalanputra/opt/anaconda3/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
      "  warn(\n",
      "/Users/andalanputra/opt/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/Users/andalanputra/opt/anaconda3/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
      "  warn(\n",
      "/Users/andalanputra/opt/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/Users/andalanputra/opt/anaconda3/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
      "  warn(\n",
      "/Users/andalanputra/opt/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/Users/andalanputra/opt/anaconda3/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
      "  warn(\n",
      "/Users/andalanputra/opt/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/Users/andalanputra/opt/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/Users/andalanputra/opt/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/Users/andalanputra/opt/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/Users/andalanputra/opt/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/Users/andalanputra/opt/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/Users/andalanputra/opt/anaconda3/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
      "  warn(\n",
      "/Users/andalanputra/opt/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/Users/andalanputra/opt/anaconda3/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
      "  warn(\n",
      "/Users/andalanputra/opt/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/Users/andalanputra/opt/anaconda3/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
      "  warn(\n",
      "/Users/andalanputra/opt/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/Users/andalanputra/opt/anaconda3/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
      "  warn(\n",
      "/Users/andalanputra/opt/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/Users/andalanputra/opt/anaconda3/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
      "  warn(\n",
      "/Users/andalanputra/opt/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/Users/andalanputra/opt/anaconda3/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
      "  warn(\n",
      "/Users/andalanputra/opt/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/Users/andalanputra/opt/anaconda3/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
      "  warn(\n",
      "/Users/andalanputra/opt/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/Users/andalanputra/opt/anaconda3/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
      "  warn(\n",
      "/Users/andalanputra/opt/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/Users/andalanputra/opt/anaconda3/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
      "  warn(\n",
      "/Users/andalanputra/opt/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/Users/andalanputra/opt/anaconda3/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
      "  warn(\n",
      "/Users/andalanputra/opt/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/Users/andalanputra/opt/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/Users/andalanputra/opt/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/Users/andalanputra/opt/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/Users/andalanputra/opt/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/Users/andalanputra/opt/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/Users/andalanputra/opt/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/Users/andalanputra/opt/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/Users/andalanputra/opt/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/Users/andalanputra/opt/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/Users/andalanputra/opt/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/Users/andalanputra/opt/anaconda3/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
      "  warn(\n",
      "/Users/andalanputra/opt/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/Users/andalanputra/opt/anaconda3/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
      "  warn(\n",
      "/Users/andalanputra/opt/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/Users/andalanputra/opt/anaconda3/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
      "  warn(\n",
      "/Users/andalanputra/opt/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/Users/andalanputra/opt/anaconda3/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
      "  warn(\n",
      "/Users/andalanputra/opt/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/Users/andalanputra/opt/anaconda3/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
      "  warn(\n",
      "/Users/andalanputra/opt/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/Users/andalanputra/opt/anaconda3/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
      "  warn(\n",
      "/Users/andalanputra/opt/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/Users/andalanputra/opt/anaconda3/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
      "  warn(\n",
      "/Users/andalanputra/opt/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/Users/andalanputra/opt/anaconda3/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
      "  warn(\n",
      "/Users/andalanputra/opt/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/Users/andalanputra/opt/anaconda3/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
      "  warn(\n",
      "/Users/andalanputra/opt/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/Users/andalanputra/opt/anaconda3/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
      "  warn(\n",
      "/Users/andalanputra/opt/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/Users/andalanputra/opt/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/Users/andalanputra/opt/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/Users/andalanputra/opt/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/Users/andalanputra/opt/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/Users/andalanputra/opt/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_search.py:909: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  self.best_estimator_.fit(X, y, **fit_params)\n",
      "/Users/andalanputra/opt/anaconda3/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
      "  warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-2 {color: black;background-color: white;}#sk-container-id-2 pre{padding: 0;}#sk-container-id-2 div.sk-toggleable {background-color: white;}#sk-container-id-2 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-2 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-2 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-2 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-2 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-2 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-2 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-2 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-2 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-2 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-2 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-2 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-2 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-2 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-2 div.sk-item {position: relative;z-index: 1;}#sk-container-id-2 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-2 div.sk-item::before, #sk-container-id-2 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-2 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-2 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-2 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-2 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-2 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-2 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-2 div.sk-label-container {text-align: center;}#sk-container-id-2 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-2 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-2\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>RandomizedSearchCV(cv=5, estimator=RandomForestRegressor(), n_jobs=-1,\n",
       "                   param_distributions={&#x27;max_depth&#x27;: [None, 10, 50, 100],\n",
       "                                        &#x27;max_features&#x27;: [&#x27;auto&#x27;, &#x27;sqrt&#x27;],\n",
       "                                        &#x27;min_samples_leaf&#x27;: [1, 2, 4],\n",
       "                                        &#x27;min_samples_split&#x27;: [2, 5, 10],\n",
       "                                        &#x27;n_estimators&#x27;: [100, 300, 500]},\n",
       "                   scoring=&#x27;neg_mean_absolute_error&#x27;)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-4\" type=\"checkbox\" ><label for=\"sk-estimator-id-4\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">RandomizedSearchCV</label><div class=\"sk-toggleable__content\"><pre>RandomizedSearchCV(cv=5, estimator=RandomForestRegressor(), n_jobs=-1,\n",
       "                   param_distributions={&#x27;max_depth&#x27;: [None, 10, 50, 100],\n",
       "                                        &#x27;max_features&#x27;: [&#x27;auto&#x27;, &#x27;sqrt&#x27;],\n",
       "                                        &#x27;min_samples_leaf&#x27;: [1, 2, 4],\n",
       "                                        &#x27;min_samples_split&#x27;: [2, 5, 10],\n",
       "                                        &#x27;n_estimators&#x27;: [100, 300, 500]},\n",
       "                   scoring=&#x27;neg_mean_absolute_error&#x27;)</pre></div></div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-5\" type=\"checkbox\" ><label for=\"sk-estimator-id-5\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">estimator: RandomForestRegressor</label><div class=\"sk-toggleable__content\"><pre>RandomForestRegressor()</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-6\" type=\"checkbox\" ><label for=\"sk-estimator-id-6\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">RandomForestRegressor</label><div class=\"sk-toggleable__content\"><pre>RandomForestRegressor()</pre></div></div></div></div></div></div></div></div></div></div>"
      ],
      "text/plain": [
       "RandomizedSearchCV(cv=5, estimator=RandomForestRegressor(), n_jobs=-1,\n",
       "                   param_distributions={'max_depth': [None, 10, 50, 100],\n",
       "                                        'max_features': ['auto', 'sqrt'],\n",
       "                                        'min_samples_leaf': [1, 2, 4],\n",
       "                                        'min_samples_split': [2, 5, 10],\n",
       "                                        'n_estimators': [100, 300, 500]},\n",
       "                   scoring='neg_mean_absolute_error')"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rscv_rf.fit(X_train1, y_train1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'n_estimators': 300,\n",
       " 'min_samples_split': 2,\n",
       " 'min_samples_leaf': 2,\n",
       " 'max_features': 'auto',\n",
       " 'max_depth': None}"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rscv_rf.best_params_"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "RF (after hyperparameter tuning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/y1/pjvjlkjn5gl846rnyzr53p340000gn/T/ipykernel_4187/4034257106.py:2: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  rfreg_ht.fit(X_train1, y_train1)\n",
      "/Users/andalanputra/opt/anaconda3/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
      "  warn(\n"
     ]
    }
   ],
   "source": [
    "rfreg_ht = RandomForestRegressor(n_estimators=300, min_samples_leaf=2, min_samples_split=2, max_features='auto', max_depth=None)\n",
    "rfreg_ht.fit(X_train1, y_train1)\n",
    "y_pred_rfreg_ht = rfreg_ht.predict(X_val)\n",
    "y_pred_rfreg_ht_r2 = rfreg_ht.predict(X_train1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.034168612405247066"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mean_absolute_error(y_val, y_pred_rfreg_ht)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.005294319249793771"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mean_squared_error(y_val, y_pred_rfreg_ht)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.07276207287999546"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mean_squared_error(y_val, y_pred_rfreg_ht, squared = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9869102038007755"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#train\n",
    "r2_score(y_train1, y_pred_rfreg_ht_r2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9605179349454175"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#val\n",
    "r2_score(y_val, y_pred_rfreg_ht)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Predicting on the test set (kNN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_knreg_test = knreg_ht.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['y_test_knreg_bert_alpine.pkl']"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import joblib\n",
    "\n",
    "joblib.dump(y_pred_knreg_test, \"y_pred_knreg_test_bert_alpine.pkl\")\n",
    "joblib.dump(y_test, \"y_test_knreg_bert_alpine.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.023684569665941613"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mean_absolute_error(y_test, y_pred_knreg_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.004796549801350592"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mean_squared_error(y_test, y_pred_knreg_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.06925712816274288"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mean_squared_error(y_test, y_pred_knreg_test, squared = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9641274776311746"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "r2_score(y_test, y_pred_knreg_test)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Error analysis (kNN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 576x432 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 432x288 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# assume y_pred is a numpy array and y_true is a pandas dataframe\n",
    "fig, ax = plt.subplots(figsize=(8, 6))\n",
    "\n",
    "column = \"X..Alpha-Pinene\"  # specify the target variable name\n",
    "ax.hist(y_pred_knreg_test, alpha=0.5, label='y_pred', bins=20)\n",
    "ax.hist(y_test[column], alpha=0.5, label='y_true', bins=20)\n",
    "ax.legend(loc='upper right')\n",
    "ax.set_title(column)\n",
    "\n",
    "plt.show()\n",
    "plt.savefig('error_hist_knn_bert_alpine.png')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pearson R (kNN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pearson correlation coefficient: 0.982\n",
      "P-value: 0.000\n"
     ]
    }
   ],
   "source": [
    "corr_coef, p_value = pearsonr(y_pred_knreg_test.flatten(), y_test.values.ravel())\n",
    "\n",
    "print(f\"Pearson correlation coefficient: {corr_coef:.3f}\")\n",
    "print(f\"P-value: {p_value:.3f}\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Predicting on the test set (RF)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_rfreg_test = rfreg_ht.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['y_test_rfreg_bert_alpine.pkl']"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "joblib.dump(y_pred_rfreg_test, \"y_pred_rfreg_test_bert_alpine.pkl\")\n",
    "joblib.dump(y_test, \"y_test_rfreg_bert_alpine.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.034973067303709714"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mean_absolute_error(y_test, y_pred_rfreg_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.005476965673014891"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mean_squared_error(y_test, y_pred_rfreg_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.07400652453003648"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mean_squared_error(y_test, y_pred_rfreg_test, squared = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9590387712511201"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "r2_score(y_test, y_pred_rfreg_test)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Error analysis (RF)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 576x432 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 432x288 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# assume y_pred is a numpy array and y_true is a pandas dataframe\n",
    "fig, ax = plt.subplots(figsize=(8, 6))\n",
    "\n",
    "column = \"X..Alpha-Pinene\"  # specify the target variable name\n",
    "ax.hist(y_pred_rfreg_test, alpha=0.5, label='y_pred', bins=20)\n",
    "ax.hist(y_test[column], alpha=0.5, label='y_true', bins=20)\n",
    "ax.legend(loc='upper right')\n",
    "ax.set_title(column)\n",
    "\n",
    "plt.show()\n",
    "plt.savefig('error_hist_rf_bert_alpine.png')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pearson R (RF)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pearson correlation coefficient: 0.979\n",
      "P-value: 0.000\n"
     ]
    }
   ],
   "source": [
    "corr_coef, p_value = pearsonr(y_pred_rfreg_test.flatten(), y_test.values.ravel())\n",
    "\n",
    "print(f\"Pearson correlation coefficient: {corr_coef:.3f}\")\n",
    "print(f\"P-value: {p_value:.3f}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
