{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn import preprocessing\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.neural_network import MLPRegressor\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "from sklearn.metrics import r2_score\n",
    "from scipy.stats import pearsonr\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.feature_selection import SelectFromModel\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_bert = pd.read_csv(\"df_thc_bert.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>feature_0</th>\n",
       "      <th>feature_1</th>\n",
       "      <th>feature_2</th>\n",
       "      <th>feature_3</th>\n",
       "      <th>feature_4</th>\n",
       "      <th>feature_5</th>\n",
       "      <th>feature_6</th>\n",
       "      <th>feature_7</th>\n",
       "      <th>feature_8</th>\n",
       "      <th>feature_9</th>\n",
       "      <th>...</th>\n",
       "      <th>feature_759</th>\n",
       "      <th>feature_760</th>\n",
       "      <th>feature_761</th>\n",
       "      <th>feature_762</th>\n",
       "      <th>feature_763</th>\n",
       "      <th>feature_764</th>\n",
       "      <th>feature_765</th>\n",
       "      <th>feature_766</th>\n",
       "      <th>feature_767</th>\n",
       "      <th>X..Delta9-THC</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.144370</td>\n",
       "      <td>0.133683</td>\n",
       "      <td>0.558613</td>\n",
       "      <td>0.002472</td>\n",
       "      <td>0.064213</td>\n",
       "      <td>-0.297644</td>\n",
       "      <td>0.649253</td>\n",
       "      <td>0.156834</td>\n",
       "      <td>-0.075428</td>\n",
       "      <td>0.340623</td>\n",
       "      <td>...</td>\n",
       "      <td>0.171215</td>\n",
       "      <td>0.197233</td>\n",
       "      <td>-0.131170</td>\n",
       "      <td>0.210236</td>\n",
       "      <td>-0.728103</td>\n",
       "      <td>0.027258</td>\n",
       "      <td>-0.683708</td>\n",
       "      <td>-0.160281</td>\n",
       "      <td>-0.718498</td>\n",
       "      <td>0.259712</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.227606</td>\n",
       "      <td>0.089886</td>\n",
       "      <td>0.612133</td>\n",
       "      <td>0.085675</td>\n",
       "      <td>0.032208</td>\n",
       "      <td>-0.384907</td>\n",
       "      <td>0.724170</td>\n",
       "      <td>0.154984</td>\n",
       "      <td>-0.061544</td>\n",
       "      <td>0.472168</td>\n",
       "      <td>...</td>\n",
       "      <td>0.149779</td>\n",
       "      <td>0.157919</td>\n",
       "      <td>-0.156806</td>\n",
       "      <td>0.295726</td>\n",
       "      <td>-0.734769</td>\n",
       "      <td>0.099060</td>\n",
       "      <td>-0.779045</td>\n",
       "      <td>-0.190468</td>\n",
       "      <td>-0.830595</td>\n",
       "      <td>0.259712</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.127047</td>\n",
       "      <td>0.111979</td>\n",
       "      <td>0.549845</td>\n",
       "      <td>0.036660</td>\n",
       "      <td>0.026879</td>\n",
       "      <td>-0.309649</td>\n",
       "      <td>0.654963</td>\n",
       "      <td>0.205110</td>\n",
       "      <td>-0.097057</td>\n",
       "      <td>0.405619</td>\n",
       "      <td>...</td>\n",
       "      <td>0.146141</td>\n",
       "      <td>0.174652</td>\n",
       "      <td>-0.146565</td>\n",
       "      <td>0.217158</td>\n",
       "      <td>-0.712819</td>\n",
       "      <td>0.046792</td>\n",
       "      <td>-0.744437</td>\n",
       "      <td>-0.214183</td>\n",
       "      <td>-0.707376</td>\n",
       "      <td>0.259712</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.147638</td>\n",
       "      <td>0.127715</td>\n",
       "      <td>0.509446</td>\n",
       "      <td>0.032539</td>\n",
       "      <td>0.056278</td>\n",
       "      <td>-0.280844</td>\n",
       "      <td>0.527530</td>\n",
       "      <td>0.212648</td>\n",
       "      <td>0.050864</td>\n",
       "      <td>0.356244</td>\n",
       "      <td>...</td>\n",
       "      <td>0.155563</td>\n",
       "      <td>0.164850</td>\n",
       "      <td>-0.106371</td>\n",
       "      <td>0.177229</td>\n",
       "      <td>-0.695585</td>\n",
       "      <td>0.023077</td>\n",
       "      <td>-0.674670</td>\n",
       "      <td>-0.076964</td>\n",
       "      <td>-0.590824</td>\n",
       "      <td>0.259712</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.147638</td>\n",
       "      <td>0.127715</td>\n",
       "      <td>0.509446</td>\n",
       "      <td>0.032539</td>\n",
       "      <td>0.056278</td>\n",
       "      <td>-0.280844</td>\n",
       "      <td>0.527530</td>\n",
       "      <td>0.212648</td>\n",
       "      <td>0.050864</td>\n",
       "      <td>0.356244</td>\n",
       "      <td>...</td>\n",
       "      <td>0.155563</td>\n",
       "      <td>0.164850</td>\n",
       "      <td>-0.106371</td>\n",
       "      <td>0.177229</td>\n",
       "      <td>-0.695585</td>\n",
       "      <td>0.023077</td>\n",
       "      <td>-0.674670</td>\n",
       "      <td>-0.076964</td>\n",
       "      <td>-0.590824</td>\n",
       "      <td>0.259712</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>74995</th>\n",
       "      <td>0.102736</td>\n",
       "      <td>0.135983</td>\n",
       "      <td>0.550969</td>\n",
       "      <td>-0.014671</td>\n",
       "      <td>0.015193</td>\n",
       "      <td>-0.269029</td>\n",
       "      <td>0.679146</td>\n",
       "      <td>0.145063</td>\n",
       "      <td>-0.059002</td>\n",
       "      <td>0.399848</td>\n",
       "      <td>...</td>\n",
       "      <td>0.252791</td>\n",
       "      <td>0.156139</td>\n",
       "      <td>-0.121033</td>\n",
       "      <td>0.199727</td>\n",
       "      <td>-0.782018</td>\n",
       "      <td>-0.003939</td>\n",
       "      <td>-0.664979</td>\n",
       "      <td>-0.150894</td>\n",
       "      <td>-0.634808</td>\n",
       "      <td>0.562557</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>74996</th>\n",
       "      <td>0.233248</td>\n",
       "      <td>0.109718</td>\n",
       "      <td>0.598537</td>\n",
       "      <td>0.061358</td>\n",
       "      <td>0.088095</td>\n",
       "      <td>-0.390093</td>\n",
       "      <td>0.800446</td>\n",
       "      <td>0.077057</td>\n",
       "      <td>-0.104278</td>\n",
       "      <td>0.487628</td>\n",
       "      <td>...</td>\n",
       "      <td>0.195909</td>\n",
       "      <td>0.095593</td>\n",
       "      <td>-0.109210</td>\n",
       "      <td>0.319783</td>\n",
       "      <td>-0.766471</td>\n",
       "      <td>0.119461</td>\n",
       "      <td>-0.819312</td>\n",
       "      <td>-0.167582</td>\n",
       "      <td>-0.830700</td>\n",
       "      <td>0.562557</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>74997</th>\n",
       "      <td>0.233248</td>\n",
       "      <td>0.109718</td>\n",
       "      <td>0.598537</td>\n",
       "      <td>0.061358</td>\n",
       "      <td>0.088095</td>\n",
       "      <td>-0.390093</td>\n",
       "      <td>0.800446</td>\n",
       "      <td>0.077057</td>\n",
       "      <td>-0.104278</td>\n",
       "      <td>0.487628</td>\n",
       "      <td>...</td>\n",
       "      <td>0.195909</td>\n",
       "      <td>0.095593</td>\n",
       "      <td>-0.109210</td>\n",
       "      <td>0.319783</td>\n",
       "      <td>-0.766471</td>\n",
       "      <td>0.119461</td>\n",
       "      <td>-0.819312</td>\n",
       "      <td>-0.167582</td>\n",
       "      <td>-0.830700</td>\n",
       "      <td>0.562557</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>74998</th>\n",
       "      <td>0.282075</td>\n",
       "      <td>0.149575</td>\n",
       "      <td>0.652933</td>\n",
       "      <td>0.145363</td>\n",
       "      <td>0.003963</td>\n",
       "      <td>-0.429747</td>\n",
       "      <td>0.819131</td>\n",
       "      <td>0.018761</td>\n",
       "      <td>-0.133602</td>\n",
       "      <td>0.517085</td>\n",
       "      <td>...</td>\n",
       "      <td>0.133490</td>\n",
       "      <td>0.180182</td>\n",
       "      <td>-0.139251</td>\n",
       "      <td>0.378032</td>\n",
       "      <td>-0.731045</td>\n",
       "      <td>0.157516</td>\n",
       "      <td>-0.825618</td>\n",
       "      <td>-0.148141</td>\n",
       "      <td>-0.877954</td>\n",
       "      <td>0.562557</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>74999</th>\n",
       "      <td>-0.037242</td>\n",
       "      <td>0.322543</td>\n",
       "      <td>0.624075</td>\n",
       "      <td>0.044270</td>\n",
       "      <td>0.237306</td>\n",
       "      <td>-0.169295</td>\n",
       "      <td>0.391078</td>\n",
       "      <td>0.432858</td>\n",
       "      <td>0.122539</td>\n",
       "      <td>0.102900</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.018295</td>\n",
       "      <td>0.240078</td>\n",
       "      <td>-0.080892</td>\n",
       "      <td>0.143712</td>\n",
       "      <td>-0.649160</td>\n",
       "      <td>-0.177820</td>\n",
       "      <td>-0.591682</td>\n",
       "      <td>-0.031716</td>\n",
       "      <td>-0.482195</td>\n",
       "      <td>0.562557</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>75000 rows Ã— 769 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       feature_0  feature_1  feature_2  feature_3  feature_4  feature_5  \\\n",
       "0       0.144370   0.133683   0.558613   0.002472   0.064213  -0.297644   \n",
       "1       0.227606   0.089886   0.612133   0.085675   0.032208  -0.384907   \n",
       "2       0.127047   0.111979   0.549845   0.036660   0.026879  -0.309649   \n",
       "3       0.147638   0.127715   0.509446   0.032539   0.056278  -0.280844   \n",
       "4       0.147638   0.127715   0.509446   0.032539   0.056278  -0.280844   \n",
       "...          ...        ...        ...        ...        ...        ...   \n",
       "74995   0.102736   0.135983   0.550969  -0.014671   0.015193  -0.269029   \n",
       "74996   0.233248   0.109718   0.598537   0.061358   0.088095  -0.390093   \n",
       "74997   0.233248   0.109718   0.598537   0.061358   0.088095  -0.390093   \n",
       "74998   0.282075   0.149575   0.652933   0.145363   0.003963  -0.429747   \n",
       "74999  -0.037242   0.322543   0.624075   0.044270   0.237306  -0.169295   \n",
       "\n",
       "       feature_6  feature_7  feature_8  feature_9  ...  feature_759  \\\n",
       "0       0.649253   0.156834  -0.075428   0.340623  ...     0.171215   \n",
       "1       0.724170   0.154984  -0.061544   0.472168  ...     0.149779   \n",
       "2       0.654963   0.205110  -0.097057   0.405619  ...     0.146141   \n",
       "3       0.527530   0.212648   0.050864   0.356244  ...     0.155563   \n",
       "4       0.527530   0.212648   0.050864   0.356244  ...     0.155563   \n",
       "...          ...        ...        ...        ...  ...          ...   \n",
       "74995   0.679146   0.145063  -0.059002   0.399848  ...     0.252791   \n",
       "74996   0.800446   0.077057  -0.104278   0.487628  ...     0.195909   \n",
       "74997   0.800446   0.077057  -0.104278   0.487628  ...     0.195909   \n",
       "74998   0.819131   0.018761  -0.133602   0.517085  ...     0.133490   \n",
       "74999   0.391078   0.432858   0.122539   0.102900  ...    -0.018295   \n",
       "\n",
       "       feature_760  feature_761  feature_762  feature_763  feature_764  \\\n",
       "0         0.197233    -0.131170     0.210236    -0.728103     0.027258   \n",
       "1         0.157919    -0.156806     0.295726    -0.734769     0.099060   \n",
       "2         0.174652    -0.146565     0.217158    -0.712819     0.046792   \n",
       "3         0.164850    -0.106371     0.177229    -0.695585     0.023077   \n",
       "4         0.164850    -0.106371     0.177229    -0.695585     0.023077   \n",
       "...            ...          ...          ...          ...          ...   \n",
       "74995     0.156139    -0.121033     0.199727    -0.782018    -0.003939   \n",
       "74996     0.095593    -0.109210     0.319783    -0.766471     0.119461   \n",
       "74997     0.095593    -0.109210     0.319783    -0.766471     0.119461   \n",
       "74998     0.180182    -0.139251     0.378032    -0.731045     0.157516   \n",
       "74999     0.240078    -0.080892     0.143712    -0.649160    -0.177820   \n",
       "\n",
       "       feature_765  feature_766  feature_767  X..Delta9-THC  \n",
       "0        -0.683708    -0.160281    -0.718498       0.259712  \n",
       "1        -0.779045    -0.190468    -0.830595       0.259712  \n",
       "2        -0.744437    -0.214183    -0.707376       0.259712  \n",
       "3        -0.674670    -0.076964    -0.590824       0.259712  \n",
       "4        -0.674670    -0.076964    -0.590824       0.259712  \n",
       "...            ...          ...          ...            ...  \n",
       "74995    -0.664979    -0.150894    -0.634808       0.562557  \n",
       "74996    -0.819312    -0.167582    -0.830700       0.562557  \n",
       "74997    -0.819312    -0.167582    -0.830700       0.562557  \n",
       "74998    -0.825618    -0.148141    -0.877954       0.562557  \n",
       "74999    -0.591682    -0.031716    -0.482195       0.562557  \n",
       "\n",
       "[75000 rows x 769 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_bert"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['feature_0',\n",
       " 'feature_1',\n",
       " 'feature_2',\n",
       " 'feature_3',\n",
       " 'feature_4',\n",
       " 'feature_5',\n",
       " 'feature_6',\n",
       " 'feature_7',\n",
       " 'feature_8',\n",
       " 'feature_9',\n",
       " 'feature_10',\n",
       " 'feature_11',\n",
       " 'feature_12',\n",
       " 'feature_13',\n",
       " 'feature_14',\n",
       " 'feature_15',\n",
       " 'feature_16',\n",
       " 'feature_17',\n",
       " 'feature_18',\n",
       " 'feature_19',\n",
       " 'feature_20',\n",
       " 'feature_21',\n",
       " 'feature_22',\n",
       " 'feature_23',\n",
       " 'feature_24',\n",
       " 'feature_25',\n",
       " 'feature_26',\n",
       " 'feature_27',\n",
       " 'feature_28',\n",
       " 'feature_29',\n",
       " 'feature_30',\n",
       " 'feature_31',\n",
       " 'feature_32',\n",
       " 'feature_33',\n",
       " 'feature_34',\n",
       " 'feature_35',\n",
       " 'feature_36',\n",
       " 'feature_37',\n",
       " 'feature_38',\n",
       " 'feature_39',\n",
       " 'feature_40',\n",
       " 'feature_41',\n",
       " 'feature_42',\n",
       " 'feature_43',\n",
       " 'feature_44',\n",
       " 'feature_45',\n",
       " 'feature_46',\n",
       " 'feature_47',\n",
       " 'feature_48',\n",
       " 'feature_49',\n",
       " 'feature_50',\n",
       " 'feature_51',\n",
       " 'feature_52',\n",
       " 'feature_53',\n",
       " 'feature_54',\n",
       " 'feature_55',\n",
       " 'feature_56',\n",
       " 'feature_57',\n",
       " 'feature_58',\n",
       " 'feature_59',\n",
       " 'feature_60',\n",
       " 'feature_61',\n",
       " 'feature_62',\n",
       " 'feature_63',\n",
       " 'feature_64',\n",
       " 'feature_65',\n",
       " 'feature_66',\n",
       " 'feature_67',\n",
       " 'feature_68',\n",
       " 'feature_69',\n",
       " 'feature_70',\n",
       " 'feature_71',\n",
       " 'feature_72',\n",
       " 'feature_73',\n",
       " 'feature_74',\n",
       " 'feature_75',\n",
       " 'feature_76',\n",
       " 'feature_77',\n",
       " 'feature_78',\n",
       " 'feature_79',\n",
       " 'feature_80',\n",
       " 'feature_81',\n",
       " 'feature_82',\n",
       " 'feature_83',\n",
       " 'feature_84',\n",
       " 'feature_85',\n",
       " 'feature_86',\n",
       " 'feature_87',\n",
       " 'feature_88',\n",
       " 'feature_89',\n",
       " 'feature_90',\n",
       " 'feature_91',\n",
       " 'feature_92',\n",
       " 'feature_93',\n",
       " 'feature_94',\n",
       " 'feature_95',\n",
       " 'feature_96',\n",
       " 'feature_97',\n",
       " 'feature_98',\n",
       " 'feature_99',\n",
       " 'feature_100',\n",
       " 'feature_101',\n",
       " 'feature_102',\n",
       " 'feature_103',\n",
       " 'feature_104',\n",
       " 'feature_105',\n",
       " 'feature_106',\n",
       " 'feature_107',\n",
       " 'feature_108',\n",
       " 'feature_109',\n",
       " 'feature_110',\n",
       " 'feature_111',\n",
       " 'feature_112',\n",
       " 'feature_113',\n",
       " 'feature_114',\n",
       " 'feature_115',\n",
       " 'feature_116',\n",
       " 'feature_117',\n",
       " 'feature_118',\n",
       " 'feature_119',\n",
       " 'feature_120',\n",
       " 'feature_121',\n",
       " 'feature_122',\n",
       " 'feature_123',\n",
       " 'feature_124',\n",
       " 'feature_125',\n",
       " 'feature_126',\n",
       " 'feature_127',\n",
       " 'feature_128',\n",
       " 'feature_129',\n",
       " 'feature_130',\n",
       " 'feature_131',\n",
       " 'feature_132',\n",
       " 'feature_133',\n",
       " 'feature_134',\n",
       " 'feature_135',\n",
       " 'feature_136',\n",
       " 'feature_137',\n",
       " 'feature_138',\n",
       " 'feature_139',\n",
       " 'feature_140',\n",
       " 'feature_141',\n",
       " 'feature_142',\n",
       " 'feature_143',\n",
       " 'feature_144',\n",
       " 'feature_145',\n",
       " 'feature_146',\n",
       " 'feature_147',\n",
       " 'feature_148',\n",
       " 'feature_149',\n",
       " 'feature_150',\n",
       " 'feature_151',\n",
       " 'feature_152',\n",
       " 'feature_153',\n",
       " 'feature_154',\n",
       " 'feature_155',\n",
       " 'feature_156',\n",
       " 'feature_157',\n",
       " 'feature_158',\n",
       " 'feature_159',\n",
       " 'feature_160',\n",
       " 'feature_161',\n",
       " 'feature_162',\n",
       " 'feature_163',\n",
       " 'feature_164',\n",
       " 'feature_165',\n",
       " 'feature_166',\n",
       " 'feature_167',\n",
       " 'feature_168',\n",
       " 'feature_169',\n",
       " 'feature_170',\n",
       " 'feature_171',\n",
       " 'feature_172',\n",
       " 'feature_173',\n",
       " 'feature_174',\n",
       " 'feature_175',\n",
       " 'feature_176',\n",
       " 'feature_177',\n",
       " 'feature_178',\n",
       " 'feature_179',\n",
       " 'feature_180',\n",
       " 'feature_181',\n",
       " 'feature_182',\n",
       " 'feature_183',\n",
       " 'feature_184',\n",
       " 'feature_185',\n",
       " 'feature_186',\n",
       " 'feature_187',\n",
       " 'feature_188',\n",
       " 'feature_189',\n",
       " 'feature_190',\n",
       " 'feature_191',\n",
       " 'feature_192',\n",
       " 'feature_193',\n",
       " 'feature_194',\n",
       " 'feature_195',\n",
       " 'feature_196',\n",
       " 'feature_197',\n",
       " 'feature_198',\n",
       " 'feature_199',\n",
       " 'feature_200',\n",
       " 'feature_201',\n",
       " 'feature_202',\n",
       " 'feature_203',\n",
       " 'feature_204',\n",
       " 'feature_205',\n",
       " 'feature_206',\n",
       " 'feature_207',\n",
       " 'feature_208',\n",
       " 'feature_209',\n",
       " 'feature_210',\n",
       " 'feature_211',\n",
       " 'feature_212',\n",
       " 'feature_213',\n",
       " 'feature_214',\n",
       " 'feature_215',\n",
       " 'feature_216',\n",
       " 'feature_217',\n",
       " 'feature_218',\n",
       " 'feature_219',\n",
       " 'feature_220',\n",
       " 'feature_221',\n",
       " 'feature_222',\n",
       " 'feature_223',\n",
       " 'feature_224',\n",
       " 'feature_225',\n",
       " 'feature_226',\n",
       " 'feature_227',\n",
       " 'feature_228',\n",
       " 'feature_229',\n",
       " 'feature_230',\n",
       " 'feature_231',\n",
       " 'feature_232',\n",
       " 'feature_233',\n",
       " 'feature_234',\n",
       " 'feature_235',\n",
       " 'feature_236',\n",
       " 'feature_237',\n",
       " 'feature_238',\n",
       " 'feature_239',\n",
       " 'feature_240',\n",
       " 'feature_241',\n",
       " 'feature_242',\n",
       " 'feature_243',\n",
       " 'feature_244',\n",
       " 'feature_245',\n",
       " 'feature_246',\n",
       " 'feature_247',\n",
       " 'feature_248',\n",
       " 'feature_249',\n",
       " 'feature_250',\n",
       " 'feature_251',\n",
       " 'feature_252',\n",
       " 'feature_253',\n",
       " 'feature_254',\n",
       " 'feature_255',\n",
       " 'feature_256',\n",
       " 'feature_257',\n",
       " 'feature_258',\n",
       " 'feature_259',\n",
       " 'feature_260',\n",
       " 'feature_261',\n",
       " 'feature_262',\n",
       " 'feature_263',\n",
       " 'feature_264',\n",
       " 'feature_265',\n",
       " 'feature_266',\n",
       " 'feature_267',\n",
       " 'feature_268',\n",
       " 'feature_269',\n",
       " 'feature_270',\n",
       " 'feature_271',\n",
       " 'feature_272',\n",
       " 'feature_273',\n",
       " 'feature_274',\n",
       " 'feature_275',\n",
       " 'feature_276',\n",
       " 'feature_277',\n",
       " 'feature_278',\n",
       " 'feature_279',\n",
       " 'feature_280',\n",
       " 'feature_281',\n",
       " 'feature_282',\n",
       " 'feature_283',\n",
       " 'feature_284',\n",
       " 'feature_285',\n",
       " 'feature_286',\n",
       " 'feature_287',\n",
       " 'feature_288',\n",
       " 'feature_289',\n",
       " 'feature_290',\n",
       " 'feature_291',\n",
       " 'feature_292',\n",
       " 'feature_293',\n",
       " 'feature_294',\n",
       " 'feature_295',\n",
       " 'feature_296',\n",
       " 'feature_297',\n",
       " 'feature_298',\n",
       " 'feature_299',\n",
       " 'feature_300',\n",
       " 'feature_301',\n",
       " 'feature_302',\n",
       " 'feature_303',\n",
       " 'feature_304',\n",
       " 'feature_305',\n",
       " 'feature_306',\n",
       " 'feature_307',\n",
       " 'feature_308',\n",
       " 'feature_309',\n",
       " 'feature_310',\n",
       " 'feature_311',\n",
       " 'feature_312',\n",
       " 'feature_313',\n",
       " 'feature_314',\n",
       " 'feature_315',\n",
       " 'feature_316',\n",
       " 'feature_317',\n",
       " 'feature_318',\n",
       " 'feature_319',\n",
       " 'feature_320',\n",
       " 'feature_321',\n",
       " 'feature_322',\n",
       " 'feature_323',\n",
       " 'feature_324',\n",
       " 'feature_325',\n",
       " 'feature_326',\n",
       " 'feature_327',\n",
       " 'feature_328',\n",
       " 'feature_329',\n",
       " 'feature_330',\n",
       " 'feature_331',\n",
       " 'feature_332',\n",
       " 'feature_333',\n",
       " 'feature_334',\n",
       " 'feature_335',\n",
       " 'feature_336',\n",
       " 'feature_337',\n",
       " 'feature_338',\n",
       " 'feature_339',\n",
       " 'feature_340',\n",
       " 'feature_341',\n",
       " 'feature_342',\n",
       " 'feature_343',\n",
       " 'feature_344',\n",
       " 'feature_345',\n",
       " 'feature_346',\n",
       " 'feature_347',\n",
       " 'feature_348',\n",
       " 'feature_349',\n",
       " 'feature_350',\n",
       " 'feature_351',\n",
       " 'feature_352',\n",
       " 'feature_353',\n",
       " 'feature_354',\n",
       " 'feature_355',\n",
       " 'feature_356',\n",
       " 'feature_357',\n",
       " 'feature_358',\n",
       " 'feature_359',\n",
       " 'feature_360',\n",
       " 'feature_361',\n",
       " 'feature_362',\n",
       " 'feature_363',\n",
       " 'feature_364',\n",
       " 'feature_365',\n",
       " 'feature_366',\n",
       " 'feature_367',\n",
       " 'feature_368',\n",
       " 'feature_369',\n",
       " 'feature_370',\n",
       " 'feature_371',\n",
       " 'feature_372',\n",
       " 'feature_373',\n",
       " 'feature_374',\n",
       " 'feature_375',\n",
       " 'feature_376',\n",
       " 'feature_377',\n",
       " 'feature_378',\n",
       " 'feature_379',\n",
       " 'feature_380',\n",
       " 'feature_381',\n",
       " 'feature_382',\n",
       " 'feature_383',\n",
       " 'feature_384',\n",
       " 'feature_385',\n",
       " 'feature_386',\n",
       " 'feature_387',\n",
       " 'feature_388',\n",
       " 'feature_389',\n",
       " 'feature_390',\n",
       " 'feature_391',\n",
       " 'feature_392',\n",
       " 'feature_393',\n",
       " 'feature_394',\n",
       " 'feature_395',\n",
       " 'feature_396',\n",
       " 'feature_397',\n",
       " 'feature_398',\n",
       " 'feature_399',\n",
       " 'feature_400',\n",
       " 'feature_401',\n",
       " 'feature_402',\n",
       " 'feature_403',\n",
       " 'feature_404',\n",
       " 'feature_405',\n",
       " 'feature_406',\n",
       " 'feature_407',\n",
       " 'feature_408',\n",
       " 'feature_409',\n",
       " 'feature_410',\n",
       " 'feature_411',\n",
       " 'feature_412',\n",
       " 'feature_413',\n",
       " 'feature_414',\n",
       " 'feature_415',\n",
       " 'feature_416',\n",
       " 'feature_417',\n",
       " 'feature_418',\n",
       " 'feature_419',\n",
       " 'feature_420',\n",
       " 'feature_421',\n",
       " 'feature_422',\n",
       " 'feature_423',\n",
       " 'feature_424',\n",
       " 'feature_425',\n",
       " 'feature_426',\n",
       " 'feature_427',\n",
       " 'feature_428',\n",
       " 'feature_429',\n",
       " 'feature_430',\n",
       " 'feature_431',\n",
       " 'feature_432',\n",
       " 'feature_433',\n",
       " 'feature_434',\n",
       " 'feature_435',\n",
       " 'feature_436',\n",
       " 'feature_437',\n",
       " 'feature_438',\n",
       " 'feature_439',\n",
       " 'feature_440',\n",
       " 'feature_441',\n",
       " 'feature_442',\n",
       " 'feature_443',\n",
       " 'feature_444',\n",
       " 'feature_445',\n",
       " 'feature_446',\n",
       " 'feature_447',\n",
       " 'feature_448',\n",
       " 'feature_449',\n",
       " 'feature_450',\n",
       " 'feature_451',\n",
       " 'feature_452',\n",
       " 'feature_453',\n",
       " 'feature_454',\n",
       " 'feature_455',\n",
       " 'feature_456',\n",
       " 'feature_457',\n",
       " 'feature_458',\n",
       " 'feature_459',\n",
       " 'feature_460',\n",
       " 'feature_461',\n",
       " 'feature_462',\n",
       " 'feature_463',\n",
       " 'feature_464',\n",
       " 'feature_465',\n",
       " 'feature_466',\n",
       " 'feature_467',\n",
       " 'feature_468',\n",
       " 'feature_469',\n",
       " 'feature_470',\n",
       " 'feature_471',\n",
       " 'feature_472',\n",
       " 'feature_473',\n",
       " 'feature_474',\n",
       " 'feature_475',\n",
       " 'feature_476',\n",
       " 'feature_477',\n",
       " 'feature_478',\n",
       " 'feature_479',\n",
       " 'feature_480',\n",
       " 'feature_481',\n",
       " 'feature_482',\n",
       " 'feature_483',\n",
       " 'feature_484',\n",
       " 'feature_485',\n",
       " 'feature_486',\n",
       " 'feature_487',\n",
       " 'feature_488',\n",
       " 'feature_489',\n",
       " 'feature_490',\n",
       " 'feature_491',\n",
       " 'feature_492',\n",
       " 'feature_493',\n",
       " 'feature_494',\n",
       " 'feature_495',\n",
       " 'feature_496',\n",
       " 'feature_497',\n",
       " 'feature_498',\n",
       " 'feature_499',\n",
       " 'feature_500',\n",
       " 'feature_501',\n",
       " 'feature_502',\n",
       " 'feature_503',\n",
       " 'feature_504',\n",
       " 'feature_505',\n",
       " 'feature_506',\n",
       " 'feature_507',\n",
       " 'feature_508',\n",
       " 'feature_509',\n",
       " 'feature_510',\n",
       " 'feature_511',\n",
       " 'feature_512',\n",
       " 'feature_513',\n",
       " 'feature_514',\n",
       " 'feature_515',\n",
       " 'feature_516',\n",
       " 'feature_517',\n",
       " 'feature_518',\n",
       " 'feature_519',\n",
       " 'feature_520',\n",
       " 'feature_521',\n",
       " 'feature_522',\n",
       " 'feature_523',\n",
       " 'feature_524',\n",
       " 'feature_525',\n",
       " 'feature_526',\n",
       " 'feature_527',\n",
       " 'feature_528',\n",
       " 'feature_529',\n",
       " 'feature_530',\n",
       " 'feature_531',\n",
       " 'feature_532',\n",
       " 'feature_533',\n",
       " 'feature_534',\n",
       " 'feature_535',\n",
       " 'feature_536',\n",
       " 'feature_537',\n",
       " 'feature_538',\n",
       " 'feature_539',\n",
       " 'feature_540',\n",
       " 'feature_541',\n",
       " 'feature_542',\n",
       " 'feature_543',\n",
       " 'feature_544',\n",
       " 'feature_545',\n",
       " 'feature_546',\n",
       " 'feature_547',\n",
       " 'feature_548',\n",
       " 'feature_549',\n",
       " 'feature_550',\n",
       " 'feature_551',\n",
       " 'feature_552',\n",
       " 'feature_553',\n",
       " 'feature_554',\n",
       " 'feature_555',\n",
       " 'feature_556',\n",
       " 'feature_557',\n",
       " 'feature_558',\n",
       " 'feature_559',\n",
       " 'feature_560',\n",
       " 'feature_561',\n",
       " 'feature_562',\n",
       " 'feature_563',\n",
       " 'feature_564',\n",
       " 'feature_565',\n",
       " 'feature_566',\n",
       " 'feature_567',\n",
       " 'feature_568',\n",
       " 'feature_569',\n",
       " 'feature_570',\n",
       " 'feature_571',\n",
       " 'feature_572',\n",
       " 'feature_573',\n",
       " 'feature_574',\n",
       " 'feature_575',\n",
       " 'feature_576',\n",
       " 'feature_577',\n",
       " 'feature_578',\n",
       " 'feature_579',\n",
       " 'feature_580',\n",
       " 'feature_581',\n",
       " 'feature_582',\n",
       " 'feature_583',\n",
       " 'feature_584',\n",
       " 'feature_585',\n",
       " 'feature_586',\n",
       " 'feature_587',\n",
       " 'feature_588',\n",
       " 'feature_589',\n",
       " 'feature_590',\n",
       " 'feature_591',\n",
       " 'feature_592',\n",
       " 'feature_593',\n",
       " 'feature_594',\n",
       " 'feature_595',\n",
       " 'feature_596',\n",
       " 'feature_597',\n",
       " 'feature_598',\n",
       " 'feature_599',\n",
       " 'feature_600',\n",
       " 'feature_601',\n",
       " 'feature_602',\n",
       " 'feature_603',\n",
       " 'feature_604',\n",
       " 'feature_605',\n",
       " 'feature_606',\n",
       " 'feature_607',\n",
       " 'feature_608',\n",
       " 'feature_609',\n",
       " 'feature_610',\n",
       " 'feature_611',\n",
       " 'feature_612',\n",
       " 'feature_613',\n",
       " 'feature_614',\n",
       " 'feature_615',\n",
       " 'feature_616',\n",
       " 'feature_617',\n",
       " 'feature_618',\n",
       " 'feature_619',\n",
       " 'feature_620',\n",
       " 'feature_621',\n",
       " 'feature_622',\n",
       " 'feature_623',\n",
       " 'feature_624',\n",
       " 'feature_625',\n",
       " 'feature_626',\n",
       " 'feature_627',\n",
       " 'feature_628',\n",
       " 'feature_629',\n",
       " 'feature_630',\n",
       " 'feature_631',\n",
       " 'feature_632',\n",
       " 'feature_633',\n",
       " 'feature_634',\n",
       " 'feature_635',\n",
       " 'feature_636',\n",
       " 'feature_637',\n",
       " 'feature_638',\n",
       " 'feature_639',\n",
       " 'feature_640',\n",
       " 'feature_641',\n",
       " 'feature_642',\n",
       " 'feature_643',\n",
       " 'feature_644',\n",
       " 'feature_645',\n",
       " 'feature_646',\n",
       " 'feature_647',\n",
       " 'feature_648',\n",
       " 'feature_649',\n",
       " 'feature_650',\n",
       " 'feature_651',\n",
       " 'feature_652',\n",
       " 'feature_653',\n",
       " 'feature_654',\n",
       " 'feature_655',\n",
       " 'feature_656',\n",
       " 'feature_657',\n",
       " 'feature_658',\n",
       " 'feature_659',\n",
       " 'feature_660',\n",
       " 'feature_661',\n",
       " 'feature_662',\n",
       " 'feature_663',\n",
       " 'feature_664',\n",
       " 'feature_665',\n",
       " 'feature_666',\n",
       " 'feature_667',\n",
       " 'feature_668',\n",
       " 'feature_669',\n",
       " 'feature_670',\n",
       " 'feature_671',\n",
       " 'feature_672',\n",
       " 'feature_673',\n",
       " 'feature_674',\n",
       " 'feature_675',\n",
       " 'feature_676',\n",
       " 'feature_677',\n",
       " 'feature_678',\n",
       " 'feature_679',\n",
       " 'feature_680',\n",
       " 'feature_681',\n",
       " 'feature_682',\n",
       " 'feature_683',\n",
       " 'feature_684',\n",
       " 'feature_685',\n",
       " 'feature_686',\n",
       " 'feature_687',\n",
       " 'feature_688',\n",
       " 'feature_689',\n",
       " 'feature_690',\n",
       " 'feature_691',\n",
       " 'feature_692',\n",
       " 'feature_693',\n",
       " 'feature_694',\n",
       " 'feature_695',\n",
       " 'feature_696',\n",
       " 'feature_697',\n",
       " 'feature_698',\n",
       " 'feature_699',\n",
       " 'feature_700',\n",
       " 'feature_701',\n",
       " 'feature_702',\n",
       " 'feature_703',\n",
       " 'feature_704',\n",
       " 'feature_705',\n",
       " 'feature_706',\n",
       " 'feature_707',\n",
       " 'feature_708',\n",
       " 'feature_709',\n",
       " 'feature_710',\n",
       " 'feature_711',\n",
       " 'feature_712',\n",
       " 'feature_713',\n",
       " 'feature_714',\n",
       " 'feature_715',\n",
       " 'feature_716',\n",
       " 'feature_717',\n",
       " 'feature_718',\n",
       " 'feature_719',\n",
       " 'feature_720',\n",
       " 'feature_721',\n",
       " 'feature_722',\n",
       " 'feature_723',\n",
       " 'feature_724',\n",
       " 'feature_725',\n",
       " 'feature_726',\n",
       " 'feature_727',\n",
       " 'feature_728',\n",
       " 'feature_729',\n",
       " 'feature_730',\n",
       " 'feature_731',\n",
       " 'feature_732',\n",
       " 'feature_733',\n",
       " 'feature_734',\n",
       " 'feature_735',\n",
       " 'feature_736',\n",
       " 'feature_737',\n",
       " 'feature_738',\n",
       " 'feature_739',\n",
       " 'feature_740',\n",
       " 'feature_741',\n",
       " 'feature_742',\n",
       " 'feature_743',\n",
       " 'feature_744',\n",
       " 'feature_745',\n",
       " 'feature_746',\n",
       " 'feature_747',\n",
       " 'feature_748',\n",
       " 'feature_749',\n",
       " 'feature_750',\n",
       " 'feature_751',\n",
       " 'feature_752',\n",
       " 'feature_753',\n",
       " 'feature_754',\n",
       " 'feature_755',\n",
       " 'feature_756',\n",
       " 'feature_757',\n",
       " 'feature_758',\n",
       " 'feature_759',\n",
       " 'feature_760',\n",
       " 'feature_761',\n",
       " 'feature_762',\n",
       " 'feature_763',\n",
       " 'feature_764',\n",
       " 'feature_765',\n",
       " 'feature_766',\n",
       " 'feature_767',\n",
       " 'X..Delta9-THC']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_bert.columns.to_list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df_bert.drop(['X..Delta9-THC'], axis = 1)\n",
    "y = df_bert[['X..Delta9-THC']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:ylabel='Count'>"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "sns.histplot(y, bins = 10)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "pca = PCA()\n",
    "pca_comps = pca.fit_transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 1.82862399e+00, -4.81264027e-01, -3.01878132e-01, ...,\n",
       "        -1.42067069e-03, -2.78117730e-03, -3.73333997e-08],\n",
       "       [-5.90762171e-01, -2.22884508e-01,  4.56214413e-01, ...,\n",
       "         2.17128574e-03, -2.04978292e-03, -5.23831009e-08],\n",
       "       [ 1.26790371e+00, -7.66551682e-01,  1.85513943e-01, ...,\n",
       "         1.72883353e-03,  1.10304671e-03,  1.04165116e-08],\n",
       "       ...,\n",
       "       [-1.55898664e+00,  3.02103437e-01, -2.56493884e-01, ...,\n",
       "         1.08725230e-03,  4.09395085e-04, -2.99944514e-08],\n",
       "       [-2.51428753e+00,  9.83616211e-01, -5.53439318e-02, ...,\n",
       "         9.26741678e-04, -1.65927873e-03,  7.01640358e-08],\n",
       "       [ 6.07634588e+00,  1.11721700e+00,  7.11153776e-01, ...,\n",
       "        -4.90539054e-03,  1.09360411e-02, -1.38106006e-08]])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pca_comps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "numpy.ndarray"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(pca_comps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "explained_variance = pca.explained_variance_ratio_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(range(1, len(explained_variance)+1), explained_variance, 'bo-', linewidth=2)\n",
    "plt.xlabel('Number of components')\n",
    "plt.ylabel('Explained variance ratio')\n",
    "plt.title('Scree Plot')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the second derivative of the explained variance ratio curve\n",
    "second_der = np.diff(explained_variance, 2)\n",
    "\n",
    "# Find the index of the maximum value of the second derivative\n",
    "elbow_index = np.argmax(second_der) + 1\n",
    "\n",
    "# The optimal number of components is the index of the elbow point\n",
    "n_components_optimal = elbow_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n_components_optimal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_reduced = pca.transform(X)[:, :n_components_optimal]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 1.82862399],\n",
       "       [-0.59076217],\n",
       "       [ 1.26790371],\n",
       "       ...,\n",
       "       [-1.55898664],\n",
       "       [-2.51428753],\n",
       "       [ 6.07634588]])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_reduced"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pca_0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.828624</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.590762</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.267904</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2.350363</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2.350363</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>74995</th>\n",
       "      <td>1.679089</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>74996</th>\n",
       "      <td>-1.558987</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>74997</th>\n",
       "      <td>-1.558987</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>74998</th>\n",
       "      <td>-2.514288</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>74999</th>\n",
       "      <td>6.076346</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>75000 rows Ã— 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          pca_0\n",
       "0      1.828624\n",
       "1     -0.590762\n",
       "2      1.267904\n",
       "3      2.350363\n",
       "4      2.350363\n",
       "...         ...\n",
       "74995  1.679089\n",
       "74996 -1.558987\n",
       "74997 -1.558987\n",
       "74998 -2.514288\n",
       "74999  6.076346\n",
       "\n",
       "[75000 rows x 1 columns]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_reduced = pd.DataFrame(X_reduced)\n",
    "X_reduced = X_reduced.add_prefix('pca_')\n",
    "X_reduced"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "train test split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X_reduced, y, random_state=1, test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train1, X_val, y_train1, y_val = train_test_split(X_train, y_train, random_state=1, test_size=0.2)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "kNN (before feature selection and hyperparameter tuning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "knreg = KNeighborsRegressor()\n",
    "knreg.fit(X_train1, y_train1)\n",
    "y_pred_knreg = knreg.predict(X_val)\n",
    "y_pred_knreg_r2 = knreg.predict(X_train1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.12151380083549289"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mean_absolute_error(y_val, y_pred_knreg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.03433505785138832"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mean_squared_error(y_val, y_pred_knreg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.1852972149045644"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mean_squared_error(y_val, y_pred_knreg, squared = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.754674466116193"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#train\n",
    "r2_score(y_train1, y_pred_knreg_r2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5819566148279283"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#val\n",
    "r2_score(y_val, y_pred_knreg)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "RF (before feature selection and hyperparameter tuning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/y1/pjvjlkjn5gl846rnyzr53p340000gn/T/ipykernel_2965/2685114911.py:2: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  rfreg.fit(X_train1, y_train1)\n"
     ]
    }
   ],
   "source": [
    "rfreg = RandomForestRegressor()\n",
    "rfreg.fit(X_train1, y_train1)\n",
    "y_pred_rfreg = rfreg.predict(X_val)\n",
    "y_pred_rfreg_r2 = rfreg.predict(X_train1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.07419000260162552"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mean_absolute_error(y_val, y_pred_rfreg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.01994339228189857"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mean_squared_error(y_val, y_pred_rfreg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.14122107591255129"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mean_squared_error(y_val, y_pred_rfreg, squared = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9640583850772183"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#train\n",
    "r2_score(y_train1, y_pred_rfreg_r2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7571810346898152"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#val\n",
    "r2_score(y_val, y_pred_rfreg)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hyperparameter tuning (kNN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "parameters_knn = {'n_neighbors' : [5, 7, 9, 11, 13, 15], \n",
    "              'weights': ['uniform', 'distance']}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "rscv_knn = RandomizedSearchCV(knreg,  \n",
    "                     parameters_knn,   \n",
    "                     cv=5, \n",
    "                     scoring='neg_mean_absolute_error')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;background-color: white;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"â–¸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"â–¾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>RandomizedSearchCV(cv=5, estimator=KNeighborsRegressor(),\n",
       "                   param_distributions={&#x27;n_neighbors&#x27;: [5, 7, 9, 11, 13, 15],\n",
       "                                        &#x27;weights&#x27;: [&#x27;uniform&#x27;, &#x27;distance&#x27;]},\n",
       "                   scoring=&#x27;neg_mean_absolute_error&#x27;)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" ><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">RandomizedSearchCV</label><div class=\"sk-toggleable__content\"><pre>RandomizedSearchCV(cv=5, estimator=KNeighborsRegressor(),\n",
       "                   param_distributions={&#x27;n_neighbors&#x27;: [5, 7, 9, 11, 13, 15],\n",
       "                                        &#x27;weights&#x27;: [&#x27;uniform&#x27;, &#x27;distance&#x27;]},\n",
       "                   scoring=&#x27;neg_mean_absolute_error&#x27;)</pre></div></div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" ><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">estimator: KNeighborsRegressor</label><div class=\"sk-toggleable__content\"><pre>KNeighborsRegressor()</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-3\" type=\"checkbox\" ><label for=\"sk-estimator-id-3\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">KNeighborsRegressor</label><div class=\"sk-toggleable__content\"><pre>KNeighborsRegressor()</pre></div></div></div></div></div></div></div></div></div></div>"
      ],
      "text/plain": [
       "RandomizedSearchCV(cv=5, estimator=KNeighborsRegressor(),\n",
       "                   param_distributions={'n_neighbors': [5, 7, 9, 11, 13, 15],\n",
       "                                        'weights': ['uniform', 'distance']},\n",
       "                   scoring='neg_mean_absolute_error')"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rscv_knn.fit(X_train1, y_train1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'weights': 'distance', 'n_neighbors': 15}"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rscv_knn.best_params_"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "kNN (after hyperparameter tuning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "knreg_ht = KNeighborsRegressor(n_neighbors=15, weights='distance')\n",
    "knreg_ht.fit(X_train1, y_train1)\n",
    "y_pred_knreg_ht = knreg_ht.predict(X_val)\n",
    "y_pred_knreg_ht_r2 = knreg_ht.predict(X_train1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.04482200128179678"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mean_absolute_error(y_val, y_pred_knreg_ht)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.01468773318949115"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mean_squared_error(y_val, y_pred_knreg_ht)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.12119295849797194"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mean_squared_error(y_val, y_pred_knreg_ht, squared = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9993756911072241"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#train\n",
    "r2_score(y_train1, y_pred_knreg_ht_r2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8211708356626287"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#val\n",
    "r2_score(y_val, y_pred_knreg_ht)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hyperparameter tuning (RF)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "parameters_rf = {'max_depth': [None, 10, 50, 100],\n",
    "              'max_features': ['auto', 'sqrt'],\n",
    "              'min_samples_leaf': [1, 2, 4],\n",
    "              'min_samples_split': [2, 5, 10],\n",
    "              'n_estimators': [100, 300, 500]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "rscv_rf = RandomizedSearchCV(rfreg,  \n",
    "                     parameters_rf,   \n",
    "                     cv=5, \n",
    "                     scoring='neg_mean_absolute_error',\n",
    "                     n_jobs = -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/andalanputra/opt/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/Users/andalanputra/opt/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/Users/andalanputra/opt/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/Users/andalanputra/opt/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/Users/andalanputra/opt/anaconda3/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
      "  warn(\n",
      "/Users/andalanputra/opt/anaconda3/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
      "  warn(\n",
      "/Users/andalanputra/opt/anaconda3/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
      "  warn(\n",
      "/Users/andalanputra/opt/anaconda3/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
      "  warn(\n",
      "/Users/andalanputra/opt/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/Users/andalanputra/opt/anaconda3/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
      "  warn(\n",
      "/Users/andalanputra/opt/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/Users/andalanputra/opt/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/Users/andalanputra/opt/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/Users/andalanputra/opt/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/Users/andalanputra/opt/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/Users/andalanputra/opt/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/Users/andalanputra/opt/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/Users/andalanputra/opt/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/Users/andalanputra/opt/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/Users/andalanputra/opt/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/Users/andalanputra/opt/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/Users/andalanputra/opt/anaconda3/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
      "  warn(\n",
      "/Users/andalanputra/opt/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/Users/andalanputra/opt/anaconda3/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
      "  warn(\n",
      "/Users/andalanputra/opt/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/Users/andalanputra/opt/anaconda3/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
      "  warn(\n",
      "/Users/andalanputra/opt/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/Users/andalanputra/opt/anaconda3/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
      "  warn(\n",
      "/Users/andalanputra/opt/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/Users/andalanputra/opt/anaconda3/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
      "  warn(\n",
      "/Users/andalanputra/opt/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/Users/andalanputra/opt/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/Users/andalanputra/opt/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/Users/andalanputra/opt/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/Users/andalanputra/opt/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/Users/andalanputra/opt/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/Users/andalanputra/opt/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/Users/andalanputra/opt/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/Users/andalanputra/opt/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/Users/andalanputra/opt/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/Users/andalanputra/opt/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/Users/andalanputra/opt/anaconda3/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
      "  warn(\n",
      "/Users/andalanputra/opt/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/Users/andalanputra/opt/anaconda3/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
      "  warn(\n",
      "/Users/andalanputra/opt/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/Users/andalanputra/opt/anaconda3/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
      "  warn(\n",
      "/Users/andalanputra/opt/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/Users/andalanputra/opt/anaconda3/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
      "  warn(\n",
      "/Users/andalanputra/opt/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/Users/andalanputra/opt/anaconda3/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
      "  warn(\n",
      "/Users/andalanputra/opt/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/Users/andalanputra/opt/anaconda3/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
      "  warn(\n",
      "/Users/andalanputra/opt/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/Users/andalanputra/opt/anaconda3/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
      "  warn(\n",
      "/Users/andalanputra/opt/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/Users/andalanputra/opt/anaconda3/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
      "  warn(\n",
      "/Users/andalanputra/opt/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/Users/andalanputra/opt/anaconda3/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
      "  warn(\n",
      "/Users/andalanputra/opt/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/Users/andalanputra/opt/anaconda3/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
      "  warn(\n",
      "/Users/andalanputra/opt/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/Users/andalanputra/opt/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/Users/andalanputra/opt/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/Users/andalanputra/opt/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/Users/andalanputra/opt/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/Users/andalanputra/opt/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/Users/andalanputra/opt/anaconda3/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
      "  warn(\n",
      "/Users/andalanputra/opt/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/Users/andalanputra/opt/anaconda3/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
      "  warn(\n",
      "/Users/andalanputra/opt/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/Users/andalanputra/opt/anaconda3/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
      "  warn(\n",
      "/Users/andalanputra/opt/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/Users/andalanputra/opt/anaconda3/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
      "  warn(\n",
      "/Users/andalanputra/opt/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/Users/andalanputra/opt/anaconda3/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
      "  warn(\n",
      "/Users/andalanputra/opt/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_search.py:909: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  self.best_estimator_.fit(X, y, **fit_params)\n",
      "/Users/andalanputra/opt/anaconda3/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
      "  warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-2 {color: black;background-color: white;}#sk-container-id-2 pre{padding: 0;}#sk-container-id-2 div.sk-toggleable {background-color: white;}#sk-container-id-2 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-2 label.sk-toggleable__label-arrow:before {content: \"â–¸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-2 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-2 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-2 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-2 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-2 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-2 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"â–¾\";}#sk-container-id-2 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-2 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-2 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-2 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-2 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-2 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-2 div.sk-item {position: relative;z-index: 1;}#sk-container-id-2 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-2 div.sk-item::before, #sk-container-id-2 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-2 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-2 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-2 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-2 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-2 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-2 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-2 div.sk-label-container {text-align: center;}#sk-container-id-2 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-2 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-2\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>RandomizedSearchCV(cv=5, estimator=RandomForestRegressor(), n_jobs=-1,\n",
       "                   param_distributions={&#x27;max_depth&#x27;: [None, 10, 50, 100],\n",
       "                                        &#x27;max_features&#x27;: [&#x27;auto&#x27;, &#x27;sqrt&#x27;],\n",
       "                                        &#x27;min_samples_leaf&#x27;: [1, 2, 4],\n",
       "                                        &#x27;min_samples_split&#x27;: [2, 5, 10],\n",
       "                                        &#x27;n_estimators&#x27;: [100, 300, 500]},\n",
       "                   scoring=&#x27;neg_mean_absolute_error&#x27;)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-4\" type=\"checkbox\" ><label for=\"sk-estimator-id-4\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">RandomizedSearchCV</label><div class=\"sk-toggleable__content\"><pre>RandomizedSearchCV(cv=5, estimator=RandomForestRegressor(), n_jobs=-1,\n",
       "                   param_distributions={&#x27;max_depth&#x27;: [None, 10, 50, 100],\n",
       "                                        &#x27;max_features&#x27;: [&#x27;auto&#x27;, &#x27;sqrt&#x27;],\n",
       "                                        &#x27;min_samples_leaf&#x27;: [1, 2, 4],\n",
       "                                        &#x27;min_samples_split&#x27;: [2, 5, 10],\n",
       "                                        &#x27;n_estimators&#x27;: [100, 300, 500]},\n",
       "                   scoring=&#x27;neg_mean_absolute_error&#x27;)</pre></div></div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-5\" type=\"checkbox\" ><label for=\"sk-estimator-id-5\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">estimator: RandomForestRegressor</label><div class=\"sk-toggleable__content\"><pre>RandomForestRegressor()</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-6\" type=\"checkbox\" ><label for=\"sk-estimator-id-6\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">RandomForestRegressor</label><div class=\"sk-toggleable__content\"><pre>RandomForestRegressor()</pre></div></div></div></div></div></div></div></div></div></div>"
      ],
      "text/plain": [
       "RandomizedSearchCV(cv=5, estimator=RandomForestRegressor(), n_jobs=-1,\n",
       "                   param_distributions={'max_depth': [None, 10, 50, 100],\n",
       "                                        'max_features': ['auto', 'sqrt'],\n",
       "                                        'min_samples_leaf': [1, 2, 4],\n",
       "                                        'min_samples_split': [2, 5, 10],\n",
       "                                        'n_estimators': [100, 300, 500]},\n",
       "                   scoring='neg_mean_absolute_error')"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rscv_rf.fit(X_train1, y_train1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'n_estimators': 300,\n",
       " 'min_samples_split': 2,\n",
       " 'min_samples_leaf': 1,\n",
       " 'max_features': 'auto',\n",
       " 'max_depth': None}"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rscv_rf.best_params_"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "RF (after hyperparameter tuning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/y1/pjvjlkjn5gl846rnyzr53p340000gn/T/ipykernel_2965/1544586679.py:2: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  rfreg_ht.fit(X_train1, y_train1)\n",
      "/Users/andalanputra/opt/anaconda3/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
      "  warn(\n"
     ]
    }
   ],
   "source": [
    "rfreg_ht = RandomForestRegressor(n_estimators=300, min_samples_leaf=1, min_samples_split=2, max_features='auto', max_depth=None)\n",
    "rfreg_ht.fit(X_train1, y_train1)\n",
    "y_pred_rfreg_ht = rfreg_ht.predict(X_val)\n",
    "y_pred_rfreg_ht_r2 = rfreg_ht.predict(X_train1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.07417672214267432"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mean_absolute_error(y_val, y_pred_rfreg_ht)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.01985890665300429"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mean_squared_error(y_val, y_pred_rfreg_ht)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.14092163301993163"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mean_squared_error(y_val, y_pred_rfreg_ht, squared = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9647226176286995"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#train\n",
    "r2_score(y_train1, y_pred_rfreg_ht_r2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7582096818077035"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#val\n",
    "r2_score(y_val, y_pred_rfreg_ht)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Predicting on the test set (kNN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_knreg_test = knreg_ht.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['y_test_knreg_bert_thc.pkl']"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import joblib\n",
    "\n",
    "joblib.dump(y_pred_knreg_test, \"y_pred_knreg_test_bert_thc.pkl\")\n",
    "joblib.dump(y_test, \"y_test_knreg_bert_thc.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.04548090300604659"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mean_absolute_error(y_test, y_pred_knreg_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.015063379314052777"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mean_squared_error(y_test, y_pred_knreg_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.12273295936321578"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mean_squared_error(y_test, y_pred_knreg_test, squared = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8169480059488765"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "r2_score(y_test, y_pred_knreg_test)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Error analysis (kNN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAe0AAAF1CAYAAADFgbLVAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjQuMywgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/MnkTPAAAACXBIWXMAAAsTAAALEwEAmpwYAAAczElEQVR4nO3df7RVZb3v8ff3AIqmHRXRQUChhR3RFBURbj/E40DMa0MZaWpdNbVBdbXSUZ38MUrvvTm0czVuHqszqAwaaqhk6elq93BQj2UobU4kgmkkRjtJEMvU0gPs7/1jTWiJG/baey/W3s/e79cYa6y1njnns77rGRs++5lz7jkjM5EkSf3f3/R1AZIkqTGGtiRJhTC0JUkqhKEtSVIhDG1JkgphaEuSVAhDWxpkIuKqiLi5r+uQ1H2GttRiEbFHRDwdER+sa9szItZExGldbDsuIjIiXqoez0bEDyNieg9r2dLf0G5sc3BE3BcRL0TEqoiY2ck6b66r8aXqM16ue//uiJgbEV/sqp6ImBwR90TEHyPi+YhYEhHn9eT7SqUztKUWy8yXgFnAVyJiZNX8j0BbZi5osJu9MnMP4HBgIfD9iPhw04vdRhWmdwE/BPah9j1ujoiD6tfLzDWZuceWR9V8eF3bjxv8vKnAfcC/A28DRgAfB97bnG8klcXQlvpAZv4r8H+BGyJiGvAB4MIe9PP7zPwKcBXwpYj4G4CIeFNEfC8i1kfE6oj45Ha6eLB6/mM1A54aEW+tZtIbIuK5iLglIvaq1vs74E3A7MzcnJn3AQ8BZ3e39gb9b2BeZn4pM5/LmqWZ+YGd9HlSv2ZoS33nEmAasAD4TGau7UVfdwL7AW+vgvtfgF8Ao4HjgYsjYkYn272net6rmgEvBgK4hlo4HwyMpfZLAdWybQVwaC9q71RE7A5MpTY+kjC0pT6TmX8AVgC7Uwvd3nimet4HOBoYmZn/MzP/MzOfAr4BnNlgXasyc2FmvpqZ64EvA8dWi38JrAM+GxHDIuKEatnuPaz7M9Wx6j9GxB+BR+uW7U3t/6je/DIjDSiGttRHIuK/AeOAfwO+1MvuRlfPzwNvAd60TRheDuzfYF37RcT8iPhdRPwJuBnYFyAzNwKnAv8V+D3waeB2oL3a9t66k80+1MDHXZeZe215AIfVLfsD0AGMaqRuaTBo+IxRSc0TEfsBs6kdy/4lsCIibs3MB3e85XbNpDYDfgLYC1idmeMb2K6z2/xdU7UflpkbIuJU4MatG2Q+yl9n3kTET4F51bKmnSCWmX+OiMXA+4H7m9WvVDJn2lLfuBH4QWbeXx3L/gfgGxGxa3c6iYj9I+Ii4ErgsszsAJYAf4qIz0XEbhExJCIOjYijO+liPbXZ7IF1bXsCL1E7OW008NltPvOwiBgeEbtHxGeozYTndqfubvgH4MMR8dmIGFF9/uERMX8nfZ7UrxnaUotVM9d3UReGmflNaruYvxARl0fEvXXr3xsRl2/TzR8j4mVgOXAScHpm3lT1tRl4HzARWA08B3wT+Ntta8nMPwNXAw9Vu9KnAP8DOBJ4gdoZ7tsebz+b2nHmddROcpuema92fyS6lpk/Bf6+ejwVEc8Dc4B7dsbnSf1dZHa2d0ySJPU3zrQlSSqEoS1JUiEMbUmSCmFoS5JUCENbkqRC9PuLq+y77745bty4vi5DkqSWWLp06XOZObKzZf0+tMeNG0dbW1tflyFJUktExG+2t8zd45IkFcLQliSpEIa2JEmF6PfHtCVJA8PGjRtpb2/nlVde6etS+oXhw4czZswYhg0b1vA2hrYkqSXa29vZc889GTduHBHR1+X0qcxkw4YNtLe3c8ABBzS8nbvHJUkt8corrzBixIhBH9gAEcGIESO6vdfB0JYktYyB/Vc9GQtDW5KkQnhMW5LUJ2YvfLKp/V0y/aCm9tcsc+fOpa2tjRtvvLHXfTnTliSpBzZv3tzyzzS0JUmDwuc//3m+8pWvbH1/xRVXcMMNN7xuvQceeID3vOc9zJw5kwkTJvCxj32Mjo4OAPbYYw++8IUvcMwxx7B48WJuvvlmJk+ezMSJE/noRz+6Nci//e1vc9BBB3Hsscfy0EMPNe07GNqSpEHhggsuYN68eQB0dHQwf/58PvShD3W67pIlS7j++utZvnw5v/71r7nzzjsBePnllzn00EN55JFHGDFiBLfddhsPPfQQy5YtY8iQIdxyyy2sXbuWK6+8koceeoiFCxeycuXKpn0Hj2lLkgaFcePGMWLECH7+85/z7LPPcsQRRzBixIhO1508eTIHHnggAGeddRY/+clPOO200xgyZAjvf//7AVi0aBFLly7l6KOPBuAvf/kL++23H4888gjTpk1j5MjajbrOOOMMnnyyOcfvDW1JGsQGy8lgW3zkIx9h7ty5/P73v+f888/f7nrb/jnWlvfDhw9nyJAhQO0CKeeeey7XXHPNa9b9wQ9+sNP+tM3d45KkQWPmzJn86Ec/4mc/+xkzZszY7npLlixh9erVdHR0cNttt/Gud73rdescf/zxLFiwgHXr1gHw/PPP85vf/IZjjjmGBx54gA0bNrBx40buuOOOptXvTFuS1Cf6Yla+yy67cNxxx7HXXnttnTF3ZurUqVx66aUsX75860lp25owYQJf/OIXOeGEE+jo6GDYsGF89atfZcqUKVx11VVMnTqVUaNGceSRRzbtTHNDW5I0aHR0dPDwww93Ofvdfffdue22217X/tJLL73m/RlnnMEZZ5zxuvXOO+88zjvvvN4V2wlDW5IGsSlr5jS5x+ua3F/zrFy5kpNPPpmZM2cyfvz4vi6nRwxtSdKgMGHCBJ566qmt75cvX87ZZ5/9mnV23XXXrWd/90eGtiRpUHrHO97BsmXL+rqMbvHscUmSCmFoS5JUCENbkqRCGNqSJNV5+umnufXWW/u6jE55IpokqW/cf03X63THcZc1pZstof3BD37wdcs2bdrE0KF9F53OtCVJg0Kjt+a89NJL+fGPf8zEiROZPXs2c+fO5fTTT+d973sfJ5xwAg888AAnn3zy1vUvuugi5s6dC8DSpUs59thjOeqoo5gxYwZr165t6ncwtCVJg0Kjt+a89tprefe7382yZcu45JJLAFi8eDHz5s3jvvvu227/Gzdu5BOf+AQLFixg6dKlnH/++VxxxRVN/Q7uHpckDQrduTXntqZPn84+++yzw3WeeOIJHnvsMaZPnw7A5s2bGTVqVK/rrmdoS5IGjUZvzbmtN7zhDVtfDx06lI6Ojq3vX3nlFaB2q85DDjmExYsXN6/gbbh7XJI0aDRya84999yTF198cbt9vOUtb2HlypW8+uqrvPDCCyxatAiAt7/97axfv35raG/cuJEVK1Y0tX5n2pKkQaORW3MedthhDB06lMMPP5wPf/jD7L333q9ZPnbsWD7wgQ9w2GGHMX78eI444oitfS9YsIBPfvKTvPDCC2zatImLL76YQw45pGn1R2Y2rbOdYdKkSdnW1tbXZUjSgLT4W59pan9TL9j+Xb4ef/xxDj744KZ+Xnd1dHRw5JFHcscdd/SLO311NiYRsTQzJ3W2fpe7xyNibETcHxGPR8SKiPhU1X5VRPwuIpZVj5PqtrksIlZFxBMRMaOu/aiIWF4tuyEiosffVJKkbli5ciVve9vbOP744/tFYPdEI7vHNwGfzsz/iIg9gaURsbBaNjszX/NrVURMAM4EDgHeBPxbRByUmZuBrwOzgIeBe4ATgXub81UkSdq+7tyas7/qMrQzcy2wtnr9YkQ8DozewSanAPMz81VgdUSsAiZHxNPAGzNzMUBEfAc4FUNbktQHBvytOSNiHHAEsOXXkIsi4tGIuCkithypHw38tm6z9qptdPV623ZJ0iDR38+jaqWejEXDoR0RewDfAy7OzD9R29X9VmAitZn49VtW7ay2HbR39lmzIqItItrWr1/faImSpH5s+PDhbNiwweCmFtgbNmxg+PDh3dquoT/5iohh1AL7lsy8s/rAZ+uWfwP4YfW2HRhbt/kY4JmqfUwn7a+TmXOAOVA7e7yRGiVJ/duYMWNob2/HyVjN8OHDGTNmTNcr1ukytKszvL8FPJ6ZX65rH1Ud7waYCTxWvb4buDUivkztRLTxwJLM3BwRL0bEFGq7188B/qlb1UqSijVs2DAOOOCAvi6jaI3MtN8JnA0sj4hlVdvlwFkRMZHaLu6ngY8CZOaKiLgdWEntzPMLqzPHAT4OzAV2o3YCmiehSZLUoEbOHv8JnR+PvmcH21wNXN1JextwaHcKlCRJNV57XJKkQhjakiQVYvDdMOT+a5rb33GXNbc/SZK2w5m2JEmFMLQlSSqEoS1JUiEMbUmSCmFoS5JUCENbkqRCGNqSJBXC0JYkqRCGtiRJhTC0JUkqhKEtSVIhDG1JkgphaEuSVAhDW5KkQhjakiQVwtCWJKkQhrYkSYUwtCVJKoShLUlSIQxtSZIKYWhLklQIQ1uSpEIY2pIkFcLQliSpEIa2JEmFMLQlSSqEoS1JUiEMbUmSCmFoS5JUCENbkqRCGNqSJBXC0JYkqRCGtiRJhTC0JUkqhKEtSVIhDG1JkgphaEuSVAhDW5KkQhjakiQVwtCWJKkQhrYkSYUwtCVJKoShLUlSIQxtSZIKYWhLklQIQ1uSpEJ0GdoRMTYi7o+IxyNiRUR8qmrfJyIWRsSvque967a5LCJWRcQTETGjrv2oiFheLbshImLnfC1JkgaeRmbam4BPZ+bBwBTgwoiYAFwKLMrM8cCi6j3VsjOBQ4ATga9FxJCqr68Ds4Dx1ePEJn4XSZIGtC5DOzPXZuZ/VK9fBB4HRgOnAPOq1eYBp1avTwHmZ+armbkaWAVMjohRwBszc3FmJvCdum0kSVIXunVMOyLGAUcAjwD7Z+ZaqAU7sF+12mjgt3WbtVdto6vX27Z39jmzIqItItrWr1/fnRIlSRqwGg7tiNgD+B5wcWb+aUerdtKWO2h/fWPmnMyclJmTRo4c2WiJkiQNaA2FdkQMoxbYt2TmnVXzs9Uub6rndVV7OzC2bvMxwDNV+5hO2iVJUgMaOXs8gG8Bj2fml+sW3Q2cW70+F7irrv3MiNg1Ig6gdsLZkmoX+osRMaXq85y6bSRJUheGNrDOO4GzgeURsaxquxy4Frg9Ii4A1gCnA2Tmioi4HVhJ7czzCzNzc7Xdx4G5wG7AvdVDkiQ1oMvQzsyf0PnxaIDjt7PN1cDVnbS3AYd2p0BJklTjFdEkSSqEoS1JUiEMbUmSCmFoS5JUCENbkqRCGNqSJBXC0JYkqRCGtiRJhTC0JUkqhKEtSVIhDG1JkgphaEuSVAhDW5KkQhjakiQVwtCWJKkQhrYkSYUwtCVJKoShLUlSIQxtSZIKYWhLklQIQ1uSpEIY2pIkFcLQliSpEIa2JEmFMLQlSSqEoS1JUiGG9nUBktRfzF74ZFP7u2T6QU3tT3KmLUlSIQxtSZIK4e5xSapMWTOnyT1e1+T+NNg505YkqRCGtiRJhTC0JUkqhKEtSVIhDG1Jkgox6M4eX/zUhqb2N/W4pnYnSdJ2OdOWJKkQhrYkSYUwtCVJKoShLUlSIQxtSZIKYWhLklQIQ1uSpEIY2pIkFcLQliSpEIa2JEmFMLQlSSqEoS1JUiG6DO2IuCki1kXEY3VtV0XE7yJiWfU4qW7ZZRGxKiKeiIgZde1HRcTyatkNERHN/zqSJA1cjcy05wIndtI+OzMnVo97ACJiAnAmcEi1zdciYki1/teBWcD46tFZn5IkaTu6DO3MfBB4vsH+TgHmZ+armbkaWAVMjohRwBszc3FmJvAd4NQe1ixJ0qDUm2PaF0XEo9Xu872rttHAb+vWaa/aRlevt22XJEkN6mlofx14KzARWAtcX7V3dpw6d9DeqYiYFRFtEdG2fv36HpYoSdLA0qPQzsxnM3NzZnYA3wAmV4vagbF1q44Bnqnax3TSvr3+52TmpMycNHLkyJ6UKEnSgNOj0K6OUW8xE9hyZvndwJkRsWtEHEDthLMlmbkWeDEiplRnjZ8D3NWLuiVJGnSGdrVCRHwXmAbsGxHtwJXAtIiYSG0X99PARwEyc0VE3A6sBDYBF2bm5qqrj1M7E3034N7qIUmSGtRlaGfmWZ00f2sH618NXN1JextwaLeqkyRJW3lFNEmSCmFoS5JUCENbkqRCGNqSJBXC0JYkqRCGtiRJhTC0JUkqhKEtSVIhDG1JkgphaEuSVAhDW5KkQhjakiQVwtCWJKkQhrYkSYUwtCVJKoShLUlSIQxtSZIKYWhLklQIQ1uSpEIY2pIkFcLQliSpEIa2JEmFMLQlSSqEoS1JUiEMbUmSCmFoS5JUCENbkqRCGNqSJBXC0JYkqRCGtiRJhTC0JUkqhKEtSVIhDG1JkgphaEuSVAhDW5KkQhjakiQVwtCWJKkQhrYkSYUwtCVJKoShLUlSIQxtSZIKYWhLklQIQ1uSpEIY2pIkFcLQliSpEIa2JEmFMLQlSSqEoS1JUiGG9nUBKtD91zS3v+Mua25/kjRAdTnTjoibImJdRDxW17ZPRCyMiF9Vz3vXLbssIlZFxBMRMaOu/aiIWF4tuyEiovlfR5KkgauR3eNzgRO3absUWJSZ44FF1XsiYgJwJnBItc3XImJItc3XgVnA+OqxbZ+SJGkHugztzHwQeH6b5lOAedXrecCpde3zM/PVzFwNrAImR8Qo4I2ZuTgzE/hO3TaSJKkBPT2mvX9mrgXIzLURsV/VPhp4uG699qptY/V623Zpp5i98Mmm9nfJ9IOa2p8k9USzzx7v7Dh17qC9804iZkVEW0S0rV+/vmnFSZJUsp6G9rPVLm+q53VVezswtm69McAzVfuYTto7lZlzMnNSZk4aOXJkD0uUJGlg6enu8buBc4Frq+e76tpvjYgvA2+idsLZkszcHBEvRsQU4BHgHOCfelW5+szipzY0tb+pxzW1O0kasLoM7Yj4LjAN2Dci2oErqYX17RFxAbAGOB0gM1dExO3ASmATcGFmbq66+ji1M9F3A+6tHlLTjz9L0kDVZWhn5lnbWXT8dta/Gri6k/Y24NBuVSdJkrbyMqaSJBXC0JYkqRCGtiRJhTC0JUkqhKEtSVIhDG1JkgphaEuSVIieXhFN6temrJnT5B6va3J/ktR9zrQlSSqEoS1JUiHcPa4+1/xd2ZI0MDnTliSpEIa2JEmFMLQlSSqEx7SlPrAz7iF+yfSDmt6npP7FmbYkSYUwtCVJKoShLUlSITymLak17r+muf0dd1lz+5MK4ExbkqRCGNqSJBXC0JYkqRAe05bUuWYfg5bUa860JUkqhDNtSUXaGVeVm9L0HqXmMrSlAaLZIXaJ/ztI/Y67xyVJKoS/S0sDxJQ1c5rb4YEjmtufpF5zpi1JUiGcaUvq1OKnNjS1v6nO3KVec6YtSVIhDG1Jkgrh7nFJLdHs3e1TaPKJd1IBnGlLklQIQ1uSpEK4e1zqA03/m2pJg4IzbUmSCmFoS5JUCENbkqRCGNqSJBXC0JYkqRCGtiRJhTC0JUkqhKEtSVIhDG1JkgphaEuSVAhDW5KkQhjakiQVwtCWJKkQvQrtiHg6IpZHxLKIaKva9omIhRHxq+p577r1L4uIVRHxRETM6G3xkiQNJs2YaR+XmRMzc1L1/lJgUWaOBxZV74mICcCZwCHAicDXImJIEz5fkqRBYWfcT/sUYFr1eh7wAPC5qn1+Zr4KrI6IVcBkYPFOqEFqqtkLn2xqf1Oa2pukwaK3M+0E/jUilkbErKpt/8xcC1A971e1jwZ+W7dte9X2OhExKyLaIqJt/fr1vSxRkqSBobcz7Xdm5jMRsR+wMCJ+uYN1o5O27GzFzJwDzAGYNGlSp+tIkjTY9GqmnZnPVM/rgO9T2939bESMAqie11WrtwNj6zYfAzzTm8+XJGkw6XFoR8QbImLPLa+BE4DHgLuBc6vVzgXuql7fDZwZEbtGxAHAeGBJTz9fkqTBpje7x/cHvh8RW/q5NTN/FBE/A26PiAuANcDpAJm5IiJuB1YCm4ALM3Nzr6qXJGkQ6XFoZ+ZTwOGdtG8Ajt/ONlcDV/f0MyVJGsy8IpokSYUwtCVJKoShLUlSIQxtSZIKYWhLklSInXHtcUkSzb9m/SXTD2pqfyqPM21JkgrhTFuSdpIpa+Y0ucfrmtzf4FTyHhBDW5I0qJT8y5S7xyVJKoShLUlSIQxtSZIKYWhLklQIQ1uSpEIY2pIkFcLQliSpEIa2JEmF8OIq/VCzr9bTbFP6ugBJGqScaUuSVAhDW5KkQhjakiQVwmPaklSIxd/6TF+XoD7mTFuSpEIY2pIkFcLQliSpEB7TlhowZc2cvi5Bkgzt/siAkCR1xt3jkiQVwtCWJKkQhrYkSYUwtCVJKoShLUlSIQxtSZIKYWhLklQIQ1uSpEIY2pIkFcLQliSpEIa2JEmF8NrjvTR74ZNN73NK03uUJA0EzrQlSSqEoS1JUiEMbUmSCuEx7V7y3teSpFZxpi1JUiEMbUmSCmFoS5JUCENbkqRCGNqSJBWi5aEdESdGxBMRsSoiLm3150uSVKqWhnZEDAG+CrwXmACcFRETWlmDJEmlavVMezKwKjOfysz/BOYDp7S4BkmSitTq0B4N/LbufXvVJkmSutDqK6JFJ235upUiZgGzqrcvRcQTTaxhX+C5JvY3GDmGvecY9p5j2BzNHcePXN+0rorxkeub/bP4lu0taHVotwNj696PAZ7ZdqXMnAPslOuDRkRbZk7aGX0PFo5h7zmGvecYNofj2HutHMNW7x7/GTA+Ig6IiF2AM4G7W1yDJElFaulMOzM3RcRFwP8DhgA3ZeaKVtYgSVKpWn6Xr8y8B7in1Z9bx9ty9Z5j2HuOYe85hs3hOPZey8YwMl93HpgkSeqHvIypJEmFGLCh3dXlUqPmhmr5oxFxZF/U2Z81MIYfqsbu0Yj4aUQc3hd19meNXrY3Io6OiM0RcVor6ytBI2MYEdMiYllErIiIf291jf1dA/+W/zYi/iUiflGN4Xl9UWd/FhE3RcS6iHhsO8tbkymZOeAe1E5y+zVwILAL8AtgwjbrnATcS+1vx6cAj/R13f3p0eAY/hdg7+r1ex3D7o9h3Xr3UTvX47S+rrs/PRr8OdwLWAm8uXq/X1/X3Z8eDY7h5cCXqtcjgeeBXfq69v70AN4DHAk8tp3lLcmUgTrTbuRyqacA38mah4G9ImJUqwvtx7ocw8z8aWb+oXr7MLW/u9dfNXrZ3k8A3wPWtbK4QjQyhh8E7szMNQCZ6Ti+ViNjmMCeERHAHtRCe1Nry+zfMvNBauOyPS3JlIEa2o1cLtVLqu5Yd8fnAmq/ZeqvuhzDiBgNzAT+uYV1laSRn8ODgL0j4oGIWBoR57SsujI0MoY3AgdTu9jVcuBTmdnRmvIGjJZkSsv/5KtFGrlcakOXVB3EGh6fiDiOWmi/a6dWVJ5GxvD/AJ/LzM21SY620cgYDgWOAo4HdgMWR8TDmfnkzi6uEI2M4QxgGfD3wFuBhRHx48z8006ubSBpSaYM1NBu5HKpDV1SdRBraHwi4jDgm8B7M3NDi2orRSNjOAmYXwX2vsBJEbEpM3/Qkgr7v0b/LT+XmS8DL0fEg8DhgKFd08gYngdcm7WDs6siYjXwd8CS1pQ4ILQkUwbq7vFGLpd6N3BOdcbfFOCFzFzb6kL7sS7HMCLeDNwJnO2splNdjmFmHpCZ4zJzHLAA+O8G9ms08m/5LuDdETE0InYHjgEeb3Gd/VkjY7iG2p4KImJ/4O3AUy2tsnwtyZQBOdPO7VwuNSI+Vi3/Z2pn6p4ErAL+TO03TVUaHMMvACOAr1UzxU3pjQe2anAMtQONjGFmPh4RPwIeBTqAb2Zmp3+WMxg1+HP4v4C5EbGc2m7ez2Wmd1CrExHfBaYB+0ZEO3AlMAxamyleEU2SpEIM1N3jkiQNOIa2JEmFMLQlSSqEoS1JUiEMbUmSCmFoS5JUCENbkqRCGNqSJBXi/wOPCQYjBaGFeAAAAABJRU5ErkJggg==",
      "text/plain": [
       "<Figure size 576x432 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 432x288 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# assume y_pred is a numpy array and y_true is a pandas dataframe\n",
    "fig, ax = plt.subplots(figsize=(8, 6))\n",
    "\n",
    "column = \"X..Delta9-THC\"  # specify the target variable name\n",
    "ax.hist(y_pred_knreg_test, alpha=0.5, label='y_pred', bins=20)\n",
    "ax.hist(y_test[column], alpha=0.5, label='y_true', bins=20)\n",
    "ax.legend(loc='upper right')\n",
    "ax.set_title(column)\n",
    "\n",
    "plt.show()\n",
    "plt.savefig('error_hist_knn_bert_thc.png')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pearson R (kNN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pearson correlation coefficient: 0.907\n",
      "P-value: 0.000\n"
     ]
    }
   ],
   "source": [
    "corr_coef, p_value = pearsonr(y_pred_knreg_test.flatten(), y_test.values.ravel())\n",
    "\n",
    "print(f\"Pearson correlation coefficient: {corr_coef:.3f}\")\n",
    "print(f\"P-value: {p_value:.3f}\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Predicting on the test set (RF)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_rfreg_test = rfreg_ht.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['y_test_rfreg_bert_thc.pkl']"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "joblib.dump(y_pred_rfreg_test, \"y_pred_rfreg_test_bert_thc.pkl\")\n",
    "joblib.dump(y_test, \"y_test_rfreg_bert_thc.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.07301084415783259"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mean_absolute_error(y_test, y_pred_rfreg_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.019791272238104573"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mean_squared_error(y_test, y_pred_rfreg_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.1406814566249034"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mean_squared_error(y_test, y_pred_rfreg_test, squared = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7594940834681161"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "r2_score(y_test, y_pred_rfreg_test)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Error analysis (RF)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 576x432 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 432x288 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# assume y_pred is a numpy array and y_true is a pandas dataframe\n",
    "fig, ax = plt.subplots(figsize=(8, 6))\n",
    "\n",
    "column = \"X..Delta9-THC\"  # specify the target variable name\n",
    "ax.hist(y_pred_rfreg_test, alpha=0.5, label='y_pred', bins=20)\n",
    "ax.hist(y_test[column], alpha=0.5, label='y_true', bins=20)\n",
    "ax.legend(loc='upper right')\n",
    "ax.set_title(column)\n",
    "\n",
    "plt.show()\n",
    "plt.savefig('error_hist_rf_bert_thc.png')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pearson R (RF)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pearson correlation coefficient: 0.874\n",
      "P-value: 0.000\n"
     ]
    }
   ],
   "source": [
    "corr_coef, p_value = pearsonr(y_pred_rfreg_test.flatten(), y_test.values.ravel())\n",
    "\n",
    "print(f\"Pearson correlation coefficient: {corr_coef:.3f}\")\n",
    "print(f\"P-value: {p_value:.3f}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
