{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn import preprocessing\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.neural_network import MLPRegressor\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "from sklearn.metrics import r2_score\n",
    "from scipy.stats import pearsonr\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.feature_selection import SelectFromModel\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compiling complete dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_rf = pd.read_csv(\"df_cbc_lsa.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>lsa_0</th>\n",
       "      <th>lsa_1</th>\n",
       "      <th>lsa_2</th>\n",
       "      <th>lsa_3</th>\n",
       "      <th>lsa_4</th>\n",
       "      <th>hybrid</th>\n",
       "      <th>indica</th>\n",
       "      <th>sativa</th>\n",
       "      <th>anxiety</th>\n",
       "      <th>...</th>\n",
       "      <th>sweet</th>\n",
       "      <th>tar</th>\n",
       "      <th>tea</th>\n",
       "      <th>tobacco</th>\n",
       "      <th>tree</th>\n",
       "      <th>tropical</th>\n",
       "      <th>vanilla</th>\n",
       "      <th>violet</th>\n",
       "      <th>woody</th>\n",
       "      <th>X..CBC</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0.341025</td>\n",
       "      <td>0.182753</td>\n",
       "      <td>0.008214</td>\n",
       "      <td>0.140406</td>\n",
       "      <td>-0.156943</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.175439</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0.232158</td>\n",
       "      <td>-0.045496</td>\n",
       "      <td>0.187131</td>\n",
       "      <td>-0.000936</td>\n",
       "      <td>0.018518</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.175439</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>0.243491</td>\n",
       "      <td>0.034313</td>\n",
       "      <td>0.080290</td>\n",
       "      <td>-0.165609</td>\n",
       "      <td>0.019773</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.175439</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>0.243491</td>\n",
       "      <td>0.034313</td>\n",
       "      <td>0.080290</td>\n",
       "      <td>-0.165609</td>\n",
       "      <td>0.019773</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.175439</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>0.238648</td>\n",
       "      <td>-0.048758</td>\n",
       "      <td>-0.107398</td>\n",
       "      <td>-0.067096</td>\n",
       "      <td>-0.006558</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.175439</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>74995</th>\n",
       "      <td>42975</td>\n",
       "      <td>0.324915</td>\n",
       "      <td>0.131823</td>\n",
       "      <td>-0.099424</td>\n",
       "      <td>0.065491</td>\n",
       "      <td>0.038437</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.614035</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>74996</th>\n",
       "      <td>42975</td>\n",
       "      <td>0.324915</td>\n",
       "      <td>0.131823</td>\n",
       "      <td>-0.099424</td>\n",
       "      <td>0.065491</td>\n",
       "      <td>0.038437</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.614035</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>74997</th>\n",
       "      <td>42975</td>\n",
       "      <td>0.324915</td>\n",
       "      <td>0.131823</td>\n",
       "      <td>-0.099424</td>\n",
       "      <td>0.065491</td>\n",
       "      <td>0.038437</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.614035</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>74998</th>\n",
       "      <td>42976</td>\n",
       "      <td>0.270141</td>\n",
       "      <td>-0.004631</td>\n",
       "      <td>-0.151272</td>\n",
       "      <td>0.035538</td>\n",
       "      <td>0.083641</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.614035</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>74999</th>\n",
       "      <td>42976</td>\n",
       "      <td>0.270141</td>\n",
       "      <td>-0.004631</td>\n",
       "      <td>-0.151272</td>\n",
       "      <td>0.035538</td>\n",
       "      <td>0.083641</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.614035</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>75000 rows × 88 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       index     lsa_0     lsa_1     lsa_2     lsa_3     lsa_4  hybrid  \\\n",
       "0          0  0.341025  0.182753  0.008214  0.140406 -0.156943       1   \n",
       "1          1  0.232158 -0.045496  0.187131 -0.000936  0.018518       1   \n",
       "2          3  0.243491  0.034313  0.080290 -0.165609  0.019773       1   \n",
       "3          3  0.243491  0.034313  0.080290 -0.165609  0.019773       1   \n",
       "4          4  0.238648 -0.048758 -0.107398 -0.067096 -0.006558       1   \n",
       "...      ...       ...       ...       ...       ...       ...     ...   \n",
       "74995  42975  0.324915  0.131823 -0.099424  0.065491  0.038437       0   \n",
       "74996  42975  0.324915  0.131823 -0.099424  0.065491  0.038437       0   \n",
       "74997  42975  0.324915  0.131823 -0.099424  0.065491  0.038437       0   \n",
       "74998  42976  0.270141 -0.004631 -0.151272  0.035538  0.083641       0   \n",
       "74999  42976  0.270141 -0.004631 -0.151272  0.035538  0.083641       0   \n",
       "\n",
       "       indica  sativa  anxiety  ...  sweet  tar  tea  tobacco  tree  tropical  \\\n",
       "0           0       0        0  ...      0    0    0        0     0         0   \n",
       "1           0       0        0  ...      0    0    0        0     0         0   \n",
       "2           0       0        0  ...      0    1    0        0     0         0   \n",
       "3           0       0        0  ...      0    1    0        0     0         0   \n",
       "4           0       0        0  ...      0    0    0        0     0         0   \n",
       "...       ...     ...      ...  ...    ...  ...  ...      ...   ...       ...   \n",
       "74995       1       0        0  ...      0    0    0        0     0         0   \n",
       "74996       1       0        0  ...      0    0    0        0     0         0   \n",
       "74997       1       0        0  ...      0    0    0        0     0         0   \n",
       "74998       1       0        0  ...      1    1    1        1     1         1   \n",
       "74999       1       0        0  ...      1    1    1        1     1         1   \n",
       "\n",
       "       vanilla  violet  woody    X..CBC  \n",
       "0            0       0      0  0.175439  \n",
       "1            1       0      0  0.175439  \n",
       "2            0       0      0  0.175439  \n",
       "3            0       0      0  0.175439  \n",
       "4            0       0      0  0.175439  \n",
       "...        ...     ...    ...       ...  \n",
       "74995        0       0      0  0.614035  \n",
       "74996        0       0      0  0.614035  \n",
       "74997        0       0      0  0.614035  \n",
       "74998        1       1      1  0.614035  \n",
       "74999        1       1      1  0.614035  \n",
       "\n",
       "[75000 rows x 88 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_rf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['index',\n",
       " 'lsa_0',\n",
       " 'lsa_1',\n",
       " 'lsa_2',\n",
       " 'lsa_3',\n",
       " 'lsa_4',\n",
       " 'hybrid',\n",
       " 'indica',\n",
       " 'sativa',\n",
       " 'anxiety',\n",
       " 'anxious',\n",
       " 'aroused',\n",
       " 'arthritis',\n",
       " 'creative',\n",
       " 'depression',\n",
       " 'dizzy',\n",
       " 'dry eyes',\n",
       " 'dry mouth',\n",
       " 'energetic',\n",
       " 'epilepsy',\n",
       " 'euphoric',\n",
       " 'eye pressure',\n",
       " 'fatigue',\n",
       " 'focused',\n",
       " 'giggly',\n",
       " 'happy',\n",
       " 'headache',\n",
       " 'hungry',\n",
       " 'migraines',\n",
       " 'pain',\n",
       " 'paranoid',\n",
       " 'relaxed',\n",
       " 'seizures',\n",
       " 'sleepy',\n",
       " 'spasticity',\n",
       " 'stress',\n",
       " 'talkative',\n",
       " 'tingly',\n",
       " 'uplifted',\n",
       " 'ammonia',\n",
       " 'apple',\n",
       " 'apricot',\n",
       " 'berry',\n",
       " 'blue cheese',\n",
       " 'blueberry',\n",
       " 'butter',\n",
       " 'cheese',\n",
       " 'chemical',\n",
       " 'chestnut',\n",
       " 'citrus',\n",
       " 'coffee',\n",
       " 'diesel',\n",
       " 'earthy',\n",
       " 'flowery',\n",
       " 'fruit',\n",
       " 'grape',\n",
       " 'grapefruit',\n",
       " 'honey',\n",
       " 'lavender',\n",
       " 'lemon',\n",
       " 'lime',\n",
       " 'mango',\n",
       " 'menthol',\n",
       " 'mint',\n",
       " 'nutty',\n",
       " 'orange',\n",
       " 'peach',\n",
       " 'pear',\n",
       " 'pepper',\n",
       " 'pine',\n",
       " 'pineapple',\n",
       " 'plum',\n",
       " 'pungent',\n",
       " 'rose',\n",
       " 'sage',\n",
       " 'skunk',\n",
       " 'spicy/herbal',\n",
       " 'strawberry',\n",
       " 'sweet',\n",
       " 'tar',\n",
       " 'tea',\n",
       " 'tobacco',\n",
       " 'tree',\n",
       " 'tropical',\n",
       " 'vanilla',\n",
       " 'violet',\n",
       " 'woody',\n",
       " 'X..CBC']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_rf.columns.to_list()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Splitting dependent and independent variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df_rf.drop(['index', 'X..CBC'], axis = 1)\n",
    "y = df_rf[['X..CBC']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plotting histograms on target variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.1754386 ],\n",
       "       [0.1754386 ],\n",
       "       [0.1754386 ],\n",
       "       ...,\n",
       "       [0.61403509],\n",
       "       [0.61403509],\n",
       "       [0.61403509]])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_array = y.to_numpy()\n",
    "y_array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:ylabel='Count'>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "sns.histplot(y, bins = 10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train test split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=1, test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train1, X_val, y_train1, y_val = train_test_split(X_train, y_train, random_state=1, test_size=0.25)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "RF modeling (before Feature selection and Hyperparameter Tuning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/y1/pjvjlkjn5gl846rnyzr53p340000gn/T/ipykernel_13386/119766249.py:2: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  rfreg.fit(X_train1, y_train1)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;background-color: white;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>RandomForestRegressor(n_jobs=-1)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">RandomForestRegressor</label><div class=\"sk-toggleable__content\"><pre>RandomForestRegressor(n_jobs=-1)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "RandomForestRegressor(n_jobs=-1)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rfreg = RandomForestRegressor(n_jobs = -1)\n",
    "rfreg.fit(X_train1, y_train1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_rfreg = rfreg.predict(X_val)\n",
    "y_pred_rfreg_r2 = rfreg.predict(X_train1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.046900780205026874"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mean_absolute_error(y_val, y_pred_rfreg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.010277529744323343"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mean_squared_error(y_val, y_pred_rfreg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.101378152204128"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mean_squared_error(y_val, y_pred_rfreg, squared = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9710568242556449"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#train\n",
    "r2_score(y_train1, y_pred_rfreg_r2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8649370820484141"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#val\n",
    "r2_score(y_val, y_pred_rfreg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Residual plots for each target variable"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Feature Selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_feat = pd.DataFrame({\n",
    "    \"features\": X_train1.columns,\n",
    "    \"score\": rfreg.feature_importances_\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>features</th>\n",
       "      <th>score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>lsa_0</td>\n",
       "      <td>0.112852</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>lsa_1</td>\n",
       "      <td>0.110565</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>lsa_2</td>\n",
       "      <td>0.111447</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>lsa_3</td>\n",
       "      <td>0.119972</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>lsa_4</td>\n",
       "      <td>0.111309</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>81</th>\n",
       "      <td>tree</td>\n",
       "      <td>0.001570</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>82</th>\n",
       "      <td>tropical</td>\n",
       "      <td>0.001906</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>83</th>\n",
       "      <td>vanilla</td>\n",
       "      <td>0.017664</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>84</th>\n",
       "      <td>violet</td>\n",
       "      <td>0.000790</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>85</th>\n",
       "      <td>woody</td>\n",
       "      <td>0.006616</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>86 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    features     score\n",
       "0      lsa_0  0.112852\n",
       "1      lsa_1  0.110565\n",
       "2      lsa_2  0.111447\n",
       "3      lsa_3  0.119972\n",
       "4      lsa_4  0.111309\n",
       "..       ...       ...\n",
       "81      tree  0.001570\n",
       "82  tropical  0.001906\n",
       "83   vanilla  0.017664\n",
       "84    violet  0.000790\n",
       "85     woody  0.006616\n",
       "\n",
       "[86 rows x 2 columns]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_feat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_feat_ranked = df_feat.sort_values(\"score\", ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>features</th>\n",
       "      <th>score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>lsa_3</td>\n",
       "      <td>1.199720e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>lsa_0</td>\n",
       "      <td>1.128523e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>lsa_2</td>\n",
       "      <td>1.114470e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>lsa_4</td>\n",
       "      <td>1.113089e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>lsa_1</td>\n",
       "      <td>1.105654e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50</th>\n",
       "      <td>diesel</td>\n",
       "      <td>4.583958e-02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>sativa</td>\n",
       "      <td>2.893210e-02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>hybrid</td>\n",
       "      <td>2.046522e-02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>64</th>\n",
       "      <td>orange</td>\n",
       "      <td>1.834213e-02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>83</th>\n",
       "      <td>vanilla</td>\n",
       "      <td>1.766437e-02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>58</th>\n",
       "      <td>lemon</td>\n",
       "      <td>1.396456e-02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>blueberry</td>\n",
       "      <td>1.292931e-02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>relaxed</td>\n",
       "      <td>1.251862e-02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>68</th>\n",
       "      <td>pine</td>\n",
       "      <td>1.101132e-02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>happy</td>\n",
       "      <td>1.031970e-02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51</th>\n",
       "      <td>earthy</td>\n",
       "      <td>1.021625e-02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>euphoric</td>\n",
       "      <td>9.932710e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>uplifted</td>\n",
       "      <td>9.678354e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>berry</td>\n",
       "      <td>9.576231e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>energetic</td>\n",
       "      <td>9.137940e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>hungry</td>\n",
       "      <td>8.692636e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>focused</td>\n",
       "      <td>8.206745e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>dry mouth</td>\n",
       "      <td>8.154836e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>55</th>\n",
       "      <td>grapefruit</td>\n",
       "      <td>8.058501e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>creative</td>\n",
       "      <td>8.027912e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>sleepy</td>\n",
       "      <td>7.914771e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>cheese</td>\n",
       "      <td>7.887033e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54</th>\n",
       "      <td>grape</td>\n",
       "      <td>7.553408e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>62</th>\n",
       "      <td>mint</td>\n",
       "      <td>7.108921e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>giggly</td>\n",
       "      <td>7.088950e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>talkative</td>\n",
       "      <td>7.048817e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>77</th>\n",
       "      <td>sweet</td>\n",
       "      <td>6.894058e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>85</th>\n",
       "      <td>woody</td>\n",
       "      <td>6.616006e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>dry eyes</td>\n",
       "      <td>6.463536e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>71</th>\n",
       "      <td>pungent</td>\n",
       "      <td>6.403594e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>tingly</td>\n",
       "      <td>6.336179e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>aroused</td>\n",
       "      <td>5.799534e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>citrus</td>\n",
       "      <td>5.456562e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52</th>\n",
       "      <td>flowery</td>\n",
       "      <td>4.881621e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>74</th>\n",
       "      <td>skunk</td>\n",
       "      <td>4.488434e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>dizzy</td>\n",
       "      <td>4.252209e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>butter</td>\n",
       "      <td>4.105569e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>paranoid</td>\n",
       "      <td>3.319467e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>63</th>\n",
       "      <td>nutty</td>\n",
       "      <td>3.244711e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75</th>\n",
       "      <td>spicy/herbal</td>\n",
       "      <td>3.074110e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>72</th>\n",
       "      <td>rose</td>\n",
       "      <td>2.898529e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>indica</td>\n",
       "      <td>2.796752e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>headache</td>\n",
       "      <td>2.381367e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>73</th>\n",
       "      <td>sage</td>\n",
       "      <td>2.302227e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>anxious</td>\n",
       "      <td>2.263336e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>82</th>\n",
       "      <td>tropical</td>\n",
       "      <td>1.906353e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>56</th>\n",
       "      <td>honey</td>\n",
       "      <td>1.806613e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>chemical</td>\n",
       "      <td>1.606136e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>81</th>\n",
       "      <td>tree</td>\n",
       "      <td>1.570133e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>60</th>\n",
       "      <td>mango</td>\n",
       "      <td>1.555344e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59</th>\n",
       "      <td>lime</td>\n",
       "      <td>1.345073e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53</th>\n",
       "      <td>fruit</td>\n",
       "      <td>1.230002e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>ammonia</td>\n",
       "      <td>1.217619e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>78</th>\n",
       "      <td>tar</td>\n",
       "      <td>9.950263e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>coffee</td>\n",
       "      <td>9.441770e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>79</th>\n",
       "      <td>tea</td>\n",
       "      <td>9.331583e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>57</th>\n",
       "      <td>lavender</td>\n",
       "      <td>8.205826e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>chestnut</td>\n",
       "      <td>7.983100e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>84</th>\n",
       "      <td>violet</td>\n",
       "      <td>7.900472e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>67</th>\n",
       "      <td>pepper</td>\n",
       "      <td>7.814208e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>80</th>\n",
       "      <td>tobacco</td>\n",
       "      <td>7.573521e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>61</th>\n",
       "      <td>menthol</td>\n",
       "      <td>6.481601e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>76</th>\n",
       "      <td>strawberry</td>\n",
       "      <td>5.698856e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>70</th>\n",
       "      <td>plum</td>\n",
       "      <td>5.630726e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>65</th>\n",
       "      <td>peach</td>\n",
       "      <td>3.967352e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>66</th>\n",
       "      <td>pear</td>\n",
       "      <td>3.364481e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>69</th>\n",
       "      <td>pineapple</td>\n",
       "      <td>3.075626e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>blue cheese</td>\n",
       "      <td>2.811689e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>apple</td>\n",
       "      <td>2.807262e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>apricot</td>\n",
       "      <td>1.778255e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>epilepsy</td>\n",
       "      <td>1.630699e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>eye pressure</td>\n",
       "      <td>1.565304e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>pain</td>\n",
       "      <td>1.172404e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>seizures</td>\n",
       "      <td>1.110455e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>fatigue</td>\n",
       "      <td>1.104721e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>anxiety</td>\n",
       "      <td>9.625185e-05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>arthritis</td>\n",
       "      <td>8.405214e-05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>migraines</td>\n",
       "      <td>8.181540e-05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>depression</td>\n",
       "      <td>6.607941e-05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>stress</td>\n",
       "      <td>1.162002e-07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>spasticity</td>\n",
       "      <td>0.000000e+00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        features         score\n",
       "3          lsa_3  1.199720e-01\n",
       "0          lsa_0  1.128523e-01\n",
       "2          lsa_2  1.114470e-01\n",
       "4          lsa_4  1.113089e-01\n",
       "1          lsa_1  1.105654e-01\n",
       "50        diesel  4.583958e-02\n",
       "7         sativa  2.893210e-02\n",
       "5         hybrid  2.046522e-02\n",
       "64        orange  1.834213e-02\n",
       "83       vanilla  1.766437e-02\n",
       "58         lemon  1.396456e-02\n",
       "43     blueberry  1.292931e-02\n",
       "30       relaxed  1.251862e-02\n",
       "68          pine  1.101132e-02\n",
       "24         happy  1.031970e-02\n",
       "51        earthy  1.021625e-02\n",
       "19      euphoric  9.932710e-03\n",
       "37      uplifted  9.678354e-03\n",
       "41         berry  9.576231e-03\n",
       "17     energetic  9.137940e-03\n",
       "26        hungry  8.692636e-03\n",
       "22       focused  8.206745e-03\n",
       "16     dry mouth  8.154836e-03\n",
       "55    grapefruit  8.058501e-03\n",
       "12      creative  8.027912e-03\n",
       "32        sleepy  7.914771e-03\n",
       "45        cheese  7.887033e-03\n",
       "54         grape  7.553408e-03\n",
       "62          mint  7.108921e-03\n",
       "23        giggly  7.088950e-03\n",
       "35     talkative  7.048817e-03\n",
       "77         sweet  6.894058e-03\n",
       "85         woody  6.616006e-03\n",
       "15      dry eyes  6.463536e-03\n",
       "71       pungent  6.403594e-03\n",
       "36        tingly  6.336179e-03\n",
       "10       aroused  5.799534e-03\n",
       "48        citrus  5.456562e-03\n",
       "52       flowery  4.881621e-03\n",
       "74         skunk  4.488434e-03\n",
       "14         dizzy  4.252209e-03\n",
       "44        butter  4.105569e-03\n",
       "29      paranoid  3.319467e-03\n",
       "63         nutty  3.244711e-03\n",
       "75  spicy/herbal  3.074110e-03\n",
       "72          rose  2.898529e-03\n",
       "6         indica  2.796752e-03\n",
       "25      headache  2.381367e-03\n",
       "73          sage  2.302227e-03\n",
       "9        anxious  2.263336e-03\n",
       "82      tropical  1.906353e-03\n",
       "56         honey  1.806613e-03\n",
       "46      chemical  1.606136e-03\n",
       "81          tree  1.570133e-03\n",
       "60         mango  1.555344e-03\n",
       "59          lime  1.345073e-03\n",
       "53         fruit  1.230002e-03\n",
       "38       ammonia  1.217619e-03\n",
       "78           tar  9.950263e-04\n",
       "49        coffee  9.441770e-04\n",
       "79           tea  9.331583e-04\n",
       "57      lavender  8.205826e-04\n",
       "47      chestnut  7.983100e-04\n",
       "84        violet  7.900472e-04\n",
       "67        pepper  7.814208e-04\n",
       "80       tobacco  7.573521e-04\n",
       "61       menthol  6.481601e-04\n",
       "76    strawberry  5.698856e-04\n",
       "70          plum  5.630726e-04\n",
       "65         peach  3.967352e-04\n",
       "66          pear  3.364481e-04\n",
       "69     pineapple  3.075626e-04\n",
       "42   blue cheese  2.811689e-04\n",
       "39         apple  2.807262e-04\n",
       "40       apricot  1.778255e-04\n",
       "18      epilepsy  1.630699e-04\n",
       "20  eye pressure  1.565304e-04\n",
       "28          pain  1.172404e-04\n",
       "31      seizures  1.110455e-04\n",
       "21       fatigue  1.104721e-04\n",
       "8        anxiety  9.625185e-05\n",
       "11     arthritis  8.405214e-05\n",
       "27     migraines  8.181540e-05\n",
       "13    depression  6.607941e-05\n",
       "34        stress  1.162002e-07\n",
       "33    spasticity  0.000000e+00"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.set_option('display.max_rows', df_feat_ranked.shape[0]+1)\n",
    "df_feat_ranked"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/andalanputra/opt/anaconda3/lib/python3.9/site-packages/sklearn/feature_selection/_from_model.py:357: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  self.estimator_.fit(X, y, **fit_params)\n"
     ]
    }
   ],
   "source": [
    "selector = SelectFromModel(rfreg).fit(X_train1, y_train1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1.13134193e-01, 1.09812712e-01, 1.10930440e-01, 1.19709233e-01,\n",
       "       1.10662587e-01, 2.12993526e-02, 2.04463521e-03, 2.88237999e-02,\n",
       "       8.46640736e-05, 2.11771119e-03, 5.67347316e-03, 1.67427034e-04,\n",
       "       8.39750653e-03, 6.63589438e-05, 4.18608288e-03, 6.54144095e-03,\n",
       "       7.93809140e-03, 9.49795623e-03, 9.27429656e-05, 1.00070841e-02,\n",
       "       1.40811238e-04, 8.48674821e-05, 7.92017860e-03, 7.08640153e-03,\n",
       "       1.03730954e-02, 2.31955331e-03, 8.53421933e-03, 9.92721421e-05,\n",
       "       1.15538835e-04, 3.31974508e-03, 1.28687867e-02, 1.07809055e-04,\n",
       "       8.21189185e-03, 0.00000000e+00, 4.14097573e-07, 7.30359897e-03,\n",
       "       6.64797284e-03, 9.24416687e-03, 1.13133068e-03, 3.12559616e-04,\n",
       "       1.71077826e-04, 1.00118319e-02, 2.75019258e-04, 1.28581906e-02,\n",
       "       3.90096048e-03, 7.68820733e-03, 1.51800788e-03, 8.59376956e-04,\n",
       "       5.54721165e-03, 9.68981937e-04, 4.59020504e-02, 1.05978998e-02,\n",
       "       5.07255228e-03, 1.26368067e-03, 7.77386290e-03, 8.03351079e-03,\n",
       "       1.74433262e-03, 7.63663415e-04, 1.41287182e-02, 1.54413585e-03,\n",
       "       1.48441134e-03, 5.46859655e-04, 6.84616050e-03, 3.33522097e-03,\n",
       "       1.83328403e-02, 4.12264435e-04, 3.63677598e-04, 7.70107905e-04,\n",
       "       1.09841706e-02, 3.28524633e-04, 5.50499424e-04, 6.79151435e-03,\n",
       "       2.97097859e-03, 2.03005752e-03, 4.33991163e-03, 3.25806061e-03,\n",
       "       5.71656163e-04, 6.91295439e-03, 1.13876113e-03, 9.78758411e-04,\n",
       "       7.51402704e-04, 1.52968808e-03, 1.97759383e-03, 1.76773745e-02,\n",
       "       7.48834521e-04, 6.73473737e-03])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "selector.estimator_.feature_importances_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.011627906976744186"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "selector.threshold_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "mask = selector.get_support()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ True,  True,  True,  True,  True,  True, False,  True, False,\n",
       "       False, False, False, False, False, False, False, False, False,\n",
       "       False, False, False, False, False, False, False, False, False,\n",
       "       False, False, False,  True, False, False, False, False, False,\n",
       "       False, False, False, False, False, False, False,  True, False,\n",
       "       False, False, False, False, False,  True, False, False, False,\n",
       "       False, False, False, False,  True, False, False, False, False,\n",
       "       False,  True, False, False, False, False, False, False, False,\n",
       "       False, False, False, False, False, False, False, False, False,\n",
       "       False, False,  True, False, False])"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "selected_features = X.columns[mask]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>lsa_0</th>\n",
       "      <th>lsa_1</th>\n",
       "      <th>lsa_2</th>\n",
       "      <th>lsa_3</th>\n",
       "      <th>lsa_4</th>\n",
       "      <th>hybrid</th>\n",
       "      <th>sativa</th>\n",
       "      <th>relaxed</th>\n",
       "      <th>blueberry</th>\n",
       "      <th>diesel</th>\n",
       "      <th>lemon</th>\n",
       "      <th>orange</th>\n",
       "      <th>vanilla</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.341025</td>\n",
       "      <td>0.182753</td>\n",
       "      <td>0.008214</td>\n",
       "      <td>0.140406</td>\n",
       "      <td>-0.156943</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.232158</td>\n",
       "      <td>-0.045496</td>\n",
       "      <td>0.187131</td>\n",
       "      <td>-0.000936</td>\n",
       "      <td>0.018518</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.243491</td>\n",
       "      <td>0.034313</td>\n",
       "      <td>0.080290</td>\n",
       "      <td>-0.165609</td>\n",
       "      <td>0.019773</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.243491</td>\n",
       "      <td>0.034313</td>\n",
       "      <td>0.080290</td>\n",
       "      <td>-0.165609</td>\n",
       "      <td>0.019773</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.238648</td>\n",
       "      <td>-0.048758</td>\n",
       "      <td>-0.107398</td>\n",
       "      <td>-0.067096</td>\n",
       "      <td>-0.006558</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>74995</th>\n",
       "      <td>0.324915</td>\n",
       "      <td>0.131823</td>\n",
       "      <td>-0.099424</td>\n",
       "      <td>0.065491</td>\n",
       "      <td>0.038437</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>74996</th>\n",
       "      <td>0.324915</td>\n",
       "      <td>0.131823</td>\n",
       "      <td>-0.099424</td>\n",
       "      <td>0.065491</td>\n",
       "      <td>0.038437</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>74997</th>\n",
       "      <td>0.324915</td>\n",
       "      <td>0.131823</td>\n",
       "      <td>-0.099424</td>\n",
       "      <td>0.065491</td>\n",
       "      <td>0.038437</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>74998</th>\n",
       "      <td>0.270141</td>\n",
       "      <td>-0.004631</td>\n",
       "      <td>-0.151272</td>\n",
       "      <td>0.035538</td>\n",
       "      <td>0.083641</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>74999</th>\n",
       "      <td>0.270141</td>\n",
       "      <td>-0.004631</td>\n",
       "      <td>-0.151272</td>\n",
       "      <td>0.035538</td>\n",
       "      <td>0.083641</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>75000 rows × 13 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          lsa_0     lsa_1     lsa_2     lsa_3     lsa_4  hybrid  sativa  \\\n",
       "0      0.341025  0.182753  0.008214  0.140406 -0.156943       1       0   \n",
       "1      0.232158 -0.045496  0.187131 -0.000936  0.018518       1       0   \n",
       "2      0.243491  0.034313  0.080290 -0.165609  0.019773       1       0   \n",
       "3      0.243491  0.034313  0.080290 -0.165609  0.019773       1       0   \n",
       "4      0.238648 -0.048758 -0.107398 -0.067096 -0.006558       1       0   \n",
       "...         ...       ...       ...       ...       ...     ...     ...   \n",
       "74995  0.324915  0.131823 -0.099424  0.065491  0.038437       0       0   \n",
       "74996  0.324915  0.131823 -0.099424  0.065491  0.038437       0       0   \n",
       "74997  0.324915  0.131823 -0.099424  0.065491  0.038437       0       0   \n",
       "74998  0.270141 -0.004631 -0.151272  0.035538  0.083641       0       0   \n",
       "74999  0.270141 -0.004631 -0.151272  0.035538  0.083641       0       0   \n",
       "\n",
       "       relaxed  blueberry  diesel  lemon  orange  vanilla  \n",
       "0            1          0       0      0       0        0  \n",
       "1            1          0       0      0       0        1  \n",
       "2            1          0       0      0       0        0  \n",
       "3            1          0       0      0       0        0  \n",
       "4            0          0       0      0       0        0  \n",
       "...        ...        ...     ...    ...     ...      ...  \n",
       "74995        1          0       0      0       0        0  \n",
       "74996        1          0       0      0       0        0  \n",
       "74997        1          0       0      0       0        0  \n",
       "74998        1          1       1      1       1        1  \n",
       "74999        1          1       1      1       1        1  \n",
       "\n",
       "[75000 rows x 13 columns]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "selected_X = df_rf[selected_features]\n",
    "selected_X"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train test split (after Feature Selection)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['selected_X_rf_lsa_elbow_cbc.pkl']"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import joblib\n",
    "\n",
    "joblib.dump(selector, \"selector_rf_lsa_elbow_cbc.pkl\")\n",
    "joblib.dump(selected_X, \"selected_X_rf_lsa_elbow_cbc.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(selected_X, y, random_state=1, test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train1, X_val, y_train1, y_val = train_test_split(X_train, y_train, random_state=1, test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/y1/pjvjlkjn5gl846rnyzr53p340000gn/T/ipykernel_13386/3758305.py:1: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  rfreg.fit(X_train1, y_train1)\n"
     ]
    }
   ],
   "source": [
    "rfreg.fit(X_train1, y_train1)\n",
    "y_pred_rfreg = rfreg.predict(X_val)\n",
    "y_pred_rfreg_r2 = rfreg.predict(X_train1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.048995060986859566"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mean_absolute_error(y_val, y_pred_rfreg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.011313724503133438"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mean_squared_error(y_val, y_pred_rfreg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.10636599317043695"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mean_squared_error(y_val, y_pred_rfreg, squared = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9602869519650639"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#train\n",
    "r2_score(y_train1, y_pred_rfreg_r2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8511472068485446"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#val\n",
    "r2_score(y_val, y_pred_rfreg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hyperparameter Tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "parameters = { 'max_depth': [None, 10, 50, 100],\n",
    "              'max_features': ['auto', 'sqrt'],\n",
    "              'min_samples_leaf': [1, 2, 4],\n",
    "              'min_samples_split': [2, 5, 10],\n",
    "              'n_estimators': [100, 300, 500]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "rscv = RandomizedSearchCV(rfreg,  \n",
    "                     parameters,   \n",
    "                     cv=5, \n",
    "                     scoring='neg_mean_absolute_error',\n",
    "                     n_jobs= -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/andalanputra/opt/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/Users/andalanputra/opt/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/Users/andalanputra/opt/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/Users/andalanputra/opt/anaconda3/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
      "  warn(\n",
      "/Users/andalanputra/opt/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/Users/andalanputra/opt/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/Users/andalanputra/opt/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/Users/andalanputra/opt/anaconda3/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
      "  warn(\n",
      "/Users/andalanputra/opt/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/Users/andalanputra/opt/anaconda3/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
      "  warn(\n",
      "/Users/andalanputra/opt/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/Users/andalanputra/opt/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/Users/andalanputra/opt/anaconda3/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
      "  warn(\n",
      "/Users/andalanputra/opt/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/Users/andalanputra/opt/anaconda3/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
      "  warn(\n",
      "/Users/andalanputra/opt/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/Users/andalanputra/opt/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/Users/andalanputra/opt/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/Users/andalanputra/opt/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/Users/andalanputra/opt/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/Users/andalanputra/opt/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/Users/andalanputra/opt/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/Users/andalanputra/opt/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/Users/andalanputra/opt/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/Users/andalanputra/opt/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/Users/andalanputra/opt/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/Users/andalanputra/opt/anaconda3/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
      "  warn(\n",
      "/Users/andalanputra/opt/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/Users/andalanputra/opt/anaconda3/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
      "  warn(\n",
      "/Users/andalanputra/opt/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/Users/andalanputra/opt/anaconda3/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
      "  warn(\n",
      "/Users/andalanputra/opt/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/Users/andalanputra/opt/anaconda3/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
      "  warn(\n",
      "/Users/andalanputra/opt/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/Users/andalanputra/opt/anaconda3/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
      "  warn(\n",
      "/Users/andalanputra/opt/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/Users/andalanputra/opt/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/Users/andalanputra/opt/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/Users/andalanputra/opt/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/Users/andalanputra/opt/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/Users/andalanputra/opt/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/Users/andalanputra/opt/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/Users/andalanputra/opt/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/Users/andalanputra/opt/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/Users/andalanputra/opt/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/Users/andalanputra/opt/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/Users/andalanputra/opt/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/Users/andalanputra/opt/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/Users/andalanputra/opt/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/Users/andalanputra/opt/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/Users/andalanputra/opt/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/Users/andalanputra/opt/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/Users/andalanputra/opt/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/Users/andalanputra/opt/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/Users/andalanputra/opt/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/Users/andalanputra/opt/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/Users/andalanputra/opt/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/Users/andalanputra/opt/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/Users/andalanputra/opt/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/Users/andalanputra/opt/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/Users/andalanputra/opt/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_search.py:909: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  self.best_estimator_.fit(X, y, **fit_params)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-2 {color: black;background-color: white;}#sk-container-id-2 pre{padding: 0;}#sk-container-id-2 div.sk-toggleable {background-color: white;}#sk-container-id-2 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-2 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-2 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-2 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-2 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-2 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-2 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-2 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-2 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-2 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-2 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-2 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-2 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-2 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-2 div.sk-item {position: relative;z-index: 1;}#sk-container-id-2 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-2 div.sk-item::before, #sk-container-id-2 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-2 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-2 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-2 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-2 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-2 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-2 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-2 div.sk-label-container {text-align: center;}#sk-container-id-2 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-2 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-2\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>RandomizedSearchCV(cv=5, estimator=RandomForestRegressor(n_jobs=-1), n_jobs=-1,\n",
       "                   param_distributions={&#x27;max_depth&#x27;: [None, 10, 50, 100],\n",
       "                                        &#x27;max_features&#x27;: [&#x27;auto&#x27;, &#x27;sqrt&#x27;],\n",
       "                                        &#x27;min_samples_leaf&#x27;: [1, 2, 4],\n",
       "                                        &#x27;min_samples_split&#x27;: [2, 5, 10],\n",
       "                                        &#x27;n_estimators&#x27;: [100, 300, 500]},\n",
       "                   scoring=&#x27;neg_mean_absolute_error&#x27;)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" ><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">RandomizedSearchCV</label><div class=\"sk-toggleable__content\"><pre>RandomizedSearchCV(cv=5, estimator=RandomForestRegressor(n_jobs=-1), n_jobs=-1,\n",
       "                   param_distributions={&#x27;max_depth&#x27;: [None, 10, 50, 100],\n",
       "                                        &#x27;max_features&#x27;: [&#x27;auto&#x27;, &#x27;sqrt&#x27;],\n",
       "                                        &#x27;min_samples_leaf&#x27;: [1, 2, 4],\n",
       "                                        &#x27;min_samples_split&#x27;: [2, 5, 10],\n",
       "                                        &#x27;n_estimators&#x27;: [100, 300, 500]},\n",
       "                   scoring=&#x27;neg_mean_absolute_error&#x27;)</pre></div></div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-3\" type=\"checkbox\" ><label for=\"sk-estimator-id-3\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">estimator: RandomForestRegressor</label><div class=\"sk-toggleable__content\"><pre>RandomForestRegressor(n_jobs=-1)</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-4\" type=\"checkbox\" ><label for=\"sk-estimator-id-4\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">RandomForestRegressor</label><div class=\"sk-toggleable__content\"><pre>RandomForestRegressor(n_jobs=-1)</pre></div></div></div></div></div></div></div></div></div></div>"
      ],
      "text/plain": [
       "RandomizedSearchCV(cv=5, estimator=RandomForestRegressor(n_jobs=-1), n_jobs=-1,\n",
       "                   param_distributions={'max_depth': [None, 10, 50, 100],\n",
       "                                        'max_features': ['auto', 'sqrt'],\n",
       "                                        'min_samples_leaf': [1, 2, 4],\n",
       "                                        'min_samples_split': [2, 5, 10],\n",
       "                                        'n_estimators': [100, 300, 500]},\n",
       "                   scoring='neg_mean_absolute_error')"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rscv.fit(X_train1, y_train1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'n_estimators': 500,\n",
       " 'min_samples_split': 2,\n",
       " 'min_samples_leaf': 1,\n",
       " 'max_features': 'sqrt',\n",
       " 'max_depth': 50}"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rscv.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['rscv_rf_lsa_elbow_best_params_cbc.pkl']"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "joblib.dump(rscv, \"rscv_rf_lsa_elbow_cbc.pkl\")\n",
    "joblib.dump(rscv.best_params_, \"rscv_rf_lsa_elbow_best_params_cbc.pkl\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "RF (after Hyperparameter Tuning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/y1/pjvjlkjn5gl846rnyzr53p340000gn/T/ipykernel_13386/2121118255.py:2: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  rfreg_ht.fit(X_train1, y_train1)\n"
     ]
    }
   ],
   "source": [
    "rfreg_ht = RandomForestRegressor(n_estimators = 500, min_samples_split = 2, max_features = 'sqrt', min_samples_leaf = 1, max_depth = 50)\n",
    "rfreg_ht.fit(X_train1, y_train1)\n",
    "y_pred_rfreg = rfreg_ht.predict(X_val)\n",
    "y_pred_rfreg_r2 = rfreg_ht.predict(X_train1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.04755933791593095"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mean_absolute_error(y_val, y_pred_rfreg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.010440828007120078"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mean_squared_error(y_val, y_pred_rfreg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.10218036996957917"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mean_squared_error(y_val, y_pred_rfreg, squared = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9620216978668112"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#train\n",
    "r2_score(y_train1, y_pred_rfreg_r2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8626317609869913"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#val\n",
    "r2_score(y_val, y_pred_rfreg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Residual plots after Hyperparameter Tuning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Predicting model on the test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_rfreg_test = rfreg_ht.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['y_test_rfreg_lsa_elbow_cbc.pkl']"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "joblib.dump(y_pred_rfreg_test, \"y_pred_rfreg_test_lsa_elbow_cbc.pkl\")\n",
    "joblib.dump(y_test, \"y_test_rfreg_lsa_elbow_cbc.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.04915670203043289"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mean_absolute_error(y_test, y_pred_rfreg_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.010492962581004288"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mean_squared_error(y_test, y_pred_rfreg_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.10243516281533548"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mean_squared_error(y_test, y_pred_rfreg_test, squared = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8621194386906271"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "r2_score(y_test, y_pred_rfreg_test)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Error analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 576x432 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 432x288 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# assume y_pred is a numpy array and y_true is a pandas dataframe\n",
    "fig, ax = plt.subplots(figsize=(8, 6))\n",
    "\n",
    "column = \"X..CBC\"  # specify the target variable name\n",
    "ax.hist(y_pred_rfreg_test, alpha=0.5, label='y_pred', bins=20)\n",
    "ax.hist(y_test[column], alpha=0.5, label='y_true', bins=20)\n",
    "ax.legend(loc='upper right')\n",
    "ax.set_title(column)\n",
    "\n",
    "plt.show()\n",
    "plt.savefig('error_hist_rf_lsa_elbow_cbc.png')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pearson R"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pearson correlation coefficient: 0.935\n",
      "P-value: 0.000\n"
     ]
    }
   ],
   "source": [
    "corr_coef, p_value = pearsonr(y_pred_rfreg_test.flatten(), y_test.values.ravel())\n",
    "\n",
    "print(f\"Pearson correlation coefficient: {corr_coef:.3f}\")\n",
    "print(f\"P-value: {p_value:.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:>"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "corr_matrix = y_test.corr()\n",
    "sns.heatmap(corr_matrix, annot=True, cmap='coolwarm', center=0)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
