{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn import preprocessing\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.neural_network import MLPRegressor\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "from sklearn.metrics import r2_score\n",
    "from scipy.stats import pearsonr\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.feature_selection import SelectFromModel\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compiling complete dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_rf = pd.read_csv(\"df_thcv_tfidf.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['index',\n",
       " 'tfidf_0',\n",
       " 'tfidf_1',\n",
       " 'tfidf_2',\n",
       " 'tfidf_3',\n",
       " 'tfidf_4',\n",
       " 'tfidf_5',\n",
       " 'tfidf_6',\n",
       " 'tfidf_7',\n",
       " 'tfidf_8',\n",
       " 'tfidf_9',\n",
       " 'tfidf_10',\n",
       " 'tfidf_11',\n",
       " 'tfidf_12',\n",
       " 'tfidf_13',\n",
       " 'tfidf_14',\n",
       " 'tfidf_15',\n",
       " 'tfidf_16',\n",
       " 'tfidf_17',\n",
       " 'tfidf_18',\n",
       " 'tfidf_19',\n",
       " 'tfidf_20',\n",
       " 'tfidf_21',\n",
       " 'tfidf_22',\n",
       " 'tfidf_23',\n",
       " 'tfidf_24',\n",
       " 'tfidf_25',\n",
       " 'tfidf_26',\n",
       " 'tfidf_27',\n",
       " 'tfidf_28',\n",
       " 'tfidf_29',\n",
       " 'tfidf_30',\n",
       " 'tfidf_31',\n",
       " 'tfidf_32',\n",
       " 'tfidf_33',\n",
       " 'tfidf_34',\n",
       " 'tfidf_35',\n",
       " 'tfidf_36',\n",
       " 'tfidf_37',\n",
       " 'tfidf_38',\n",
       " 'tfidf_39',\n",
       " 'tfidf_40',\n",
       " 'tfidf_41',\n",
       " 'tfidf_42',\n",
       " 'tfidf_43',\n",
       " 'tfidf_44',\n",
       " 'tfidf_45',\n",
       " 'tfidf_46',\n",
       " 'tfidf_47',\n",
       " 'tfidf_48',\n",
       " 'tfidf_49',\n",
       " 'tfidf_50',\n",
       " 'tfidf_51',\n",
       " 'tfidf_52',\n",
       " 'tfidf_53',\n",
       " 'tfidf_54',\n",
       " 'tfidf_55',\n",
       " 'tfidf_56',\n",
       " 'tfidf_57',\n",
       " 'tfidf_58',\n",
       " 'tfidf_59',\n",
       " 'tfidf_60',\n",
       " 'tfidf_61',\n",
       " 'tfidf_62',\n",
       " 'tfidf_63',\n",
       " 'tfidf_64',\n",
       " 'tfidf_65',\n",
       " 'tfidf_66',\n",
       " 'tfidf_67',\n",
       " 'tfidf_68',\n",
       " 'tfidf_69',\n",
       " 'tfidf_70',\n",
       " 'tfidf_71',\n",
       " 'tfidf_72',\n",
       " 'tfidf_73',\n",
       " 'tfidf_74',\n",
       " 'tfidf_75',\n",
       " 'tfidf_76',\n",
       " 'tfidf_77',\n",
       " 'tfidf_78',\n",
       " 'tfidf_79',\n",
       " 'tfidf_80',\n",
       " 'tfidf_81',\n",
       " 'tfidf_82',\n",
       " 'tfidf_83',\n",
       " 'tfidf_84',\n",
       " 'tfidf_85',\n",
       " 'tfidf_86',\n",
       " 'tfidf_87',\n",
       " 'tfidf_88',\n",
       " 'tfidf_89',\n",
       " 'tfidf_90',\n",
       " 'tfidf_91',\n",
       " 'tfidf_92',\n",
       " 'tfidf_93',\n",
       " 'tfidf_94',\n",
       " 'tfidf_95',\n",
       " 'tfidf_96',\n",
       " 'tfidf_97',\n",
       " 'tfidf_98',\n",
       " 'tfidf_99',\n",
       " 'tfidf_100',\n",
       " 'tfidf_101',\n",
       " 'tfidf_102',\n",
       " 'tfidf_103',\n",
       " 'tfidf_104',\n",
       " 'tfidf_105',\n",
       " 'tfidf_106',\n",
       " 'tfidf_107',\n",
       " 'tfidf_108',\n",
       " 'tfidf_109',\n",
       " 'tfidf_110',\n",
       " 'tfidf_111',\n",
       " 'tfidf_112',\n",
       " 'tfidf_113',\n",
       " 'tfidf_114',\n",
       " 'tfidf_115',\n",
       " 'tfidf_116',\n",
       " 'tfidf_117',\n",
       " 'tfidf_118',\n",
       " 'tfidf_119',\n",
       " 'tfidf_120',\n",
       " 'tfidf_121',\n",
       " 'tfidf_122',\n",
       " 'tfidf_123',\n",
       " 'tfidf_124',\n",
       " 'tfidf_125',\n",
       " 'tfidf_126',\n",
       " 'tfidf_127',\n",
       " 'tfidf_128',\n",
       " 'tfidf_129',\n",
       " 'tfidf_130',\n",
       " 'tfidf_131',\n",
       " 'tfidf_132',\n",
       " 'tfidf_133',\n",
       " 'tfidf_134',\n",
       " 'tfidf_135',\n",
       " 'tfidf_136',\n",
       " 'tfidf_137',\n",
       " 'tfidf_138',\n",
       " 'tfidf_139',\n",
       " 'tfidf_140',\n",
       " 'tfidf_141',\n",
       " 'tfidf_142',\n",
       " 'tfidf_143',\n",
       " 'tfidf_144',\n",
       " 'tfidf_145',\n",
       " 'tfidf_146',\n",
       " 'tfidf_147',\n",
       " 'tfidf_148',\n",
       " 'tfidf_149',\n",
       " 'tfidf_150',\n",
       " 'tfidf_151',\n",
       " 'tfidf_152',\n",
       " 'tfidf_153',\n",
       " 'tfidf_154',\n",
       " 'tfidf_155',\n",
       " 'tfidf_156',\n",
       " 'tfidf_157',\n",
       " 'tfidf_158',\n",
       " 'tfidf_159',\n",
       " 'tfidf_160',\n",
       " 'tfidf_161',\n",
       " 'tfidf_162',\n",
       " 'tfidf_163',\n",
       " 'tfidf_164',\n",
       " 'tfidf_165',\n",
       " 'tfidf_166',\n",
       " 'tfidf_167',\n",
       " 'tfidf_168',\n",
       " 'tfidf_169',\n",
       " 'tfidf_170',\n",
       " 'tfidf_171',\n",
       " 'tfidf_172',\n",
       " 'tfidf_173',\n",
       " 'tfidf_174',\n",
       " 'tfidf_175',\n",
       " 'tfidf_176',\n",
       " 'tfidf_177',\n",
       " 'tfidf_178',\n",
       " 'tfidf_179',\n",
       " 'tfidf_180',\n",
       " 'tfidf_181',\n",
       " 'tfidf_182',\n",
       " 'tfidf_183',\n",
       " 'tfidf_184',\n",
       " 'tfidf_185',\n",
       " 'tfidf_186',\n",
       " 'tfidf_187',\n",
       " 'tfidf_188',\n",
       " 'tfidf_189',\n",
       " 'tfidf_190',\n",
       " 'tfidf_191',\n",
       " 'tfidf_192',\n",
       " 'tfidf_193',\n",
       " 'tfidf_194',\n",
       " 'tfidf_195',\n",
       " 'tfidf_196',\n",
       " 'tfidf_197',\n",
       " 'tfidf_198',\n",
       " 'tfidf_199',\n",
       " 'tfidf_200',\n",
       " 'tfidf_201',\n",
       " 'tfidf_202',\n",
       " 'tfidf_203',\n",
       " 'tfidf_204',\n",
       " 'tfidf_205',\n",
       " 'tfidf_206',\n",
       " 'tfidf_207',\n",
       " 'tfidf_208',\n",
       " 'tfidf_209',\n",
       " 'tfidf_210',\n",
       " 'tfidf_211',\n",
       " 'tfidf_212',\n",
       " 'tfidf_213',\n",
       " 'tfidf_214',\n",
       " 'tfidf_215',\n",
       " 'tfidf_216',\n",
       " 'tfidf_217',\n",
       " 'tfidf_218',\n",
       " 'tfidf_219',\n",
       " 'tfidf_220',\n",
       " 'tfidf_221',\n",
       " 'tfidf_222',\n",
       " 'tfidf_223',\n",
       " 'tfidf_224',\n",
       " 'tfidf_225',\n",
       " 'tfidf_226',\n",
       " 'tfidf_227',\n",
       " 'tfidf_228',\n",
       " 'tfidf_229',\n",
       " 'tfidf_230',\n",
       " 'tfidf_231',\n",
       " 'tfidf_232',\n",
       " 'tfidf_233',\n",
       " 'tfidf_234',\n",
       " 'tfidf_235',\n",
       " 'tfidf_236',\n",
       " 'tfidf_237',\n",
       " 'tfidf_238',\n",
       " 'tfidf_239',\n",
       " 'tfidf_240',\n",
       " 'tfidf_241',\n",
       " 'tfidf_242',\n",
       " 'tfidf_243',\n",
       " 'tfidf_244',\n",
       " 'tfidf_245',\n",
       " 'tfidf_246',\n",
       " 'tfidf_247',\n",
       " 'tfidf_248',\n",
       " 'tfidf_249',\n",
       " 'tfidf_250',\n",
       " 'tfidf_251',\n",
       " 'tfidf_252',\n",
       " 'tfidf_253',\n",
       " 'tfidf_254',\n",
       " 'tfidf_255',\n",
       " 'tfidf_256',\n",
       " 'tfidf_257',\n",
       " 'tfidf_258',\n",
       " 'tfidf_259',\n",
       " 'tfidf_260',\n",
       " 'tfidf_261',\n",
       " 'tfidf_262',\n",
       " 'tfidf_263',\n",
       " 'tfidf_264',\n",
       " 'tfidf_265',\n",
       " 'tfidf_266',\n",
       " 'tfidf_267',\n",
       " 'tfidf_268',\n",
       " 'tfidf_269',\n",
       " 'tfidf_270',\n",
       " 'tfidf_271',\n",
       " 'tfidf_272',\n",
       " 'tfidf_273',\n",
       " 'tfidf_274',\n",
       " 'tfidf_275',\n",
       " 'tfidf_276',\n",
       " 'tfidf_277',\n",
       " 'tfidf_278',\n",
       " 'tfidf_279',\n",
       " 'tfidf_280',\n",
       " 'tfidf_281',\n",
       " 'tfidf_282',\n",
       " 'tfidf_283',\n",
       " 'tfidf_284',\n",
       " 'tfidf_285',\n",
       " 'tfidf_286',\n",
       " 'tfidf_287',\n",
       " 'tfidf_288',\n",
       " 'tfidf_289',\n",
       " 'tfidf_290',\n",
       " 'tfidf_291',\n",
       " 'tfidf_292',\n",
       " 'tfidf_293',\n",
       " 'tfidf_294',\n",
       " 'tfidf_295',\n",
       " 'tfidf_296',\n",
       " 'tfidf_297',\n",
       " 'tfidf_298',\n",
       " 'tfidf_299',\n",
       " 'tfidf_300',\n",
       " 'tfidf_301',\n",
       " 'tfidf_302',\n",
       " 'tfidf_303',\n",
       " 'tfidf_304',\n",
       " 'tfidf_305',\n",
       " 'tfidf_306',\n",
       " 'tfidf_307',\n",
       " 'tfidf_308',\n",
       " 'tfidf_309',\n",
       " 'tfidf_310',\n",
       " 'tfidf_311',\n",
       " 'tfidf_312',\n",
       " 'tfidf_313',\n",
       " 'tfidf_314',\n",
       " 'tfidf_315',\n",
       " 'tfidf_316',\n",
       " 'tfidf_317',\n",
       " 'tfidf_318',\n",
       " 'tfidf_319',\n",
       " 'tfidf_320',\n",
       " 'tfidf_321',\n",
       " 'tfidf_322',\n",
       " 'tfidf_323',\n",
       " 'tfidf_324',\n",
       " 'tfidf_325',\n",
       " 'tfidf_326',\n",
       " 'tfidf_327',\n",
       " 'tfidf_328',\n",
       " 'tfidf_329',\n",
       " 'tfidf_330',\n",
       " 'tfidf_331',\n",
       " 'tfidf_332',\n",
       " 'tfidf_333',\n",
       " 'tfidf_334',\n",
       " 'tfidf_335',\n",
       " 'tfidf_336',\n",
       " 'tfidf_337',\n",
       " 'tfidf_338',\n",
       " 'tfidf_339',\n",
       " 'tfidf_340',\n",
       " 'tfidf_341',\n",
       " 'tfidf_342',\n",
       " 'tfidf_343',\n",
       " 'tfidf_344',\n",
       " 'tfidf_345',\n",
       " 'tfidf_346',\n",
       " 'tfidf_347',\n",
       " 'tfidf_348',\n",
       " 'tfidf_349',\n",
       " 'tfidf_350',\n",
       " 'tfidf_351',\n",
       " 'tfidf_352',\n",
       " 'tfidf_353',\n",
       " 'tfidf_354',\n",
       " 'tfidf_355',\n",
       " 'tfidf_356',\n",
       " 'tfidf_357',\n",
       " 'tfidf_358',\n",
       " 'tfidf_359',\n",
       " 'tfidf_360',\n",
       " 'tfidf_361',\n",
       " 'tfidf_362',\n",
       " 'tfidf_363',\n",
       " 'tfidf_364',\n",
       " 'tfidf_365',\n",
       " 'tfidf_366',\n",
       " 'tfidf_367',\n",
       " 'tfidf_368',\n",
       " 'tfidf_369',\n",
       " 'tfidf_370',\n",
       " 'tfidf_371',\n",
       " 'tfidf_372',\n",
       " 'tfidf_373',\n",
       " 'tfidf_374',\n",
       " 'tfidf_375',\n",
       " 'tfidf_376',\n",
       " 'tfidf_377',\n",
       " 'tfidf_378',\n",
       " 'tfidf_379',\n",
       " 'tfidf_380',\n",
       " 'tfidf_381',\n",
       " 'tfidf_382',\n",
       " 'tfidf_383',\n",
       " 'tfidf_384',\n",
       " 'tfidf_385',\n",
       " 'tfidf_386',\n",
       " 'tfidf_387',\n",
       " 'hybrid',\n",
       " 'indica',\n",
       " 'sativa',\n",
       " 'anxiety',\n",
       " 'anxious',\n",
       " 'aroused',\n",
       " 'arthritis',\n",
       " 'creative',\n",
       " 'depression',\n",
       " 'dizzy',\n",
       " 'dry eyes',\n",
       " 'dry mouth',\n",
       " 'energetic',\n",
       " 'epilepsy',\n",
       " 'euphoric',\n",
       " 'eye pressure',\n",
       " 'fatigue',\n",
       " 'focused',\n",
       " 'giggly',\n",
       " 'happy',\n",
       " 'headache',\n",
       " 'hungry',\n",
       " 'migraines',\n",
       " 'pain',\n",
       " 'paranoid',\n",
       " 'relaxed',\n",
       " 'seizures',\n",
       " 'sleepy',\n",
       " 'spasticity',\n",
       " 'stress',\n",
       " 'talkative',\n",
       " 'tingly',\n",
       " 'uplifted',\n",
       " 'ammonia',\n",
       " 'apple',\n",
       " 'apricot',\n",
       " 'berry',\n",
       " 'blue cheese',\n",
       " 'blueberry',\n",
       " 'butter',\n",
       " 'cheese',\n",
       " 'chemical',\n",
       " 'chestnut',\n",
       " 'citrus',\n",
       " 'coffee',\n",
       " 'diesel',\n",
       " 'earthy',\n",
       " 'flowery',\n",
       " 'fruit',\n",
       " 'grape',\n",
       " 'grapefruit',\n",
       " 'honey',\n",
       " 'lavender',\n",
       " 'lemon',\n",
       " 'lime',\n",
       " 'mango',\n",
       " 'menthol',\n",
       " 'mint',\n",
       " 'nutty',\n",
       " 'orange',\n",
       " 'peach',\n",
       " 'pear',\n",
       " 'pepper',\n",
       " 'pine',\n",
       " 'pineapple',\n",
       " 'plum',\n",
       " 'pungent',\n",
       " 'rose',\n",
       " 'sage',\n",
       " 'skunk',\n",
       " 'spicy/herbal',\n",
       " 'strawberry',\n",
       " 'sweet',\n",
       " 'tar',\n",
       " 'tea',\n",
       " 'tobacco',\n",
       " 'tree',\n",
       " 'tropical',\n",
       " 'vanilla',\n",
       " 'violet',\n",
       " 'woody',\n",
       " 'X..THCV']"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_rf.columns.to_list()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Splitting dependent and independent variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df_rf.drop(['index', 'X..THCV'], axis = 1)\n",
    "y = df_rf[['X..THCV']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plotting histograms on target variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.03092784],\n",
       "       [0.03092784],\n",
       "       [0.03092784],\n",
       "       ...,\n",
       "       [0.15463918],\n",
       "       [0.15463918],\n",
       "       [0.15463918]])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_array = y.to_numpy()\n",
    "y_array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Axes: ylabel='Count'>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "sns.histplot(y, bins = 10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train test split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=1, test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train1, X_val, y_train1, y_val = train_test_split(X_train, y_train, random_state=1, test_size=0.25)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "RF modeling (before Feature selection and Hyperparameter Tuning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/ns/m5pnr0211w91v02hpv22958m0000gn/T/ipykernel_88939/350139188.py:2: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  rfreg.fit(X_train1, y_train1)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;background-color: white;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>RandomForestRegressor()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">RandomForestRegressor</label><div class=\"sk-toggleable__content\"><pre>RandomForestRegressor()</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "RandomForestRegressor()"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rfreg = RandomForestRegressor()\n",
    "rfreg.fit(X_train1, y_train1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_rfreg = rfreg.predict(X_val)\n",
    "y_pred_rfreg_r2 = rfreg.predict(X_train1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.012955338223744074"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mean_absolute_error(y_val, y_pred_rfreg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0024511209831902924"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mean_squared_error(y_val, y_pred_rfreg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.049508797028308946"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mean_squared_error(y_val, y_pred_rfreg, squared = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9903618586728513"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#train\n",
    "r2_score(y_train1, y_pred_rfreg_r2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9799679944362413"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#val\n",
    "r2_score(y_val, y_pred_rfreg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Residual plots for each target variable"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Feature Selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_feat = pd.DataFrame({\n",
    "    \"features\": X_train1.columns,\n",
    "    \"score\": rfreg.feature_importances_\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>features</th>\n",
       "      <th>score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>tfidf_0</td>\n",
       "      <td>0.000200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>tfidf_1</td>\n",
       "      <td>0.000012</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>tfidf_2</td>\n",
       "      <td>0.000096</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>tfidf_3</td>\n",
       "      <td>0.000572</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>tfidf_4</td>\n",
       "      <td>0.001707</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>464</th>\n",
       "      <td>tree</td>\n",
       "      <td>0.000021</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>465</th>\n",
       "      <td>tropical</td>\n",
       "      <td>0.000093</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>466</th>\n",
       "      <td>vanilla</td>\n",
       "      <td>0.000072</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>467</th>\n",
       "      <td>violet</td>\n",
       "      <td>0.000004</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>468</th>\n",
       "      <td>woody</td>\n",
       "      <td>0.000353</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>469 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     features     score\n",
       "0     tfidf_0  0.000200\n",
       "1     tfidf_1  0.000012\n",
       "2     tfidf_2  0.000096\n",
       "3     tfidf_3  0.000572\n",
       "4     tfidf_4  0.001707\n",
       "..        ...       ...\n",
       "464      tree  0.000021\n",
       "465  tropical  0.000093\n",
       "466   vanilla  0.000072\n",
       "467    violet  0.000004\n",
       "468     woody  0.000353\n",
       "\n",
       "[469 rows x 2 columns]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_feat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_feat_ranked = df_feat.sort_values(\"score\", ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>features</th>\n",
       "      <th>score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>388</th>\n",
       "      <td>hybrid</td>\n",
       "      <td>2.649031e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>442</th>\n",
       "      <td>lime</td>\n",
       "      <td>1.032429e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>329</th>\n",
       "      <td>tfidf_329</td>\n",
       "      <td>3.377811e-02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>428</th>\n",
       "      <td>cheese</td>\n",
       "      <td>2.529199e-02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>431</th>\n",
       "      <td>citrus</td>\n",
       "      <td>2.510699e-02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>173</th>\n",
       "      <td>tfidf_173</td>\n",
       "      <td>1.968425e-02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>415</th>\n",
       "      <td>sleepy</td>\n",
       "      <td>1.945040e-02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>165</th>\n",
       "      <td>tfidf_165</td>\n",
       "      <td>1.915327e-02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>149</th>\n",
       "      <td>tfidf_149</td>\n",
       "      <td>1.672243e-02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>tfidf_97</td>\n",
       "      <td>1.463868e-02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>236</th>\n",
       "      <td>tfidf_236</td>\n",
       "      <td>1.450761e-02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>355</th>\n",
       "      <td>tfidf_355</td>\n",
       "      <td>1.444622e-02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>288</th>\n",
       "      <td>tfidf_288</td>\n",
       "      <td>1.371909e-02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>406</th>\n",
       "      <td>giggly</td>\n",
       "      <td>1.321744e-02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>163</th>\n",
       "      <td>tfidf_163</td>\n",
       "      <td>1.317515e-02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>145</th>\n",
       "      <td>tfidf_145</td>\n",
       "      <td>1.272533e-02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>245</th>\n",
       "      <td>tfidf_245</td>\n",
       "      <td>1.219378e-02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>291</th>\n",
       "      <td>tfidf_291</td>\n",
       "      <td>1.023757e-02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>312</th>\n",
       "      <td>tfidf_312</td>\n",
       "      <td>1.012455e-02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>168</th>\n",
       "      <td>tfidf_168</td>\n",
       "      <td>9.797227e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>402</th>\n",
       "      <td>euphoric</td>\n",
       "      <td>9.746783e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>395</th>\n",
       "      <td>creative</td>\n",
       "      <td>9.487908e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>167</th>\n",
       "      <td>tfidf_167</td>\n",
       "      <td>9.234840e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>460</th>\n",
       "      <td>sweet</td>\n",
       "      <td>9.120556e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>200</th>\n",
       "      <td>tfidf_200</td>\n",
       "      <td>8.984860e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>161</th>\n",
       "      <td>tfidf_161</td>\n",
       "      <td>6.857506e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>121</th>\n",
       "      <td>tfidf_121</td>\n",
       "      <td>6.819664e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>141</th>\n",
       "      <td>tfidf_141</td>\n",
       "      <td>6.819315e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>234</th>\n",
       "      <td>tfidf_234</td>\n",
       "      <td>6.744356e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>78</th>\n",
       "      <td>tfidf_78</td>\n",
       "      <td>6.369843e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>207</th>\n",
       "      <td>tfidf_207</td>\n",
       "      <td>6.167513e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>82</th>\n",
       "      <td>tfidf_82</td>\n",
       "      <td>5.834080e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>tfidf_26</td>\n",
       "      <td>5.746394e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>345</th>\n",
       "      <td>tfidf_345</td>\n",
       "      <td>5.199211e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>433</th>\n",
       "      <td>diesel</td>\n",
       "      <td>5.040527e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>434</th>\n",
       "      <td>earthy</td>\n",
       "      <td>4.709965e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>tfidf_43</td>\n",
       "      <td>4.600295e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>160</th>\n",
       "      <td>tfidf_160</td>\n",
       "      <td>4.474011e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>93</th>\n",
       "      <td>tfidf_93</td>\n",
       "      <td>4.371716e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>357</th>\n",
       "      <td>tfidf_357</td>\n",
       "      <td>4.326457e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>437</th>\n",
       "      <td>grape</td>\n",
       "      <td>4.236871e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>80</th>\n",
       "      <td>tfidf_80</td>\n",
       "      <td>4.080059e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>405</th>\n",
       "      <td>focused</td>\n",
       "      <td>4.014851e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>409</th>\n",
       "      <td>hungry</td>\n",
       "      <td>4.004472e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>235</th>\n",
       "      <td>tfidf_235</td>\n",
       "      <td>3.983566e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>253</th>\n",
       "      <td>tfidf_253</td>\n",
       "      <td>3.562002e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>199</th>\n",
       "      <td>tfidf_199</td>\n",
       "      <td>3.546574e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>304</th>\n",
       "      <td>tfidf_304</td>\n",
       "      <td>3.406805e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>239</th>\n",
       "      <td>tfidf_239</td>\n",
       "      <td>3.359015e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>454</th>\n",
       "      <td>pungent</td>\n",
       "      <td>3.224509e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>376</th>\n",
       "      <td>tfidf_376</td>\n",
       "      <td>3.177833e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>447</th>\n",
       "      <td>orange</td>\n",
       "      <td>3.164462e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>117</th>\n",
       "      <td>tfidf_117</td>\n",
       "      <td>3.097391e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>285</th>\n",
       "      <td>tfidf_285</td>\n",
       "      <td>3.050532e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>162</th>\n",
       "      <td>tfidf_162</td>\n",
       "      <td>2.927450e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>419</th>\n",
       "      <td>tingly</td>\n",
       "      <td>2.903620e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>309</th>\n",
       "      <td>tfidf_309</td>\n",
       "      <td>2.856444e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>243</th>\n",
       "      <td>tfidf_243</td>\n",
       "      <td>2.793350e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>202</th>\n",
       "      <td>tfidf_202</td>\n",
       "      <td>2.785786e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51</th>\n",
       "      <td>tfidf_51</td>\n",
       "      <td>2.753927e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>374</th>\n",
       "      <td>tfidf_374</td>\n",
       "      <td>2.652834e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>314</th>\n",
       "      <td>tfidf_314</td>\n",
       "      <td>2.496994e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>386</th>\n",
       "      <td>tfidf_386</td>\n",
       "      <td>2.443936e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>281</th>\n",
       "      <td>tfidf_281</td>\n",
       "      <td>2.428023e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>119</th>\n",
       "      <td>tfidf_119</td>\n",
       "      <td>2.410830e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>tfidf_28</td>\n",
       "      <td>2.392389e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>399</th>\n",
       "      <td>dry mouth</td>\n",
       "      <td>2.257910e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>tfidf_13</td>\n",
       "      <td>2.257596e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>150</th>\n",
       "      <td>tfidf_150</td>\n",
       "      <td>2.250384e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>422</th>\n",
       "      <td>apple</td>\n",
       "      <td>2.228937e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>420</th>\n",
       "      <td>uplifted</td>\n",
       "      <td>2.040118e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>307</th>\n",
       "      <td>tfidf_307</td>\n",
       "      <td>2.033282e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>222</th>\n",
       "      <td>tfidf_222</td>\n",
       "      <td>1.967825e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>267</th>\n",
       "      <td>tfidf_267</td>\n",
       "      <td>1.884789e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>128</th>\n",
       "      <td>tfidf_128</td>\n",
       "      <td>1.771868e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>73</th>\n",
       "      <td>tfidf_73</td>\n",
       "      <td>1.712835e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>389</th>\n",
       "      <td>indica</td>\n",
       "      <td>1.707542e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>tfidf_4</td>\n",
       "      <td>1.706918e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>358</th>\n",
       "      <td>tfidf_358</td>\n",
       "      <td>1.689872e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>424</th>\n",
       "      <td>berry</td>\n",
       "      <td>1.572431e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>146</th>\n",
       "      <td>tfidf_146</td>\n",
       "      <td>1.501301e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>144</th>\n",
       "      <td>tfidf_144</td>\n",
       "      <td>1.478810e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>158</th>\n",
       "      <td>tfidf_158</td>\n",
       "      <td>1.433898e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>tfidf_37</td>\n",
       "      <td>1.374869e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>337</th>\n",
       "      <td>tfidf_337</td>\n",
       "      <td>1.351902e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>413</th>\n",
       "      <td>relaxed</td>\n",
       "      <td>1.343555e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>tfidf_11</td>\n",
       "      <td>1.298042e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>tfidf_7</td>\n",
       "      <td>1.286003e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>191</th>\n",
       "      <td>tfidf_191</td>\n",
       "      <td>1.230869e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>230</th>\n",
       "      <td>tfidf_230</td>\n",
       "      <td>1.226065e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>318</th>\n",
       "      <td>tfidf_318</td>\n",
       "      <td>1.163486e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>441</th>\n",
       "      <td>lemon</td>\n",
       "      <td>1.152388e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>tfidf_21</td>\n",
       "      <td>1.150616e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>210</th>\n",
       "      <td>tfidf_210</td>\n",
       "      <td>1.115506e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>322</th>\n",
       "      <td>tfidf_322</td>\n",
       "      <td>1.092614e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>65</th>\n",
       "      <td>tfidf_65</td>\n",
       "      <td>1.085325e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>270</th>\n",
       "      <td>tfidf_270</td>\n",
       "      <td>1.074401e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>tfidf_5</td>\n",
       "      <td>1.069066e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>362</th>\n",
       "      <td>tfidf_362</td>\n",
       "      <td>1.050763e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>177</th>\n",
       "      <td>tfidf_177</td>\n",
       "      <td>1.038925e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>tfidf_30</td>\n",
       "      <td>1.034522e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>tfidf_23</td>\n",
       "      <td>1.025596e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>151</th>\n",
       "      <td>tfidf_151</td>\n",
       "      <td>1.019694e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>393</th>\n",
       "      <td>aroused</td>\n",
       "      <td>1.013227e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>205</th>\n",
       "      <td>tfidf_205</td>\n",
       "      <td>9.986131e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>407</th>\n",
       "      <td>happy</td>\n",
       "      <td>9.818767e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>418</th>\n",
       "      <td>talkative</td>\n",
       "      <td>9.736765e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52</th>\n",
       "      <td>tfidf_52</td>\n",
       "      <td>9.644926e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>380</th>\n",
       "      <td>tfidf_380</td>\n",
       "      <td>9.198831e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>tfidf_20</td>\n",
       "      <td>8.602528e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>457</th>\n",
       "      <td>skunk</td>\n",
       "      <td>8.511339e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>400</th>\n",
       "      <td>energetic</td>\n",
       "      <td>8.478768e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>382</th>\n",
       "      <td>tfidf_382</td>\n",
       "      <td>8.445344e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>300</th>\n",
       "      <td>tfidf_300</td>\n",
       "      <td>8.429617e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>390</th>\n",
       "      <td>sativa</td>\n",
       "      <td>8.410174e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>101</th>\n",
       "      <td>tfidf_101</td>\n",
       "      <td>8.408262e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>373</th>\n",
       "      <td>tfidf_373</td>\n",
       "      <td>8.372552e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>398</th>\n",
       "      <td>dry eyes</td>\n",
       "      <td>8.370628e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>tfidf_19</td>\n",
       "      <td>8.156405e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>276</th>\n",
       "      <td>tfidf_276</td>\n",
       "      <td>8.053203e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>350</th>\n",
       "      <td>tfidf_350</td>\n",
       "      <td>7.635822e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>240</th>\n",
       "      <td>tfidf_240</td>\n",
       "      <td>7.627133e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>178</th>\n",
       "      <td>tfidf_178</td>\n",
       "      <td>7.475767e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>426</th>\n",
       "      <td>blueberry</td>\n",
       "      <td>7.279714e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>tfidf_46</td>\n",
       "      <td>7.132885e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>103</th>\n",
       "      <td>tfidf_103</td>\n",
       "      <td>6.984190e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>175</th>\n",
       "      <td>tfidf_175</td>\n",
       "      <td>6.971808e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>340</th>\n",
       "      <td>tfidf_340</td>\n",
       "      <td>6.948278e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>336</th>\n",
       "      <td>tfidf_336</td>\n",
       "      <td>6.900636e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>190</th>\n",
       "      <td>tfidf_190</td>\n",
       "      <td>6.730377e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>366</th>\n",
       "      <td>tfidf_366</td>\n",
       "      <td>6.658042e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>361</th>\n",
       "      <td>tfidf_361</td>\n",
       "      <td>6.495118e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>451</th>\n",
       "      <td>pine</td>\n",
       "      <td>6.432582e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>85</th>\n",
       "      <td>tfidf_85</td>\n",
       "      <td>6.237511e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75</th>\n",
       "      <td>tfidf_75</td>\n",
       "      <td>6.187331e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>208</th>\n",
       "      <td>tfidf_208</td>\n",
       "      <td>5.909482e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>338</th>\n",
       "      <td>tfidf_338</td>\n",
       "      <td>5.833557e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>116</th>\n",
       "      <td>tfidf_116</td>\n",
       "      <td>5.803195e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>tfidf_3</td>\n",
       "      <td>5.722776e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>283</th>\n",
       "      <td>tfidf_283</td>\n",
       "      <td>5.649269e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>86</th>\n",
       "      <td>tfidf_86</td>\n",
       "      <td>5.505581e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>435</th>\n",
       "      <td>flowery</td>\n",
       "      <td>5.489934e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>262</th>\n",
       "      <td>tfidf_262</td>\n",
       "      <td>5.350398e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>tfidf_98</td>\n",
       "      <td>5.282878e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>324</th>\n",
       "      <td>tfidf_324</td>\n",
       "      <td>5.206372e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>81</th>\n",
       "      <td>tfidf_81</td>\n",
       "      <td>5.198656e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>126</th>\n",
       "      <td>tfidf_126</td>\n",
       "      <td>5.178093e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>271</th>\n",
       "      <td>tfidf_271</td>\n",
       "      <td>5.033450e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>445</th>\n",
       "      <td>mint</td>\n",
       "      <td>4.998413e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>107</th>\n",
       "      <td>tfidf_107</td>\n",
       "      <td>4.868873e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>tfidf_24</td>\n",
       "      <td>4.707715e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>228</th>\n",
       "      <td>tfidf_228</td>\n",
       "      <td>4.596954e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>tfidf_48</td>\n",
       "      <td>4.498876e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>203</th>\n",
       "      <td>tfidf_203</td>\n",
       "      <td>4.471079e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>319</th>\n",
       "      <td>tfidf_319</td>\n",
       "      <td>4.390795e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>tfidf_29</td>\n",
       "      <td>4.386514e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>298</th>\n",
       "      <td>tfidf_298</td>\n",
       "      <td>4.365387e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>342</th>\n",
       "      <td>tfidf_342</td>\n",
       "      <td>4.108592e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>154</th>\n",
       "      <td>tfidf_154</td>\n",
       "      <td>4.050308e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>64</th>\n",
       "      <td>tfidf_64</td>\n",
       "      <td>4.012526e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>279</th>\n",
       "      <td>tfidf_279</td>\n",
       "      <td>3.978938e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>124</th>\n",
       "      <td>tfidf_124</td>\n",
       "      <td>3.954503e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>79</th>\n",
       "      <td>tfidf_79</td>\n",
       "      <td>3.902356e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>69</th>\n",
       "      <td>tfidf_69</td>\n",
       "      <td>3.868379e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>249</th>\n",
       "      <td>tfidf_249</td>\n",
       "      <td>3.678508e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>135</th>\n",
       "      <td>tfidf_135</td>\n",
       "      <td>3.593500e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>343</th>\n",
       "      <td>tfidf_343</td>\n",
       "      <td>3.548655e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>194</th>\n",
       "      <td>tfidf_194</td>\n",
       "      <td>3.537794e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>468</th>\n",
       "      <td>woody</td>\n",
       "      <td>3.534224e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>341</th>\n",
       "      <td>tfidf_341</td>\n",
       "      <td>3.500653e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>364</th>\n",
       "      <td>tfidf_364</td>\n",
       "      <td>3.482993e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>258</th>\n",
       "      <td>tfidf_258</td>\n",
       "      <td>3.425133e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>104</th>\n",
       "      <td>tfidf_104</td>\n",
       "      <td>3.391487e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>325</th>\n",
       "      <td>tfidf_325</td>\n",
       "      <td>3.384099e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>286</th>\n",
       "      <td>tfidf_286</td>\n",
       "      <td>3.370643e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>392</th>\n",
       "      <td>anxious</td>\n",
       "      <td>3.325690e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>367</th>\n",
       "      <td>tfidf_367</td>\n",
       "      <td>3.231073e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>354</th>\n",
       "      <td>tfidf_354</td>\n",
       "      <td>3.219333e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>360</th>\n",
       "      <td>tfidf_360</td>\n",
       "      <td>3.216486e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>182</th>\n",
       "      <td>tfidf_182</td>\n",
       "      <td>3.165534e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>125</th>\n",
       "      <td>tfidf_125</td>\n",
       "      <td>3.094531e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>123</th>\n",
       "      <td>tfidf_123</td>\n",
       "      <td>3.042475e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>385</th>\n",
       "      <td>tfidf_385</td>\n",
       "      <td>3.032838e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>277</th>\n",
       "      <td>tfidf_277</td>\n",
       "      <td>2.920719e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>397</th>\n",
       "      <td>dizzy</td>\n",
       "      <td>2.786340e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>88</th>\n",
       "      <td>tfidf_88</td>\n",
       "      <td>2.765484e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>290</th>\n",
       "      <td>tfidf_290</td>\n",
       "      <td>2.756611e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>tfidf_14</td>\n",
       "      <td>2.727580e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>292</th>\n",
       "      <td>tfidf_292</td>\n",
       "      <td>2.709556e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>129</th>\n",
       "      <td>tfidf_129</td>\n",
       "      <td>2.660983e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>tfidf_39</td>\n",
       "      <td>2.628068e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>371</th>\n",
       "      <td>tfidf_371</td>\n",
       "      <td>2.555182e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>273</th>\n",
       "      <td>tfidf_273</td>\n",
       "      <td>2.453721e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>188</th>\n",
       "      <td>tfidf_188</td>\n",
       "      <td>2.362573e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>352</th>\n",
       "      <td>tfidf_352</td>\n",
       "      <td>2.346948e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>217</th>\n",
       "      <td>tfidf_217</td>\n",
       "      <td>2.253163e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>297</th>\n",
       "      <td>tfidf_297</td>\n",
       "      <td>2.234360e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>351</th>\n",
       "      <td>tfidf_351</td>\n",
       "      <td>2.202693e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>323</th>\n",
       "      <td>tfidf_323</td>\n",
       "      <td>2.158286e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>197</th>\n",
       "      <td>tfidf_197</td>\n",
       "      <td>2.113464e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>206</th>\n",
       "      <td>tfidf_206</td>\n",
       "      <td>2.110866e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>tfidf_45</td>\n",
       "      <td>2.072574e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>130</th>\n",
       "      <td>tfidf_130</td>\n",
       "      <td>2.071323e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>105</th>\n",
       "      <td>tfidf_105</td>\n",
       "      <td>2.057576e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>63</th>\n",
       "      <td>tfidf_63</td>\n",
       "      <td>2.049142e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>139</th>\n",
       "      <td>tfidf_139</td>\n",
       "      <td>2.003615e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>tfidf_0</td>\n",
       "      <td>1.995830e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>387</th>\n",
       "      <td>tfidf_387</td>\n",
       "      <td>1.988413e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>tfidf_22</td>\n",
       "      <td>1.922303e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>166</th>\n",
       "      <td>tfidf_166</td>\n",
       "      <td>1.912662e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>221</th>\n",
       "      <td>tfidf_221</td>\n",
       "      <td>1.906118e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>109</th>\n",
       "      <td>tfidf_109</td>\n",
       "      <td>1.898070e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>68</th>\n",
       "      <td>tfidf_68</td>\n",
       "      <td>1.881781e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>tfidf_96</td>\n",
       "      <td>1.848226e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>264</th>\n",
       "      <td>tfidf_264</td>\n",
       "      <td>1.846930e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>311</th>\n",
       "      <td>tfidf_311</td>\n",
       "      <td>1.820485e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>408</th>\n",
       "      <td>headache</td>\n",
       "      <td>1.802506e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>353</th>\n",
       "      <td>tfidf_353</td>\n",
       "      <td>1.801133e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>136</th>\n",
       "      <td>tfidf_136</td>\n",
       "      <td>1.774792e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>tfidf_95</td>\n",
       "      <td>1.740589e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>452</th>\n",
       "      <td>pineapple</td>\n",
       "      <td>1.706375e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>56</th>\n",
       "      <td>tfidf_56</td>\n",
       "      <td>1.700553e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>131</th>\n",
       "      <td>tfidf_131</td>\n",
       "      <td>1.678189e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>184</th>\n",
       "      <td>tfidf_184</td>\n",
       "      <td>1.667387e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>227</th>\n",
       "      <td>tfidf_227</td>\n",
       "      <td>1.655477e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>246</th>\n",
       "      <td>tfidf_246</td>\n",
       "      <td>1.636222e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>87</th>\n",
       "      <td>tfidf_87</td>\n",
       "      <td>1.634416e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>294</th>\n",
       "      <td>tfidf_294</td>\n",
       "      <td>1.615589e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>153</th>\n",
       "      <td>tfidf_153</td>\n",
       "      <td>1.605233e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>185</th>\n",
       "      <td>tfidf_185</td>\n",
       "      <td>1.600755e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>346</th>\n",
       "      <td>tfidf_346</td>\n",
       "      <td>1.591130e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>198</th>\n",
       "      <td>tfidf_198</td>\n",
       "      <td>1.588454e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>tfidf_6</td>\n",
       "      <td>1.576677e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>370</th>\n",
       "      <td>tfidf_370</td>\n",
       "      <td>1.570432e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>333</th>\n",
       "      <td>tfidf_333</td>\n",
       "      <td>1.565937e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>223</th>\n",
       "      <td>tfidf_223</td>\n",
       "      <td>1.545155e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>90</th>\n",
       "      <td>tfidf_90</td>\n",
       "      <td>1.500720e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>278</th>\n",
       "      <td>tfidf_278</td>\n",
       "      <td>1.427403e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>127</th>\n",
       "      <td>tfidf_127</td>\n",
       "      <td>1.424136e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>102</th>\n",
       "      <td>tfidf_102</td>\n",
       "      <td>1.398544e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>tfidf_40</td>\n",
       "      <td>1.393068e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>275</th>\n",
       "      <td>tfidf_275</td>\n",
       "      <td>1.328188e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>232</th>\n",
       "      <td>tfidf_232</td>\n",
       "      <td>1.312392e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54</th>\n",
       "      <td>tfidf_54</td>\n",
       "      <td>1.274839e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>326</th>\n",
       "      <td>tfidf_326</td>\n",
       "      <td>1.220610e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>152</th>\n",
       "      <td>tfidf_152</td>\n",
       "      <td>1.215518e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>110</th>\n",
       "      <td>tfidf_110</td>\n",
       "      <td>1.198964e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>289</th>\n",
       "      <td>tfidf_289</td>\n",
       "      <td>1.184729e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>299</th>\n",
       "      <td>tfidf_299</td>\n",
       "      <td>1.179231e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>193</th>\n",
       "      <td>tfidf_193</td>\n",
       "      <td>1.171892e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>242</th>\n",
       "      <td>tfidf_242</td>\n",
       "      <td>1.159113e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>211</th>\n",
       "      <td>tfidf_211</td>\n",
       "      <td>1.152976e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>tfidf_10</td>\n",
       "      <td>1.138468e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>229</th>\n",
       "      <td>tfidf_229</td>\n",
       "      <td>1.134181e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>171</th>\n",
       "      <td>tfidf_171</td>\n",
       "      <td>1.118411e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>379</th>\n",
       "      <td>tfidf_379</td>\n",
       "      <td>1.098865e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>429</th>\n",
       "      <td>chemical</td>\n",
       "      <td>1.098496e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>344</th>\n",
       "      <td>tfidf_344</td>\n",
       "      <td>1.097486e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>303</th>\n",
       "      <td>tfidf_303</td>\n",
       "      <td>1.091774e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>381</th>\n",
       "      <td>tfidf_381</td>\n",
       "      <td>1.061415e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>226</th>\n",
       "      <td>tfidf_226</td>\n",
       "      <td>1.048148e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>113</th>\n",
       "      <td>tfidf_113</td>\n",
       "      <td>1.014055e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>189</th>\n",
       "      <td>tfidf_189</td>\n",
       "      <td>9.966942e-05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>233</th>\n",
       "      <td>tfidf_233</td>\n",
       "      <td>9.964612e-05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>61</th>\n",
       "      <td>tfidf_61</td>\n",
       "      <td>9.893818e-05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>248</th>\n",
       "      <td>tfidf_248</td>\n",
       "      <td>9.789262e-05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>tfidf_99</td>\n",
       "      <td>9.718603e-05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>tfidf_2</td>\n",
       "      <td>9.635137e-05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>tfidf_42</td>\n",
       "      <td>9.539705e-05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>465</th>\n",
       "      <td>tropical</td>\n",
       "      <td>9.340795e-05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>58</th>\n",
       "      <td>tfidf_58</td>\n",
       "      <td>9.276213e-05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>60</th>\n",
       "      <td>tfidf_60</td>\n",
       "      <td>8.861253e-05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>tfidf_17</td>\n",
       "      <td>8.818458e-05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>tfidf_34</td>\n",
       "      <td>8.796009e-05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>316</th>\n",
       "      <td>tfidf_316</td>\n",
       "      <td>8.620930e-05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>274</th>\n",
       "      <td>tfidf_274</td>\n",
       "      <td>8.472700e-05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>tfidf_41</td>\n",
       "      <td>8.116235e-05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>215</th>\n",
       "      <td>tfidf_215</td>\n",
       "      <td>8.098788e-05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>272</th>\n",
       "      <td>tfidf_272</td>\n",
       "      <td>7.993683e-05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>71</th>\n",
       "      <td>tfidf_71</td>\n",
       "      <td>7.973850e-05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>259</th>\n",
       "      <td>tfidf_259</td>\n",
       "      <td>7.833635e-05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>295</th>\n",
       "      <td>tfidf_295</td>\n",
       "      <td>7.779102e-05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>tfidf_31</td>\n",
       "      <td>7.726718e-05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>308</th>\n",
       "      <td>tfidf_308</td>\n",
       "      <td>7.689452e-05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>84</th>\n",
       "      <td>tfidf_84</td>\n",
       "      <td>7.407499e-05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>349</th>\n",
       "      <td>tfidf_349</td>\n",
       "      <td>7.309889e-05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>138</th>\n",
       "      <td>tfidf_138</td>\n",
       "      <td>7.249110e-05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>466</th>\n",
       "      <td>vanilla</td>\n",
       "      <td>7.211577e-05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>216</th>\n",
       "      <td>tfidf_216</td>\n",
       "      <td>7.170269e-05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>tfidf_32</td>\n",
       "      <td>7.080009e-05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>147</th>\n",
       "      <td>tfidf_147</td>\n",
       "      <td>7.041002e-05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>320</th>\n",
       "      <td>tfidf_320</td>\n",
       "      <td>6.961021e-05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>120</th>\n",
       "      <td>tfidf_120</td>\n",
       "      <td>6.908445e-05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>tfidf_12</td>\n",
       "      <td>6.864939e-05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>254</th>\n",
       "      <td>tfidf_254</td>\n",
       "      <td>6.737970e-05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>tfidf_16</td>\n",
       "      <td>6.708656e-05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>55</th>\n",
       "      <td>tfidf_55</td>\n",
       "      <td>6.648421e-05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>156</th>\n",
       "      <td>tfidf_156</td>\n",
       "      <td>6.619884e-05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>260</th>\n",
       "      <td>tfidf_260</td>\n",
       "      <td>6.611504e-05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>67</th>\n",
       "      <td>tfidf_67</td>\n",
       "      <td>6.578842e-05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>180</th>\n",
       "      <td>tfidf_180</td>\n",
       "      <td>6.550173e-05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>tfidf_35</td>\n",
       "      <td>6.454752e-05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>332</th>\n",
       "      <td>tfidf_332</td>\n",
       "      <td>6.369728e-05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>368</th>\n",
       "      <td>tfidf_368</td>\n",
       "      <td>6.261654e-05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>280</th>\n",
       "      <td>tfidf_280</td>\n",
       "      <td>6.234993e-05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>170</th>\n",
       "      <td>tfidf_170</td>\n",
       "      <td>5.911909e-05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>261</th>\n",
       "      <td>tfidf_261</td>\n",
       "      <td>5.820111e-05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>237</th>\n",
       "      <td>tfidf_237</td>\n",
       "      <td>5.737123e-05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>339</th>\n",
       "      <td>tfidf_339</td>\n",
       "      <td>5.647155e-05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>287</th>\n",
       "      <td>tfidf_287</td>\n",
       "      <td>5.645043e-05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>231</th>\n",
       "      <td>tfidf_231</td>\n",
       "      <td>5.575636e-05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>179</th>\n",
       "      <td>tfidf_179</td>\n",
       "      <td>5.253777e-05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>220</th>\n",
       "      <td>tfidf_220</td>\n",
       "      <td>5.233022e-05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>159</th>\n",
       "      <td>tfidf_159</td>\n",
       "      <td>5.227667e-05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>238</th>\n",
       "      <td>tfidf_238</td>\n",
       "      <td>5.169937e-05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>115</th>\n",
       "      <td>tfidf_115</td>\n",
       "      <td>5.130411e-05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>183</th>\n",
       "      <td>tfidf_183</td>\n",
       "      <td>5.079811e-05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>66</th>\n",
       "      <td>tfidf_66</td>\n",
       "      <td>5.046173e-05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>438</th>\n",
       "      <td>grapefruit</td>\n",
       "      <td>5.001800e-05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>91</th>\n",
       "      <td>tfidf_91</td>\n",
       "      <td>4.902169e-05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>252</th>\n",
       "      <td>tfidf_252</td>\n",
       "      <td>4.897056e-05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>196</th>\n",
       "      <td>tfidf_196</td>\n",
       "      <td>4.863871e-05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>257</th>\n",
       "      <td>tfidf_257</td>\n",
       "      <td>4.829323e-05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>tfidf_9</td>\n",
       "      <td>4.799232e-05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>443</th>\n",
       "      <td>mango</td>\n",
       "      <td>4.762640e-05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>225</th>\n",
       "      <td>tfidf_225</td>\n",
       "      <td>4.636858e-05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>83</th>\n",
       "      <td>tfidf_83</td>\n",
       "      <td>4.623388e-05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>106</th>\n",
       "      <td>tfidf_106</td>\n",
       "      <td>4.522909e-05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>412</th>\n",
       "      <td>paranoid</td>\n",
       "      <td>4.353682e-05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>459</th>\n",
       "      <td>strawberry</td>\n",
       "      <td>4.272681e-05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>263</th>\n",
       "      <td>tfidf_263</td>\n",
       "      <td>4.240475e-05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>164</th>\n",
       "      <td>tfidf_164</td>\n",
       "      <td>4.178735e-05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>375</th>\n",
       "      <td>tfidf_375</td>\n",
       "      <td>4.086138e-05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>157</th>\n",
       "      <td>tfidf_157</td>\n",
       "      <td>4.007429e-05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>268</th>\n",
       "      <td>tfidf_268</td>\n",
       "      <td>3.928309e-05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>456</th>\n",
       "      <td>sage</td>\n",
       "      <td>3.907778e-05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>282</th>\n",
       "      <td>tfidf_282</td>\n",
       "      <td>3.837373e-05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>70</th>\n",
       "      <td>tfidf_70</td>\n",
       "      <td>3.738149e-05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>tfidf_8</td>\n",
       "      <td>3.720607e-05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>335</th>\n",
       "      <td>tfidf_335</td>\n",
       "      <td>3.684941e-05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50</th>\n",
       "      <td>tfidf_50</td>\n",
       "      <td>3.649132e-05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>251</th>\n",
       "      <td>tfidf_251</td>\n",
       "      <td>3.621127e-05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>tfidf_36</td>\n",
       "      <td>3.595940e-05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>255</th>\n",
       "      <td>tfidf_255</td>\n",
       "      <td>3.584880e-05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>265</th>\n",
       "      <td>tfidf_265</td>\n",
       "      <td>3.512516e-05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>334</th>\n",
       "      <td>tfidf_334</td>\n",
       "      <td>3.511584e-05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>140</th>\n",
       "      <td>tfidf_140</td>\n",
       "      <td>3.452125e-05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>122</th>\n",
       "      <td>tfidf_122</td>\n",
       "      <td>3.427484e-05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>62</th>\n",
       "      <td>tfidf_62</td>\n",
       "      <td>3.339792e-05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>186</th>\n",
       "      <td>tfidf_186</td>\n",
       "      <td>3.252546e-05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>57</th>\n",
       "      <td>tfidf_57</td>\n",
       "      <td>3.217371e-05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>327</th>\n",
       "      <td>tfidf_327</td>\n",
       "      <td>3.171197e-05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53</th>\n",
       "      <td>tfidf_53</td>\n",
       "      <td>3.137454e-05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>458</th>\n",
       "      <td>spicy/herbal</td>\n",
       "      <td>3.106160e-05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>143</th>\n",
       "      <td>tfidf_143</td>\n",
       "      <td>3.044629e-05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>250</th>\n",
       "      <td>tfidf_250</td>\n",
       "      <td>3.011802e-05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>133</th>\n",
       "      <td>tfidf_133</td>\n",
       "      <td>2.900171e-05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>369</th>\n",
       "      <td>tfidf_369</td>\n",
       "      <td>2.893336e-05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>172</th>\n",
       "      <td>tfidf_172</td>\n",
       "      <td>2.883310e-05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>348</th>\n",
       "      <td>tfidf_348</td>\n",
       "      <td>2.859111e-05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>tfidf_44</td>\n",
       "      <td>2.843331e-05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>450</th>\n",
       "      <td>pepper</td>\n",
       "      <td>2.834317e-05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>310</th>\n",
       "      <td>tfidf_310</td>\n",
       "      <td>2.812930e-05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>377</th>\n",
       "      <td>tfidf_377</td>\n",
       "      <td>2.801570e-05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>306</th>\n",
       "      <td>tfidf_306</td>\n",
       "      <td>2.708432e-05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>92</th>\n",
       "      <td>tfidf_92</td>\n",
       "      <td>2.587913e-05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>tfidf_15</td>\n",
       "      <td>2.557276e-05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>317</th>\n",
       "      <td>tfidf_317</td>\n",
       "      <td>2.550695e-05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>302</th>\n",
       "      <td>tfidf_302</td>\n",
       "      <td>2.544843e-05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>134</th>\n",
       "      <td>tfidf_134</td>\n",
       "      <td>2.511190e-05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>155</th>\n",
       "      <td>tfidf_155</td>\n",
       "      <td>2.464291e-05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>256</th>\n",
       "      <td>tfidf_256</td>\n",
       "      <td>2.414415e-05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>169</th>\n",
       "      <td>tfidf_169</td>\n",
       "      <td>2.393079e-05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>313</th>\n",
       "      <td>tfidf_313</td>\n",
       "      <td>2.379702e-05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>100</th>\n",
       "      <td>tfidf_100</td>\n",
       "      <td>2.349975e-05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>74</th>\n",
       "      <td>tfidf_74</td>\n",
       "      <td>2.299944e-05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>321</th>\n",
       "      <td>tfidf_321</td>\n",
       "      <td>2.291264e-05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>132</th>\n",
       "      <td>tfidf_132</td>\n",
       "      <td>2.281833e-05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>247</th>\n",
       "      <td>tfidf_247</td>\n",
       "      <td>2.270527e-05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>363</th>\n",
       "      <td>tfidf_363</td>\n",
       "      <td>2.255321e-05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>372</th>\n",
       "      <td>tfidf_372</td>\n",
       "      <td>2.248823e-05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>94</th>\n",
       "      <td>tfidf_94</td>\n",
       "      <td>2.201541e-05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>112</th>\n",
       "      <td>tfidf_112</td>\n",
       "      <td>2.194135e-05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>181</th>\n",
       "      <td>tfidf_181</td>\n",
       "      <td>2.193170e-05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>224</th>\n",
       "      <td>tfidf_224</td>\n",
       "      <td>2.126808e-05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>213</th>\n",
       "      <td>tfidf_213</td>\n",
       "      <td>2.101175e-05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>108</th>\n",
       "      <td>tfidf_108</td>\n",
       "      <td>2.084061e-05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>464</th>\n",
       "      <td>tree</td>\n",
       "      <td>2.070276e-05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>176</th>\n",
       "      <td>tfidf_176</td>\n",
       "      <td>2.067988e-05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>301</th>\n",
       "      <td>tfidf_301</td>\n",
       "      <td>2.064201e-05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>305</th>\n",
       "      <td>tfidf_305</td>\n",
       "      <td>2.063158e-05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>137</th>\n",
       "      <td>tfidf_137</td>\n",
       "      <td>2.031219e-05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>142</th>\n",
       "      <td>tfidf_142</td>\n",
       "      <td>1.961882e-05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>201</th>\n",
       "      <td>tfidf_201</td>\n",
       "      <td>1.946902e-05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>293</th>\n",
       "      <td>tfidf_293</td>\n",
       "      <td>1.925567e-05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>423</th>\n",
       "      <td>apricot</td>\n",
       "      <td>1.923490e-05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>365</th>\n",
       "      <td>tfidf_365</td>\n",
       "      <td>1.909631e-05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>218</th>\n",
       "      <td>tfidf_218</td>\n",
       "      <td>1.908644e-05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>383</th>\n",
       "      <td>tfidf_383</td>\n",
       "      <td>1.723534e-05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>76</th>\n",
       "      <td>tfidf_76</td>\n",
       "      <td>1.676327e-05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>432</th>\n",
       "      <td>coffee</td>\n",
       "      <td>1.646652e-05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>tfidf_49</td>\n",
       "      <td>1.604559e-05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>315</th>\n",
       "      <td>tfidf_315</td>\n",
       "      <td>1.572510e-05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>436</th>\n",
       "      <td>fruit</td>\n",
       "      <td>1.505971e-05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>148</th>\n",
       "      <td>tfidf_148</td>\n",
       "      <td>1.491469e-05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>330</th>\n",
       "      <td>tfidf_330</td>\n",
       "      <td>1.472842e-05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>449</th>\n",
       "      <td>pear</td>\n",
       "      <td>1.469985e-05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>tfidf_18</td>\n",
       "      <td>1.465559e-05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>114</th>\n",
       "      <td>tfidf_114</td>\n",
       "      <td>1.457405e-05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>212</th>\n",
       "      <td>tfidf_212</td>\n",
       "      <td>1.435445e-05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>89</th>\n",
       "      <td>tfidf_89</td>\n",
       "      <td>1.424348e-05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>111</th>\n",
       "      <td>tfidf_111</td>\n",
       "      <td>1.398615e-05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>266</th>\n",
       "      <td>tfidf_266</td>\n",
       "      <td>1.329637e-05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>187</th>\n",
       "      <td>tfidf_187</td>\n",
       "      <td>1.317715e-05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>359</th>\n",
       "      <td>tfidf_359</td>\n",
       "      <td>1.315426e-05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>tfidf_27</td>\n",
       "      <td>1.265170e-05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>347</th>\n",
       "      <td>tfidf_347</td>\n",
       "      <td>1.229425e-05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>tfidf_1</td>\n",
       "      <td>1.221465e-05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>118</th>\n",
       "      <td>tfidf_118</td>\n",
       "      <td>1.201870e-05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>174</th>\n",
       "      <td>tfidf_174</td>\n",
       "      <td>1.201405e-05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>430</th>\n",
       "      <td>chestnut</td>\n",
       "      <td>1.170298e-05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>tfidf_47</td>\n",
       "      <td>1.148453e-05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>331</th>\n",
       "      <td>tfidf_331</td>\n",
       "      <td>1.085553e-05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>440</th>\n",
       "      <td>lavender</td>\n",
       "      <td>1.082984e-05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>421</th>\n",
       "      <td>ammonia</td>\n",
       "      <td>1.059456e-05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>72</th>\n",
       "      <td>tfidf_72</td>\n",
       "      <td>1.030968e-05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>244</th>\n",
       "      <td>tfidf_244</td>\n",
       "      <td>8.912341e-06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>192</th>\n",
       "      <td>tfidf_192</td>\n",
       "      <td>8.461149e-06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>356</th>\n",
       "      <td>tfidf_356</td>\n",
       "      <td>8.437157e-06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>tfidf_25</td>\n",
       "      <td>7.983180e-06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>tfidf_33</td>\n",
       "      <td>7.581075e-06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>269</th>\n",
       "      <td>tfidf_269</td>\n",
       "      <td>6.949518e-06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59</th>\n",
       "      <td>tfidf_59</td>\n",
       "      <td>6.649978e-06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>204</th>\n",
       "      <td>tfidf_204</td>\n",
       "      <td>5.608428e-06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>214</th>\n",
       "      <td>tfidf_214</td>\n",
       "      <td>5.545533e-06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>195</th>\n",
       "      <td>tfidf_195</td>\n",
       "      <td>5.439169e-06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>446</th>\n",
       "      <td>nutty</td>\n",
       "      <td>5.257192e-06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>296</th>\n",
       "      <td>tfidf_296</td>\n",
       "      <td>5.061194e-06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>284</th>\n",
       "      <td>tfidf_284</td>\n",
       "      <td>4.923063e-06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>378</th>\n",
       "      <td>tfidf_378</td>\n",
       "      <td>4.921997e-06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>328</th>\n",
       "      <td>tfidf_328</td>\n",
       "      <td>4.806074e-06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>384</th>\n",
       "      <td>tfidf_384</td>\n",
       "      <td>4.785962e-06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>tfidf_38</td>\n",
       "      <td>4.650576e-06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>462</th>\n",
       "      <td>tea</td>\n",
       "      <td>4.631835e-06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>455</th>\n",
       "      <td>rose</td>\n",
       "      <td>4.603913e-06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>439</th>\n",
       "      <td>honey</td>\n",
       "      <td>4.438241e-06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>467</th>\n",
       "      <td>violet</td>\n",
       "      <td>4.108339e-06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>448</th>\n",
       "      <td>peach</td>\n",
       "      <td>3.394023e-06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>77</th>\n",
       "      <td>tfidf_77</td>\n",
       "      <td>2.935281e-06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>427</th>\n",
       "      <td>butter</td>\n",
       "      <td>2.738485e-06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>461</th>\n",
       "      <td>tar</td>\n",
       "      <td>2.644055e-06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>444</th>\n",
       "      <td>menthol</td>\n",
       "      <td>2.369664e-06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>463</th>\n",
       "      <td>tobacco</td>\n",
       "      <td>2.066494e-06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>453</th>\n",
       "      <td>plum</td>\n",
       "      <td>1.880012e-06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>209</th>\n",
       "      <td>tfidf_209</td>\n",
       "      <td>1.799393e-06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>425</th>\n",
       "      <td>blue cheese</td>\n",
       "      <td>1.682796e-06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>241</th>\n",
       "      <td>tfidf_241</td>\n",
       "      <td>1.491966e-06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>219</th>\n",
       "      <td>tfidf_219</td>\n",
       "      <td>1.455911e-06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>410</th>\n",
       "      <td>migraines</td>\n",
       "      <td>1.324854e-06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>396</th>\n",
       "      <td>depression</td>\n",
       "      <td>5.195100e-07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>391</th>\n",
       "      <td>anxiety</td>\n",
       "      <td>3.481752e-07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>401</th>\n",
       "      <td>epilepsy</td>\n",
       "      <td>0.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>394</th>\n",
       "      <td>arthritis</td>\n",
       "      <td>0.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>404</th>\n",
       "      <td>fatigue</td>\n",
       "      <td>0.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>411</th>\n",
       "      <td>pain</td>\n",
       "      <td>0.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>414</th>\n",
       "      <td>seizures</td>\n",
       "      <td>0.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>416</th>\n",
       "      <td>spasticity</td>\n",
       "      <td>0.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>417</th>\n",
       "      <td>stress</td>\n",
       "      <td>0.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>403</th>\n",
       "      <td>eye pressure</td>\n",
       "      <td>0.000000e+00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         features         score\n",
       "388        hybrid  2.649031e-01\n",
       "442          lime  1.032429e-01\n",
       "329     tfidf_329  3.377811e-02\n",
       "428        cheese  2.529199e-02\n",
       "431        citrus  2.510699e-02\n",
       "173     tfidf_173  1.968425e-02\n",
       "415        sleepy  1.945040e-02\n",
       "165     tfidf_165  1.915327e-02\n",
       "149     tfidf_149  1.672243e-02\n",
       "97       tfidf_97  1.463868e-02\n",
       "236     tfidf_236  1.450761e-02\n",
       "355     tfidf_355  1.444622e-02\n",
       "288     tfidf_288  1.371909e-02\n",
       "406        giggly  1.321744e-02\n",
       "163     tfidf_163  1.317515e-02\n",
       "145     tfidf_145  1.272533e-02\n",
       "245     tfidf_245  1.219378e-02\n",
       "291     tfidf_291  1.023757e-02\n",
       "312     tfidf_312  1.012455e-02\n",
       "168     tfidf_168  9.797227e-03\n",
       "402      euphoric  9.746783e-03\n",
       "395      creative  9.487908e-03\n",
       "167     tfidf_167  9.234840e-03\n",
       "460         sweet  9.120556e-03\n",
       "200     tfidf_200  8.984860e-03\n",
       "161     tfidf_161  6.857506e-03\n",
       "121     tfidf_121  6.819664e-03\n",
       "141     tfidf_141  6.819315e-03\n",
       "234     tfidf_234  6.744356e-03\n",
       "78       tfidf_78  6.369843e-03\n",
       "207     tfidf_207  6.167513e-03\n",
       "82       tfidf_82  5.834080e-03\n",
       "26       tfidf_26  5.746394e-03\n",
       "345     tfidf_345  5.199211e-03\n",
       "433        diesel  5.040527e-03\n",
       "434        earthy  4.709965e-03\n",
       "43       tfidf_43  4.600295e-03\n",
       "160     tfidf_160  4.474011e-03\n",
       "93       tfidf_93  4.371716e-03\n",
       "357     tfidf_357  4.326457e-03\n",
       "437         grape  4.236871e-03\n",
       "80       tfidf_80  4.080059e-03\n",
       "405       focused  4.014851e-03\n",
       "409        hungry  4.004472e-03\n",
       "235     tfidf_235  3.983566e-03\n",
       "253     tfidf_253  3.562002e-03\n",
       "199     tfidf_199  3.546574e-03\n",
       "304     tfidf_304  3.406805e-03\n",
       "239     tfidf_239  3.359015e-03\n",
       "454       pungent  3.224509e-03\n",
       "376     tfidf_376  3.177833e-03\n",
       "447        orange  3.164462e-03\n",
       "117     tfidf_117  3.097391e-03\n",
       "285     tfidf_285  3.050532e-03\n",
       "162     tfidf_162  2.927450e-03\n",
       "419        tingly  2.903620e-03\n",
       "309     tfidf_309  2.856444e-03\n",
       "243     tfidf_243  2.793350e-03\n",
       "202     tfidf_202  2.785786e-03\n",
       "51       tfidf_51  2.753927e-03\n",
       "374     tfidf_374  2.652834e-03\n",
       "314     tfidf_314  2.496994e-03\n",
       "386     tfidf_386  2.443936e-03\n",
       "281     tfidf_281  2.428023e-03\n",
       "119     tfidf_119  2.410830e-03\n",
       "28       tfidf_28  2.392389e-03\n",
       "399     dry mouth  2.257910e-03\n",
       "13       tfidf_13  2.257596e-03\n",
       "150     tfidf_150  2.250384e-03\n",
       "422         apple  2.228937e-03\n",
       "420      uplifted  2.040118e-03\n",
       "307     tfidf_307  2.033282e-03\n",
       "222     tfidf_222  1.967825e-03\n",
       "267     tfidf_267  1.884789e-03\n",
       "128     tfidf_128  1.771868e-03\n",
       "73       tfidf_73  1.712835e-03\n",
       "389        indica  1.707542e-03\n",
       "4         tfidf_4  1.706918e-03\n",
       "358     tfidf_358  1.689872e-03\n",
       "424         berry  1.572431e-03\n",
       "146     tfidf_146  1.501301e-03\n",
       "144     tfidf_144  1.478810e-03\n",
       "158     tfidf_158  1.433898e-03\n",
       "37       tfidf_37  1.374869e-03\n",
       "337     tfidf_337  1.351902e-03\n",
       "413       relaxed  1.343555e-03\n",
       "11       tfidf_11  1.298042e-03\n",
       "7         tfidf_7  1.286003e-03\n",
       "191     tfidf_191  1.230869e-03\n",
       "230     tfidf_230  1.226065e-03\n",
       "318     tfidf_318  1.163486e-03\n",
       "441         lemon  1.152388e-03\n",
       "21       tfidf_21  1.150616e-03\n",
       "210     tfidf_210  1.115506e-03\n",
       "322     tfidf_322  1.092614e-03\n",
       "65       tfidf_65  1.085325e-03\n",
       "270     tfidf_270  1.074401e-03\n",
       "5         tfidf_5  1.069066e-03\n",
       "362     tfidf_362  1.050763e-03\n",
       "177     tfidf_177  1.038925e-03\n",
       "30       tfidf_30  1.034522e-03\n",
       "23       tfidf_23  1.025596e-03\n",
       "151     tfidf_151  1.019694e-03\n",
       "393       aroused  1.013227e-03\n",
       "205     tfidf_205  9.986131e-04\n",
       "407         happy  9.818767e-04\n",
       "418     talkative  9.736765e-04\n",
       "52       tfidf_52  9.644926e-04\n",
       "380     tfidf_380  9.198831e-04\n",
       "20       tfidf_20  8.602528e-04\n",
       "457         skunk  8.511339e-04\n",
       "400     energetic  8.478768e-04\n",
       "382     tfidf_382  8.445344e-04\n",
       "300     tfidf_300  8.429617e-04\n",
       "390        sativa  8.410174e-04\n",
       "101     tfidf_101  8.408262e-04\n",
       "373     tfidf_373  8.372552e-04\n",
       "398      dry eyes  8.370628e-04\n",
       "19       tfidf_19  8.156405e-04\n",
       "276     tfidf_276  8.053203e-04\n",
       "350     tfidf_350  7.635822e-04\n",
       "240     tfidf_240  7.627133e-04\n",
       "178     tfidf_178  7.475767e-04\n",
       "426     blueberry  7.279714e-04\n",
       "46       tfidf_46  7.132885e-04\n",
       "103     tfidf_103  6.984190e-04\n",
       "175     tfidf_175  6.971808e-04\n",
       "340     tfidf_340  6.948278e-04\n",
       "336     tfidf_336  6.900636e-04\n",
       "190     tfidf_190  6.730377e-04\n",
       "366     tfidf_366  6.658042e-04\n",
       "361     tfidf_361  6.495118e-04\n",
       "451          pine  6.432582e-04\n",
       "85       tfidf_85  6.237511e-04\n",
       "75       tfidf_75  6.187331e-04\n",
       "208     tfidf_208  5.909482e-04\n",
       "338     tfidf_338  5.833557e-04\n",
       "116     tfidf_116  5.803195e-04\n",
       "3         tfidf_3  5.722776e-04\n",
       "283     tfidf_283  5.649269e-04\n",
       "86       tfidf_86  5.505581e-04\n",
       "435       flowery  5.489934e-04\n",
       "262     tfidf_262  5.350398e-04\n",
       "98       tfidf_98  5.282878e-04\n",
       "324     tfidf_324  5.206372e-04\n",
       "81       tfidf_81  5.198656e-04\n",
       "126     tfidf_126  5.178093e-04\n",
       "271     tfidf_271  5.033450e-04\n",
       "445          mint  4.998413e-04\n",
       "107     tfidf_107  4.868873e-04\n",
       "24       tfidf_24  4.707715e-04\n",
       "228     tfidf_228  4.596954e-04\n",
       "48       tfidf_48  4.498876e-04\n",
       "203     tfidf_203  4.471079e-04\n",
       "319     tfidf_319  4.390795e-04\n",
       "29       tfidf_29  4.386514e-04\n",
       "298     tfidf_298  4.365387e-04\n",
       "342     tfidf_342  4.108592e-04\n",
       "154     tfidf_154  4.050308e-04\n",
       "64       tfidf_64  4.012526e-04\n",
       "279     tfidf_279  3.978938e-04\n",
       "124     tfidf_124  3.954503e-04\n",
       "79       tfidf_79  3.902356e-04\n",
       "69       tfidf_69  3.868379e-04\n",
       "249     tfidf_249  3.678508e-04\n",
       "135     tfidf_135  3.593500e-04\n",
       "343     tfidf_343  3.548655e-04\n",
       "194     tfidf_194  3.537794e-04\n",
       "468         woody  3.534224e-04\n",
       "341     tfidf_341  3.500653e-04\n",
       "364     tfidf_364  3.482993e-04\n",
       "258     tfidf_258  3.425133e-04\n",
       "104     tfidf_104  3.391487e-04\n",
       "325     tfidf_325  3.384099e-04\n",
       "286     tfidf_286  3.370643e-04\n",
       "392       anxious  3.325690e-04\n",
       "367     tfidf_367  3.231073e-04\n",
       "354     tfidf_354  3.219333e-04\n",
       "360     tfidf_360  3.216486e-04\n",
       "182     tfidf_182  3.165534e-04\n",
       "125     tfidf_125  3.094531e-04\n",
       "123     tfidf_123  3.042475e-04\n",
       "385     tfidf_385  3.032838e-04\n",
       "277     tfidf_277  2.920719e-04\n",
       "397         dizzy  2.786340e-04\n",
       "88       tfidf_88  2.765484e-04\n",
       "290     tfidf_290  2.756611e-04\n",
       "14       tfidf_14  2.727580e-04\n",
       "292     tfidf_292  2.709556e-04\n",
       "129     tfidf_129  2.660983e-04\n",
       "39       tfidf_39  2.628068e-04\n",
       "371     tfidf_371  2.555182e-04\n",
       "273     tfidf_273  2.453721e-04\n",
       "188     tfidf_188  2.362573e-04\n",
       "352     tfidf_352  2.346948e-04\n",
       "217     tfidf_217  2.253163e-04\n",
       "297     tfidf_297  2.234360e-04\n",
       "351     tfidf_351  2.202693e-04\n",
       "323     tfidf_323  2.158286e-04\n",
       "197     tfidf_197  2.113464e-04\n",
       "206     tfidf_206  2.110866e-04\n",
       "45       tfidf_45  2.072574e-04\n",
       "130     tfidf_130  2.071323e-04\n",
       "105     tfidf_105  2.057576e-04\n",
       "63       tfidf_63  2.049142e-04\n",
       "139     tfidf_139  2.003615e-04\n",
       "0         tfidf_0  1.995830e-04\n",
       "387     tfidf_387  1.988413e-04\n",
       "22       tfidf_22  1.922303e-04\n",
       "166     tfidf_166  1.912662e-04\n",
       "221     tfidf_221  1.906118e-04\n",
       "109     tfidf_109  1.898070e-04\n",
       "68       tfidf_68  1.881781e-04\n",
       "96       tfidf_96  1.848226e-04\n",
       "264     tfidf_264  1.846930e-04\n",
       "311     tfidf_311  1.820485e-04\n",
       "408      headache  1.802506e-04\n",
       "353     tfidf_353  1.801133e-04\n",
       "136     tfidf_136  1.774792e-04\n",
       "95       tfidf_95  1.740589e-04\n",
       "452     pineapple  1.706375e-04\n",
       "56       tfidf_56  1.700553e-04\n",
       "131     tfidf_131  1.678189e-04\n",
       "184     tfidf_184  1.667387e-04\n",
       "227     tfidf_227  1.655477e-04\n",
       "246     tfidf_246  1.636222e-04\n",
       "87       tfidf_87  1.634416e-04\n",
       "294     tfidf_294  1.615589e-04\n",
       "153     tfidf_153  1.605233e-04\n",
       "185     tfidf_185  1.600755e-04\n",
       "346     tfidf_346  1.591130e-04\n",
       "198     tfidf_198  1.588454e-04\n",
       "6         tfidf_6  1.576677e-04\n",
       "370     tfidf_370  1.570432e-04\n",
       "333     tfidf_333  1.565937e-04\n",
       "223     tfidf_223  1.545155e-04\n",
       "90       tfidf_90  1.500720e-04\n",
       "278     tfidf_278  1.427403e-04\n",
       "127     tfidf_127  1.424136e-04\n",
       "102     tfidf_102  1.398544e-04\n",
       "40       tfidf_40  1.393068e-04\n",
       "275     tfidf_275  1.328188e-04\n",
       "232     tfidf_232  1.312392e-04\n",
       "54       tfidf_54  1.274839e-04\n",
       "326     tfidf_326  1.220610e-04\n",
       "152     tfidf_152  1.215518e-04\n",
       "110     tfidf_110  1.198964e-04\n",
       "289     tfidf_289  1.184729e-04\n",
       "299     tfidf_299  1.179231e-04\n",
       "193     tfidf_193  1.171892e-04\n",
       "242     tfidf_242  1.159113e-04\n",
       "211     tfidf_211  1.152976e-04\n",
       "10       tfidf_10  1.138468e-04\n",
       "229     tfidf_229  1.134181e-04\n",
       "171     tfidf_171  1.118411e-04\n",
       "379     tfidf_379  1.098865e-04\n",
       "429      chemical  1.098496e-04\n",
       "344     tfidf_344  1.097486e-04\n",
       "303     tfidf_303  1.091774e-04\n",
       "381     tfidf_381  1.061415e-04\n",
       "226     tfidf_226  1.048148e-04\n",
       "113     tfidf_113  1.014055e-04\n",
       "189     tfidf_189  9.966942e-05\n",
       "233     tfidf_233  9.964612e-05\n",
       "61       tfidf_61  9.893818e-05\n",
       "248     tfidf_248  9.789262e-05\n",
       "99       tfidf_99  9.718603e-05\n",
       "2         tfidf_2  9.635137e-05\n",
       "42       tfidf_42  9.539705e-05\n",
       "465      tropical  9.340795e-05\n",
       "58       tfidf_58  9.276213e-05\n",
       "60       tfidf_60  8.861253e-05\n",
       "17       tfidf_17  8.818458e-05\n",
       "34       tfidf_34  8.796009e-05\n",
       "316     tfidf_316  8.620930e-05\n",
       "274     tfidf_274  8.472700e-05\n",
       "41       tfidf_41  8.116235e-05\n",
       "215     tfidf_215  8.098788e-05\n",
       "272     tfidf_272  7.993683e-05\n",
       "71       tfidf_71  7.973850e-05\n",
       "259     tfidf_259  7.833635e-05\n",
       "295     tfidf_295  7.779102e-05\n",
       "31       tfidf_31  7.726718e-05\n",
       "308     tfidf_308  7.689452e-05\n",
       "84       tfidf_84  7.407499e-05\n",
       "349     tfidf_349  7.309889e-05\n",
       "138     tfidf_138  7.249110e-05\n",
       "466       vanilla  7.211577e-05\n",
       "216     tfidf_216  7.170269e-05\n",
       "32       tfidf_32  7.080009e-05\n",
       "147     tfidf_147  7.041002e-05\n",
       "320     tfidf_320  6.961021e-05\n",
       "120     tfidf_120  6.908445e-05\n",
       "12       tfidf_12  6.864939e-05\n",
       "254     tfidf_254  6.737970e-05\n",
       "16       tfidf_16  6.708656e-05\n",
       "55       tfidf_55  6.648421e-05\n",
       "156     tfidf_156  6.619884e-05\n",
       "260     tfidf_260  6.611504e-05\n",
       "67       tfidf_67  6.578842e-05\n",
       "180     tfidf_180  6.550173e-05\n",
       "35       tfidf_35  6.454752e-05\n",
       "332     tfidf_332  6.369728e-05\n",
       "368     tfidf_368  6.261654e-05\n",
       "280     tfidf_280  6.234993e-05\n",
       "170     tfidf_170  5.911909e-05\n",
       "261     tfidf_261  5.820111e-05\n",
       "237     tfidf_237  5.737123e-05\n",
       "339     tfidf_339  5.647155e-05\n",
       "287     tfidf_287  5.645043e-05\n",
       "231     tfidf_231  5.575636e-05\n",
       "179     tfidf_179  5.253777e-05\n",
       "220     tfidf_220  5.233022e-05\n",
       "159     tfidf_159  5.227667e-05\n",
       "238     tfidf_238  5.169937e-05\n",
       "115     tfidf_115  5.130411e-05\n",
       "183     tfidf_183  5.079811e-05\n",
       "66       tfidf_66  5.046173e-05\n",
       "438    grapefruit  5.001800e-05\n",
       "91       tfidf_91  4.902169e-05\n",
       "252     tfidf_252  4.897056e-05\n",
       "196     tfidf_196  4.863871e-05\n",
       "257     tfidf_257  4.829323e-05\n",
       "9         tfidf_9  4.799232e-05\n",
       "443         mango  4.762640e-05\n",
       "225     tfidf_225  4.636858e-05\n",
       "83       tfidf_83  4.623388e-05\n",
       "106     tfidf_106  4.522909e-05\n",
       "412      paranoid  4.353682e-05\n",
       "459    strawberry  4.272681e-05\n",
       "263     tfidf_263  4.240475e-05\n",
       "164     tfidf_164  4.178735e-05\n",
       "375     tfidf_375  4.086138e-05\n",
       "157     tfidf_157  4.007429e-05\n",
       "268     tfidf_268  3.928309e-05\n",
       "456          sage  3.907778e-05\n",
       "282     tfidf_282  3.837373e-05\n",
       "70       tfidf_70  3.738149e-05\n",
       "8         tfidf_8  3.720607e-05\n",
       "335     tfidf_335  3.684941e-05\n",
       "50       tfidf_50  3.649132e-05\n",
       "251     tfidf_251  3.621127e-05\n",
       "36       tfidf_36  3.595940e-05\n",
       "255     tfidf_255  3.584880e-05\n",
       "265     tfidf_265  3.512516e-05\n",
       "334     tfidf_334  3.511584e-05\n",
       "140     tfidf_140  3.452125e-05\n",
       "122     tfidf_122  3.427484e-05\n",
       "62       tfidf_62  3.339792e-05\n",
       "186     tfidf_186  3.252546e-05\n",
       "57       tfidf_57  3.217371e-05\n",
       "327     tfidf_327  3.171197e-05\n",
       "53       tfidf_53  3.137454e-05\n",
       "458  spicy/herbal  3.106160e-05\n",
       "143     tfidf_143  3.044629e-05\n",
       "250     tfidf_250  3.011802e-05\n",
       "133     tfidf_133  2.900171e-05\n",
       "369     tfidf_369  2.893336e-05\n",
       "172     tfidf_172  2.883310e-05\n",
       "348     tfidf_348  2.859111e-05\n",
       "44       tfidf_44  2.843331e-05\n",
       "450        pepper  2.834317e-05\n",
       "310     tfidf_310  2.812930e-05\n",
       "377     tfidf_377  2.801570e-05\n",
       "306     tfidf_306  2.708432e-05\n",
       "92       tfidf_92  2.587913e-05\n",
       "15       tfidf_15  2.557276e-05\n",
       "317     tfidf_317  2.550695e-05\n",
       "302     tfidf_302  2.544843e-05\n",
       "134     tfidf_134  2.511190e-05\n",
       "155     tfidf_155  2.464291e-05\n",
       "256     tfidf_256  2.414415e-05\n",
       "169     tfidf_169  2.393079e-05\n",
       "313     tfidf_313  2.379702e-05\n",
       "100     tfidf_100  2.349975e-05\n",
       "74       tfidf_74  2.299944e-05\n",
       "321     tfidf_321  2.291264e-05\n",
       "132     tfidf_132  2.281833e-05\n",
       "247     tfidf_247  2.270527e-05\n",
       "363     tfidf_363  2.255321e-05\n",
       "372     tfidf_372  2.248823e-05\n",
       "94       tfidf_94  2.201541e-05\n",
       "112     tfidf_112  2.194135e-05\n",
       "181     tfidf_181  2.193170e-05\n",
       "224     tfidf_224  2.126808e-05\n",
       "213     tfidf_213  2.101175e-05\n",
       "108     tfidf_108  2.084061e-05\n",
       "464          tree  2.070276e-05\n",
       "176     tfidf_176  2.067988e-05\n",
       "301     tfidf_301  2.064201e-05\n",
       "305     tfidf_305  2.063158e-05\n",
       "137     tfidf_137  2.031219e-05\n",
       "142     tfidf_142  1.961882e-05\n",
       "201     tfidf_201  1.946902e-05\n",
       "293     tfidf_293  1.925567e-05\n",
       "423       apricot  1.923490e-05\n",
       "365     tfidf_365  1.909631e-05\n",
       "218     tfidf_218  1.908644e-05\n",
       "383     tfidf_383  1.723534e-05\n",
       "76       tfidf_76  1.676327e-05\n",
       "432        coffee  1.646652e-05\n",
       "49       tfidf_49  1.604559e-05\n",
       "315     tfidf_315  1.572510e-05\n",
       "436         fruit  1.505971e-05\n",
       "148     tfidf_148  1.491469e-05\n",
       "330     tfidf_330  1.472842e-05\n",
       "449          pear  1.469985e-05\n",
       "18       tfidf_18  1.465559e-05\n",
       "114     tfidf_114  1.457405e-05\n",
       "212     tfidf_212  1.435445e-05\n",
       "89       tfidf_89  1.424348e-05\n",
       "111     tfidf_111  1.398615e-05\n",
       "266     tfidf_266  1.329637e-05\n",
       "187     tfidf_187  1.317715e-05\n",
       "359     tfidf_359  1.315426e-05\n",
       "27       tfidf_27  1.265170e-05\n",
       "347     tfidf_347  1.229425e-05\n",
       "1         tfidf_1  1.221465e-05\n",
       "118     tfidf_118  1.201870e-05\n",
       "174     tfidf_174  1.201405e-05\n",
       "430      chestnut  1.170298e-05\n",
       "47       tfidf_47  1.148453e-05\n",
       "331     tfidf_331  1.085553e-05\n",
       "440      lavender  1.082984e-05\n",
       "421       ammonia  1.059456e-05\n",
       "72       tfidf_72  1.030968e-05\n",
       "244     tfidf_244  8.912341e-06\n",
       "192     tfidf_192  8.461149e-06\n",
       "356     tfidf_356  8.437157e-06\n",
       "25       tfidf_25  7.983180e-06\n",
       "33       tfidf_33  7.581075e-06\n",
       "269     tfidf_269  6.949518e-06\n",
       "59       tfidf_59  6.649978e-06\n",
       "204     tfidf_204  5.608428e-06\n",
       "214     tfidf_214  5.545533e-06\n",
       "195     tfidf_195  5.439169e-06\n",
       "446         nutty  5.257192e-06\n",
       "296     tfidf_296  5.061194e-06\n",
       "284     tfidf_284  4.923063e-06\n",
       "378     tfidf_378  4.921997e-06\n",
       "328     tfidf_328  4.806074e-06\n",
       "384     tfidf_384  4.785962e-06\n",
       "38       tfidf_38  4.650576e-06\n",
       "462           tea  4.631835e-06\n",
       "455          rose  4.603913e-06\n",
       "439         honey  4.438241e-06\n",
       "467        violet  4.108339e-06\n",
       "448         peach  3.394023e-06\n",
       "77       tfidf_77  2.935281e-06\n",
       "427        butter  2.738485e-06\n",
       "461           tar  2.644055e-06\n",
       "444       menthol  2.369664e-06\n",
       "463       tobacco  2.066494e-06\n",
       "453          plum  1.880012e-06\n",
       "209     tfidf_209  1.799393e-06\n",
       "425   blue cheese  1.682796e-06\n",
       "241     tfidf_241  1.491966e-06\n",
       "219     tfidf_219  1.455911e-06\n",
       "410     migraines  1.324854e-06\n",
       "396    depression  5.195100e-07\n",
       "391       anxiety  3.481752e-07\n",
       "401      epilepsy  0.000000e+00\n",
       "394     arthritis  0.000000e+00\n",
       "404       fatigue  0.000000e+00\n",
       "411          pain  0.000000e+00\n",
       "414      seizures  0.000000e+00\n",
       "416    spasticity  0.000000e+00\n",
       "417        stress  0.000000e+00\n",
       "403  eye pressure  0.000000e+00"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.set_option('display.max_rows', df_feat_ranked.shape[0]+1)\n",
    "df_feat_ranked"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/louispandu/anaconda3/lib/python3.10/site-packages/sklearn/feature_selection/_from_model.py:357: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  self.estimator_.fit(X, y, **fit_params)\n"
     ]
    }
   ],
   "source": [
    "selector = SelectFromModel(rfreg).fit(X_train1, y_train1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1.41781534e-04, 2.33936338e-05, 8.36089626e-05, 8.16148570e-04,\n",
       "       2.03587725e-03, 8.39381773e-04, 1.64037102e-04, 1.29040111e-03,\n",
       "       2.49801072e-05, 5.18511138e-05, 1.14178134e-04, 1.18630016e-03,\n",
       "       5.70362966e-05, 1.71372521e-03, 2.59466231e-04, 3.47063148e-05,\n",
       "       7.96966481e-05, 7.30566763e-05, 2.44362099e-05, 7.15504090e-04,\n",
       "       8.80572040e-04, 7.70070763e-04, 1.75161454e-04, 1.31569485e-03,\n",
       "       7.13999397e-04, 5.85929494e-06, 6.43622016e-03, 1.03771265e-04,\n",
       "       2.03675711e-03, 4.02840965e-04, 1.08678098e-03, 7.51597727e-05,\n",
       "       9.00304096e-05, 4.68530808e-06, 2.51016244e-04, 7.30316520e-05,\n",
       "       4.44631813e-05, 1.23637423e-03, 6.60547353e-06, 4.72293516e-04,\n",
       "       2.00445922e-04, 6.50509415e-05, 9.43626016e-05, 4.58057863e-03,\n",
       "       1.64953801e-05, 2.51968271e-04, 8.43821515e-04, 1.07588957e-05,\n",
       "       3.81368179e-04, 2.95472613e-05, 3.13956025e-05, 2.84925345e-03,\n",
       "       8.94342678e-04, 3.62418667e-05, 1.15239565e-04, 1.47904554e-04,\n",
       "       1.44256081e-04, 2.30287384e-05, 6.90590495e-05, 2.81155175e-06,\n",
       "       1.02541327e-04, 5.56037133e-05, 5.33889318e-05, 1.48307520e-04,\n",
       "       1.08463684e-04, 1.07069815e-03, 3.43920203e-05, 1.48074889e-04,\n",
       "       3.57665595e-04, 2.23674563e-04, 3.20784644e-05, 7.42448893e-05,\n",
       "       1.96223985e-05, 1.52459799e-03, 2.49633077e-05, 5.24438630e-04,\n",
       "       4.44513418e-05, 3.66205871e-06, 5.42618379e-03, 3.30096616e-04,\n",
       "       3.62750361e-03, 3.50613424e-04, 7.74486749e-03, 3.30266029e-05,\n",
       "       7.75691992e-05, 1.69163943e-04, 7.41810866e-04, 1.74996724e-04,\n",
       "       2.50619177e-04, 9.62566683e-06, 2.54855063e-04, 3.62597182e-05,\n",
       "       2.66676334e-05, 5.08396783e-03, 8.20123765e-06, 1.56793253e-04,\n",
       "       1.84837703e-04, 1.48624597e-02, 4.41250061e-04, 8.16679182e-05,\n",
       "       2.33251637e-05, 9.72775915e-04, 1.56976970e-04, 6.67645070e-04,\n",
       "       3.32717064e-04, 2.41863900e-04, 3.69601659e-05, 5.22250755e-04,\n",
       "       5.95354770e-05, 2.18627566e-04, 7.71223151e-05, 1.15749669e-05,\n",
       "       2.04337597e-05, 7.85132056e-05, 2.06247580e-05, 5.69561750e-05,\n",
       "       5.34223138e-04, 2.92850364e-03, 1.14556237e-05, 2.36986700e-03,\n",
       "       6.41977762e-05, 7.44373962e-03, 2.64481520e-05, 3.06786413e-04,\n",
       "       2.63374997e-04, 4.44336975e-04, 4.37041275e-04, 9.35256619e-05,\n",
       "       1.81118849e-03, 2.64323618e-04, 2.20641917e-04, 1.40968577e-04,\n",
       "       2.11979396e-05, 8.37467723e-05, 1.70835249e-05, 4.93988250e-04,\n",
       "       1.34167315e-04, 2.12276331e-05, 4.49176217e-05, 2.43069987e-04,\n",
       "       1.35086445e-05, 5.68339408e-03, 1.67185843e-05, 3.27173252e-05,\n",
       "       1.55630970e-03, 1.24401470e-02, 1.50820039e-03, 7.85819205e-05,\n",
       "       1.22142923e-05, 1.62149945e-02, 6.70372417e-04, 1.20258210e-03,\n",
       "       1.39780631e-04, 1.40657273e-04, 3.38048174e-04, 2.91937831e-05,\n",
       "       1.00712175e-04, 1.04824103e-04, 1.52432862e-03, 4.83532789e-05,\n",
       "       4.52295149e-03, 7.33688309e-03, 2.27730133e-03, 1.47550775e-02,\n",
       "       9.34906328e-05, 1.95554285e-02, 2.31594307e-04, 1.00932553e-02,\n",
       "       1.03464234e-02, 3.24206625e-05, 1.07830093e-04, 6.12937874e-05,\n",
       "       5.71100423e-05, 1.95817756e-02, 1.90487658e-05, 8.57031040e-04,\n",
       "       3.05945582e-05, 1.14524559e-03, 6.47543277e-04, 4.31993816e-05,\n",
       "       7.58047202e-05, 2.24210066e-05, 3.25419526e-04, 1.78873027e-05,\n",
       "       9.48023935e-05, 1.73987648e-04, 4.49796707e-05, 7.76582361e-06,\n",
       "       1.60812422e-04, 7.35978419e-05, 6.24971571e-04, 1.02526233e-03,\n",
       "       9.43860164e-06, 7.64413798e-05, 3.49291254e-04, 6.74356723e-06,\n",
       "       5.81433622e-05, 2.37301769e-04, 1.20413186e-04, 3.97292262e-03,\n",
       "       9.25308411e-03, 9.24270436e-06, 2.29631001e-03, 4.02109789e-04,\n",
       "       7.22685599e-06, 1.16173987e-03, 2.00530942e-04, 7.37709875e-03,\n",
       "       7.26149116e-04, 1.56478326e-06, 1.25813807e-03, 1.50576537e-04,\n",
       "       1.50244633e-05, 9.85017124e-06, 1.06147790e-05, 7.94757481e-05,\n",
       "       6.34422866e-05, 2.24923657e-04, 1.84941777e-05, 3.63943651e-05,\n",
       "       2.99833630e-05, 1.96132992e-04, 1.25904005e-03, 1.38140526e-04,\n",
       "       2.86277652e-05, 6.86584746e-05, 1.28345159e-04, 2.57677691e-04,\n",
       "       3.10871430e-04, 2.43873469e-05, 1.17711868e-03, 9.96587937e-05,\n",
       "       8.73794277e-05, 7.71293054e-05, 6.33345003e-03, 4.02049582e-03,\n",
       "       1.48222268e-02, 7.48399325e-05, 1.03133173e-05, 2.49652950e-03,\n",
       "       5.94097772e-04, 2.84601275e-06, 8.92395311e-05, 1.99386454e-03,\n",
       "       5.73102713e-06, 1.21735961e-02, 1.17520932e-05, 2.49065793e-05,\n",
       "       8.95398542e-05, 2.99709052e-04, 1.97929287e-05, 1.67813957e-05,\n",
       "       1.60301314e-05, 3.87301900e-03, 5.72164756e-05, 1.62016925e-05,\n",
       "       2.44256517e-05, 2.08610331e-05, 2.08808236e-04, 1.12932241e-04,\n",
       "       9.94523408e-05, 4.83887471e-05, 7.29414350e-04, 7.81103251e-05,\n",
       "       1.59207203e-04, 1.10881685e-05, 1.00797962e-05, 1.46915994e-03,\n",
       "       5.68139124e-05, 7.82127975e-05, 7.59241159e-04, 5.05350137e-04,\n",
       "       4.96669127e-05, 2.31799739e-04, 1.13314990e-04, 1.01358478e-04,\n",
       "       1.06843762e-03, 3.45843574e-04, 1.44226882e-04, 3.99187352e-04,\n",
       "       6.87082809e-05, 1.47122957e-03, 6.08309781e-05, 5.93175600e-04,\n",
       "       5.27479983e-06, 2.76892321e-03, 4.55422520e-04, 3.41334044e-05,\n",
       "       1.39983643e-02, 1.13009698e-04, 7.48269396e-05, 1.14801595e-02,\n",
       "       2.33468040e-04, 1.08478193e-05, 1.81612068e-04, 1.61832299e-04,\n",
       "       6.39067101e-06, 2.32540664e-04, 1.65037818e-04, 1.72494299e-04,\n",
       "       4.86012482e-04, 2.32750569e-05, 1.51989922e-05, 1.96458797e-04,\n",
       "       3.35099601e-03, 1.62520703e-05, 1.82995581e-05, 1.62690243e-03,\n",
       "       6.56912320e-05, 1.90765223e-03, 3.03075077e-05, 1.62496959e-04,\n",
       "       1.01741405e-02, 2.19773325e-05, 2.51906824e-03, 9.95521818e-06,\n",
       "       1.37006771e-04, 5.46066674e-04, 4.90656793e-04, 4.03205763e-04,\n",
       "       4.08583291e-05, 2.66099926e-05, 1.17013220e-03, 7.19204697e-04,\n",
       "       4.63761211e-04, 2.67718107e-04, 1.09472284e-04, 1.02384415e-04,\n",
       "       1.07051863e-05, 3.43963514e-02, 2.35046468e-05, 6.99211561e-06,\n",
       "       1.17068679e-04, 6.88636716e-04, 2.33439315e-05, 1.50094578e-05,\n",
       "       7.43876134e-04, 1.41577690e-03, 3.87992005e-04, 1.22983843e-04,\n",
       "       6.37475030e-04, 2.58554905e-04, 4.11983623e-04, 2.63572547e-04,\n",
       "       4.89216665e-05, 4.75646836e-03, 2.20639813e-04, 2.80607210e-04,\n",
       "       4.60251848e-05, 9.23931833e-05, 9.05735667e-04, 6.50893003e-05,\n",
       "       2.27049907e-04, 1.51307374e-04, 2.02204972e-04, 1.39098902e-02,\n",
       "       7.42632434e-06, 3.72781416e-03, 2.07147793e-03, 1.12919814e-05,\n",
       "       3.45340166e-04, 7.12056846e-04, 1.11463963e-03, 1.84195974e-05,\n",
       "       4.49617808e-04, 1.73008265e-05, 6.19722244e-04, 3.23168886e-04,\n",
       "       4.81852046e-05, 4.61218419e-05, 1.03158048e-04, 2.51967600e-04,\n",
       "       2.06281076e-05, 4.64860284e-04, 2.90763385e-03, 1.29340369e-04,\n",
       "       3.18029181e-03, 2.31913415e-05, 4.66590758e-06, 9.62415899e-05,\n",
       "       1.24115384e-03, 9.41836579e-05, 6.03897547e-04, 3.80156072e-05,\n",
       "       1.05245173e-05, 3.36511192e-04, 3.12324695e-03, 2.02857723e-04,\n",
       "       2.65310192e-01, 1.76470652e-03, 8.22877325e-04, 5.86369170e-07,\n",
       "       3.99890542e-04, 7.26890458e-04, 0.00000000e+00, 9.14339584e-03,\n",
       "       8.85700856e-07, 2.59079818e-04, 1.11370938e-03, 1.70528850e-03,\n",
       "       6.29812077e-04, 0.00000000e+00, 9.35360202e-03, 0.00000000e+00,\n",
       "       0.00000000e+00, 3.44115297e-03, 1.35961389e-02, 9.06298865e-04,\n",
       "       9.01205092e-05, 3.82921507e-03, 9.13714921e-07, 0.00000000e+00,\n",
       "       3.72344936e-05, 1.39687463e-03, 0.00000000e+00, 1.99361037e-02,\n",
       "       0.00000000e+00, 0.00000000e+00, 1.04666733e-03, 3.13784253e-03,\n",
       "       1.82793739e-03, 1.94478887e-05, 2.63913607e-03, 2.52157091e-05,\n",
       "       1.50302118e-03, 2.58167420e-06, 8.19211269e-04, 3.60211493e-06,\n",
       "       2.52088771e-02, 1.10208702e-04, 1.67780953e-05, 2.61274947e-02,\n",
       "       1.57684261e-05, 4.47252456e-03, 5.01241124e-03, 5.24099520e-04,\n",
       "       2.22474434e-05, 4.40663136e-03, 5.08622802e-05, 1.00113123e-05,\n",
       "       1.51684399e-05, 1.01878449e-03, 1.03366981e-01, 3.13344291e-05,\n",
       "       2.19753871e-06, 5.10298539e-04, 3.18796496e-06, 2.65726372e-03,\n",
       "       2.64052626e-06, 7.66745517e-06, 1.43962601e-05, 6.25406514e-04,\n",
       "       1.61218890e-04, 4.05657048e-06, 3.46231935e-03, 9.66948104e-06,\n",
       "       5.53883050e-05, 1.03923884e-03, 3.74154683e-05, 5.35048141e-05,\n",
       "       9.31795370e-03, 1.64765485e-06, 7.54538240e-06, 1.73015548e-06,\n",
       "       5.00867282e-05, 1.73589516e-04, 5.14592562e-05, 2.59378085e-06,\n",
       "       2.59584039e-04])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "selector.estimator_.feature_importances_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0021321961620469083"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "selector.threshold_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "mask = selector.get_support()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([False, False, False, False, False, False, False, False, False,\n",
       "       False, False, False, False, False, False, False, False, False,\n",
       "       False, False, False, False, False, False, False, False,  True,\n",
       "       False, False, False, False, False, False, False, False, False,\n",
       "       False, False, False, False, False, False, False,  True, False,\n",
       "       False, False, False, False, False, False,  True, False, False,\n",
       "       False, False, False, False, False, False, False, False, False,\n",
       "       False, False, False, False, False, False, False, False, False,\n",
       "       False, False, False, False, False, False,  True, False,  True,\n",
       "       False,  True, False, False, False, False, False, False, False,\n",
       "       False, False, False,  True, False, False, False,  True, False,\n",
       "       False, False, False, False, False, False, False, False, False,\n",
       "       False, False, False, False, False, False, False, False, False,\n",
       "        True, False,  True, False,  True, False, False, False, False,\n",
       "       False, False, False, False, False, False, False, False, False,\n",
       "       False, False, False, False, False, False,  True, False, False,\n",
       "       False,  True, False, False, False,  True, False, False, False,\n",
       "       False, False, False, False, False, False, False,  True,  True,\n",
       "        True,  True, False,  True, False,  True,  True, False, False,\n",
       "       False, False,  True, False, False, False, False, False, False,\n",
       "       False, False, False, False, False, False, False, False, False,\n",
       "       False, False, False, False, False, False, False, False, False,\n",
       "       False,  True,  True, False,  True, False, False, False, False,\n",
       "        True, False, False, False, False, False, False, False, False,\n",
       "       False, False, False, False, False, False, False, False, False,\n",
       "       False, False, False, False, False, False, False, False, False,\n",
       "        True,  True,  True, False, False,  True, False, False, False,\n",
       "       False, False,  True, False, False, False, False, False, False,\n",
       "       False,  True, False, False, False, False, False, False, False,\n",
       "       False, False, False, False, False, False, False, False, False,\n",
       "       False, False, False, False, False, False, False, False, False,\n",
       "       False, False, False, False, False, False,  True, False, False,\n",
       "        True, False, False,  True, False, False, False, False, False,\n",
       "       False, False, False, False, False, False, False,  True, False,\n",
       "       False, False, False, False, False, False,  True, False,  True,\n",
       "       False, False, False, False, False, False, False, False, False,\n",
       "       False, False, False, False, False,  True, False, False, False,\n",
       "       False, False, False, False, False, False, False, False, False,\n",
       "       False, False, False,  True, False, False, False, False, False,\n",
       "       False, False, False, False,  True, False,  True, False, False,\n",
       "       False, False, False, False, False, False, False, False, False,\n",
       "       False, False, False, False, False,  True, False,  True, False,\n",
       "       False, False, False, False, False, False, False, False,  True,\n",
       "       False,  True, False, False, False, False, False, False,  True,\n",
       "       False, False, False, False, False, False,  True, False, False,\n",
       "        True,  True, False, False,  True, False, False, False, False,\n",
       "       False,  True, False, False, False,  True, False, False,  True,\n",
       "       False, False, False, False, False,  True, False, False,  True,\n",
       "       False,  True,  True, False, False,  True, False, False, False,\n",
       "       False,  True, False, False, False, False,  True, False, False,\n",
       "       False, False, False, False,  True, False, False, False, False,\n",
       "       False,  True, False, False, False, False, False, False, False,\n",
       "       False])"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "selected_features = X.columns[mask]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tfidf_26</th>\n",
       "      <th>tfidf_43</th>\n",
       "      <th>tfidf_51</th>\n",
       "      <th>tfidf_78</th>\n",
       "      <th>tfidf_80</th>\n",
       "      <th>tfidf_82</th>\n",
       "      <th>tfidf_93</th>\n",
       "      <th>tfidf_97</th>\n",
       "      <th>tfidf_117</th>\n",
       "      <th>tfidf_119</th>\n",
       "      <th>...</th>\n",
       "      <th>apple</th>\n",
       "      <th>cheese</th>\n",
       "      <th>citrus</th>\n",
       "      <th>diesel</th>\n",
       "      <th>earthy</th>\n",
       "      <th>grape</th>\n",
       "      <th>lime</th>\n",
       "      <th>orange</th>\n",
       "      <th>pungent</th>\n",
       "      <th>sweet</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.152565</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.253181</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.16079</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.205162</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.140663</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>74995</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>74996</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>74997</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>74998</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>74999</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>75000 rows × 63 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       tfidf_26  tfidf_43  tfidf_51  tfidf_78  tfidf_80  tfidf_82  tfidf_93  \\\n",
       "0           0.0  0.000000       0.0  0.152565       0.0       0.0  0.000000   \n",
       "1           0.0  0.000000       0.0  0.000000       0.0       0.0  0.253181   \n",
       "2           0.0  0.000000       0.0  0.000000       0.0       0.0  0.000000   \n",
       "3           0.0  0.205162       0.0  0.000000       0.0       0.0  0.000000   \n",
       "4           0.0  0.000000       0.0  0.000000       0.0       0.0  0.000000   \n",
       "...         ...       ...       ...       ...       ...       ...       ...   \n",
       "74995       0.0  0.000000       0.0  0.000000       0.0       0.0  0.000000   \n",
       "74996       0.0  0.000000       0.0  0.000000       0.0       0.0  0.000000   \n",
       "74997       0.0  0.000000       0.0  0.000000       0.0       0.0  0.000000   \n",
       "74998       0.0  0.000000       0.0  0.000000       0.0       0.0  0.000000   \n",
       "74999       0.0  0.000000       0.0  0.000000       0.0       0.0  0.000000   \n",
       "\n",
       "       tfidf_97  tfidf_117  tfidf_119  ...  apple  cheese  citrus  diesel  \\\n",
       "0           0.0   0.000000    0.00000  ...      0       0       0       0   \n",
       "1           0.0   0.000000    0.00000  ...      0       1       0       0   \n",
       "2           0.0   0.000000    0.16079  ...      0       0       0       0   \n",
       "3           0.0   0.140663    0.00000  ...      0       0       0       0   \n",
       "4           0.0   0.000000    0.00000  ...      0       0       0       0   \n",
       "...         ...        ...        ...  ...    ...     ...     ...     ...   \n",
       "74995       0.0   0.000000    0.00000  ...      1       1       1       1   \n",
       "74996       0.0   0.000000    0.00000  ...      1       1       1       1   \n",
       "74997       0.0   0.000000    0.00000  ...      1       1       1       1   \n",
       "74998       0.0   0.000000    0.00000  ...      1       1       1       1   \n",
       "74999       0.0   0.000000    0.00000  ...      1       1       1       1   \n",
       "\n",
       "       earthy  grape  lime  orange  pungent  sweet  \n",
       "0           0      0     0       0        0      0  \n",
       "1           0      0     0       0        0      0  \n",
       "2           0      0     0       0        0      0  \n",
       "3           0      0     0       0        0      0  \n",
       "4           0      0     0       0        0      1  \n",
       "...       ...    ...   ...     ...      ...    ...  \n",
       "74995       1      1     1       1        1      1  \n",
       "74996       1      1     1       1        1      1  \n",
       "74997       1      1     1       1        1      1  \n",
       "74998       1      1     1       1        1      1  \n",
       "74999       1      1     1       1        1      1  \n",
       "\n",
       "[75000 rows x 63 columns]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "selected_X = df_rf[selected_features]\n",
    "selected_X"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train test split (after Feature Selection)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['selected_X_rf_tfidf_thcv.pkl']"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import joblib\n",
    "\n",
    "joblib.dump(selector, \"selector_rf_tfidf_thcv.pkl\")\n",
    "joblib.dump(selected_X, \"selected_X_rf_tfidf_thcv.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(selected_X, y, random_state=1, test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train1, X_val, y_train1, y_val = train_test_split(X_train, y_train, random_state=1, test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/ns/m5pnr0211w91v02hpv22958m0000gn/T/ipykernel_88939/3758305.py:1: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  rfreg.fit(X_train1, y_train1)\n"
     ]
    }
   ],
   "source": [
    "rfreg.fit(X_train1, y_train1)\n",
    "y_pred_rfreg = rfreg.predict(X_val)\n",
    "y_pred_rfreg_r2 = rfreg.predict(X_train1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.013745148654672449"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mean_absolute_error(y_val, y_pred_rfreg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0030083751745504845"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mean_squared_error(y_val, y_pred_rfreg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.05484865699860375"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mean_squared_error(y_val, y_pred_rfreg, squared = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9824056265396571"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#train\n",
    "r2_score(y_train1, y_pred_rfreg_r2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9755287221531959"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#val\n",
    "r2_score(y_val, y_pred_rfreg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hyperparameter Tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "parameters = {'max_depth': [None, 10, 50, 100],\n",
    "              'max_features': ['auto', 'sqrt'],\n",
    "              'min_samples_leaf': [1, 2, 4],\n",
    "              'min_samples_split': [2, 5, 10],\n",
    "              'n_estimators': [100, 300, 500]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "rscv = RandomizedSearchCV(rfreg,  \n",
    "                     parameters,   \n",
    "                     cv=5, \n",
    "                     scoring='neg_mean_absolute_error',\n",
    "                     n_jobs = -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/louispandu/anaconda3/lib/python3.10/site-packages/sklearn/model_selection/_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/Users/louispandu/anaconda3/lib/python3.10/site-packages/sklearn/model_selection/_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/Users/louispandu/anaconda3/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
      "  warn(\n",
      "/Users/louispandu/anaconda3/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
      "  warn(\n",
      "/Users/louispandu/anaconda3/lib/python3.10/site-packages/sklearn/model_selection/_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/Users/louispandu/anaconda3/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
      "  warn(\n",
      "/Users/louispandu/anaconda3/lib/python3.10/site-packages/sklearn/model_selection/_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/Users/louispandu/anaconda3/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
      "  warn(\n",
      "/Users/louispandu/anaconda3/lib/python3.10/site-packages/sklearn/model_selection/_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/Users/louispandu/anaconda3/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
      "  warn(\n",
      "/Users/louispandu/anaconda3/lib/python3.10/site-packages/sklearn/model_selection/_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/Users/louispandu/anaconda3/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
      "  warn(\n",
      "/Users/louispandu/anaconda3/lib/python3.10/site-packages/sklearn/model_selection/_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/Users/louispandu/anaconda3/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
      "  warn(\n",
      "/Users/louispandu/anaconda3/lib/python3.10/site-packages/sklearn/model_selection/_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/Users/louispandu/anaconda3/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
      "  warn(\n",
      "/Users/louispandu/anaconda3/lib/python3.10/site-packages/sklearn/model_selection/_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/Users/louispandu/anaconda3/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
      "  warn(\n",
      "/Users/louispandu/anaconda3/lib/python3.10/site-packages/sklearn/model_selection/_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/Users/louispandu/anaconda3/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
      "  warn(\n",
      "/Users/louispandu/anaconda3/lib/python3.10/site-packages/sklearn/model_selection/_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/Users/louispandu/anaconda3/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
      "  warn(\n",
      "/Users/louispandu/anaconda3/lib/python3.10/site-packages/sklearn/model_selection/_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/Users/louispandu/anaconda3/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
      "  warn(\n",
      "/Users/louispandu/anaconda3/lib/python3.10/site-packages/sklearn/model_selection/_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/Users/louispandu/anaconda3/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
      "  warn(\n",
      "/Users/louispandu/anaconda3/lib/python3.10/site-packages/sklearn/model_selection/_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/Users/louispandu/anaconda3/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
      "  warn(\n",
      "/Users/louispandu/anaconda3/lib/python3.10/site-packages/sklearn/model_selection/_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/Users/louispandu/anaconda3/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
      "  warn(\n",
      "/Users/louispandu/anaconda3/lib/python3.10/site-packages/sklearn/model_selection/_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/Users/louispandu/anaconda3/lib/python3.10/site-packages/sklearn/model_selection/_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/Users/louispandu/anaconda3/lib/python3.10/site-packages/sklearn/model_selection/_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/Users/louispandu/anaconda3/lib/python3.10/site-packages/sklearn/model_selection/_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/Users/louispandu/anaconda3/lib/python3.10/site-packages/sklearn/model_selection/_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/Users/louispandu/anaconda3/lib/python3.10/site-packages/sklearn/model_selection/_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/Users/louispandu/anaconda3/lib/python3.10/site-packages/sklearn/model_selection/_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/Users/louispandu/anaconda3/lib/python3.10/site-packages/sklearn/model_selection/_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/Users/louispandu/anaconda3/lib/python3.10/site-packages/sklearn/model_selection/_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/Users/louispandu/anaconda3/lib/python3.10/site-packages/sklearn/model_selection/_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/Users/louispandu/anaconda3/lib/python3.10/site-packages/sklearn/model_selection/_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/Users/louispandu/anaconda3/lib/python3.10/site-packages/sklearn/model_selection/_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/Users/louispandu/anaconda3/lib/python3.10/site-packages/sklearn/model_selection/_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/Users/louispandu/anaconda3/lib/python3.10/site-packages/sklearn/model_selection/_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/Users/louispandu/anaconda3/lib/python3.10/site-packages/sklearn/model_selection/_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/Users/louispandu/anaconda3/lib/python3.10/site-packages/sklearn/model_selection/_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/Users/louispandu/anaconda3/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
      "  warn(\n",
      "/Users/louispandu/anaconda3/lib/python3.10/site-packages/sklearn/model_selection/_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/Users/louispandu/anaconda3/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
      "  warn(\n",
      "/Users/louispandu/anaconda3/lib/python3.10/site-packages/sklearn/model_selection/_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/Users/louispandu/anaconda3/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
      "  warn(\n",
      "/Users/louispandu/anaconda3/lib/python3.10/site-packages/sklearn/model_selection/_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/Users/louispandu/anaconda3/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
      "  warn(\n",
      "/Users/louispandu/anaconda3/lib/python3.10/site-packages/sklearn/model_selection/_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/Users/louispandu/anaconda3/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
      "  warn(\n",
      "/Users/louispandu/anaconda3/lib/python3.10/site-packages/sklearn/model_selection/_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/Users/louispandu/anaconda3/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
      "  warn(\n",
      "/Users/louispandu/anaconda3/lib/python3.10/site-packages/sklearn/model_selection/_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/Users/louispandu/anaconda3/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
      "  warn(\n",
      "/Users/louispandu/anaconda3/lib/python3.10/site-packages/sklearn/model_selection/_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/Users/louispandu/anaconda3/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
      "  warn(\n",
      "/Users/louispandu/anaconda3/lib/python3.10/site-packages/sklearn/model_selection/_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/Users/louispandu/anaconda3/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
      "  warn(\n",
      "/Users/louispandu/anaconda3/lib/python3.10/site-packages/sklearn/model_selection/_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/Users/louispandu/anaconda3/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
      "  warn(\n",
      "/Users/louispandu/anaconda3/lib/python3.10/site-packages/sklearn/model_selection/_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/Users/louispandu/anaconda3/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
      "  warn(\n",
      "/Users/louispandu/anaconda3/lib/python3.10/site-packages/sklearn/model_selection/_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/Users/louispandu/anaconda3/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
      "  warn(\n",
      "/Users/louispandu/anaconda3/lib/python3.10/site-packages/sklearn/model_selection/_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/Users/louispandu/anaconda3/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
      "  warn(\n",
      "/Users/louispandu/anaconda3/lib/python3.10/site-packages/sklearn/model_selection/_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/Users/louispandu/anaconda3/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
      "  warn(\n",
      "/Users/louispandu/anaconda3/lib/python3.10/site-packages/sklearn/model_selection/_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/Users/louispandu/anaconda3/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
      "  warn(\n",
      "/Users/louispandu/anaconda3/lib/python3.10/site-packages/sklearn/model_selection/_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/Users/louispandu/anaconda3/lib/python3.10/site-packages/sklearn/model_selection/_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/Users/louispandu/anaconda3/lib/python3.10/site-packages/sklearn/model_selection/_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/Users/louispandu/anaconda3/lib/python3.10/site-packages/sklearn/model_selection/_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/Users/louispandu/anaconda3/lib/python3.10/site-packages/sklearn/model_selection/_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/Users/louispandu/anaconda3/lib/python3.10/site-packages/sklearn/model_selection/_search.py:909: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  self.best_estimator_.fit(X, y, **fit_params)\n",
      "/Users/louispandu/anaconda3/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
      "  warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-2 {color: black;background-color: white;}#sk-container-id-2 pre{padding: 0;}#sk-container-id-2 div.sk-toggleable {background-color: white;}#sk-container-id-2 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-2 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-2 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-2 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-2 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-2 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-2 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-2 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-2 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-2 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-2 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-2 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-2 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-2 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-2 div.sk-item {position: relative;z-index: 1;}#sk-container-id-2 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-2 div.sk-item::before, #sk-container-id-2 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-2 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-2 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-2 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-2 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-2 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-2 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-2 div.sk-label-container {text-align: center;}#sk-container-id-2 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-2 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-2\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>RandomizedSearchCV(cv=5, estimator=RandomForestRegressor(), n_jobs=-1,\n",
       "                   param_distributions={&#x27;max_depth&#x27;: [None, 10, 50, 100],\n",
       "                                        &#x27;max_features&#x27;: [&#x27;auto&#x27;, &#x27;sqrt&#x27;],\n",
       "                                        &#x27;min_samples_leaf&#x27;: [1, 2, 4],\n",
       "                                        &#x27;min_samples_split&#x27;: [2, 5, 10],\n",
       "                                        &#x27;n_estimators&#x27;: [100, 300, 500]},\n",
       "                   scoring=&#x27;neg_mean_absolute_error&#x27;)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" ><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">RandomizedSearchCV</label><div class=\"sk-toggleable__content\"><pre>RandomizedSearchCV(cv=5, estimator=RandomForestRegressor(), n_jobs=-1,\n",
       "                   param_distributions={&#x27;max_depth&#x27;: [None, 10, 50, 100],\n",
       "                                        &#x27;max_features&#x27;: [&#x27;auto&#x27;, &#x27;sqrt&#x27;],\n",
       "                                        &#x27;min_samples_leaf&#x27;: [1, 2, 4],\n",
       "                                        &#x27;min_samples_split&#x27;: [2, 5, 10],\n",
       "                                        &#x27;n_estimators&#x27;: [100, 300, 500]},\n",
       "                   scoring=&#x27;neg_mean_absolute_error&#x27;)</pre></div></div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-3\" type=\"checkbox\" ><label for=\"sk-estimator-id-3\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">estimator: RandomForestRegressor</label><div class=\"sk-toggleable__content\"><pre>RandomForestRegressor()</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-4\" type=\"checkbox\" ><label for=\"sk-estimator-id-4\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">RandomForestRegressor</label><div class=\"sk-toggleable__content\"><pre>RandomForestRegressor()</pre></div></div></div></div></div></div></div></div></div></div>"
      ],
      "text/plain": [
       "RandomizedSearchCV(cv=5, estimator=RandomForestRegressor(), n_jobs=-1,\n",
       "                   param_distributions={'max_depth': [None, 10, 50, 100],\n",
       "                                        'max_features': ['auto', 'sqrt'],\n",
       "                                        'min_samples_leaf': [1, 2, 4],\n",
       "                                        'min_samples_split': [2, 5, 10],\n",
       "                                        'n_estimators': [100, 300, 500]},\n",
       "                   scoring='neg_mean_absolute_error')"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rscv.fit(X_train1, y_train1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'n_estimators': 300,\n",
       " 'min_samples_split': 2,\n",
       " 'min_samples_leaf': 2,\n",
       " 'max_features': 'auto',\n",
       " 'max_depth': None}"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rscv.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['rscv_rf_tfidf_best_params_thcv.pkl']"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "joblib.dump(rscv, \"rscv_rf_tfidf_thcv.pkl\")\n",
    "joblib.dump(rscv.best_params_, \"rscv_rf_tfidf_best_params_thcv.pkl\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "RF (after Hyperparameter Tuning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/ns/m5pnr0211w91v02hpv22958m0000gn/T/ipykernel_88939/289611894.py:2: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  rfreg_ht.fit(X_train1, y_train1)\n",
      "/Users/louispandu/anaconda3/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
      "  warn(\n"
     ]
    }
   ],
   "source": [
    "rfreg_ht = RandomForestRegressor(n_estimators = 300, min_samples_split = 2, min_samples_leaf = 2, max_features = 'auto', max_depth = None)\n",
    "rfreg_ht.fit(X_train1, y_train1)\n",
    "y_pred_rfreg = rfreg_ht.predict(X_val)\n",
    "y_pred_rfreg_r2 = rfreg_ht.predict(X_train1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.01529306974598882"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mean_absolute_error(y_val, y_pred_rfreg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.003060340667927915"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mean_squared_error(y_val, y_pred_rfreg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.05532034587679216"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mean_squared_error(y_val, y_pred_rfreg, squared = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9811156458914654"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#train\n",
    "r2_score(y_train1, y_pred_rfreg_r2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9751060148932627"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#val\n",
    "r2_score(y_val, y_pred_rfreg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Residual plots after Hyperparameter Tuning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Predicting model on the test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_rfreg_test = rfreg_ht.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['y_test_rfreg_tfidf_thcv.pkl']"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "joblib.dump(y_pred_rfreg_test, \"y_pred_rfreg_test_tfidf_thcv.pkl\")\n",
    "joblib.dump(y_test, \"y_test_rfreg_tfidf_thcv.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.015402650265940102"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mean_absolute_error(y_test, y_pred_rfreg_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.00321146948909584"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mean_squared_error(y_test, y_pred_rfreg_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.05666982873713172"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mean_squared_error(y_test, y_pred_rfreg_test, squared = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9735127460270759"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "r2_score(y_test, y_pred_rfreg_test)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Error analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 800x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# assume y_pred is a numpy array and y_true is a pandas dataframe\n",
    "fig, ax = plt.subplots(figsize=(8, 6))\n",
    "\n",
    "column = \"X..THCV\"  # specify the target variable name\n",
    "ax.hist(y_pred_rfreg_test, alpha=0.5, label='y_pred', bins=20)\n",
    "ax.hist(y_test[column], alpha=0.5, label='y_true', bins=20)\n",
    "ax.legend(loc='upper right')\n",
    "ax.set_title(column)\n",
    "\n",
    "plt.show()\n",
    "plt.savefig('error_hist_knn_tfidf_thcv.png')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pearson R"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pearson correlation coefficient: 0.987\n",
      "P-value: 0.000\n"
     ]
    }
   ],
   "source": [
    "corr_coef, p_value = pearsonr(y_pred_rfreg_test.flatten(), y_test.values.ravel())\n",
    "\n",
    "print(f\"Pearson correlation coefficient: {corr_coef:.3f}\")\n",
    "print(f\"P-value: {p_value:.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Axes: >"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "corr_matrix = y_test.corr()\n",
    "sns.heatmap(corr_matrix, annot=True, cmap='coolwarm', center=0)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
