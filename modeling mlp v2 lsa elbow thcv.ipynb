{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn import preprocessing\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.neural_network import MLPRegressor\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "from sklearn.metrics import r2_score\n",
    "from scipy.stats import pearsonr\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.feature_selection import SelectFromModel\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compiling complete dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_mlp = pd.read_csv(\"df_thcv_lsa.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>lsa_0</th>\n",
       "      <th>lsa_1</th>\n",
       "      <th>lsa_2</th>\n",
       "      <th>lsa_3</th>\n",
       "      <th>lsa_4</th>\n",
       "      <th>hybrid</th>\n",
       "      <th>indica</th>\n",
       "      <th>sativa</th>\n",
       "      <th>anxiety</th>\n",
       "      <th>...</th>\n",
       "      <th>sweet</th>\n",
       "      <th>tar</th>\n",
       "      <th>tea</th>\n",
       "      <th>tobacco</th>\n",
       "      <th>tree</th>\n",
       "      <th>tropical</th>\n",
       "      <th>vanilla</th>\n",
       "      <th>violet</th>\n",
       "      <th>woody</th>\n",
       "      <th>X..THCV</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0.341025</td>\n",
       "      <td>0.182753</td>\n",
       "      <td>0.008214</td>\n",
       "      <td>0.140406</td>\n",
       "      <td>-0.156943</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.030928</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0.232158</td>\n",
       "      <td>-0.045496</td>\n",
       "      <td>0.187131</td>\n",
       "      <td>-0.000936</td>\n",
       "      <td>0.018518</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.030928</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4</td>\n",
       "      <td>0.238648</td>\n",
       "      <td>-0.048758</td>\n",
       "      <td>-0.107398</td>\n",
       "      <td>-0.067096</td>\n",
       "      <td>-0.006558</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.030928</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>7</td>\n",
       "      <td>0.401841</td>\n",
       "      <td>-0.062527</td>\n",
       "      <td>-0.018128</td>\n",
       "      <td>-0.104475</td>\n",
       "      <td>0.009215</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.030928</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>11</td>\n",
       "      <td>0.260672</td>\n",
       "      <td>-0.019644</td>\n",
       "      <td>0.215790</td>\n",
       "      <td>-0.106098</td>\n",
       "      <td>0.058930</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.030928</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>74995</th>\n",
       "      <td>42976</td>\n",
       "      <td>0.270141</td>\n",
       "      <td>-0.004631</td>\n",
       "      <td>-0.151272</td>\n",
       "      <td>0.035538</td>\n",
       "      <td>0.083641</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.154639</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>74996</th>\n",
       "      <td>42976</td>\n",
       "      <td>0.270141</td>\n",
       "      <td>-0.004631</td>\n",
       "      <td>-0.151272</td>\n",
       "      <td>0.035538</td>\n",
       "      <td>0.083641</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.154639</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>74997</th>\n",
       "      <td>42976</td>\n",
       "      <td>0.270141</td>\n",
       "      <td>-0.004631</td>\n",
       "      <td>-0.151272</td>\n",
       "      <td>0.035538</td>\n",
       "      <td>0.083641</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.154639</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>74998</th>\n",
       "      <td>42976</td>\n",
       "      <td>0.270141</td>\n",
       "      <td>-0.004631</td>\n",
       "      <td>-0.151272</td>\n",
       "      <td>0.035538</td>\n",
       "      <td>0.083641</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.154639</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>74999</th>\n",
       "      <td>42976</td>\n",
       "      <td>0.270141</td>\n",
       "      <td>-0.004631</td>\n",
       "      <td>-0.151272</td>\n",
       "      <td>0.035538</td>\n",
       "      <td>0.083641</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.154639</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>75000 rows × 88 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       index     lsa_0     lsa_1     lsa_2     lsa_3     lsa_4  hybrid  \\\n",
       "0          0  0.341025  0.182753  0.008214  0.140406 -0.156943       1   \n",
       "1          1  0.232158 -0.045496  0.187131 -0.000936  0.018518       1   \n",
       "2          4  0.238648 -0.048758 -0.107398 -0.067096 -0.006558       1   \n",
       "3          7  0.401841 -0.062527 -0.018128 -0.104475  0.009215       1   \n",
       "4         11  0.260672 -0.019644  0.215790 -0.106098  0.058930       1   \n",
       "...      ...       ...       ...       ...       ...       ...     ...   \n",
       "74995  42976  0.270141 -0.004631 -0.151272  0.035538  0.083641       0   \n",
       "74996  42976  0.270141 -0.004631 -0.151272  0.035538  0.083641       0   \n",
       "74997  42976  0.270141 -0.004631 -0.151272  0.035538  0.083641       0   \n",
       "74998  42976  0.270141 -0.004631 -0.151272  0.035538  0.083641       0   \n",
       "74999  42976  0.270141 -0.004631 -0.151272  0.035538  0.083641       0   \n",
       "\n",
       "       indica  sativa  anxiety  ...  sweet  tar  tea  tobacco  tree  tropical  \\\n",
       "0           0       0        0  ...      0    0    0        0     0         0   \n",
       "1           0       0        0  ...      0    0    0        0     0         0   \n",
       "2           0       0        0  ...      0    0    0        0     0         0   \n",
       "3           0       0        0  ...      0    1    0        0     0         0   \n",
       "4           0       0        0  ...      1    0    0        0     0         0   \n",
       "...       ...     ...      ...  ...    ...  ...  ...      ...   ...       ...   \n",
       "74995       1       0        0  ...      1    1    1        1     1         1   \n",
       "74996       1       0        0  ...      1    1    1        1     1         1   \n",
       "74997       1       0        0  ...      1    1    1        1     1         1   \n",
       "74998       1       0        0  ...      1    1    1        1     1         1   \n",
       "74999       1       0        0  ...      1    1    1        1     1         1   \n",
       "\n",
       "       vanilla  violet  woody   X..THCV  \n",
       "0            0       0      0  0.030928  \n",
       "1            1       0      0  0.030928  \n",
       "2            0       0      0  0.030928  \n",
       "3            1       1      1  0.030928  \n",
       "4            0       0      0  0.030928  \n",
       "...        ...     ...    ...       ...  \n",
       "74995        1       1      1  0.154639  \n",
       "74996        1       1      1  0.154639  \n",
       "74997        1       1      1  0.154639  \n",
       "74998        1       1      1  0.154639  \n",
       "74999        1       1      1  0.154639  \n",
       "\n",
       "[75000 rows x 88 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_mlp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['index',\n",
       " 'lsa_0',\n",
       " 'lsa_1',\n",
       " 'lsa_2',\n",
       " 'lsa_3',\n",
       " 'lsa_4',\n",
       " 'hybrid',\n",
       " 'indica',\n",
       " 'sativa',\n",
       " 'anxiety',\n",
       " 'anxious',\n",
       " 'aroused',\n",
       " 'arthritis',\n",
       " 'creative',\n",
       " 'depression',\n",
       " 'dizzy',\n",
       " 'dry eyes',\n",
       " 'dry mouth',\n",
       " 'energetic',\n",
       " 'epilepsy',\n",
       " 'euphoric',\n",
       " 'eye pressure',\n",
       " 'fatigue',\n",
       " 'focused',\n",
       " 'giggly',\n",
       " 'happy',\n",
       " 'headache',\n",
       " 'hungry',\n",
       " 'migraines',\n",
       " 'pain',\n",
       " 'paranoid',\n",
       " 'relaxed',\n",
       " 'seizures',\n",
       " 'sleepy',\n",
       " 'spasticity',\n",
       " 'stress',\n",
       " 'talkative',\n",
       " 'tingly',\n",
       " 'uplifted',\n",
       " 'ammonia',\n",
       " 'apple',\n",
       " 'apricot',\n",
       " 'berry',\n",
       " 'blue cheese',\n",
       " 'blueberry',\n",
       " 'butter',\n",
       " 'cheese',\n",
       " 'chemical',\n",
       " 'chestnut',\n",
       " 'citrus',\n",
       " 'coffee',\n",
       " 'diesel',\n",
       " 'earthy',\n",
       " 'flowery',\n",
       " 'fruit',\n",
       " 'grape',\n",
       " 'grapefruit',\n",
       " 'honey',\n",
       " 'lavender',\n",
       " 'lemon',\n",
       " 'lime',\n",
       " 'mango',\n",
       " 'menthol',\n",
       " 'mint',\n",
       " 'nutty',\n",
       " 'orange',\n",
       " 'peach',\n",
       " 'pear',\n",
       " 'pepper',\n",
       " 'pine',\n",
       " 'pineapple',\n",
       " 'plum',\n",
       " 'pungent',\n",
       " 'rose',\n",
       " 'sage',\n",
       " 'skunk',\n",
       " 'spicy/herbal',\n",
       " 'strawberry',\n",
       " 'sweet',\n",
       " 'tar',\n",
       " 'tea',\n",
       " 'tobacco',\n",
       " 'tree',\n",
       " 'tropical',\n",
       " 'vanilla',\n",
       " 'violet',\n",
       " 'woody',\n",
       " 'X..THCV']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_mlp.columns.to_list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df_mlp.drop(['index', 'X..THCV'], axis = 1)\n",
    "y = df_mlp[['X..THCV']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:ylabel='Count'>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "sns.histplot(y, bins = 10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train test split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=1, test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train1, X_val, y_train1, y_val = train_test_split(X_train, y_train, random_state=1, test_size=0.25)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "MLP modeling (before Feature selection and Hyperparameter Tuning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/andalanputra/opt/anaconda3/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:1623: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    }
   ],
   "source": [
    "mlpreg = MLPRegressor(random_state=1, early_stopping=True)\n",
    "mlpreg.fit(X_train1, y_train1)\n",
    "y_pred_mlp = mlpreg.predict(X_val)\n",
    "y_pred_mlp_r2 = mlpreg.predict(X_train1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.05477529017189228"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mean_absolute_error(y_val, y_pred_mlp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9333255947171886"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#train\n",
    "r2_score(y_train1, y_pred_mlp_r2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9026654434604404"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#val\n",
    "r2_score(y_val, y_pred_mlp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Residual plots for each target variable"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Feature Selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "rfreg = RandomForestRegressor()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/andalanputra/opt/anaconda3/lib/python3.9/site-packages/sklearn/feature_selection/_from_model.py:357: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  self.estimator_.fit(X, y, **fit_params)\n"
     ]
    }
   ],
   "source": [
    "selector = SelectFromModel(rfreg).fit(X_train1, y_train1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1.05075102e-01, 5.99085607e-02, 1.01671617e-01, 6.64505340e-02,\n",
       "       7.63132891e-02, 2.65159464e-01, 1.77322741e-03, 7.99222820e-04,\n",
       "       8.87899927e-05, 4.06786995e-04, 1.85410028e-03, 0.00000000e+00,\n",
       "       3.55706561e-03, 5.88289971e-04, 2.43254400e-04, 4.12579769e-03,\n",
       "       4.62472354e-03, 1.68202655e-03, 0.00000000e+00, 5.84916993e-03,\n",
       "       0.00000000e+00, 0.00000000e+00, 3.09406579e-03, 5.04052096e-03,\n",
       "       5.50788503e-03, 3.32191727e-04, 6.81907468e-03, 2.67909592e-04,\n",
       "       0.00000000e+00, 6.16342080e-04, 3.06321960e-03, 0.00000000e+00,\n",
       "       5.65146464e-03, 0.00000000e+00, 0.00000000e+00, 2.35683628e-03,\n",
       "       4.19640384e-03, 4.02755008e-03, 3.86278051e-05, 1.14360309e-04,\n",
       "       2.74027829e-05, 2.80321950e-03, 3.55730693e-06, 8.25150235e-04,\n",
       "       1.58854059e-05, 2.53399255e-02, 1.53467486e-04, 4.80867642e-06,\n",
       "       6.93073948e-02, 3.51777971e-05, 1.04923740e-02, 7.51188508e-03,\n",
       "       9.27258825e-04, 2.57953357e-04, 4.00215671e-03, 8.14582115e-04,\n",
       "       6.08808743e-04, 2.69937716e-05, 3.39203443e-03, 1.04710301e-01,\n",
       "       2.60233221e-03, 5.57337894e-05, 9.70647134e-04, 1.79593450e-04,\n",
       "       5.52828882e-03, 1.10700489e-06, 4.52839732e-06, 1.70404352e-03,\n",
       "       2.84242120e-03, 5.09965526e-05, 9.45693617e-05, 4.23688142e-03,\n",
       "       4.41780341e-05, 2.26725879e-04, 3.23319022e-03, 6.93036381e-04,\n",
       "       6.43449907e-05, 2.24043756e-03, 6.96309406e-05, 3.56836270e-05,\n",
       "       3.45213398e-05, 1.32836600e-04, 1.43113764e-03, 2.24710519e-04,\n",
       "       2.44301671e-05, 7.16181181e-04])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "selector.estimator_.feature_importances_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.011627906976744186"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "selector.threshold_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "mask = selector.get_support()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ True,  True,  True,  True,  True,  True, False, False, False,\n",
       "       False, False, False, False, False, False, False, False, False,\n",
       "       False, False, False, False, False, False, False, False, False,\n",
       "       False, False, False, False, False, False, False, False, False,\n",
       "       False, False, False, False, False, False, False, False, False,\n",
       "        True, False, False,  True, False, False, False, False, False,\n",
       "       False, False, False, False, False,  True, False, False, False,\n",
       "       False, False, False, False, False, False, False, False, False,\n",
       "       False, False, False, False, False, False, False, False, False,\n",
       "       False, False, False, False, False])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "selected_features = X.columns[mask]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>lsa_0</th>\n",
       "      <th>lsa_1</th>\n",
       "      <th>lsa_2</th>\n",
       "      <th>lsa_3</th>\n",
       "      <th>lsa_4</th>\n",
       "      <th>hybrid</th>\n",
       "      <th>cheese</th>\n",
       "      <th>citrus</th>\n",
       "      <th>lime</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.341025</td>\n",
       "      <td>0.182753</td>\n",
       "      <td>0.008214</td>\n",
       "      <td>0.140406</td>\n",
       "      <td>-0.156943</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.232158</td>\n",
       "      <td>-0.045496</td>\n",
       "      <td>0.187131</td>\n",
       "      <td>-0.000936</td>\n",
       "      <td>0.018518</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.238648</td>\n",
       "      <td>-0.048758</td>\n",
       "      <td>-0.107398</td>\n",
       "      <td>-0.067096</td>\n",
       "      <td>-0.006558</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.401841</td>\n",
       "      <td>-0.062527</td>\n",
       "      <td>-0.018128</td>\n",
       "      <td>-0.104475</td>\n",
       "      <td>0.009215</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.260672</td>\n",
       "      <td>-0.019644</td>\n",
       "      <td>0.215790</td>\n",
       "      <td>-0.106098</td>\n",
       "      <td>0.058930</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>74995</th>\n",
       "      <td>0.270141</td>\n",
       "      <td>-0.004631</td>\n",
       "      <td>-0.151272</td>\n",
       "      <td>0.035538</td>\n",
       "      <td>0.083641</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>74996</th>\n",
       "      <td>0.270141</td>\n",
       "      <td>-0.004631</td>\n",
       "      <td>-0.151272</td>\n",
       "      <td>0.035538</td>\n",
       "      <td>0.083641</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>74997</th>\n",
       "      <td>0.270141</td>\n",
       "      <td>-0.004631</td>\n",
       "      <td>-0.151272</td>\n",
       "      <td>0.035538</td>\n",
       "      <td>0.083641</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>74998</th>\n",
       "      <td>0.270141</td>\n",
       "      <td>-0.004631</td>\n",
       "      <td>-0.151272</td>\n",
       "      <td>0.035538</td>\n",
       "      <td>0.083641</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>74999</th>\n",
       "      <td>0.270141</td>\n",
       "      <td>-0.004631</td>\n",
       "      <td>-0.151272</td>\n",
       "      <td>0.035538</td>\n",
       "      <td>0.083641</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>75000 rows × 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          lsa_0     lsa_1     lsa_2     lsa_3     lsa_4  hybrid  cheese  \\\n",
       "0      0.341025  0.182753  0.008214  0.140406 -0.156943       1       0   \n",
       "1      0.232158 -0.045496  0.187131 -0.000936  0.018518       1       1   \n",
       "2      0.238648 -0.048758 -0.107398 -0.067096 -0.006558       1       0   \n",
       "3      0.401841 -0.062527 -0.018128 -0.104475  0.009215       1       0   \n",
       "4      0.260672 -0.019644  0.215790 -0.106098  0.058930       1       0   \n",
       "...         ...       ...       ...       ...       ...     ...     ...   \n",
       "74995  0.270141 -0.004631 -0.151272  0.035538  0.083641       0       1   \n",
       "74996  0.270141 -0.004631 -0.151272  0.035538  0.083641       0       1   \n",
       "74997  0.270141 -0.004631 -0.151272  0.035538  0.083641       0       1   \n",
       "74998  0.270141 -0.004631 -0.151272  0.035538  0.083641       0       1   \n",
       "74999  0.270141 -0.004631 -0.151272  0.035538  0.083641       0       1   \n",
       "\n",
       "       citrus  lime  \n",
       "0           0     0  \n",
       "1           0     0  \n",
       "2           0     0  \n",
       "3           0     0  \n",
       "4           0     0  \n",
       "...       ...   ...  \n",
       "74995       1     1  \n",
       "74996       1     1  \n",
       "74997       1     1  \n",
       "74998       1     1  \n",
       "74999       1     1  \n",
       "\n",
       "[75000 rows x 9 columns]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "selected_X = df_mlp[selected_features]\n",
    "selected_X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['lsa_0',\n",
       " 'lsa_1',\n",
       " 'lsa_2',\n",
       " 'lsa_3',\n",
       " 'lsa_4',\n",
       " 'hybrid',\n",
       " 'cheese',\n",
       " 'citrus',\n",
       " 'lime']"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "selected_X.columns.to_list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['selected_X_mlp_lsa_elbow_thcv.pkl']"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import joblib\n",
    "\n",
    "joblib.dump(selector, \"selector_mlp_lsa_elbow_thcv.pkl\")\n",
    "joblib.dump(selected_X, \"selected_X_mlp_lsa_elbow_thcv.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import joblib\n",
    "\n",
    "# selected_X = joblib.load(\"selected_X_mlp_lsa_elbow_thcv.pkl\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train test split (after Feature Selection)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(selected_X, y, random_state=1, test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train1, X_val, y_train1, y_val = train_test_split(X_train, y_train, random_state=1, test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/andalanputra/opt/anaconda3/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:1623: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/Users/andalanputra/opt/anaconda3/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "mlpreg.fit(X_train1, y_train1)\n",
    "y_pred_mlpreg = mlpreg.predict(X_val)\n",
    "y_pred_mlpreg_r2 = mlpreg.predict(X_train1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.10327769056687221"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mean_absolute_error(y_val, y_pred_mlpreg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7692154383708321"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#train\n",
    "r2_score(y_train1, y_pred_mlpreg_r2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7634926819091323"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#val\n",
    "r2_score(y_val, y_pred_mlpreg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hyperparameter Tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "parameters = {'hidden_layer_sizes': [(100,), (50, 50, 50), (50, 100, 50)],\n",
    "              'activation': ['tanh', 'relu'], #only tanh and relu\n",
    "              'max_iter': [200, 500, 1000]\n",
    "              }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "rscv = RandomizedSearchCV(mlpreg,  \n",
    "                     parameters,   \n",
    "                     cv=5, \n",
    "                     scoring='neg_mean_absolute_error',\n",
    "                     n_jobs=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/andalanputra/opt/anaconda3/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:1623: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/Users/andalanputra/opt/anaconda3/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:1623: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/Users/andalanputra/opt/anaconda3/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:1623: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/Users/andalanputra/opt/anaconda3/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:1623: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/Users/andalanputra/opt/anaconda3/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:1623: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/Users/andalanputra/opt/anaconda3/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:1623: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/Users/andalanputra/opt/anaconda3/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:1623: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/Users/andalanputra/opt/anaconda3/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:1623: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/Users/andalanputra/opt/anaconda3/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:1623: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/Users/andalanputra/opt/anaconda3/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:1623: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/Users/andalanputra/opt/anaconda3/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:1623: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/Users/andalanputra/opt/anaconda3/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:1623: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/Users/andalanputra/opt/anaconda3/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/Users/andalanputra/opt/anaconda3/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:1623: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/Users/andalanputra/opt/anaconda3/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/Users/andalanputra/opt/anaconda3/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:1623: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/Users/andalanputra/opt/anaconda3/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:1623: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/Users/andalanputra/opt/anaconda3/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:1623: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/Users/andalanputra/opt/anaconda3/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/Users/andalanputra/opt/anaconda3/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:1623: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/Users/andalanputra/opt/anaconda3/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:1623: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/Users/andalanputra/opt/anaconda3/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:1623: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/Users/andalanputra/opt/anaconda3/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:1623: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/Users/andalanputra/opt/anaconda3/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:1623: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/Users/andalanputra/opt/anaconda3/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:1623: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/Users/andalanputra/opt/anaconda3/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:1623: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/Users/andalanputra/opt/anaconda3/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:1623: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/Users/andalanputra/opt/anaconda3/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:1623: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/Users/andalanputra/opt/anaconda3/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:1623: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/Users/andalanputra/opt/anaconda3/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:1623: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/Users/andalanputra/opt/anaconda3/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:1623: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/Users/andalanputra/opt/anaconda3/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:1623: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/Users/andalanputra/opt/anaconda3/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:1623: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/Users/andalanputra/opt/anaconda3/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:1623: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/Users/andalanputra/opt/anaconda3/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:1623: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/Users/andalanputra/opt/anaconda3/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:1623: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/Users/andalanputra/opt/anaconda3/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:1623: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/Users/andalanputra/opt/anaconda3/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:1623: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/Users/andalanputra/opt/anaconda3/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:1623: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/Users/andalanputra/opt/anaconda3/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:1623: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/Users/andalanputra/opt/anaconda3/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:1623: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/Users/andalanputra/opt/anaconda3/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:1623: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/Users/andalanputra/opt/anaconda3/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:1623: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/Users/andalanputra/opt/anaconda3/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:1623: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/Users/andalanputra/opt/anaconda3/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:1623: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/Users/andalanputra/opt/anaconda3/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:1623: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/Users/andalanputra/opt/anaconda3/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:1623: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/Users/andalanputra/opt/anaconda3/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:1623: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/Users/andalanputra/opt/anaconda3/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:1623: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/Users/andalanputra/opt/anaconda3/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:1623: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/Users/andalanputra/opt/anaconda3/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:1623: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/Users/andalanputra/opt/anaconda3/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:1623: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/Users/andalanputra/opt/anaconda3/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:1623: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/Users/andalanputra/opt/anaconda3/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/Users/andalanputra/opt/anaconda3/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/Users/andalanputra/opt/anaconda3/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/Users/andalanputra/opt/anaconda3/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/Users/andalanputra/opt/anaconda3/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:1623: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;background-color: white;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>RandomizedSearchCV(cv=5,\n",
       "                   estimator=MLPRegressor(early_stopping=True, random_state=1),\n",
       "                   n_jobs=-1,\n",
       "                   param_distributions={&#x27;activation&#x27;: [&#x27;tanh&#x27;, &#x27;relu&#x27;],\n",
       "                                        &#x27;hidden_layer_sizes&#x27;: [(100,),\n",
       "                                                               (50, 50, 50),\n",
       "                                                               (50, 100, 50)],\n",
       "                                        &#x27;max_iter&#x27;: [200, 500, 1000]},\n",
       "                   scoring=&#x27;neg_mean_absolute_error&#x27;)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" ><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">RandomizedSearchCV</label><div class=\"sk-toggleable__content\"><pre>RandomizedSearchCV(cv=5,\n",
       "                   estimator=MLPRegressor(early_stopping=True, random_state=1),\n",
       "                   n_jobs=-1,\n",
       "                   param_distributions={&#x27;activation&#x27;: [&#x27;tanh&#x27;, &#x27;relu&#x27;],\n",
       "                                        &#x27;hidden_layer_sizes&#x27;: [(100,),\n",
       "                                                               (50, 50, 50),\n",
       "                                                               (50, 100, 50)],\n",
       "                                        &#x27;max_iter&#x27;: [200, 500, 1000]},\n",
       "                   scoring=&#x27;neg_mean_absolute_error&#x27;)</pre></div></div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" ><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">estimator: MLPRegressor</label><div class=\"sk-toggleable__content\"><pre>MLPRegressor(early_stopping=True, random_state=1)</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-3\" type=\"checkbox\" ><label for=\"sk-estimator-id-3\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">MLPRegressor</label><div class=\"sk-toggleable__content\"><pre>MLPRegressor(early_stopping=True, random_state=1)</pre></div></div></div></div></div></div></div></div></div></div>"
      ],
      "text/plain": [
       "RandomizedSearchCV(cv=5,\n",
       "                   estimator=MLPRegressor(early_stopping=True, random_state=1),\n",
       "                   n_jobs=-1,\n",
       "                   param_distributions={'activation': ['tanh', 'relu'],\n",
       "                                        'hidden_layer_sizes': [(100,),\n",
       "                                                               (50, 50, 50),\n",
       "                                                               (50, 100, 50)],\n",
       "                                        'max_iter': [200, 500, 1000]},\n",
       "                   scoring='neg_mean_absolute_error')"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rscv.fit(X_train1, y_train1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'max_iter': 200, 'hidden_layer_sizes': (50, 100, 50), 'activation': 'tanh'}"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rscv.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['rscv_mlp_lsa_elbow_best_params_thcv.pkl']"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "joblib.dump(rscv, \"rscv_mlp_lsa_elbow_thcv.pkl\")\n",
    "joblib.dump(rscv.best_params_, \"rscv_mlp_lsa_elbow_best_params_thcv.pkl\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "MLP fit (after hyperparameter tuning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/andalanputra/opt/anaconda3/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:1623: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    }
   ],
   "source": [
    "mlpreg_ht = MLPRegressor(random_state=1, max_iter=200, activation = 'tanh', hidden_layer_sizes= (50,100,50), early_stopping=True)\n",
    "mlpreg_ht.fit(X_train1, y_train1)\n",
    "y_pred_mlp_ht = mlpreg_ht.predict(X_val)\n",
    "y_pred_mlp_r2_ht = mlpreg_ht.predict(X_train1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.04440890527067239"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mean_absolute_error(y_val, y_pred_mlp_ht)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9540713623383562"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#train\n",
    "r2_score(y_train1, y_pred_mlp_r2_ht)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9372688278844584"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#val\n",
    "r2_score(y_val, y_pred_mlp_ht)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Residual plots after Hyperparameter Tuning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Predicting model on the test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_mlpreg_test = mlpreg_ht.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['y_test_mlpreg_lsa_elbow_thcv.pkl']"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "joblib.dump(y_pred_mlpreg_test, \"y_pred_mlpreg_test_lsa_elbow_thcv.pkl\")\n",
    "joblib.dump(y_test, \"y_test_mlpreg_lsa_elbow_thcv.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.045202325809562446"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mean_absolute_error(y_test, y_pred_mlpreg_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.007557174439353705"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mean_squared_error(y_test, y_pred_mlpreg_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0869320104412276"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mean_squared_error(y_test, y_pred_mlpreg_test, squared = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9376706522131064"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "r2_score(y_test, y_pred_mlpreg_test)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Error analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 576x432 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 432x288 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# assume y_pred is a numpy array and y_true is a pandas dataframe\n",
    "fig, ax = plt.subplots(figsize=(8, 6))\n",
    "\n",
    "column = \"X..THCV\"  # specify the target variable name\n",
    "ax.hist(y_pred_mlpreg_test, alpha=0.5, label='y_pred', bins=20)\n",
    "ax.hist(y_test[column], alpha=0.5, label='y_true', bins=20)\n",
    "ax.legend(loc='upper right')\n",
    "ax.set_title(column)\n",
    "\n",
    "plt.show()\n",
    "plt.savefig('error_hist_mlp_lsa_elbow_thcv.png')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pearson R"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pearson correlation coefficient: 0.968\n",
      "P-value: 0.000\n"
     ]
    }
   ],
   "source": [
    "corr_coef, p_value = pearsonr(y_pred_mlpreg_test.flatten(), y_test.values.ravel())\n",
    "\n",
    "print(f\"Pearson correlation coefficient: {corr_coef:.3f}\")\n",
    "print(f\"P-value: {p_value:.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:>"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "corr_matrix = y_test.corr()\n",
    "sns.heatmap(corr_matrix, annot=True, cmap='coolwarm', center=0)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
