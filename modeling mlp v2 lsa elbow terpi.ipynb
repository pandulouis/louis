{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn import preprocessing\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.neural_network import MLPRegressor\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "from sklearn.metrics import r2_score\n",
    "from scipy.stats import pearsonr\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.feature_selection import SelectFromModel\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compiling complete dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_mlp = pd.read_csv(\"df_terpi_lsa.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>lsa_0</th>\n",
       "      <th>lsa_1</th>\n",
       "      <th>lsa_2</th>\n",
       "      <th>lsa_3</th>\n",
       "      <th>lsa_4</th>\n",
       "      <th>hybrid</th>\n",
       "      <th>indica</th>\n",
       "      <th>sativa</th>\n",
       "      <th>anxiety</th>\n",
       "      <th>...</th>\n",
       "      <th>sweet</th>\n",
       "      <th>tar</th>\n",
       "      <th>tea</th>\n",
       "      <th>tobacco</th>\n",
       "      <th>tree</th>\n",
       "      <th>tropical</th>\n",
       "      <th>vanilla</th>\n",
       "      <th>violet</th>\n",
       "      <th>woody</th>\n",
       "      <th>X..Terpinolene</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0.341025</td>\n",
       "      <td>0.182753</td>\n",
       "      <td>0.008214</td>\n",
       "      <td>0.140406</td>\n",
       "      <td>-0.156943</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0.341025</td>\n",
       "      <td>0.182753</td>\n",
       "      <td>0.008214</td>\n",
       "      <td>0.140406</td>\n",
       "      <td>-0.156943</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0.341025</td>\n",
       "      <td>0.182753</td>\n",
       "      <td>0.008214</td>\n",
       "      <td>0.140406</td>\n",
       "      <td>-0.156943</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0.341025</td>\n",
       "      <td>0.182753</td>\n",
       "      <td>0.008214</td>\n",
       "      <td>0.140406</td>\n",
       "      <td>-0.156943</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0.341025</td>\n",
       "      <td>0.182753</td>\n",
       "      <td>0.008214</td>\n",
       "      <td>0.140406</td>\n",
       "      <td>-0.156943</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>74995</th>\n",
       "      <td>42965</td>\n",
       "      <td>0.360708</td>\n",
       "      <td>-0.269375</td>\n",
       "      <td>0.169135</td>\n",
       "      <td>0.099257</td>\n",
       "      <td>0.141142</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>74996</th>\n",
       "      <td>42965</td>\n",
       "      <td>0.360708</td>\n",
       "      <td>-0.269375</td>\n",
       "      <td>0.169135</td>\n",
       "      <td>0.099257</td>\n",
       "      <td>0.141142</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>74997</th>\n",
       "      <td>42970</td>\n",
       "      <td>0.440634</td>\n",
       "      <td>-0.078839</td>\n",
       "      <td>0.085152</td>\n",
       "      <td>0.087878</td>\n",
       "      <td>-0.133604</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>74998</th>\n",
       "      <td>42972</td>\n",
       "      <td>0.181714</td>\n",
       "      <td>-0.045560</td>\n",
       "      <td>-0.055692</td>\n",
       "      <td>0.015649</td>\n",
       "      <td>-0.045585</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>74999</th>\n",
       "      <td>42973</td>\n",
       "      <td>0.055494</td>\n",
       "      <td>0.003622</td>\n",
       "      <td>-0.050252</td>\n",
       "      <td>-0.024795</td>\n",
       "      <td>-0.031141</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>75000 rows × 88 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       index     lsa_0     lsa_1     lsa_2     lsa_3     lsa_4  hybrid  \\\n",
       "0          0  0.341025  0.182753  0.008214  0.140406 -0.156943       1   \n",
       "1          0  0.341025  0.182753  0.008214  0.140406 -0.156943       1   \n",
       "2          0  0.341025  0.182753  0.008214  0.140406 -0.156943       1   \n",
       "3          0  0.341025  0.182753  0.008214  0.140406 -0.156943       1   \n",
       "4          0  0.341025  0.182753  0.008214  0.140406 -0.156943       1   \n",
       "...      ...       ...       ...       ...       ...       ...     ...   \n",
       "74995  42965  0.360708 -0.269375  0.169135  0.099257  0.141142       0   \n",
       "74996  42965  0.360708 -0.269375  0.169135  0.099257  0.141142       0   \n",
       "74997  42970  0.440634 -0.078839  0.085152  0.087878 -0.133604       0   \n",
       "74998  42972  0.181714 -0.045560 -0.055692  0.015649 -0.045585       0   \n",
       "74999  42973  0.055494  0.003622 -0.050252 -0.024795 -0.031141       0   \n",
       "\n",
       "       indica  sativa  anxiety  ...  sweet  tar  tea  tobacco  tree  tropical  \\\n",
       "0           0       0        0  ...      0    0    0        0     0         0   \n",
       "1           0       0        0  ...      0    0    0        0     0         0   \n",
       "2           0       0        0  ...      0    0    0        0     0         0   \n",
       "3           0       0        0  ...      0    0    0        0     0         0   \n",
       "4           0       0        0  ...      0    0    0        0     0         0   \n",
       "...       ...     ...      ...  ...    ...  ...  ...      ...   ...       ...   \n",
       "74995       1       0        0  ...      0    0    0        0     0         0   \n",
       "74996       1       0        0  ...      0    0    0        0     0         0   \n",
       "74997       1       0        0  ...      0    0    0        0     0         0   \n",
       "74998       1       0        0  ...      0    0    0        0     0         0   \n",
       "74999       1       0        0  ...      0    0    0        0     0         0   \n",
       "\n",
       "       vanilla  violet  woody  X..Terpinolene  \n",
       "0            0       0      0             1.0  \n",
       "1            0       0      0             1.0  \n",
       "2            0       0      0             1.0  \n",
       "3            0       0      0             1.0  \n",
       "4            0       0      0             1.0  \n",
       "...        ...     ...    ...             ...  \n",
       "74995        0       0      0             0.0  \n",
       "74996        0       0      0             0.0  \n",
       "74997        0       0      0             0.0  \n",
       "74998        0       0      0             0.0  \n",
       "74999        0       0      0             0.0  \n",
       "\n",
       "[75000 rows x 88 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_mlp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['index',\n",
       " 'lsa_0',\n",
       " 'lsa_1',\n",
       " 'lsa_2',\n",
       " 'lsa_3',\n",
       " 'lsa_4',\n",
       " 'hybrid',\n",
       " 'indica',\n",
       " 'sativa',\n",
       " 'anxiety',\n",
       " 'anxious',\n",
       " 'aroused',\n",
       " 'arthritis',\n",
       " 'creative',\n",
       " 'depression',\n",
       " 'dizzy',\n",
       " 'dry eyes',\n",
       " 'dry mouth',\n",
       " 'energetic',\n",
       " 'epilepsy',\n",
       " 'euphoric',\n",
       " 'eye pressure',\n",
       " 'fatigue',\n",
       " 'focused',\n",
       " 'giggly',\n",
       " 'happy',\n",
       " 'headache',\n",
       " 'hungry',\n",
       " 'migraines',\n",
       " 'pain',\n",
       " 'paranoid',\n",
       " 'relaxed',\n",
       " 'seizures',\n",
       " 'sleepy',\n",
       " 'spasticity',\n",
       " 'stress',\n",
       " 'talkative',\n",
       " 'tingly',\n",
       " 'uplifted',\n",
       " 'ammonia',\n",
       " 'apple',\n",
       " 'apricot',\n",
       " 'berry',\n",
       " 'blue cheese',\n",
       " 'blueberry',\n",
       " 'butter',\n",
       " 'cheese',\n",
       " 'chemical',\n",
       " 'chestnut',\n",
       " 'citrus',\n",
       " 'coffee',\n",
       " 'diesel',\n",
       " 'earthy',\n",
       " 'flowery',\n",
       " 'fruit',\n",
       " 'grape',\n",
       " 'grapefruit',\n",
       " 'honey',\n",
       " 'lavender',\n",
       " 'lemon',\n",
       " 'lime',\n",
       " 'mango',\n",
       " 'menthol',\n",
       " 'mint',\n",
       " 'nutty',\n",
       " 'orange',\n",
       " 'peach',\n",
       " 'pear',\n",
       " 'pepper',\n",
       " 'pine',\n",
       " 'pineapple',\n",
       " 'plum',\n",
       " 'pungent',\n",
       " 'rose',\n",
       " 'sage',\n",
       " 'skunk',\n",
       " 'spicy/herbal',\n",
       " 'strawberry',\n",
       " 'sweet',\n",
       " 'tar',\n",
       " 'tea',\n",
       " 'tobacco',\n",
       " 'tree',\n",
       " 'tropical',\n",
       " 'vanilla',\n",
       " 'violet',\n",
       " 'woody',\n",
       " 'X..Terpinolene']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_mlp.columns.to_list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df_mlp.drop(['index', 'X..Terpinolene'], axis = 1)\n",
    "y = df_mlp[['X..Terpinolene']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:ylabel='Count'>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "sns.histplot(y, bins = 10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train test split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=1, test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train1, X_val, y_train1, y_val = train_test_split(X_train, y_train, random_state=1, test_size=0.25)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "MLP modeling (before Feature selection and Hyperparameter Tuning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/andalanputra/opt/anaconda3/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:1623: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    }
   ],
   "source": [
    "mlpreg = MLPRegressor(random_state=1, early_stopping=True)\n",
    "mlpreg.fit(X_train1, y_train1)\n",
    "y_pred_mlp = mlpreg.predict(X_val)\n",
    "y_pred_mlp_r2 = mlpreg.predict(X_train1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.10563850757384588"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mean_absolute_error(y_val, y_pred_mlp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8213847478765722"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#train\n",
    "r2_score(y_train1, y_pred_mlp_r2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7409733343446891"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#val\n",
    "r2_score(y_val, y_pred_mlp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Residual plots for each target variable"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Feature Selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "rfreg = RandomForestRegressor()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/andalanputra/opt/anaconda3/lib/python3.9/site-packages/sklearn/feature_selection/_from_model.py:357: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  self.estimator_.fit(X, y, **fit_params)\n"
     ]
    }
   ],
   "source": [
    "selector = SelectFromModel(rfreg).fit(X_train1, y_train1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1.08685923e-01, 8.92640461e-02, 9.41204272e-02, 8.76421064e-02,\n",
       "       8.08407571e-02, 2.25469398e-02, 8.05566837e-02, 2.60045360e-02,\n",
       "       2.57807737e-04, 1.78791779e-03, 2.89283020e-03, 1.39937017e-08,\n",
       "       4.40316501e-03, 1.81210129e-04, 7.79004556e-03, 1.23864782e-02,\n",
       "       4.28625963e-03, 7.54136253e-03, 5.43780042e-09, 7.52286731e-03,\n",
       "       3.80924372e-10, 2.58942504e-08, 6.07501933e-03, 1.10720502e-02,\n",
       "       1.10878366e-02, 1.69614533e-03, 4.75938215e-03, 1.46678124e-04,\n",
       "       6.57610238e-09, 1.98066054e-03, 1.46030548e-02, 3.13290323e-10,\n",
       "       7.13282200e-03, 4.68877990e-06, 0.00000000e+00, 5.24849297e-03,\n",
       "       4.21028631e-03, 7.83363747e-03, 3.34102279e-04, 1.24495677e-04,\n",
       "       8.03214213e-04, 1.78773113e-02, 1.28437624e-04, 7.96509012e-03,\n",
       "       1.92650632e-04, 1.10399712e-01, 5.47512439e-04, 2.18662876e-03,\n",
       "       3.44720710e-03, 9.68046914e-04, 1.96523003e-02, 6.68584369e-03,\n",
       "       1.77345971e-03, 7.60471385e-04, 2.07142753e-03, 3.63962165e-04,\n",
       "       1.02648019e-03, 4.98576388e-04, 1.41073111e-02, 6.75882909e-03,\n",
       "       1.96748858e-03, 7.71345467e-05, 1.25915654e-03, 1.06130189e-03,\n",
       "       1.70553508e-02, 1.11048362e-04, 2.01734491e-04, 8.30053523e-04,\n",
       "       2.64094132e-03, 3.49333154e-04, 9.63556352e-05, 3.24393040e-03,\n",
       "       2.97064495e-04, 1.02854049e-03, 2.94676736e-03, 1.97612902e-03,\n",
       "       9.52245624e-04, 5.04916577e-03, 6.54383560e-05, 7.80394068e-04,\n",
       "       2.18092270e-04, 7.65145945e-04, 1.05161822e-03, 4.01716749e-02,\n",
       "       4.01424142e-05, 2.52851083e-03])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "selector.estimator_.feature_importances_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.011627906976744186"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "selector.threshold_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "mask = selector.get_support()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ True,  True,  True,  True,  True,  True,  True,  True, False,\n",
       "       False, False, False, False, False, False,  True, False, False,\n",
       "       False, False, False, False, False, False, False, False, False,\n",
       "       False, False, False,  True, False, False, False, False, False,\n",
       "       False, False, False, False, False,  True, False, False, False,\n",
       "        True, False, False, False, False,  True, False, False, False,\n",
       "       False, False, False, False,  True, False, False, False, False,\n",
       "       False,  True, False, False, False, False, False, False, False,\n",
       "       False, False, False, False, False, False, False, False, False,\n",
       "       False, False,  True, False, False])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "selected_features = X.columns[mask]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>lsa_0</th>\n",
       "      <th>lsa_1</th>\n",
       "      <th>lsa_2</th>\n",
       "      <th>lsa_3</th>\n",
       "      <th>lsa_4</th>\n",
       "      <th>hybrid</th>\n",
       "      <th>indica</th>\n",
       "      <th>sativa</th>\n",
       "      <th>dry eyes</th>\n",
       "      <th>relaxed</th>\n",
       "      <th>berry</th>\n",
       "      <th>cheese</th>\n",
       "      <th>diesel</th>\n",
       "      <th>lemon</th>\n",
       "      <th>orange</th>\n",
       "      <th>vanilla</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.341025</td>\n",
       "      <td>0.182753</td>\n",
       "      <td>0.008214</td>\n",
       "      <td>0.140406</td>\n",
       "      <td>-0.156943</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.341025</td>\n",
       "      <td>0.182753</td>\n",
       "      <td>0.008214</td>\n",
       "      <td>0.140406</td>\n",
       "      <td>-0.156943</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.341025</td>\n",
       "      <td>0.182753</td>\n",
       "      <td>0.008214</td>\n",
       "      <td>0.140406</td>\n",
       "      <td>-0.156943</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.341025</td>\n",
       "      <td>0.182753</td>\n",
       "      <td>0.008214</td>\n",
       "      <td>0.140406</td>\n",
       "      <td>-0.156943</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.341025</td>\n",
       "      <td>0.182753</td>\n",
       "      <td>0.008214</td>\n",
       "      <td>0.140406</td>\n",
       "      <td>-0.156943</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>74995</th>\n",
       "      <td>0.360708</td>\n",
       "      <td>-0.269375</td>\n",
       "      <td>0.169135</td>\n",
       "      <td>0.099257</td>\n",
       "      <td>0.141142</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>74996</th>\n",
       "      <td>0.360708</td>\n",
       "      <td>-0.269375</td>\n",
       "      <td>0.169135</td>\n",
       "      <td>0.099257</td>\n",
       "      <td>0.141142</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>74997</th>\n",
       "      <td>0.440634</td>\n",
       "      <td>-0.078839</td>\n",
       "      <td>0.085152</td>\n",
       "      <td>0.087878</td>\n",
       "      <td>-0.133604</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>74998</th>\n",
       "      <td>0.181714</td>\n",
       "      <td>-0.045560</td>\n",
       "      <td>-0.055692</td>\n",
       "      <td>0.015649</td>\n",
       "      <td>-0.045585</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>74999</th>\n",
       "      <td>0.055494</td>\n",
       "      <td>0.003622</td>\n",
       "      <td>-0.050252</td>\n",
       "      <td>-0.024795</td>\n",
       "      <td>-0.031141</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>75000 rows × 16 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          lsa_0     lsa_1     lsa_2     lsa_3     lsa_4  hybrid  indica  \\\n",
       "0      0.341025  0.182753  0.008214  0.140406 -0.156943       1       0   \n",
       "1      0.341025  0.182753  0.008214  0.140406 -0.156943       1       0   \n",
       "2      0.341025  0.182753  0.008214  0.140406 -0.156943       1       0   \n",
       "3      0.341025  0.182753  0.008214  0.140406 -0.156943       1       0   \n",
       "4      0.341025  0.182753  0.008214  0.140406 -0.156943       1       0   \n",
       "...         ...       ...       ...       ...       ...     ...     ...   \n",
       "74995  0.360708 -0.269375  0.169135  0.099257  0.141142       0       1   \n",
       "74996  0.360708 -0.269375  0.169135  0.099257  0.141142       0       1   \n",
       "74997  0.440634 -0.078839  0.085152  0.087878 -0.133604       0       1   \n",
       "74998  0.181714 -0.045560 -0.055692  0.015649 -0.045585       0       1   \n",
       "74999  0.055494  0.003622 -0.050252 -0.024795 -0.031141       0       1   \n",
       "\n",
       "       sativa  dry eyes  relaxed  berry  cheese  diesel  lemon  orange  \\\n",
       "0           0         0        1      0       0       0      0       0   \n",
       "1           0         0        1      0       0       0      0       0   \n",
       "2           0         0        1      0       0       0      0       0   \n",
       "3           0         0        1      0       0       0      0       0   \n",
       "4           0         0        1      0       0       0      0       0   \n",
       "...       ...       ...      ...    ...     ...     ...    ...     ...   \n",
       "74995       0         0        0      0       0       0      0       0   \n",
       "74996       0         0        0      0       0       0      0       0   \n",
       "74997       0         0        0      0       0       0      0       0   \n",
       "74998       0         0        1      0       0       0      0       0   \n",
       "74999       0         0        0      0       0       0      0       0   \n",
       "\n",
       "       vanilla  \n",
       "0            0  \n",
       "1            0  \n",
       "2            0  \n",
       "3            0  \n",
       "4            0  \n",
       "...        ...  \n",
       "74995        0  \n",
       "74996        0  \n",
       "74997        0  \n",
       "74998        0  \n",
       "74999        0  \n",
       "\n",
       "[75000 rows x 16 columns]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "selected_X = df_mlp[selected_features]\n",
    "selected_X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['lsa_0',\n",
       " 'lsa_1',\n",
       " 'lsa_2',\n",
       " 'lsa_3',\n",
       " 'lsa_4',\n",
       " 'hybrid',\n",
       " 'indica',\n",
       " 'sativa',\n",
       " 'dry eyes',\n",
       " 'relaxed',\n",
       " 'berry',\n",
       " 'cheese',\n",
       " 'diesel',\n",
       " 'lemon',\n",
       " 'orange',\n",
       " 'vanilla']"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "selected_X.columns.to_list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['selected_X_mlp_lsa_elbow_terpi.pkl']"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import joblib\n",
    "\n",
    "joblib.dump(selector, \"selector_mlp_lsa_elbow_terpi.pkl\")\n",
    "joblib.dump(selected_X, \"selected_X_mlp_lsa_elbow_terpi.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import joblib\n",
    "\n",
    "# selected_X = joblib.load(\"selected_X_mlp_lsa_elbow_terpi.pkl\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train test split (after Feature Selection)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(selected_X, y, random_state=1, test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train1, X_val, y_train1, y_val = train_test_split(X_train, y_train, random_state=1, test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/andalanputra/opt/anaconda3/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:1623: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    }
   ],
   "source": [
    "mlpreg.fit(X_train1, y_train1)\n",
    "y_pred_mlpreg = mlpreg.predict(X_val)\n",
    "y_pred_mlpreg_r2 = mlpreg.predict(X_train1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.17502592967984296"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mean_absolute_error(y_val, y_pred_mlpreg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5527059356970055"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#train\n",
    "r2_score(y_train1, y_pred_mlpreg_r2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5289119725722635"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#val\n",
    "r2_score(y_val, y_pred_mlpreg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hyperparameter Tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "parameters = {'hidden_layer_sizes': [(100,), (50, 50, 50), (50, 100, 50)],\n",
    "              'activation': ['tanh', 'relu'], #only tanh and relu\n",
    "              'max_iter': [200, 500, 1000]\n",
    "              }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "rscv = RandomizedSearchCV(mlpreg,  \n",
    "                     parameters,   \n",
    "                     cv=5, \n",
    "                     scoring='neg_mean_absolute_error',\n",
    "                     n_jobs=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/andalanputra/opt/anaconda3/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:1623: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/Users/andalanputra/opt/anaconda3/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:1623: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/Users/andalanputra/opt/anaconda3/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:1623: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/Users/andalanputra/opt/anaconda3/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:1623: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/Users/andalanputra/opt/anaconda3/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:1623: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/Users/andalanputra/opt/anaconda3/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:1623: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/Users/andalanputra/opt/anaconda3/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:1623: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/Users/andalanputra/opt/anaconda3/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:1623: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/Users/andalanputra/opt/anaconda3/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:1623: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/Users/andalanputra/opt/anaconda3/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:1623: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/Users/andalanputra/opt/anaconda3/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:1623: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/Users/andalanputra/opt/anaconda3/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:1623: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/Users/andalanputra/opt/anaconda3/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:1623: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/Users/andalanputra/opt/anaconda3/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:1623: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/Users/andalanputra/opt/anaconda3/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:1623: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/Users/andalanputra/opt/anaconda3/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:1623: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/Users/andalanputra/opt/anaconda3/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:1623: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/Users/andalanputra/opt/anaconda3/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:1623: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/Users/andalanputra/opt/anaconda3/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:1623: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/Users/andalanputra/opt/anaconda3/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:1623: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/Users/andalanputra/opt/anaconda3/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:1623: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/Users/andalanputra/opt/anaconda3/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:1623: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/Users/andalanputra/opt/anaconda3/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:1623: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/Users/andalanputra/opt/anaconda3/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:1623: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/Users/andalanputra/opt/anaconda3/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:1623: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/Users/andalanputra/opt/anaconda3/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:1623: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/Users/andalanputra/opt/anaconda3/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:1623: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/Users/andalanputra/opt/anaconda3/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:1623: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/Users/andalanputra/opt/anaconda3/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:1623: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/Users/andalanputra/opt/anaconda3/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:1623: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/Users/andalanputra/opt/anaconda3/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:1623: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/Users/andalanputra/opt/anaconda3/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:1623: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/Users/andalanputra/opt/anaconda3/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:1623: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/Users/andalanputra/opt/anaconda3/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:1623: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/Users/andalanputra/opt/anaconda3/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:1623: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/Users/andalanputra/opt/anaconda3/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:1623: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/Users/andalanputra/opt/anaconda3/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:1623: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/Users/andalanputra/opt/anaconda3/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:1623: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/Users/andalanputra/opt/anaconda3/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:1623: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/Users/andalanputra/opt/anaconda3/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:1623: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/Users/andalanputra/opt/anaconda3/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:1623: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/Users/andalanputra/opt/anaconda3/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:1623: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/Users/andalanputra/opt/anaconda3/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:1623: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/Users/andalanputra/opt/anaconda3/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:1623: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/Users/andalanputra/opt/anaconda3/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:1623: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/Users/andalanputra/opt/anaconda3/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:1623: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/Users/andalanputra/opt/anaconda3/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:1623: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/Users/andalanputra/opt/anaconda3/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:1623: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/Users/andalanputra/opt/anaconda3/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/Users/andalanputra/opt/anaconda3/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:1623: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/Users/andalanputra/opt/anaconda3/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:1623: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/Users/andalanputra/opt/anaconda3/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/Users/andalanputra/opt/anaconda3/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/Users/andalanputra/opt/anaconda3/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/Users/andalanputra/opt/anaconda3/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/Users/andalanputra/opt/anaconda3/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:1623: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;background-color: white;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>RandomizedSearchCV(cv=5,\n",
       "                   estimator=MLPRegressor(early_stopping=True, random_state=1),\n",
       "                   n_jobs=-1,\n",
       "                   param_distributions={&#x27;activation&#x27;: [&#x27;tanh&#x27;, &#x27;relu&#x27;],\n",
       "                                        &#x27;hidden_layer_sizes&#x27;: [(100,),\n",
       "                                                               (50, 50, 50),\n",
       "                                                               (50, 100, 50)],\n",
       "                                        &#x27;max_iter&#x27;: [200, 500, 1000]},\n",
       "                   scoring=&#x27;neg_mean_absolute_error&#x27;)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" ><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">RandomizedSearchCV</label><div class=\"sk-toggleable__content\"><pre>RandomizedSearchCV(cv=5,\n",
       "                   estimator=MLPRegressor(early_stopping=True, random_state=1),\n",
       "                   n_jobs=-1,\n",
       "                   param_distributions={&#x27;activation&#x27;: [&#x27;tanh&#x27;, &#x27;relu&#x27;],\n",
       "                                        &#x27;hidden_layer_sizes&#x27;: [(100,),\n",
       "                                                               (50, 50, 50),\n",
       "                                                               (50, 100, 50)],\n",
       "                                        &#x27;max_iter&#x27;: [200, 500, 1000]},\n",
       "                   scoring=&#x27;neg_mean_absolute_error&#x27;)</pre></div></div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" ><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">estimator: MLPRegressor</label><div class=\"sk-toggleable__content\"><pre>MLPRegressor(early_stopping=True, random_state=1)</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-3\" type=\"checkbox\" ><label for=\"sk-estimator-id-3\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">MLPRegressor</label><div class=\"sk-toggleable__content\"><pre>MLPRegressor(early_stopping=True, random_state=1)</pre></div></div></div></div></div></div></div></div></div></div>"
      ],
      "text/plain": [
       "RandomizedSearchCV(cv=5,\n",
       "                   estimator=MLPRegressor(early_stopping=True, random_state=1),\n",
       "                   n_jobs=-1,\n",
       "                   param_distributions={'activation': ['tanh', 'relu'],\n",
       "                                        'hidden_layer_sizes': [(100,),\n",
       "                                                               (50, 50, 50),\n",
       "                                                               (50, 100, 50)],\n",
       "                                        'max_iter': [200, 500, 1000]},\n",
       "                   scoring='neg_mean_absolute_error')"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rscv.fit(X_train1, y_train1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'max_iter': 500, 'hidden_layer_sizes': (50, 100, 50), 'activation': 'tanh'}"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rscv.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['rscv_mlp_lsa_elbow_best_params_terpi.pkl']"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "joblib.dump(rscv, \"rscv_mlp_lsa_elbow_terpi.pkl\")\n",
    "joblib.dump(rscv.best_params_, \"rscv_mlp_lsa_elbow_best_params_terpi.pkl\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "MLP fit (after hyperparameter tuning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/andalanputra/opt/anaconda3/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:1623: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    }
   ],
   "source": [
    "mlpreg_ht = MLPRegressor(random_state=1, max_iter=500, activation = 'tanh', hidden_layer_sizes= (50,100,50), early_stopping=True)\n",
    "mlpreg_ht.fit(X_train1, y_train1)\n",
    "y_pred_mlp_ht = mlpreg_ht.predict(X_val)\n",
    "y_pred_mlp_r2_ht = mlpreg_ht.predict(X_train1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.09813897444486859"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mean_absolute_error(y_val, y_pred_mlp_ht)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.85061761302948"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#train\n",
    "r2_score(y_train1, y_pred_mlp_r2_ht)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7963763277205544"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#val\n",
    "r2_score(y_val, y_pred_mlp_ht)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Residual plots after Hyperparameter Tuning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Predicting model on the test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_mlpreg_test = mlpreg_ht.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['y_test_mlpreg_lsa_elbow_terpi.pkl']"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "joblib.dump(y_pred_mlpreg_test, \"y_pred_mlpreg_test_lsa_elbow_terpi.pkl\")\n",
    "joblib.dump(y_test, \"y_test_mlpreg_lsa_elbow_terpi.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.09735442891001808"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mean_absolute_error(y_test, y_pred_mlpreg_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.023379897761800255"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mean_squared_error(y_test, y_pred_mlpreg_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.1529048650691019"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mean_squared_error(y_test, y_pred_mlpreg_test, squared = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8046078419467415"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "r2_score(y_test, y_pred_mlpreg_test)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Error analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 576x432 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 432x288 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# assume y_pred is a numpy array and y_true is a pandas dataframe\n",
    "fig, ax = plt.subplots(figsize=(8, 6))\n",
    "\n",
    "column = \"X..Terpinolene\"  # specify the target variable name\n",
    "ax.hist(y_pred_mlpreg_test, alpha=0.5, label='y_pred', bins=20)\n",
    "ax.hist(y_test[column], alpha=0.5, label='y_true', bins=20)\n",
    "ax.legend(loc='upper right')\n",
    "ax.set_title(column)\n",
    "\n",
    "plt.show()\n",
    "plt.savefig('error_hist_mlp_lsa_elbow_terpi.png')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pearson R"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pearson correlation coefficient: 0.897\n",
      "P-value: 0.000\n"
     ]
    }
   ],
   "source": [
    "corr_coef, p_value = pearsonr(y_pred_mlpreg_test.flatten(), y_test.values.ravel())\n",
    "\n",
    "print(f\"Pearson correlation coefficient: {corr_coef:.3f}\")\n",
    "print(f\"P-value: {p_value:.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:>"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "corr_matrix = y_test.corr()\n",
    "sns.heatmap(corr_matrix, annot=True, cmap='coolwarm', center=0)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
