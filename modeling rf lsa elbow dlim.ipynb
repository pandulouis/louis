{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn import preprocessing\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.neural_network import MLPRegressor\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "from sklearn.metrics import r2_score\n",
    "from scipy.stats import pearsonr\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.feature_selection import SelectFromModel\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compiling complete dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_rf = pd.read_csv(\"df_dlim_lsa.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>lsa_0</th>\n",
       "      <th>lsa_1</th>\n",
       "      <th>lsa_2</th>\n",
       "      <th>lsa_3</th>\n",
       "      <th>lsa_4</th>\n",
       "      <th>hybrid</th>\n",
       "      <th>indica</th>\n",
       "      <th>sativa</th>\n",
       "      <th>anxiety</th>\n",
       "      <th>...</th>\n",
       "      <th>sweet</th>\n",
       "      <th>tar</th>\n",
       "      <th>tea</th>\n",
       "      <th>tobacco</th>\n",
       "      <th>tree</th>\n",
       "      <th>tropical</th>\n",
       "      <th>vanilla</th>\n",
       "      <th>violet</th>\n",
       "      <th>woody</th>\n",
       "      <th>X..D-Limonene</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0.341025</td>\n",
       "      <td>0.182753</td>\n",
       "      <td>0.008214</td>\n",
       "      <td>0.140406</td>\n",
       "      <td>-0.156943</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.341772</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0.232158</td>\n",
       "      <td>-0.045496</td>\n",
       "      <td>0.187131</td>\n",
       "      <td>-0.000936</td>\n",
       "      <td>0.018518</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.341772</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>0.261225</td>\n",
       "      <td>0.100324</td>\n",
       "      <td>-0.043622</td>\n",
       "      <td>0.141860</td>\n",
       "      <td>-0.034786</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.341772</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2</td>\n",
       "      <td>0.261225</td>\n",
       "      <td>0.100324</td>\n",
       "      <td>-0.043622</td>\n",
       "      <td>0.141860</td>\n",
       "      <td>-0.034786</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.341772</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3</td>\n",
       "      <td>0.243491</td>\n",
       "      <td>0.034313</td>\n",
       "      <td>0.080290</td>\n",
       "      <td>-0.165609</td>\n",
       "      <td>0.019773</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.341772</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>74995</th>\n",
       "      <td>42974</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.240506</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>74996</th>\n",
       "      <td>42975</td>\n",
       "      <td>0.324915</td>\n",
       "      <td>0.131823</td>\n",
       "      <td>-0.099424</td>\n",
       "      <td>0.065491</td>\n",
       "      <td>0.038437</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.240506</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>74997</th>\n",
       "      <td>42976</td>\n",
       "      <td>0.270141</td>\n",
       "      <td>-0.004631</td>\n",
       "      <td>-0.151272</td>\n",
       "      <td>0.035538</td>\n",
       "      <td>0.083641</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.240506</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>74998</th>\n",
       "      <td>42976</td>\n",
       "      <td>0.270141</td>\n",
       "      <td>-0.004631</td>\n",
       "      <td>-0.151272</td>\n",
       "      <td>0.035538</td>\n",
       "      <td>0.083641</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.240506</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>74999</th>\n",
       "      <td>42976</td>\n",
       "      <td>0.270141</td>\n",
       "      <td>-0.004631</td>\n",
       "      <td>-0.151272</td>\n",
       "      <td>0.035538</td>\n",
       "      <td>0.083641</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.240506</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>75000 rows × 88 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       index     lsa_0     lsa_1     lsa_2     lsa_3     lsa_4  hybrid  \\\n",
       "0          0  0.341025  0.182753  0.008214  0.140406 -0.156943       1   \n",
       "1          1  0.232158 -0.045496  0.187131 -0.000936  0.018518       1   \n",
       "2          2  0.261225  0.100324 -0.043622  0.141860 -0.034786       1   \n",
       "3          2  0.261225  0.100324 -0.043622  0.141860 -0.034786       1   \n",
       "4          3  0.243491  0.034313  0.080290 -0.165609  0.019773       1   \n",
       "...      ...       ...       ...       ...       ...       ...     ...   \n",
       "74995  42974  0.000000  0.000000  0.000000  0.000000  0.000000       0   \n",
       "74996  42975  0.324915  0.131823 -0.099424  0.065491  0.038437       0   \n",
       "74997  42976  0.270141 -0.004631 -0.151272  0.035538  0.083641       0   \n",
       "74998  42976  0.270141 -0.004631 -0.151272  0.035538  0.083641       0   \n",
       "74999  42976  0.270141 -0.004631 -0.151272  0.035538  0.083641       0   \n",
       "\n",
       "       indica  sativa  anxiety  ...  sweet  tar  tea  tobacco  tree  tropical  \\\n",
       "0           0       0        0  ...      0    0    0        0     0         0   \n",
       "1           0       0        0  ...      0    0    0        0     0         0   \n",
       "2           0       0        0  ...      1    0    0        0     0         0   \n",
       "3           0       0        0  ...      1    0    0        0     0         0   \n",
       "4           0       0        0  ...      0    1    0        0     0         0   \n",
       "...       ...     ...      ...  ...    ...  ...  ...      ...   ...       ...   \n",
       "74995       1       0        0  ...      0    0    0        0     0         0   \n",
       "74996       1       0        0  ...      0    0    0        0     0         0   \n",
       "74997       1       0        0  ...      1    1    1        1     1         1   \n",
       "74998       1       0        0  ...      1    1    1        1     1         1   \n",
       "74999       1       0        0  ...      1    1    1        1     1         1   \n",
       "\n",
       "       vanilla  violet  woody  X..D-Limonene  \n",
       "0            0       0      0       0.341772  \n",
       "1            1       0      0       0.341772  \n",
       "2            1       0      0       0.341772  \n",
       "3            1       0      0       0.341772  \n",
       "4            0       0      0       0.341772  \n",
       "...        ...     ...    ...            ...  \n",
       "74995        0       0      0       0.240506  \n",
       "74996        0       0      0       0.240506  \n",
       "74997        1       1      1       0.240506  \n",
       "74998        1       1      1       0.240506  \n",
       "74999        1       1      1       0.240506  \n",
       "\n",
       "[75000 rows x 88 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_rf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['index',\n",
       " 'lsa_0',\n",
       " 'lsa_1',\n",
       " 'lsa_2',\n",
       " 'lsa_3',\n",
       " 'lsa_4',\n",
       " 'hybrid',\n",
       " 'indica',\n",
       " 'sativa',\n",
       " 'anxiety',\n",
       " 'anxious',\n",
       " 'aroused',\n",
       " 'arthritis',\n",
       " 'creative',\n",
       " 'depression',\n",
       " 'dizzy',\n",
       " 'dry eyes',\n",
       " 'dry mouth',\n",
       " 'energetic',\n",
       " 'epilepsy',\n",
       " 'euphoric',\n",
       " 'eye pressure',\n",
       " 'fatigue',\n",
       " 'focused',\n",
       " 'giggly',\n",
       " 'happy',\n",
       " 'headache',\n",
       " 'hungry',\n",
       " 'migraines',\n",
       " 'pain',\n",
       " 'paranoid',\n",
       " 'relaxed',\n",
       " 'seizures',\n",
       " 'sleepy',\n",
       " 'spasticity',\n",
       " 'stress',\n",
       " 'talkative',\n",
       " 'tingly',\n",
       " 'uplifted',\n",
       " 'ammonia',\n",
       " 'apple',\n",
       " 'apricot',\n",
       " 'berry',\n",
       " 'blue cheese',\n",
       " 'blueberry',\n",
       " 'butter',\n",
       " 'cheese',\n",
       " 'chemical',\n",
       " 'chestnut',\n",
       " 'citrus',\n",
       " 'coffee',\n",
       " 'diesel',\n",
       " 'earthy',\n",
       " 'flowery',\n",
       " 'fruit',\n",
       " 'grape',\n",
       " 'grapefruit',\n",
       " 'honey',\n",
       " 'lavender',\n",
       " 'lemon',\n",
       " 'lime',\n",
       " 'mango',\n",
       " 'menthol',\n",
       " 'mint',\n",
       " 'nutty',\n",
       " 'orange',\n",
       " 'peach',\n",
       " 'pear',\n",
       " 'pepper',\n",
       " 'pine',\n",
       " 'pineapple',\n",
       " 'plum',\n",
       " 'pungent',\n",
       " 'rose',\n",
       " 'sage',\n",
       " 'skunk',\n",
       " 'spicy/herbal',\n",
       " 'strawberry',\n",
       " 'sweet',\n",
       " 'tar',\n",
       " 'tea',\n",
       " 'tobacco',\n",
       " 'tree',\n",
       " 'tropical',\n",
       " 'vanilla',\n",
       " 'violet',\n",
       " 'woody',\n",
       " 'X..D-Limonene']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_rf.columns.to_list()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Splitting dependent and independent variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df_rf.drop(['index', 'X..D-Limonene'], axis = 1)\n",
    "y = df_rf[['X..D-Limonene']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plotting histograms on target variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.34177215],\n",
       "       [0.34177215],\n",
       "       [0.34177215],\n",
       "       ...,\n",
       "       [0.24050633],\n",
       "       [0.24050633],\n",
       "       [0.24050633]])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_array = y.to_numpy()\n",
    "y_array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Axes: ylabel='Count'>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "sns.histplot(y, bins = 10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train test split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=1, test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train1, X_val, y_train1, y_val = train_test_split(X_train, y_train, random_state=1, test_size=0.25)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "RF modeling (before Feature selection and Hyperparameter Tuning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/ns/m5pnr0211w91v02hpv22958m0000gn/T/ipykernel_3460/119766249.py:2: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  rfreg.fit(X_train1, y_train1)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;background-color: white;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>RandomForestRegressor(n_jobs=-1)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">RandomForestRegressor</label><div class=\"sk-toggleable__content\"><pre>RandomForestRegressor(n_jobs=-1)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "RandomForestRegressor(n_jobs=-1)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rfreg = RandomForestRegressor(n_jobs = -1)\n",
    "rfreg.fit(X_train1, y_train1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_rfreg = rfreg.predict(X_val)\n",
    "y_pred_rfreg_r2 = rfreg.predict(X_train1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.05312623996014345"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mean_absolute_error(y_val, y_pred_rfreg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.011054729413151332"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mean_squared_error(y_val, y_pred_rfreg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.10514147332594942"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mean_squared_error(y_val, y_pred_rfreg, squared = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9749038915616636"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#train\n",
    "r2_score(y_train1, y_pred_rfreg_r2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8688912118196692"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#val\n",
    "r2_score(y_val, y_pred_rfreg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Residual plots for each target variable"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Feature Selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_feat = pd.DataFrame({\n",
    "    \"features\": X_train1.columns,\n",
    "    \"score\": rfreg.feature_importances_\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>features</th>\n",
       "      <th>score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>lsa_0</td>\n",
       "      <td>0.103711</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>lsa_1</td>\n",
       "      <td>0.091773</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>lsa_2</td>\n",
       "      <td>0.096387</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>lsa_3</td>\n",
       "      <td>0.099238</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>lsa_4</td>\n",
       "      <td>0.099537</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>81</th>\n",
       "      <td>tree</td>\n",
       "      <td>0.002371</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>82</th>\n",
       "      <td>tropical</td>\n",
       "      <td>0.004493</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>83</th>\n",
       "      <td>vanilla</td>\n",
       "      <td>0.003023</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>84</th>\n",
       "      <td>violet</td>\n",
       "      <td>0.000117</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>85</th>\n",
       "      <td>woody</td>\n",
       "      <td>0.004542</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>86 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    features     score\n",
       "0      lsa_0  0.103711\n",
       "1      lsa_1  0.091773\n",
       "2      lsa_2  0.096387\n",
       "3      lsa_3  0.099238\n",
       "4      lsa_4  0.099537\n",
       "..       ...       ...\n",
       "81      tree  0.002371\n",
       "82  tropical  0.004493\n",
       "83   vanilla  0.003023\n",
       "84    violet  0.000117\n",
       "85     woody  0.004542\n",
       "\n",
       "[86 rows x 2 columns]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_feat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_feat_ranked = df_feat.sort_values(\"score\", ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>features</th>\n",
       "      <th>score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>50</th>\n",
       "      <td>diesel</td>\n",
       "      <td>1.483413e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>lsa_0</td>\n",
       "      <td>1.037107e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>lsa_4</td>\n",
       "      <td>9.953735e-02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>lsa_3</td>\n",
       "      <td>9.923771e-02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>lsa_2</td>\n",
       "      <td>9.638705e-02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>lsa_1</td>\n",
       "      <td>9.177257e-02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>hybrid</td>\n",
       "      <td>4.194091e-02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>indica</td>\n",
       "      <td>2.417293e-02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>citrus</td>\n",
       "      <td>1.271379e-02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>58</th>\n",
       "      <td>lemon</td>\n",
       "      <td>1.113529e-02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>sativa</td>\n",
       "      <td>1.005957e-02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>64</th>\n",
       "      <td>orange</td>\n",
       "      <td>9.901987e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>blueberry</td>\n",
       "      <td>9.831352e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51</th>\n",
       "      <td>earthy</td>\n",
       "      <td>9.692688e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>relaxed</td>\n",
       "      <td>9.116825e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>euphoric</td>\n",
       "      <td>8.876866e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>hungry</td>\n",
       "      <td>8.839422e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>happy</td>\n",
       "      <td>8.647417e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>focused</td>\n",
       "      <td>8.227766e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>dry mouth</td>\n",
       "      <td>8.216280e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>uplifted</td>\n",
       "      <td>7.996766e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>74</th>\n",
       "      <td>skunk</td>\n",
       "      <td>7.872100e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>tingly</td>\n",
       "      <td>7.820782e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>76</th>\n",
       "      <td>strawberry</td>\n",
       "      <td>7.650034e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>creative</td>\n",
       "      <td>7.410865e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>71</th>\n",
       "      <td>pungent</td>\n",
       "      <td>7.278971e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54</th>\n",
       "      <td>grape</td>\n",
       "      <td>7.268016e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>77</th>\n",
       "      <td>sweet</td>\n",
       "      <td>7.026640e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>energetic</td>\n",
       "      <td>6.551514e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>68</th>\n",
       "      <td>pine</td>\n",
       "      <td>6.457957e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>giggly</td>\n",
       "      <td>6.205381e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>sleepy</td>\n",
       "      <td>6.096669e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>talkative</td>\n",
       "      <td>5.989508e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>berry</td>\n",
       "      <td>5.856411e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>dry eyes</td>\n",
       "      <td>5.356583e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>aroused</td>\n",
       "      <td>5.329815e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>85</th>\n",
       "      <td>woody</td>\n",
       "      <td>4.541617e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>82</th>\n",
       "      <td>tropical</td>\n",
       "      <td>4.492597e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>62</th>\n",
       "      <td>mint</td>\n",
       "      <td>3.997396e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75</th>\n",
       "      <td>spicy/herbal</td>\n",
       "      <td>3.909833e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>dizzy</td>\n",
       "      <td>3.760675e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>cheese</td>\n",
       "      <td>3.753014e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>butter</td>\n",
       "      <td>3.657948e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59</th>\n",
       "      <td>lime</td>\n",
       "      <td>3.649178e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>paranoid</td>\n",
       "      <td>3.179001e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>83</th>\n",
       "      <td>vanilla</td>\n",
       "      <td>3.022715e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>anxious</td>\n",
       "      <td>3.002910e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52</th>\n",
       "      <td>flowery</td>\n",
       "      <td>2.980990e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>headache</td>\n",
       "      <td>2.863783e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>81</th>\n",
       "      <td>tree</td>\n",
       "      <td>2.371362e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53</th>\n",
       "      <td>fruit</td>\n",
       "      <td>2.317067e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>coffee</td>\n",
       "      <td>2.275570e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>67</th>\n",
       "      <td>pepper</td>\n",
       "      <td>2.230115e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>chemical</td>\n",
       "      <td>1.728371e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>73</th>\n",
       "      <td>sage</td>\n",
       "      <td>1.691026e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>79</th>\n",
       "      <td>tea</td>\n",
       "      <td>1.410940e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>57</th>\n",
       "      <td>lavender</td>\n",
       "      <td>1.364145e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>55</th>\n",
       "      <td>grapefruit</td>\n",
       "      <td>1.239728e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>63</th>\n",
       "      <td>nutty</td>\n",
       "      <td>1.008604e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>72</th>\n",
       "      <td>rose</td>\n",
       "      <td>8.885974e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>56</th>\n",
       "      <td>honey</td>\n",
       "      <td>8.693611e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>60</th>\n",
       "      <td>mango</td>\n",
       "      <td>7.227306e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>69</th>\n",
       "      <td>pineapple</td>\n",
       "      <td>5.504972e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>migraines</td>\n",
       "      <td>4.950608e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>80</th>\n",
       "      <td>tobacco</td>\n",
       "      <td>4.495184e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>anxiety</td>\n",
       "      <td>4.223045e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>78</th>\n",
       "      <td>tar</td>\n",
       "      <td>3.983153e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>ammonia</td>\n",
       "      <td>3.627406e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>depression</td>\n",
       "      <td>3.308124e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>61</th>\n",
       "      <td>menthol</td>\n",
       "      <td>3.265462e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>apple</td>\n",
       "      <td>1.953101e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>70</th>\n",
       "      <td>plum</td>\n",
       "      <td>1.853795e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>chestnut</td>\n",
       "      <td>1.720289e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>65</th>\n",
       "      <td>peach</td>\n",
       "      <td>1.594931e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>apricot</td>\n",
       "      <td>1.542509e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>66</th>\n",
       "      <td>pear</td>\n",
       "      <td>1.531832e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>84</th>\n",
       "      <td>violet</td>\n",
       "      <td>1.171929e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>blue cheese</td>\n",
       "      <td>6.765937e-05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>stress</td>\n",
       "      <td>1.871258e-06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>epilepsy</td>\n",
       "      <td>3.957426e-07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>eye pressure</td>\n",
       "      <td>2.609032e-07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>spasticity</td>\n",
       "      <td>1.035366e-07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>fatigue</td>\n",
       "      <td>3.567053e-08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>arthritis</td>\n",
       "      <td>3.388470e-09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>seizures</td>\n",
       "      <td>1.363217e-09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>pain</td>\n",
       "      <td>2.656947e-10</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        features         score\n",
       "50        diesel  1.483413e-01\n",
       "0          lsa_0  1.037107e-01\n",
       "4          lsa_4  9.953735e-02\n",
       "3          lsa_3  9.923771e-02\n",
       "2          lsa_2  9.638705e-02\n",
       "1          lsa_1  9.177257e-02\n",
       "5         hybrid  4.194091e-02\n",
       "6         indica  2.417293e-02\n",
       "48        citrus  1.271379e-02\n",
       "58         lemon  1.113529e-02\n",
       "7         sativa  1.005957e-02\n",
       "64        orange  9.901987e-03\n",
       "43     blueberry  9.831352e-03\n",
       "51        earthy  9.692688e-03\n",
       "30       relaxed  9.116825e-03\n",
       "19      euphoric  8.876866e-03\n",
       "26        hungry  8.839422e-03\n",
       "24         happy  8.647417e-03\n",
       "22       focused  8.227766e-03\n",
       "16     dry mouth  8.216280e-03\n",
       "37      uplifted  7.996766e-03\n",
       "74         skunk  7.872100e-03\n",
       "36        tingly  7.820782e-03\n",
       "76    strawberry  7.650034e-03\n",
       "12      creative  7.410865e-03\n",
       "71       pungent  7.278971e-03\n",
       "54         grape  7.268016e-03\n",
       "77         sweet  7.026640e-03\n",
       "17     energetic  6.551514e-03\n",
       "68          pine  6.457957e-03\n",
       "23        giggly  6.205381e-03\n",
       "32        sleepy  6.096669e-03\n",
       "35     talkative  5.989508e-03\n",
       "41         berry  5.856411e-03\n",
       "15      dry eyes  5.356583e-03\n",
       "10       aroused  5.329815e-03\n",
       "85         woody  4.541617e-03\n",
       "82      tropical  4.492597e-03\n",
       "62          mint  3.997396e-03\n",
       "75  spicy/herbal  3.909833e-03\n",
       "14         dizzy  3.760675e-03\n",
       "45        cheese  3.753014e-03\n",
       "44        butter  3.657948e-03\n",
       "59          lime  3.649178e-03\n",
       "29      paranoid  3.179001e-03\n",
       "83       vanilla  3.022715e-03\n",
       "9        anxious  3.002910e-03\n",
       "52       flowery  2.980990e-03\n",
       "25      headache  2.863783e-03\n",
       "81          tree  2.371362e-03\n",
       "53         fruit  2.317067e-03\n",
       "49        coffee  2.275570e-03\n",
       "67        pepper  2.230115e-03\n",
       "46      chemical  1.728371e-03\n",
       "73          sage  1.691026e-03\n",
       "79           tea  1.410940e-03\n",
       "57      lavender  1.364145e-03\n",
       "55    grapefruit  1.239728e-03\n",
       "63         nutty  1.008604e-03\n",
       "72          rose  8.885974e-04\n",
       "56         honey  8.693611e-04\n",
       "60         mango  7.227306e-04\n",
       "69     pineapple  5.504972e-04\n",
       "27     migraines  4.950608e-04\n",
       "80       tobacco  4.495184e-04\n",
       "8        anxiety  4.223045e-04\n",
       "78           tar  3.983153e-04\n",
       "38       ammonia  3.627406e-04\n",
       "13    depression  3.308124e-04\n",
       "61       menthol  3.265462e-04\n",
       "39         apple  1.953101e-04\n",
       "70          plum  1.853795e-04\n",
       "47      chestnut  1.720289e-04\n",
       "65         peach  1.594931e-04\n",
       "40       apricot  1.542509e-04\n",
       "66          pear  1.531832e-04\n",
       "84        violet  1.171929e-04\n",
       "42   blue cheese  6.765937e-05\n",
       "34        stress  1.871258e-06\n",
       "18      epilepsy  3.957426e-07\n",
       "20  eye pressure  2.609032e-07\n",
       "33    spasticity  1.035366e-07\n",
       "21       fatigue  3.567053e-08\n",
       "11     arthritis  3.388470e-09\n",
       "31      seizures  1.363217e-09\n",
       "28          pain  2.656947e-10"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.set_option('display.max_rows', df_feat_ranked.shape[0]+1)\n",
    "df_feat_ranked"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/louispandu/anaconda3/lib/python3.10/site-packages/sklearn/feature_selection/_from_model.py:357: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  self.estimator_.fit(X, y, **fit_params)\n"
     ]
    }
   ],
   "source": [
    "selector = SelectFromModel(rfreg).fit(X_train1, y_train1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1.04628113e-01, 9.05800431e-02, 9.73475377e-02, 9.88823763e-02,\n",
       "       9.90196065e-02, 4.19736370e-02, 2.43168331e-02, 9.97198086e-03,\n",
       "       5.02040197e-04, 2.87034995e-03, 5.42431192e-03, 2.41347467e-10,\n",
       "       7.53848520e-03, 3.61657703e-04, 3.78877248e-03, 5.57548589e-03,\n",
       "       8.34207335e-03, 6.64668439e-03, 2.89803237e-10, 8.91008190e-03,\n",
       "       2.27693646e-07, 3.56036309e-10, 8.00744786e-03, 6.28660134e-03,\n",
       "       8.43204821e-03, 2.81179951e-03, 8.26368136e-03, 4.29530685e-04,\n",
       "       8.03798654e-09, 3.12501409e-03, 9.48093364e-03, 1.36736567e-09,\n",
       "       6.03123308e-03, 4.62232257e-08, 1.12713188e-06, 6.06101920e-03,\n",
       "       7.71643480e-03, 8.08639665e-03, 3.91030729e-04, 1.77688901e-04,\n",
       "       1.91032535e-04, 5.92221267e-03, 7.35276555e-05, 9.84877420e-03,\n",
       "       3.70369403e-03, 3.77949371e-03, 1.58115477e-03, 1.51409643e-04,\n",
       "       1.27285435e-02, 2.23553993e-03, 1.48186562e-01, 1.00219442e-02,\n",
       "       2.73608930e-03, 2.40640536e-03, 7.58684895e-03, 1.17682683e-03,\n",
       "       9.45034468e-04, 1.43871203e-03, 1.12148325e-02, 3.63984773e-03,\n",
       "       7.54035349e-04, 3.92234434e-04, 3.75104879e-03, 9.39294459e-04,\n",
       "       9.59691602e-03, 2.02179229e-04, 1.44252896e-04, 2.06242746e-03,\n",
       "       6.47134464e-03, 5.55581283e-04, 1.54615627e-04, 7.09858608e-03,\n",
       "       9.16815998e-04, 1.91384989e-03, 7.98056540e-03, 3.75140573e-03,\n",
       "       7.75020037e-03, 7.09649198e-03, 4.26017985e-04, 1.49611328e-03,\n",
       "       3.98306488e-04, 2.23617657e-03, 4.73340514e-03, 2.95452340e-03,\n",
       "       1.38972746e-04, 4.53381130e-03])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "selector.estimator_.feature_importances_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.011627906976744184"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "selector.threshold_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "mask = selector.get_support()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ True,  True,  True,  True,  True,  True,  True, False, False,\n",
       "       False, False, False, False, False, False, False, False, False,\n",
       "       False, False, False, False, False, False, False, False, False,\n",
       "       False, False, False, False, False, False, False, False, False,\n",
       "       False, False, False, False, False, False, False, False, False,\n",
       "       False, False, False,  True, False,  True, False, False, False,\n",
       "       False, False, False, False, False, False, False, False, False,\n",
       "       False, False, False, False, False, False, False, False, False,\n",
       "       False, False, False, False, False, False, False, False, False,\n",
       "       False, False, False, False, False])"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "selected_features = X.columns[mask]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>lsa_0</th>\n",
       "      <th>lsa_1</th>\n",
       "      <th>lsa_2</th>\n",
       "      <th>lsa_3</th>\n",
       "      <th>lsa_4</th>\n",
       "      <th>hybrid</th>\n",
       "      <th>indica</th>\n",
       "      <th>citrus</th>\n",
       "      <th>diesel</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.341025</td>\n",
       "      <td>0.182753</td>\n",
       "      <td>0.008214</td>\n",
       "      <td>0.140406</td>\n",
       "      <td>-0.156943</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.232158</td>\n",
       "      <td>-0.045496</td>\n",
       "      <td>0.187131</td>\n",
       "      <td>-0.000936</td>\n",
       "      <td>0.018518</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.261225</td>\n",
       "      <td>0.100324</td>\n",
       "      <td>-0.043622</td>\n",
       "      <td>0.141860</td>\n",
       "      <td>-0.034786</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.261225</td>\n",
       "      <td>0.100324</td>\n",
       "      <td>-0.043622</td>\n",
       "      <td>0.141860</td>\n",
       "      <td>-0.034786</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.243491</td>\n",
       "      <td>0.034313</td>\n",
       "      <td>0.080290</td>\n",
       "      <td>-0.165609</td>\n",
       "      <td>0.019773</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>74995</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>74996</th>\n",
       "      <td>0.324915</td>\n",
       "      <td>0.131823</td>\n",
       "      <td>-0.099424</td>\n",
       "      <td>0.065491</td>\n",
       "      <td>0.038437</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>74997</th>\n",
       "      <td>0.270141</td>\n",
       "      <td>-0.004631</td>\n",
       "      <td>-0.151272</td>\n",
       "      <td>0.035538</td>\n",
       "      <td>0.083641</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>74998</th>\n",
       "      <td>0.270141</td>\n",
       "      <td>-0.004631</td>\n",
       "      <td>-0.151272</td>\n",
       "      <td>0.035538</td>\n",
       "      <td>0.083641</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>74999</th>\n",
       "      <td>0.270141</td>\n",
       "      <td>-0.004631</td>\n",
       "      <td>-0.151272</td>\n",
       "      <td>0.035538</td>\n",
       "      <td>0.083641</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>75000 rows × 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          lsa_0     lsa_1     lsa_2     lsa_3     lsa_4  hybrid  indica  \\\n",
       "0      0.341025  0.182753  0.008214  0.140406 -0.156943       1       0   \n",
       "1      0.232158 -0.045496  0.187131 -0.000936  0.018518       1       0   \n",
       "2      0.261225  0.100324 -0.043622  0.141860 -0.034786       1       0   \n",
       "3      0.261225  0.100324 -0.043622  0.141860 -0.034786       1       0   \n",
       "4      0.243491  0.034313  0.080290 -0.165609  0.019773       1       0   \n",
       "...         ...       ...       ...       ...       ...     ...     ...   \n",
       "74995  0.000000  0.000000  0.000000  0.000000  0.000000       0       1   \n",
       "74996  0.324915  0.131823 -0.099424  0.065491  0.038437       0       1   \n",
       "74997  0.270141 -0.004631 -0.151272  0.035538  0.083641       0       1   \n",
       "74998  0.270141 -0.004631 -0.151272  0.035538  0.083641       0       1   \n",
       "74999  0.270141 -0.004631 -0.151272  0.035538  0.083641       0       1   \n",
       "\n",
       "       citrus  diesel  \n",
       "0           0       0  \n",
       "1           0       0  \n",
       "2           0       0  \n",
       "3           0       0  \n",
       "4           0       0  \n",
       "...       ...     ...  \n",
       "74995       0       0  \n",
       "74996       0       0  \n",
       "74997       1       1  \n",
       "74998       1       1  \n",
       "74999       1       1  \n",
       "\n",
       "[75000 rows x 9 columns]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "selected_X = df_rf[selected_features]\n",
    "selected_X"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train test split (after Feature Selection)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['selected_X_rf_lsa_elbow_dlim.pkl']"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import joblib\n",
    "\n",
    "joblib.dump(selector, \"selector_rf_lsa_elbow_dlim.pkl\")\n",
    "joblib.dump(selected_X, \"selected_X_rf_lsa_elbow_dlim.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(selected_X, y, random_state=1, test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train1, X_val, y_train1, y_val = train_test_split(X_train, y_train, random_state=1, test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/ns/m5pnr0211w91v02hpv22958m0000gn/T/ipykernel_3460/3758305.py:1: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  rfreg.fit(X_train1, y_train1)\n"
     ]
    }
   ],
   "source": [
    "rfreg.fit(X_train1, y_train1)\n",
    "y_pred_rfreg = rfreg.predict(X_val)\n",
    "y_pred_rfreg_r2 = rfreg.predict(X_train1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.06051750085029742"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mean_absolute_error(y_val, y_pred_rfreg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.013464864596242599"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mean_squared_error(y_val, y_pred_rfreg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.11603820317568951"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mean_squared_error(y_val, y_pred_rfreg, squared = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9556013167337912"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#train\n",
    "r2_score(y_train1, y_pred_rfreg_r2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8401893121478042"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#val\n",
    "r2_score(y_val, y_pred_rfreg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hyperparameter Tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "parameters = { 'max_depth': [None, 10, 50, 100],\n",
    "              'max_features': ['auto', 'sqrt'],\n",
    "              'min_samples_leaf': [1, 2, 4],\n",
    "              'min_samples_split': [2, 5, 10],\n",
    "              'n_estimators': [100, 300, 500]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "rscv = RandomizedSearchCV(rfreg,  \n",
    "                     parameters,   \n",
    "                     cv=5, \n",
    "                     scoring='neg_mean_absolute_error',\n",
    "                     n_jobs= -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/louispandu/anaconda3/lib/python3.10/site-packages/sklearn/model_selection/_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/Users/louispandu/anaconda3/lib/python3.10/site-packages/sklearn/model_selection/_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/Users/louispandu/anaconda3/lib/python3.10/site-packages/sklearn/model_selection/_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/Users/louispandu/anaconda3/lib/python3.10/site-packages/sklearn/model_selection/_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/Users/louispandu/anaconda3/lib/python3.10/site-packages/sklearn/model_selection/_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/Users/louispandu/anaconda3/lib/python3.10/site-packages/sklearn/model_selection/_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/Users/louispandu/anaconda3/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
      "  warn(\n",
      "/Users/louispandu/anaconda3/lib/python3.10/site-packages/sklearn/model_selection/_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/Users/louispandu/anaconda3/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
      "  warn(\n",
      "/Users/louispandu/anaconda3/lib/python3.10/site-packages/sklearn/model_selection/_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/Users/louispandu/anaconda3/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
      "  warn(\n",
      "/Users/louispandu/anaconda3/lib/python3.10/site-packages/sklearn/model_selection/_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/Users/louispandu/anaconda3/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
      "  warn(\n",
      "/Users/louispandu/anaconda3/lib/python3.10/site-packages/sklearn/model_selection/_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/Users/louispandu/anaconda3/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
      "  warn(\n",
      "/Users/louispandu/anaconda3/lib/python3.10/site-packages/sklearn/model_selection/_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/Users/louispandu/anaconda3/lib/python3.10/site-packages/sklearn/model_selection/_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/Users/louispandu/anaconda3/lib/python3.10/site-packages/sklearn/model_selection/_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/Users/louispandu/anaconda3/lib/python3.10/site-packages/sklearn/model_selection/_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/Users/louispandu/anaconda3/lib/python3.10/site-packages/sklearn/model_selection/_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/Users/louispandu/anaconda3/lib/python3.10/site-packages/sklearn/model_selection/_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/Users/louispandu/anaconda3/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
      "  warn(\n",
      "/Users/louispandu/anaconda3/lib/python3.10/site-packages/sklearn/model_selection/_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/Users/louispandu/anaconda3/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
      "  warn(\n",
      "/Users/louispandu/anaconda3/lib/python3.10/site-packages/sklearn/model_selection/_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/Users/louispandu/anaconda3/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
      "  warn(\n",
      "/Users/louispandu/anaconda3/lib/python3.10/site-packages/sklearn/model_selection/_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/Users/louispandu/anaconda3/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
      "  warn(\n",
      "/Users/louispandu/anaconda3/lib/python3.10/site-packages/sklearn/model_selection/_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/Users/louispandu/anaconda3/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
      "  warn(\n",
      "/Users/louispandu/anaconda3/lib/python3.10/site-packages/sklearn/model_selection/_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/Users/louispandu/anaconda3/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
      "  warn(\n",
      "/Users/louispandu/anaconda3/lib/python3.10/site-packages/sklearn/model_selection/_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/Users/louispandu/anaconda3/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
      "  warn(\n",
      "/Users/louispandu/anaconda3/lib/python3.10/site-packages/sklearn/model_selection/_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/Users/louispandu/anaconda3/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
      "  warn(\n",
      "/Users/louispandu/anaconda3/lib/python3.10/site-packages/sklearn/model_selection/_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/Users/louispandu/anaconda3/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
      "  warn(\n",
      "/Users/louispandu/anaconda3/lib/python3.10/site-packages/sklearn/model_selection/_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/Users/louispandu/anaconda3/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
      "  warn(\n",
      "/Users/louispandu/anaconda3/lib/python3.10/site-packages/sklearn/model_selection/_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/Users/louispandu/anaconda3/lib/python3.10/site-packages/sklearn/model_selection/_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/Users/louispandu/anaconda3/lib/python3.10/site-packages/sklearn/model_selection/_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/Users/louispandu/anaconda3/lib/python3.10/site-packages/sklearn/model_selection/_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/Users/louispandu/anaconda3/lib/python3.10/site-packages/sklearn/model_selection/_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/Users/louispandu/anaconda3/lib/python3.10/site-packages/sklearn/model_selection/_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/Users/louispandu/anaconda3/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
      "  warn(\n",
      "/Users/louispandu/anaconda3/lib/python3.10/site-packages/sklearn/model_selection/_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/Users/louispandu/anaconda3/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
      "  warn(\n",
      "/Users/louispandu/anaconda3/lib/python3.10/site-packages/sklearn/model_selection/_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/Users/louispandu/anaconda3/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
      "  warn(\n",
      "/Users/louispandu/anaconda3/lib/python3.10/site-packages/sklearn/model_selection/_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/Users/louispandu/anaconda3/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
      "  warn(\n",
      "/Users/louispandu/anaconda3/lib/python3.10/site-packages/sklearn/model_selection/_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/Users/louispandu/anaconda3/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
      "  warn(\n",
      "/Users/louispandu/anaconda3/lib/python3.10/site-packages/sklearn/model_selection/_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/Users/louispandu/anaconda3/lib/python3.10/site-packages/sklearn/model_selection/_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/Users/louispandu/anaconda3/lib/python3.10/site-packages/sklearn/model_selection/_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/Users/louispandu/anaconda3/lib/python3.10/site-packages/sklearn/model_selection/_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/Users/louispandu/anaconda3/lib/python3.10/site-packages/sklearn/model_selection/_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/Users/louispandu/anaconda3/lib/python3.10/site-packages/sklearn/model_selection/_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/Users/louispandu/anaconda3/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
      "  warn(\n",
      "/Users/louispandu/anaconda3/lib/python3.10/site-packages/sklearn/model_selection/_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/Users/louispandu/anaconda3/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
      "  warn(\n",
      "/Users/louispandu/anaconda3/lib/python3.10/site-packages/sklearn/model_selection/_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/Users/louispandu/anaconda3/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
      "  warn(\n",
      "/Users/louispandu/anaconda3/lib/python3.10/site-packages/sklearn/model_selection/_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/Users/louispandu/anaconda3/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
      "  warn(\n",
      "/Users/louispandu/anaconda3/lib/python3.10/site-packages/sklearn/model_selection/_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/Users/louispandu/anaconda3/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
      "  warn(\n",
      "/Users/louispandu/anaconda3/lib/python3.10/site-packages/sklearn/model_selection/_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/Users/louispandu/anaconda3/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
      "  warn(\n",
      "/Users/louispandu/anaconda3/lib/python3.10/site-packages/joblib/externals/loky/process_executor.py:702: UserWarning: A worker stopped while some jobs were given to the executor. This can be caused by a too short worker timeout or by a memory leak.\n",
      "  warnings.warn(\n",
      "/Users/louispandu/anaconda3/lib/python3.10/site-packages/sklearn/model_selection/_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/Users/louispandu/anaconda3/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
      "  warn(\n",
      "/Users/louispandu/anaconda3/lib/python3.10/site-packages/sklearn/model_selection/_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/Users/louispandu/anaconda3/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
      "  warn(\n",
      "/Users/louispandu/anaconda3/lib/python3.10/site-packages/sklearn/model_selection/_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/Users/louispandu/anaconda3/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
      "  warn(\n",
      "/Users/louispandu/anaconda3/lib/python3.10/site-packages/sklearn/model_selection/_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/Users/louispandu/anaconda3/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
      "  warn(\n",
      "/Users/louispandu/anaconda3/lib/python3.10/site-packages/sklearn/model_selection/_search.py:909: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  self.best_estimator_.fit(X, y, **fit_params)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-2 {color: black;background-color: white;}#sk-container-id-2 pre{padding: 0;}#sk-container-id-2 div.sk-toggleable {background-color: white;}#sk-container-id-2 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-2 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-2 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-2 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-2 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-2 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-2 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-2 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-2 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-2 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-2 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-2 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-2 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-2 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-2 div.sk-item {position: relative;z-index: 1;}#sk-container-id-2 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-2 div.sk-item::before, #sk-container-id-2 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-2 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-2 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-2 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-2 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-2 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-2 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-2 div.sk-label-container {text-align: center;}#sk-container-id-2 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-2 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-2\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>RandomizedSearchCV(cv=5, estimator=RandomForestRegressor(n_jobs=-1), n_jobs=-1,\n",
       "                   param_distributions={&#x27;max_depth&#x27;: [None, 10, 50, 100],\n",
       "                                        &#x27;max_features&#x27;: [&#x27;auto&#x27;, &#x27;sqrt&#x27;],\n",
       "                                        &#x27;min_samples_leaf&#x27;: [1, 2, 4],\n",
       "                                        &#x27;min_samples_split&#x27;: [2, 5, 10],\n",
       "                                        &#x27;n_estimators&#x27;: [100, 300, 500]},\n",
       "                   scoring=&#x27;neg_mean_absolute_error&#x27;)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" ><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">RandomizedSearchCV</label><div class=\"sk-toggleable__content\"><pre>RandomizedSearchCV(cv=5, estimator=RandomForestRegressor(n_jobs=-1), n_jobs=-1,\n",
       "                   param_distributions={&#x27;max_depth&#x27;: [None, 10, 50, 100],\n",
       "                                        &#x27;max_features&#x27;: [&#x27;auto&#x27;, &#x27;sqrt&#x27;],\n",
       "                                        &#x27;min_samples_leaf&#x27;: [1, 2, 4],\n",
       "                                        &#x27;min_samples_split&#x27;: [2, 5, 10],\n",
       "                                        &#x27;n_estimators&#x27;: [100, 300, 500]},\n",
       "                   scoring=&#x27;neg_mean_absolute_error&#x27;)</pre></div></div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-3\" type=\"checkbox\" ><label for=\"sk-estimator-id-3\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">estimator: RandomForestRegressor</label><div class=\"sk-toggleable__content\"><pre>RandomForestRegressor(n_jobs=-1)</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-4\" type=\"checkbox\" ><label for=\"sk-estimator-id-4\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">RandomForestRegressor</label><div class=\"sk-toggleable__content\"><pre>RandomForestRegressor(n_jobs=-1)</pre></div></div></div></div></div></div></div></div></div></div>"
      ],
      "text/plain": [
       "RandomizedSearchCV(cv=5, estimator=RandomForestRegressor(n_jobs=-1), n_jobs=-1,\n",
       "                   param_distributions={'max_depth': [None, 10, 50, 100],\n",
       "                                        'max_features': ['auto', 'sqrt'],\n",
       "                                        'min_samples_leaf': [1, 2, 4],\n",
       "                                        'min_samples_split': [2, 5, 10],\n",
       "                                        'n_estimators': [100, 300, 500]},\n",
       "                   scoring='neg_mean_absolute_error')"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rscv.fit(X_train1, y_train1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'n_estimators': 100,\n",
       " 'min_samples_split': 2,\n",
       " 'min_samples_leaf': 1,\n",
       " 'max_features': 'sqrt',\n",
       " 'max_depth': 50}"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rscv.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['rscv_rf_lsa_elbow_best_params_dlim.pkl']"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "joblib.dump(rscv, \"rscv_rf_lsa_elbow_dlim.pkl\")\n",
    "joblib.dump(rscv.best_params_, \"rscv_rf_lsa_elbow_best_params_dlim.pkl\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "RF (after Hyperparameter Tuning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/ns/m5pnr0211w91v02hpv22958m0000gn/T/ipykernel_3460/2143269374.py:2: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  rfreg_ht.fit(X_train1, y_train1)\n"
     ]
    }
   ],
   "source": [
    "rfreg_ht = RandomForestRegressor(n_estimators = 100, min_samples_split = 2, max_features = 'sqrt', min_samples_leaf = 1, max_depth = 50)\n",
    "rfreg_ht.fit(X_train1, y_train1)\n",
    "y_pred_rfreg = rfreg_ht.predict(X_val)\n",
    "y_pred_rfreg_r2 = rfreg_ht.predict(X_train1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.05978000627664793"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mean_absolute_error(y_val, y_pred_rfreg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.013075054025433833"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mean_squared_error(y_val, y_pred_rfreg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.11434620249677657"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mean_squared_error(y_val, y_pred_rfreg, squared = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9562844078592736"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#train\n",
    "r2_score(y_train1, y_pred_rfreg_r2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8448158640902864"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#val\n",
    "r2_score(y_val, y_pred_rfreg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Residual plots after Hyperparameter Tuning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Predicting model on the test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_rfreg_test = rfreg_ht.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['y_test_rfreg_lsa_elbow_dlim.pkl']"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "joblib.dump(y_pred_rfreg_test, \"y_pred_rfreg_test_lsa_elbow_dlim.pkl\")\n",
    "joblib.dump(y_test, \"y_test_rfreg_lsa_elbow_dlim.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.05919378959507985"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mean_absolute_error(y_test, y_pred_rfreg_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.01262471768342695"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mean_squared_error(y_test, y_pred_rfreg_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.11235976897193652"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mean_squared_error(y_test, y_pred_rfreg_test, squared = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8521188828364707"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "r2_score(y_test, y_pred_rfreg_test)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Error analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 800x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# assume y_pred is a numpy array and y_true is a pandas dataframe\n",
    "fig, ax = plt.subplots(figsize=(8, 6))\n",
    "\n",
    "column = \"X..D-Limonene\"  # specify the target variable name\n",
    "ax.hist(y_pred_rfreg_test, alpha=0.5, label='y_pred', bins=20)\n",
    "ax.hist(y_test[column], alpha=0.5, label='y_true', bins=20)\n",
    "ax.legend(loc='upper right')\n",
    "ax.set_title(column)\n",
    "\n",
    "plt.show()\n",
    "plt.savefig('error_hist_rf_lsa_below_dlim.png')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pearson R"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pearson correlation coefficient: 0.928\n",
      "P-value: 0.000\n"
     ]
    }
   ],
   "source": [
    "corr_coef, p_value = pearsonr(y_pred_rfreg_test.flatten(), y_test.values.ravel())\n",
    "\n",
    "print(f\"Pearson correlation coefficient: {corr_coef:.3f}\")\n",
    "print(f\"P-value: {p_value:.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Axes: >"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "corr_matrix = y_test.corr()\n",
    "sns.heatmap(corr_matrix, annot=True, cmap='coolwarm', center=0)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
