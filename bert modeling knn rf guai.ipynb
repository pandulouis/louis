{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn import preprocessing\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.neural_network import MLPRegressor\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "from sklearn.metrics import r2_score\n",
    "from scipy.stats import pearsonr\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.feature_selection import SelectFromModel\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_bert = pd.read_csv(\"df_guai_bert.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>feature_0</th>\n",
       "      <th>feature_1</th>\n",
       "      <th>feature_2</th>\n",
       "      <th>feature_3</th>\n",
       "      <th>feature_4</th>\n",
       "      <th>feature_5</th>\n",
       "      <th>feature_6</th>\n",
       "      <th>feature_7</th>\n",
       "      <th>feature_8</th>\n",
       "      <th>...</th>\n",
       "      <th>feature_759</th>\n",
       "      <th>feature_760</th>\n",
       "      <th>feature_761</th>\n",
       "      <th>feature_762</th>\n",
       "      <th>feature_763</th>\n",
       "      <th>feature_764</th>\n",
       "      <th>feature_765</th>\n",
       "      <th>feature_766</th>\n",
       "      <th>feature_767</th>\n",
       "      <th>X..Guaiol</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0.144370</td>\n",
       "      <td>0.133683</td>\n",
       "      <td>0.558613</td>\n",
       "      <td>0.002472</td>\n",
       "      <td>0.064213</td>\n",
       "      <td>-0.297644</td>\n",
       "      <td>0.649253</td>\n",
       "      <td>0.156834</td>\n",
       "      <td>-0.075428</td>\n",
       "      <td>...</td>\n",
       "      <td>0.171215</td>\n",
       "      <td>0.197233</td>\n",
       "      <td>-0.131170</td>\n",
       "      <td>0.210236</td>\n",
       "      <td>-0.728103</td>\n",
       "      <td>0.027258</td>\n",
       "      <td>-0.683708</td>\n",
       "      <td>-0.160281</td>\n",
       "      <td>-0.718498</td>\n",
       "      <td>0.444444</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0.144370</td>\n",
       "      <td>0.133683</td>\n",
       "      <td>0.558613</td>\n",
       "      <td>0.002472</td>\n",
       "      <td>0.064213</td>\n",
       "      <td>-0.297644</td>\n",
       "      <td>0.649253</td>\n",
       "      <td>0.156834</td>\n",
       "      <td>-0.075428</td>\n",
       "      <td>...</td>\n",
       "      <td>0.171215</td>\n",
       "      <td>0.197233</td>\n",
       "      <td>-0.131170</td>\n",
       "      <td>0.210236</td>\n",
       "      <td>-0.728103</td>\n",
       "      <td>0.027258</td>\n",
       "      <td>-0.683708</td>\n",
       "      <td>-0.160281</td>\n",
       "      <td>-0.718498</td>\n",
       "      <td>0.444444</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0.144370</td>\n",
       "      <td>0.133683</td>\n",
       "      <td>0.558613</td>\n",
       "      <td>0.002472</td>\n",
       "      <td>0.064213</td>\n",
       "      <td>-0.297644</td>\n",
       "      <td>0.649253</td>\n",
       "      <td>0.156834</td>\n",
       "      <td>-0.075428</td>\n",
       "      <td>...</td>\n",
       "      <td>0.171215</td>\n",
       "      <td>0.197233</td>\n",
       "      <td>-0.131170</td>\n",
       "      <td>0.210236</td>\n",
       "      <td>-0.728103</td>\n",
       "      <td>0.027258</td>\n",
       "      <td>-0.683708</td>\n",
       "      <td>-0.160281</td>\n",
       "      <td>-0.718498</td>\n",
       "      <td>0.444444</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2</td>\n",
       "      <td>0.127047</td>\n",
       "      <td>0.111979</td>\n",
       "      <td>0.549845</td>\n",
       "      <td>0.036660</td>\n",
       "      <td>0.026879</td>\n",
       "      <td>-0.309649</td>\n",
       "      <td>0.654963</td>\n",
       "      <td>0.205110</td>\n",
       "      <td>-0.097057</td>\n",
       "      <td>...</td>\n",
       "      <td>0.146141</td>\n",
       "      <td>0.174652</td>\n",
       "      <td>-0.146565</td>\n",
       "      <td>0.217158</td>\n",
       "      <td>-0.712819</td>\n",
       "      <td>0.046792</td>\n",
       "      <td>-0.744437</td>\n",
       "      <td>-0.214183</td>\n",
       "      <td>-0.707376</td>\n",
       "      <td>0.444444</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2</td>\n",
       "      <td>0.127047</td>\n",
       "      <td>0.111979</td>\n",
       "      <td>0.549845</td>\n",
       "      <td>0.036660</td>\n",
       "      <td>0.026879</td>\n",
       "      <td>-0.309649</td>\n",
       "      <td>0.654963</td>\n",
       "      <td>0.205110</td>\n",
       "      <td>-0.097057</td>\n",
       "      <td>...</td>\n",
       "      <td>0.146141</td>\n",
       "      <td>0.174652</td>\n",
       "      <td>-0.146565</td>\n",
       "      <td>0.217158</td>\n",
       "      <td>-0.712819</td>\n",
       "      <td>0.046792</td>\n",
       "      <td>-0.744437</td>\n",
       "      <td>-0.214183</td>\n",
       "      <td>-0.707376</td>\n",
       "      <td>0.444444</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>74995</th>\n",
       "      <td>42969</td>\n",
       "      <td>0.212347</td>\n",
       "      <td>0.124677</td>\n",
       "      <td>0.604793</td>\n",
       "      <td>0.083085</td>\n",
       "      <td>0.034133</td>\n",
       "      <td>-0.408407</td>\n",
       "      <td>0.786280</td>\n",
       "      <td>0.111345</td>\n",
       "      <td>-0.127262</td>\n",
       "      <td>...</td>\n",
       "      <td>0.161177</td>\n",
       "      <td>0.153434</td>\n",
       "      <td>-0.125303</td>\n",
       "      <td>0.314786</td>\n",
       "      <td>-0.765685</td>\n",
       "      <td>0.128396</td>\n",
       "      <td>-0.816410</td>\n",
       "      <td>-0.213200</td>\n",
       "      <td>-0.849931</td>\n",
       "      <td>0.222222</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>74996</th>\n",
       "      <td>42972</td>\n",
       "      <td>0.102736</td>\n",
       "      <td>0.135983</td>\n",
       "      <td>0.550969</td>\n",
       "      <td>-0.014671</td>\n",
       "      <td>0.015193</td>\n",
       "      <td>-0.269029</td>\n",
       "      <td>0.679146</td>\n",
       "      <td>0.145063</td>\n",
       "      <td>-0.059002</td>\n",
       "      <td>...</td>\n",
       "      <td>0.252791</td>\n",
       "      <td>0.156139</td>\n",
       "      <td>-0.121033</td>\n",
       "      <td>0.199727</td>\n",
       "      <td>-0.782018</td>\n",
       "      <td>-0.003939</td>\n",
       "      <td>-0.664979</td>\n",
       "      <td>-0.150894</td>\n",
       "      <td>-0.634808</td>\n",
       "      <td>0.222222</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>74997</th>\n",
       "      <td>42972</td>\n",
       "      <td>0.102736</td>\n",
       "      <td>0.135983</td>\n",
       "      <td>0.550969</td>\n",
       "      <td>-0.014671</td>\n",
       "      <td>0.015193</td>\n",
       "      <td>-0.269029</td>\n",
       "      <td>0.679146</td>\n",
       "      <td>0.145063</td>\n",
       "      <td>-0.059002</td>\n",
       "      <td>...</td>\n",
       "      <td>0.252791</td>\n",
       "      <td>0.156139</td>\n",
       "      <td>-0.121033</td>\n",
       "      <td>0.199727</td>\n",
       "      <td>-0.782018</td>\n",
       "      <td>-0.003939</td>\n",
       "      <td>-0.664979</td>\n",
       "      <td>-0.150894</td>\n",
       "      <td>-0.634808</td>\n",
       "      <td>0.222222</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>74998</th>\n",
       "      <td>42976</td>\n",
       "      <td>-0.037242</td>\n",
       "      <td>0.322543</td>\n",
       "      <td>0.624075</td>\n",
       "      <td>0.044270</td>\n",
       "      <td>0.237306</td>\n",
       "      <td>-0.169295</td>\n",
       "      <td>0.391078</td>\n",
       "      <td>0.432858</td>\n",
       "      <td>0.122539</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.018295</td>\n",
       "      <td>0.240078</td>\n",
       "      <td>-0.080892</td>\n",
       "      <td>0.143712</td>\n",
       "      <td>-0.649160</td>\n",
       "      <td>-0.177820</td>\n",
       "      <td>-0.591682</td>\n",
       "      <td>-0.031716</td>\n",
       "      <td>-0.482195</td>\n",
       "      <td>0.222222</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>74999</th>\n",
       "      <td>42976</td>\n",
       "      <td>-0.037242</td>\n",
       "      <td>0.322543</td>\n",
       "      <td>0.624075</td>\n",
       "      <td>0.044270</td>\n",
       "      <td>0.237306</td>\n",
       "      <td>-0.169295</td>\n",
       "      <td>0.391078</td>\n",
       "      <td>0.432858</td>\n",
       "      <td>0.122539</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.018295</td>\n",
       "      <td>0.240078</td>\n",
       "      <td>-0.080892</td>\n",
       "      <td>0.143712</td>\n",
       "      <td>-0.649160</td>\n",
       "      <td>-0.177820</td>\n",
       "      <td>-0.591682</td>\n",
       "      <td>-0.031716</td>\n",
       "      <td>-0.482195</td>\n",
       "      <td>0.222222</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>75000 rows × 770 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       index  feature_0  feature_1  feature_2  feature_3  feature_4  \\\n",
       "0          0   0.144370   0.133683   0.558613   0.002472   0.064213   \n",
       "1          0   0.144370   0.133683   0.558613   0.002472   0.064213   \n",
       "2          0   0.144370   0.133683   0.558613   0.002472   0.064213   \n",
       "3          2   0.127047   0.111979   0.549845   0.036660   0.026879   \n",
       "4          2   0.127047   0.111979   0.549845   0.036660   0.026879   \n",
       "...      ...        ...        ...        ...        ...        ...   \n",
       "74995  42969   0.212347   0.124677   0.604793   0.083085   0.034133   \n",
       "74996  42972   0.102736   0.135983   0.550969  -0.014671   0.015193   \n",
       "74997  42972   0.102736   0.135983   0.550969  -0.014671   0.015193   \n",
       "74998  42976  -0.037242   0.322543   0.624075   0.044270   0.237306   \n",
       "74999  42976  -0.037242   0.322543   0.624075   0.044270   0.237306   \n",
       "\n",
       "       feature_5  feature_6  feature_7  feature_8  ...  feature_759  \\\n",
       "0      -0.297644   0.649253   0.156834  -0.075428  ...     0.171215   \n",
       "1      -0.297644   0.649253   0.156834  -0.075428  ...     0.171215   \n",
       "2      -0.297644   0.649253   0.156834  -0.075428  ...     0.171215   \n",
       "3      -0.309649   0.654963   0.205110  -0.097057  ...     0.146141   \n",
       "4      -0.309649   0.654963   0.205110  -0.097057  ...     0.146141   \n",
       "...          ...        ...        ...        ...  ...          ...   \n",
       "74995  -0.408407   0.786280   0.111345  -0.127262  ...     0.161177   \n",
       "74996  -0.269029   0.679146   0.145063  -0.059002  ...     0.252791   \n",
       "74997  -0.269029   0.679146   0.145063  -0.059002  ...     0.252791   \n",
       "74998  -0.169295   0.391078   0.432858   0.122539  ...    -0.018295   \n",
       "74999  -0.169295   0.391078   0.432858   0.122539  ...    -0.018295   \n",
       "\n",
       "       feature_760  feature_761  feature_762  feature_763  feature_764  \\\n",
       "0         0.197233    -0.131170     0.210236    -0.728103     0.027258   \n",
       "1         0.197233    -0.131170     0.210236    -0.728103     0.027258   \n",
       "2         0.197233    -0.131170     0.210236    -0.728103     0.027258   \n",
       "3         0.174652    -0.146565     0.217158    -0.712819     0.046792   \n",
       "4         0.174652    -0.146565     0.217158    -0.712819     0.046792   \n",
       "...            ...          ...          ...          ...          ...   \n",
       "74995     0.153434    -0.125303     0.314786    -0.765685     0.128396   \n",
       "74996     0.156139    -0.121033     0.199727    -0.782018    -0.003939   \n",
       "74997     0.156139    -0.121033     0.199727    -0.782018    -0.003939   \n",
       "74998     0.240078    -0.080892     0.143712    -0.649160    -0.177820   \n",
       "74999     0.240078    -0.080892     0.143712    -0.649160    -0.177820   \n",
       "\n",
       "       feature_765  feature_766  feature_767  X..Guaiol  \n",
       "0        -0.683708    -0.160281    -0.718498   0.444444  \n",
       "1        -0.683708    -0.160281    -0.718498   0.444444  \n",
       "2        -0.683708    -0.160281    -0.718498   0.444444  \n",
       "3        -0.744437    -0.214183    -0.707376   0.444444  \n",
       "4        -0.744437    -0.214183    -0.707376   0.444444  \n",
       "...            ...          ...          ...        ...  \n",
       "74995    -0.816410    -0.213200    -0.849931   0.222222  \n",
       "74996    -0.664979    -0.150894    -0.634808   0.222222  \n",
       "74997    -0.664979    -0.150894    -0.634808   0.222222  \n",
       "74998    -0.591682    -0.031716    -0.482195   0.222222  \n",
       "74999    -0.591682    -0.031716    -0.482195   0.222222  \n",
       "\n",
       "[75000 rows x 770 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_bert"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['index',\n",
       " 'feature_0',\n",
       " 'feature_1',\n",
       " 'feature_2',\n",
       " 'feature_3',\n",
       " 'feature_4',\n",
       " 'feature_5',\n",
       " 'feature_6',\n",
       " 'feature_7',\n",
       " 'feature_8',\n",
       " 'feature_9',\n",
       " 'feature_10',\n",
       " 'feature_11',\n",
       " 'feature_12',\n",
       " 'feature_13',\n",
       " 'feature_14',\n",
       " 'feature_15',\n",
       " 'feature_16',\n",
       " 'feature_17',\n",
       " 'feature_18',\n",
       " 'feature_19',\n",
       " 'feature_20',\n",
       " 'feature_21',\n",
       " 'feature_22',\n",
       " 'feature_23',\n",
       " 'feature_24',\n",
       " 'feature_25',\n",
       " 'feature_26',\n",
       " 'feature_27',\n",
       " 'feature_28',\n",
       " 'feature_29',\n",
       " 'feature_30',\n",
       " 'feature_31',\n",
       " 'feature_32',\n",
       " 'feature_33',\n",
       " 'feature_34',\n",
       " 'feature_35',\n",
       " 'feature_36',\n",
       " 'feature_37',\n",
       " 'feature_38',\n",
       " 'feature_39',\n",
       " 'feature_40',\n",
       " 'feature_41',\n",
       " 'feature_42',\n",
       " 'feature_43',\n",
       " 'feature_44',\n",
       " 'feature_45',\n",
       " 'feature_46',\n",
       " 'feature_47',\n",
       " 'feature_48',\n",
       " 'feature_49',\n",
       " 'feature_50',\n",
       " 'feature_51',\n",
       " 'feature_52',\n",
       " 'feature_53',\n",
       " 'feature_54',\n",
       " 'feature_55',\n",
       " 'feature_56',\n",
       " 'feature_57',\n",
       " 'feature_58',\n",
       " 'feature_59',\n",
       " 'feature_60',\n",
       " 'feature_61',\n",
       " 'feature_62',\n",
       " 'feature_63',\n",
       " 'feature_64',\n",
       " 'feature_65',\n",
       " 'feature_66',\n",
       " 'feature_67',\n",
       " 'feature_68',\n",
       " 'feature_69',\n",
       " 'feature_70',\n",
       " 'feature_71',\n",
       " 'feature_72',\n",
       " 'feature_73',\n",
       " 'feature_74',\n",
       " 'feature_75',\n",
       " 'feature_76',\n",
       " 'feature_77',\n",
       " 'feature_78',\n",
       " 'feature_79',\n",
       " 'feature_80',\n",
       " 'feature_81',\n",
       " 'feature_82',\n",
       " 'feature_83',\n",
       " 'feature_84',\n",
       " 'feature_85',\n",
       " 'feature_86',\n",
       " 'feature_87',\n",
       " 'feature_88',\n",
       " 'feature_89',\n",
       " 'feature_90',\n",
       " 'feature_91',\n",
       " 'feature_92',\n",
       " 'feature_93',\n",
       " 'feature_94',\n",
       " 'feature_95',\n",
       " 'feature_96',\n",
       " 'feature_97',\n",
       " 'feature_98',\n",
       " 'feature_99',\n",
       " 'feature_100',\n",
       " 'feature_101',\n",
       " 'feature_102',\n",
       " 'feature_103',\n",
       " 'feature_104',\n",
       " 'feature_105',\n",
       " 'feature_106',\n",
       " 'feature_107',\n",
       " 'feature_108',\n",
       " 'feature_109',\n",
       " 'feature_110',\n",
       " 'feature_111',\n",
       " 'feature_112',\n",
       " 'feature_113',\n",
       " 'feature_114',\n",
       " 'feature_115',\n",
       " 'feature_116',\n",
       " 'feature_117',\n",
       " 'feature_118',\n",
       " 'feature_119',\n",
       " 'feature_120',\n",
       " 'feature_121',\n",
       " 'feature_122',\n",
       " 'feature_123',\n",
       " 'feature_124',\n",
       " 'feature_125',\n",
       " 'feature_126',\n",
       " 'feature_127',\n",
       " 'feature_128',\n",
       " 'feature_129',\n",
       " 'feature_130',\n",
       " 'feature_131',\n",
       " 'feature_132',\n",
       " 'feature_133',\n",
       " 'feature_134',\n",
       " 'feature_135',\n",
       " 'feature_136',\n",
       " 'feature_137',\n",
       " 'feature_138',\n",
       " 'feature_139',\n",
       " 'feature_140',\n",
       " 'feature_141',\n",
       " 'feature_142',\n",
       " 'feature_143',\n",
       " 'feature_144',\n",
       " 'feature_145',\n",
       " 'feature_146',\n",
       " 'feature_147',\n",
       " 'feature_148',\n",
       " 'feature_149',\n",
       " 'feature_150',\n",
       " 'feature_151',\n",
       " 'feature_152',\n",
       " 'feature_153',\n",
       " 'feature_154',\n",
       " 'feature_155',\n",
       " 'feature_156',\n",
       " 'feature_157',\n",
       " 'feature_158',\n",
       " 'feature_159',\n",
       " 'feature_160',\n",
       " 'feature_161',\n",
       " 'feature_162',\n",
       " 'feature_163',\n",
       " 'feature_164',\n",
       " 'feature_165',\n",
       " 'feature_166',\n",
       " 'feature_167',\n",
       " 'feature_168',\n",
       " 'feature_169',\n",
       " 'feature_170',\n",
       " 'feature_171',\n",
       " 'feature_172',\n",
       " 'feature_173',\n",
       " 'feature_174',\n",
       " 'feature_175',\n",
       " 'feature_176',\n",
       " 'feature_177',\n",
       " 'feature_178',\n",
       " 'feature_179',\n",
       " 'feature_180',\n",
       " 'feature_181',\n",
       " 'feature_182',\n",
       " 'feature_183',\n",
       " 'feature_184',\n",
       " 'feature_185',\n",
       " 'feature_186',\n",
       " 'feature_187',\n",
       " 'feature_188',\n",
       " 'feature_189',\n",
       " 'feature_190',\n",
       " 'feature_191',\n",
       " 'feature_192',\n",
       " 'feature_193',\n",
       " 'feature_194',\n",
       " 'feature_195',\n",
       " 'feature_196',\n",
       " 'feature_197',\n",
       " 'feature_198',\n",
       " 'feature_199',\n",
       " 'feature_200',\n",
       " 'feature_201',\n",
       " 'feature_202',\n",
       " 'feature_203',\n",
       " 'feature_204',\n",
       " 'feature_205',\n",
       " 'feature_206',\n",
       " 'feature_207',\n",
       " 'feature_208',\n",
       " 'feature_209',\n",
       " 'feature_210',\n",
       " 'feature_211',\n",
       " 'feature_212',\n",
       " 'feature_213',\n",
       " 'feature_214',\n",
       " 'feature_215',\n",
       " 'feature_216',\n",
       " 'feature_217',\n",
       " 'feature_218',\n",
       " 'feature_219',\n",
       " 'feature_220',\n",
       " 'feature_221',\n",
       " 'feature_222',\n",
       " 'feature_223',\n",
       " 'feature_224',\n",
       " 'feature_225',\n",
       " 'feature_226',\n",
       " 'feature_227',\n",
       " 'feature_228',\n",
       " 'feature_229',\n",
       " 'feature_230',\n",
       " 'feature_231',\n",
       " 'feature_232',\n",
       " 'feature_233',\n",
       " 'feature_234',\n",
       " 'feature_235',\n",
       " 'feature_236',\n",
       " 'feature_237',\n",
       " 'feature_238',\n",
       " 'feature_239',\n",
       " 'feature_240',\n",
       " 'feature_241',\n",
       " 'feature_242',\n",
       " 'feature_243',\n",
       " 'feature_244',\n",
       " 'feature_245',\n",
       " 'feature_246',\n",
       " 'feature_247',\n",
       " 'feature_248',\n",
       " 'feature_249',\n",
       " 'feature_250',\n",
       " 'feature_251',\n",
       " 'feature_252',\n",
       " 'feature_253',\n",
       " 'feature_254',\n",
       " 'feature_255',\n",
       " 'feature_256',\n",
       " 'feature_257',\n",
       " 'feature_258',\n",
       " 'feature_259',\n",
       " 'feature_260',\n",
       " 'feature_261',\n",
       " 'feature_262',\n",
       " 'feature_263',\n",
       " 'feature_264',\n",
       " 'feature_265',\n",
       " 'feature_266',\n",
       " 'feature_267',\n",
       " 'feature_268',\n",
       " 'feature_269',\n",
       " 'feature_270',\n",
       " 'feature_271',\n",
       " 'feature_272',\n",
       " 'feature_273',\n",
       " 'feature_274',\n",
       " 'feature_275',\n",
       " 'feature_276',\n",
       " 'feature_277',\n",
       " 'feature_278',\n",
       " 'feature_279',\n",
       " 'feature_280',\n",
       " 'feature_281',\n",
       " 'feature_282',\n",
       " 'feature_283',\n",
       " 'feature_284',\n",
       " 'feature_285',\n",
       " 'feature_286',\n",
       " 'feature_287',\n",
       " 'feature_288',\n",
       " 'feature_289',\n",
       " 'feature_290',\n",
       " 'feature_291',\n",
       " 'feature_292',\n",
       " 'feature_293',\n",
       " 'feature_294',\n",
       " 'feature_295',\n",
       " 'feature_296',\n",
       " 'feature_297',\n",
       " 'feature_298',\n",
       " 'feature_299',\n",
       " 'feature_300',\n",
       " 'feature_301',\n",
       " 'feature_302',\n",
       " 'feature_303',\n",
       " 'feature_304',\n",
       " 'feature_305',\n",
       " 'feature_306',\n",
       " 'feature_307',\n",
       " 'feature_308',\n",
       " 'feature_309',\n",
       " 'feature_310',\n",
       " 'feature_311',\n",
       " 'feature_312',\n",
       " 'feature_313',\n",
       " 'feature_314',\n",
       " 'feature_315',\n",
       " 'feature_316',\n",
       " 'feature_317',\n",
       " 'feature_318',\n",
       " 'feature_319',\n",
       " 'feature_320',\n",
       " 'feature_321',\n",
       " 'feature_322',\n",
       " 'feature_323',\n",
       " 'feature_324',\n",
       " 'feature_325',\n",
       " 'feature_326',\n",
       " 'feature_327',\n",
       " 'feature_328',\n",
       " 'feature_329',\n",
       " 'feature_330',\n",
       " 'feature_331',\n",
       " 'feature_332',\n",
       " 'feature_333',\n",
       " 'feature_334',\n",
       " 'feature_335',\n",
       " 'feature_336',\n",
       " 'feature_337',\n",
       " 'feature_338',\n",
       " 'feature_339',\n",
       " 'feature_340',\n",
       " 'feature_341',\n",
       " 'feature_342',\n",
       " 'feature_343',\n",
       " 'feature_344',\n",
       " 'feature_345',\n",
       " 'feature_346',\n",
       " 'feature_347',\n",
       " 'feature_348',\n",
       " 'feature_349',\n",
       " 'feature_350',\n",
       " 'feature_351',\n",
       " 'feature_352',\n",
       " 'feature_353',\n",
       " 'feature_354',\n",
       " 'feature_355',\n",
       " 'feature_356',\n",
       " 'feature_357',\n",
       " 'feature_358',\n",
       " 'feature_359',\n",
       " 'feature_360',\n",
       " 'feature_361',\n",
       " 'feature_362',\n",
       " 'feature_363',\n",
       " 'feature_364',\n",
       " 'feature_365',\n",
       " 'feature_366',\n",
       " 'feature_367',\n",
       " 'feature_368',\n",
       " 'feature_369',\n",
       " 'feature_370',\n",
       " 'feature_371',\n",
       " 'feature_372',\n",
       " 'feature_373',\n",
       " 'feature_374',\n",
       " 'feature_375',\n",
       " 'feature_376',\n",
       " 'feature_377',\n",
       " 'feature_378',\n",
       " 'feature_379',\n",
       " 'feature_380',\n",
       " 'feature_381',\n",
       " 'feature_382',\n",
       " 'feature_383',\n",
       " 'feature_384',\n",
       " 'feature_385',\n",
       " 'feature_386',\n",
       " 'feature_387',\n",
       " 'feature_388',\n",
       " 'feature_389',\n",
       " 'feature_390',\n",
       " 'feature_391',\n",
       " 'feature_392',\n",
       " 'feature_393',\n",
       " 'feature_394',\n",
       " 'feature_395',\n",
       " 'feature_396',\n",
       " 'feature_397',\n",
       " 'feature_398',\n",
       " 'feature_399',\n",
       " 'feature_400',\n",
       " 'feature_401',\n",
       " 'feature_402',\n",
       " 'feature_403',\n",
       " 'feature_404',\n",
       " 'feature_405',\n",
       " 'feature_406',\n",
       " 'feature_407',\n",
       " 'feature_408',\n",
       " 'feature_409',\n",
       " 'feature_410',\n",
       " 'feature_411',\n",
       " 'feature_412',\n",
       " 'feature_413',\n",
       " 'feature_414',\n",
       " 'feature_415',\n",
       " 'feature_416',\n",
       " 'feature_417',\n",
       " 'feature_418',\n",
       " 'feature_419',\n",
       " 'feature_420',\n",
       " 'feature_421',\n",
       " 'feature_422',\n",
       " 'feature_423',\n",
       " 'feature_424',\n",
       " 'feature_425',\n",
       " 'feature_426',\n",
       " 'feature_427',\n",
       " 'feature_428',\n",
       " 'feature_429',\n",
       " 'feature_430',\n",
       " 'feature_431',\n",
       " 'feature_432',\n",
       " 'feature_433',\n",
       " 'feature_434',\n",
       " 'feature_435',\n",
       " 'feature_436',\n",
       " 'feature_437',\n",
       " 'feature_438',\n",
       " 'feature_439',\n",
       " 'feature_440',\n",
       " 'feature_441',\n",
       " 'feature_442',\n",
       " 'feature_443',\n",
       " 'feature_444',\n",
       " 'feature_445',\n",
       " 'feature_446',\n",
       " 'feature_447',\n",
       " 'feature_448',\n",
       " 'feature_449',\n",
       " 'feature_450',\n",
       " 'feature_451',\n",
       " 'feature_452',\n",
       " 'feature_453',\n",
       " 'feature_454',\n",
       " 'feature_455',\n",
       " 'feature_456',\n",
       " 'feature_457',\n",
       " 'feature_458',\n",
       " 'feature_459',\n",
       " 'feature_460',\n",
       " 'feature_461',\n",
       " 'feature_462',\n",
       " 'feature_463',\n",
       " 'feature_464',\n",
       " 'feature_465',\n",
       " 'feature_466',\n",
       " 'feature_467',\n",
       " 'feature_468',\n",
       " 'feature_469',\n",
       " 'feature_470',\n",
       " 'feature_471',\n",
       " 'feature_472',\n",
       " 'feature_473',\n",
       " 'feature_474',\n",
       " 'feature_475',\n",
       " 'feature_476',\n",
       " 'feature_477',\n",
       " 'feature_478',\n",
       " 'feature_479',\n",
       " 'feature_480',\n",
       " 'feature_481',\n",
       " 'feature_482',\n",
       " 'feature_483',\n",
       " 'feature_484',\n",
       " 'feature_485',\n",
       " 'feature_486',\n",
       " 'feature_487',\n",
       " 'feature_488',\n",
       " 'feature_489',\n",
       " 'feature_490',\n",
       " 'feature_491',\n",
       " 'feature_492',\n",
       " 'feature_493',\n",
       " 'feature_494',\n",
       " 'feature_495',\n",
       " 'feature_496',\n",
       " 'feature_497',\n",
       " 'feature_498',\n",
       " 'feature_499',\n",
       " 'feature_500',\n",
       " 'feature_501',\n",
       " 'feature_502',\n",
       " 'feature_503',\n",
       " 'feature_504',\n",
       " 'feature_505',\n",
       " 'feature_506',\n",
       " 'feature_507',\n",
       " 'feature_508',\n",
       " 'feature_509',\n",
       " 'feature_510',\n",
       " 'feature_511',\n",
       " 'feature_512',\n",
       " 'feature_513',\n",
       " 'feature_514',\n",
       " 'feature_515',\n",
       " 'feature_516',\n",
       " 'feature_517',\n",
       " 'feature_518',\n",
       " 'feature_519',\n",
       " 'feature_520',\n",
       " 'feature_521',\n",
       " 'feature_522',\n",
       " 'feature_523',\n",
       " 'feature_524',\n",
       " 'feature_525',\n",
       " 'feature_526',\n",
       " 'feature_527',\n",
       " 'feature_528',\n",
       " 'feature_529',\n",
       " 'feature_530',\n",
       " 'feature_531',\n",
       " 'feature_532',\n",
       " 'feature_533',\n",
       " 'feature_534',\n",
       " 'feature_535',\n",
       " 'feature_536',\n",
       " 'feature_537',\n",
       " 'feature_538',\n",
       " 'feature_539',\n",
       " 'feature_540',\n",
       " 'feature_541',\n",
       " 'feature_542',\n",
       " 'feature_543',\n",
       " 'feature_544',\n",
       " 'feature_545',\n",
       " 'feature_546',\n",
       " 'feature_547',\n",
       " 'feature_548',\n",
       " 'feature_549',\n",
       " 'feature_550',\n",
       " 'feature_551',\n",
       " 'feature_552',\n",
       " 'feature_553',\n",
       " 'feature_554',\n",
       " 'feature_555',\n",
       " 'feature_556',\n",
       " 'feature_557',\n",
       " 'feature_558',\n",
       " 'feature_559',\n",
       " 'feature_560',\n",
       " 'feature_561',\n",
       " 'feature_562',\n",
       " 'feature_563',\n",
       " 'feature_564',\n",
       " 'feature_565',\n",
       " 'feature_566',\n",
       " 'feature_567',\n",
       " 'feature_568',\n",
       " 'feature_569',\n",
       " 'feature_570',\n",
       " 'feature_571',\n",
       " 'feature_572',\n",
       " 'feature_573',\n",
       " 'feature_574',\n",
       " 'feature_575',\n",
       " 'feature_576',\n",
       " 'feature_577',\n",
       " 'feature_578',\n",
       " 'feature_579',\n",
       " 'feature_580',\n",
       " 'feature_581',\n",
       " 'feature_582',\n",
       " 'feature_583',\n",
       " 'feature_584',\n",
       " 'feature_585',\n",
       " 'feature_586',\n",
       " 'feature_587',\n",
       " 'feature_588',\n",
       " 'feature_589',\n",
       " 'feature_590',\n",
       " 'feature_591',\n",
       " 'feature_592',\n",
       " 'feature_593',\n",
       " 'feature_594',\n",
       " 'feature_595',\n",
       " 'feature_596',\n",
       " 'feature_597',\n",
       " 'feature_598',\n",
       " 'feature_599',\n",
       " 'feature_600',\n",
       " 'feature_601',\n",
       " 'feature_602',\n",
       " 'feature_603',\n",
       " 'feature_604',\n",
       " 'feature_605',\n",
       " 'feature_606',\n",
       " 'feature_607',\n",
       " 'feature_608',\n",
       " 'feature_609',\n",
       " 'feature_610',\n",
       " 'feature_611',\n",
       " 'feature_612',\n",
       " 'feature_613',\n",
       " 'feature_614',\n",
       " 'feature_615',\n",
       " 'feature_616',\n",
       " 'feature_617',\n",
       " 'feature_618',\n",
       " 'feature_619',\n",
       " 'feature_620',\n",
       " 'feature_621',\n",
       " 'feature_622',\n",
       " 'feature_623',\n",
       " 'feature_624',\n",
       " 'feature_625',\n",
       " 'feature_626',\n",
       " 'feature_627',\n",
       " 'feature_628',\n",
       " 'feature_629',\n",
       " 'feature_630',\n",
       " 'feature_631',\n",
       " 'feature_632',\n",
       " 'feature_633',\n",
       " 'feature_634',\n",
       " 'feature_635',\n",
       " 'feature_636',\n",
       " 'feature_637',\n",
       " 'feature_638',\n",
       " 'feature_639',\n",
       " 'feature_640',\n",
       " 'feature_641',\n",
       " 'feature_642',\n",
       " 'feature_643',\n",
       " 'feature_644',\n",
       " 'feature_645',\n",
       " 'feature_646',\n",
       " 'feature_647',\n",
       " 'feature_648',\n",
       " 'feature_649',\n",
       " 'feature_650',\n",
       " 'feature_651',\n",
       " 'feature_652',\n",
       " 'feature_653',\n",
       " 'feature_654',\n",
       " 'feature_655',\n",
       " 'feature_656',\n",
       " 'feature_657',\n",
       " 'feature_658',\n",
       " 'feature_659',\n",
       " 'feature_660',\n",
       " 'feature_661',\n",
       " 'feature_662',\n",
       " 'feature_663',\n",
       " 'feature_664',\n",
       " 'feature_665',\n",
       " 'feature_666',\n",
       " 'feature_667',\n",
       " 'feature_668',\n",
       " 'feature_669',\n",
       " 'feature_670',\n",
       " 'feature_671',\n",
       " 'feature_672',\n",
       " 'feature_673',\n",
       " 'feature_674',\n",
       " 'feature_675',\n",
       " 'feature_676',\n",
       " 'feature_677',\n",
       " 'feature_678',\n",
       " 'feature_679',\n",
       " 'feature_680',\n",
       " 'feature_681',\n",
       " 'feature_682',\n",
       " 'feature_683',\n",
       " 'feature_684',\n",
       " 'feature_685',\n",
       " 'feature_686',\n",
       " 'feature_687',\n",
       " 'feature_688',\n",
       " 'feature_689',\n",
       " 'feature_690',\n",
       " 'feature_691',\n",
       " 'feature_692',\n",
       " 'feature_693',\n",
       " 'feature_694',\n",
       " 'feature_695',\n",
       " 'feature_696',\n",
       " 'feature_697',\n",
       " 'feature_698',\n",
       " 'feature_699',\n",
       " 'feature_700',\n",
       " 'feature_701',\n",
       " 'feature_702',\n",
       " 'feature_703',\n",
       " 'feature_704',\n",
       " 'feature_705',\n",
       " 'feature_706',\n",
       " 'feature_707',\n",
       " 'feature_708',\n",
       " 'feature_709',\n",
       " 'feature_710',\n",
       " 'feature_711',\n",
       " 'feature_712',\n",
       " 'feature_713',\n",
       " 'feature_714',\n",
       " 'feature_715',\n",
       " 'feature_716',\n",
       " 'feature_717',\n",
       " 'feature_718',\n",
       " 'feature_719',\n",
       " 'feature_720',\n",
       " 'feature_721',\n",
       " 'feature_722',\n",
       " 'feature_723',\n",
       " 'feature_724',\n",
       " 'feature_725',\n",
       " 'feature_726',\n",
       " 'feature_727',\n",
       " 'feature_728',\n",
       " 'feature_729',\n",
       " 'feature_730',\n",
       " 'feature_731',\n",
       " 'feature_732',\n",
       " 'feature_733',\n",
       " 'feature_734',\n",
       " 'feature_735',\n",
       " 'feature_736',\n",
       " 'feature_737',\n",
       " 'feature_738',\n",
       " 'feature_739',\n",
       " 'feature_740',\n",
       " 'feature_741',\n",
       " 'feature_742',\n",
       " 'feature_743',\n",
       " 'feature_744',\n",
       " 'feature_745',\n",
       " 'feature_746',\n",
       " 'feature_747',\n",
       " 'feature_748',\n",
       " 'feature_749',\n",
       " 'feature_750',\n",
       " 'feature_751',\n",
       " 'feature_752',\n",
       " 'feature_753',\n",
       " 'feature_754',\n",
       " 'feature_755',\n",
       " 'feature_756',\n",
       " 'feature_757',\n",
       " 'feature_758',\n",
       " 'feature_759',\n",
       " 'feature_760',\n",
       " 'feature_761',\n",
       " 'feature_762',\n",
       " 'feature_763',\n",
       " 'feature_764',\n",
       " 'feature_765',\n",
       " 'feature_766',\n",
       " 'feature_767',\n",
       " 'X..Guaiol']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_bert.columns.to_list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df_bert.drop(['X..Guaiol', 'index'], axis = 1)\n",
    "y = df_bert[['X..Guaiol']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:ylabel='Count'>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "sns.histplot(y, bins = 10)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "pca = PCA()\n",
    "pca_comps = pca.fit_transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 1.83214084e+00, -5.37342907e-01, -2.73903196e-01, ...,\n",
       "        -2.04321328e-03,  3.95855167e-03, -2.25949263e-08],\n",
       "       [ 1.83214084e+00, -5.37342907e-01, -2.73903196e-01, ...,\n",
       "        -2.04321328e-03,  3.95855167e-03, -2.25949228e-08],\n",
       "       [ 1.83214084e+00, -5.37342907e-01, -2.73903196e-01, ...,\n",
       "        -2.04321328e-03,  3.95855167e-03, -2.25949199e-08],\n",
       "       ...,\n",
       "       [ 1.67824983e+00, -5.26314014e-01, -4.90465900e-01, ...,\n",
       "         3.63254616e-03,  2.10117917e-03,  2.14349431e-08],\n",
       "       [ 6.10551399e+00,  9.77647348e-01,  6.96130010e-01, ...,\n",
       "        -1.21399917e-03,  5.33410160e-03,  1.72193664e-08],\n",
       "       [ 6.10551399e+00,  9.77647348e-01,  6.96130010e-01, ...,\n",
       "        -1.21399917e-03,  5.33410160e-03,  1.72193664e-08]])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pca_comps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "numpy.ndarray"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(pca_comps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "explained_variance = pca.explained_variance_ratio_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(range(1, len(explained_variance)+1), explained_variance, 'bo-', linewidth=2)\n",
    "plt.xlabel('Number of components')\n",
    "plt.ylabel('Explained variance ratio')\n",
    "plt.title('Scree Plot')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the second derivative of the explained variance ratio curve\n",
    "second_der = np.diff(explained_variance, 2)\n",
    "\n",
    "# Find the index of the maximum value of the second derivative\n",
    "elbow_index = np.argmax(second_der) + 1\n",
    "\n",
    "# The optimal number of components is the index of the elbow point\n",
    "n_components_optimal = elbow_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n_components_optimal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_reduced = pca.transform(X)[:, :n_components_optimal]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1.83214084],\n",
       "       [1.83214084],\n",
       "       [1.83214084],\n",
       "       ...,\n",
       "       [1.67824983],\n",
       "       [6.10551399],\n",
       "       [6.10551399]])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_reduced"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pca_0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.832141</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.832141</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.832141</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.264775</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.264775</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>74995</th>\n",
       "      <td>-1.180021</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>74996</th>\n",
       "      <td>1.678250</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>74997</th>\n",
       "      <td>1.678250</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>74998</th>\n",
       "      <td>6.105514</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>74999</th>\n",
       "      <td>6.105514</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>75000 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          pca_0\n",
       "0      1.832141\n",
       "1      1.832141\n",
       "2      1.832141\n",
       "3      1.264775\n",
       "4      1.264775\n",
       "...         ...\n",
       "74995 -1.180021\n",
       "74996  1.678250\n",
       "74997  1.678250\n",
       "74998  6.105514\n",
       "74999  6.105514\n",
       "\n",
       "[75000 rows x 1 columns]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_reduced = pd.DataFrame(X_reduced)\n",
    "X_reduced = X_reduced.add_prefix('pca_')\n",
    "X_reduced"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "train test split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X_reduced, y, random_state=1, test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train1, X_val, y_train1, y_val = train_test_split(X_train, y_train, random_state=1, test_size=0.2)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "kNN (before feature selection and hyperparameter tuning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "knreg = KNeighborsRegressor()\n",
    "knreg.fit(X_train1, y_train1)\n",
    "y_pred_knreg = knreg.predict(X_val)\n",
    "y_pred_knreg_r2 = knreg.predict(X_train1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0936188022317189"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mean_absolute_error(y_val, y_pred_knreg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.030768674196612826"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mean_squared_error(y_val, y_pred_knreg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.17541001737817832"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mean_squared_error(y_val, y_pred_knreg, squared = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8764641875292452"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#train\n",
    "r2_score(y_train1, y_pred_knreg_r2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7811747440408932"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#val\n",
    "r2_score(y_val, y_pred_knreg)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "RF (before feature selection and hyperparameter tuning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/y1/pjvjlkjn5gl846rnyzr53p340000gn/T/ipykernel_5822/2685114911.py:2: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  rfreg.fit(X_train1, y_train1)\n"
     ]
    }
   ],
   "source": [
    "rfreg = RandomForestRegressor()\n",
    "rfreg.fit(X_train1, y_train1)\n",
    "y_pred_rfreg = rfreg.predict(X_val)\n",
    "y_pred_rfreg_r2 = rfreg.predict(X_train1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.059284160829372684"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mean_absolute_error(y_val, y_pred_rfreg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.01872960190670804"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mean_squared_error(y_val, y_pred_rfreg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.13685613580219208"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mean_squared_error(y_val, y_pred_rfreg, squared = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9823218159904383"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#train\n",
    "r2_score(y_train1, y_pred_rfreg_r2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.866796017759558"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#val\n",
    "r2_score(y_val, y_pred_rfreg)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hyperparameter tuning (kNN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "parameters_knn = {'n_neighbors' : [5, 7, 9, 11, 13, 15], \n",
    "              'weights': ['uniform', 'distance']}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "rscv_knn = RandomizedSearchCV(knreg,  \n",
    "                     parameters_knn,   \n",
    "                     cv=5, \n",
    "                     scoring='neg_mean_absolute_error')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;background-color: white;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>RandomizedSearchCV(cv=5, estimator=KNeighborsRegressor(),\n",
       "                   param_distributions={&#x27;n_neighbors&#x27;: [5, 7, 9, 11, 13, 15],\n",
       "                                        &#x27;weights&#x27;: [&#x27;uniform&#x27;, &#x27;distance&#x27;]},\n",
       "                   scoring=&#x27;neg_mean_absolute_error&#x27;)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" ><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">RandomizedSearchCV</label><div class=\"sk-toggleable__content\"><pre>RandomizedSearchCV(cv=5, estimator=KNeighborsRegressor(),\n",
       "                   param_distributions={&#x27;n_neighbors&#x27;: [5, 7, 9, 11, 13, 15],\n",
       "                                        &#x27;weights&#x27;: [&#x27;uniform&#x27;, &#x27;distance&#x27;]},\n",
       "                   scoring=&#x27;neg_mean_absolute_error&#x27;)</pre></div></div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" ><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">estimator: KNeighborsRegressor</label><div class=\"sk-toggleable__content\"><pre>KNeighborsRegressor()</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-3\" type=\"checkbox\" ><label for=\"sk-estimator-id-3\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">KNeighborsRegressor</label><div class=\"sk-toggleable__content\"><pre>KNeighborsRegressor()</pre></div></div></div></div></div></div></div></div></div></div>"
      ],
      "text/plain": [
       "RandomizedSearchCV(cv=5, estimator=KNeighborsRegressor(),\n",
       "                   param_distributions={'n_neighbors': [5, 7, 9, 11, 13, 15],\n",
       "                                        'weights': ['uniform', 'distance']},\n",
       "                   scoring='neg_mean_absolute_error')"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rscv_knn.fit(X_train1, y_train1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'weights': 'distance', 'n_neighbors': 5}"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rscv_knn.best_params_"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "kNN (after hyperparameter tuning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "knreg_ht = KNeighborsRegressor(n_neighbors=5, weights='distance')\n",
    "knreg_ht.fit(X_train1, y_train1)\n",
    "y_pred_knreg_ht = knreg_ht.predict(X_val)\n",
    "y_pred_knreg_ht_r2 = knreg_ht.predict(X_train1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.04429090312307037"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mean_absolute_error(y_val, y_pred_knreg_ht)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.017522714187260577"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mean_squared_error(y_val, y_pred_knreg_ht)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.1323733892716379"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mean_squared_error(y_val, y_pred_knreg_ht, squared = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.999601685743317"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#train\n",
    "r2_score(y_train1, y_pred_knreg_ht_r2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8753793422289323"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#val\n",
    "r2_score(y_val, y_pred_knreg_ht)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hyperparameter tuning (RF)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "parameters_rf = {'max_depth': [None, 10, 50, 100],\n",
    "              'max_features': ['auto', 'sqrt'],\n",
    "              'min_samples_leaf': [1, 2, 4],\n",
    "              'min_samples_split': [2, 5, 10],\n",
    "              'n_estimators': [100, 300, 500]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "rscv_rf = RandomizedSearchCV(rfreg,  \n",
    "                     parameters_rf,   \n",
    "                     cv=5, \n",
    "                     scoring='neg_mean_absolute_error',\n",
    "                     n_jobs = -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/andalanputra/opt/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/Users/andalanputra/opt/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/Users/andalanputra/opt/anaconda3/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
      "  warn(\n",
      "/Users/andalanputra/opt/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/Users/andalanputra/opt/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/Users/andalanputra/opt/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/Users/andalanputra/opt/anaconda3/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
      "  warn(\n",
      "/Users/andalanputra/opt/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/Users/andalanputra/opt/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/Users/andalanputra/opt/anaconda3/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
      "  warn(\n",
      "/Users/andalanputra/opt/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/Users/andalanputra/opt/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/Users/andalanputra/opt/anaconda3/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
      "  warn(\n",
      "/Users/andalanputra/opt/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/Users/andalanputra/opt/anaconda3/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
      "  warn(\n",
      "/Users/andalanputra/opt/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/Users/andalanputra/opt/anaconda3/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
      "  warn(\n",
      "/Users/andalanputra/opt/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/Users/andalanputra/opt/anaconda3/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
      "  warn(\n",
      "/Users/andalanputra/opt/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/Users/andalanputra/opt/anaconda3/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
      "  warn(\n",
      "/Users/andalanputra/opt/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/Users/andalanputra/opt/anaconda3/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
      "  warn(\n",
      "/Users/andalanputra/opt/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/Users/andalanputra/opt/anaconda3/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
      "  warn(\n",
      "/Users/andalanputra/opt/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/Users/andalanputra/opt/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/Users/andalanputra/opt/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/Users/andalanputra/opt/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/Users/andalanputra/opt/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/Users/andalanputra/opt/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/Users/andalanputra/opt/anaconda3/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
      "  warn(\n",
      "/Users/andalanputra/opt/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/Users/andalanputra/opt/anaconda3/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
      "  warn(\n",
      "/Users/andalanputra/opt/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/Users/andalanputra/opt/anaconda3/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
      "  warn(\n",
      "/Users/andalanputra/opt/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/Users/andalanputra/opt/anaconda3/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
      "  warn(\n",
      "/Users/andalanputra/opt/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/Users/andalanputra/opt/anaconda3/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
      "  warn(\n",
      "/Users/andalanputra/opt/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/Users/andalanputra/opt/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/Users/andalanputra/opt/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/Users/andalanputra/opt/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/Users/andalanputra/opt/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/Users/andalanputra/opt/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/Users/andalanputra/opt/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/Users/andalanputra/opt/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/Users/andalanputra/opt/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/Users/andalanputra/opt/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/Users/andalanputra/opt/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/Users/andalanputra/opt/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/Users/andalanputra/opt/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/Users/andalanputra/opt/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/Users/andalanputra/opt/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/Users/andalanputra/opt/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/Users/andalanputra/opt/anaconda3/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
      "  warn(\n",
      "/Users/andalanputra/opt/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/Users/andalanputra/opt/anaconda3/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
      "  warn(\n",
      "/Users/andalanputra/opt/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/Users/andalanputra/opt/anaconda3/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
      "  warn(\n",
      "/Users/andalanputra/opt/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/Users/andalanputra/opt/anaconda3/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
      "  warn(\n",
      "/Users/andalanputra/opt/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/Users/andalanputra/opt/anaconda3/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
      "  warn(\n",
      "/Users/andalanputra/opt/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/Users/andalanputra/opt/anaconda3/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
      "  warn(\n",
      "/Users/andalanputra/opt/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/Users/andalanputra/opt/anaconda3/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
      "  warn(\n",
      "/Users/andalanputra/opt/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/Users/andalanputra/opt/anaconda3/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
      "  warn(\n",
      "/Users/andalanputra/opt/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/Users/andalanputra/opt/anaconda3/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
      "  warn(\n",
      "/Users/andalanputra/opt/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/Users/andalanputra/opt/anaconda3/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
      "  warn(\n",
      "/Users/andalanputra/opt/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_search.py:909: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  self.best_estimator_.fit(X, y, **fit_params)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-2 {color: black;background-color: white;}#sk-container-id-2 pre{padding: 0;}#sk-container-id-2 div.sk-toggleable {background-color: white;}#sk-container-id-2 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-2 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-2 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-2 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-2 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-2 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-2 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-2 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-2 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-2 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-2 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-2 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-2 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-2 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-2 div.sk-item {position: relative;z-index: 1;}#sk-container-id-2 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-2 div.sk-item::before, #sk-container-id-2 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-2 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-2 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-2 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-2 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-2 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-2 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-2 div.sk-label-container {text-align: center;}#sk-container-id-2 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-2 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-2\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>RandomizedSearchCV(cv=5, estimator=RandomForestRegressor(), n_jobs=-1,\n",
       "                   param_distributions={&#x27;max_depth&#x27;: [None, 10, 50, 100],\n",
       "                                        &#x27;max_features&#x27;: [&#x27;auto&#x27;, &#x27;sqrt&#x27;],\n",
       "                                        &#x27;min_samples_leaf&#x27;: [1, 2, 4],\n",
       "                                        &#x27;min_samples_split&#x27;: [2, 5, 10],\n",
       "                                        &#x27;n_estimators&#x27;: [100, 300, 500]},\n",
       "                   scoring=&#x27;neg_mean_absolute_error&#x27;)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-4\" type=\"checkbox\" ><label for=\"sk-estimator-id-4\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">RandomizedSearchCV</label><div class=\"sk-toggleable__content\"><pre>RandomizedSearchCV(cv=5, estimator=RandomForestRegressor(), n_jobs=-1,\n",
       "                   param_distributions={&#x27;max_depth&#x27;: [None, 10, 50, 100],\n",
       "                                        &#x27;max_features&#x27;: [&#x27;auto&#x27;, &#x27;sqrt&#x27;],\n",
       "                                        &#x27;min_samples_leaf&#x27;: [1, 2, 4],\n",
       "                                        &#x27;min_samples_split&#x27;: [2, 5, 10],\n",
       "                                        &#x27;n_estimators&#x27;: [100, 300, 500]},\n",
       "                   scoring=&#x27;neg_mean_absolute_error&#x27;)</pre></div></div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-5\" type=\"checkbox\" ><label for=\"sk-estimator-id-5\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">estimator: RandomForestRegressor</label><div class=\"sk-toggleable__content\"><pre>RandomForestRegressor()</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-6\" type=\"checkbox\" ><label for=\"sk-estimator-id-6\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">RandomForestRegressor</label><div class=\"sk-toggleable__content\"><pre>RandomForestRegressor()</pre></div></div></div></div></div></div></div></div></div></div>"
      ],
      "text/plain": [
       "RandomizedSearchCV(cv=5, estimator=RandomForestRegressor(), n_jobs=-1,\n",
       "                   param_distributions={'max_depth': [None, 10, 50, 100],\n",
       "                                        'max_features': ['auto', 'sqrt'],\n",
       "                                        'min_samples_leaf': [1, 2, 4],\n",
       "                                        'min_samples_split': [2, 5, 10],\n",
       "                                        'n_estimators': [100, 300, 500]},\n",
       "                   scoring='neg_mean_absolute_error')"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rscv_rf.fit(X_train1, y_train1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'n_estimators': 300,\n",
       " 'min_samples_split': 2,\n",
       " 'min_samples_leaf': 1,\n",
       " 'max_features': 'sqrt',\n",
       " 'max_depth': 100}"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rscv_rf.best_params_"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "RF (after hyperparameter tuning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/y1/pjvjlkjn5gl846rnyzr53p340000gn/T/ipykernel_5822/909679340.py:2: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  rfreg_ht.fit(X_train1, y_train1)\n"
     ]
    }
   ],
   "source": [
    "rfreg_ht = RandomForestRegressor(n_estimators=300, min_samples_leaf=1, min_samples_split=2, max_features='sqrt', max_depth=100)\n",
    "rfreg_ht.fit(X_train1, y_train1)\n",
    "y_pred_rfreg_ht = rfreg_ht.predict(X_val)\n",
    "y_pred_rfreg_ht_r2 = rfreg_ht.predict(X_train1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.05925964865295823"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mean_absolute_error(y_val, y_pred_rfreg_ht)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.018700207243162438"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mean_squared_error(y_val, y_pred_rfreg_ht)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.13674870106572287"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mean_squared_error(y_val, y_pred_rfreg_ht, squared = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9826835536095172"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#train\n",
    "r2_score(y_train1, y_pred_rfreg_ht_r2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8670050711212042"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#val\n",
    "r2_score(y_val, y_pred_rfreg_ht)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Predicting on the test set (kNN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_knreg_test = knreg_ht.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['y_test_knreg_bert_guai.pkl']"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import joblib\n",
    "\n",
    "joblib.dump(y_pred_knreg_test, \"y_pred_knreg_test_bert_guai.pkl\")\n",
    "joblib.dump(y_test, \"y_test_knreg_bert_guai.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.04437835250835561"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mean_absolute_error(y_test, y_pred_knreg_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0177696928528185"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mean_squared_error(y_test, y_pred_knreg_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.13330301141691622"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mean_squared_error(y_test, y_pred_knreg_test, squared = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8765477656098228"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "r2_score(y_test, y_pred_knreg_test)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Error analysis (kNN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 576x432 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 432x288 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# assume y_pred is a numpy array and y_true is a pandas dataframe\n",
    "fig, ax = plt.subplots(figsize=(8, 6))\n",
    "\n",
    "column = \"X..Guaiol\"  # specify the target variable name\n",
    "ax.hist(y_pred_knreg_test, alpha=0.5, label='y_pred', bins=20)\n",
    "ax.hist(y_test[column], alpha=0.5, label='y_true', bins=20)\n",
    "ax.legend(loc='upper right')\n",
    "ax.set_title(column)\n",
    "\n",
    "plt.show()\n",
    "plt.savefig('error_hist_knn_bert_guai.png')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pearson R (kNN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pearson correlation coefficient: 0.939\n",
      "P-value: 0.000\n"
     ]
    }
   ],
   "source": [
    "corr_coef, p_value = pearsonr(y_pred_knreg_test.flatten(), y_test.values.ravel())\n",
    "\n",
    "print(f\"Pearson correlation coefficient: {corr_coef:.3f}\")\n",
    "print(f\"P-value: {p_value:.3f}\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Predicting on the test set (RF)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_rfreg_test = rfreg_ht.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['y_test_rfreg_bert_guai.pkl']"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "joblib.dump(y_pred_rfreg_test, \"y_pred_rfreg_test_bert_guai.pkl\")\n",
    "joblib.dump(y_test, \"y_test_rfreg_bert_guai.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.05803279230753647"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mean_absolute_error(y_test, y_pred_rfreg_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.01810279035046759"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mean_squared_error(y_test, y_pred_rfreg_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.13454661032693313"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mean_squared_error(y_test, y_pred_rfreg_test, squared = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8742336214827884"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "r2_score(y_test, y_pred_rfreg_test)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Error analysis (RF)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 576x432 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 432x288 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# assume y_pred is a numpy array and y_true is a pandas dataframe\n",
    "fig, ax = plt.subplots(figsize=(8, 6))\n",
    "\n",
    "column = \"X..Guaiol\"  # specify the target variable name\n",
    "ax.hist(y_pred_rfreg_test, alpha=0.5, label='y_pred', bins=20)\n",
    "ax.hist(y_test[column], alpha=0.5, label='y_true', bins=20)\n",
    "ax.legend(loc='upper right')\n",
    "ax.set_title(column)\n",
    "\n",
    "plt.show()\n",
    "plt.savefig('error_hist_rf_bert_guai.png')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pearson R (RF)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pearson correlation coefficient: 0.937\n",
      "P-value: 0.000\n"
     ]
    }
   ],
   "source": [
    "corr_coef, p_value = pearsonr(y_pred_rfreg_test.flatten(), y_test.values.ravel())\n",
    "\n",
    "print(f\"Pearson correlation coefficient: {corr_coef:.3f}\")\n",
    "print(f\"P-value: {p_value:.3f}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
