{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn import preprocessing\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.neural_network import MLPRegressor\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "from sklearn.metrics import r2_score\n",
    "from scipy.stats import pearsonr\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.feature_selection import SelectFromModel\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compiling complete dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_rf = pd.read_csv(\"df_dlim_tfidf.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['index',\n",
       " 'tfidf_0',\n",
       " 'tfidf_1',\n",
       " 'tfidf_2',\n",
       " 'tfidf_3',\n",
       " 'tfidf_4',\n",
       " 'tfidf_5',\n",
       " 'tfidf_6',\n",
       " 'tfidf_7',\n",
       " 'tfidf_8',\n",
       " 'tfidf_9',\n",
       " 'tfidf_10',\n",
       " 'tfidf_11',\n",
       " 'tfidf_12',\n",
       " 'tfidf_13',\n",
       " 'tfidf_14',\n",
       " 'tfidf_15',\n",
       " 'tfidf_16',\n",
       " 'tfidf_17',\n",
       " 'tfidf_18',\n",
       " 'tfidf_19',\n",
       " 'tfidf_20',\n",
       " 'tfidf_21',\n",
       " 'tfidf_22',\n",
       " 'tfidf_23',\n",
       " 'tfidf_24',\n",
       " 'tfidf_25',\n",
       " 'tfidf_26',\n",
       " 'tfidf_27',\n",
       " 'tfidf_28',\n",
       " 'tfidf_29',\n",
       " 'tfidf_30',\n",
       " 'tfidf_31',\n",
       " 'tfidf_32',\n",
       " 'tfidf_33',\n",
       " 'tfidf_34',\n",
       " 'tfidf_35',\n",
       " 'tfidf_36',\n",
       " 'tfidf_37',\n",
       " 'tfidf_38',\n",
       " 'tfidf_39',\n",
       " 'tfidf_40',\n",
       " 'tfidf_41',\n",
       " 'tfidf_42',\n",
       " 'tfidf_43',\n",
       " 'tfidf_44',\n",
       " 'tfidf_45',\n",
       " 'tfidf_46',\n",
       " 'tfidf_47',\n",
       " 'tfidf_48',\n",
       " 'tfidf_49',\n",
       " 'tfidf_50',\n",
       " 'tfidf_51',\n",
       " 'tfidf_52',\n",
       " 'tfidf_53',\n",
       " 'tfidf_54',\n",
       " 'tfidf_55',\n",
       " 'tfidf_56',\n",
       " 'tfidf_57',\n",
       " 'tfidf_58',\n",
       " 'tfidf_59',\n",
       " 'tfidf_60',\n",
       " 'tfidf_61',\n",
       " 'tfidf_62',\n",
       " 'tfidf_63',\n",
       " 'tfidf_64',\n",
       " 'tfidf_65',\n",
       " 'tfidf_66',\n",
       " 'tfidf_67',\n",
       " 'tfidf_68',\n",
       " 'tfidf_69',\n",
       " 'tfidf_70',\n",
       " 'tfidf_71',\n",
       " 'tfidf_72',\n",
       " 'tfidf_73',\n",
       " 'tfidf_74',\n",
       " 'tfidf_75',\n",
       " 'tfidf_76',\n",
       " 'tfidf_77',\n",
       " 'tfidf_78',\n",
       " 'tfidf_79',\n",
       " 'tfidf_80',\n",
       " 'tfidf_81',\n",
       " 'tfidf_82',\n",
       " 'tfidf_83',\n",
       " 'tfidf_84',\n",
       " 'tfidf_85',\n",
       " 'tfidf_86',\n",
       " 'tfidf_87',\n",
       " 'tfidf_88',\n",
       " 'tfidf_89',\n",
       " 'tfidf_90',\n",
       " 'tfidf_91',\n",
       " 'tfidf_92',\n",
       " 'tfidf_93',\n",
       " 'tfidf_94',\n",
       " 'tfidf_95',\n",
       " 'tfidf_96',\n",
       " 'tfidf_97',\n",
       " 'tfidf_98',\n",
       " 'tfidf_99',\n",
       " 'tfidf_100',\n",
       " 'tfidf_101',\n",
       " 'tfidf_102',\n",
       " 'tfidf_103',\n",
       " 'tfidf_104',\n",
       " 'tfidf_105',\n",
       " 'tfidf_106',\n",
       " 'tfidf_107',\n",
       " 'tfidf_108',\n",
       " 'tfidf_109',\n",
       " 'tfidf_110',\n",
       " 'tfidf_111',\n",
       " 'tfidf_112',\n",
       " 'tfidf_113',\n",
       " 'tfidf_114',\n",
       " 'tfidf_115',\n",
       " 'tfidf_116',\n",
       " 'tfidf_117',\n",
       " 'tfidf_118',\n",
       " 'tfidf_119',\n",
       " 'tfidf_120',\n",
       " 'tfidf_121',\n",
       " 'tfidf_122',\n",
       " 'tfidf_123',\n",
       " 'tfidf_124',\n",
       " 'tfidf_125',\n",
       " 'tfidf_126',\n",
       " 'tfidf_127',\n",
       " 'tfidf_128',\n",
       " 'tfidf_129',\n",
       " 'tfidf_130',\n",
       " 'tfidf_131',\n",
       " 'tfidf_132',\n",
       " 'tfidf_133',\n",
       " 'tfidf_134',\n",
       " 'tfidf_135',\n",
       " 'tfidf_136',\n",
       " 'tfidf_137',\n",
       " 'tfidf_138',\n",
       " 'tfidf_139',\n",
       " 'tfidf_140',\n",
       " 'tfidf_141',\n",
       " 'tfidf_142',\n",
       " 'tfidf_143',\n",
       " 'tfidf_144',\n",
       " 'tfidf_145',\n",
       " 'tfidf_146',\n",
       " 'tfidf_147',\n",
       " 'tfidf_148',\n",
       " 'tfidf_149',\n",
       " 'tfidf_150',\n",
       " 'tfidf_151',\n",
       " 'tfidf_152',\n",
       " 'tfidf_153',\n",
       " 'tfidf_154',\n",
       " 'tfidf_155',\n",
       " 'tfidf_156',\n",
       " 'tfidf_157',\n",
       " 'tfidf_158',\n",
       " 'tfidf_159',\n",
       " 'tfidf_160',\n",
       " 'tfidf_161',\n",
       " 'tfidf_162',\n",
       " 'tfidf_163',\n",
       " 'tfidf_164',\n",
       " 'tfidf_165',\n",
       " 'tfidf_166',\n",
       " 'tfidf_167',\n",
       " 'tfidf_168',\n",
       " 'tfidf_169',\n",
       " 'tfidf_170',\n",
       " 'tfidf_171',\n",
       " 'tfidf_172',\n",
       " 'tfidf_173',\n",
       " 'tfidf_174',\n",
       " 'tfidf_175',\n",
       " 'tfidf_176',\n",
       " 'tfidf_177',\n",
       " 'tfidf_178',\n",
       " 'tfidf_179',\n",
       " 'tfidf_180',\n",
       " 'tfidf_181',\n",
       " 'tfidf_182',\n",
       " 'tfidf_183',\n",
       " 'tfidf_184',\n",
       " 'tfidf_185',\n",
       " 'tfidf_186',\n",
       " 'tfidf_187',\n",
       " 'tfidf_188',\n",
       " 'tfidf_189',\n",
       " 'tfidf_190',\n",
       " 'tfidf_191',\n",
       " 'tfidf_192',\n",
       " 'tfidf_193',\n",
       " 'tfidf_194',\n",
       " 'tfidf_195',\n",
       " 'tfidf_196',\n",
       " 'tfidf_197',\n",
       " 'tfidf_198',\n",
       " 'tfidf_199',\n",
       " 'tfidf_200',\n",
       " 'tfidf_201',\n",
       " 'tfidf_202',\n",
       " 'tfidf_203',\n",
       " 'tfidf_204',\n",
       " 'tfidf_205',\n",
       " 'tfidf_206',\n",
       " 'tfidf_207',\n",
       " 'tfidf_208',\n",
       " 'tfidf_209',\n",
       " 'tfidf_210',\n",
       " 'tfidf_211',\n",
       " 'tfidf_212',\n",
       " 'tfidf_213',\n",
       " 'tfidf_214',\n",
       " 'tfidf_215',\n",
       " 'tfidf_216',\n",
       " 'tfidf_217',\n",
       " 'tfidf_218',\n",
       " 'tfidf_219',\n",
       " 'tfidf_220',\n",
       " 'tfidf_221',\n",
       " 'tfidf_222',\n",
       " 'tfidf_223',\n",
       " 'tfidf_224',\n",
       " 'tfidf_225',\n",
       " 'tfidf_226',\n",
       " 'tfidf_227',\n",
       " 'tfidf_228',\n",
       " 'tfidf_229',\n",
       " 'tfidf_230',\n",
       " 'tfidf_231',\n",
       " 'tfidf_232',\n",
       " 'tfidf_233',\n",
       " 'tfidf_234',\n",
       " 'tfidf_235',\n",
       " 'tfidf_236',\n",
       " 'tfidf_237',\n",
       " 'tfidf_238',\n",
       " 'tfidf_239',\n",
       " 'tfidf_240',\n",
       " 'tfidf_241',\n",
       " 'tfidf_242',\n",
       " 'tfidf_243',\n",
       " 'tfidf_244',\n",
       " 'tfidf_245',\n",
       " 'tfidf_246',\n",
       " 'tfidf_247',\n",
       " 'tfidf_248',\n",
       " 'tfidf_249',\n",
       " 'tfidf_250',\n",
       " 'tfidf_251',\n",
       " 'tfidf_252',\n",
       " 'tfidf_253',\n",
       " 'tfidf_254',\n",
       " 'tfidf_255',\n",
       " 'tfidf_256',\n",
       " 'tfidf_257',\n",
       " 'tfidf_258',\n",
       " 'tfidf_259',\n",
       " 'tfidf_260',\n",
       " 'tfidf_261',\n",
       " 'tfidf_262',\n",
       " 'tfidf_263',\n",
       " 'tfidf_264',\n",
       " 'tfidf_265',\n",
       " 'tfidf_266',\n",
       " 'tfidf_267',\n",
       " 'tfidf_268',\n",
       " 'tfidf_269',\n",
       " 'tfidf_270',\n",
       " 'tfidf_271',\n",
       " 'tfidf_272',\n",
       " 'tfidf_273',\n",
       " 'tfidf_274',\n",
       " 'tfidf_275',\n",
       " 'tfidf_276',\n",
       " 'tfidf_277',\n",
       " 'tfidf_278',\n",
       " 'tfidf_279',\n",
       " 'tfidf_280',\n",
       " 'tfidf_281',\n",
       " 'tfidf_282',\n",
       " 'tfidf_283',\n",
       " 'tfidf_284',\n",
       " 'tfidf_285',\n",
       " 'tfidf_286',\n",
       " 'tfidf_287',\n",
       " 'tfidf_288',\n",
       " 'tfidf_289',\n",
       " 'tfidf_290',\n",
       " 'tfidf_291',\n",
       " 'tfidf_292',\n",
       " 'tfidf_293',\n",
       " 'tfidf_294',\n",
       " 'tfidf_295',\n",
       " 'tfidf_296',\n",
       " 'tfidf_297',\n",
       " 'tfidf_298',\n",
       " 'tfidf_299',\n",
       " 'tfidf_300',\n",
       " 'tfidf_301',\n",
       " 'tfidf_302',\n",
       " 'tfidf_303',\n",
       " 'tfidf_304',\n",
       " 'tfidf_305',\n",
       " 'tfidf_306',\n",
       " 'tfidf_307',\n",
       " 'tfidf_308',\n",
       " 'tfidf_309',\n",
       " 'tfidf_310',\n",
       " 'tfidf_311',\n",
       " 'tfidf_312',\n",
       " 'tfidf_313',\n",
       " 'tfidf_314',\n",
       " 'tfidf_315',\n",
       " 'tfidf_316',\n",
       " 'tfidf_317',\n",
       " 'tfidf_318',\n",
       " 'tfidf_319',\n",
       " 'tfidf_320',\n",
       " 'tfidf_321',\n",
       " 'tfidf_322',\n",
       " 'tfidf_323',\n",
       " 'tfidf_324',\n",
       " 'tfidf_325',\n",
       " 'tfidf_326',\n",
       " 'tfidf_327',\n",
       " 'tfidf_328',\n",
       " 'tfidf_329',\n",
       " 'tfidf_330',\n",
       " 'tfidf_331',\n",
       " 'tfidf_332',\n",
       " 'tfidf_333',\n",
       " 'tfidf_334',\n",
       " 'tfidf_335',\n",
       " 'tfidf_336',\n",
       " 'tfidf_337',\n",
       " 'tfidf_338',\n",
       " 'tfidf_339',\n",
       " 'tfidf_340',\n",
       " 'tfidf_341',\n",
       " 'tfidf_342',\n",
       " 'tfidf_343',\n",
       " 'tfidf_344',\n",
       " 'tfidf_345',\n",
       " 'tfidf_346',\n",
       " 'tfidf_347',\n",
       " 'tfidf_348',\n",
       " 'tfidf_349',\n",
       " 'tfidf_350',\n",
       " 'tfidf_351',\n",
       " 'tfidf_352',\n",
       " 'tfidf_353',\n",
       " 'tfidf_354',\n",
       " 'tfidf_355',\n",
       " 'tfidf_356',\n",
       " 'tfidf_357',\n",
       " 'tfidf_358',\n",
       " 'tfidf_359',\n",
       " 'tfidf_360',\n",
       " 'tfidf_361',\n",
       " 'tfidf_362',\n",
       " 'tfidf_363',\n",
       " 'tfidf_364',\n",
       " 'tfidf_365',\n",
       " 'tfidf_366',\n",
       " 'tfidf_367',\n",
       " 'tfidf_368',\n",
       " 'tfidf_369',\n",
       " 'tfidf_370',\n",
       " 'tfidf_371',\n",
       " 'tfidf_372',\n",
       " 'tfidf_373',\n",
       " 'tfidf_374',\n",
       " 'tfidf_375',\n",
       " 'tfidf_376',\n",
       " 'tfidf_377',\n",
       " 'tfidf_378',\n",
       " 'tfidf_379',\n",
       " 'tfidf_380',\n",
       " 'tfidf_381',\n",
       " 'tfidf_382',\n",
       " 'tfidf_383',\n",
       " 'tfidf_384',\n",
       " 'tfidf_385',\n",
       " 'tfidf_386',\n",
       " 'tfidf_387',\n",
       " 'hybrid',\n",
       " 'indica',\n",
       " 'sativa',\n",
       " 'anxiety',\n",
       " 'anxious',\n",
       " 'aroused',\n",
       " 'arthritis',\n",
       " 'creative',\n",
       " 'depression',\n",
       " 'dizzy',\n",
       " 'dry eyes',\n",
       " 'dry mouth',\n",
       " 'energetic',\n",
       " 'epilepsy',\n",
       " 'euphoric',\n",
       " 'eye pressure',\n",
       " 'fatigue',\n",
       " 'focused',\n",
       " 'giggly',\n",
       " 'happy',\n",
       " 'headache',\n",
       " 'hungry',\n",
       " 'migraines',\n",
       " 'pain',\n",
       " 'paranoid',\n",
       " 'relaxed',\n",
       " 'seizures',\n",
       " 'sleepy',\n",
       " 'spasticity',\n",
       " 'stress',\n",
       " 'talkative',\n",
       " 'tingly',\n",
       " 'uplifted',\n",
       " 'ammonia',\n",
       " 'apple',\n",
       " 'apricot',\n",
       " 'berry',\n",
       " 'blue cheese',\n",
       " 'blueberry',\n",
       " 'butter',\n",
       " 'cheese',\n",
       " 'chemical',\n",
       " 'chestnut',\n",
       " 'citrus',\n",
       " 'coffee',\n",
       " 'diesel',\n",
       " 'earthy',\n",
       " 'flowery',\n",
       " 'fruit',\n",
       " 'grape',\n",
       " 'grapefruit',\n",
       " 'honey',\n",
       " 'lavender',\n",
       " 'lemon',\n",
       " 'lime',\n",
       " 'mango',\n",
       " 'menthol',\n",
       " 'mint',\n",
       " 'nutty',\n",
       " 'orange',\n",
       " 'peach',\n",
       " 'pear',\n",
       " 'pepper',\n",
       " 'pine',\n",
       " 'pineapple',\n",
       " 'plum',\n",
       " 'pungent',\n",
       " 'rose',\n",
       " 'sage',\n",
       " 'skunk',\n",
       " 'spicy/herbal',\n",
       " 'strawberry',\n",
       " 'sweet',\n",
       " 'tar',\n",
       " 'tea',\n",
       " 'tobacco',\n",
       " 'tree',\n",
       " 'tropical',\n",
       " 'vanilla',\n",
       " 'violet',\n",
       " 'woody',\n",
       " 'X..D-Limonene']"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_rf.columns.to_list()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Splitting dependent and independent variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df_rf.drop(['index', 'X..D-Limonene'], axis = 1)\n",
    "y = df_rf[['X..D-Limonene']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plotting histograms on target variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.34177215],\n",
       "       [0.34177215],\n",
       "       [0.34177215],\n",
       "       ...,\n",
       "       [0.24050633],\n",
       "       [0.24050633],\n",
       "       [0.24050633]])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_array = y.to_numpy()\n",
    "y_array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:ylabel='Count'>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "sns.histplot(y, bins = 10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train test split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=1, test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train1, X_val, y_train1, y_val = train_test_split(X_train, y_train, random_state=1, test_size=0.25)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "RF modeling (before Feature selection and Hyperparameter Tuning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/y1/pjvjlkjn5gl846rnyzr53p340000gn/T/ipykernel_9372/350139188.py:2: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  rfreg.fit(X_train1, y_train1)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;background-color: white;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>RandomForestRegressor()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">RandomForestRegressor</label><div class=\"sk-toggleable__content\"><pre>RandomForestRegressor()</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "RandomForestRegressor()"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rfreg = RandomForestRegressor()\n",
    "rfreg.fit(X_train1, y_train1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_rfreg = rfreg.predict(X_val)\n",
    "y_pred_rfreg_r2 = rfreg.predict(X_train1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.05364446960100501"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mean_absolute_error(y_val, y_pred_rfreg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.011899109827375761"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mean_squared_error(y_val, y_pred_rfreg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.10908304097051824"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mean_squared_error(y_val, y_pred_rfreg, squared = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9745495339855069"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#train\n",
    "r2_score(y_train1, y_pred_rfreg_r2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8588768832246636"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#val\n",
    "r2_score(y_val, y_pred_rfreg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Residual plots for each target variable"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Feature Selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_feat = pd.DataFrame({\n",
    "    \"features\": X_train1.columns,\n",
    "    \"score\": rfreg.feature_importances_\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>features</th>\n",
       "      <th>score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>tfidf_0</td>\n",
       "      <td>0.001263</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>tfidf_1</td>\n",
       "      <td>0.001094</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>tfidf_2</td>\n",
       "      <td>0.000849</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>tfidf_3</td>\n",
       "      <td>0.001256</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>tfidf_4</td>\n",
       "      <td>0.000900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>464</th>\n",
       "      <td>tree</td>\n",
       "      <td>0.000389</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>465</th>\n",
       "      <td>tropical</td>\n",
       "      <td>0.001640</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>466</th>\n",
       "      <td>vanilla</td>\n",
       "      <td>0.001697</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>467</th>\n",
       "      <td>violet</td>\n",
       "      <td>0.000054</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>468</th>\n",
       "      <td>woody</td>\n",
       "      <td>0.002209</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>469 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     features     score\n",
       "0     tfidf_0  0.001263\n",
       "1     tfidf_1  0.001094\n",
       "2     tfidf_2  0.000849\n",
       "3     tfidf_3  0.001256\n",
       "4     tfidf_4  0.000900\n",
       "..        ...       ...\n",
       "464      tree  0.000389\n",
       "465  tropical  0.001640\n",
       "466   vanilla  0.001697\n",
       "467    violet  0.000054\n",
       "468     woody  0.002209\n",
       "\n",
       "[469 rows x 2 columns]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_feat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_feat_ranked = df_feat.sort_values(\"score\", ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>features</th>\n",
       "      <th>score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>433</th>\n",
       "      <td>diesel</td>\n",
       "      <td>1.487013e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>388</th>\n",
       "      <td>hybrid</td>\n",
       "      <td>3.737938e-02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>389</th>\n",
       "      <td>indica</td>\n",
       "      <td>2.394308e-02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>329</th>\n",
       "      <td>tfidf_329</td>\n",
       "      <td>1.775884e-02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>272</th>\n",
       "      <td>tfidf_272</td>\n",
       "      <td>1.335973e-02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>168</th>\n",
       "      <td>tfidf_168</td>\n",
       "      <td>1.190080e-02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>145</th>\n",
       "      <td>tfidf_145</td>\n",
       "      <td>1.060210e-02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>441</th>\n",
       "      <td>lemon</td>\n",
       "      <td>1.055308e-02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>345</th>\n",
       "      <td>tfidf_345</td>\n",
       "      <td>9.614425e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>149</th>\n",
       "      <td>tfidf_149</td>\n",
       "      <td>9.595636e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>431</th>\n",
       "      <td>citrus</td>\n",
       "      <td>9.519611e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>312</th>\n",
       "      <td>tfidf_312</td>\n",
       "      <td>8.821956e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>426</th>\n",
       "      <td>blueberry</td>\n",
       "      <td>8.800840e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>285</th>\n",
       "      <td>tfidf_285</td>\n",
       "      <td>7.053814e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>253</th>\n",
       "      <td>tfidf_253</td>\n",
       "      <td>7.025128e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>141</th>\n",
       "      <td>tfidf_141</td>\n",
       "      <td>6.839639e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>459</th>\n",
       "      <td>strawberry</td>\n",
       "      <td>6.815504e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>357</th>\n",
       "      <td>tfidf_357</td>\n",
       "      <td>6.796992e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>309</th>\n",
       "      <td>tfidf_309</td>\n",
       "      <td>6.607504e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>199</th>\n",
       "      <td>tfidf_199</td>\n",
       "      <td>6.594391e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>390</th>\n",
       "      <td>sativa</td>\n",
       "      <td>6.502518e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>434</th>\n",
       "      <td>earthy</td>\n",
       "      <td>6.488123e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>447</th>\n",
       "      <td>orange</td>\n",
       "      <td>5.991571e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>281</th>\n",
       "      <td>tfidf_281</td>\n",
       "      <td>5.974750e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>413</th>\n",
       "      <td>relaxed</td>\n",
       "      <td>5.951124e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>239</th>\n",
       "      <td>tfidf_239</td>\n",
       "      <td>5.797104e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>121</th>\n",
       "      <td>tfidf_121</td>\n",
       "      <td>5.748401e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>245</th>\n",
       "      <td>tfidf_245</td>\n",
       "      <td>5.711310e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>tfidf_43</td>\n",
       "      <td>5.682924e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>tfidf_6</td>\n",
       "      <td>5.599256e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>207</th>\n",
       "      <td>tfidf_207</td>\n",
       "      <td>5.500953e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>210</th>\n",
       "      <td>tfidf_210</td>\n",
       "      <td>5.474117e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>457</th>\n",
       "      <td>skunk</td>\n",
       "      <td>5.129432e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>tfidf_30</td>\n",
       "      <td>5.044121e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>178</th>\n",
       "      <td>tfidf_178</td>\n",
       "      <td>4.726388e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>437</th>\n",
       "      <td>grape</td>\n",
       "      <td>4.599183e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>158</th>\n",
       "      <td>tfidf_158</td>\n",
       "      <td>4.570493e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>402</th>\n",
       "      <td>euphoric</td>\n",
       "      <td>4.479681e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>366</th>\n",
       "      <td>tfidf_366</td>\n",
       "      <td>4.457919e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>420</th>\n",
       "      <td>uplifted</td>\n",
       "      <td>4.443766e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>tfidf_37</td>\n",
       "      <td>4.253213e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>82</th>\n",
       "      <td>tfidf_82</td>\n",
       "      <td>4.245343e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>90</th>\n",
       "      <td>tfidf_90</td>\n",
       "      <td>4.217215e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>119</th>\n",
       "      <td>tfidf_119</td>\n",
       "      <td>4.078689e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>407</th>\n",
       "      <td>happy</td>\n",
       "      <td>4.074350e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>342</th>\n",
       "      <td>tfidf_342</td>\n",
       "      <td>4.025357e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>424</th>\n",
       "      <td>berry</td>\n",
       "      <td>3.892043e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>tfidf_11</td>\n",
       "      <td>3.816099e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>409</th>\n",
       "      <td>hungry</td>\n",
       "      <td>3.624293e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>73</th>\n",
       "      <td>tfidf_73</td>\n",
       "      <td>3.560409e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>460</th>\n",
       "      <td>sweet</td>\n",
       "      <td>3.472497e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>303</th>\n",
       "      <td>tfidf_303</td>\n",
       "      <td>3.389362e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>337</th>\n",
       "      <td>tfidf_337</td>\n",
       "      <td>3.363268e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>419</th>\n",
       "      <td>tingly</td>\n",
       "      <td>3.351001e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>454</th>\n",
       "      <td>pungent</td>\n",
       "      <td>3.340884e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>399</th>\n",
       "      <td>dry mouth</td>\n",
       "      <td>3.267293e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>395</th>\n",
       "      <td>creative</td>\n",
       "      <td>3.252787e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>tfidf_16</td>\n",
       "      <td>3.222863e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>428</th>\n",
       "      <td>cheese</td>\n",
       "      <td>3.196112e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>167</th>\n",
       "      <td>tfidf_167</td>\n",
       "      <td>3.186680e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>173</th>\n",
       "      <td>tfidf_173</td>\n",
       "      <td>3.185598e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>362</th>\n",
       "      <td>tfidf_362</td>\n",
       "      <td>3.122876e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>400</th>\n",
       "      <td>energetic</td>\n",
       "      <td>3.121349e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>153</th>\n",
       "      <td>tfidf_153</td>\n",
       "      <td>3.109318e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>175</th>\n",
       "      <td>tfidf_175</td>\n",
       "      <td>3.103625e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>405</th>\n",
       "      <td>focused</td>\n",
       "      <td>3.084462e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>78</th>\n",
       "      <td>tfidf_78</td>\n",
       "      <td>3.056799e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>338</th>\n",
       "      <td>tfidf_338</td>\n",
       "      <td>3.021017e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>382</th>\n",
       "      <td>tfidf_382</td>\n",
       "      <td>2.996129e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>128</th>\n",
       "      <td>tfidf_128</td>\n",
       "      <td>2.991375e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>93</th>\n",
       "      <td>tfidf_93</td>\n",
       "      <td>2.950466e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>314</th>\n",
       "      <td>tfidf_314</td>\n",
       "      <td>2.944013e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>tfidf_7</td>\n",
       "      <td>2.916267e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>144</th>\n",
       "      <td>tfidf_144</td>\n",
       "      <td>2.855409e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>355</th>\n",
       "      <td>tfidf_355</td>\n",
       "      <td>2.850326e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>162</th>\n",
       "      <td>tfidf_162</td>\n",
       "      <td>2.760218e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>171</th>\n",
       "      <td>tfidf_171</td>\n",
       "      <td>2.745160e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>445</th>\n",
       "      <td>mint</td>\n",
       "      <td>2.743121e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>283</th>\n",
       "      <td>tfidf_283</td>\n",
       "      <td>2.683147e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>264</th>\n",
       "      <td>tfidf_264</td>\n",
       "      <td>2.680295e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>200</th>\n",
       "      <td>tfidf_200</td>\n",
       "      <td>2.557031e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>427</th>\n",
       "      <td>butter</td>\n",
       "      <td>2.556151e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>tfidf_5</td>\n",
       "      <td>2.537428e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>135</th>\n",
       "      <td>tfidf_135</td>\n",
       "      <td>2.499371e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>415</th>\n",
       "      <td>sleepy</td>\n",
       "      <td>2.485147e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>110</th>\n",
       "      <td>tfidf_110</td>\n",
       "      <td>2.460017e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>tfidf_9</td>\n",
       "      <td>2.457418e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>323</th>\n",
       "      <td>tfidf_323</td>\n",
       "      <td>2.446984e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>tfidf_39</td>\n",
       "      <td>2.437634e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>203</th>\n",
       "      <td>tfidf_203</td>\n",
       "      <td>2.416386e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>277</th>\n",
       "      <td>tfidf_277</td>\n",
       "      <td>2.402640e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>258</th>\n",
       "      <td>tfidf_258</td>\n",
       "      <td>2.399866e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>398</th>\n",
       "      <td>dry eyes</td>\n",
       "      <td>2.372510e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>231</th>\n",
       "      <td>tfidf_231</td>\n",
       "      <td>2.349160e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>418</th>\n",
       "      <td>talkative</td>\n",
       "      <td>2.343902e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>432</th>\n",
       "      <td>coffee</td>\n",
       "      <td>2.337457e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>230</th>\n",
       "      <td>tfidf_230</td>\n",
       "      <td>2.317166e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53</th>\n",
       "      <td>tfidf_53</td>\n",
       "      <td>2.313963e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>406</th>\n",
       "      <td>giggly</td>\n",
       "      <td>2.298760e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>124</th>\n",
       "      <td>tfidf_124</td>\n",
       "      <td>2.298622e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>236</th>\n",
       "      <td>tfidf_236</td>\n",
       "      <td>2.290692e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>319</th>\n",
       "      <td>tfidf_319</td>\n",
       "      <td>2.281411e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>468</th>\n",
       "      <td>woody</td>\n",
       "      <td>2.209281e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>126</th>\n",
       "      <td>tfidf_126</td>\n",
       "      <td>2.203983e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>240</th>\n",
       "      <td>tfidf_240</td>\n",
       "      <td>2.196794e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>107</th>\n",
       "      <td>tfidf_107</td>\n",
       "      <td>2.196094e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>376</th>\n",
       "      <td>tfidf_376</td>\n",
       "      <td>2.177988e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>116</th>\n",
       "      <td>tfidf_116</td>\n",
       "      <td>2.158162e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>271</th>\n",
       "      <td>tfidf_271</td>\n",
       "      <td>2.130248e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>451</th>\n",
       "      <td>pine</td>\n",
       "      <td>2.118871e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>343</th>\n",
       "      <td>tfidf_343</td>\n",
       "      <td>2.112191e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>211</th>\n",
       "      <td>tfidf_211</td>\n",
       "      <td>2.104970e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>340</th>\n",
       "      <td>tfidf_340</td>\n",
       "      <td>2.103430e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>273</th>\n",
       "      <td>tfidf_273</td>\n",
       "      <td>2.067527e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>369</th>\n",
       "      <td>tfidf_369</td>\n",
       "      <td>2.056491e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>289</th>\n",
       "      <td>tfidf_289</td>\n",
       "      <td>2.046363e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>216</th>\n",
       "      <td>tfidf_216</td>\n",
       "      <td>2.045274e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>354</th>\n",
       "      <td>tfidf_354</td>\n",
       "      <td>2.025623e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>tfidf_34</td>\n",
       "      <td>2.012529e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>tfidf_20</td>\n",
       "      <td>2.006954e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>360</th>\n",
       "      <td>tfidf_360</td>\n",
       "      <td>1.967350e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>193</th>\n",
       "      <td>tfidf_193</td>\n",
       "      <td>1.966443e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>315</th>\n",
       "      <td>tfidf_315</td>\n",
       "      <td>1.940129e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>364</th>\n",
       "      <td>tfidf_364</td>\n",
       "      <td>1.929454e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>291</th>\n",
       "      <td>tfidf_291</td>\n",
       "      <td>1.924556e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>170</th>\n",
       "      <td>tfidf_170</td>\n",
       "      <td>1.908905e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>386</th>\n",
       "      <td>tfidf_386</td>\n",
       "      <td>1.907299e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>336</th>\n",
       "      <td>tfidf_336</td>\n",
       "      <td>1.879643e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>tfidf_98</td>\n",
       "      <td>1.868287e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>180</th>\n",
       "      <td>tfidf_180</td>\n",
       "      <td>1.863434e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>349</th>\n",
       "      <td>tfidf_349</td>\n",
       "      <td>1.838577e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>146</th>\n",
       "      <td>tfidf_146</td>\n",
       "      <td>1.836678e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>103</th>\n",
       "      <td>tfidf_103</td>\n",
       "      <td>1.834930e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>393</th>\n",
       "      <td>aroused</td>\n",
       "      <td>1.832401e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>301</th>\n",
       "      <td>tfidf_301</td>\n",
       "      <td>1.803506e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>166</th>\n",
       "      <td>tfidf_166</td>\n",
       "      <td>1.771101e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>346</th>\n",
       "      <td>tfidf_346</td>\n",
       "      <td>1.752237e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>106</th>\n",
       "      <td>tfidf_106</td>\n",
       "      <td>1.738679e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>278</th>\n",
       "      <td>tfidf_278</td>\n",
       "      <td>1.722929e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>442</th>\n",
       "      <td>lime</td>\n",
       "      <td>1.722342e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>246</th>\n",
       "      <td>tfidf_246</td>\n",
       "      <td>1.720847e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>104</th>\n",
       "      <td>tfidf_104</td>\n",
       "      <td>1.718416e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>205</th>\n",
       "      <td>tfidf_205</td>\n",
       "      <td>1.705194e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>466</th>\n",
       "      <td>vanilla</td>\n",
       "      <td>1.697382e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>142</th>\n",
       "      <td>tfidf_142</td>\n",
       "      <td>1.695385e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>458</th>\n",
       "      <td>spicy/herbal</td>\n",
       "      <td>1.673196e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>267</th>\n",
       "      <td>tfidf_267</td>\n",
       "      <td>1.671634e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>380</th>\n",
       "      <td>tfidf_380</td>\n",
       "      <td>1.652051e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>465</th>\n",
       "      <td>tropical</td>\n",
       "      <td>1.639799e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>71</th>\n",
       "      <td>tfidf_71</td>\n",
       "      <td>1.633099e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>263</th>\n",
       "      <td>tfidf_263</td>\n",
       "      <td>1.621636e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>83</th>\n",
       "      <td>tfidf_83</td>\n",
       "      <td>1.621579e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>108</th>\n",
       "      <td>tfidf_108</td>\n",
       "      <td>1.621512e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>tfidf_32</td>\n",
       "      <td>1.612261e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>367</th>\n",
       "      <td>tfidf_367</td>\n",
       "      <td>1.609601e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>189</th>\n",
       "      <td>tfidf_189</td>\n",
       "      <td>1.573988e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>320</th>\n",
       "      <td>tfidf_320</td>\n",
       "      <td>1.573350e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>tfidf_27</td>\n",
       "      <td>1.553977e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>tfidf_21</td>\n",
       "      <td>1.550110e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>282</th>\n",
       "      <td>tfidf_282</td>\n",
       "      <td>1.547443e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>86</th>\n",
       "      <td>tfidf_86</td>\n",
       "      <td>1.546445e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>tfidf_48</td>\n",
       "      <td>1.538105e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>270</th>\n",
       "      <td>tfidf_270</td>\n",
       "      <td>1.508087e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>139</th>\n",
       "      <td>tfidf_139</td>\n",
       "      <td>1.505420e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>456</th>\n",
       "      <td>sage</td>\n",
       "      <td>1.500662e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>165</th>\n",
       "      <td>tfidf_165</td>\n",
       "      <td>1.495998e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>247</th>\n",
       "      <td>tfidf_247</td>\n",
       "      <td>1.492655e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>181</th>\n",
       "      <td>tfidf_181</td>\n",
       "      <td>1.491234e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>326</th>\n",
       "      <td>tfidf_326</td>\n",
       "      <td>1.468588e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>123</th>\n",
       "      <td>tfidf_123</td>\n",
       "      <td>1.453665e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>371</th>\n",
       "      <td>tfidf_371</td>\n",
       "      <td>1.452489e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>249</th>\n",
       "      <td>tfidf_249</td>\n",
       "      <td>1.442777e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>325</th>\n",
       "      <td>tfidf_325</td>\n",
       "      <td>1.438692e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>190</th>\n",
       "      <td>tfidf_190</td>\n",
       "      <td>1.432993e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>tfidf_96</td>\n",
       "      <td>1.430943e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>117</th>\n",
       "      <td>tfidf_117</td>\n",
       "      <td>1.426578e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>tfidf_46</td>\n",
       "      <td>1.418236e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>tfidf_17</td>\n",
       "      <td>1.415655e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>118</th>\n",
       "      <td>tfidf_118</td>\n",
       "      <td>1.405621e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>339</th>\n",
       "      <td>tfidf_339</td>\n",
       "      <td>1.399157e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>101</th>\n",
       "      <td>tfidf_101</td>\n",
       "      <td>1.394305e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>374</th>\n",
       "      <td>tfidf_374</td>\n",
       "      <td>1.388729e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>252</th>\n",
       "      <td>tfidf_252</td>\n",
       "      <td>1.375742e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>373</th>\n",
       "      <td>tfidf_373</td>\n",
       "      <td>1.375341e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>217</th>\n",
       "      <td>tfidf_217</td>\n",
       "      <td>1.372730e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>279</th>\n",
       "      <td>tfidf_279</td>\n",
       "      <td>1.367872e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>129</th>\n",
       "      <td>tfidf_129</td>\n",
       "      <td>1.346483e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>159</th>\n",
       "      <td>tfidf_159</td>\n",
       "      <td>1.341284e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>tfidf_24</td>\n",
       "      <td>1.336408e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>316</th>\n",
       "      <td>tfidf_316</td>\n",
       "      <td>1.332307e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>81</th>\n",
       "      <td>tfidf_81</td>\n",
       "      <td>1.328389e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>387</th>\n",
       "      <td>tfidf_387</td>\n",
       "      <td>1.325343e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>255</th>\n",
       "      <td>tfidf_255</td>\n",
       "      <td>1.317190e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>64</th>\n",
       "      <td>tfidf_64</td>\n",
       "      <td>1.316308e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>130</th>\n",
       "      <td>tfidf_130</td>\n",
       "      <td>1.306908e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>127</th>\n",
       "      <td>tfidf_127</td>\n",
       "      <td>1.304243e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>tfidf_26</td>\n",
       "      <td>1.304118e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>tfidf_41</td>\n",
       "      <td>1.286804e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>112</th>\n",
       "      <td>tfidf_112</td>\n",
       "      <td>1.283379e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>206</th>\n",
       "      <td>tfidf_206</td>\n",
       "      <td>1.271095e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>304</th>\n",
       "      <td>tfidf_304</td>\n",
       "      <td>1.267499e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>tfidf_0</td>\n",
       "      <td>1.262991e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>tfidf_3</td>\n",
       "      <td>1.255733e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>215</th>\n",
       "      <td>tfidf_215</td>\n",
       "      <td>1.233134e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>tfidf_99</td>\n",
       "      <td>1.229274e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>61</th>\n",
       "      <td>tfidf_61</td>\n",
       "      <td>1.227436e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>163</th>\n",
       "      <td>tfidf_163</td>\n",
       "      <td>1.222274e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>tfidf_97</td>\n",
       "      <td>1.218691e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>151</th>\n",
       "      <td>tfidf_151</td>\n",
       "      <td>1.217957e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>397</th>\n",
       "      <td>dizzy</td>\n",
       "      <td>1.204964e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>194</th>\n",
       "      <td>tfidf_194</td>\n",
       "      <td>1.200308e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>tfidf_49</td>\n",
       "      <td>1.195454e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>265</th>\n",
       "      <td>tfidf_265</td>\n",
       "      <td>1.195120e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>222</th>\n",
       "      <td>tfidf_222</td>\n",
       "      <td>1.187605e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>212</th>\n",
       "      <td>tfidf_212</td>\n",
       "      <td>1.180165e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>220</th>\n",
       "      <td>tfidf_220</td>\n",
       "      <td>1.180116e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>221</th>\n",
       "      <td>tfidf_221</td>\n",
       "      <td>1.179307e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>353</th>\n",
       "      <td>tfidf_353</td>\n",
       "      <td>1.171109e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>208</th>\n",
       "      <td>tfidf_208</td>\n",
       "      <td>1.166075e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>184</th>\n",
       "      <td>tfidf_184</td>\n",
       "      <td>1.149386e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>292</th>\n",
       "      <td>tfidf_292</td>\n",
       "      <td>1.146452e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>143</th>\n",
       "      <td>tfidf_143</td>\n",
       "      <td>1.144608e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>tfidf_19</td>\n",
       "      <td>1.142525e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52</th>\n",
       "      <td>tfidf_52</td>\n",
       "      <td>1.135538e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>161</th>\n",
       "      <td>tfidf_161</td>\n",
       "      <td>1.134832e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>321</th>\n",
       "      <td>tfidf_321</td>\n",
       "      <td>1.131892e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>295</th>\n",
       "      <td>tfidf_295</td>\n",
       "      <td>1.130515e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50</th>\n",
       "      <td>tfidf_50</td>\n",
       "      <td>1.130148e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75</th>\n",
       "      <td>tfidf_75</td>\n",
       "      <td>1.107494e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>169</th>\n",
       "      <td>tfidf_169</td>\n",
       "      <td>1.107321e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>429</th>\n",
       "      <td>chemical</td>\n",
       "      <td>1.098962e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>288</th>\n",
       "      <td>tfidf_288</td>\n",
       "      <td>1.095616e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>154</th>\n",
       "      <td>tfidf_154</td>\n",
       "      <td>1.094462e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>tfidf_1</td>\n",
       "      <td>1.093521e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>63</th>\n",
       "      <td>tfidf_63</td>\n",
       "      <td>1.090399e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>348</th>\n",
       "      <td>tfidf_348</td>\n",
       "      <td>1.084396e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>tfidf_23</td>\n",
       "      <td>1.083422e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>275</th>\n",
       "      <td>tfidf_275</td>\n",
       "      <td>1.083047e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>tfidf_44</td>\n",
       "      <td>1.082912e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>132</th>\n",
       "      <td>tfidf_132</td>\n",
       "      <td>1.081111e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>125</th>\n",
       "      <td>tfidf_125</td>\n",
       "      <td>1.071294e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>294</th>\n",
       "      <td>tfidf_294</td>\n",
       "      <td>1.049954e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>56</th>\n",
       "      <td>tfidf_56</td>\n",
       "      <td>1.044902e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>209</th>\n",
       "      <td>tfidf_209</td>\n",
       "      <td>1.043651e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>tfidf_36</td>\n",
       "      <td>1.043383e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>341</th>\n",
       "      <td>tfidf_341</td>\n",
       "      <td>1.040788e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>157</th>\n",
       "      <td>tfidf_157</td>\n",
       "      <td>1.023309e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>tfidf_15</td>\n",
       "      <td>1.005558e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>262</th>\n",
       "      <td>tfidf_262</td>\n",
       "      <td>1.003826e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>269</th>\n",
       "      <td>tfidf_269</td>\n",
       "      <td>1.000305e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>79</th>\n",
       "      <td>tfidf_79</td>\n",
       "      <td>9.996706e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>224</th>\n",
       "      <td>tfidf_224</td>\n",
       "      <td>9.954586e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>147</th>\n",
       "      <td>tfidf_147</td>\n",
       "      <td>9.948652e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>80</th>\n",
       "      <td>tfidf_80</td>\n",
       "      <td>9.914052e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>120</th>\n",
       "      <td>tfidf_120</td>\n",
       "      <td>9.911036e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>tfidf_45</td>\n",
       "      <td>9.838963e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>152</th>\n",
       "      <td>tfidf_152</td>\n",
       "      <td>9.824468e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>tfidf_31</td>\n",
       "      <td>9.807736e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>109</th>\n",
       "      <td>tfidf_109</td>\n",
       "      <td>9.721322e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>tfidf_28</td>\n",
       "      <td>9.684737e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>85</th>\n",
       "      <td>tfidf_85</td>\n",
       "      <td>9.623155e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>223</th>\n",
       "      <td>tfidf_223</td>\n",
       "      <td>9.570238e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>164</th>\n",
       "      <td>tfidf_164</td>\n",
       "      <td>9.427703e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>69</th>\n",
       "      <td>tfidf_69</td>\n",
       "      <td>9.397755e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>105</th>\n",
       "      <td>tfidf_105</td>\n",
       "      <td>9.381363e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>tfidf_12</td>\n",
       "      <td>9.359925e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>136</th>\n",
       "      <td>tfidf_136</td>\n",
       "      <td>9.271609e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>251</th>\n",
       "      <td>tfidf_251</td>\n",
       "      <td>9.269223e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>76</th>\n",
       "      <td>tfidf_76</td>\n",
       "      <td>9.263847e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>114</th>\n",
       "      <td>tfidf_114</td>\n",
       "      <td>9.238083e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54</th>\n",
       "      <td>tfidf_54</td>\n",
       "      <td>9.153787e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>88</th>\n",
       "      <td>tfidf_88</td>\n",
       "      <td>9.140739e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>tfidf_4</td>\n",
       "      <td>8.999865e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>381</th>\n",
       "      <td>tfidf_381</td>\n",
       "      <td>8.986345e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>244</th>\n",
       "      <td>tfidf_244</td>\n",
       "      <td>8.970097e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>115</th>\n",
       "      <td>tfidf_115</td>\n",
       "      <td>8.957595e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>84</th>\n",
       "      <td>tfidf_84</td>\n",
       "      <td>8.904686e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>261</th>\n",
       "      <td>tfidf_261</td>\n",
       "      <td>8.874869e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>62</th>\n",
       "      <td>tfidf_62</td>\n",
       "      <td>8.856990e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>tfidf_35</td>\n",
       "      <td>8.828380e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>tfidf_22</td>\n",
       "      <td>8.780717e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>356</th>\n",
       "      <td>tfidf_356</td>\n",
       "      <td>8.751172e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>237</th>\n",
       "      <td>tfidf_237</td>\n",
       "      <td>8.713477e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>122</th>\n",
       "      <td>tfidf_122</td>\n",
       "      <td>8.698747e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>201</th>\n",
       "      <td>tfidf_201</td>\n",
       "      <td>8.607952e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>450</th>\n",
       "      <td>pepper</td>\n",
       "      <td>8.578187e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>379</th>\n",
       "      <td>tfidf_379</td>\n",
       "      <td>8.573575e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>188</th>\n",
       "      <td>tfidf_188</td>\n",
       "      <td>8.528513e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>226</th>\n",
       "      <td>tfidf_226</td>\n",
       "      <td>8.497319e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>tfidf_2</td>\n",
       "      <td>8.486286e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>372</th>\n",
       "      <td>tfidf_372</td>\n",
       "      <td>8.444968e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>297</th>\n",
       "      <td>tfidf_297</td>\n",
       "      <td>8.357651e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>260</th>\n",
       "      <td>tfidf_260</td>\n",
       "      <td>8.277683e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>tfidf_47</td>\n",
       "      <td>8.265738e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>148</th>\n",
       "      <td>tfidf_148</td>\n",
       "      <td>8.264475e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>328</th>\n",
       "      <td>tfidf_328</td>\n",
       "      <td>8.181086e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>176</th>\n",
       "      <td>tfidf_176</td>\n",
       "      <td>8.165893e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>350</th>\n",
       "      <td>tfidf_350</td>\n",
       "      <td>8.031109e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>318</th>\n",
       "      <td>tfidf_318</td>\n",
       "      <td>8.014959e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>254</th>\n",
       "      <td>tfidf_254</td>\n",
       "      <td>7.981132e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>182</th>\n",
       "      <td>tfidf_182</td>\n",
       "      <td>7.910313e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>286</th>\n",
       "      <td>tfidf_286</td>\n",
       "      <td>7.900887e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>131</th>\n",
       "      <td>tfidf_131</td>\n",
       "      <td>7.881075e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>177</th>\n",
       "      <td>tfidf_177</td>\n",
       "      <td>7.873170e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>219</th>\n",
       "      <td>tfidf_219</td>\n",
       "      <td>7.871711e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>435</th>\n",
       "      <td>flowery</td>\n",
       "      <td>7.718503e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>183</th>\n",
       "      <td>tfidf_183</td>\n",
       "      <td>7.700287e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>218</th>\n",
       "      <td>tfidf_218</td>\n",
       "      <td>7.605469e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>58</th>\n",
       "      <td>tfidf_58</td>\n",
       "      <td>7.573189e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>229</th>\n",
       "      <td>tfidf_229</td>\n",
       "      <td>7.538503e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>197</th>\n",
       "      <td>tfidf_197</td>\n",
       "      <td>7.501841e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>198</th>\n",
       "      <td>tfidf_198</td>\n",
       "      <td>7.473438e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>443</th>\n",
       "      <td>mango</td>\n",
       "      <td>7.472319e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>317</th>\n",
       "      <td>tfidf_317</td>\n",
       "      <td>7.364847e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>259</th>\n",
       "      <td>tfidf_259</td>\n",
       "      <td>7.290879e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>358</th>\n",
       "      <td>tfidf_358</td>\n",
       "      <td>7.275010e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>192</th>\n",
       "      <td>tfidf_192</td>\n",
       "      <td>7.269390e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>284</th>\n",
       "      <td>tfidf_284</td>\n",
       "      <td>7.228744e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>186</th>\n",
       "      <td>tfidf_186</td>\n",
       "      <td>7.211699e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>202</th>\n",
       "      <td>tfidf_202</td>\n",
       "      <td>7.199241e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>363</th>\n",
       "      <td>tfidf_363</td>\n",
       "      <td>7.140342e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>327</th>\n",
       "      <td>tfidf_327</td>\n",
       "      <td>7.094848e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>368</th>\n",
       "      <td>tfidf_368</td>\n",
       "      <td>7.035277e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>310</th>\n",
       "      <td>tfidf_310</td>\n",
       "      <td>7.016720e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>370</th>\n",
       "      <td>tfidf_370</td>\n",
       "      <td>7.009311e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>68</th>\n",
       "      <td>tfidf_68</td>\n",
       "      <td>6.885581e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>tfidf_13</td>\n",
       "      <td>6.859858e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>102</th>\n",
       "      <td>tfidf_102</td>\n",
       "      <td>6.783643e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>91</th>\n",
       "      <td>tfidf_91</td>\n",
       "      <td>6.775488e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>tfidf_10</td>\n",
       "      <td>6.754252e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>233</th>\n",
       "      <td>tfidf_233</td>\n",
       "      <td>6.752600e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>187</th>\n",
       "      <td>tfidf_187</td>\n",
       "      <td>6.737401e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>111</th>\n",
       "      <td>tfidf_111</td>\n",
       "      <td>6.686434e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>347</th>\n",
       "      <td>tfidf_347</td>\n",
       "      <td>6.684559e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>133</th>\n",
       "      <td>tfidf_133</td>\n",
       "      <td>6.579367e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>tfidf_42</td>\n",
       "      <td>6.573146e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>185</th>\n",
       "      <td>tfidf_185</td>\n",
       "      <td>6.567716e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>311</th>\n",
       "      <td>tfidf_311</td>\n",
       "      <td>6.560951e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>266</th>\n",
       "      <td>tfidf_266</td>\n",
       "      <td>6.552280e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>322</th>\n",
       "      <td>tfidf_322</td>\n",
       "      <td>6.535404e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>344</th>\n",
       "      <td>tfidf_344</td>\n",
       "      <td>6.525390e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>274</th>\n",
       "      <td>tfidf_274</td>\n",
       "      <td>6.446913e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>57</th>\n",
       "      <td>tfidf_57</td>\n",
       "      <td>6.418363e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>332</th>\n",
       "      <td>tfidf_332</td>\n",
       "      <td>6.303845e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>305</th>\n",
       "      <td>tfidf_305</td>\n",
       "      <td>6.229826e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>196</th>\n",
       "      <td>tfidf_196</td>\n",
       "      <td>6.219876e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>195</th>\n",
       "      <td>tfidf_195</td>\n",
       "      <td>6.212928e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>412</th>\n",
       "      <td>paranoid</td>\n",
       "      <td>6.203295e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>440</th>\n",
       "      <td>lavender</td>\n",
       "      <td>5.984033e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>287</th>\n",
       "      <td>tfidf_287</td>\n",
       "      <td>5.974266e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>227</th>\n",
       "      <td>tfidf_227</td>\n",
       "      <td>5.961844e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>140</th>\n",
       "      <td>tfidf_140</td>\n",
       "      <td>5.885368e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>446</th>\n",
       "      <td>nutty</td>\n",
       "      <td>5.868948e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>385</th>\n",
       "      <td>tfidf_385</td>\n",
       "      <td>5.855037e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59</th>\n",
       "      <td>tfidf_59</td>\n",
       "      <td>5.788673e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>392</th>\n",
       "      <td>anxious</td>\n",
       "      <td>5.784043e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>160</th>\n",
       "      <td>tfidf_160</td>\n",
       "      <td>5.491717e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>65</th>\n",
       "      <td>tfidf_65</td>\n",
       "      <td>5.439619e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>235</th>\n",
       "      <td>tfidf_235</td>\n",
       "      <td>5.429223e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>408</th>\n",
       "      <td>headache</td>\n",
       "      <td>5.411621e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>324</th>\n",
       "      <td>tfidf_324</td>\n",
       "      <td>5.357947e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>438</th>\n",
       "      <td>grapefruit</td>\n",
       "      <td>5.346014e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>257</th>\n",
       "      <td>tfidf_257</td>\n",
       "      <td>5.215954e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>214</th>\n",
       "      <td>tfidf_214</td>\n",
       "      <td>5.167318e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>94</th>\n",
       "      <td>tfidf_94</td>\n",
       "      <td>5.158937e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>377</th>\n",
       "      <td>tfidf_377</td>\n",
       "      <td>5.133591e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>256</th>\n",
       "      <td>tfidf_256</td>\n",
       "      <td>5.115375e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>77</th>\n",
       "      <td>tfidf_77</td>\n",
       "      <td>5.063459e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>383</th>\n",
       "      <td>tfidf_383</td>\n",
       "      <td>5.051258e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>228</th>\n",
       "      <td>tfidf_228</td>\n",
       "      <td>5.014358e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>174</th>\n",
       "      <td>tfidf_174</td>\n",
       "      <td>4.927756e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>298</th>\n",
       "      <td>tfidf_298</td>\n",
       "      <td>4.919887e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>67</th>\n",
       "      <td>tfidf_67</td>\n",
       "      <td>4.903663e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>tfidf_25</td>\n",
       "      <td>4.873100e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>307</th>\n",
       "      <td>tfidf_307</td>\n",
       "      <td>4.872507e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>334</th>\n",
       "      <td>tfidf_334</td>\n",
       "      <td>4.840911e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>tfidf_33</td>\n",
       "      <td>4.833316e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>225</th>\n",
       "      <td>tfidf_225</td>\n",
       "      <td>4.825851e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>204</th>\n",
       "      <td>tfidf_204</td>\n",
       "      <td>4.817633e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>280</th>\n",
       "      <td>tfidf_280</td>\n",
       "      <td>4.797200e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>436</th>\n",
       "      <td>fruit</td>\n",
       "      <td>4.794423e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>tfidf_18</td>\n",
       "      <td>4.774984e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>172</th>\n",
       "      <td>tfidf_172</td>\n",
       "      <td>4.721940e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>138</th>\n",
       "      <td>tfidf_138</td>\n",
       "      <td>4.682167e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>234</th>\n",
       "      <td>tfidf_234</td>\n",
       "      <td>4.581775e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>243</th>\n",
       "      <td>tfidf_243</td>\n",
       "      <td>4.519303e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>213</th>\n",
       "      <td>tfidf_213</td>\n",
       "      <td>4.423894e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>179</th>\n",
       "      <td>tfidf_179</td>\n",
       "      <td>4.342165e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>306</th>\n",
       "      <td>tfidf_306</td>\n",
       "      <td>4.290777e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>134</th>\n",
       "      <td>tfidf_134</td>\n",
       "      <td>4.282850e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>tfidf_29</td>\n",
       "      <td>4.268448e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>137</th>\n",
       "      <td>tfidf_137</td>\n",
       "      <td>4.227149e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>352</th>\n",
       "      <td>tfidf_352</td>\n",
       "      <td>4.167872e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>365</th>\n",
       "      <td>tfidf_365</td>\n",
       "      <td>4.145407e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>268</th>\n",
       "      <td>tfidf_268</td>\n",
       "      <td>4.122158e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>156</th>\n",
       "      <td>tfidf_156</td>\n",
       "      <td>4.107260e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>384</th>\n",
       "      <td>tfidf_384</td>\n",
       "      <td>4.035283e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>55</th>\n",
       "      <td>tfidf_55</td>\n",
       "      <td>3.982937e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>238</th>\n",
       "      <td>tfidf_238</td>\n",
       "      <td>3.973690e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>232</th>\n",
       "      <td>tfidf_232</td>\n",
       "      <td>3.946523e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>464</th>\n",
       "      <td>tree</td>\n",
       "      <td>3.886166e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>300</th>\n",
       "      <td>tfidf_300</td>\n",
       "      <td>3.829302e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>463</th>\n",
       "      <td>tobacco</td>\n",
       "      <td>3.821457e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>150</th>\n",
       "      <td>tfidf_150</td>\n",
       "      <td>3.792401e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>313</th>\n",
       "      <td>tfidf_313</td>\n",
       "      <td>3.773625e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>248</th>\n",
       "      <td>tfidf_248</td>\n",
       "      <td>3.715401e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>302</th>\n",
       "      <td>tfidf_302</td>\n",
       "      <td>3.707379e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>293</th>\n",
       "      <td>tfidf_293</td>\n",
       "      <td>3.670483e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>66</th>\n",
       "      <td>tfidf_66</td>\n",
       "      <td>3.634284e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>308</th>\n",
       "      <td>tfidf_308</td>\n",
       "      <td>3.593237e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>276</th>\n",
       "      <td>tfidf_276</td>\n",
       "      <td>3.537274e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>72</th>\n",
       "      <td>tfidf_72</td>\n",
       "      <td>3.520738e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>333</th>\n",
       "      <td>tfidf_333</td>\n",
       "      <td>3.491990e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>74</th>\n",
       "      <td>tfidf_74</td>\n",
       "      <td>3.463848e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51</th>\n",
       "      <td>tfidf_51</td>\n",
       "      <td>3.335896e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>tfidf_14</td>\n",
       "      <td>3.305763e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>331</th>\n",
       "      <td>tfidf_331</td>\n",
       "      <td>3.300439e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>242</th>\n",
       "      <td>tfidf_242</td>\n",
       "      <td>3.289466e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>87</th>\n",
       "      <td>tfidf_87</td>\n",
       "      <td>3.261528e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>299</th>\n",
       "      <td>tfidf_299</td>\n",
       "      <td>3.063973e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>359</th>\n",
       "      <td>tfidf_359</td>\n",
       "      <td>3.052390e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>89</th>\n",
       "      <td>tfidf_89</td>\n",
       "      <td>3.026584e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>191</th>\n",
       "      <td>tfidf_191</td>\n",
       "      <td>3.010939e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>tfidf_8</td>\n",
       "      <td>2.941955e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>330</th>\n",
       "      <td>tfidf_330</td>\n",
       "      <td>2.902407e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>92</th>\n",
       "      <td>tfidf_92</td>\n",
       "      <td>2.804499e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>378</th>\n",
       "      <td>tfidf_378</td>\n",
       "      <td>2.784009e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>tfidf_38</td>\n",
       "      <td>2.731954e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>361</th>\n",
       "      <td>tfidf_361</td>\n",
       "      <td>2.709754e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>375</th>\n",
       "      <td>tfidf_375</td>\n",
       "      <td>2.620596e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>455</th>\n",
       "      <td>rose</td>\n",
       "      <td>2.576635e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>452</th>\n",
       "      <td>pineapple</td>\n",
       "      <td>2.536654e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>155</th>\n",
       "      <td>tfidf_155</td>\n",
       "      <td>2.477795e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>tfidf_40</td>\n",
       "      <td>2.466212e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>70</th>\n",
       "      <td>tfidf_70</td>\n",
       "      <td>2.465676e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>290</th>\n",
       "      <td>tfidf_290</td>\n",
       "      <td>2.445507e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>335</th>\n",
       "      <td>tfidf_335</td>\n",
       "      <td>2.395274e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>296</th>\n",
       "      <td>tfidf_296</td>\n",
       "      <td>2.331982e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>241</th>\n",
       "      <td>tfidf_241</td>\n",
       "      <td>2.264831e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>351</th>\n",
       "      <td>tfidf_351</td>\n",
       "      <td>2.113342e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>453</th>\n",
       "      <td>plum</td>\n",
       "      <td>2.089134e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>462</th>\n",
       "      <td>tea</td>\n",
       "      <td>2.079756e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>444</th>\n",
       "      <td>menthol</td>\n",
       "      <td>1.979514e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>60</th>\n",
       "      <td>tfidf_60</td>\n",
       "      <td>1.906496e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>439</th>\n",
       "      <td>honey</td>\n",
       "      <td>1.771867e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>100</th>\n",
       "      <td>tfidf_100</td>\n",
       "      <td>1.639909e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>430</th>\n",
       "      <td>chestnut</td>\n",
       "      <td>1.551446e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>tfidf_95</td>\n",
       "      <td>1.549289e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>421</th>\n",
       "      <td>ammonia</td>\n",
       "      <td>1.531370e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>461</th>\n",
       "      <td>tar</td>\n",
       "      <td>1.329332e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>113</th>\n",
       "      <td>tfidf_113</td>\n",
       "      <td>1.320782e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>422</th>\n",
       "      <td>apple</td>\n",
       "      <td>6.596237e-05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>250</th>\n",
       "      <td>tfidf_250</td>\n",
       "      <td>6.518208e-05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>423</th>\n",
       "      <td>apricot</td>\n",
       "      <td>5.937191e-05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>467</th>\n",
       "      <td>violet</td>\n",
       "      <td>5.435372e-05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>448</th>\n",
       "      <td>peach</td>\n",
       "      <td>4.328522e-05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>396</th>\n",
       "      <td>depression</td>\n",
       "      <td>3.834170e-05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>410</th>\n",
       "      <td>migraines</td>\n",
       "      <td>3.521216e-05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>449</th>\n",
       "      <td>pear</td>\n",
       "      <td>3.114162e-05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>391</th>\n",
       "      <td>anxiety</td>\n",
       "      <td>2.518997e-05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>425</th>\n",
       "      <td>blue cheese</td>\n",
       "      <td>1.178549e-05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>411</th>\n",
       "      <td>pain</td>\n",
       "      <td>2.028097e-08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>404</th>\n",
       "      <td>fatigue</td>\n",
       "      <td>1.305318e-08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>414</th>\n",
       "      <td>seizures</td>\n",
       "      <td>5.473437e-09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>401</th>\n",
       "      <td>epilepsy</td>\n",
       "      <td>8.180816e-10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>403</th>\n",
       "      <td>eye pressure</td>\n",
       "      <td>1.246061e-10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>417</th>\n",
       "      <td>stress</td>\n",
       "      <td>0.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>416</th>\n",
       "      <td>spasticity</td>\n",
       "      <td>0.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>394</th>\n",
       "      <td>arthritis</td>\n",
       "      <td>0.000000e+00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         features         score\n",
       "433        diesel  1.487013e-01\n",
       "388        hybrid  3.737938e-02\n",
       "389        indica  2.394308e-02\n",
       "329     tfidf_329  1.775884e-02\n",
       "272     tfidf_272  1.335973e-02\n",
       "168     tfidf_168  1.190080e-02\n",
       "145     tfidf_145  1.060210e-02\n",
       "441         lemon  1.055308e-02\n",
       "345     tfidf_345  9.614425e-03\n",
       "149     tfidf_149  9.595636e-03\n",
       "431        citrus  9.519611e-03\n",
       "312     tfidf_312  8.821956e-03\n",
       "426     blueberry  8.800840e-03\n",
       "285     tfidf_285  7.053814e-03\n",
       "253     tfidf_253  7.025128e-03\n",
       "141     tfidf_141  6.839639e-03\n",
       "459    strawberry  6.815504e-03\n",
       "357     tfidf_357  6.796992e-03\n",
       "309     tfidf_309  6.607504e-03\n",
       "199     tfidf_199  6.594391e-03\n",
       "390        sativa  6.502518e-03\n",
       "434        earthy  6.488123e-03\n",
       "447        orange  5.991571e-03\n",
       "281     tfidf_281  5.974750e-03\n",
       "413       relaxed  5.951124e-03\n",
       "239     tfidf_239  5.797104e-03\n",
       "121     tfidf_121  5.748401e-03\n",
       "245     tfidf_245  5.711310e-03\n",
       "43       tfidf_43  5.682924e-03\n",
       "6         tfidf_6  5.599256e-03\n",
       "207     tfidf_207  5.500953e-03\n",
       "210     tfidf_210  5.474117e-03\n",
       "457         skunk  5.129432e-03\n",
       "30       tfidf_30  5.044121e-03\n",
       "178     tfidf_178  4.726388e-03\n",
       "437         grape  4.599183e-03\n",
       "158     tfidf_158  4.570493e-03\n",
       "402      euphoric  4.479681e-03\n",
       "366     tfidf_366  4.457919e-03\n",
       "420      uplifted  4.443766e-03\n",
       "37       tfidf_37  4.253213e-03\n",
       "82       tfidf_82  4.245343e-03\n",
       "90       tfidf_90  4.217215e-03\n",
       "119     tfidf_119  4.078689e-03\n",
       "407         happy  4.074350e-03\n",
       "342     tfidf_342  4.025357e-03\n",
       "424         berry  3.892043e-03\n",
       "11       tfidf_11  3.816099e-03\n",
       "409        hungry  3.624293e-03\n",
       "73       tfidf_73  3.560409e-03\n",
       "460         sweet  3.472497e-03\n",
       "303     tfidf_303  3.389362e-03\n",
       "337     tfidf_337  3.363268e-03\n",
       "419        tingly  3.351001e-03\n",
       "454       pungent  3.340884e-03\n",
       "399     dry mouth  3.267293e-03\n",
       "395      creative  3.252787e-03\n",
       "16       tfidf_16  3.222863e-03\n",
       "428        cheese  3.196112e-03\n",
       "167     tfidf_167  3.186680e-03\n",
       "173     tfidf_173  3.185598e-03\n",
       "362     tfidf_362  3.122876e-03\n",
       "400     energetic  3.121349e-03\n",
       "153     tfidf_153  3.109318e-03\n",
       "175     tfidf_175  3.103625e-03\n",
       "405       focused  3.084462e-03\n",
       "78       tfidf_78  3.056799e-03\n",
       "338     tfidf_338  3.021017e-03\n",
       "382     tfidf_382  2.996129e-03\n",
       "128     tfidf_128  2.991375e-03\n",
       "93       tfidf_93  2.950466e-03\n",
       "314     tfidf_314  2.944013e-03\n",
       "7         tfidf_7  2.916267e-03\n",
       "144     tfidf_144  2.855409e-03\n",
       "355     tfidf_355  2.850326e-03\n",
       "162     tfidf_162  2.760218e-03\n",
       "171     tfidf_171  2.745160e-03\n",
       "445          mint  2.743121e-03\n",
       "283     tfidf_283  2.683147e-03\n",
       "264     tfidf_264  2.680295e-03\n",
       "200     tfidf_200  2.557031e-03\n",
       "427        butter  2.556151e-03\n",
       "5         tfidf_5  2.537428e-03\n",
       "135     tfidf_135  2.499371e-03\n",
       "415        sleepy  2.485147e-03\n",
       "110     tfidf_110  2.460017e-03\n",
       "9         tfidf_9  2.457418e-03\n",
       "323     tfidf_323  2.446984e-03\n",
       "39       tfidf_39  2.437634e-03\n",
       "203     tfidf_203  2.416386e-03\n",
       "277     tfidf_277  2.402640e-03\n",
       "258     tfidf_258  2.399866e-03\n",
       "398      dry eyes  2.372510e-03\n",
       "231     tfidf_231  2.349160e-03\n",
       "418     talkative  2.343902e-03\n",
       "432        coffee  2.337457e-03\n",
       "230     tfidf_230  2.317166e-03\n",
       "53       tfidf_53  2.313963e-03\n",
       "406        giggly  2.298760e-03\n",
       "124     tfidf_124  2.298622e-03\n",
       "236     tfidf_236  2.290692e-03\n",
       "319     tfidf_319  2.281411e-03\n",
       "468         woody  2.209281e-03\n",
       "126     tfidf_126  2.203983e-03\n",
       "240     tfidf_240  2.196794e-03\n",
       "107     tfidf_107  2.196094e-03\n",
       "376     tfidf_376  2.177988e-03\n",
       "116     tfidf_116  2.158162e-03\n",
       "271     tfidf_271  2.130248e-03\n",
       "451          pine  2.118871e-03\n",
       "343     tfidf_343  2.112191e-03\n",
       "211     tfidf_211  2.104970e-03\n",
       "340     tfidf_340  2.103430e-03\n",
       "273     tfidf_273  2.067527e-03\n",
       "369     tfidf_369  2.056491e-03\n",
       "289     tfidf_289  2.046363e-03\n",
       "216     tfidf_216  2.045274e-03\n",
       "354     tfidf_354  2.025623e-03\n",
       "34       tfidf_34  2.012529e-03\n",
       "20       tfidf_20  2.006954e-03\n",
       "360     tfidf_360  1.967350e-03\n",
       "193     tfidf_193  1.966443e-03\n",
       "315     tfidf_315  1.940129e-03\n",
       "364     tfidf_364  1.929454e-03\n",
       "291     tfidf_291  1.924556e-03\n",
       "170     tfidf_170  1.908905e-03\n",
       "386     tfidf_386  1.907299e-03\n",
       "336     tfidf_336  1.879643e-03\n",
       "98       tfidf_98  1.868287e-03\n",
       "180     tfidf_180  1.863434e-03\n",
       "349     tfidf_349  1.838577e-03\n",
       "146     tfidf_146  1.836678e-03\n",
       "103     tfidf_103  1.834930e-03\n",
       "393       aroused  1.832401e-03\n",
       "301     tfidf_301  1.803506e-03\n",
       "166     tfidf_166  1.771101e-03\n",
       "346     tfidf_346  1.752237e-03\n",
       "106     tfidf_106  1.738679e-03\n",
       "278     tfidf_278  1.722929e-03\n",
       "442          lime  1.722342e-03\n",
       "246     tfidf_246  1.720847e-03\n",
       "104     tfidf_104  1.718416e-03\n",
       "205     tfidf_205  1.705194e-03\n",
       "466       vanilla  1.697382e-03\n",
       "142     tfidf_142  1.695385e-03\n",
       "458  spicy/herbal  1.673196e-03\n",
       "267     tfidf_267  1.671634e-03\n",
       "380     tfidf_380  1.652051e-03\n",
       "465      tropical  1.639799e-03\n",
       "71       tfidf_71  1.633099e-03\n",
       "263     tfidf_263  1.621636e-03\n",
       "83       tfidf_83  1.621579e-03\n",
       "108     tfidf_108  1.621512e-03\n",
       "32       tfidf_32  1.612261e-03\n",
       "367     tfidf_367  1.609601e-03\n",
       "189     tfidf_189  1.573988e-03\n",
       "320     tfidf_320  1.573350e-03\n",
       "27       tfidf_27  1.553977e-03\n",
       "21       tfidf_21  1.550110e-03\n",
       "282     tfidf_282  1.547443e-03\n",
       "86       tfidf_86  1.546445e-03\n",
       "48       tfidf_48  1.538105e-03\n",
       "270     tfidf_270  1.508087e-03\n",
       "139     tfidf_139  1.505420e-03\n",
       "456          sage  1.500662e-03\n",
       "165     tfidf_165  1.495998e-03\n",
       "247     tfidf_247  1.492655e-03\n",
       "181     tfidf_181  1.491234e-03\n",
       "326     tfidf_326  1.468588e-03\n",
       "123     tfidf_123  1.453665e-03\n",
       "371     tfidf_371  1.452489e-03\n",
       "249     tfidf_249  1.442777e-03\n",
       "325     tfidf_325  1.438692e-03\n",
       "190     tfidf_190  1.432993e-03\n",
       "96       tfidf_96  1.430943e-03\n",
       "117     tfidf_117  1.426578e-03\n",
       "46       tfidf_46  1.418236e-03\n",
       "17       tfidf_17  1.415655e-03\n",
       "118     tfidf_118  1.405621e-03\n",
       "339     tfidf_339  1.399157e-03\n",
       "101     tfidf_101  1.394305e-03\n",
       "374     tfidf_374  1.388729e-03\n",
       "252     tfidf_252  1.375742e-03\n",
       "373     tfidf_373  1.375341e-03\n",
       "217     tfidf_217  1.372730e-03\n",
       "279     tfidf_279  1.367872e-03\n",
       "129     tfidf_129  1.346483e-03\n",
       "159     tfidf_159  1.341284e-03\n",
       "24       tfidf_24  1.336408e-03\n",
       "316     tfidf_316  1.332307e-03\n",
       "81       tfidf_81  1.328389e-03\n",
       "387     tfidf_387  1.325343e-03\n",
       "255     tfidf_255  1.317190e-03\n",
       "64       tfidf_64  1.316308e-03\n",
       "130     tfidf_130  1.306908e-03\n",
       "127     tfidf_127  1.304243e-03\n",
       "26       tfidf_26  1.304118e-03\n",
       "41       tfidf_41  1.286804e-03\n",
       "112     tfidf_112  1.283379e-03\n",
       "206     tfidf_206  1.271095e-03\n",
       "304     tfidf_304  1.267499e-03\n",
       "0         tfidf_0  1.262991e-03\n",
       "3         tfidf_3  1.255733e-03\n",
       "215     tfidf_215  1.233134e-03\n",
       "99       tfidf_99  1.229274e-03\n",
       "61       tfidf_61  1.227436e-03\n",
       "163     tfidf_163  1.222274e-03\n",
       "97       tfidf_97  1.218691e-03\n",
       "151     tfidf_151  1.217957e-03\n",
       "397         dizzy  1.204964e-03\n",
       "194     tfidf_194  1.200308e-03\n",
       "49       tfidf_49  1.195454e-03\n",
       "265     tfidf_265  1.195120e-03\n",
       "222     tfidf_222  1.187605e-03\n",
       "212     tfidf_212  1.180165e-03\n",
       "220     tfidf_220  1.180116e-03\n",
       "221     tfidf_221  1.179307e-03\n",
       "353     tfidf_353  1.171109e-03\n",
       "208     tfidf_208  1.166075e-03\n",
       "184     tfidf_184  1.149386e-03\n",
       "292     tfidf_292  1.146452e-03\n",
       "143     tfidf_143  1.144608e-03\n",
       "19       tfidf_19  1.142525e-03\n",
       "52       tfidf_52  1.135538e-03\n",
       "161     tfidf_161  1.134832e-03\n",
       "321     tfidf_321  1.131892e-03\n",
       "295     tfidf_295  1.130515e-03\n",
       "50       tfidf_50  1.130148e-03\n",
       "75       tfidf_75  1.107494e-03\n",
       "169     tfidf_169  1.107321e-03\n",
       "429      chemical  1.098962e-03\n",
       "288     tfidf_288  1.095616e-03\n",
       "154     tfidf_154  1.094462e-03\n",
       "1         tfidf_1  1.093521e-03\n",
       "63       tfidf_63  1.090399e-03\n",
       "348     tfidf_348  1.084396e-03\n",
       "23       tfidf_23  1.083422e-03\n",
       "275     tfidf_275  1.083047e-03\n",
       "44       tfidf_44  1.082912e-03\n",
       "132     tfidf_132  1.081111e-03\n",
       "125     tfidf_125  1.071294e-03\n",
       "294     tfidf_294  1.049954e-03\n",
       "56       tfidf_56  1.044902e-03\n",
       "209     tfidf_209  1.043651e-03\n",
       "36       tfidf_36  1.043383e-03\n",
       "341     tfidf_341  1.040788e-03\n",
       "157     tfidf_157  1.023309e-03\n",
       "15       tfidf_15  1.005558e-03\n",
       "262     tfidf_262  1.003826e-03\n",
       "269     tfidf_269  1.000305e-03\n",
       "79       tfidf_79  9.996706e-04\n",
       "224     tfidf_224  9.954586e-04\n",
       "147     tfidf_147  9.948652e-04\n",
       "80       tfidf_80  9.914052e-04\n",
       "120     tfidf_120  9.911036e-04\n",
       "45       tfidf_45  9.838963e-04\n",
       "152     tfidf_152  9.824468e-04\n",
       "31       tfidf_31  9.807736e-04\n",
       "109     tfidf_109  9.721322e-04\n",
       "28       tfidf_28  9.684737e-04\n",
       "85       tfidf_85  9.623155e-04\n",
       "223     tfidf_223  9.570238e-04\n",
       "164     tfidf_164  9.427703e-04\n",
       "69       tfidf_69  9.397755e-04\n",
       "105     tfidf_105  9.381363e-04\n",
       "12       tfidf_12  9.359925e-04\n",
       "136     tfidf_136  9.271609e-04\n",
       "251     tfidf_251  9.269223e-04\n",
       "76       tfidf_76  9.263847e-04\n",
       "114     tfidf_114  9.238083e-04\n",
       "54       tfidf_54  9.153787e-04\n",
       "88       tfidf_88  9.140739e-04\n",
       "4         tfidf_4  8.999865e-04\n",
       "381     tfidf_381  8.986345e-04\n",
       "244     tfidf_244  8.970097e-04\n",
       "115     tfidf_115  8.957595e-04\n",
       "84       tfidf_84  8.904686e-04\n",
       "261     tfidf_261  8.874869e-04\n",
       "62       tfidf_62  8.856990e-04\n",
       "35       tfidf_35  8.828380e-04\n",
       "22       tfidf_22  8.780717e-04\n",
       "356     tfidf_356  8.751172e-04\n",
       "237     tfidf_237  8.713477e-04\n",
       "122     tfidf_122  8.698747e-04\n",
       "201     tfidf_201  8.607952e-04\n",
       "450        pepper  8.578187e-04\n",
       "379     tfidf_379  8.573575e-04\n",
       "188     tfidf_188  8.528513e-04\n",
       "226     tfidf_226  8.497319e-04\n",
       "2         tfidf_2  8.486286e-04\n",
       "372     tfidf_372  8.444968e-04\n",
       "297     tfidf_297  8.357651e-04\n",
       "260     tfidf_260  8.277683e-04\n",
       "47       tfidf_47  8.265738e-04\n",
       "148     tfidf_148  8.264475e-04\n",
       "328     tfidf_328  8.181086e-04\n",
       "176     tfidf_176  8.165893e-04\n",
       "350     tfidf_350  8.031109e-04\n",
       "318     tfidf_318  8.014959e-04\n",
       "254     tfidf_254  7.981132e-04\n",
       "182     tfidf_182  7.910313e-04\n",
       "286     tfidf_286  7.900887e-04\n",
       "131     tfidf_131  7.881075e-04\n",
       "177     tfidf_177  7.873170e-04\n",
       "219     tfidf_219  7.871711e-04\n",
       "435       flowery  7.718503e-04\n",
       "183     tfidf_183  7.700287e-04\n",
       "218     tfidf_218  7.605469e-04\n",
       "58       tfidf_58  7.573189e-04\n",
       "229     tfidf_229  7.538503e-04\n",
       "197     tfidf_197  7.501841e-04\n",
       "198     tfidf_198  7.473438e-04\n",
       "443         mango  7.472319e-04\n",
       "317     tfidf_317  7.364847e-04\n",
       "259     tfidf_259  7.290879e-04\n",
       "358     tfidf_358  7.275010e-04\n",
       "192     tfidf_192  7.269390e-04\n",
       "284     tfidf_284  7.228744e-04\n",
       "186     tfidf_186  7.211699e-04\n",
       "202     tfidf_202  7.199241e-04\n",
       "363     tfidf_363  7.140342e-04\n",
       "327     tfidf_327  7.094848e-04\n",
       "368     tfidf_368  7.035277e-04\n",
       "310     tfidf_310  7.016720e-04\n",
       "370     tfidf_370  7.009311e-04\n",
       "68       tfidf_68  6.885581e-04\n",
       "13       tfidf_13  6.859858e-04\n",
       "102     tfidf_102  6.783643e-04\n",
       "91       tfidf_91  6.775488e-04\n",
       "10       tfidf_10  6.754252e-04\n",
       "233     tfidf_233  6.752600e-04\n",
       "187     tfidf_187  6.737401e-04\n",
       "111     tfidf_111  6.686434e-04\n",
       "347     tfidf_347  6.684559e-04\n",
       "133     tfidf_133  6.579367e-04\n",
       "42       tfidf_42  6.573146e-04\n",
       "185     tfidf_185  6.567716e-04\n",
       "311     tfidf_311  6.560951e-04\n",
       "266     tfidf_266  6.552280e-04\n",
       "322     tfidf_322  6.535404e-04\n",
       "344     tfidf_344  6.525390e-04\n",
       "274     tfidf_274  6.446913e-04\n",
       "57       tfidf_57  6.418363e-04\n",
       "332     tfidf_332  6.303845e-04\n",
       "305     tfidf_305  6.229826e-04\n",
       "196     tfidf_196  6.219876e-04\n",
       "195     tfidf_195  6.212928e-04\n",
       "412      paranoid  6.203295e-04\n",
       "440      lavender  5.984033e-04\n",
       "287     tfidf_287  5.974266e-04\n",
       "227     tfidf_227  5.961844e-04\n",
       "140     tfidf_140  5.885368e-04\n",
       "446         nutty  5.868948e-04\n",
       "385     tfidf_385  5.855037e-04\n",
       "59       tfidf_59  5.788673e-04\n",
       "392       anxious  5.784043e-04\n",
       "160     tfidf_160  5.491717e-04\n",
       "65       tfidf_65  5.439619e-04\n",
       "235     tfidf_235  5.429223e-04\n",
       "408      headache  5.411621e-04\n",
       "324     tfidf_324  5.357947e-04\n",
       "438    grapefruit  5.346014e-04\n",
       "257     tfidf_257  5.215954e-04\n",
       "214     tfidf_214  5.167318e-04\n",
       "94       tfidf_94  5.158937e-04\n",
       "377     tfidf_377  5.133591e-04\n",
       "256     tfidf_256  5.115375e-04\n",
       "77       tfidf_77  5.063459e-04\n",
       "383     tfidf_383  5.051258e-04\n",
       "228     tfidf_228  5.014358e-04\n",
       "174     tfidf_174  4.927756e-04\n",
       "298     tfidf_298  4.919887e-04\n",
       "67       tfidf_67  4.903663e-04\n",
       "25       tfidf_25  4.873100e-04\n",
       "307     tfidf_307  4.872507e-04\n",
       "334     tfidf_334  4.840911e-04\n",
       "33       tfidf_33  4.833316e-04\n",
       "225     tfidf_225  4.825851e-04\n",
       "204     tfidf_204  4.817633e-04\n",
       "280     tfidf_280  4.797200e-04\n",
       "436         fruit  4.794423e-04\n",
       "18       tfidf_18  4.774984e-04\n",
       "172     tfidf_172  4.721940e-04\n",
       "138     tfidf_138  4.682167e-04\n",
       "234     tfidf_234  4.581775e-04\n",
       "243     tfidf_243  4.519303e-04\n",
       "213     tfidf_213  4.423894e-04\n",
       "179     tfidf_179  4.342165e-04\n",
       "306     tfidf_306  4.290777e-04\n",
       "134     tfidf_134  4.282850e-04\n",
       "29       tfidf_29  4.268448e-04\n",
       "137     tfidf_137  4.227149e-04\n",
       "352     tfidf_352  4.167872e-04\n",
       "365     tfidf_365  4.145407e-04\n",
       "268     tfidf_268  4.122158e-04\n",
       "156     tfidf_156  4.107260e-04\n",
       "384     tfidf_384  4.035283e-04\n",
       "55       tfidf_55  3.982937e-04\n",
       "238     tfidf_238  3.973690e-04\n",
       "232     tfidf_232  3.946523e-04\n",
       "464          tree  3.886166e-04\n",
       "300     tfidf_300  3.829302e-04\n",
       "463       tobacco  3.821457e-04\n",
       "150     tfidf_150  3.792401e-04\n",
       "313     tfidf_313  3.773625e-04\n",
       "248     tfidf_248  3.715401e-04\n",
       "302     tfidf_302  3.707379e-04\n",
       "293     tfidf_293  3.670483e-04\n",
       "66       tfidf_66  3.634284e-04\n",
       "308     tfidf_308  3.593237e-04\n",
       "276     tfidf_276  3.537274e-04\n",
       "72       tfidf_72  3.520738e-04\n",
       "333     tfidf_333  3.491990e-04\n",
       "74       tfidf_74  3.463848e-04\n",
       "51       tfidf_51  3.335896e-04\n",
       "14       tfidf_14  3.305763e-04\n",
       "331     tfidf_331  3.300439e-04\n",
       "242     tfidf_242  3.289466e-04\n",
       "87       tfidf_87  3.261528e-04\n",
       "299     tfidf_299  3.063973e-04\n",
       "359     tfidf_359  3.052390e-04\n",
       "89       tfidf_89  3.026584e-04\n",
       "191     tfidf_191  3.010939e-04\n",
       "8         tfidf_8  2.941955e-04\n",
       "330     tfidf_330  2.902407e-04\n",
       "92       tfidf_92  2.804499e-04\n",
       "378     tfidf_378  2.784009e-04\n",
       "38       tfidf_38  2.731954e-04\n",
       "361     tfidf_361  2.709754e-04\n",
       "375     tfidf_375  2.620596e-04\n",
       "455          rose  2.576635e-04\n",
       "452     pineapple  2.536654e-04\n",
       "155     tfidf_155  2.477795e-04\n",
       "40       tfidf_40  2.466212e-04\n",
       "70       tfidf_70  2.465676e-04\n",
       "290     tfidf_290  2.445507e-04\n",
       "335     tfidf_335  2.395274e-04\n",
       "296     tfidf_296  2.331982e-04\n",
       "241     tfidf_241  2.264831e-04\n",
       "351     tfidf_351  2.113342e-04\n",
       "453          plum  2.089134e-04\n",
       "462           tea  2.079756e-04\n",
       "444       menthol  1.979514e-04\n",
       "60       tfidf_60  1.906496e-04\n",
       "439         honey  1.771867e-04\n",
       "100     tfidf_100  1.639909e-04\n",
       "430      chestnut  1.551446e-04\n",
       "95       tfidf_95  1.549289e-04\n",
       "421       ammonia  1.531370e-04\n",
       "461           tar  1.329332e-04\n",
       "113     tfidf_113  1.320782e-04\n",
       "422         apple  6.596237e-05\n",
       "250     tfidf_250  6.518208e-05\n",
       "423       apricot  5.937191e-05\n",
       "467        violet  5.435372e-05\n",
       "448         peach  4.328522e-05\n",
       "396    depression  3.834170e-05\n",
       "410     migraines  3.521216e-05\n",
       "449          pear  3.114162e-05\n",
       "391       anxiety  2.518997e-05\n",
       "425   blue cheese  1.178549e-05\n",
       "411          pain  2.028097e-08\n",
       "404       fatigue  1.305318e-08\n",
       "414      seizures  5.473437e-09\n",
       "401      epilepsy  8.180816e-10\n",
       "403  eye pressure  1.246061e-10\n",
       "417        stress  0.000000e+00\n",
       "416    spasticity  0.000000e+00\n",
       "394     arthritis  0.000000e+00"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.set_option('display.max_rows', df_feat_ranked.shape[0]+1)\n",
    "df_feat_ranked"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/andalanputra/opt/anaconda3/lib/python3.9/site-packages/sklearn/feature_selection/_from_model.py:357: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  self.estimator_.fit(X, y, **fit_params)\n"
     ]
    }
   ],
   "source": [
    "selector = SelectFromModel(rfreg).fit(X_train1, y_train1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1.28505435e-03, 1.05281616e-03, 8.00033088e-04, 1.24961745e-03,\n",
       "       8.23825518e-04, 2.66582549e-03, 5.70856167e-03, 3.16183743e-03,\n",
       "       2.75203503e-04, 2.67745160e-03, 8.85476616e-04, 3.75555835e-03,\n",
       "       1.02041047e-03, 6.58686694e-04, 3.47731882e-04, 1.00194414e-03,\n",
       "       3.40867964e-03, 1.46580088e-03, 5.92324584e-04, 1.03472197e-03,\n",
       "       1.77056430e-03, 1.21545321e-03, 8.85513844e-04, 1.07920835e-03,\n",
       "       1.57234511e-03, 4.49121598e-04, 1.25946385e-03, 1.50898033e-03,\n",
       "       9.50884921e-04, 3.71415255e-04, 5.11135255e-03, 9.60080838e-04,\n",
       "       1.69100364e-03, 4.79693721e-04, 1.77737362e-03, 8.44738992e-04,\n",
       "       1.23797062e-03, 4.25769248e-03, 2.78175075e-04, 2.00580352e-03,\n",
       "       2.75670178e-04, 1.41499240e-03, 7.27272224e-04, 5.50281816e-03,\n",
       "       1.06776750e-03, 9.29742527e-04, 1.37729536e-03, 8.00315320e-04,\n",
       "       1.59254188e-03, 1.12070187e-03, 9.94667473e-04, 3.86394688e-04,\n",
       "       1.35382993e-03, 2.22713538e-03, 9.01807810e-04, 3.59167846e-04,\n",
       "       9.37976596e-04, 6.34198850e-04, 6.05814768e-04, 5.60837945e-04,\n",
       "       1.56811795e-04, 1.38317472e-03, 1.03935353e-03, 1.11028394e-03,\n",
       "       1.18546586e-03, 5.70338143e-04, 3.67444199e-04, 4.06765443e-04,\n",
       "       6.41854061e-04, 9.16924882e-04, 2.69132382e-04, 1.72151513e-03,\n",
       "       3.10247135e-04, 3.51235732e-03, 3.63994832e-04, 1.16848289e-03,\n",
       "       9.09840481e-04, 4.54909929e-04, 3.23805122e-03, 9.68537308e-04,\n",
       "       9.75766024e-04, 1.47165735e-03, 4.02136717e-03, 1.65543684e-03,\n",
       "       9.15583127e-04, 8.26644218e-04, 1.51993741e-03, 3.59144071e-04,\n",
       "       1.09290605e-03, 3.40371312e-04, 4.23745671e-03, 7.48216591e-04,\n",
       "       2.77650744e-04, 3.03036670e-03, 4.95833640e-04, 2.01507275e-04,\n",
       "       1.18045455e-03, 1.31980097e-03, 2.02150220e-03, 1.04736626e-03,\n",
       "       1.97454863e-04, 1.48511316e-03, 7.36328356e-04, 1.70861625e-03,\n",
       "       1.48331893e-03, 8.58144766e-04, 1.79801525e-03, 2.24871694e-03,\n",
       "       1.63670161e-03, 1.00640091e-03, 2.45227531e-03, 6.43578962e-04,\n",
       "       9.91351320e-04, 1.91580576e-04, 1.15469396e-03, 9.05936400e-04,\n",
       "       2.14792123e-03, 1.48881783e-03, 1.40153625e-03, 4.06186791e-03,\n",
       "       1.04596690e-03, 5.67268066e-03, 6.78647591e-04, 1.42558473e-03,\n",
       "       2.32460753e-03, 1.02686861e-03, 2.15395150e-03, 1.36898765e-03,\n",
       "       2.89246164e-03, 1.38720635e-03, 1.33153091e-03, 8.70376900e-04,\n",
       "       1.20794225e-03, 5.81470829e-04, 3.18635689e-04, 2.58088217e-03,\n",
       "       1.04862514e-03, 4.27822335e-04, 4.60206515e-04, 1.33843923e-03,\n",
       "       5.28987857e-04, 7.09685340e-03, 1.71812373e-03, 1.20440072e-03,\n",
       "       2.83168201e-03, 1.08254875e-02, 1.91146088e-03, 1.05917130e-03,\n",
       "       8.70283702e-04, 9.59126179e-03, 4.21617770e-04, 1.24295650e-03,\n",
       "       1.02745314e-03, 3.21233057e-03, 1.10372748e-03, 2.55283980e-04,\n",
       "       4.47543419e-04, 1.07407489e-03, 4.31838144e-03, 1.56201875e-03,\n",
       "       5.51082943e-04, 1.08397300e-03, 2.91540485e-03, 1.13061346e-03,\n",
       "       9.26125757e-04, 1.46629952e-03, 1.70094674e-03, 3.21523146e-03,\n",
       "       1.20285497e-02, 1.05405035e-03, 2.11907091e-03, 2.61441257e-03,\n",
       "       5.01222615e-04, 3.11338975e-03, 4.65402236e-04, 3.02650479e-03,\n",
       "       8.00116180e-04, 7.04443662e-04, 4.57155551e-03, 3.37221609e-04,\n",
       "       1.67490221e-03, 1.41239967e-03, 7.51812969e-04, 6.00883524e-04,\n",
       "       1.14696887e-03, 6.55085672e-04, 7.54957747e-04, 6.63209850e-04,\n",
       "       8.67810655e-04, 1.49816474e-03, 1.34016455e-03, 2.65942036e-04,\n",
       "       7.21772894e-04, 1.78482021e-03, 1.21455340e-03, 5.68684985e-04,\n",
       "       5.98312237e-04, 8.08368716e-04, 8.95777033e-04, 6.46108288e-03,\n",
       "       2.43675332e-03, 8.51591784e-04, 7.19520396e-04, 2.46040113e-03,\n",
       "       4.68607770e-04, 1.62481954e-03, 1.28979736e-03, 5.42638276e-03,\n",
       "       1.11091728e-03, 1.09122868e-03, 5.55070368e-03, 2.47933893e-03,\n",
       "       1.19614811e-03, 4.59432442e-04, 5.60536881e-04, 1.23853465e-03,\n",
       "       2.03466548e-03, 1.35486378e-03, 6.38369823e-04, 8.80917187e-04,\n",
       "       1.13058108e-03, 1.17095263e-03, 1.23440576e-03, 9.99096495e-04,\n",
       "       1.00392450e-03, 4.84369655e-04, 7.77854023e-04, 6.13716758e-04,\n",
       "       4.93093444e-04, 7.19825985e-04, 2.44042549e-03, 2.32955897e-03,\n",
       "       4.67688522e-04, 6.61708367e-04, 5.19120349e-04, 5.53678344e-04,\n",
       "       2.32732911e-03, 7.74046789e-04, 4.57190239e-04, 6.27949990e-03,\n",
       "       2.56808554e-03, 2.50391556e-04, 2.63288829e-04, 4.54525750e-04,\n",
       "       6.46605953e-04, 5.73475384e-03, 1.75452345e-03, 1.27959486e-03,\n",
       "       3.18329200e-04, 1.60527154e-03, 5.62796666e-05, 8.70663608e-04,\n",
       "       1.44307302e-03, 7.13183184e-03, 7.87421732e-04, 1.50367159e-03,\n",
       "       5.96880042e-04, 5.15984870e-04, 2.43755169e-03, 7.69884523e-04,\n",
       "       8.45784916e-04, 9.60760039e-04, 1.03441745e-03, 1.68450135e-03,\n",
       "       2.59627870e-03, 1.19830263e-03, 5.60460439e-04, 1.66934946e-03,\n",
       "       3.85174559e-04, 8.63869838e-04, 1.56505198e-03, 1.94323024e-03,\n",
       "       1.32746885e-02, 2.06223772e-03, 6.30167801e-04, 1.01098955e-03,\n",
       "       3.90087174e-04, 2.52921827e-03, 1.62515283e-03, 1.46901480e-03,\n",
       "       4.94265035e-04, 5.58380531e-03, 1.45293380e-03, 2.87938439e-03,\n",
       "       7.82414678e-04, 7.08332662e-03, 6.61826690e-04, 5.87540851e-04,\n",
       "       1.09342638e-03, 1.86328341e-03, 2.37544113e-04, 1.83463308e-03,\n",
       "       1.13672845e-03, 3.91218512e-04, 1.16366032e-03, 1.16499656e-03,\n",
       "       2.68652883e-04, 9.04200634e-04, 4.86351141e-04, 2.50383446e-04,\n",
       "       4.21358123e-04, 1.74535462e-03, 4.25553658e-04, 3.22850058e-03,\n",
       "       1.30208902e-03, 6.10714072e-04, 5.02975564e-04, 4.30864891e-04,\n",
       "       3.83964422e-04, 6.55524624e-03, 6.00464446e-04, 6.44137274e-04,\n",
       "       8.63620883e-03, 4.44795198e-04, 2.69056516e-03, 1.96002425e-03,\n",
       "       1.13140593e-03, 7.52646258e-04, 9.46247698e-04, 2.28257412e-03,\n",
       "       1.43188703e-03, 1.09940047e-03, 6.62499998e-04, 2.34986037e-03,\n",
       "       4.98214222e-04, 1.61486680e-03, 1.43146061e-03, 6.45345171e-04,\n",
       "       7.16674257e-04, 1.75720351e-02, 3.08819007e-04, 3.07321284e-04,\n",
       "       7.23076805e-04, 3.33337351e-04, 6.46732092e-04, 2.31676724e-04,\n",
       "       1.99462517e-03, 3.29995633e-03, 3.03685110e-03, 1.54609294e-03,\n",
       "       2.00396507e-03, 9.53969481e-04, 4.27596032e-03, 2.17135355e-03,\n",
       "       6.61723457e-04, 9.88534621e-03, 2.06697941e-03, 6.41928702e-04,\n",
       "       1.16701362e-03, 1.75841392e-03, 8.31451915e-04, 1.79541662e-04,\n",
       "       4.03226967e-04, 1.14644395e-03, 2.09813645e-03, 2.94252785e-03,\n",
       "       7.97601729e-04, 6.73018240e-03, 7.68922945e-04, 2.73981196e-04,\n",
       "       1.94934761e-03, 2.78650420e-04, 3.02471275e-03, 6.66453468e-04,\n",
       "       1.80975706e-03, 3.91800786e-04, 4.50803813e-03, 1.70650863e-03,\n",
       "       7.74353762e-04, 2.03315601e-03, 6.50341989e-04, 1.69518642e-03,\n",
       "       8.35816039e-04, 1.52722207e-03, 1.41334203e-03, 2.81745943e-04,\n",
       "       2.16294020e-03, 5.79567290e-04, 2.91595475e-04, 7.79701357e-04,\n",
       "       1.66066323e-03, 8.79550055e-04, 3.18654574e-03, 3.74356080e-04,\n",
       "       3.73426684e-04, 6.27128805e-04, 1.75712977e-03, 1.23681033e-03,\n",
       "       3.70655761e-02, 2.41091136e-02, 7.11394112e-03, 2.49465882e-05,\n",
       "       5.77629404e-04, 1.90919090e-03, 1.44211509e-10, 3.49521270e-03,\n",
       "       1.46390403e-05, 1.21937127e-03, 2.54181954e-03, 3.20913620e-03,\n",
       "       3.21597903e-03, 0.00000000e+00, 4.54676023e-03, 4.58723793e-10,\n",
       "       1.72085310e-10, 3.05609270e-03, 2.46135290e-03, 4.12431334e-03,\n",
       "       5.99560602e-04, 3.35252888e-03, 2.73085254e-05, 0.00000000e+00,\n",
       "       5.39196551e-04, 5.49879862e-03, 0.00000000e+00, 2.39321017e-03,\n",
       "       0.00000000e+00, 0.00000000e+00, 2.39827121e-03, 3.18340107e-03,\n",
       "       4.46546999e-03, 1.90840885e-04, 6.69897359e-05, 3.15600284e-05,\n",
       "       3.74364675e-03, 1.57971082e-05, 8.52468276e-03, 2.56256582e-03,\n",
       "       3.14016302e-03, 1.19506102e-03, 1.64213746e-04, 9.62334609e-03,\n",
       "       2.32652176e-03, 1.47984106e-01, 6.54616713e-03, 9.15142361e-04,\n",
       "       4.79273333e-04, 4.73580331e-03, 5.32969302e-04, 2.58676276e-04,\n",
       "       5.48600242e-04, 1.05915343e-02, 1.66214247e-03, 7.38544798e-04,\n",
       "       1.87608823e-04, 2.75587665e-03, 5.08466355e-04, 6.14779093e-03,\n",
       "       3.94602995e-05, 3.54901416e-05, 7.44784921e-04, 2.11048695e-03,\n",
       "       2.44766459e-04, 2.46567792e-04, 3.37824441e-03, 2.98020688e-04,\n",
       "       1.48678926e-03, 5.36156477e-03, 1.83149422e-03, 6.68821597e-03,\n",
       "       3.40630628e-03, 1.40758055e-04, 2.83770409e-04, 4.63222968e-04,\n",
       "       3.45132781e-04, 1.65435607e-03, 1.72129821e-03, 7.39589421e-05,\n",
       "       2.00447160e-03])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "selector.estimator_.feature_importances_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0021321961620469083"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "selector.threshold_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "mask = selector.get_support()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([False, False, False, False, False,  True,  True,  True, False,\n",
       "        True, False,  True, False, False, False, False,  True, False,\n",
       "       False, False, False, False, False, False, False, False, False,\n",
       "       False, False, False,  True, False, False, False, False, False,\n",
       "       False,  True, False, False, False, False, False,  True, False,\n",
       "       False, False, False, False, False, False, False, False,  True,\n",
       "       False, False, False, False, False, False, False, False, False,\n",
       "       False, False, False, False, False, False, False, False, False,\n",
       "       False,  True, False, False, False, False,  True, False, False,\n",
       "       False,  True, False, False, False, False, False, False, False,\n",
       "        True, False, False,  True, False, False, False, False, False,\n",
       "       False, False, False, False, False, False, False, False,  True,\n",
       "       False, False,  True, False, False, False, False, False,  True,\n",
       "       False, False,  True, False,  True, False, False,  True, False,\n",
       "        True, False,  True, False, False, False, False, False, False,\n",
       "        True, False, False, False, False, False,  True, False, False,\n",
       "        True,  True, False, False, False,  True, False, False, False,\n",
       "        True, False, False, False, False,  True, False, False, False,\n",
       "        True, False, False, False, False,  True,  True, False, False,\n",
       "        True, False,  True, False,  True, False, False,  True, False,\n",
       "       False, False, False, False, False, False, False, False, False,\n",
       "       False, False, False, False, False, False, False, False, False,\n",
       "       False,  True,  True, False, False,  True, False, False, False,\n",
       "        True, False, False,  True,  True, False, False, False, False,\n",
       "       False, False, False, False, False, False, False, False, False,\n",
       "       False, False, False, False, False,  True,  True, False, False,\n",
       "       False, False,  True, False, False,  True,  True, False, False,\n",
       "       False, False,  True, False, False, False, False, False, False,\n",
       "       False,  True, False, False, False, False,  True, False, False,\n",
       "       False, False, False,  True, False, False, False, False, False,\n",
       "       False, False,  True, False, False, False, False,  True, False,\n",
       "       False, False,  True, False,  True, False,  True, False, False,\n",
       "       False, False, False, False, False, False, False, False, False,\n",
       "       False, False, False, False, False, False,  True, False, False,\n",
       "       False, False, False,  True, False, False,  True, False,  True,\n",
       "       False, False, False, False,  True, False, False, False,  True,\n",
       "       False, False, False, False, False,  True, False, False, False,\n",
       "       False, False, False, False,  True,  True, False, False, False,\n",
       "        True,  True, False,  True, False, False, False, False, False,\n",
       "       False, False, False, False,  True, False,  True, False, False,\n",
       "       False, False,  True, False, False, False,  True, False, False,\n",
       "       False, False, False, False, False, False, False,  True, False,\n",
       "       False, False, False, False,  True, False, False, False, False,\n",
       "       False,  True,  True,  True, False, False, False, False,  True,\n",
       "       False, False,  True,  True,  True, False,  True, False, False,\n",
       "        True,  True,  True, False,  True, False, False, False,  True,\n",
       "       False,  True, False, False,  True,  True,  True, False, False,\n",
       "       False,  True, False,  True,  True,  True, False, False,  True,\n",
       "        True,  True,  True, False, False,  True, False, False, False,\n",
       "        True, False, False, False,  True, False,  True, False, False,\n",
       "       False, False, False, False,  True, False, False,  True, False,\n",
       "        True,  True, False, False, False, False, False, False, False,\n",
       "       False])"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "selected_features = X.columns[mask]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tfidf_5</th>\n",
       "      <th>tfidf_6</th>\n",
       "      <th>tfidf_7</th>\n",
       "      <th>tfidf_9</th>\n",
       "      <th>tfidf_11</th>\n",
       "      <th>tfidf_16</th>\n",
       "      <th>tfidf_30</th>\n",
       "      <th>tfidf_37</th>\n",
       "      <th>tfidf_43</th>\n",
       "      <th>tfidf_53</th>\n",
       "      <th>...</th>\n",
       "      <th>diesel</th>\n",
       "      <th>earthy</th>\n",
       "      <th>grape</th>\n",
       "      <th>lemon</th>\n",
       "      <th>mint</th>\n",
       "      <th>orange</th>\n",
       "      <th>pungent</th>\n",
       "      <th>skunk</th>\n",
       "      <th>strawberry</th>\n",
       "      <th>sweet</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.14162</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.198545</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.198545</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.145484</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.433694</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>74995</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>74996</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>74997</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>74998</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>74999</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>75000 rows × 108 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        tfidf_5  tfidf_6  tfidf_7  tfidf_9  tfidf_11  tfidf_16  tfidf_30  \\\n",
       "0      0.000000      0.0      0.0      0.0       0.0       0.0       0.0   \n",
       "1      0.000000      0.0      0.0      0.0       0.0       0.0       0.0   \n",
       "2      0.000000      0.0      0.0      0.0       0.0       0.0       0.0   \n",
       "3      0.000000      0.0      0.0      0.0       0.0       0.0       0.0   \n",
       "4      0.145484      0.0      0.0      0.0       0.0       0.0       0.0   \n",
       "...         ...      ...      ...      ...       ...       ...       ...   \n",
       "74995  0.000000      0.0      0.0      0.0       0.0       0.0       0.0   \n",
       "74996  0.000000      0.0      0.0      0.0       0.0       0.0       0.0   \n",
       "74997  0.000000      0.0      0.0      0.0       0.0       0.0       0.0   \n",
       "74998  0.000000      0.0      0.0      0.0       0.0       0.0       0.0   \n",
       "74999  0.000000      0.0      0.0      0.0       0.0       0.0       0.0   \n",
       "\n",
       "       tfidf_37  tfidf_43  tfidf_53  ...  diesel  earthy  grape  lemon  mint  \\\n",
       "0       0.14162  0.000000  0.000000  ...       0       0      0      0     0   \n",
       "1       0.00000  0.000000  0.000000  ...       0       0      0      0     0   \n",
       "2       0.00000  0.198545  0.000000  ...       0       0      0      0     0   \n",
       "3       0.00000  0.198545  0.000000  ...       0       0      0      0     0   \n",
       "4       0.00000  0.000000  0.433694  ...       0       0      1      0     0   \n",
       "...         ...       ...       ...  ...     ...     ...    ...    ...   ...   \n",
       "74995   0.00000  0.000000  0.000000  ...       0       0      0      0     0   \n",
       "74996   0.00000  0.000000  0.000000  ...       0       0      0      0     0   \n",
       "74997   0.00000  0.000000  0.000000  ...       1       1      1      1     1   \n",
       "74998   0.00000  0.000000  0.000000  ...       1       1      1      1     1   \n",
       "74999   0.00000  0.000000  0.000000  ...       1       1      1      1     1   \n",
       "\n",
       "       orange  pungent  skunk  strawberry  sweet  \n",
       "0           0        0      0           0      0  \n",
       "1           0        0      0           0      0  \n",
       "2           0        0      0           0      1  \n",
       "3           0        0      0           0      1  \n",
       "4           0        0      0           0      0  \n",
       "...       ...      ...    ...         ...    ...  \n",
       "74995       0        0      0           0      0  \n",
       "74996       0        0      0           0      0  \n",
       "74997       1        1      1           1      1  \n",
       "74998       1        1      1           1      1  \n",
       "74999       1        1      1           1      1  \n",
       "\n",
       "[75000 rows x 108 columns]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "selected_X = df_rf[selected_features]\n",
    "selected_X"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train test split (after Feature Selection)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['selected_X_rf_tfidf_dlim.pkl']"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import joblib\n",
    "\n",
    "joblib.dump(selector, \"selector_rf_tfidf_dlim.pkl\")\n",
    "joblib.dump(selected_X, \"selected_X_rf_tfidf_dlim.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(selected_X, y, random_state=1, test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train1, X_val, y_train1, y_val = train_test_split(X_train, y_train, random_state=1, test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/y1/pjvjlkjn5gl846rnyzr53p340000gn/T/ipykernel_9372/3758305.py:1: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  rfreg.fit(X_train1, y_train1)\n"
     ]
    }
   ],
   "source": [
    "rfreg.fit(X_train1, y_train1)\n",
    "y_pred_rfreg = rfreg.predict(X_val)\n",
    "y_pred_rfreg_r2 = rfreg.predict(X_train1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.05353010230735233"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mean_absolute_error(y_val, y_pred_rfreg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.011840399101837831"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mean_squared_error(y_val, y_pred_rfreg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.10881359796384747"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mean_squared_error(y_val, y_pred_rfreg, squared = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9689397587076154"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#train\n",
    "r2_score(y_train1, y_pred_rfreg_r2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8594696358523164"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#val\n",
    "r2_score(y_val, y_pred_rfreg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hyperparameter Tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "parameters = {'max_depth': [None, 10, 50, 100],\n",
    "              'max_features': ['auto', 'sqrt'],\n",
    "              'min_samples_leaf': [1, 2, 4],\n",
    "              'min_samples_split': [2, 5, 10],\n",
    "              'n_estimators': [100, 300, 500]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "rscv = RandomizedSearchCV(rfreg,  \n",
    "                     parameters,   \n",
    "                     cv=5, \n",
    "                     scoring='neg_mean_absolute_error',\n",
    "                     n_jobs = -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/andalanputra/opt/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/Users/andalanputra/opt/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/Users/andalanputra/opt/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/Users/andalanputra/opt/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/Users/andalanputra/opt/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/Users/andalanputra/opt/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/Users/andalanputra/opt/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/Users/andalanputra/opt/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/Users/andalanputra/opt/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/Users/andalanputra/opt/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/Users/andalanputra/opt/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/Users/andalanputra/opt/anaconda3/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
      "  warn(\n",
      "/Users/andalanputra/opt/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/Users/andalanputra/opt/anaconda3/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
      "  warn(\n",
      "/Users/andalanputra/opt/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/Users/andalanputra/opt/anaconda3/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
      "  warn(\n",
      "/Users/andalanputra/opt/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/Users/andalanputra/opt/anaconda3/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
      "  warn(\n",
      "/Users/andalanputra/opt/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/Users/andalanputra/opt/anaconda3/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
      "  warn(\n",
      "/Users/andalanputra/opt/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/Users/andalanputra/opt/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/Users/andalanputra/opt/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/Users/andalanputra/opt/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/Users/andalanputra/opt/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/Users/andalanputra/opt/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/Users/andalanputra/opt/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/Users/andalanputra/opt/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/Users/andalanputra/opt/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/Users/andalanputra/opt/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/Users/andalanputra/opt/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/Users/andalanputra/opt/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/Users/andalanputra/opt/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/Users/andalanputra/opt/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/Users/andalanputra/opt/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/Users/andalanputra/opt/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/Users/andalanputra/opt/anaconda3/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
      "  warn(\n",
      "/Users/andalanputra/opt/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/Users/andalanputra/opt/anaconda3/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
      "  warn(\n",
      "/Users/andalanputra/opt/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/Users/andalanputra/opt/anaconda3/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
      "  warn(\n",
      "/Users/andalanputra/opt/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/Users/andalanputra/opt/anaconda3/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
      "  warn(\n",
      "/Users/andalanputra/opt/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/Users/andalanputra/opt/anaconda3/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
      "  warn(\n",
      "/Users/andalanputra/opt/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/Users/andalanputra/opt/anaconda3/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
      "  warn(\n",
      "/Users/andalanputra/opt/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/Users/andalanputra/opt/anaconda3/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
      "  warn(\n",
      "/Users/andalanputra/opt/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/Users/andalanputra/opt/anaconda3/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
      "  warn(\n",
      "/Users/andalanputra/opt/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/Users/andalanputra/opt/anaconda3/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
      "  warn(\n",
      "/Users/andalanputra/opt/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/Users/andalanputra/opt/anaconda3/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
      "  warn(\n",
      "/Users/andalanputra/opt/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/Users/andalanputra/opt/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/Users/andalanputra/opt/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/Users/andalanputra/opt/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/Users/andalanputra/opt/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/Users/andalanputra/opt/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/Users/andalanputra/opt/anaconda3/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
      "  warn(\n",
      "/Users/andalanputra/opt/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/Users/andalanputra/opt/anaconda3/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
      "  warn(\n",
      "/Users/andalanputra/opt/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/Users/andalanputra/opt/anaconda3/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
      "  warn(\n",
      "/Users/andalanputra/opt/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/Users/andalanputra/opt/anaconda3/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
      "  warn(\n",
      "/Users/andalanputra/opt/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/Users/andalanputra/opt/anaconda3/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
      "  warn(\n",
      "/Users/andalanputra/opt/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_search.py:909: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  self.best_estimator_.fit(X, y, **fit_params)\n",
      "/Users/andalanputra/opt/anaconda3/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
      "  warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-2 {color: black;background-color: white;}#sk-container-id-2 pre{padding: 0;}#sk-container-id-2 div.sk-toggleable {background-color: white;}#sk-container-id-2 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-2 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-2 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-2 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-2 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-2 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-2 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-2 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-2 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-2 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-2 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-2 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-2 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-2 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-2 div.sk-item {position: relative;z-index: 1;}#sk-container-id-2 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-2 div.sk-item::before, #sk-container-id-2 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-2 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-2 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-2 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-2 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-2 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-2 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-2 div.sk-label-container {text-align: center;}#sk-container-id-2 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-2 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-2\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>RandomizedSearchCV(cv=5, estimator=RandomForestRegressor(), n_jobs=-1,\n",
       "                   param_distributions={&#x27;max_depth&#x27;: [None, 10, 50, 100],\n",
       "                                        &#x27;max_features&#x27;: [&#x27;auto&#x27;, &#x27;sqrt&#x27;],\n",
       "                                        &#x27;min_samples_leaf&#x27;: [1, 2, 4],\n",
       "                                        &#x27;min_samples_split&#x27;: [2, 5, 10],\n",
       "                                        &#x27;n_estimators&#x27;: [100, 300, 500]},\n",
       "                   scoring=&#x27;neg_mean_absolute_error&#x27;)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" ><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">RandomizedSearchCV</label><div class=\"sk-toggleable__content\"><pre>RandomizedSearchCV(cv=5, estimator=RandomForestRegressor(), n_jobs=-1,\n",
       "                   param_distributions={&#x27;max_depth&#x27;: [None, 10, 50, 100],\n",
       "                                        &#x27;max_features&#x27;: [&#x27;auto&#x27;, &#x27;sqrt&#x27;],\n",
       "                                        &#x27;min_samples_leaf&#x27;: [1, 2, 4],\n",
       "                                        &#x27;min_samples_split&#x27;: [2, 5, 10],\n",
       "                                        &#x27;n_estimators&#x27;: [100, 300, 500]},\n",
       "                   scoring=&#x27;neg_mean_absolute_error&#x27;)</pre></div></div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-3\" type=\"checkbox\" ><label for=\"sk-estimator-id-3\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">estimator: RandomForestRegressor</label><div class=\"sk-toggleable__content\"><pre>RandomForestRegressor()</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-4\" type=\"checkbox\" ><label for=\"sk-estimator-id-4\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">RandomForestRegressor</label><div class=\"sk-toggleable__content\"><pre>RandomForestRegressor()</pre></div></div></div></div></div></div></div></div></div></div>"
      ],
      "text/plain": [
       "RandomizedSearchCV(cv=5, estimator=RandomForestRegressor(), n_jobs=-1,\n",
       "                   param_distributions={'max_depth': [None, 10, 50, 100],\n",
       "                                        'max_features': ['auto', 'sqrt'],\n",
       "                                        'min_samples_leaf': [1, 2, 4],\n",
       "                                        'min_samples_split': [2, 5, 10],\n",
       "                                        'n_estimators': [100, 300, 500]},\n",
       "                   scoring='neg_mean_absolute_error')"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rscv.fit(X_train1, y_train1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'n_estimators': 300,\n",
       " 'min_samples_split': 5,\n",
       " 'min_samples_leaf': 2,\n",
       " 'max_features': 'auto',\n",
       " 'max_depth': None}"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rscv.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['rscv_rf_tfidf_best_params_dlim.pkl']"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "joblib.dump(rscv, \"rscv_rf_tfidf_dlim.pkl\")\n",
    "joblib.dump(rscv.best_params_, \"rscv_rf_tfidf_best_params_dlim.pkl\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "RF (after Hyperparameter Tuning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/y1/pjvjlkjn5gl846rnyzr53p340000gn/T/ipykernel_9372/2332686591.py:2: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  rfreg_ht.fit(X_train1, y_train1)\n",
      "/Users/andalanputra/opt/anaconda3/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
      "  warn(\n"
     ]
    }
   ],
   "source": [
    "rfreg_ht = RandomForestRegressor(n_estimators = 300, min_samples_split = 5, min_samples_leaf = 2, max_features = 'auto', max_depth = None)\n",
    "rfreg_ht.fit(X_train1, y_train1)\n",
    "y_pred_rfreg = rfreg_ht.predict(X_val)\n",
    "y_pred_rfreg_r2 = rfreg_ht.predict(X_train1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.06403348946262577"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mean_absolute_error(y_val, y_pred_rfreg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.013195431461751972"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mean_squared_error(y_val, y_pred_rfreg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.11487136919943094"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mean_squared_error(y_val, y_pred_rfreg, squared = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9502306259936719"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#train\n",
    "r2_score(y_train1, y_pred_rfreg_r2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8433871381820248"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#val\n",
    "r2_score(y_val, y_pred_rfreg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Residual plots after Hyperparameter Tuning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Predicting model on the test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_rfreg_test = rfreg_ht.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['y_test_rfreg_tfidf_dlim.pkl']"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "joblib.dump(y_pred_rfreg_test, \"y_pred_rfreg_test_tfidf_dlim.pkl\")\n",
    "joblib.dump(y_test, \"y_test_rfreg_tfidf_dlim.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.06277802290780919"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mean_absolute_error(y_test, y_pred_rfreg_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.01281261080574468"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mean_squared_error(y_test, y_pred_rfreg_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.11319280368355879"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mean_squared_error(y_test, y_pred_rfreg_test, squared = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8499179746235159"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "r2_score(y_test, y_pred_rfreg_test)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Error analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 576x432 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 432x288 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# assume y_pred is a numpy array and y_true is a pandas dataframe\n",
    "fig, ax = plt.subplots(figsize=(8, 6))\n",
    "\n",
    "column = \"X..D-Limonene\"  # specify the target variable name\n",
    "ax.hist(y_pred_rfreg_test, alpha=0.5, label='y_pred', bins=20)\n",
    "ax.hist(y_test[column], alpha=0.5, label='y_true', bins=20)\n",
    "ax.legend(loc='upper right')\n",
    "ax.set_title(column)\n",
    "\n",
    "plt.show()\n",
    "plt.savefig('error_hist_knn_tfidf_dlim.png')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pearson R"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pearson correlation coefficient: 0.926\n",
      "P-value: 0.000\n"
     ]
    }
   ],
   "source": [
    "corr_coef, p_value = pearsonr(y_pred_rfreg_test.flatten(), y_test.values.ravel())\n",
    "\n",
    "print(f\"Pearson correlation coefficient: {corr_coef:.3f}\")\n",
    "print(f\"P-value: {p_value:.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:>"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "corr_matrix = y_test.corr()\n",
    "sns.heatmap(corr_matrix, annot=True, cmap='coolwarm', center=0)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
