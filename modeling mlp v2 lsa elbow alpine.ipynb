{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn import preprocessing\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.neural_network import MLPRegressor\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "from sklearn.metrics import r2_score\n",
    "from scipy.stats import pearsonr\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.feature_selection import SelectFromModel\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compiling complete dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_mlp = pd.read_csv(\"df_alpine_lsa.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>lsa_0</th>\n",
       "      <th>lsa_1</th>\n",
       "      <th>lsa_2</th>\n",
       "      <th>lsa_3</th>\n",
       "      <th>lsa_4</th>\n",
       "      <th>hybrid</th>\n",
       "      <th>indica</th>\n",
       "      <th>sativa</th>\n",
       "      <th>anxiety</th>\n",
       "      <th>...</th>\n",
       "      <th>sweet</th>\n",
       "      <th>tar</th>\n",
       "      <th>tea</th>\n",
       "      <th>tobacco</th>\n",
       "      <th>tree</th>\n",
       "      <th>tropical</th>\n",
       "      <th>vanilla</th>\n",
       "      <th>violet</th>\n",
       "      <th>woody</th>\n",
       "      <th>X..Alpha-Pinene</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0.341025</td>\n",
       "      <td>0.182753</td>\n",
       "      <td>0.008214</td>\n",
       "      <td>0.140406</td>\n",
       "      <td>-0.156943</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.106952</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0.341025</td>\n",
       "      <td>0.182753</td>\n",
       "      <td>0.008214</td>\n",
       "      <td>0.140406</td>\n",
       "      <td>-0.156943</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.106952</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>0.232158</td>\n",
       "      <td>-0.045496</td>\n",
       "      <td>0.187131</td>\n",
       "      <td>-0.000936</td>\n",
       "      <td>0.018518</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.106952</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2</td>\n",
       "      <td>0.261225</td>\n",
       "      <td>0.100324</td>\n",
       "      <td>-0.043622</td>\n",
       "      <td>0.141860</td>\n",
       "      <td>-0.034786</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.106952</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3</td>\n",
       "      <td>0.243491</td>\n",
       "      <td>0.034313</td>\n",
       "      <td>0.080290</td>\n",
       "      <td>-0.165609</td>\n",
       "      <td>0.019773</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.106952</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59995</th>\n",
       "      <td>42967</td>\n",
       "      <td>0.175310</td>\n",
       "      <td>0.233013</td>\n",
       "      <td>0.002148</td>\n",
       "      <td>0.114778</td>\n",
       "      <td>0.056574</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.021390</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59996</th>\n",
       "      <td>42970</td>\n",
       "      <td>0.440634</td>\n",
       "      <td>-0.078839</td>\n",
       "      <td>0.085152</td>\n",
       "      <td>0.087878</td>\n",
       "      <td>-0.133604</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.021390</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59997</th>\n",
       "      <td>42971</td>\n",
       "      <td>0.184573</td>\n",
       "      <td>-0.137296</td>\n",
       "      <td>-0.095301</td>\n",
       "      <td>0.181735</td>\n",
       "      <td>-0.042683</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.021390</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59998</th>\n",
       "      <td>42973</td>\n",
       "      <td>0.055494</td>\n",
       "      <td>0.003622</td>\n",
       "      <td>-0.050252</td>\n",
       "      <td>-0.024795</td>\n",
       "      <td>-0.031141</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.021390</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59999</th>\n",
       "      <td>42974</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.021390</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>60000 rows × 88 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       index     lsa_0     lsa_1     lsa_2     lsa_3     lsa_4  hybrid  \\\n",
       "0          0  0.341025  0.182753  0.008214  0.140406 -0.156943       1   \n",
       "1          0  0.341025  0.182753  0.008214  0.140406 -0.156943       1   \n",
       "2          1  0.232158 -0.045496  0.187131 -0.000936  0.018518       1   \n",
       "3          2  0.261225  0.100324 -0.043622  0.141860 -0.034786       1   \n",
       "4          3  0.243491  0.034313  0.080290 -0.165609  0.019773       1   \n",
       "...      ...       ...       ...       ...       ...       ...     ...   \n",
       "59995  42967  0.175310  0.233013  0.002148  0.114778  0.056574       0   \n",
       "59996  42970  0.440634 -0.078839  0.085152  0.087878 -0.133604       0   \n",
       "59997  42971  0.184573 -0.137296 -0.095301  0.181735 -0.042683       0   \n",
       "59998  42973  0.055494  0.003622 -0.050252 -0.024795 -0.031141       0   \n",
       "59999  42974  0.000000  0.000000  0.000000  0.000000  0.000000       0   \n",
       "\n",
       "       indica  sativa  anxiety  ...  sweet  tar  tea  tobacco  tree  tropical  \\\n",
       "0           0       0        0  ...      0    0    0        0     0         0   \n",
       "1           0       0        0  ...      0    0    0        0     0         0   \n",
       "2           0       0        0  ...      0    0    0        0     0         0   \n",
       "3           0       0        0  ...      1    0    0        0     0         0   \n",
       "4           0       0        0  ...      0    1    0        0     0         0   \n",
       "...       ...     ...      ...  ...    ...  ...  ...      ...   ...       ...   \n",
       "59995       1       0        0  ...      0    0    0        0     0         0   \n",
       "59996       1       0        0  ...      0    0    0        0     0         0   \n",
       "59997       1       0        0  ...      0    0    0        0     0         0   \n",
       "59998       1       0        0  ...      0    0    0        0     0         0   \n",
       "59999       1       0        0  ...      0    0    0        0     0         0   \n",
       "\n",
       "       vanilla  violet  woody  X..Alpha-Pinene  \n",
       "0            0       0      0         0.106952  \n",
       "1            0       0      0         0.106952  \n",
       "2            1       0      0         0.106952  \n",
       "3            1       0      0         0.106952  \n",
       "4            0       0      0         0.106952  \n",
       "...        ...     ...    ...              ...  \n",
       "59995        0       0      0         0.021390  \n",
       "59996        0       0      0         0.021390  \n",
       "59997        0       0      0         0.021390  \n",
       "59998        0       0      0         0.021390  \n",
       "59999        0       0      0         0.021390  \n",
       "\n",
       "[60000 rows x 88 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_mlp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['index',\n",
       " 'lsa_0',\n",
       " 'lsa_1',\n",
       " 'lsa_2',\n",
       " 'lsa_3',\n",
       " 'lsa_4',\n",
       " 'hybrid',\n",
       " 'indica',\n",
       " 'sativa',\n",
       " 'anxiety',\n",
       " 'anxious',\n",
       " 'aroused',\n",
       " 'arthritis',\n",
       " 'creative',\n",
       " 'depression',\n",
       " 'dizzy',\n",
       " 'dry eyes',\n",
       " 'dry mouth',\n",
       " 'energetic',\n",
       " 'epilepsy',\n",
       " 'euphoric',\n",
       " 'eye pressure',\n",
       " 'fatigue',\n",
       " 'focused',\n",
       " 'giggly',\n",
       " 'happy',\n",
       " 'headache',\n",
       " 'hungry',\n",
       " 'migraines',\n",
       " 'pain',\n",
       " 'paranoid',\n",
       " 'relaxed',\n",
       " 'seizures',\n",
       " 'sleepy',\n",
       " 'spasticity',\n",
       " 'stress',\n",
       " 'talkative',\n",
       " 'tingly',\n",
       " 'uplifted',\n",
       " 'ammonia',\n",
       " 'apple',\n",
       " 'apricot',\n",
       " 'berry',\n",
       " 'blue cheese',\n",
       " 'blueberry',\n",
       " 'butter',\n",
       " 'cheese',\n",
       " 'chemical',\n",
       " 'chestnut',\n",
       " 'citrus',\n",
       " 'coffee',\n",
       " 'diesel',\n",
       " 'earthy',\n",
       " 'flowery',\n",
       " 'fruit',\n",
       " 'grape',\n",
       " 'grapefruit',\n",
       " 'honey',\n",
       " 'lavender',\n",
       " 'lemon',\n",
       " 'lime',\n",
       " 'mango',\n",
       " 'menthol',\n",
       " 'mint',\n",
       " 'nutty',\n",
       " 'orange',\n",
       " 'peach',\n",
       " 'pear',\n",
       " 'pepper',\n",
       " 'pine',\n",
       " 'pineapple',\n",
       " 'plum',\n",
       " 'pungent',\n",
       " 'rose',\n",
       " 'sage',\n",
       " 'skunk',\n",
       " 'spicy/herbal',\n",
       " 'strawberry',\n",
       " 'sweet',\n",
       " 'tar',\n",
       " 'tea',\n",
       " 'tobacco',\n",
       " 'tree',\n",
       " 'tropical',\n",
       " 'vanilla',\n",
       " 'violet',\n",
       " 'woody',\n",
       " 'X..Alpha-Pinene']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_mlp.columns.to_list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df_mlp.drop(['index', 'X..Alpha-Pinene'], axis = 1)\n",
    "y = df_mlp[['X..Alpha-Pinene']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:ylabel='Count'>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "sns.histplot(y, bins = 10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train test split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=1, test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train1, X_val, y_train1, y_val = train_test_split(X_train, y_train, random_state=1, test_size=0.25)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "MLP modeling (before Feature selection and Hyperparameter Tuning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/andalanputra/opt/anaconda3/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:1623: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    }
   ],
   "source": [
    "mlpreg = MLPRegressor(random_state=1, early_stopping=True)\n",
    "mlpreg.fit(X_train1, y_train1)\n",
    "y_pred_mlp = mlpreg.predict(X_val)\n",
    "y_pred_mlp_r2 = mlpreg.predict(X_train1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.08290327926750637"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mean_absolute_error(y_val, y_pred_mlp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8973345823940929"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#train\n",
    "r2_score(y_train1, y_pred_mlp_r2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8647775420065618"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#val\n",
    "r2_score(y_val, y_pred_mlp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Residual plots for each target variable"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Feature Selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "rfreg = RandomForestRegressor()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/andalanputra/opt/anaconda3/lib/python3.9/site-packages/sklearn/feature_selection/_from_model.py:357: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  self.estimator_.fit(X, y, **fit_params)\n"
     ]
    }
   ],
   "source": [
    "selector = SelectFromModel(rfreg).fit(X_train1, y_train1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([6.98740005e-02, 4.65310765e-02, 5.64203157e-02, 6.99375631e-02,\n",
       "       6.46146284e-02, 2.94340947e-03, 3.62248702e-01, 4.67595722e-03,\n",
       "       6.09273406e-06, 7.95373890e-04, 8.40555787e-03, 2.77333334e-08,\n",
       "       8.67668533e-03, 8.32974580e-06, 1.51982685e-03, 1.77714544e-03,\n",
       "       5.55940868e-03, 1.12045219e-03, 5.24986243e-08, 1.23851481e-02,\n",
       "       5.69552749e-08, 5.50482408e-08, 4.96131413e-03, 3.14650196e-03,\n",
       "       5.62713871e-03, 2.85372669e-04, 1.85279256e-02, 4.01284715e-06,\n",
       "       2.00545719e-08, 1.39773356e-03, 1.69484872e-02, 1.17345596e-08,\n",
       "       3.33680627e-03, 3.70758380e-07, 9.53871833e-08, 5.15673624e-03,\n",
       "       4.39689167e-03, 2.13374949e-03, 1.68992640e-04, 2.06910096e-05,\n",
       "       1.66680639e-04, 6.94641662e-03, 4.08549204e-05, 3.58228738e-02,\n",
       "       1.43434954e-04, 1.64114135e-03, 2.11229635e-04, 6.42106212e-05,\n",
       "       1.24207133e-03, 8.45795998e-04, 3.84878486e-03, 3.47503294e-02,\n",
       "       9.74521225e-04, 5.48101851e-04, 1.57253541e-03, 1.38402796e-04,\n",
       "       7.99245642e-05, 7.59655349e-05, 3.99516213e-03, 2.01390722e-04,\n",
       "       9.72400747e-02, 4.42634309e-05, 1.97909693e-03, 9.52508087e-05,\n",
       "       4.21504671e-03, 1.99485164e-04, 4.53754774e-06, 1.01573365e-03,\n",
       "       2.14719167e-03, 4.79556011e-05, 1.95761846e-04, 6.66513221e-04,\n",
       "       1.44308936e-03, 9.58917821e-05, 4.43311247e-03, 6.22703807e-04,\n",
       "       1.53342720e-03, 3.40273549e-03, 5.83922571e-05, 1.14028149e-04,\n",
       "       4.69708491e-04, 6.46438536e-04, 4.06711731e-04, 9.54548817e-04,\n",
       "       4.54601677e-05, 1.00029456e-03])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "selector.estimator_.feature_importances_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.011627906976744186"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "selector.threshold_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "mask = selector.get_support()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ True,  True,  True,  True,  True, False,  True, False, False,\n",
       "       False, False, False, False, False, False, False, False, False,\n",
       "       False,  True, False, False, False, False, False, False,  True,\n",
       "       False, False, False,  True, False, False, False, False, False,\n",
       "       False, False, False, False, False, False, False,  True, False,\n",
       "       False, False, False, False, False, False,  True, False, False,\n",
       "       False, False, False, False, False, False,  True, False, False,\n",
       "       False, False, False, False, False, False, False, False, False,\n",
       "       False, False, False, False, False, False, False, False, False,\n",
       "       False, False, False, False, False])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "selected_features = X.columns[mask]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>lsa_0</th>\n",
       "      <th>lsa_1</th>\n",
       "      <th>lsa_2</th>\n",
       "      <th>lsa_3</th>\n",
       "      <th>lsa_4</th>\n",
       "      <th>indica</th>\n",
       "      <th>euphoric</th>\n",
       "      <th>hungry</th>\n",
       "      <th>relaxed</th>\n",
       "      <th>blueberry</th>\n",
       "      <th>earthy</th>\n",
       "      <th>mango</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.341025</td>\n",
       "      <td>0.182753</td>\n",
       "      <td>0.008214</td>\n",
       "      <td>0.140406</td>\n",
       "      <td>-0.156943</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.341025</td>\n",
       "      <td>0.182753</td>\n",
       "      <td>0.008214</td>\n",
       "      <td>0.140406</td>\n",
       "      <td>-0.156943</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.232158</td>\n",
       "      <td>-0.045496</td>\n",
       "      <td>0.187131</td>\n",
       "      <td>-0.000936</td>\n",
       "      <td>0.018518</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.261225</td>\n",
       "      <td>0.100324</td>\n",
       "      <td>-0.043622</td>\n",
       "      <td>0.141860</td>\n",
       "      <td>-0.034786</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.243491</td>\n",
       "      <td>0.034313</td>\n",
       "      <td>0.080290</td>\n",
       "      <td>-0.165609</td>\n",
       "      <td>0.019773</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59995</th>\n",
       "      <td>0.175310</td>\n",
       "      <td>0.233013</td>\n",
       "      <td>0.002148</td>\n",
       "      <td>0.114778</td>\n",
       "      <td>0.056574</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59996</th>\n",
       "      <td>0.440634</td>\n",
       "      <td>-0.078839</td>\n",
       "      <td>0.085152</td>\n",
       "      <td>0.087878</td>\n",
       "      <td>-0.133604</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59997</th>\n",
       "      <td>0.184573</td>\n",
       "      <td>-0.137296</td>\n",
       "      <td>-0.095301</td>\n",
       "      <td>0.181735</td>\n",
       "      <td>-0.042683</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59998</th>\n",
       "      <td>0.055494</td>\n",
       "      <td>0.003622</td>\n",
       "      <td>-0.050252</td>\n",
       "      <td>-0.024795</td>\n",
       "      <td>-0.031141</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59999</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>60000 rows × 12 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          lsa_0     lsa_1     lsa_2     lsa_3     lsa_4  indica  euphoric  \\\n",
       "0      0.341025  0.182753  0.008214  0.140406 -0.156943       0         1   \n",
       "1      0.341025  0.182753  0.008214  0.140406 -0.156943       0         1   \n",
       "2      0.232158 -0.045496  0.187131 -0.000936  0.018518       0         1   \n",
       "3      0.261225  0.100324 -0.043622  0.141860 -0.034786       0         1   \n",
       "4      0.243491  0.034313  0.080290 -0.165609  0.019773       0         1   \n",
       "...         ...       ...       ...       ...       ...     ...       ...   \n",
       "59995  0.175310  0.233013  0.002148  0.114778  0.056574       1         0   \n",
       "59996  0.440634 -0.078839  0.085152  0.087878 -0.133604       1         0   \n",
       "59997  0.184573 -0.137296 -0.095301  0.181735 -0.042683       1         0   \n",
       "59998  0.055494  0.003622 -0.050252 -0.024795 -0.031141       1         0   \n",
       "59999  0.000000  0.000000  0.000000  0.000000  0.000000       1         1   \n",
       "\n",
       "       hungry  relaxed  blueberry  earthy  mango  \n",
       "0           1        1          0       0      0  \n",
       "1           1        1          0       0      0  \n",
       "2           0        1          0       0      0  \n",
       "3           1        0          0       0      0  \n",
       "4           0        1          0       0      0  \n",
       "...       ...      ...        ...     ...    ...  \n",
       "59995       0        1          0       0      0  \n",
       "59996       0        0          0       0      0  \n",
       "59997       0        0          0       0      0  \n",
       "59998       0        0          0       0      0  \n",
       "59999       0        0          0       0      0  \n",
       "\n",
       "[60000 rows x 12 columns]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "selected_X = df_mlp[selected_features]\n",
    "selected_X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['lsa_0',\n",
       " 'lsa_1',\n",
       " 'lsa_2',\n",
       " 'lsa_3',\n",
       " 'lsa_4',\n",
       " 'indica',\n",
       " 'euphoric',\n",
       " 'hungry',\n",
       " 'relaxed',\n",
       " 'blueberry',\n",
       " 'earthy',\n",
       " 'mango']"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "selected_X.columns.to_list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['selected_X_mlp_lsa_elbow_alpine.pkl']"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import joblib\n",
    "\n",
    "joblib.dump(selector, \"selector_mlp_lsa_elbow_alpine.pkl\")\n",
    "joblib.dump(selected_X, \"selected_X_mlp_lsa_elbow_alpine.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import joblib\n",
    "\n",
    "# selected_X = joblib.load(\"selected_X_mlp_lsa_elbow_alpine.pkl\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train test split (after Feature Selection)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(selected_X, y, random_state=1, test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train1, X_val, y_train1, y_val = train_test_split(X_train, y_train, random_state=1, test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/andalanputra/opt/anaconda3/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:1623: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/Users/andalanputra/opt/anaconda3/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "mlpreg.fit(X_train1, y_train1)\n",
    "y_pred_mlpreg = mlpreg.predict(X_val)\n",
    "y_pred_mlpreg_r2 = mlpreg.predict(X_train1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.11930652581497116"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mean_absolute_error(y_val, y_pred_mlpreg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.811201633601936"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#train\n",
    "r2_score(y_train1, y_pred_mlpreg_r2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7982468202924011"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#val\n",
    "r2_score(y_val, y_pred_mlpreg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hyperparameter Tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "parameters = {'hidden_layer_sizes': [(100,), (50, 50, 50), (50, 100, 50)],\n",
    "              'activation': ['tanh', 'relu'], #only tanh and relu\n",
    "              'max_iter': [200, 500, 1000]\n",
    "              }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "rscv = RandomizedSearchCV(mlpreg,  \n",
    "                     parameters,   \n",
    "                     cv=5, \n",
    "                     scoring='neg_mean_absolute_error',\n",
    "                     n_jobs=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/andalanputra/opt/anaconda3/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:1623: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/Users/andalanputra/opt/anaconda3/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:1623: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/Users/andalanputra/opt/anaconda3/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:1623: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/Users/andalanputra/opt/anaconda3/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:1623: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/Users/andalanputra/opt/anaconda3/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:1623: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/Users/andalanputra/opt/anaconda3/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:1623: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/Users/andalanputra/opt/anaconda3/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:1623: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/Users/andalanputra/opt/anaconda3/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:1623: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/Users/andalanputra/opt/anaconda3/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:1623: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/Users/andalanputra/opt/anaconda3/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:1623: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/Users/andalanputra/opt/anaconda3/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:1623: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/Users/andalanputra/opt/anaconda3/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:1623: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/Users/andalanputra/opt/anaconda3/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:1623: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/Users/andalanputra/opt/anaconda3/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:1623: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/Users/andalanputra/opt/anaconda3/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:1623: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/Users/andalanputra/opt/anaconda3/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:1623: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/Users/andalanputra/opt/anaconda3/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:1623: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/Users/andalanputra/opt/anaconda3/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:1623: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/Users/andalanputra/opt/anaconda3/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:1623: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/Users/andalanputra/opt/anaconda3/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:1623: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/Users/andalanputra/opt/anaconda3/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/Users/andalanputra/opt/anaconda3/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:1623: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/Users/andalanputra/opt/anaconda3/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:1623: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/Users/andalanputra/opt/anaconda3/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:1623: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/Users/andalanputra/opt/anaconda3/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/Users/andalanputra/opt/anaconda3/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:1623: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/Users/andalanputra/opt/anaconda3/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:1623: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/Users/andalanputra/opt/anaconda3/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:1623: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/Users/andalanputra/opt/anaconda3/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/Users/andalanputra/opt/anaconda3/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:1623: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/Users/andalanputra/opt/anaconda3/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:1623: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/Users/andalanputra/opt/anaconda3/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:1623: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/Users/andalanputra/opt/anaconda3/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:1623: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/Users/andalanputra/opt/anaconda3/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:1623: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/Users/andalanputra/opt/anaconda3/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:1623: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/Users/andalanputra/opt/anaconda3/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:1623: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/Users/andalanputra/opt/anaconda3/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:1623: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/Users/andalanputra/opt/anaconda3/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:1623: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/Users/andalanputra/opt/anaconda3/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:1623: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/Users/andalanputra/opt/anaconda3/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:1623: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/Users/andalanputra/opt/anaconda3/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:1623: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/Users/andalanputra/opt/anaconda3/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:1623: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/Users/andalanputra/opt/anaconda3/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:1623: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/Users/andalanputra/opt/anaconda3/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:1623: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/Users/andalanputra/opt/anaconda3/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:1623: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/Users/andalanputra/opt/anaconda3/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:1623: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/Users/andalanputra/opt/anaconda3/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:1623: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/Users/andalanputra/opt/anaconda3/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:1623: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/Users/andalanputra/opt/anaconda3/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:1623: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/Users/andalanputra/opt/anaconda3/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:1623: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/Users/andalanputra/opt/anaconda3/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:1623: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/Users/andalanputra/opt/anaconda3/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:1623: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/Users/andalanputra/opt/anaconda3/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:1623: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/Users/andalanputra/opt/anaconda3/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:1623: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;background-color: white;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>RandomizedSearchCV(cv=5,\n",
       "                   estimator=MLPRegressor(early_stopping=True, random_state=1),\n",
       "                   n_jobs=-1,\n",
       "                   param_distributions={&#x27;activation&#x27;: [&#x27;tanh&#x27;, &#x27;relu&#x27;],\n",
       "                                        &#x27;hidden_layer_sizes&#x27;: [(100,),\n",
       "                                                               (50, 50, 50),\n",
       "                                                               (50, 100, 50)],\n",
       "                                        &#x27;max_iter&#x27;: [200, 500, 1000]},\n",
       "                   scoring=&#x27;neg_mean_absolute_error&#x27;)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" ><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">RandomizedSearchCV</label><div class=\"sk-toggleable__content\"><pre>RandomizedSearchCV(cv=5,\n",
       "                   estimator=MLPRegressor(early_stopping=True, random_state=1),\n",
       "                   n_jobs=-1,\n",
       "                   param_distributions={&#x27;activation&#x27;: [&#x27;tanh&#x27;, &#x27;relu&#x27;],\n",
       "                                        &#x27;hidden_layer_sizes&#x27;: [(100,),\n",
       "                                                               (50, 50, 50),\n",
       "                                                               (50, 100, 50)],\n",
       "                                        &#x27;max_iter&#x27;: [200, 500, 1000]},\n",
       "                   scoring=&#x27;neg_mean_absolute_error&#x27;)</pre></div></div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" ><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">estimator: MLPRegressor</label><div class=\"sk-toggleable__content\"><pre>MLPRegressor(early_stopping=True, random_state=1)</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-3\" type=\"checkbox\" ><label for=\"sk-estimator-id-3\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">MLPRegressor</label><div class=\"sk-toggleable__content\"><pre>MLPRegressor(early_stopping=True, random_state=1)</pre></div></div></div></div></div></div></div></div></div></div>"
      ],
      "text/plain": [
       "RandomizedSearchCV(cv=5,\n",
       "                   estimator=MLPRegressor(early_stopping=True, random_state=1),\n",
       "                   n_jobs=-1,\n",
       "                   param_distributions={'activation': ['tanh', 'relu'],\n",
       "                                        'hidden_layer_sizes': [(100,),\n",
       "                                                               (50, 50, 50),\n",
       "                                                               (50, 100, 50)],\n",
       "                                        'max_iter': [200, 500, 1000]},\n",
       "                   scoring='neg_mean_absolute_error')"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rscv.fit(X_train1, y_train1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'max_iter': 500, 'hidden_layer_sizes': (50, 50, 50), 'activation': 'tanh'}"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rscv.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['rscv_mlp_lsa_elbow_best_params_alpine.pkl']"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "joblib.dump(rscv, \"rscv_mlp_lsa_elbow_alpine.pkl\")\n",
    "joblib.dump(rscv.best_params_, \"rscv_mlp_lsa_elbow_best_params_alpine.pkl\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "MLP fit (after hyperparameter tuning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/andalanputra/opt/anaconda3/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:1623: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    }
   ],
   "source": [
    "mlpreg_ht = MLPRegressor(random_state=1, max_iter=500, activation = 'tanh', hidden_layer_sizes= (50,50,50), early_stopping=True)\n",
    "mlpreg_ht.fit(X_train1, y_train1)\n",
    "y_pred_mlp_ht = mlpreg_ht.predict(X_val)\n",
    "y_pred_mlp_r2_ht = mlpreg_ht.predict(X_train1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.07442493801326293"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mean_absolute_error(y_val, y_pred_mlp_ht)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9185291564846102"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#train\n",
    "r2_score(y_train1, y_pred_mlp_r2_ht)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9012027188454466"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#val\n",
    "r2_score(y_val, y_pred_mlp_ht)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Residual plots after Hyperparameter Tuning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Predicting model on the test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_mlpreg_test = mlpreg_ht.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['y_test_mlpreg_lsa_elbow_alpine.pkl']"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "joblib.dump(y_pred_mlpreg_test, \"y_pred_mlpreg_test_lsa_elbow_alpine.pkl\")\n",
    "joblib.dump(y_test, \"y_test_mlpreg_lsa_elbow_alpine.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.07496877065962919"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mean_absolute_error(y_test, y_pred_mlpreg_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.013307755099851179"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mean_squared_error(y_test, y_pred_mlpreg_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.11535924366885897"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mean_squared_error(y_test, y_pred_mlpreg_test, squared = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9004737233492619"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "r2_score(y_test, y_pred_mlpreg_test)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Error analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 576x432 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 432x288 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# assume y_pred is a numpy array and y_true is a pandas dataframe\n",
    "fig, ax = plt.subplots(figsize=(8, 6))\n",
    "\n",
    "column = \"X..Alpha-Pinene\"  # specify the target variable name\n",
    "ax.hist(y_pred_mlpreg_test, alpha=0.5, label='y_pred', bins=20)\n",
    "ax.hist(y_test[column], alpha=0.5, label='y_true', bins=20)\n",
    "ax.legend(loc='upper right')\n",
    "ax.set_title(column)\n",
    "\n",
    "plt.show()\n",
    "plt.savefig('error_hist_mlp_lsa_elbow_alpine.png')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pearson R"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pearson correlation coefficient: 0.949\n",
      "P-value: 0.000\n"
     ]
    }
   ],
   "source": [
    "corr_coef, p_value = pearsonr(y_pred_mlpreg_test.flatten(), y_test.values.ravel())\n",
    "\n",
    "print(f\"Pearson correlation coefficient: {corr_coef:.3f}\")\n",
    "print(f\"P-value: {p_value:.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:>"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "corr_matrix = y_test.corr()\n",
    "sns.heatmap(corr_matrix, annot=True, cmap='coolwarm', center=0)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
