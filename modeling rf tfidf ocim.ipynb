{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn import preprocessing\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.neural_network import MLPRegressor\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "from sklearn.metrics import r2_score\n",
    "from scipy.stats import pearsonr\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.feature_selection import SelectFromModel\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compiling complete dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_rf = pd.read_csv(\"df_ocim_tfidf.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['index',\n",
       " 'tfidf_0',\n",
       " 'tfidf_1',\n",
       " 'tfidf_2',\n",
       " 'tfidf_3',\n",
       " 'tfidf_4',\n",
       " 'tfidf_5',\n",
       " 'tfidf_6',\n",
       " 'tfidf_7',\n",
       " 'tfidf_8',\n",
       " 'tfidf_9',\n",
       " 'tfidf_10',\n",
       " 'tfidf_11',\n",
       " 'tfidf_12',\n",
       " 'tfidf_13',\n",
       " 'tfidf_14',\n",
       " 'tfidf_15',\n",
       " 'tfidf_16',\n",
       " 'tfidf_17',\n",
       " 'tfidf_18',\n",
       " 'tfidf_19',\n",
       " 'tfidf_20',\n",
       " 'tfidf_21',\n",
       " 'tfidf_22',\n",
       " 'tfidf_23',\n",
       " 'tfidf_24',\n",
       " 'tfidf_25',\n",
       " 'tfidf_26',\n",
       " 'tfidf_27',\n",
       " 'tfidf_28',\n",
       " 'tfidf_29',\n",
       " 'tfidf_30',\n",
       " 'tfidf_31',\n",
       " 'tfidf_32',\n",
       " 'tfidf_33',\n",
       " 'tfidf_34',\n",
       " 'tfidf_35',\n",
       " 'tfidf_36',\n",
       " 'tfidf_37',\n",
       " 'tfidf_38',\n",
       " 'tfidf_39',\n",
       " 'tfidf_40',\n",
       " 'tfidf_41',\n",
       " 'tfidf_42',\n",
       " 'tfidf_43',\n",
       " 'tfidf_44',\n",
       " 'tfidf_45',\n",
       " 'tfidf_46',\n",
       " 'tfidf_47',\n",
       " 'tfidf_48',\n",
       " 'tfidf_49',\n",
       " 'tfidf_50',\n",
       " 'tfidf_51',\n",
       " 'tfidf_52',\n",
       " 'tfidf_53',\n",
       " 'tfidf_54',\n",
       " 'tfidf_55',\n",
       " 'tfidf_56',\n",
       " 'tfidf_57',\n",
       " 'tfidf_58',\n",
       " 'tfidf_59',\n",
       " 'tfidf_60',\n",
       " 'tfidf_61',\n",
       " 'tfidf_62',\n",
       " 'tfidf_63',\n",
       " 'tfidf_64',\n",
       " 'tfidf_65',\n",
       " 'tfidf_66',\n",
       " 'tfidf_67',\n",
       " 'tfidf_68',\n",
       " 'tfidf_69',\n",
       " 'tfidf_70',\n",
       " 'tfidf_71',\n",
       " 'tfidf_72',\n",
       " 'tfidf_73',\n",
       " 'tfidf_74',\n",
       " 'tfidf_75',\n",
       " 'tfidf_76',\n",
       " 'tfidf_77',\n",
       " 'tfidf_78',\n",
       " 'tfidf_79',\n",
       " 'tfidf_80',\n",
       " 'tfidf_81',\n",
       " 'tfidf_82',\n",
       " 'tfidf_83',\n",
       " 'tfidf_84',\n",
       " 'tfidf_85',\n",
       " 'tfidf_86',\n",
       " 'tfidf_87',\n",
       " 'tfidf_88',\n",
       " 'tfidf_89',\n",
       " 'tfidf_90',\n",
       " 'tfidf_91',\n",
       " 'tfidf_92',\n",
       " 'tfidf_93',\n",
       " 'tfidf_94',\n",
       " 'tfidf_95',\n",
       " 'tfidf_96',\n",
       " 'tfidf_97',\n",
       " 'tfidf_98',\n",
       " 'tfidf_99',\n",
       " 'tfidf_100',\n",
       " 'tfidf_101',\n",
       " 'tfidf_102',\n",
       " 'tfidf_103',\n",
       " 'tfidf_104',\n",
       " 'tfidf_105',\n",
       " 'tfidf_106',\n",
       " 'tfidf_107',\n",
       " 'tfidf_108',\n",
       " 'tfidf_109',\n",
       " 'tfidf_110',\n",
       " 'tfidf_111',\n",
       " 'tfidf_112',\n",
       " 'tfidf_113',\n",
       " 'tfidf_114',\n",
       " 'tfidf_115',\n",
       " 'tfidf_116',\n",
       " 'tfidf_117',\n",
       " 'tfidf_118',\n",
       " 'tfidf_119',\n",
       " 'tfidf_120',\n",
       " 'tfidf_121',\n",
       " 'tfidf_122',\n",
       " 'tfidf_123',\n",
       " 'tfidf_124',\n",
       " 'tfidf_125',\n",
       " 'tfidf_126',\n",
       " 'tfidf_127',\n",
       " 'tfidf_128',\n",
       " 'tfidf_129',\n",
       " 'tfidf_130',\n",
       " 'tfidf_131',\n",
       " 'tfidf_132',\n",
       " 'tfidf_133',\n",
       " 'tfidf_134',\n",
       " 'tfidf_135',\n",
       " 'tfidf_136',\n",
       " 'tfidf_137',\n",
       " 'tfidf_138',\n",
       " 'tfidf_139',\n",
       " 'tfidf_140',\n",
       " 'tfidf_141',\n",
       " 'tfidf_142',\n",
       " 'tfidf_143',\n",
       " 'tfidf_144',\n",
       " 'tfidf_145',\n",
       " 'tfidf_146',\n",
       " 'tfidf_147',\n",
       " 'tfidf_148',\n",
       " 'tfidf_149',\n",
       " 'tfidf_150',\n",
       " 'tfidf_151',\n",
       " 'tfidf_152',\n",
       " 'tfidf_153',\n",
       " 'tfidf_154',\n",
       " 'tfidf_155',\n",
       " 'tfidf_156',\n",
       " 'tfidf_157',\n",
       " 'tfidf_158',\n",
       " 'tfidf_159',\n",
       " 'tfidf_160',\n",
       " 'tfidf_161',\n",
       " 'tfidf_162',\n",
       " 'tfidf_163',\n",
       " 'tfidf_164',\n",
       " 'tfidf_165',\n",
       " 'tfidf_166',\n",
       " 'tfidf_167',\n",
       " 'tfidf_168',\n",
       " 'tfidf_169',\n",
       " 'tfidf_170',\n",
       " 'tfidf_171',\n",
       " 'tfidf_172',\n",
       " 'tfidf_173',\n",
       " 'tfidf_174',\n",
       " 'tfidf_175',\n",
       " 'tfidf_176',\n",
       " 'tfidf_177',\n",
       " 'tfidf_178',\n",
       " 'tfidf_179',\n",
       " 'tfidf_180',\n",
       " 'tfidf_181',\n",
       " 'tfidf_182',\n",
       " 'tfidf_183',\n",
       " 'tfidf_184',\n",
       " 'tfidf_185',\n",
       " 'tfidf_186',\n",
       " 'tfidf_187',\n",
       " 'tfidf_188',\n",
       " 'tfidf_189',\n",
       " 'tfidf_190',\n",
       " 'tfidf_191',\n",
       " 'tfidf_192',\n",
       " 'tfidf_193',\n",
       " 'tfidf_194',\n",
       " 'tfidf_195',\n",
       " 'tfidf_196',\n",
       " 'tfidf_197',\n",
       " 'tfidf_198',\n",
       " 'tfidf_199',\n",
       " 'tfidf_200',\n",
       " 'tfidf_201',\n",
       " 'tfidf_202',\n",
       " 'tfidf_203',\n",
       " 'tfidf_204',\n",
       " 'tfidf_205',\n",
       " 'tfidf_206',\n",
       " 'tfidf_207',\n",
       " 'tfidf_208',\n",
       " 'tfidf_209',\n",
       " 'tfidf_210',\n",
       " 'tfidf_211',\n",
       " 'tfidf_212',\n",
       " 'tfidf_213',\n",
       " 'tfidf_214',\n",
       " 'tfidf_215',\n",
       " 'tfidf_216',\n",
       " 'tfidf_217',\n",
       " 'tfidf_218',\n",
       " 'tfidf_219',\n",
       " 'tfidf_220',\n",
       " 'tfidf_221',\n",
       " 'tfidf_222',\n",
       " 'tfidf_223',\n",
       " 'tfidf_224',\n",
       " 'tfidf_225',\n",
       " 'tfidf_226',\n",
       " 'tfidf_227',\n",
       " 'tfidf_228',\n",
       " 'tfidf_229',\n",
       " 'tfidf_230',\n",
       " 'tfidf_231',\n",
       " 'tfidf_232',\n",
       " 'tfidf_233',\n",
       " 'tfidf_234',\n",
       " 'tfidf_235',\n",
       " 'tfidf_236',\n",
       " 'tfidf_237',\n",
       " 'tfidf_238',\n",
       " 'tfidf_239',\n",
       " 'tfidf_240',\n",
       " 'tfidf_241',\n",
       " 'tfidf_242',\n",
       " 'tfidf_243',\n",
       " 'tfidf_244',\n",
       " 'tfidf_245',\n",
       " 'tfidf_246',\n",
       " 'tfidf_247',\n",
       " 'tfidf_248',\n",
       " 'tfidf_249',\n",
       " 'tfidf_250',\n",
       " 'tfidf_251',\n",
       " 'tfidf_252',\n",
       " 'tfidf_253',\n",
       " 'tfidf_254',\n",
       " 'tfidf_255',\n",
       " 'tfidf_256',\n",
       " 'tfidf_257',\n",
       " 'tfidf_258',\n",
       " 'tfidf_259',\n",
       " 'tfidf_260',\n",
       " 'tfidf_261',\n",
       " 'tfidf_262',\n",
       " 'tfidf_263',\n",
       " 'tfidf_264',\n",
       " 'tfidf_265',\n",
       " 'tfidf_266',\n",
       " 'tfidf_267',\n",
       " 'tfidf_268',\n",
       " 'tfidf_269',\n",
       " 'tfidf_270',\n",
       " 'tfidf_271',\n",
       " 'tfidf_272',\n",
       " 'tfidf_273',\n",
       " 'tfidf_274',\n",
       " 'tfidf_275',\n",
       " 'tfidf_276',\n",
       " 'tfidf_277',\n",
       " 'tfidf_278',\n",
       " 'tfidf_279',\n",
       " 'tfidf_280',\n",
       " 'tfidf_281',\n",
       " 'tfidf_282',\n",
       " 'tfidf_283',\n",
       " 'tfidf_284',\n",
       " 'tfidf_285',\n",
       " 'tfidf_286',\n",
       " 'tfidf_287',\n",
       " 'tfidf_288',\n",
       " 'tfidf_289',\n",
       " 'tfidf_290',\n",
       " 'tfidf_291',\n",
       " 'tfidf_292',\n",
       " 'tfidf_293',\n",
       " 'tfidf_294',\n",
       " 'tfidf_295',\n",
       " 'tfidf_296',\n",
       " 'tfidf_297',\n",
       " 'tfidf_298',\n",
       " 'tfidf_299',\n",
       " 'tfidf_300',\n",
       " 'tfidf_301',\n",
       " 'tfidf_302',\n",
       " 'tfidf_303',\n",
       " 'tfidf_304',\n",
       " 'tfidf_305',\n",
       " 'tfidf_306',\n",
       " 'tfidf_307',\n",
       " 'tfidf_308',\n",
       " 'tfidf_309',\n",
       " 'tfidf_310',\n",
       " 'tfidf_311',\n",
       " 'tfidf_312',\n",
       " 'tfidf_313',\n",
       " 'tfidf_314',\n",
       " 'tfidf_315',\n",
       " 'tfidf_316',\n",
       " 'tfidf_317',\n",
       " 'tfidf_318',\n",
       " 'tfidf_319',\n",
       " 'tfidf_320',\n",
       " 'tfidf_321',\n",
       " 'tfidf_322',\n",
       " 'tfidf_323',\n",
       " 'tfidf_324',\n",
       " 'tfidf_325',\n",
       " 'tfidf_326',\n",
       " 'tfidf_327',\n",
       " 'tfidf_328',\n",
       " 'tfidf_329',\n",
       " 'tfidf_330',\n",
       " 'tfidf_331',\n",
       " 'tfidf_332',\n",
       " 'tfidf_333',\n",
       " 'tfidf_334',\n",
       " 'tfidf_335',\n",
       " 'tfidf_336',\n",
       " 'tfidf_337',\n",
       " 'tfidf_338',\n",
       " 'tfidf_339',\n",
       " 'tfidf_340',\n",
       " 'tfidf_341',\n",
       " 'tfidf_342',\n",
       " 'tfidf_343',\n",
       " 'tfidf_344',\n",
       " 'tfidf_345',\n",
       " 'tfidf_346',\n",
       " 'tfidf_347',\n",
       " 'tfidf_348',\n",
       " 'tfidf_349',\n",
       " 'tfidf_350',\n",
       " 'tfidf_351',\n",
       " 'tfidf_352',\n",
       " 'tfidf_353',\n",
       " 'tfidf_354',\n",
       " 'tfidf_355',\n",
       " 'tfidf_356',\n",
       " 'tfidf_357',\n",
       " 'tfidf_358',\n",
       " 'tfidf_359',\n",
       " 'tfidf_360',\n",
       " 'tfidf_361',\n",
       " 'tfidf_362',\n",
       " 'tfidf_363',\n",
       " 'tfidf_364',\n",
       " 'tfidf_365',\n",
       " 'tfidf_366',\n",
       " 'tfidf_367',\n",
       " 'tfidf_368',\n",
       " 'tfidf_369',\n",
       " 'tfidf_370',\n",
       " 'tfidf_371',\n",
       " 'tfidf_372',\n",
       " 'tfidf_373',\n",
       " 'tfidf_374',\n",
       " 'tfidf_375',\n",
       " 'tfidf_376',\n",
       " 'tfidf_377',\n",
       " 'tfidf_378',\n",
       " 'tfidf_379',\n",
       " 'tfidf_380',\n",
       " 'tfidf_381',\n",
       " 'tfidf_382',\n",
       " 'tfidf_383',\n",
       " 'tfidf_384',\n",
       " 'tfidf_385',\n",
       " 'tfidf_386',\n",
       " 'tfidf_387',\n",
       " 'hybrid',\n",
       " 'indica',\n",
       " 'sativa',\n",
       " 'anxiety',\n",
       " 'anxious',\n",
       " 'aroused',\n",
       " 'arthritis',\n",
       " 'creative',\n",
       " 'depression',\n",
       " 'dizzy',\n",
       " 'dry eyes',\n",
       " 'dry mouth',\n",
       " 'energetic',\n",
       " 'epilepsy',\n",
       " 'euphoric',\n",
       " 'eye pressure',\n",
       " 'fatigue',\n",
       " 'focused',\n",
       " 'giggly',\n",
       " 'happy',\n",
       " 'headache',\n",
       " 'hungry',\n",
       " 'migraines',\n",
       " 'pain',\n",
       " 'paranoid',\n",
       " 'relaxed',\n",
       " 'seizures',\n",
       " 'sleepy',\n",
       " 'spasticity',\n",
       " 'stress',\n",
       " 'talkative',\n",
       " 'tingly',\n",
       " 'uplifted',\n",
       " 'ammonia',\n",
       " 'apple',\n",
       " 'apricot',\n",
       " 'berry',\n",
       " 'blue cheese',\n",
       " 'blueberry',\n",
       " 'butter',\n",
       " 'cheese',\n",
       " 'chemical',\n",
       " 'chestnut',\n",
       " 'citrus',\n",
       " 'coffee',\n",
       " 'diesel',\n",
       " 'earthy',\n",
       " 'flowery',\n",
       " 'fruit',\n",
       " 'grape',\n",
       " 'grapefruit',\n",
       " 'honey',\n",
       " 'lavender',\n",
       " 'lemon',\n",
       " 'lime',\n",
       " 'mango',\n",
       " 'menthol',\n",
       " 'mint',\n",
       " 'nutty',\n",
       " 'orange',\n",
       " 'peach',\n",
       " 'pear',\n",
       " 'pepper',\n",
       " 'pine',\n",
       " 'pineapple',\n",
       " 'plum',\n",
       " 'pungent',\n",
       " 'rose',\n",
       " 'sage',\n",
       " 'skunk',\n",
       " 'spicy/herbal',\n",
       " 'strawberry',\n",
       " 'sweet',\n",
       " 'tar',\n",
       " 'tea',\n",
       " 'tobacco',\n",
       " 'tree',\n",
       " 'tropical',\n",
       " 'vanilla',\n",
       " 'violet',\n",
       " 'woody',\n",
       " 'X..Ocimene']"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_rf.columns.to_list()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Splitting dependent and independent variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df_rf.drop(['index', 'X..Ocimene'], axis = 1)\n",
    "y = df_rf[['X..Ocimene']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plotting histograms on target variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       ...,\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.]])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_array = y.to_numpy()\n",
    "y_array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Axes: ylabel='Count'>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "sns.histplot(y, bins = 10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train test split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=1, test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train1, X_val, y_train1, y_val = train_test_split(X_train, y_train, random_state=1, test_size=0.25)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "RF modeling (before Feature selection and Hyperparameter Tuning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/ns/m5pnr0211w91v02hpv22958m0000gn/T/ipykernel_88584/350139188.py:2: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  rfreg.fit(X_train1, y_train1)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;background-color: white;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>RandomForestRegressor()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">RandomForestRegressor</label><div class=\"sk-toggleable__content\"><pre>RandomForestRegressor()</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "RandomForestRegressor()"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rfreg = RandomForestRegressor()\n",
    "rfreg.fit(X_train1, y_train1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_rfreg = rfreg.predict(X_val)\n",
    "y_pred_rfreg_r2 = rfreg.predict(X_train1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.004336867249505967"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mean_absolute_error(y_val, y_pred_rfreg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0013628771490373172"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mean_squared_error(y_val, y_pred_rfreg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.03691716604829408"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mean_squared_error(y_val, y_pred_rfreg, squared = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9990027122447596"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#train\n",
    "r2_score(y_train1, y_pred_rfreg_r2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9920756922083673"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#val\n",
    "r2_score(y_val, y_pred_rfreg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Residual plots for each target variable"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Feature Selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_feat = pd.DataFrame({\n",
    "    \"features\": X_train1.columns,\n",
    "    \"score\": rfreg.feature_importances_\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>features</th>\n",
       "      <th>score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>tfidf_0</td>\n",
       "      <td>0.000005</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>tfidf_1</td>\n",
       "      <td>0.000008</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>tfidf_2</td>\n",
       "      <td>0.000030</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>tfidf_3</td>\n",
       "      <td>0.000072</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>tfidf_4</td>\n",
       "      <td>0.000005</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>464</th>\n",
       "      <td>tree</td>\n",
       "      <td>0.000002</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>465</th>\n",
       "      <td>tropical</td>\n",
       "      <td>0.000014</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>466</th>\n",
       "      <td>vanilla</td>\n",
       "      <td>0.000001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>467</th>\n",
       "      <td>violet</td>\n",
       "      <td>0.000016</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>468</th>\n",
       "      <td>woody</td>\n",
       "      <td>0.000010</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>469 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     features     score\n",
       "0     tfidf_0  0.000005\n",
       "1     tfidf_1  0.000008\n",
       "2     tfidf_2  0.000030\n",
       "3     tfidf_3  0.000072\n",
       "4     tfidf_4  0.000005\n",
       "..        ...       ...\n",
       "464      tree  0.000002\n",
       "465  tropical  0.000014\n",
       "466   vanilla  0.000001\n",
       "467    violet  0.000016\n",
       "468     woody  0.000010\n",
       "\n",
       "[469 rows x 2 columns]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_feat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_feat_ranked = df_feat.sort_values(\"score\", ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>features</th>\n",
       "      <th>score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>451</th>\n",
       "      <td>pine</td>\n",
       "      <td>7.034848e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>390</th>\n",
       "      <td>sativa</td>\n",
       "      <td>1.193894e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>447</th>\n",
       "      <td>orange</td>\n",
       "      <td>7.154758e-02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>62</th>\n",
       "      <td>tfidf_62</td>\n",
       "      <td>3.173269e-02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>431</th>\n",
       "      <td>citrus</td>\n",
       "      <td>1.545548e-02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>tfidf_38</td>\n",
       "      <td>1.529211e-02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>140</th>\n",
       "      <td>tfidf_140</td>\n",
       "      <td>5.301782e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>388</th>\n",
       "      <td>hybrid</td>\n",
       "      <td>3.999261e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>441</th>\n",
       "      <td>lemon</td>\n",
       "      <td>3.439013e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>161</th>\n",
       "      <td>tfidf_161</td>\n",
       "      <td>2.035684e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>367</th>\n",
       "      <td>tfidf_367</td>\n",
       "      <td>1.138131e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>338</th>\n",
       "      <td>tfidf_338</td>\n",
       "      <td>1.130323e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>249</th>\n",
       "      <td>tfidf_249</td>\n",
       "      <td>7.587222e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>130</th>\n",
       "      <td>tfidf_130</td>\n",
       "      <td>7.257191e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>435</th>\n",
       "      <td>flowery</td>\n",
       "      <td>7.045836e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>158</th>\n",
       "      <td>tfidf_158</td>\n",
       "      <td>6.122193e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>253</th>\n",
       "      <td>tfidf_253</td>\n",
       "      <td>6.041094e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>345</th>\n",
       "      <td>tfidf_345</td>\n",
       "      <td>6.021046e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>328</th>\n",
       "      <td>tfidf_328</td>\n",
       "      <td>5.295510e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>200</th>\n",
       "      <td>tfidf_200</td>\n",
       "      <td>5.184117e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>105</th>\n",
       "      <td>tfidf_105</td>\n",
       "      <td>5.079302e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>tfidf_48</td>\n",
       "      <td>4.987579e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>tfidf_5</td>\n",
       "      <td>4.879631e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>222</th>\n",
       "      <td>tfidf_222</td>\n",
       "      <td>4.848107e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>307</th>\n",
       "      <td>tfidf_307</td>\n",
       "      <td>4.046249e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>tfidf_46</td>\n",
       "      <td>4.004633e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>363</th>\n",
       "      <td>tfidf_363</td>\n",
       "      <td>3.834864e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>tfidf_26</td>\n",
       "      <td>3.755910e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>366</th>\n",
       "      <td>tfidf_366</td>\n",
       "      <td>3.685354e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>197</th>\n",
       "      <td>tfidf_197</td>\n",
       "      <td>3.390576e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>349</th>\n",
       "      <td>tfidf_349</td>\n",
       "      <td>3.267724e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>121</th>\n",
       "      <td>tfidf_121</td>\n",
       "      <td>3.219647e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>402</th>\n",
       "      <td>euphoric</td>\n",
       "      <td>3.026008e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>94</th>\n",
       "      <td>tfidf_94</td>\n",
       "      <td>3.016969e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>210</th>\n",
       "      <td>tfidf_210</td>\n",
       "      <td>2.907839e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>415</th>\n",
       "      <td>sleepy</td>\n",
       "      <td>2.902143e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>457</th>\n",
       "      <td>skunk</td>\n",
       "      <td>2.842822e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>329</th>\n",
       "      <td>tfidf_329</td>\n",
       "      <td>2.717306e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>239</th>\n",
       "      <td>tfidf_239</td>\n",
       "      <td>2.644476e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>145</th>\n",
       "      <td>tfidf_145</td>\n",
       "      <td>2.514300e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>tfidf_11</td>\n",
       "      <td>2.492591e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>343</th>\n",
       "      <td>tfidf_343</td>\n",
       "      <td>2.447265e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>371</th>\n",
       "      <td>tfidf_371</td>\n",
       "      <td>2.352341e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>424</th>\n",
       "      <td>berry</td>\n",
       "      <td>2.156951e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>393</th>\n",
       "      <td>aroused</td>\n",
       "      <td>2.129484e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>419</th>\n",
       "      <td>tingly</td>\n",
       "      <td>1.984651e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>tfidf_37</td>\n",
       "      <td>1.979708e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>155</th>\n",
       "      <td>tfidf_155</td>\n",
       "      <td>1.844728e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>tfidf_39</td>\n",
       "      <td>1.798762e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>58</th>\n",
       "      <td>tfidf_58</td>\n",
       "      <td>1.795273e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>437</th>\n",
       "      <td>grape</td>\n",
       "      <td>1.785302e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>153</th>\n",
       "      <td>tfidf_153</td>\n",
       "      <td>1.767164e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>134</th>\n",
       "      <td>tfidf_134</td>\n",
       "      <td>1.758628e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>167</th>\n",
       "      <td>tfidf_167</td>\n",
       "      <td>1.627669e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>149</th>\n",
       "      <td>tfidf_149</td>\n",
       "      <td>1.580988e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>80</th>\n",
       "      <td>tfidf_80</td>\n",
       "      <td>1.567970e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>55</th>\n",
       "      <td>tfidf_55</td>\n",
       "      <td>1.553641e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>141</th>\n",
       "      <td>tfidf_141</td>\n",
       "      <td>1.520103e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>269</th>\n",
       "      <td>tfidf_269</td>\n",
       "      <td>1.430016e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>190</th>\n",
       "      <td>tfidf_190</td>\n",
       "      <td>1.371915e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>369</th>\n",
       "      <td>tfidf_369</td>\n",
       "      <td>1.362035e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>285</th>\n",
       "      <td>tfidf_285</td>\n",
       "      <td>1.341112e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>309</th>\n",
       "      <td>tfidf_309</td>\n",
       "      <td>1.333412e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>tfidf_34</td>\n",
       "      <td>1.305390e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>109</th>\n",
       "      <td>tfidf_109</td>\n",
       "      <td>1.281698e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>292</th>\n",
       "      <td>tfidf_292</td>\n",
       "      <td>1.280185e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>245</th>\n",
       "      <td>tfidf_245</td>\n",
       "      <td>1.273274e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>454</th>\n",
       "      <td>pungent</td>\n",
       "      <td>1.273061e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>168</th>\n",
       "      <td>tfidf_168</td>\n",
       "      <td>1.256292e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>332</th>\n",
       "      <td>tfidf_332</td>\n",
       "      <td>1.205493e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>458</th>\n",
       "      <td>spicy/herbal</td>\n",
       "      <td>1.200469e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>162</th>\n",
       "      <td>tfidf_162</td>\n",
       "      <td>1.126521e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>128</th>\n",
       "      <td>tfidf_128</td>\n",
       "      <td>1.088837e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>319</th>\n",
       "      <td>tfidf_319</td>\n",
       "      <td>1.075397e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>117</th>\n",
       "      <td>tfidf_117</td>\n",
       "      <td>1.032242e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>tfidf_96</td>\n",
       "      <td>1.019175e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>312</th>\n",
       "      <td>tfidf_312</td>\n",
       "      <td>1.014665e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>224</th>\n",
       "      <td>tfidf_224</td>\n",
       "      <td>9.979611e-05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>108</th>\n",
       "      <td>tfidf_108</td>\n",
       "      <td>9.628348e-05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>380</th>\n",
       "      <td>tfidf_380</td>\n",
       "      <td>8.982128e-05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>178</th>\n",
       "      <td>tfidf_178</td>\n",
       "      <td>8.674215e-05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>376</th>\n",
       "      <td>tfidf_376</td>\n",
       "      <td>8.368690e-05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75</th>\n",
       "      <td>tfidf_75</td>\n",
       "      <td>8.242960e-05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>tfidf_43</td>\n",
       "      <td>8.234384e-05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>433</th>\n",
       "      <td>diesel</td>\n",
       "      <td>8.225703e-05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>265</th>\n",
       "      <td>tfidf_265</td>\n",
       "      <td>8.074914e-05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>362</th>\n",
       "      <td>tfidf_362</td>\n",
       "      <td>8.064790e-05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>234</th>\n",
       "      <td>tfidf_234</td>\n",
       "      <td>7.902805e-05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>151</th>\n",
       "      <td>tfidf_151</td>\n",
       "      <td>7.725983e-05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>227</th>\n",
       "      <td>tfidf_227</td>\n",
       "      <td>7.538504e-05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>297</th>\n",
       "      <td>tfidf_297</td>\n",
       "      <td>7.471361e-05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>182</th>\n",
       "      <td>tfidf_182</td>\n",
       "      <td>7.341876e-05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>tfidf_32</td>\n",
       "      <td>7.326190e-05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>337</th>\n",
       "      <td>tfidf_337</td>\n",
       "      <td>7.215806e-05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>tfidf_3</td>\n",
       "      <td>7.192743e-05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>tfidf_30</td>\n",
       "      <td>7.079374e-05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>342</th>\n",
       "      <td>tfidf_342</td>\n",
       "      <td>7.067568e-05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>405</th>\n",
       "      <td>focused</td>\n",
       "      <td>7.062295e-05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>373</th>\n",
       "      <td>tfidf_373</td>\n",
       "      <td>6.895003e-05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>203</th>\n",
       "      <td>tfidf_203</td>\n",
       "      <td>6.879830e-05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>289</th>\n",
       "      <td>tfidf_289</td>\n",
       "      <td>6.757679e-05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>131</th>\n",
       "      <td>tfidf_131</td>\n",
       "      <td>6.734844e-05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>258</th>\n",
       "      <td>tfidf_258</td>\n",
       "      <td>6.696700e-05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>179</th>\n",
       "      <td>tfidf_179</td>\n",
       "      <td>6.677409e-05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>101</th>\n",
       "      <td>tfidf_101</td>\n",
       "      <td>6.563393e-05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>321</th>\n",
       "      <td>tfidf_321</td>\n",
       "      <td>6.465363e-05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>106</th>\n",
       "      <td>tfidf_106</td>\n",
       "      <td>6.368961e-05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>144</th>\n",
       "      <td>tfidf_144</td>\n",
       "      <td>6.310072e-05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>400</th>\n",
       "      <td>energetic</td>\n",
       "      <td>6.241948e-05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>331</th>\n",
       "      <td>tfidf_331</td>\n",
       "      <td>6.147830e-05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>tfidf_24</td>\n",
       "      <td>6.121755e-05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>tfidf_42</td>\n",
       "      <td>5.996259e-05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>199</th>\n",
       "      <td>tfidf_199</td>\n",
       "      <td>5.991088e-05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>198</th>\n",
       "      <td>tfidf_198</td>\n",
       "      <td>5.907833e-05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>79</th>\n",
       "      <td>tfidf_79</td>\n",
       "      <td>5.875160e-05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>267</th>\n",
       "      <td>tfidf_267</td>\n",
       "      <td>5.815536e-05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>324</th>\n",
       "      <td>tfidf_324</td>\n",
       "      <td>5.767712e-05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>395</th>\n",
       "      <td>creative</td>\n",
       "      <td>5.631096e-05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>406</th>\n",
       "      <td>giggly</td>\n",
       "      <td>5.571089e-05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>250</th>\n",
       "      <td>tfidf_250</td>\n",
       "      <td>5.554624e-05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>137</th>\n",
       "      <td>tfidf_137</td>\n",
       "      <td>5.532570e-05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>195</th>\n",
       "      <td>tfidf_195</td>\n",
       "      <td>5.532019e-05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>tfidf_6</td>\n",
       "      <td>5.434364e-05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>420</th>\n",
       "      <td>uplifted</td>\n",
       "      <td>5.186893e-05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>341</th>\n",
       "      <td>tfidf_341</td>\n",
       "      <td>5.149238e-05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>274</th>\n",
       "      <td>tfidf_274</td>\n",
       "      <td>5.130243e-05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>443</th>\n",
       "      <td>mango</td>\n",
       "      <td>5.122480e-05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>379</th>\n",
       "      <td>tfidf_379</td>\n",
       "      <td>5.052090e-05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>159</th>\n",
       "      <td>tfidf_159</td>\n",
       "      <td>5.007676e-05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>278</th>\n",
       "      <td>tfidf_278</td>\n",
       "      <td>4.935524e-05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>360</th>\n",
       "      <td>tfidf_360</td>\n",
       "      <td>4.912302e-05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>281</th>\n",
       "      <td>tfidf_281</td>\n",
       "      <td>4.890108e-05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>78</th>\n",
       "      <td>tfidf_78</td>\n",
       "      <td>4.880038e-05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>tfidf_7</td>\n",
       "      <td>4.853368e-05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>372</th>\n",
       "      <td>tfidf_372</td>\n",
       "      <td>4.852219e-05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>tfidf_33</td>\n",
       "      <td>4.784751e-05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>399</th>\n",
       "      <td>dry mouth</td>\n",
       "      <td>4.722526e-05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>407</th>\n",
       "      <td>happy</td>\n",
       "      <td>4.629022e-05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>129</th>\n",
       "      <td>tfidf_129</td>\n",
       "      <td>4.571345e-05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>136</th>\n",
       "      <td>tfidf_136</td>\n",
       "      <td>4.544765e-05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>142</th>\n",
       "      <td>tfidf_142</td>\n",
       "      <td>4.500529e-05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>115</th>\n",
       "      <td>tfidf_115</td>\n",
       "      <td>4.454446e-05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>333</th>\n",
       "      <td>tfidf_333</td>\n",
       "      <td>4.345501e-05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>143</th>\n",
       "      <td>tfidf_143</td>\n",
       "      <td>4.328038e-05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>439</th>\n",
       "      <td>honey</td>\n",
       "      <td>4.320621e-05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>413</th>\n",
       "      <td>relaxed</td>\n",
       "      <td>4.294698e-05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>340</th>\n",
       "      <td>tfidf_340</td>\n",
       "      <td>4.257891e-05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>430</th>\n",
       "      <td>chestnut</td>\n",
       "      <td>4.088300e-05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>461</th>\n",
       "      <td>tar</td>\n",
       "      <td>4.076223e-05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>175</th>\n",
       "      <td>tfidf_175</td>\n",
       "      <td>4.070738e-05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>350</th>\n",
       "      <td>tfidf_350</td>\n",
       "      <td>4.047064e-05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>127</th>\n",
       "      <td>tfidf_127</td>\n",
       "      <td>4.014687e-05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>204</th>\n",
       "      <td>tfidf_204</td>\n",
       "      <td>3.960021e-05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>177</th>\n",
       "      <td>tfidf_177</td>\n",
       "      <td>3.954573e-05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>262</th>\n",
       "      <td>tfidf_262</td>\n",
       "      <td>3.937440e-05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>418</th>\n",
       "      <td>talkative</td>\n",
       "      <td>3.937384e-05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>73</th>\n",
       "      <td>tfidf_73</td>\n",
       "      <td>3.934030e-05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>275</th>\n",
       "      <td>tfidf_275</td>\n",
       "      <td>3.894263e-05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>260</th>\n",
       "      <td>tfidf_260</td>\n",
       "      <td>3.887792e-05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>90</th>\n",
       "      <td>tfidf_90</td>\n",
       "      <td>3.804393e-05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>188</th>\n",
       "      <td>tfidf_188</td>\n",
       "      <td>3.723743e-05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>124</th>\n",
       "      <td>tfidf_124</td>\n",
       "      <td>3.695678e-05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>tfidf_29</td>\n",
       "      <td>3.600592e-05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>323</th>\n",
       "      <td>tfidf_323</td>\n",
       "      <td>3.519680e-05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>122</th>\n",
       "      <td>tfidf_122</td>\n",
       "      <td>3.474107e-05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>86</th>\n",
       "      <td>tfidf_86</td>\n",
       "      <td>3.428616e-05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>81</th>\n",
       "      <td>tfidf_81</td>\n",
       "      <td>3.427571e-05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>386</th>\n",
       "      <td>tfidf_386</td>\n",
       "      <td>3.393397e-05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>172</th>\n",
       "      <td>tfidf_172</td>\n",
       "      <td>3.359684e-05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>194</th>\n",
       "      <td>tfidf_194</td>\n",
       "      <td>3.336177e-05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>247</th>\n",
       "      <td>tfidf_247</td>\n",
       "      <td>3.328637e-05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>116</th>\n",
       "      <td>tfidf_116</td>\n",
       "      <td>3.288701e-05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>211</th>\n",
       "      <td>tfidf_211</td>\n",
       "      <td>3.235027e-05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>56</th>\n",
       "      <td>tfidf_56</td>\n",
       "      <td>3.183188e-05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>104</th>\n",
       "      <td>tfidf_104</td>\n",
       "      <td>3.176285e-05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>357</th>\n",
       "      <td>tfidf_357</td>\n",
       "      <td>3.154305e-05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>293</th>\n",
       "      <td>tfidf_293</td>\n",
       "      <td>3.084952e-05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>286</th>\n",
       "      <td>tfidf_286</td>\n",
       "      <td>3.061168e-05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>187</th>\n",
       "      <td>tfidf_187</td>\n",
       "      <td>3.060336e-05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>tfidf_17</td>\n",
       "      <td>3.023085e-05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>tfidf_2</td>\n",
       "      <td>2.955966e-05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>tfidf_22</td>\n",
       "      <td>2.931175e-05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>132</th>\n",
       "      <td>tfidf_132</td>\n",
       "      <td>2.928512e-05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>440</th>\n",
       "      <td>lavender</td>\n",
       "      <td>2.830653e-05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>84</th>\n",
       "      <td>tfidf_84</td>\n",
       "      <td>2.775932e-05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>294</th>\n",
       "      <td>tfidf_294</td>\n",
       "      <td>2.771050e-05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>230</th>\n",
       "      <td>tfidf_230</td>\n",
       "      <td>2.707475e-05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>139</th>\n",
       "      <td>tfidf_139</td>\n",
       "      <td>2.702862e-05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>300</th>\n",
       "      <td>tfidf_300</td>\n",
       "      <td>2.698110e-05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>432</th>\n",
       "      <td>coffee</td>\n",
       "      <td>2.680580e-05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>166</th>\n",
       "      <td>tfidf_166</td>\n",
       "      <td>2.676794e-05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>409</th>\n",
       "      <td>hungry</td>\n",
       "      <td>2.641903e-05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>237</th>\n",
       "      <td>tfidf_237</td>\n",
       "      <td>2.640039e-05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>355</th>\n",
       "      <td>tfidf_355</td>\n",
       "      <td>2.634273e-05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>384</th>\n",
       "      <td>tfidf_384</td>\n",
       "      <td>2.632096e-05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>tfidf_98</td>\n",
       "      <td>2.631519e-05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>448</th>\n",
       "      <td>peach</td>\n",
       "      <td>2.627993e-05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>248</th>\n",
       "      <td>tfidf_248</td>\n",
       "      <td>2.614501e-05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>233</th>\n",
       "      <td>tfidf_233</td>\n",
       "      <td>2.612576e-05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>434</th>\n",
       "      <td>earthy</td>\n",
       "      <td>2.592628e-05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>456</th>\n",
       "      <td>sage</td>\n",
       "      <td>2.561365e-05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>242</th>\n",
       "      <td>tfidf_242</td>\n",
       "      <td>2.556246e-05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>460</th>\n",
       "      <td>sweet</td>\n",
       "      <td>2.538125e-05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>93</th>\n",
       "      <td>tfidf_93</td>\n",
       "      <td>2.502344e-05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>66</th>\n",
       "      <td>tfidf_66</td>\n",
       "      <td>2.478705e-05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>429</th>\n",
       "      <td>chemical</td>\n",
       "      <td>2.455806e-05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>244</th>\n",
       "      <td>tfidf_244</td>\n",
       "      <td>2.411583e-05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>351</th>\n",
       "      <td>tfidf_351</td>\n",
       "      <td>2.409354e-05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>353</th>\n",
       "      <td>tfidf_353</td>\n",
       "      <td>2.390120e-05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>tfidf_23</td>\n",
       "      <td>2.370177e-05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>282</th>\n",
       "      <td>tfidf_282</td>\n",
       "      <td>2.338383e-05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>126</th>\n",
       "      <td>tfidf_126</td>\n",
       "      <td>2.234316e-05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>tfidf_16</td>\n",
       "      <td>2.213871e-05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>438</th>\n",
       "      <td>grapefruit</td>\n",
       "      <td>2.190981e-05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>311</th>\n",
       "      <td>tfidf_311</td>\n",
       "      <td>2.136918e-05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>74</th>\n",
       "      <td>tfidf_74</td>\n",
       "      <td>2.062784e-05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>163</th>\n",
       "      <td>tfidf_163</td>\n",
       "      <td>2.062173e-05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>tfidf_14</td>\n",
       "      <td>2.036267e-05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>tfidf_97</td>\n",
       "      <td>2.031038e-05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>246</th>\n",
       "      <td>tfidf_246</td>\n",
       "      <td>2.016964e-05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>tfidf_10</td>\n",
       "      <td>1.933831e-05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>114</th>\n",
       "      <td>tfidf_114</td>\n",
       "      <td>1.930018e-05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>370</th>\n",
       "      <td>tfidf_370</td>\n",
       "      <td>1.926130e-05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>61</th>\n",
       "      <td>tfidf_61</td>\n",
       "      <td>1.916255e-05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>85</th>\n",
       "      <td>tfidf_85</td>\n",
       "      <td>1.909696e-05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>310</th>\n",
       "      <td>tfidf_310</td>\n",
       "      <td>1.825913e-05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>449</th>\n",
       "      <td>pear</td>\n",
       "      <td>1.789240e-05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>tfidf_19</td>\n",
       "      <td>1.774666e-05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>398</th>\n",
       "      <td>dry eyes</td>\n",
       "      <td>1.762006e-05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>63</th>\n",
       "      <td>tfidf_63</td>\n",
       "      <td>1.754201e-05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>255</th>\n",
       "      <td>tfidf_255</td>\n",
       "      <td>1.737299e-05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54</th>\n",
       "      <td>tfidf_54</td>\n",
       "      <td>1.731466e-05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>119</th>\n",
       "      <td>tfidf_119</td>\n",
       "      <td>1.723642e-05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>118</th>\n",
       "      <td>tfidf_118</td>\n",
       "      <td>1.691252e-05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>207</th>\n",
       "      <td>tfidf_207</td>\n",
       "      <td>1.623759e-05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>173</th>\n",
       "      <td>tfidf_173</td>\n",
       "      <td>1.593446e-05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>467</th>\n",
       "      <td>violet</td>\n",
       "      <td>1.564929e-05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>189</th>\n",
       "      <td>tfidf_189</td>\n",
       "      <td>1.562558e-05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>133</th>\n",
       "      <td>tfidf_133</td>\n",
       "      <td>1.559632e-05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>186</th>\n",
       "      <td>tfidf_186</td>\n",
       "      <td>1.558590e-05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>107</th>\n",
       "      <td>tfidf_107</td>\n",
       "      <td>1.556241e-05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>82</th>\n",
       "      <td>tfidf_82</td>\n",
       "      <td>1.550659e-05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>217</th>\n",
       "      <td>tfidf_217</td>\n",
       "      <td>1.548788e-05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>216</th>\n",
       "      <td>tfidf_216</td>\n",
       "      <td>1.542576e-05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>382</th>\n",
       "      <td>tfidf_382</td>\n",
       "      <td>1.542112e-05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>138</th>\n",
       "      <td>tfidf_138</td>\n",
       "      <td>1.528925e-05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>185</th>\n",
       "      <td>tfidf_185</td>\n",
       "      <td>1.525954e-05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>206</th>\n",
       "      <td>tfidf_206</td>\n",
       "      <td>1.520694e-05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>238</th>\n",
       "      <td>tfidf_238</td>\n",
       "      <td>1.467084e-05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>374</th>\n",
       "      <td>tfidf_374</td>\n",
       "      <td>1.446583e-05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>465</th>\n",
       "      <td>tropical</td>\n",
       "      <td>1.444227e-05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>156</th>\n",
       "      <td>tfidf_156</td>\n",
       "      <td>1.443641e-05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>tfidf_15</td>\n",
       "      <td>1.435344e-05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>205</th>\n",
       "      <td>tfidf_205</td>\n",
       "      <td>1.396699e-05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>364</th>\n",
       "      <td>tfidf_364</td>\n",
       "      <td>1.393870e-05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>tfidf_99</td>\n",
       "      <td>1.371722e-05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>tfidf_45</td>\n",
       "      <td>1.366366e-05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>316</th>\n",
       "      <td>tfidf_316</td>\n",
       "      <td>1.350930e-05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>336</th>\n",
       "      <td>tfidf_336</td>\n",
       "      <td>1.325938e-05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>tfidf_31</td>\n",
       "      <td>1.319489e-05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>65</th>\n",
       "      <td>tfidf_65</td>\n",
       "      <td>1.319052e-05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>221</th>\n",
       "      <td>tfidf_221</td>\n",
       "      <td>1.313546e-05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>64</th>\n",
       "      <td>tfidf_64</td>\n",
       "      <td>1.295613e-05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>tfidf_47</td>\n",
       "      <td>1.292629e-05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>68</th>\n",
       "      <td>tfidf_68</td>\n",
       "      <td>1.289643e-05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>378</th>\n",
       "      <td>tfidf_378</td>\n",
       "      <td>1.276205e-05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>240</th>\n",
       "      <td>tfidf_240</td>\n",
       "      <td>1.272176e-05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52</th>\n",
       "      <td>tfidf_52</td>\n",
       "      <td>1.261073e-05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>152</th>\n",
       "      <td>tfidf_152</td>\n",
       "      <td>1.259359e-05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>112</th>\n",
       "      <td>tfidf_112</td>\n",
       "      <td>1.256276e-05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>223</th>\n",
       "      <td>tfidf_223</td>\n",
       "      <td>1.249350e-05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>334</th>\n",
       "      <td>tfidf_334</td>\n",
       "      <td>1.230763e-05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>57</th>\n",
       "      <td>tfidf_57</td>\n",
       "      <td>1.172855e-05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>455</th>\n",
       "      <td>rose</td>\n",
       "      <td>1.166033e-05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>160</th>\n",
       "      <td>tfidf_160</td>\n",
       "      <td>1.164748e-05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>359</th>\n",
       "      <td>tfidf_359</td>\n",
       "      <td>1.139314e-05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>383</th>\n",
       "      <td>tfidf_383</td>\n",
       "      <td>1.137769e-05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>426</th>\n",
       "      <td>blueberry</td>\n",
       "      <td>1.127643e-05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>196</th>\n",
       "      <td>tfidf_196</td>\n",
       "      <td>1.113372e-05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>110</th>\n",
       "      <td>tfidf_110</td>\n",
       "      <td>1.111956e-05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>412</th>\n",
       "      <td>paranoid</td>\n",
       "      <td>1.104986e-05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>231</th>\n",
       "      <td>tfidf_231</td>\n",
       "      <td>1.103562e-05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>184</th>\n",
       "      <td>tfidf_184</td>\n",
       "      <td>1.102703e-05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>tfidf_35</td>\n",
       "      <td>1.095282e-05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>tfidf_9</td>\n",
       "      <td>1.083569e-05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>123</th>\n",
       "      <td>tfidf_123</td>\n",
       "      <td>1.054337e-05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>468</th>\n",
       "      <td>woody</td>\n",
       "      <td>1.014698e-05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>270</th>\n",
       "      <td>tfidf_270</td>\n",
       "      <td>9.890158e-06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>397</th>\n",
       "      <td>dizzy</td>\n",
       "      <td>9.781125e-06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>88</th>\n",
       "      <td>tfidf_88</td>\n",
       "      <td>9.728507e-06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>219</th>\n",
       "      <td>tfidf_219</td>\n",
       "      <td>9.540774e-06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>273</th>\n",
       "      <td>tfidf_273</td>\n",
       "      <td>9.482413e-06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>111</th>\n",
       "      <td>tfidf_111</td>\n",
       "      <td>9.334463e-06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>201</th>\n",
       "      <td>tfidf_201</td>\n",
       "      <td>9.333153e-06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>193</th>\n",
       "      <td>tfidf_193</td>\n",
       "      <td>9.312737e-06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>271</th>\n",
       "      <td>tfidf_271</td>\n",
       "      <td>9.154793e-06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>365</th>\n",
       "      <td>tfidf_365</td>\n",
       "      <td>9.000162e-06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>tfidf_18</td>\n",
       "      <td>8.863091e-06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>251</th>\n",
       "      <td>tfidf_251</td>\n",
       "      <td>8.639939e-06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>76</th>\n",
       "      <td>tfidf_76</td>\n",
       "      <td>8.400075e-06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>218</th>\n",
       "      <td>tfidf_218</td>\n",
       "      <td>8.196175e-06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>305</th>\n",
       "      <td>tfidf_305</td>\n",
       "      <td>8.174863e-06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>236</th>\n",
       "      <td>tfidf_236</td>\n",
       "      <td>8.098509e-06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>421</th>\n",
       "      <td>ammonia</td>\n",
       "      <td>8.092596e-06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>277</th>\n",
       "      <td>tfidf_277</td>\n",
       "      <td>8.068579e-06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>tfidf_1</td>\n",
       "      <td>8.018919e-06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>302</th>\n",
       "      <td>tfidf_302</td>\n",
       "      <td>7.917799e-06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>314</th>\n",
       "      <td>tfidf_314</td>\n",
       "      <td>7.839083e-06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>422</th>\n",
       "      <td>apple</td>\n",
       "      <td>7.382713e-06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>442</th>\n",
       "      <td>lime</td>\n",
       "      <td>7.181162e-06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>243</th>\n",
       "      <td>tfidf_243</td>\n",
       "      <td>7.164625e-06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>344</th>\n",
       "      <td>tfidf_344</td>\n",
       "      <td>7.152928e-06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>146</th>\n",
       "      <td>tfidf_146</td>\n",
       "      <td>7.102688e-06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>tfidf_8</td>\n",
       "      <td>6.893867e-06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>264</th>\n",
       "      <td>tfidf_264</td>\n",
       "      <td>6.860947e-06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>356</th>\n",
       "      <td>tfidf_356</td>\n",
       "      <td>6.846988e-06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>354</th>\n",
       "      <td>tfidf_354</td>\n",
       "      <td>6.654521e-06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>228</th>\n",
       "      <td>tfidf_228</td>\n",
       "      <td>6.537196e-06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>209</th>\n",
       "      <td>tfidf_209</td>\n",
       "      <td>6.501540e-06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>283</th>\n",
       "      <td>tfidf_283</td>\n",
       "      <td>6.493678e-06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>215</th>\n",
       "      <td>tfidf_215</td>\n",
       "      <td>6.434339e-06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>408</th>\n",
       "      <td>headache</td>\n",
       "      <td>6.282483e-06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>387</th>\n",
       "      <td>tfidf_387</td>\n",
       "      <td>6.279307e-06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>361</th>\n",
       "      <td>tfidf_361</td>\n",
       "      <td>6.172817e-06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>326</th>\n",
       "      <td>tfidf_326</td>\n",
       "      <td>6.115950e-06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>229</th>\n",
       "      <td>tfidf_229</td>\n",
       "      <td>6.106503e-06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>392</th>\n",
       "      <td>anxious</td>\n",
       "      <td>6.086943e-06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>317</th>\n",
       "      <td>tfidf_317</td>\n",
       "      <td>6.064738e-06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>150</th>\n",
       "      <td>tfidf_150</td>\n",
       "      <td>6.061395e-06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>298</th>\n",
       "      <td>tfidf_298</td>\n",
       "      <td>6.032118e-06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>220</th>\n",
       "      <td>tfidf_220</td>\n",
       "      <td>5.961244e-06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>202</th>\n",
       "      <td>tfidf_202</td>\n",
       "      <td>5.736214e-06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>tfidf_21</td>\n",
       "      <td>5.526113e-06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>70</th>\n",
       "      <td>tfidf_70</td>\n",
       "      <td>5.499360e-06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59</th>\n",
       "      <td>tfidf_59</td>\n",
       "      <td>5.456948e-06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>452</th>\n",
       "      <td>pineapple</td>\n",
       "      <td>5.418750e-06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>427</th>\n",
       "      <td>butter</td>\n",
       "      <td>5.415245e-06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>72</th>\n",
       "      <td>tfidf_72</td>\n",
       "      <td>5.408344e-06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>318</th>\n",
       "      <td>tfidf_318</td>\n",
       "      <td>5.365242e-06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>tfidf_4</td>\n",
       "      <td>5.326962e-06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>154</th>\n",
       "      <td>tfidf_154</td>\n",
       "      <td>5.247716e-06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>tfidf_0</td>\n",
       "      <td>5.139023e-06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>348</th>\n",
       "      <td>tfidf_348</td>\n",
       "      <td>5.092974e-06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>428</th>\n",
       "      <td>cheese</td>\n",
       "      <td>4.939189e-06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>71</th>\n",
       "      <td>tfidf_71</td>\n",
       "      <td>4.764729e-06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>320</th>\n",
       "      <td>tfidf_320</td>\n",
       "      <td>4.532998e-06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>176</th>\n",
       "      <td>tfidf_176</td>\n",
       "      <td>4.495773e-06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>tfidf_44</td>\n",
       "      <td>4.482645e-06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>87</th>\n",
       "      <td>tfidf_87</td>\n",
       "      <td>4.430417e-06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>235</th>\n",
       "      <td>tfidf_235</td>\n",
       "      <td>4.227216e-06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>170</th>\n",
       "      <td>tfidf_170</td>\n",
       "      <td>4.082023e-06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>272</th>\n",
       "      <td>tfidf_272</td>\n",
       "      <td>4.053747e-06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>tfidf_41</td>\n",
       "      <td>4.037072e-06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>263</th>\n",
       "      <td>tfidf_263</td>\n",
       "      <td>3.962136e-06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>103</th>\n",
       "      <td>tfidf_103</td>\n",
       "      <td>3.961278e-06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50</th>\n",
       "      <td>tfidf_50</td>\n",
       "      <td>3.939144e-06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>226</th>\n",
       "      <td>tfidf_226</td>\n",
       "      <td>3.927894e-06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>330</th>\n",
       "      <td>tfidf_330</td>\n",
       "      <td>3.901321e-06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>89</th>\n",
       "      <td>tfidf_89</td>\n",
       "      <td>3.804854e-06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>214</th>\n",
       "      <td>tfidf_214</td>\n",
       "      <td>3.756417e-06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>60</th>\n",
       "      <td>tfidf_60</td>\n",
       "      <td>3.711248e-06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>296</th>\n",
       "      <td>tfidf_296</td>\n",
       "      <td>3.576516e-06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>147</th>\n",
       "      <td>tfidf_147</td>\n",
       "      <td>3.557020e-06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>291</th>\n",
       "      <td>tfidf_291</td>\n",
       "      <td>3.547555e-06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>tfidf_20</td>\n",
       "      <td>3.542974e-06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>444</th>\n",
       "      <td>menthol</td>\n",
       "      <td>3.466499e-06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>303</th>\n",
       "      <td>tfidf_303</td>\n",
       "      <td>3.463317e-06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>268</th>\n",
       "      <td>tfidf_268</td>\n",
       "      <td>3.428238e-06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>135</th>\n",
       "      <td>tfidf_135</td>\n",
       "      <td>3.278868e-06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>322</th>\n",
       "      <td>tfidf_322</td>\n",
       "      <td>3.275154e-06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>335</th>\n",
       "      <td>tfidf_335</td>\n",
       "      <td>3.236998e-06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>346</th>\n",
       "      <td>tfidf_346</td>\n",
       "      <td>3.220845e-06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>385</th>\n",
       "      <td>tfidf_385</td>\n",
       "      <td>3.079699e-06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>252</th>\n",
       "      <td>tfidf_252</td>\n",
       "      <td>3.020919e-06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>389</th>\n",
       "      <td>indica</td>\n",
       "      <td>2.985160e-06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>165</th>\n",
       "      <td>tfidf_165</td>\n",
       "      <td>2.849962e-06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>tfidf_36</td>\n",
       "      <td>2.750509e-06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>192</th>\n",
       "      <td>tfidf_192</td>\n",
       "      <td>2.735896e-06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>174</th>\n",
       "      <td>tfidf_174</td>\n",
       "      <td>2.652821e-06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>287</th>\n",
       "      <td>tfidf_287</td>\n",
       "      <td>2.567705e-06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>284</th>\n",
       "      <td>tfidf_284</td>\n",
       "      <td>2.525409e-06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>306</th>\n",
       "      <td>tfidf_306</td>\n",
       "      <td>2.490873e-06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>325</th>\n",
       "      <td>tfidf_325</td>\n",
       "      <td>2.453903e-06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>148</th>\n",
       "      <td>tfidf_148</td>\n",
       "      <td>2.426353e-06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>266</th>\n",
       "      <td>tfidf_266</td>\n",
       "      <td>2.395433e-06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>232</th>\n",
       "      <td>tfidf_232</td>\n",
       "      <td>2.391214e-06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>280</th>\n",
       "      <td>tfidf_280</td>\n",
       "      <td>2.334366e-06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>368</th>\n",
       "      <td>tfidf_368</td>\n",
       "      <td>2.153744e-06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>446</th>\n",
       "      <td>nutty</td>\n",
       "      <td>2.140995e-06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>tfidf_25</td>\n",
       "      <td>2.096588e-06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>352</th>\n",
       "      <td>tfidf_352</td>\n",
       "      <td>2.000942e-06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>464</th>\n",
       "      <td>tree</td>\n",
       "      <td>1.974408e-06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>436</th>\n",
       "      <td>fruit</td>\n",
       "      <td>1.943040e-06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>91</th>\n",
       "      <td>tfidf_91</td>\n",
       "      <td>1.926824e-06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>381</th>\n",
       "      <td>tfidf_381</td>\n",
       "      <td>1.918936e-06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>225</th>\n",
       "      <td>tfidf_225</td>\n",
       "      <td>1.840246e-06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>358</th>\n",
       "      <td>tfidf_358</td>\n",
       "      <td>1.831503e-06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>169</th>\n",
       "      <td>tfidf_169</td>\n",
       "      <td>1.730400e-06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>120</th>\n",
       "      <td>tfidf_120</td>\n",
       "      <td>1.703154e-06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>164</th>\n",
       "      <td>tfidf_164</td>\n",
       "      <td>1.664897e-06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>67</th>\n",
       "      <td>tfidf_67</td>\n",
       "      <td>1.535747e-06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>462</th>\n",
       "      <td>tea</td>\n",
       "      <td>1.489828e-06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>445</th>\n",
       "      <td>mint</td>\n",
       "      <td>1.457752e-06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53</th>\n",
       "      <td>tfidf_53</td>\n",
       "      <td>1.260760e-06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>tfidf_40</td>\n",
       "      <td>1.250234e-06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>308</th>\n",
       "      <td>tfidf_308</td>\n",
       "      <td>1.230526e-06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>tfidf_95</td>\n",
       "      <td>1.208289e-06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>tfidf_28</td>\n",
       "      <td>1.151847e-06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>tfidf_12</td>\n",
       "      <td>1.120371e-06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>466</th>\n",
       "      <td>vanilla</td>\n",
       "      <td>1.092439e-06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>304</th>\n",
       "      <td>tfidf_304</td>\n",
       "      <td>1.011158e-06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>125</th>\n",
       "      <td>tfidf_125</td>\n",
       "      <td>1.005197e-06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>208</th>\n",
       "      <td>tfidf_208</td>\n",
       "      <td>9.939714e-07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>347</th>\n",
       "      <td>tfidf_347</td>\n",
       "      <td>9.801135e-07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>375</th>\n",
       "      <td>tfidf_375</td>\n",
       "      <td>9.713731e-07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>295</th>\n",
       "      <td>tfidf_295</td>\n",
       "      <td>9.673458e-07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>83</th>\n",
       "      <td>tfidf_83</td>\n",
       "      <td>9.661675e-07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>259</th>\n",
       "      <td>tfidf_259</td>\n",
       "      <td>9.597726e-07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>290</th>\n",
       "      <td>tfidf_290</td>\n",
       "      <td>9.537515e-07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>423</th>\n",
       "      <td>apricot</td>\n",
       "      <td>9.091421e-07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>313</th>\n",
       "      <td>tfidf_313</td>\n",
       "      <td>8.769140e-07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>92</th>\n",
       "      <td>tfidf_92</td>\n",
       "      <td>8.083940e-07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>425</th>\n",
       "      <td>blue cheese</td>\n",
       "      <td>7.605929e-07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>tfidf_13</td>\n",
       "      <td>7.510220e-07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>191</th>\n",
       "      <td>tfidf_191</td>\n",
       "      <td>7.507570e-07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>69</th>\n",
       "      <td>tfidf_69</td>\n",
       "      <td>6.877357e-07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>180</th>\n",
       "      <td>tfidf_180</td>\n",
       "      <td>6.744426e-07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>183</th>\n",
       "      <td>tfidf_183</td>\n",
       "      <td>6.554240e-07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>279</th>\n",
       "      <td>tfidf_279</td>\n",
       "      <td>5.078970e-07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>102</th>\n",
       "      <td>tfidf_102</td>\n",
       "      <td>5.071511e-07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>tfidf_49</td>\n",
       "      <td>5.058645e-07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>257</th>\n",
       "      <td>tfidf_257</td>\n",
       "      <td>5.033788e-07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>171</th>\n",
       "      <td>tfidf_171</td>\n",
       "      <td>4.887023e-07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>77</th>\n",
       "      <td>tfidf_77</td>\n",
       "      <td>4.443853e-07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>377</th>\n",
       "      <td>tfidf_377</td>\n",
       "      <td>2.572740e-07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>288</th>\n",
       "      <td>tfidf_288</td>\n",
       "      <td>2.536027e-07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>301</th>\n",
       "      <td>tfidf_301</td>\n",
       "      <td>2.517108e-07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>tfidf_27</td>\n",
       "      <td>2.490613e-07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>213</th>\n",
       "      <td>tfidf_213</td>\n",
       "      <td>2.384952e-07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>212</th>\n",
       "      <td>tfidf_212</td>\n",
       "      <td>7.312899e-08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>315</th>\n",
       "      <td>tfidf_315</td>\n",
       "      <td>8.239048e-17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>256</th>\n",
       "      <td>tfidf_256</td>\n",
       "      <td>7.869875e-17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>327</th>\n",
       "      <td>tfidf_327</td>\n",
       "      <td>6.687059e-17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>299</th>\n",
       "      <td>tfidf_299</td>\n",
       "      <td>3.353015e-17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>276</th>\n",
       "      <td>tfidf_276</td>\n",
       "      <td>2.455783e-17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>100</th>\n",
       "      <td>tfidf_100</td>\n",
       "      <td>1.323494e-17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>157</th>\n",
       "      <td>tfidf_157</td>\n",
       "      <td>1.092996e-17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>450</th>\n",
       "      <td>pepper</td>\n",
       "      <td>9.809543e-18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>113</th>\n",
       "      <td>tfidf_113</td>\n",
       "      <td>6.208903e-18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>254</th>\n",
       "      <td>tfidf_254</td>\n",
       "      <td>2.912306e-18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>339</th>\n",
       "      <td>tfidf_339</td>\n",
       "      <td>1.929166e-18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51</th>\n",
       "      <td>tfidf_51</td>\n",
       "      <td>1.632310e-18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>241</th>\n",
       "      <td>tfidf_241</td>\n",
       "      <td>1.146764e-18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>459</th>\n",
       "      <td>strawberry</td>\n",
       "      <td>8.870427e-19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>396</th>\n",
       "      <td>depression</td>\n",
       "      <td>4.380981e-19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>410</th>\n",
       "      <td>migraines</td>\n",
       "      <td>4.072131e-19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>261</th>\n",
       "      <td>tfidf_261</td>\n",
       "      <td>4.596100e-20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>403</th>\n",
       "      <td>eye pressure</td>\n",
       "      <td>0.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>391</th>\n",
       "      <td>anxiety</td>\n",
       "      <td>0.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>404</th>\n",
       "      <td>fatigue</td>\n",
       "      <td>0.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>401</th>\n",
       "      <td>epilepsy</td>\n",
       "      <td>0.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>411</th>\n",
       "      <td>pain</td>\n",
       "      <td>0.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>453</th>\n",
       "      <td>plum</td>\n",
       "      <td>0.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>416</th>\n",
       "      <td>spasticity</td>\n",
       "      <td>0.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>394</th>\n",
       "      <td>arthritis</td>\n",
       "      <td>0.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>414</th>\n",
       "      <td>seizures</td>\n",
       "      <td>0.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>417</th>\n",
       "      <td>stress</td>\n",
       "      <td>0.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>463</th>\n",
       "      <td>tobacco</td>\n",
       "      <td>-3.199000e-20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>181</th>\n",
       "      <td>tfidf_181</td>\n",
       "      <td>-3.554808e-19</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         features         score\n",
       "451          pine  7.034848e-01\n",
       "390        sativa  1.193894e-01\n",
       "447        orange  7.154758e-02\n",
       "62       tfidf_62  3.173269e-02\n",
       "431        citrus  1.545548e-02\n",
       "38       tfidf_38  1.529211e-02\n",
       "140     tfidf_140  5.301782e-03\n",
       "388        hybrid  3.999261e-03\n",
       "441         lemon  3.439013e-03\n",
       "161     tfidf_161  2.035684e-03\n",
       "367     tfidf_367  1.138131e-03\n",
       "338     tfidf_338  1.130323e-03\n",
       "249     tfidf_249  7.587222e-04\n",
       "130     tfidf_130  7.257191e-04\n",
       "435       flowery  7.045836e-04\n",
       "158     tfidf_158  6.122193e-04\n",
       "253     tfidf_253  6.041094e-04\n",
       "345     tfidf_345  6.021046e-04\n",
       "328     tfidf_328  5.295510e-04\n",
       "200     tfidf_200  5.184117e-04\n",
       "105     tfidf_105  5.079302e-04\n",
       "48       tfidf_48  4.987579e-04\n",
       "5         tfidf_5  4.879631e-04\n",
       "222     tfidf_222  4.848107e-04\n",
       "307     tfidf_307  4.046249e-04\n",
       "46       tfidf_46  4.004633e-04\n",
       "363     tfidf_363  3.834864e-04\n",
       "26       tfidf_26  3.755910e-04\n",
       "366     tfidf_366  3.685354e-04\n",
       "197     tfidf_197  3.390576e-04\n",
       "349     tfidf_349  3.267724e-04\n",
       "121     tfidf_121  3.219647e-04\n",
       "402      euphoric  3.026008e-04\n",
       "94       tfidf_94  3.016969e-04\n",
       "210     tfidf_210  2.907839e-04\n",
       "415        sleepy  2.902143e-04\n",
       "457         skunk  2.842822e-04\n",
       "329     tfidf_329  2.717306e-04\n",
       "239     tfidf_239  2.644476e-04\n",
       "145     tfidf_145  2.514300e-04\n",
       "11       tfidf_11  2.492591e-04\n",
       "343     tfidf_343  2.447265e-04\n",
       "371     tfidf_371  2.352341e-04\n",
       "424         berry  2.156951e-04\n",
       "393       aroused  2.129484e-04\n",
       "419        tingly  1.984651e-04\n",
       "37       tfidf_37  1.979708e-04\n",
       "155     tfidf_155  1.844728e-04\n",
       "39       tfidf_39  1.798762e-04\n",
       "58       tfidf_58  1.795273e-04\n",
       "437         grape  1.785302e-04\n",
       "153     tfidf_153  1.767164e-04\n",
       "134     tfidf_134  1.758628e-04\n",
       "167     tfidf_167  1.627669e-04\n",
       "149     tfidf_149  1.580988e-04\n",
       "80       tfidf_80  1.567970e-04\n",
       "55       tfidf_55  1.553641e-04\n",
       "141     tfidf_141  1.520103e-04\n",
       "269     tfidf_269  1.430016e-04\n",
       "190     tfidf_190  1.371915e-04\n",
       "369     tfidf_369  1.362035e-04\n",
       "285     tfidf_285  1.341112e-04\n",
       "309     tfidf_309  1.333412e-04\n",
       "34       tfidf_34  1.305390e-04\n",
       "109     tfidf_109  1.281698e-04\n",
       "292     tfidf_292  1.280185e-04\n",
       "245     tfidf_245  1.273274e-04\n",
       "454       pungent  1.273061e-04\n",
       "168     tfidf_168  1.256292e-04\n",
       "332     tfidf_332  1.205493e-04\n",
       "458  spicy/herbal  1.200469e-04\n",
       "162     tfidf_162  1.126521e-04\n",
       "128     tfidf_128  1.088837e-04\n",
       "319     tfidf_319  1.075397e-04\n",
       "117     tfidf_117  1.032242e-04\n",
       "96       tfidf_96  1.019175e-04\n",
       "312     tfidf_312  1.014665e-04\n",
       "224     tfidf_224  9.979611e-05\n",
       "108     tfidf_108  9.628348e-05\n",
       "380     tfidf_380  8.982128e-05\n",
       "178     tfidf_178  8.674215e-05\n",
       "376     tfidf_376  8.368690e-05\n",
       "75       tfidf_75  8.242960e-05\n",
       "43       tfidf_43  8.234384e-05\n",
       "433        diesel  8.225703e-05\n",
       "265     tfidf_265  8.074914e-05\n",
       "362     tfidf_362  8.064790e-05\n",
       "234     tfidf_234  7.902805e-05\n",
       "151     tfidf_151  7.725983e-05\n",
       "227     tfidf_227  7.538504e-05\n",
       "297     tfidf_297  7.471361e-05\n",
       "182     tfidf_182  7.341876e-05\n",
       "32       tfidf_32  7.326190e-05\n",
       "337     tfidf_337  7.215806e-05\n",
       "3         tfidf_3  7.192743e-05\n",
       "30       tfidf_30  7.079374e-05\n",
       "342     tfidf_342  7.067568e-05\n",
       "405       focused  7.062295e-05\n",
       "373     tfidf_373  6.895003e-05\n",
       "203     tfidf_203  6.879830e-05\n",
       "289     tfidf_289  6.757679e-05\n",
       "131     tfidf_131  6.734844e-05\n",
       "258     tfidf_258  6.696700e-05\n",
       "179     tfidf_179  6.677409e-05\n",
       "101     tfidf_101  6.563393e-05\n",
       "321     tfidf_321  6.465363e-05\n",
       "106     tfidf_106  6.368961e-05\n",
       "144     tfidf_144  6.310072e-05\n",
       "400     energetic  6.241948e-05\n",
       "331     tfidf_331  6.147830e-05\n",
       "24       tfidf_24  6.121755e-05\n",
       "42       tfidf_42  5.996259e-05\n",
       "199     tfidf_199  5.991088e-05\n",
       "198     tfidf_198  5.907833e-05\n",
       "79       tfidf_79  5.875160e-05\n",
       "267     tfidf_267  5.815536e-05\n",
       "324     tfidf_324  5.767712e-05\n",
       "395      creative  5.631096e-05\n",
       "406        giggly  5.571089e-05\n",
       "250     tfidf_250  5.554624e-05\n",
       "137     tfidf_137  5.532570e-05\n",
       "195     tfidf_195  5.532019e-05\n",
       "6         tfidf_6  5.434364e-05\n",
       "420      uplifted  5.186893e-05\n",
       "341     tfidf_341  5.149238e-05\n",
       "274     tfidf_274  5.130243e-05\n",
       "443         mango  5.122480e-05\n",
       "379     tfidf_379  5.052090e-05\n",
       "159     tfidf_159  5.007676e-05\n",
       "278     tfidf_278  4.935524e-05\n",
       "360     tfidf_360  4.912302e-05\n",
       "281     tfidf_281  4.890108e-05\n",
       "78       tfidf_78  4.880038e-05\n",
       "7         tfidf_7  4.853368e-05\n",
       "372     tfidf_372  4.852219e-05\n",
       "33       tfidf_33  4.784751e-05\n",
       "399     dry mouth  4.722526e-05\n",
       "407         happy  4.629022e-05\n",
       "129     tfidf_129  4.571345e-05\n",
       "136     tfidf_136  4.544765e-05\n",
       "142     tfidf_142  4.500529e-05\n",
       "115     tfidf_115  4.454446e-05\n",
       "333     tfidf_333  4.345501e-05\n",
       "143     tfidf_143  4.328038e-05\n",
       "439         honey  4.320621e-05\n",
       "413       relaxed  4.294698e-05\n",
       "340     tfidf_340  4.257891e-05\n",
       "430      chestnut  4.088300e-05\n",
       "461           tar  4.076223e-05\n",
       "175     tfidf_175  4.070738e-05\n",
       "350     tfidf_350  4.047064e-05\n",
       "127     tfidf_127  4.014687e-05\n",
       "204     tfidf_204  3.960021e-05\n",
       "177     tfidf_177  3.954573e-05\n",
       "262     tfidf_262  3.937440e-05\n",
       "418     talkative  3.937384e-05\n",
       "73       tfidf_73  3.934030e-05\n",
       "275     tfidf_275  3.894263e-05\n",
       "260     tfidf_260  3.887792e-05\n",
       "90       tfidf_90  3.804393e-05\n",
       "188     tfidf_188  3.723743e-05\n",
       "124     tfidf_124  3.695678e-05\n",
       "29       tfidf_29  3.600592e-05\n",
       "323     tfidf_323  3.519680e-05\n",
       "122     tfidf_122  3.474107e-05\n",
       "86       tfidf_86  3.428616e-05\n",
       "81       tfidf_81  3.427571e-05\n",
       "386     tfidf_386  3.393397e-05\n",
       "172     tfidf_172  3.359684e-05\n",
       "194     tfidf_194  3.336177e-05\n",
       "247     tfidf_247  3.328637e-05\n",
       "116     tfidf_116  3.288701e-05\n",
       "211     tfidf_211  3.235027e-05\n",
       "56       tfidf_56  3.183188e-05\n",
       "104     tfidf_104  3.176285e-05\n",
       "357     tfidf_357  3.154305e-05\n",
       "293     tfidf_293  3.084952e-05\n",
       "286     tfidf_286  3.061168e-05\n",
       "187     tfidf_187  3.060336e-05\n",
       "17       tfidf_17  3.023085e-05\n",
       "2         tfidf_2  2.955966e-05\n",
       "22       tfidf_22  2.931175e-05\n",
       "132     tfidf_132  2.928512e-05\n",
       "440      lavender  2.830653e-05\n",
       "84       tfidf_84  2.775932e-05\n",
       "294     tfidf_294  2.771050e-05\n",
       "230     tfidf_230  2.707475e-05\n",
       "139     tfidf_139  2.702862e-05\n",
       "300     tfidf_300  2.698110e-05\n",
       "432        coffee  2.680580e-05\n",
       "166     tfidf_166  2.676794e-05\n",
       "409        hungry  2.641903e-05\n",
       "237     tfidf_237  2.640039e-05\n",
       "355     tfidf_355  2.634273e-05\n",
       "384     tfidf_384  2.632096e-05\n",
       "98       tfidf_98  2.631519e-05\n",
       "448         peach  2.627993e-05\n",
       "248     tfidf_248  2.614501e-05\n",
       "233     tfidf_233  2.612576e-05\n",
       "434        earthy  2.592628e-05\n",
       "456          sage  2.561365e-05\n",
       "242     tfidf_242  2.556246e-05\n",
       "460         sweet  2.538125e-05\n",
       "93       tfidf_93  2.502344e-05\n",
       "66       tfidf_66  2.478705e-05\n",
       "429      chemical  2.455806e-05\n",
       "244     tfidf_244  2.411583e-05\n",
       "351     tfidf_351  2.409354e-05\n",
       "353     tfidf_353  2.390120e-05\n",
       "23       tfidf_23  2.370177e-05\n",
       "282     tfidf_282  2.338383e-05\n",
       "126     tfidf_126  2.234316e-05\n",
       "16       tfidf_16  2.213871e-05\n",
       "438    grapefruit  2.190981e-05\n",
       "311     tfidf_311  2.136918e-05\n",
       "74       tfidf_74  2.062784e-05\n",
       "163     tfidf_163  2.062173e-05\n",
       "14       tfidf_14  2.036267e-05\n",
       "97       tfidf_97  2.031038e-05\n",
       "246     tfidf_246  2.016964e-05\n",
       "10       tfidf_10  1.933831e-05\n",
       "114     tfidf_114  1.930018e-05\n",
       "370     tfidf_370  1.926130e-05\n",
       "61       tfidf_61  1.916255e-05\n",
       "85       tfidf_85  1.909696e-05\n",
       "310     tfidf_310  1.825913e-05\n",
       "449          pear  1.789240e-05\n",
       "19       tfidf_19  1.774666e-05\n",
       "398      dry eyes  1.762006e-05\n",
       "63       tfidf_63  1.754201e-05\n",
       "255     tfidf_255  1.737299e-05\n",
       "54       tfidf_54  1.731466e-05\n",
       "119     tfidf_119  1.723642e-05\n",
       "118     tfidf_118  1.691252e-05\n",
       "207     tfidf_207  1.623759e-05\n",
       "173     tfidf_173  1.593446e-05\n",
       "467        violet  1.564929e-05\n",
       "189     tfidf_189  1.562558e-05\n",
       "133     tfidf_133  1.559632e-05\n",
       "186     tfidf_186  1.558590e-05\n",
       "107     tfidf_107  1.556241e-05\n",
       "82       tfidf_82  1.550659e-05\n",
       "217     tfidf_217  1.548788e-05\n",
       "216     tfidf_216  1.542576e-05\n",
       "382     tfidf_382  1.542112e-05\n",
       "138     tfidf_138  1.528925e-05\n",
       "185     tfidf_185  1.525954e-05\n",
       "206     tfidf_206  1.520694e-05\n",
       "238     tfidf_238  1.467084e-05\n",
       "374     tfidf_374  1.446583e-05\n",
       "465      tropical  1.444227e-05\n",
       "156     tfidf_156  1.443641e-05\n",
       "15       tfidf_15  1.435344e-05\n",
       "205     tfidf_205  1.396699e-05\n",
       "364     tfidf_364  1.393870e-05\n",
       "99       tfidf_99  1.371722e-05\n",
       "45       tfidf_45  1.366366e-05\n",
       "316     tfidf_316  1.350930e-05\n",
       "336     tfidf_336  1.325938e-05\n",
       "31       tfidf_31  1.319489e-05\n",
       "65       tfidf_65  1.319052e-05\n",
       "221     tfidf_221  1.313546e-05\n",
       "64       tfidf_64  1.295613e-05\n",
       "47       tfidf_47  1.292629e-05\n",
       "68       tfidf_68  1.289643e-05\n",
       "378     tfidf_378  1.276205e-05\n",
       "240     tfidf_240  1.272176e-05\n",
       "52       tfidf_52  1.261073e-05\n",
       "152     tfidf_152  1.259359e-05\n",
       "112     tfidf_112  1.256276e-05\n",
       "223     tfidf_223  1.249350e-05\n",
       "334     tfidf_334  1.230763e-05\n",
       "57       tfidf_57  1.172855e-05\n",
       "455          rose  1.166033e-05\n",
       "160     tfidf_160  1.164748e-05\n",
       "359     tfidf_359  1.139314e-05\n",
       "383     tfidf_383  1.137769e-05\n",
       "426     blueberry  1.127643e-05\n",
       "196     tfidf_196  1.113372e-05\n",
       "110     tfidf_110  1.111956e-05\n",
       "412      paranoid  1.104986e-05\n",
       "231     tfidf_231  1.103562e-05\n",
       "184     tfidf_184  1.102703e-05\n",
       "35       tfidf_35  1.095282e-05\n",
       "9         tfidf_9  1.083569e-05\n",
       "123     tfidf_123  1.054337e-05\n",
       "468         woody  1.014698e-05\n",
       "270     tfidf_270  9.890158e-06\n",
       "397         dizzy  9.781125e-06\n",
       "88       tfidf_88  9.728507e-06\n",
       "219     tfidf_219  9.540774e-06\n",
       "273     tfidf_273  9.482413e-06\n",
       "111     tfidf_111  9.334463e-06\n",
       "201     tfidf_201  9.333153e-06\n",
       "193     tfidf_193  9.312737e-06\n",
       "271     tfidf_271  9.154793e-06\n",
       "365     tfidf_365  9.000162e-06\n",
       "18       tfidf_18  8.863091e-06\n",
       "251     tfidf_251  8.639939e-06\n",
       "76       tfidf_76  8.400075e-06\n",
       "218     tfidf_218  8.196175e-06\n",
       "305     tfidf_305  8.174863e-06\n",
       "236     tfidf_236  8.098509e-06\n",
       "421       ammonia  8.092596e-06\n",
       "277     tfidf_277  8.068579e-06\n",
       "1         tfidf_1  8.018919e-06\n",
       "302     tfidf_302  7.917799e-06\n",
       "314     tfidf_314  7.839083e-06\n",
       "422         apple  7.382713e-06\n",
       "442          lime  7.181162e-06\n",
       "243     tfidf_243  7.164625e-06\n",
       "344     tfidf_344  7.152928e-06\n",
       "146     tfidf_146  7.102688e-06\n",
       "8         tfidf_8  6.893867e-06\n",
       "264     tfidf_264  6.860947e-06\n",
       "356     tfidf_356  6.846988e-06\n",
       "354     tfidf_354  6.654521e-06\n",
       "228     tfidf_228  6.537196e-06\n",
       "209     tfidf_209  6.501540e-06\n",
       "283     tfidf_283  6.493678e-06\n",
       "215     tfidf_215  6.434339e-06\n",
       "408      headache  6.282483e-06\n",
       "387     tfidf_387  6.279307e-06\n",
       "361     tfidf_361  6.172817e-06\n",
       "326     tfidf_326  6.115950e-06\n",
       "229     tfidf_229  6.106503e-06\n",
       "392       anxious  6.086943e-06\n",
       "317     tfidf_317  6.064738e-06\n",
       "150     tfidf_150  6.061395e-06\n",
       "298     tfidf_298  6.032118e-06\n",
       "220     tfidf_220  5.961244e-06\n",
       "202     tfidf_202  5.736214e-06\n",
       "21       tfidf_21  5.526113e-06\n",
       "70       tfidf_70  5.499360e-06\n",
       "59       tfidf_59  5.456948e-06\n",
       "452     pineapple  5.418750e-06\n",
       "427        butter  5.415245e-06\n",
       "72       tfidf_72  5.408344e-06\n",
       "318     tfidf_318  5.365242e-06\n",
       "4         tfidf_4  5.326962e-06\n",
       "154     tfidf_154  5.247716e-06\n",
       "0         tfidf_0  5.139023e-06\n",
       "348     tfidf_348  5.092974e-06\n",
       "428        cheese  4.939189e-06\n",
       "71       tfidf_71  4.764729e-06\n",
       "320     tfidf_320  4.532998e-06\n",
       "176     tfidf_176  4.495773e-06\n",
       "44       tfidf_44  4.482645e-06\n",
       "87       tfidf_87  4.430417e-06\n",
       "235     tfidf_235  4.227216e-06\n",
       "170     tfidf_170  4.082023e-06\n",
       "272     tfidf_272  4.053747e-06\n",
       "41       tfidf_41  4.037072e-06\n",
       "263     tfidf_263  3.962136e-06\n",
       "103     tfidf_103  3.961278e-06\n",
       "50       tfidf_50  3.939144e-06\n",
       "226     tfidf_226  3.927894e-06\n",
       "330     tfidf_330  3.901321e-06\n",
       "89       tfidf_89  3.804854e-06\n",
       "214     tfidf_214  3.756417e-06\n",
       "60       tfidf_60  3.711248e-06\n",
       "296     tfidf_296  3.576516e-06\n",
       "147     tfidf_147  3.557020e-06\n",
       "291     tfidf_291  3.547555e-06\n",
       "20       tfidf_20  3.542974e-06\n",
       "444       menthol  3.466499e-06\n",
       "303     tfidf_303  3.463317e-06\n",
       "268     tfidf_268  3.428238e-06\n",
       "135     tfidf_135  3.278868e-06\n",
       "322     tfidf_322  3.275154e-06\n",
       "335     tfidf_335  3.236998e-06\n",
       "346     tfidf_346  3.220845e-06\n",
       "385     tfidf_385  3.079699e-06\n",
       "252     tfidf_252  3.020919e-06\n",
       "389        indica  2.985160e-06\n",
       "165     tfidf_165  2.849962e-06\n",
       "36       tfidf_36  2.750509e-06\n",
       "192     tfidf_192  2.735896e-06\n",
       "174     tfidf_174  2.652821e-06\n",
       "287     tfidf_287  2.567705e-06\n",
       "284     tfidf_284  2.525409e-06\n",
       "306     tfidf_306  2.490873e-06\n",
       "325     tfidf_325  2.453903e-06\n",
       "148     tfidf_148  2.426353e-06\n",
       "266     tfidf_266  2.395433e-06\n",
       "232     tfidf_232  2.391214e-06\n",
       "280     tfidf_280  2.334366e-06\n",
       "368     tfidf_368  2.153744e-06\n",
       "446         nutty  2.140995e-06\n",
       "25       tfidf_25  2.096588e-06\n",
       "352     tfidf_352  2.000942e-06\n",
       "464          tree  1.974408e-06\n",
       "436         fruit  1.943040e-06\n",
       "91       tfidf_91  1.926824e-06\n",
       "381     tfidf_381  1.918936e-06\n",
       "225     tfidf_225  1.840246e-06\n",
       "358     tfidf_358  1.831503e-06\n",
       "169     tfidf_169  1.730400e-06\n",
       "120     tfidf_120  1.703154e-06\n",
       "164     tfidf_164  1.664897e-06\n",
       "67       tfidf_67  1.535747e-06\n",
       "462           tea  1.489828e-06\n",
       "445          mint  1.457752e-06\n",
       "53       tfidf_53  1.260760e-06\n",
       "40       tfidf_40  1.250234e-06\n",
       "308     tfidf_308  1.230526e-06\n",
       "95       tfidf_95  1.208289e-06\n",
       "28       tfidf_28  1.151847e-06\n",
       "12       tfidf_12  1.120371e-06\n",
       "466       vanilla  1.092439e-06\n",
       "304     tfidf_304  1.011158e-06\n",
       "125     tfidf_125  1.005197e-06\n",
       "208     tfidf_208  9.939714e-07\n",
       "347     tfidf_347  9.801135e-07\n",
       "375     tfidf_375  9.713731e-07\n",
       "295     tfidf_295  9.673458e-07\n",
       "83       tfidf_83  9.661675e-07\n",
       "259     tfidf_259  9.597726e-07\n",
       "290     tfidf_290  9.537515e-07\n",
       "423       apricot  9.091421e-07\n",
       "313     tfidf_313  8.769140e-07\n",
       "92       tfidf_92  8.083940e-07\n",
       "425   blue cheese  7.605929e-07\n",
       "13       tfidf_13  7.510220e-07\n",
       "191     tfidf_191  7.507570e-07\n",
       "69       tfidf_69  6.877357e-07\n",
       "180     tfidf_180  6.744426e-07\n",
       "183     tfidf_183  6.554240e-07\n",
       "279     tfidf_279  5.078970e-07\n",
       "102     tfidf_102  5.071511e-07\n",
       "49       tfidf_49  5.058645e-07\n",
       "257     tfidf_257  5.033788e-07\n",
       "171     tfidf_171  4.887023e-07\n",
       "77       tfidf_77  4.443853e-07\n",
       "377     tfidf_377  2.572740e-07\n",
       "288     tfidf_288  2.536027e-07\n",
       "301     tfidf_301  2.517108e-07\n",
       "27       tfidf_27  2.490613e-07\n",
       "213     tfidf_213  2.384952e-07\n",
       "212     tfidf_212  7.312899e-08\n",
       "315     tfidf_315  8.239048e-17\n",
       "256     tfidf_256  7.869875e-17\n",
       "327     tfidf_327  6.687059e-17\n",
       "299     tfidf_299  3.353015e-17\n",
       "276     tfidf_276  2.455783e-17\n",
       "100     tfidf_100  1.323494e-17\n",
       "157     tfidf_157  1.092996e-17\n",
       "450        pepper  9.809543e-18\n",
       "113     tfidf_113  6.208903e-18\n",
       "254     tfidf_254  2.912306e-18\n",
       "339     tfidf_339  1.929166e-18\n",
       "51       tfidf_51  1.632310e-18\n",
       "241     tfidf_241  1.146764e-18\n",
       "459    strawberry  8.870427e-19\n",
       "396    depression  4.380981e-19\n",
       "410     migraines  4.072131e-19\n",
       "261     tfidf_261  4.596100e-20\n",
       "403  eye pressure  0.000000e+00\n",
       "391       anxiety  0.000000e+00\n",
       "404       fatigue  0.000000e+00\n",
       "401      epilepsy  0.000000e+00\n",
       "411          pain  0.000000e+00\n",
       "453          plum  0.000000e+00\n",
       "416    spasticity  0.000000e+00\n",
       "394     arthritis  0.000000e+00\n",
       "414      seizures  0.000000e+00\n",
       "417        stress  0.000000e+00\n",
       "463       tobacco -3.199000e-20\n",
       "181     tfidf_181 -3.554808e-19"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.set_option('display.max_rows', df_feat_ranked.shape[0]+1)\n",
    "df_feat_ranked"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/louispandu/anaconda3/lib/python3.10/site-packages/sklearn/feature_selection/_from_model.py:357: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  self.estimator_.fit(X, y, **fit_params)\n"
     ]
    }
   ],
   "source": [
    "selector = SelectFromModel(rfreg).fit(X_train1, y_train1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 5.63574864e-06,  2.96668604e-05,  1.44297410e-05,  9.34129710e-05,\n",
       "        1.07469080e-05,  5.09026715e-04,  7.80140046e-05,  4.61921220e-05,\n",
       "        6.96210151e-06,  9.73414963e-06,  1.64450739e-05,  1.71146250e-04,\n",
       "        2.53789288e-06,  5.63660039e-07,  3.05766237e-05,  3.10581459e-05,\n",
       "        2.11746233e-05,  3.10496025e-05,  8.59270818e-06,  2.97445259e-06,\n",
       "        5.36589257e-06,  3.42672111e-06,  2.46270387e-05,  3.17301699e-05,\n",
       "        5.79666130e-05,  1.77047014e-17,  5.12760686e-04,  2.61106015e-06,\n",
       "        1.09988812e-17,  2.71362414e-05,  6.99326660e-05,  1.28976904e-05,\n",
       "        3.75737471e-05,  5.77534000e-05,  1.23901036e-04,  1.72274504e-05,\n",
       "        3.75557879e-06,  2.48891992e-04,  9.96956560e-03,  1.73039325e-04,\n",
       "        1.74157455e-06,  7.78266530e-06,  5.39080652e-05,  6.12568870e-05,\n",
       "        4.50692958e-06,  1.20813667e-05,  4.63109432e-04,  1.58943922e-05,\n",
       "        5.28955670e-04,  4.87407204e-18,  3.39412898e-06,  1.18367382e-18,\n",
       "        7.02160601e-06,  2.08170519e-06,  8.70055726e-06,  1.68301898e-04,\n",
       "        3.80155851e-05,  1.92811469e-05,  2.67682560e-04,  1.66791766e-05,\n",
       "        4.29375059e-06,  2.35011966e-05,  4.20356609e-02,  2.96814245e-06,\n",
       "        1.78422848e-05,  1.75606183e-05,  2.21209918e-05,  1.18288161e-06,\n",
       "        6.90397860e-06,  2.39958367e-07,  5.95166755e-06,  8.15014272e-06,\n",
       "        4.05282424e-06,  3.77930802e-05,  1.72482761e-05,  1.05871829e-04,\n",
       "        4.82785375e-06,  3.88020738e-07,  6.93192363e-05,  6.34275115e-05,\n",
       "        2.16747830e-04,  2.33313889e-05,  1.76554333e-05,  6.94507624e-07,\n",
       "        3.01747883e-05,  9.58824509e-06,  2.79590981e-05,  7.97894891e-06,\n",
       "        4.31571368e-06,  6.83964202e-06,  3.98196081e-05,  1.57373115e-06,\n",
       "        2.59319442e-07,  2.50417244e-05,  2.55319879e-04,  2.47305093e-06,\n",
       "        1.07861782e-04,  2.48880278e-05,  2.96438496e-05,  1.29164977e-05,\n",
       "        2.55131106e-07,  7.32286060e-05,  1.49578231e-06,  3.49725046e-06,\n",
       "        4.08517598e-05,  5.41674359e-04,  8.99623016e-05,  1.27065888e-05,\n",
       "        9.83785150e-05,  1.36522927e-04,  1.63509737e-05,  5.02246916e-06,\n",
       "        1.20311240e-05,  2.61789974e-17,  8.60565178e-06,  4.39574118e-05,\n",
       "        2.91237035e-05,  9.52618601e-05,  1.49932969e-05,  1.39762114e-05,\n",
       "        3.65296661e-06,  3.64685152e-04,  3.94529009e-05,  6.59056216e-06,\n",
       "        4.16021602e-05,  2.22063136e-06,  1.40567404e-05,  1.97719977e-05,\n",
       "        9.19635464e-05,  6.08921677e-05,  6.44641348e-04,  8.67598213e-05,\n",
       "        3.36313512e-05,  1.17575821e-05,  1.78806943e-04,  2.78646546e-06,\n",
       "        3.62664595e-05,  7.22118061e-05,  1.90954945e-05,  2.38853173e-05,\n",
       "        1.43439666e-04,  1.30757788e-04,  3.60002559e-05,  2.91379604e-05,\n",
       "        6.78584473e-05,  2.62199904e-04,  9.89928189e-06,  4.07997366e-06,\n",
       "        1.32503308e-06,  1.36413098e-04,  5.04897301e-06,  7.89566828e-05,\n",
       "        1.20549147e-05,  1.74822306e-04,  4.55624412e-06,  1.46873602e-04,\n",
       "        1.12484793e-05, -4.17250009e-19,  7.26051836e-04,  7.03865946e-05,\n",
       "        8.63158506e-06,  2.05895762e-03,  1.20937714e-04,  1.98736820e-05,\n",
       "        1.95057795e-06,  2.14576801e-06,  1.16761468e-05,  1.86344923e-04,\n",
       "        1.03002884e-04,  5.00966137e-07,  3.14859505e-06,  1.60525692e-06,\n",
       "        2.09278202e-05,  1.21238932e-05,  4.53548441e-06,  1.14883276e-05,\n",
       "        2.55248867e-06,  5.83213240e-05,  4.09581869e-05,  6.78252695e-05,\n",
       "        5.98494722e-07,  2.59162702e-18,  1.07369929e-04,  9.63460639e-07,\n",
       "        1.43434234e-05,  7.41448506e-06,  1.36406723e-06,  3.74419186e-05,\n",
       "        3.78132969e-05,  1.35334482e-05,  8.68036681e-05,  1.50157179e-06,\n",
       "        1.75035159e-06,  1.12256969e-05,  3.94369769e-05,  4.71112623e-05,\n",
       "        7.99195976e-06,  3.30727485e-04,  6.04138166e-05,  6.45490210e-05,\n",
       "        4.95947942e-04,  7.98894889e-06,  2.05749338e-05,  5.33399109e-05,\n",
       "        5.28322666e-05,  1.20404113e-05,  1.91522336e-05,  2.13349945e-05,\n",
       "        1.24427323e-06,  5.89745283e-06,  2.61038086e-04,  2.90532990e-05,\n",
       "        4.20895582e-07,  4.57883230e-06,  1.36313358e-05,  6.72913823e-06,\n",
       "        1.56008860e-05,  2.52060395e-05,  5.17986231e-06,  8.94483570e-06,\n",
       "        2.79958464e-06,  1.11449628e-05,  4.23479033e-04,  1.19446598e-05,\n",
       "        9.69494024e-05,  1.38198598e-06,  6.67884428e-06,  1.12197860e-04,\n",
       "        5.71156648e-06,  6.19122679e-06,  4.13929182e-05,  1.85940957e-05,\n",
       "        3.75208115e-06,  2.47626926e-05,  8.13315459e-05,  4.42947782e-06,\n",
       "        1.99116844e-05,  2.39438483e-05,  1.43744403e-05,  2.63107588e-04,\n",
       "        5.73853250e-06,  2.43905364e-07,  3.38886887e-05,  8.01051145e-06,\n",
       "        2.33332181e-05,  1.54194197e-04,  2.05637296e-05,  2.32071441e-05,\n",
       "        1.83052832e-05,  7.73988944e-04,  5.09518673e-05,  6.06786618e-06,\n",
       "        3.01831436e-06,  5.26198102e-04,  1.08885082e-06,  1.30574012e-05,\n",
       "        5.05277356e-07,  2.56256271e-07,  7.56406717e-05,  1.79845969e-06,\n",
       "        4.31164205e-05,  9.76541906e-07,  4.11240749e-05,  4.99563388e-06,\n",
       "        1.30629887e-05,  7.47719843e-05,  1.74279212e-06,  6.96035442e-05,\n",
       "        1.27969570e-06,  7.11150263e-05,  1.37016395e-05,  7.98214341e-06,\n",
       "        9.54976924e-06,  3.02490093e-06,  5.15239617e-05,  3.59174392e-05,\n",
       "        2.29205317e-07,  4.78083337e-06,  5.12478479e-05,  2.50031763e-07,\n",
       "        6.24867556e-06,  5.22474317e-05,  1.75953038e-05,  7.16508419e-06,\n",
       "        1.44173133e-06,  1.71368975e-04,  2.08475882e-05,  5.42318945e-06,\n",
       "        7.62158752e-07,  6.06627505e-05,  6.47772917e-07,  6.41818368e-06,\n",
       "        1.44728095e-04,  7.92013445e-05,  3.16682472e-05,  3.95840385e-17,\n",
       "        6.45962606e-17,  7.16736125e-05,  2.81037819e-06,  5.48069009e-17,\n",
       "        2.96852013e-05,  2.44286185e-07,  4.91029656e-07,  7.82097494e-06,\n",
       "        2.00825693e-06,  1.14829946e-05,  3.68246318e-06,  4.02961791e-04,\n",
       "        2.37735403e-07,  8.95489481e-05,  2.14719425e-05,  1.06089551e-05,\n",
       "        1.30980311e-04,  2.13872682e-06,  8.17631058e-06,  1.79995076e-18,\n",
       "        2.12611463e-05,  1.69020092e-06,  6.23259288e-06,  1.12774276e-04,\n",
       "        3.57725321e-05,  5.52307126e-05,  3.22154728e-06,  3.98552889e-05,\n",
       "        4.46485539e-05,  2.22383907e-06,  4.39283938e-06,  2.54461289e-07,\n",
       "        5.86730510e-04,  2.20189699e-04,  1.77132541e-05,  6.28829713e-05,\n",
       "        1.27805343e-04,  4.11337010e-05,  1.39087820e-05,  2.91060360e-06,\n",
       "        1.42687878e-05,  8.55259884e-05,  1.18875066e-03,  1.50385105e-17,\n",
       "        8.46178712e-05,  5.32350817e-05,  1.10534763e-04,  2.89860533e-04,\n",
       "        8.99993810e-06,  5.47249143e-04,  4.38782018e-06,  1.25247133e-06,\n",
       "        7.11537079e-06,  2.75989556e-04,  3.97443099e-05,  3.87422639e-07,\n",
       "        1.81351064e-06,  2.58432926e-05,  1.13031901e-05,  2.57741274e-05,\n",
       "        9.29291699e-06,  3.96394290e-05,  3.13405656e-06,  7.79123689e-06,\n",
       "        2.49667544e-05,  2.16320431e-06,  7.82661884e-05,  3.83515997e-04,\n",
       "        1.22626516e-05,  7.40751633e-06,  5.27156677e-04,  1.20325762e-03,\n",
       "        3.09072787e-06,  1.03651928e-04,  1.52629008e-05,  2.30378229e-04,\n",
       "        4.79031254e-05,  8.75928417e-05,  9.43386613e-06,  7.00499528e-06,\n",
       "        7.85314873e-05,  0.00000000e+00,  1.64228272e-05,  5.32283856e-05,\n",
       "        9.53755452e-05,  1.32641753e-05,  3.31930316e-05,  2.57531736e-05,\n",
       "        2.00946646e-05,  2.15083724e-06,  2.23155520e-05,  2.50636522e-06,\n",
       "        3.99700877e-03,  0.00000000e+00,  1.19376319e-01,  1.30430407e-17,\n",
       "        9.76748731e-07,  1.27576905e-04,  0.00000000e+00,  5.14830003e-05,\n",
       "        0.00000000e+00,  6.28293667e-06,  1.79471870e-05,  7.41933701e-05,\n",
       "        2.25096531e-05,  0.00000000e+00,  3.48229930e-04,  0.00000000e+00,\n",
       "        0.00000000e+00,  5.95740661e-05,  3.92639050e-05,  5.03041363e-05,\n",
       "        1.61192534e-06,  3.24799844e-05,  0.00000000e+00,  0.00000000e+00,\n",
       "        1.45597461e-05,  3.52323394e-05,  0.00000000e+00,  2.96708912e-04,\n",
       "        0.00000000e+00,  0.00000000e+00,  3.05436128e-05,  7.87945083e-05,\n",
       "        5.89421004e-05,  1.26439237e-06,  3.31907531e-06,  1.20988344e-06,\n",
       "        1.94096530e-04,  4.60225716e-20,  1.10775521e-05,  2.01114277e-06,\n",
       "        4.43134977e-06,  3.59081785e-05,  4.51575403e-05,  1.50913587e-02,\n",
       "        2.40313979e-05,  1.33625248e-04,  2.43236820e-05,  7.93989743e-04,\n",
       "        2.89996248e-06,  1.82634679e-04,  1.19485312e-05,  3.64064173e-05,\n",
       "        1.86824689e-05,  3.43664951e-03,  2.41942248e-05,  6.06907525e-05,\n",
       "        7.50741489e-07,  8.04248532e-06,  2.40966504e-06,  7.16693999e-02,\n",
       "        1.29309676e-05,  4.24827941e-05,  1.94132587e-06,  7.03284507e-01,\n",
       "        1.01766252e-05,  0.00000000e+00,  1.42297001e-04,  7.58735436e-07,\n",
       "        4.30326635e-06,  3.77324880e-04,  1.03635464e-04,  4.43087708e-07,\n",
       "        2.99070989e-05,  3.21862911e-05,  1.33757713e-05, -6.05891016e-19,\n",
       "        6.78863497e-06,  2.06532955e-05,  1.15873129e-06,  1.17981052e-05,\n",
       "        1.29703140e-05])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "selector.estimator_.feature_importances_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0021321961620469083"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "selector.threshold_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "mask = selector.get_support()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([False, False, False, False, False, False, False, False, False,\n",
       "       False, False, False, False, False, False, False, False, False,\n",
       "       False, False, False, False, False, False, False, False, False,\n",
       "       False, False, False, False, False, False, False, False, False,\n",
       "       False, False,  True, False, False, False, False, False, False,\n",
       "       False, False, False, False, False, False, False, False, False,\n",
       "       False, False, False, False, False, False, False, False,  True,\n",
       "       False, False, False, False, False, False, False, False, False,\n",
       "       False, False, False, False, False, False, False, False, False,\n",
       "       False, False, False, False, False, False, False, False, False,\n",
       "       False, False, False, False, False, False, False, False, False,\n",
       "       False, False, False, False, False, False, False, False, False,\n",
       "       False, False, False, False, False, False, False, False, False,\n",
       "       False, False, False, False, False, False, False, False, False,\n",
       "       False, False, False, False, False, False, False, False, False,\n",
       "       False, False, False, False, False, False, False, False, False,\n",
       "       False, False, False, False, False, False, False, False, False,\n",
       "       False, False, False, False, False, False, False, False, False,\n",
       "       False, False, False, False, False, False, False, False, False,\n",
       "       False, False, False, False, False, False, False, False, False,\n",
       "       False, False, False, False, False, False, False, False, False,\n",
       "       False, False, False, False, False, False, False, False, False,\n",
       "       False, False, False, False, False, False, False, False, False,\n",
       "       False, False, False, False, False, False, False, False, False,\n",
       "       False, False, False, False, False, False, False, False, False,\n",
       "       False, False, False, False, False, False, False, False, False,\n",
       "       False, False, False, False, False, False, False, False, False,\n",
       "       False, False, False, False, False, False, False, False, False,\n",
       "       False, False, False, False, False, False, False, False, False,\n",
       "       False, False, False, False, False, False, False, False, False,\n",
       "       False, False, False, False, False, False, False, False, False,\n",
       "       False, False, False, False, False, False, False, False, False,\n",
       "       False, False, False, False, False, False, False, False, False,\n",
       "       False, False, False, False, False, False, False, False, False,\n",
       "       False, False, False, False, False, False, False, False, False,\n",
       "       False, False, False, False, False, False, False, False, False,\n",
       "       False, False, False, False, False, False, False, False, False,\n",
       "       False, False, False, False, False, False, False, False, False,\n",
       "       False, False, False, False, False, False, False, False, False,\n",
       "       False, False, False, False, False, False, False, False, False,\n",
       "       False, False, False, False, False, False, False, False, False,\n",
       "       False, False, False, False, False, False, False, False, False,\n",
       "       False, False, False, False, False, False, False, False, False,\n",
       "       False,  True, False,  True, False, False, False, False, False,\n",
       "       False, False, False, False, False, False, False, False, False,\n",
       "       False, False, False, False, False, False, False, False, False,\n",
       "       False, False, False, False, False, False, False, False, False,\n",
       "       False, False, False, False, False, False, False, False,  True,\n",
       "       False, False, False, False, False, False, False, False, False,\n",
       "        True, False, False, False, False, False,  True, False, False,\n",
       "       False,  True, False, False, False, False, False, False, False,\n",
       "       False, False, False, False, False, False, False, False, False,\n",
       "       False])"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "selected_features = X.columns[mask]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tfidf_38</th>\n",
       "      <th>tfidf_62</th>\n",
       "      <th>hybrid</th>\n",
       "      <th>sativa</th>\n",
       "      <th>citrus</th>\n",
       "      <th>lemon</th>\n",
       "      <th>orange</th>\n",
       "      <th>pine</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44995</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44996</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44997</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44998</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44999</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>45000 rows × 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       tfidf_38  tfidf_62  hybrid  sativa  citrus  lemon  orange  pine\n",
       "0           0.0       0.0       1       0       0      0       0     0\n",
       "1           0.0       0.0       1       0       0      0       0     0\n",
       "2           0.0       0.0       1       0       0      0       0     0\n",
       "3           0.0       0.0       1       0       0      0       0     0\n",
       "4           0.0       0.0       1       0       0      0       0     0\n",
       "...         ...       ...     ...     ...     ...    ...     ...   ...\n",
       "44995       0.0       0.0       0       0       0      0       0     0\n",
       "44996       0.0       0.0       0       0       0      0       0     0\n",
       "44997       0.0       0.0       0       0       0      0       0     0\n",
       "44998       0.0       0.0       0       0       0      0       0     0\n",
       "44999       0.0       0.0       0       0       1      1       1     1\n",
       "\n",
       "[45000 rows x 8 columns]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "selected_X = df_rf[selected_features]\n",
    "selected_X"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train test split (after Feature Selection)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['selected_X_rf_tfidf_ocim.pkl']"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import joblib\n",
    "\n",
    "joblib.dump(selector, \"selector_rf_tfidf_ocim.pkl\")\n",
    "joblib.dump(selected_X, \"selected_X_rf_tfidf_ocim.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(selected_X, y, random_state=1, test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train1, X_val, y_train1, y_val = train_test_split(X_train, y_train, random_state=1, test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/ns/m5pnr0211w91v02hpv22958m0000gn/T/ipykernel_88584/3758305.py:1: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  rfreg.fit(X_train1, y_train1)\n"
     ]
    }
   ],
   "source": [
    "rfreg.fit(X_train1, y_train1)\n",
    "y_pred_rfreg = rfreg.predict(X_val)\n",
    "y_pred_rfreg_r2 = rfreg.predict(X_train1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.019976278633083152"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mean_absolute_error(y_val, y_pred_rfreg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.004626364555172394"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mean_squared_error(y_val, y_pred_rfreg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.06801738421295246"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mean_squared_error(y_val, y_pred_rfreg, squared = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9744300206990565"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#train\n",
    "r2_score(y_train1, y_pred_rfreg_r2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9731371823010492"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#val\n",
    "r2_score(y_val, y_pred_rfreg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hyperparameter Tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "parameters = {'max_depth': [None, 10, 50, 100],\n",
    "              'max_features': ['auto', 'sqrt'],\n",
    "              'min_samples_leaf': [1, 2, 4],\n",
    "              'min_samples_split': [2, 5, 10],\n",
    "              'n_estimators': [100, 300, 500]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "rscv = RandomizedSearchCV(rfreg,  \n",
    "                     parameters,   \n",
    "                     cv=5, \n",
    "                     scoring='neg_mean_absolute_error',\n",
    "                     n_jobs = -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/louispandu/anaconda3/lib/python3.10/site-packages/sklearn/model_selection/_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/Users/louispandu/anaconda3/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
      "  warn(\n",
      "/Users/louispandu/anaconda3/lib/python3.10/site-packages/sklearn/model_selection/_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/Users/louispandu/anaconda3/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
      "  warn(\n",
      "/Users/louispandu/anaconda3/lib/python3.10/site-packages/sklearn/model_selection/_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/Users/louispandu/anaconda3/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
      "  warn(\n",
      "/Users/louispandu/anaconda3/lib/python3.10/site-packages/sklearn/model_selection/_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/Users/louispandu/anaconda3/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
      "  warn(\n",
      "/Users/louispandu/anaconda3/lib/python3.10/site-packages/sklearn/model_selection/_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/Users/louispandu/anaconda3/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
      "  warn(\n",
      "/Users/louispandu/anaconda3/lib/python3.10/site-packages/sklearn/model_selection/_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/Users/louispandu/anaconda3/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
      "  warn(\n",
      "/Users/louispandu/anaconda3/lib/python3.10/site-packages/sklearn/model_selection/_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/Users/louispandu/anaconda3/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
      "  warn(\n",
      "/Users/louispandu/anaconda3/lib/python3.10/site-packages/sklearn/model_selection/_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/Users/louispandu/anaconda3/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
      "  warn(\n",
      "/Users/louispandu/anaconda3/lib/python3.10/site-packages/sklearn/model_selection/_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/Users/louispandu/anaconda3/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
      "  warn(\n",
      "/Users/louispandu/anaconda3/lib/python3.10/site-packages/sklearn/model_selection/_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/Users/louispandu/anaconda3/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
      "  warn(\n",
      "/Users/louispandu/anaconda3/lib/python3.10/site-packages/sklearn/model_selection/_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/Users/louispandu/anaconda3/lib/python3.10/site-packages/sklearn/model_selection/_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/Users/louispandu/anaconda3/lib/python3.10/site-packages/sklearn/model_selection/_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/Users/louispandu/anaconda3/lib/python3.10/site-packages/sklearn/model_selection/_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/Users/louispandu/anaconda3/lib/python3.10/site-packages/sklearn/model_selection/_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/Users/louispandu/anaconda3/lib/python3.10/site-packages/sklearn/model_selection/_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/Users/louispandu/anaconda3/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
      "  warn(\n",
      "/Users/louispandu/anaconda3/lib/python3.10/site-packages/sklearn/model_selection/_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/Users/louispandu/anaconda3/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
      "  warn(\n",
      "/Users/louispandu/anaconda3/lib/python3.10/site-packages/sklearn/model_selection/_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/Users/louispandu/anaconda3/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
      "  warn(\n",
      "/Users/louispandu/anaconda3/lib/python3.10/site-packages/sklearn/model_selection/_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/Users/louispandu/anaconda3/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
      "  warn(\n",
      "/Users/louispandu/anaconda3/lib/python3.10/site-packages/sklearn/model_selection/_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/Users/louispandu/anaconda3/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
      "  warn(\n",
      "/Users/louispandu/anaconda3/lib/python3.10/site-packages/sklearn/model_selection/_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/Users/louispandu/anaconda3/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
      "  warn(\n",
      "/Users/louispandu/anaconda3/lib/python3.10/site-packages/sklearn/model_selection/_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/Users/louispandu/anaconda3/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
      "  warn(\n",
      "/Users/louispandu/anaconda3/lib/python3.10/site-packages/sklearn/model_selection/_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/Users/louispandu/anaconda3/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
      "  warn(\n",
      "/Users/louispandu/anaconda3/lib/python3.10/site-packages/sklearn/model_selection/_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/Users/louispandu/anaconda3/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
      "  warn(\n",
      "/Users/louispandu/anaconda3/lib/python3.10/site-packages/sklearn/model_selection/_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/Users/louispandu/anaconda3/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
      "  warn(\n",
      "/Users/louispandu/anaconda3/lib/python3.10/site-packages/sklearn/model_selection/_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/Users/louispandu/anaconda3/lib/python3.10/site-packages/sklearn/model_selection/_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/Users/louispandu/anaconda3/lib/python3.10/site-packages/sklearn/model_selection/_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/Users/louispandu/anaconda3/lib/python3.10/site-packages/sklearn/model_selection/_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/Users/louispandu/anaconda3/lib/python3.10/site-packages/sklearn/model_selection/_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/Users/louispandu/anaconda3/lib/python3.10/site-packages/sklearn/model_selection/_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/Users/louispandu/anaconda3/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
      "  warn(\n",
      "/Users/louispandu/anaconda3/lib/python3.10/site-packages/sklearn/model_selection/_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/Users/louispandu/anaconda3/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
      "  warn(\n",
      "/Users/louispandu/anaconda3/lib/python3.10/site-packages/sklearn/model_selection/_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/Users/louispandu/anaconda3/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
      "  warn(\n",
      "/Users/louispandu/anaconda3/lib/python3.10/site-packages/sklearn/model_selection/_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/Users/louispandu/anaconda3/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
      "  warn(\n",
      "/Users/louispandu/anaconda3/lib/python3.10/site-packages/sklearn/model_selection/_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/Users/louispandu/anaconda3/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
      "  warn(\n",
      "/Users/louispandu/anaconda3/lib/python3.10/site-packages/sklearn/model_selection/_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/Users/louispandu/anaconda3/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
      "  warn(\n",
      "/Users/louispandu/anaconda3/lib/python3.10/site-packages/sklearn/model_selection/_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/Users/louispandu/anaconda3/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
      "  warn(\n",
      "/Users/louispandu/anaconda3/lib/python3.10/site-packages/sklearn/model_selection/_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/Users/louispandu/anaconda3/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
      "  warn(\n",
      "/Users/louispandu/anaconda3/lib/python3.10/site-packages/sklearn/model_selection/_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/Users/louispandu/anaconda3/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
      "  warn(\n",
      "/Users/louispandu/anaconda3/lib/python3.10/site-packages/sklearn/model_selection/_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/Users/louispandu/anaconda3/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
      "  warn(\n",
      "/Users/louispandu/anaconda3/lib/python3.10/site-packages/sklearn/model_selection/_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/Users/louispandu/anaconda3/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
      "  warn(\n",
      "/Users/louispandu/anaconda3/lib/python3.10/site-packages/sklearn/model_selection/_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/Users/louispandu/anaconda3/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
      "  warn(\n",
      "/Users/louispandu/anaconda3/lib/python3.10/site-packages/sklearn/model_selection/_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/Users/louispandu/anaconda3/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
      "  warn(\n",
      "/Users/louispandu/anaconda3/lib/python3.10/site-packages/sklearn/model_selection/_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/Users/louispandu/anaconda3/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
      "  warn(\n",
      "/Users/louispandu/anaconda3/lib/python3.10/site-packages/sklearn/model_selection/_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/Users/louispandu/anaconda3/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
      "  warn(\n",
      "/Users/louispandu/anaconda3/lib/python3.10/site-packages/sklearn/model_selection/_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/Users/louispandu/anaconda3/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
      "  warn(\n",
      "/Users/louispandu/anaconda3/lib/python3.10/site-packages/sklearn/model_selection/_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/Users/louispandu/anaconda3/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
      "  warn(\n",
      "/Users/louispandu/anaconda3/lib/python3.10/site-packages/sklearn/model_selection/_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/Users/louispandu/anaconda3/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
      "  warn(\n",
      "/Users/louispandu/anaconda3/lib/python3.10/site-packages/sklearn/model_selection/_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/Users/louispandu/anaconda3/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
      "  warn(\n",
      "/Users/louispandu/anaconda3/lib/python3.10/site-packages/sklearn/model_selection/_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/Users/louispandu/anaconda3/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
      "  warn(\n",
      "/Users/louispandu/anaconda3/lib/python3.10/site-packages/sklearn/model_selection/_search.py:909: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  self.best_estimator_.fit(X, y, **fit_params)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-2 {color: black;background-color: white;}#sk-container-id-2 pre{padding: 0;}#sk-container-id-2 div.sk-toggleable {background-color: white;}#sk-container-id-2 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-2 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-2 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-2 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-2 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-2 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-2 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-2 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-2 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-2 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-2 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-2 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-2 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-2 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-2 div.sk-item {position: relative;z-index: 1;}#sk-container-id-2 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-2 div.sk-item::before, #sk-container-id-2 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-2 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-2 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-2 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-2 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-2 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-2 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-2 div.sk-label-container {text-align: center;}#sk-container-id-2 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-2 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-2\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>RandomizedSearchCV(cv=5, estimator=RandomForestRegressor(), n_jobs=-1,\n",
       "                   param_distributions={&#x27;max_depth&#x27;: [None, 10, 50, 100],\n",
       "                                        &#x27;max_features&#x27;: [&#x27;auto&#x27;, &#x27;sqrt&#x27;],\n",
       "                                        &#x27;min_samples_leaf&#x27;: [1, 2, 4],\n",
       "                                        &#x27;min_samples_split&#x27;: [2, 5, 10],\n",
       "                                        &#x27;n_estimators&#x27;: [100, 300, 500]},\n",
       "                   scoring=&#x27;neg_mean_absolute_error&#x27;)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" ><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">RandomizedSearchCV</label><div class=\"sk-toggleable__content\"><pre>RandomizedSearchCV(cv=5, estimator=RandomForestRegressor(), n_jobs=-1,\n",
       "                   param_distributions={&#x27;max_depth&#x27;: [None, 10, 50, 100],\n",
       "                                        &#x27;max_features&#x27;: [&#x27;auto&#x27;, &#x27;sqrt&#x27;],\n",
       "                                        &#x27;min_samples_leaf&#x27;: [1, 2, 4],\n",
       "                                        &#x27;min_samples_split&#x27;: [2, 5, 10],\n",
       "                                        &#x27;n_estimators&#x27;: [100, 300, 500]},\n",
       "                   scoring=&#x27;neg_mean_absolute_error&#x27;)</pre></div></div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-3\" type=\"checkbox\" ><label for=\"sk-estimator-id-3\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">estimator: RandomForestRegressor</label><div class=\"sk-toggleable__content\"><pre>RandomForestRegressor()</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-4\" type=\"checkbox\" ><label for=\"sk-estimator-id-4\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">RandomForestRegressor</label><div class=\"sk-toggleable__content\"><pre>RandomForestRegressor()</pre></div></div></div></div></div></div></div></div></div></div>"
      ],
      "text/plain": [
       "RandomizedSearchCV(cv=5, estimator=RandomForestRegressor(), n_jobs=-1,\n",
       "                   param_distributions={'max_depth': [None, 10, 50, 100],\n",
       "                                        'max_features': ['auto', 'sqrt'],\n",
       "                                        'min_samples_leaf': [1, 2, 4],\n",
       "                                        'min_samples_split': [2, 5, 10],\n",
       "                                        'n_estimators': [100, 300, 500]},\n",
       "                   scoring='neg_mean_absolute_error')"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rscv.fit(X_train1, y_train1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'n_estimators': 300,\n",
       " 'min_samples_split': 2,\n",
       " 'min_samples_leaf': 1,\n",
       " 'max_features': 'sqrt',\n",
       " 'max_depth': None}"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rscv.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['rscv_rf_tfidf_best_params_ocim.pkl']"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "joblib.dump(rscv, \"rscv_rf_tfidf_ocim.pkl\")\n",
    "joblib.dump(rscv.best_params_, \"rscv_rf_tfidf_best_params_ocim.pkl\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "RF (after Hyperparameter Tuning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/ns/m5pnr0211w91v02hpv22958m0000gn/T/ipykernel_88584/1649723548.py:2: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  rfreg_ht.fit(X_train1, y_train1)\n"
     ]
    }
   ],
   "source": [
    "rfreg_ht = RandomForestRegressor(n_estimators = 300, min_samples_split = 2, min_samples_leaf = 1, max_features = 'sqrt', max_depth = None)\n",
    "rfreg_ht.fit(X_train1, y_train1)\n",
    "y_pred_rfreg = rfreg_ht.predict(X_val)\n",
    "y_pred_rfreg_r2 = rfreg_ht.predict(X_train1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.019978231497248807"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mean_absolute_error(y_val, y_pred_rfreg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.004616256028153104"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mean_squared_error(y_val, y_pred_rfreg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.06794303517030355"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mean_squared_error(y_val, y_pred_rfreg, squared = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9744622323454027"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#train\n",
    "r2_score(y_train1, y_pred_rfreg_r2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9731958770959115"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#val\n",
    "r2_score(y_val, y_pred_rfreg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Residual plots after Hyperparameter Tuning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Predicting model on the test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_rfreg_test = rfreg_ht.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['y_test_rfreg_tfidf_ocim.pkl']"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "joblib.dump(y_pred_rfreg_test, \"y_pred_rfreg_test_tfidf_ocim.pkl\")\n",
    "joblib.dump(y_test, \"y_test_rfreg_tfidf_ocim.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.020077083364913716"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mean_absolute_error(y_test, y_pred_rfreg_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0047197242824005385"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mean_squared_error(y_test, y_pred_rfreg_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.06870024950755665"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mean_squared_error(y_test, y_pred_rfreg_test, squared = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9725164502231387"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "r2_score(y_test, y_pred_rfreg_test)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Error analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 800x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# assume y_pred is a numpy array and y_true is a pandas dataframe\n",
    "fig, ax = plt.subplots(figsize=(8, 6))\n",
    "\n",
    "column = \"X..Ocimene\"  # specify the target variable name\n",
    "ax.hist(y_pred_rfreg_test, alpha=0.5, label='y_pred', bins=20)\n",
    "ax.hist(y_test[column], alpha=0.5, label='y_true', bins=20)\n",
    "ax.legend(loc='upper right')\n",
    "ax.set_title(column)\n",
    "\n",
    "plt.show()\n",
    "plt.savefig('error_hist_knn_tfidf_ocim.png')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pearson R"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pearson correlation coefficient: 0.986\n",
      "P-value: 0.000\n"
     ]
    }
   ],
   "source": [
    "corr_coef, p_value = pearsonr(y_pred_rfreg_test.flatten(), y_test.values.ravel())\n",
    "\n",
    "print(f\"Pearson correlation coefficient: {corr_coef:.3f}\")\n",
    "print(f\"P-value: {p_value:.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Axes: >"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "corr_matrix = y_test.corr()\n",
    "sns.heatmap(corr_matrix, annot=True, cmap='coolwarm', center=0)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
