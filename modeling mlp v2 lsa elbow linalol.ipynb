{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn import preprocessing\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.neural_network import MLPRegressor\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "from sklearn.metrics import r2_score\n",
    "from scipy.stats import pearsonr\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.feature_selection import SelectFromModel\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compiling complete dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_mlp = pd.read_csv(\"df_linalol_lsa.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>lsa_0</th>\n",
       "      <th>lsa_1</th>\n",
       "      <th>lsa_2</th>\n",
       "      <th>lsa_3</th>\n",
       "      <th>lsa_4</th>\n",
       "      <th>hybrid</th>\n",
       "      <th>indica</th>\n",
       "      <th>sativa</th>\n",
       "      <th>anxiety</th>\n",
       "      <th>...</th>\n",
       "      <th>sweet</th>\n",
       "      <th>tar</th>\n",
       "      <th>tea</th>\n",
       "      <th>tobacco</th>\n",
       "      <th>tree</th>\n",
       "      <th>tropical</th>\n",
       "      <th>vanilla</th>\n",
       "      <th>violet</th>\n",
       "      <th>woody</th>\n",
       "      <th>X..Linalool</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0.341025</td>\n",
       "      <td>0.182753</td>\n",
       "      <td>0.008214</td>\n",
       "      <td>0.140406</td>\n",
       "      <td>-0.156943</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.5000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0.341025</td>\n",
       "      <td>0.182753</td>\n",
       "      <td>0.008214</td>\n",
       "      <td>0.140406</td>\n",
       "      <td>-0.156943</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.5000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>0.232158</td>\n",
       "      <td>-0.045496</td>\n",
       "      <td>0.187131</td>\n",
       "      <td>-0.000936</td>\n",
       "      <td>0.018518</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.5000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>0.232158</td>\n",
       "      <td>-0.045496</td>\n",
       "      <td>0.187131</td>\n",
       "      <td>-0.000936</td>\n",
       "      <td>0.018518</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.5000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>0.232158</td>\n",
       "      <td>-0.045496</td>\n",
       "      <td>0.187131</td>\n",
       "      <td>-0.000936</td>\n",
       "      <td>0.018518</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.5000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>74995</th>\n",
       "      <td>42971</td>\n",
       "      <td>0.184573</td>\n",
       "      <td>-0.137296</td>\n",
       "      <td>-0.095301</td>\n",
       "      <td>0.181735</td>\n",
       "      <td>-0.042683</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0625</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>74996</th>\n",
       "      <td>42972</td>\n",
       "      <td>0.181714</td>\n",
       "      <td>-0.045560</td>\n",
       "      <td>-0.055692</td>\n",
       "      <td>0.015649</td>\n",
       "      <td>-0.045585</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0625</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>74997</th>\n",
       "      <td>42972</td>\n",
       "      <td>0.181714</td>\n",
       "      <td>-0.045560</td>\n",
       "      <td>-0.055692</td>\n",
       "      <td>0.015649</td>\n",
       "      <td>-0.045585</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0625</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>74998</th>\n",
       "      <td>42975</td>\n",
       "      <td>0.324915</td>\n",
       "      <td>0.131823</td>\n",
       "      <td>-0.099424</td>\n",
       "      <td>0.065491</td>\n",
       "      <td>0.038437</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0625</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>74999</th>\n",
       "      <td>42976</td>\n",
       "      <td>0.270141</td>\n",
       "      <td>-0.004631</td>\n",
       "      <td>-0.151272</td>\n",
       "      <td>0.035538</td>\n",
       "      <td>0.083641</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0625</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>75000 rows × 88 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       index     lsa_0     lsa_1     lsa_2     lsa_3     lsa_4  hybrid  \\\n",
       "0          0  0.341025  0.182753  0.008214  0.140406 -0.156943       1   \n",
       "1          0  0.341025  0.182753  0.008214  0.140406 -0.156943       1   \n",
       "2          1  0.232158 -0.045496  0.187131 -0.000936  0.018518       1   \n",
       "3          1  0.232158 -0.045496  0.187131 -0.000936  0.018518       1   \n",
       "4          1  0.232158 -0.045496  0.187131 -0.000936  0.018518       1   \n",
       "...      ...       ...       ...       ...       ...       ...     ...   \n",
       "74995  42971  0.184573 -0.137296 -0.095301  0.181735 -0.042683       0   \n",
       "74996  42972  0.181714 -0.045560 -0.055692  0.015649 -0.045585       0   \n",
       "74997  42972  0.181714 -0.045560 -0.055692  0.015649 -0.045585       0   \n",
       "74998  42975  0.324915  0.131823 -0.099424  0.065491  0.038437       0   \n",
       "74999  42976  0.270141 -0.004631 -0.151272  0.035538  0.083641       0   \n",
       "\n",
       "       indica  sativa  anxiety  ...  sweet  tar  tea  tobacco  tree  tropical  \\\n",
       "0           0       0        0  ...      0    0    0        0     0         0   \n",
       "1           0       0        0  ...      0    0    0        0     0         0   \n",
       "2           0       0        0  ...      0    0    0        0     0         0   \n",
       "3           0       0        0  ...      0    0    0        0     0         0   \n",
       "4           0       0        0  ...      0    0    0        0     0         0   \n",
       "...       ...     ...      ...  ...    ...  ...  ...      ...   ...       ...   \n",
       "74995       1       0        0  ...      0    0    0        0     0         0   \n",
       "74996       1       0        0  ...      0    0    0        0     0         0   \n",
       "74997       1       0        0  ...      0    0    0        0     0         0   \n",
       "74998       1       0        0  ...      0    0    0        0     0         0   \n",
       "74999       1       0        0  ...      1    1    1        1     1         1   \n",
       "\n",
       "       vanilla  violet  woody  X..Linalool  \n",
       "0            0       0      0       0.5000  \n",
       "1            0       0      0       0.5000  \n",
       "2            1       0      0       0.5000  \n",
       "3            1       0      0       0.5000  \n",
       "4            1       0      0       0.5000  \n",
       "...        ...     ...    ...          ...  \n",
       "74995        0       0      0       0.0625  \n",
       "74996        0       0      0       0.0625  \n",
       "74997        0       0      0       0.0625  \n",
       "74998        0       0      0       0.0625  \n",
       "74999        1       1      1       0.0625  \n",
       "\n",
       "[75000 rows x 88 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_mlp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['index',\n",
       " 'lsa_0',\n",
       " 'lsa_1',\n",
       " 'lsa_2',\n",
       " 'lsa_3',\n",
       " 'lsa_4',\n",
       " 'hybrid',\n",
       " 'indica',\n",
       " 'sativa',\n",
       " 'anxiety',\n",
       " 'anxious',\n",
       " 'aroused',\n",
       " 'arthritis',\n",
       " 'creative',\n",
       " 'depression',\n",
       " 'dizzy',\n",
       " 'dry eyes',\n",
       " 'dry mouth',\n",
       " 'energetic',\n",
       " 'epilepsy',\n",
       " 'euphoric',\n",
       " 'eye pressure',\n",
       " 'fatigue',\n",
       " 'focused',\n",
       " 'giggly',\n",
       " 'happy',\n",
       " 'headache',\n",
       " 'hungry',\n",
       " 'migraines',\n",
       " 'pain',\n",
       " 'paranoid',\n",
       " 'relaxed',\n",
       " 'seizures',\n",
       " 'sleepy',\n",
       " 'spasticity',\n",
       " 'stress',\n",
       " 'talkative',\n",
       " 'tingly',\n",
       " 'uplifted',\n",
       " 'ammonia',\n",
       " 'apple',\n",
       " 'apricot',\n",
       " 'berry',\n",
       " 'blue cheese',\n",
       " 'blueberry',\n",
       " 'butter',\n",
       " 'cheese',\n",
       " 'chemical',\n",
       " 'chestnut',\n",
       " 'citrus',\n",
       " 'coffee',\n",
       " 'diesel',\n",
       " 'earthy',\n",
       " 'flowery',\n",
       " 'fruit',\n",
       " 'grape',\n",
       " 'grapefruit',\n",
       " 'honey',\n",
       " 'lavender',\n",
       " 'lemon',\n",
       " 'lime',\n",
       " 'mango',\n",
       " 'menthol',\n",
       " 'mint',\n",
       " 'nutty',\n",
       " 'orange',\n",
       " 'peach',\n",
       " 'pear',\n",
       " 'pepper',\n",
       " 'pine',\n",
       " 'pineapple',\n",
       " 'plum',\n",
       " 'pungent',\n",
       " 'rose',\n",
       " 'sage',\n",
       " 'skunk',\n",
       " 'spicy/herbal',\n",
       " 'strawberry',\n",
       " 'sweet',\n",
       " 'tar',\n",
       " 'tea',\n",
       " 'tobacco',\n",
       " 'tree',\n",
       " 'tropical',\n",
       " 'vanilla',\n",
       " 'violet',\n",
       " 'woody',\n",
       " 'X..Linalool']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_mlp.columns.to_list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df_mlp.drop(['index', 'X..Linalool'], axis = 1)\n",
    "y = df_mlp[['X..Linalool']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:ylabel='Count'>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "sns.histplot(y, bins = 10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train test split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=1, test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train1, X_val, y_train1, y_val = train_test_split(X_train, y_train, random_state=1, test_size=0.25)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "MLP modeling (before Feature selection and Hyperparameter Tuning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/andalanputra/opt/anaconda3/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:1623: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    }
   ],
   "source": [
    "mlpreg = MLPRegressor(random_state=1, early_stopping=True)\n",
    "mlpreg.fit(X_train1, y_train1)\n",
    "y_pred_mlp = mlpreg.predict(X_val)\n",
    "y_pred_mlp_r2 = mlpreg.predict(X_train1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.10678550083522195"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mean_absolute_error(y_val, y_pred_mlp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8058303792735952"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#train\n",
    "r2_score(y_train1, y_pred_mlp_r2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7531800824622289"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#val\n",
    "r2_score(y_val, y_pred_mlp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Residual plots for each target variable"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Feature Selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "rfreg = RandomForestRegressor()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/andalanputra/opt/anaconda3/lib/python3.9/site-packages/sklearn/feature_selection/_from_model.py:357: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  self.estimator_.fit(X, y, **fit_params)\n"
     ]
    }
   ],
   "source": [
    "selector = SelectFromModel(rfreg).fit(X_train1, y_train1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1.09321139e-01, 8.74737732e-02, 8.46348319e-02, 8.18298390e-02,\n",
       "       9.51325615e-02, 2.32286302e-01, 1.29876544e-03, 1.70428472e-03,\n",
       "       3.18039802e-05, 2.15201754e-03, 7.68354877e-03, 1.49802076e-07,\n",
       "       9.61791288e-03, 3.55408698e-05, 1.41099105e-03, 5.76950721e-03,\n",
       "       6.57286185e-03, 8.85770506e-03, 1.21193286e-07, 8.11462886e-03,\n",
       "       3.03175061e-07, 3.29592301e-07, 4.63915816e-03, 7.32071884e-03,\n",
       "       1.22466990e-02, 9.04996897e-04, 4.90368068e-03, 5.28565472e-05,\n",
       "       1.39285998e-07, 1.20880911e-03, 1.10308244e-02, 4.32753990e-07,\n",
       "       1.06191773e-02, 0.00000000e+00, 0.00000000e+00, 4.70680956e-03,\n",
       "       1.13124988e-02, 6.43501606e-03, 9.19956931e-04, 8.44361451e-04,\n",
       "       2.01443588e-05, 3.28400744e-03, 2.79067021e-04, 1.17761835e-02,\n",
       "       1.18883803e-03, 2.30489251e-02, 1.61490412e-03, 1.56657532e-03,\n",
       "       3.54038206e-03, 1.71974130e-03, 9.38745270e-03, 1.54974820e-02,\n",
       "       5.01965957e-03, 4.75844876e-04, 4.07548935e-03, 5.19445173e-04,\n",
       "       1.66004688e-02, 3.52002079e-04, 4.18856902e-03, 9.24025181e-04,\n",
       "       5.14215851e-04, 1.71325146e-04, 1.73178420e-03, 5.48774776e-04,\n",
       "       1.62551673e-02, 1.08076417e-04, 4.81662333e-05, 6.95281964e-04,\n",
       "       2.08926313e-02, 1.17435641e-03, 1.76125109e-04, 4.19344938e-03,\n",
       "       5.26897210e-04, 7.90315537e-04, 4.00704872e-03, 1.48617556e-03,\n",
       "       4.53421184e-04, 1.23136019e-02, 1.13490831e-04, 1.90271737e-03,\n",
       "       6.50336826e-04, 3.90027303e-04, 1.03862954e-03, 1.50225613e-03,\n",
       "       8.56717678e-05, 2.07579460e-03])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "selector.estimator_.feature_importances_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.011627906976744186"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "selector.threshold_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "mask = selector.get_support()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ True,  True,  True,  True,  True,  True, False, False, False,\n",
       "       False, False, False, False, False, False, False, False, False,\n",
       "       False, False, False, False, False, False,  True, False, False,\n",
       "       False, False, False, False, False, False, False, False, False,\n",
       "       False, False, False, False, False, False, False,  True, False,\n",
       "        True, False, False, False, False, False,  True, False, False,\n",
       "       False, False,  True, False, False, False, False, False, False,\n",
       "       False,  True, False, False, False,  True, False, False, False,\n",
       "       False, False, False, False, False,  True, False, False, False,\n",
       "       False, False, False, False, False])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "selected_features = X.columns[mask]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>lsa_0</th>\n",
       "      <th>lsa_1</th>\n",
       "      <th>lsa_2</th>\n",
       "      <th>lsa_3</th>\n",
       "      <th>lsa_4</th>\n",
       "      <th>hybrid</th>\n",
       "      <th>happy</th>\n",
       "      <th>blueberry</th>\n",
       "      <th>cheese</th>\n",
       "      <th>earthy</th>\n",
       "      <th>honey</th>\n",
       "      <th>orange</th>\n",
       "      <th>pine</th>\n",
       "      <th>sweet</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.341025</td>\n",
       "      <td>0.182753</td>\n",
       "      <td>0.008214</td>\n",
       "      <td>0.140406</td>\n",
       "      <td>-0.156943</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.341025</td>\n",
       "      <td>0.182753</td>\n",
       "      <td>0.008214</td>\n",
       "      <td>0.140406</td>\n",
       "      <td>-0.156943</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.232158</td>\n",
       "      <td>-0.045496</td>\n",
       "      <td>0.187131</td>\n",
       "      <td>-0.000936</td>\n",
       "      <td>0.018518</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.232158</td>\n",
       "      <td>-0.045496</td>\n",
       "      <td>0.187131</td>\n",
       "      <td>-0.000936</td>\n",
       "      <td>0.018518</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.232158</td>\n",
       "      <td>-0.045496</td>\n",
       "      <td>0.187131</td>\n",
       "      <td>-0.000936</td>\n",
       "      <td>0.018518</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>74995</th>\n",
       "      <td>0.184573</td>\n",
       "      <td>-0.137296</td>\n",
       "      <td>-0.095301</td>\n",
       "      <td>0.181735</td>\n",
       "      <td>-0.042683</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>74996</th>\n",
       "      <td>0.181714</td>\n",
       "      <td>-0.045560</td>\n",
       "      <td>-0.055692</td>\n",
       "      <td>0.015649</td>\n",
       "      <td>-0.045585</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>74997</th>\n",
       "      <td>0.181714</td>\n",
       "      <td>-0.045560</td>\n",
       "      <td>-0.055692</td>\n",
       "      <td>0.015649</td>\n",
       "      <td>-0.045585</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>74998</th>\n",
       "      <td>0.324915</td>\n",
       "      <td>0.131823</td>\n",
       "      <td>-0.099424</td>\n",
       "      <td>0.065491</td>\n",
       "      <td>0.038437</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>74999</th>\n",
       "      <td>0.270141</td>\n",
       "      <td>-0.004631</td>\n",
       "      <td>-0.151272</td>\n",
       "      <td>0.035538</td>\n",
       "      <td>0.083641</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>75000 rows × 14 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          lsa_0     lsa_1     lsa_2     lsa_3     lsa_4  hybrid  happy  \\\n",
       "0      0.341025  0.182753  0.008214  0.140406 -0.156943       1      0   \n",
       "1      0.341025  0.182753  0.008214  0.140406 -0.156943       1      0   \n",
       "2      0.232158 -0.045496  0.187131 -0.000936  0.018518       1      1   \n",
       "3      0.232158 -0.045496  0.187131 -0.000936  0.018518       1      1   \n",
       "4      0.232158 -0.045496  0.187131 -0.000936  0.018518       1      1   \n",
       "...         ...       ...       ...       ...       ...     ...    ...   \n",
       "74995  0.184573 -0.137296 -0.095301  0.181735 -0.042683       0      1   \n",
       "74996  0.181714 -0.045560 -0.055692  0.015649 -0.045585       0      1   \n",
       "74997  0.181714 -0.045560 -0.055692  0.015649 -0.045585       0      1   \n",
       "74998  0.324915  0.131823 -0.099424  0.065491  0.038437       0      1   \n",
       "74999  0.270141 -0.004631 -0.151272  0.035538  0.083641       0      1   \n",
       "\n",
       "       blueberry  cheese  earthy  honey  orange  pine  sweet  \n",
       "0              0       0       0      0       0     0      0  \n",
       "1              0       0       0      0       0     0      0  \n",
       "2              0       1       0      0       0     0      0  \n",
       "3              0       1       0      0       0     0      0  \n",
       "4              0       1       0      0       0     0      0  \n",
       "...          ...     ...     ...    ...     ...   ...    ...  \n",
       "74995          0       0       0      0       0     0      0  \n",
       "74996          0       0       0      0       0     0      0  \n",
       "74997          0       0       0      0       0     0      0  \n",
       "74998          0       0       0      0       0     0      0  \n",
       "74999          1       1       1      1       1     1      1  \n",
       "\n",
       "[75000 rows x 14 columns]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "selected_X = df_mlp[selected_features]\n",
    "selected_X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['lsa_0',\n",
       " 'lsa_1',\n",
       " 'lsa_2',\n",
       " 'lsa_3',\n",
       " 'lsa_4',\n",
       " 'hybrid',\n",
       " 'happy',\n",
       " 'blueberry',\n",
       " 'cheese',\n",
       " 'earthy',\n",
       " 'honey',\n",
       " 'orange',\n",
       " 'pine',\n",
       " 'sweet']"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "selected_X.columns.to_list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['selected_X_mlp_lsa_elbow_linalol.pkl']"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import joblib\n",
    "\n",
    "joblib.dump(selector, \"selector_mlp_lsa_elbow_linalol.pkl\")\n",
    "joblib.dump(selected_X, \"selected_X_mlp_lsa_elbow_linalol.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import joblib\n",
    "\n",
    "# selected_X = joblib.load(\"selected_X_mlp_lsa_elbow_linalol.pkl\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train test split (after Feature Selection)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(selected_X, y, random_state=1, test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train1, X_val, y_train1, y_val = train_test_split(X_train, y_train, random_state=1, test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/andalanputra/opt/anaconda3/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:1623: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    }
   ],
   "source": [
    "mlpreg.fit(X_train1, y_train1)\n",
    "y_pred_mlpreg = mlpreg.predict(X_val)\n",
    "y_pred_mlpreg_r2 = mlpreg.predict(X_train1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.15942188480382063"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mean_absolute_error(y_val, y_pred_mlpreg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5750640882535849"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#train\n",
    "r2_score(y_train1, y_pred_mlpreg_r2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5592318196318414"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#val\n",
    "r2_score(y_val, y_pred_mlpreg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hyperparameter Tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "parameters = {'hidden_layer_sizes': [(100,), (50, 50, 50), (50, 100, 50)],\n",
    "              'activation': ['tanh', 'relu'], #only tanh and relu\n",
    "              'max_iter': [200, 500, 1000]\n",
    "              }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "rscv = RandomizedSearchCV(mlpreg,  \n",
    "                     parameters,   \n",
    "                     cv=5, \n",
    "                     scoring='neg_mean_absolute_error',\n",
    "                     n_jobs=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/andalanputra/opt/anaconda3/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:1623: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/Users/andalanputra/opt/anaconda3/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:1623: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/Users/andalanputra/opt/anaconda3/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:1623: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/Users/andalanputra/opt/anaconda3/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:1623: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/Users/andalanputra/opt/anaconda3/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:1623: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/Users/andalanputra/opt/anaconda3/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:1623: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/Users/andalanputra/opt/anaconda3/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:1623: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/Users/andalanputra/opt/anaconda3/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:1623: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/Users/andalanputra/opt/anaconda3/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:1623: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/Users/andalanputra/opt/anaconda3/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:1623: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/Users/andalanputra/opt/anaconda3/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:1623: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/Users/andalanputra/opt/anaconda3/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/Users/andalanputra/opt/anaconda3/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:1623: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/Users/andalanputra/opt/anaconda3/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/Users/andalanputra/opt/anaconda3/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:1623: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/Users/andalanputra/opt/anaconda3/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:1623: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/Users/andalanputra/opt/anaconda3/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:1623: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/Users/andalanputra/opt/anaconda3/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:1623: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/Users/andalanputra/opt/anaconda3/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:1623: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/Users/andalanputra/opt/anaconda3/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:1623: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/Users/andalanputra/opt/anaconda3/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:1623: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/Users/andalanputra/opt/anaconda3/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:1623: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/Users/andalanputra/opt/anaconda3/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:1623: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/Users/andalanputra/opt/anaconda3/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:1623: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/Users/andalanputra/opt/anaconda3/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:1623: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/Users/andalanputra/opt/anaconda3/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:1623: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/Users/andalanputra/opt/anaconda3/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/Users/andalanputra/opt/anaconda3/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:1623: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/Users/andalanputra/opt/anaconda3/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:1623: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/Users/andalanputra/opt/anaconda3/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:1623: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/Users/andalanputra/opt/anaconda3/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:1623: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/Users/andalanputra/opt/anaconda3/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/Users/andalanputra/opt/anaconda3/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:1623: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/Users/andalanputra/opt/anaconda3/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/Users/andalanputra/opt/anaconda3/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:1623: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/Users/andalanputra/opt/anaconda3/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/Users/andalanputra/opt/anaconda3/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:1623: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/Users/andalanputra/opt/anaconda3/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:1623: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/Users/andalanputra/opt/anaconda3/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:1623: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/Users/andalanputra/opt/anaconda3/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:1623: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/Users/andalanputra/opt/anaconda3/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:1623: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/Users/andalanputra/opt/anaconda3/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:1623: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/Users/andalanputra/opt/anaconda3/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:1623: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/Users/andalanputra/opt/anaconda3/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:1623: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/Users/andalanputra/opt/anaconda3/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:1623: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/Users/andalanputra/opt/anaconda3/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:1623: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/Users/andalanputra/opt/anaconda3/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:1623: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/Users/andalanputra/opt/anaconda3/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:1623: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/Users/andalanputra/opt/anaconda3/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:1623: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/Users/andalanputra/opt/anaconda3/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:1623: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/Users/andalanputra/opt/anaconda3/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:1623: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/Users/andalanputra/opt/anaconda3/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:1623: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/Users/andalanputra/opt/anaconda3/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:1623: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/Users/andalanputra/opt/anaconda3/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:1623: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/Users/andalanputra/opt/anaconda3/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:1623: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/Users/andalanputra/opt/anaconda3/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:1623: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/Users/andalanputra/opt/anaconda3/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:1623: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;background-color: white;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>RandomizedSearchCV(cv=5,\n",
       "                   estimator=MLPRegressor(early_stopping=True, random_state=1),\n",
       "                   n_jobs=-1,\n",
       "                   param_distributions={&#x27;activation&#x27;: [&#x27;tanh&#x27;, &#x27;relu&#x27;],\n",
       "                                        &#x27;hidden_layer_sizes&#x27;: [(100,),\n",
       "                                                               (50, 50, 50),\n",
       "                                                               (50, 100, 50)],\n",
       "                                        &#x27;max_iter&#x27;: [200, 500, 1000]},\n",
       "                   scoring=&#x27;neg_mean_absolute_error&#x27;)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" ><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">RandomizedSearchCV</label><div class=\"sk-toggleable__content\"><pre>RandomizedSearchCV(cv=5,\n",
       "                   estimator=MLPRegressor(early_stopping=True, random_state=1),\n",
       "                   n_jobs=-1,\n",
       "                   param_distributions={&#x27;activation&#x27;: [&#x27;tanh&#x27;, &#x27;relu&#x27;],\n",
       "                                        &#x27;hidden_layer_sizes&#x27;: [(100,),\n",
       "                                                               (50, 50, 50),\n",
       "                                                               (50, 100, 50)],\n",
       "                                        &#x27;max_iter&#x27;: [200, 500, 1000]},\n",
       "                   scoring=&#x27;neg_mean_absolute_error&#x27;)</pre></div></div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" ><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">estimator: MLPRegressor</label><div class=\"sk-toggleable__content\"><pre>MLPRegressor(early_stopping=True, random_state=1)</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-3\" type=\"checkbox\" ><label for=\"sk-estimator-id-3\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">MLPRegressor</label><div class=\"sk-toggleable__content\"><pre>MLPRegressor(early_stopping=True, random_state=1)</pre></div></div></div></div></div></div></div></div></div></div>"
      ],
      "text/plain": [
       "RandomizedSearchCV(cv=5,\n",
       "                   estimator=MLPRegressor(early_stopping=True, random_state=1),\n",
       "                   n_jobs=-1,\n",
       "                   param_distributions={'activation': ['tanh', 'relu'],\n",
       "                                        'hidden_layer_sizes': [(100,),\n",
       "                                                               (50, 50, 50),\n",
       "                                                               (50, 100, 50)],\n",
       "                                        'max_iter': [200, 500, 1000]},\n",
       "                   scoring='neg_mean_absolute_error')"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rscv.fit(X_train1, y_train1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'max_iter': 500, 'hidden_layer_sizes': (50, 100, 50), 'activation': 'relu'}"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rscv.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['rscv_mlp_lsa_elbow_best_params_linalol.pkl']"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "joblib.dump(rscv, \"rscv_mlp_lsa_elbow_linalol.pkl\")\n",
    "joblib.dump(rscv.best_params_, \"rscv_mlp_lsa_elbow_best_params_linalol.pkl\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "MLP fit (after hyperparameter tuning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/andalanputra/opt/anaconda3/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:1623: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    }
   ],
   "source": [
    "mlpreg_ht = MLPRegressor(random_state=1, max_iter=500, activation = 'relu', hidden_layer_sizes= (50,100,50), early_stopping=True)\n",
    "mlpreg_ht.fit(X_train1, y_train1)\n",
    "y_pred_mlp_ht = mlpreg_ht.predict(X_val)\n",
    "y_pred_mlp_r2_ht = mlpreg_ht.predict(X_train1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.09855847650714865"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mean_absolute_error(y_val, y_pred_mlp_ht)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8333002301579373"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#train\n",
    "r2_score(y_train1, y_pred_mlp_r2_ht)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8034535914801028"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#val\n",
    "r2_score(y_val, y_pred_mlp_ht)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Residual plots after Hyperparameter Tuning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Predicting model on the test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_mlpreg_test = mlpreg_ht.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['y_test_mlpreg_lsa_elbow_linalol.pkl']"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "joblib.dump(y_pred_mlpreg_test, \"y_pred_mlpreg_test_lsa_elbow_linalol.pkl\")\n",
    "joblib.dump(y_test, \"y_test_mlpreg_lsa_elbow_linalol.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.09858274155954823"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mean_absolute_error(y_test, y_pred_mlpreg_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.02009131591917703"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mean_squared_error(y_test, y_pred_mlpreg_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.14174383908719643"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mean_squared_error(y_test, y_pred_mlpreg_test, squared = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8002822098549879"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "r2_score(y_test, y_pred_mlpreg_test)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Error analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 576x432 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 432x288 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# assume y_pred is a numpy array and y_true is a pandas dataframe\n",
    "fig, ax = plt.subplots(figsize=(8, 6))\n",
    "\n",
    "column = \"X..Linalool\"  # specify the target variable name\n",
    "ax.hist(y_pred_mlpreg_test, alpha=0.5, label='y_pred', bins=20)\n",
    "ax.hist(y_test[column], alpha=0.5, label='y_true', bins=20)\n",
    "ax.legend(loc='upper right')\n",
    "ax.set_title(column)\n",
    "\n",
    "plt.show()\n",
    "plt.savefig('error_hist_mlp_lsa_elbow_linalol.png')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pearson R"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pearson correlation coefficient: 0.895\n",
      "P-value: 0.000\n"
     ]
    }
   ],
   "source": [
    "corr_coef, p_value = pearsonr(y_pred_mlpreg_test.flatten(), y_test.values.ravel())\n",
    "\n",
    "print(f\"Pearson correlation coefficient: {corr_coef:.3f}\")\n",
    "print(f\"P-value: {p_value:.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:>"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAWoAAAD8CAYAAABekO4JAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjQuMywgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/MnkTPAAAACXBIWXMAAAsTAAALEwEAmpwYAAAVlUlEQVR4nO3df8xe5X3f8fdnxqxL2gwzhOfYHrDIIngodVLqoDLRJIjIdtIYUOjwH+Ah0odscQNT2s1lf5BJ00pYaERWZmpaC7OlINrGwwsshHlJvFRJwDEOvz1cIPDEDp5Ci6uxBUy+++M+pic394/nefBjH8z7JR3d51zXuc75PpL18dF1n/ucVBWSpO76W0e7AEnSaAa1JHWcQS1JHWdQS1LHGdSS1HEGtSR1nEEtSUMk2ZRkf5JHhvS/O8m3k/wkyW/19a1IsjvJniTrW+0nJrkvyZPN57xxdRjUkjTcrcCKEf0vAJ8GPt9uTDIHuAlYCSwF1iRZ2nSvB7ZV1RJgW7M9kkEtSUNU1XZ6YTysf39VPQC80te1HNhTVU9V1cvAHcDqpm81sLlZ3wxcMK6O46ZZ97TdPfd0f/ooaUo+8sruvNFjTCdzPnrwf10JTLSaNlbVxjdaA7AQeK61PQm8v1mfX1X7AKpqX5KTxx1s1oNakrqqCeXDEcz9Bv2HM+OLVqc+JOnwmwQWt7YXAXub9eeTLABoPvePO5hBLUmH3wPAkiSnJTkeuATY2vRtBdY262uBu8YdzKkPSRoiye3AB4CTkkwC1wJzAarq5iR/H9gBvAP4aZKrgaVVdSDJOuBeYA6wqaoebQ57HXBnkiuAZ4GLx9VhUEvSEFW1Zkz/j+hNawzquwe4Z0D7j4HzplOHUx+S1HEGtSR1nEEtSR1nUEtSxxnUktRxBrUkdZxBLUkdZ1BLUscZ1JLUcQa1JHWcQS1JHWdQS1LHGdSS1HEGtSR1nEEtSR1nUEtSxxnUktRxBrUkdZxBLUlDJNmUZH+SR4b0J8kXk+xJ8lCS9zXtpyfZ1VoONO9TJMlnk/yw1bdqXB2+M1GShrsV+H3gtiH9K4ElzfJ+YAPw/qraDSwDSDIH+CGwpTXuC1X1+akW4RW1JA1RVduBF0bsshq4rXq+A5yQZEHfPucBf1FVP5hpHQa1JM3cQuC51vZk09Z2CXB7X9u6ZqpkU5J5405iUEt6y0oykWRHa5mY7iEGtFXr+McDHwP+pNW/AXgXvamRfcAN407iHLWkt6yq2ghsfAOHmAQWt7YXAXtb2yuBnVX1fOucr60nuQX4yriTeEUtSTO3FbisufvjbODFqtrX6l9D37RH3xz2hcDAO0ravKKWpCGS3A58ADgpySRwLTAXoKpuBu4BVgF7gJeAy1tj3wacD1zZd9jrkyyjN0XyzID+1zGoJWmIqlozpr+ATw3pewn4ewPaL51uHU59SFLHGdSS1HEGtSR1nEEtSR1nUEtSxxnUktRxBrUkdZxBLUkdZ1BLUscZ1JLUcQa1JHWcQS1JHWdQS1LHGdSS1HEGtSR1nEEtSR1nUEtSxxnUktRxBrUkdZxBLUlDJNmUZH+SgW8Kb94+/sUke5I8lOR9rb5nkjycZFeSHa32E5Pcl+TJ5nPeuDoMakka7lZgxYj+lcCSZpkANvT1f7CqllXVWa229cC2qloCbGu2RzKoJWmIqtoOvDBil9XAbdXzHeCEJAvGHHY1sLlZ3wxcMK4Og1rSW1aSiSQ7WsvENA+xEHiutT3ZtAEU8LUk3+s77vyq2gfQfJ487iTHTbMoSTpmVNVGYOMbOEQGHbb5PKeq9iY5GbgvyRPNFfq0eUUtSTM3CSxubS8C9gJU1aHP/cAWYHmzz/OHpkeaz/3jTmJQS9LMbQUua+7+OBt4sar2JXl7kl8ASPJ24MPAI60xa5v1tcBd407i1IckDZHkduADwElJJoFrgbkAVXUzcA+wCtgDvARc3gydD2xJAr2c/eOq+mrTdx1wZ5IrgGeBi8fVYVBL0hBVtWZMfwGfGtD+FPCLQ8b8GDhvOnU49SFJHWdQS1LHGdSS1HEGtSR1nEEtSR1nUEtSxxnUktRxBrUkdZxBLUkdZ1BLUscZ1JLUcQa1JHWcQS1JHWdQS1LHGdSS1HEGtSR1nEEtSR1nUEtSxxnUkjREkk1J9id5ZEh/knwxyZ4kDyV5X9O+OMnXkzye5NEkV7XGfDbJD5PsapZV4+owqCVpuFuBFSP6VwJLmmUC2NC0HwQ+U1VnAGcDn0qytDXuC1W1rFnuGVeEQS1JQ1TVduCFEbusBm6rnu8AJyRZUFX7qmpnc4y/Bh4HFs60DoNa0ltWkokkO1rLxDQPsRB4rrU9SV8gJzkVeC/w3VbzumaqZFOSeeNOYlBLesuqqo1VdVZr2TjNQ2TQYV/rTH4e+DPg6qo60DRvAN4FLAP2ATeMO4lBLUkzNwksbm0vAvYCJJlLL6S/VFVfPrRDVT1fVa9W1U+BW4Dl405iUEvSzG0FLmvu/jgbeLGq9iUJ8EfA41X1e+0BSRa0Ni8EBt5R0nbcsI4kJ44aWFWjJtgl6U0vye3AB4CTkkwC1wJzAarqZuAeYBWwB3gJuLwZeg5wKfBwkl1N2zXNHR7XJ1lGb4rkGeDKcXUMDWrge82Bhs3B/MNxB5ekN7OqWjOmv4BPDWj/FoOzk6q6dLp1DA3qqjptugeTJB1+o66oX5PkY8C5zeY3quors1eSJKlt7JeJSa4DrgIea5arkvzubBcmSeqZyhX1KmBZcysJSTYDDwK/M5uFSZJ6pnp73gmt9b87C3VIkoaYyhX17wIPJvk6vW8xz8WraUk6YsYGdVXdnuQbwC/TC+p/VVU/mu3CJEk9U7rrg15IH7rr46fAf52dciRJ/WZy18envetDko4c7/qQpI7zrg9J6jjv+pCkjvOuD0nquFGPOX1fX9Nk8/nOJO889D4wSdLsGnVFPer1MAV86DDXIkkaYNRjTj94JAuRJA021cecngksBX7uUFtV3TZbRUmS/sbYoE5yLb1X0Syl99qZlcC3AINa0/aeW/4dJ6/6AC/v/zHb3/trR7sc6U1hKvdRfxw4D/hRVV0O/CLwt2e1Kh2zJjd/mfs/+omjXYY0JUk2JdmfZOALaJuX2n4xyZ4kD7VvwkiyIsnupm99q/3EJPclebL5nDeujqkE9f9tfpV4MMk7gP34vkTN0Avf2sErL7x4tMuQpupWYMWI/pXAkmaZADYAJJkD3NT0LwXWJFnajFkPbKuqJcC2ZnukqQT1jiQnALfQe+HtTuD+KYyTpDe1qtoOvDBil9XAbdXzHeCEJAuA5cCeqnqqql4G7mj2PTRmc7O+GbhgXB1jg7qq/nlV/VXzavTzgbXNFMhQSSaS7Eiy46s//atxp5Cko6KdVc0yMc1DLASea21PNm3D2gHmV9U+gObz5HEnmepdHwuBUw7tn+Tc5n+agapqI7AR4O65p9dUziFJR1o7q2Yogw47on1GpnLXx+eAf0LvEaevtk44NKgl6S1iEljc2l4E7AWOH9IO8HySBVW1r5km2T/uJFOZo74AOL2qVlXVrzXLx6byF0j9lv2nG/iV/3kHbz/9ND709DdZfPnHj3ZJ0huxFbisufvjbODFZjrjAWBJktOSHA9c0ux7aMzaZn0tcNe4k0xl6uMpYC7wk2n+AdLr7Lr0M0e7BGnKktxO73ckJyWZBK6ll4c039vdQ++Z/XuAl4DLm76DSdYB9wJzgE1V9Whz2OuAO5NcATwLXDyujqkE9UvAriTbaIV1VX16CmMl6U2rqtaM6S/gU0P67qEX5P3tP6b325Qpm0pQb+VvLtklSUfYVJ5HvXncPpKk2TPqedR3VtWvJ3mYAbeVVNV7ZrUySRIw+or6qubzo0eiEEnSYKOeR33olzM/6O9L8ufAObNYlySpMdW3kPf7B4e1CknSUDMNan8WLklHyKgvEy8a1gX8ndkpR5LUb9SXiaNev/GVw12IJGmwUV8mjnyUqSTpyJjRHHX7dTOSpNk10y8T/9lhrUKSNNSMgrqqfuNwFyJJGmymV9SSpCNkpnPUOw93IZKkwYYGdZLFw/qAqw9/KZKkQUZdUX8zyb9M8totfEnmJ/nPwA2zX5okCUYH9S8B7wIeTPKhJFcB9wPfBt5/JIqTJI0I6qr6y6q6EvhD4L8Dvw2cU1U3VdVPj1SBknS0JFmRZHeSPUnWD+ifl2RLkoeS3J/kzKb99CS7WsuBJFc3fZ9N8sNW36pxdYyaoz4hyR/Qe1njCuBPgf+W5EMz/Jsl6U0jyRzgJmAlsBRYk2Rp327XALuaF6lcBtwIUFW7q2pZVS2jNzvxErClNe4Lh/qbdyuONGrqYyfwJHBWVX2tqq4GLgX+bfNmXkk6li0H9lTVU1X1MnAHsLpvn6XANoCqegI4Ncn8vn3OA/5i0LP9p2pUUJ9bVZ+vqoOHGqpqV1X9CvA/ZnpCSeqKJBNJdrSWiVb3QuC51vZk09b2feCi5ljLgVOARX37XAL0X9yua6ZLNiWZN67OUXPUkyP6bhl3YEnquqraWFVntZaNre4MGtK3fR0wL8ku4DeBB4HXLm6THA98DPiT1pgN9G7UWAbsYwp30Y19C7kkvUVNAu3fkywC9rZ3qKoD9L7HI0mAp5vlkJXAzqp6vjXmtfUktzCFx0b7E3JJGuwBYEmS05or40uAre0dmpsujm82PwFsb8L7kDX0TXskWdDavBB4ZFwhXlFL0gBVdTDJOuBeYA6wqaoeTfLJpv9m4AzgtiSvAo8BVxwan+RtwPnAlX2Hvj7JMnrTKM8M6H+dVM3u6w/vnnu671eUNCUfeWX3oHnhaZlO5hyO8x0JTn1IUscZ1JLUcQa1JHWcQS1JHWdQS1LHGdSS1HEGtSR1nEEtSR1nUEtSxxnUktRxBrUkdZxBLUkdZ1BLUscZ1JLUcQa1JHWcQS1JHWdQS1LHGdSS1HEGtSQNkWRFkt1J9iRZP6B/XpItSR5Kcn+SM1t9zyR5OMmuJDta7ScmuS/Jk83nvHF1GNSSNECSOcBNwEpgKbAmydK+3a4BdlXVe4DLgBv7+j9YVcuq6qxW23pgW1UtAbY12yMZ1JI02HJgT1U9VVUvA3cAq/v2WUovbKmqJ4BTk8wfc9zVwOZmfTNwwbhCDGpJb1lJJpLsaC0Tre6FwHOt7cmmre37wEXNsZYDpwCLmr4Cvpbke33HnV9V+wCaz5PH1XncdP4oSTqWVNVGYOOQ7gwa0rd9HXBjkl3Aw8CDwMGm75yq2pvkZOC+JE9U1faZ1GlQS9Jgk8Di1vYiYG97h6o6AFwOkCTA081CVe1tPvcn2UJvKmU78HySBVW1L8kCYP+4Qpz6kKTBHgCWJDktyfHAJcDW9g5JTmj6AD4BbK+qA0nenuQXmn3eDnwYeKTZbyuwtllfC9w1rhCvqCVpgKo6mGQdcC8wB9hUVY8m+WTTfzNwBnBbkleBx4ArmuHzgS29i2yOA/64qr7a9F0H3JnkCuBZ4OJxtaSqf8rl8Lp77umzewJJx4yPvLJ70LzwtEwncw7H+Y4Epz4kqeMMaknqOINakjrOoJakjjOoJanjDGpJ6jiDWpI6zqCWpI4zqCWp4wxqSeo4g1qSOs6glqSOM6glqeMMaknqOINakjrOoJakjjOoJanjDGpJ6jiDWpKGSLIiye4ke5KsH9A/L8mWJA8luT/JmU374iRfT/J4kkeTXNUa89kkP0yyq1lWjavDl9tK0gBJ5gA3AecDk8ADSbZW1WOt3a4BdlXVhUne3ex/HnAQ+ExV7WzeRv69JPe1xn6hqj4/1Vq8opakwZYDe6rqqap6GbgDWN23z1JgG0BVPQGcmmR+Ve2rqp1N+18DjwMLZ1qIQS1Jgy0EnmttT/L6sP0+cBFAkuXAKcCi9g5JTgXeC3y31byumS7ZlGTeuEIMaklvWUkmkuxoLRPt7gFDqm/7OmBekl3AbwIP0pv2OHT8nwf+DLi6qg40zRuAdwHLgH3ADePqdI5a0ltWVW0ENg7pngQWt7YXAXv7xh8ALgdIEuDpZiHJXHoh/aWq+nJrzPOH1pPcAnxlXJ1eUUvSYA8AS5KcluR44BJga3uHJCc0fQCfALZX1YEmtP8IeLyqfq9vzILW5oXAI+MK8YpakgaoqoNJ1gH3AnOATVX1aJJPNv03A2cAtyV5FXgMuKIZfg5wKfBwMy0CcE1V3QNcn2QZvWmUZ4Arx9WSqv4pl8Pr7rmnz+4JJB0zPvLK7kHzwtMyncw5HOc7Epz6kKSOM6glqeMMaknqOINakjrOoJakjjOoJanjDGpJ6jiDWpI6zqCWpI4zqCWp4wxqSeo4g1qSOs6glqSOM6glqeMMaknqOINakjrOoJakjjOoJanjDGpJ6jiDWpKGSLIiye4ke5KsH9A/L8mWJA8luT/JmePGJjkxyX1Jnmw+542rw6CWpAGSzAFuAlYCS4E1SZb27XYNsKuq3gNcBtw4hbHrgW1VtQTY1myPZFBL0mDLgT1V9VRVvQzcAazu22cpvbClqp4ATk0yf8zY1cDmZn0zcMG4Qo57g3/IWG+W17HryEoyUVUbj3YdOvZMJ3OSTAATraaNrX+XC4HnWn2TwPv7DvF94CLgW0mWA6cAi8aMnV9V+wCqal+Sk8fVOetBLQ0xARjUOqqaUB7273BQ4Fff9nXAjUl2AQ8DDwIHpzh2ygxqSRpsEljc2l4E7G3vUFUHgMsBkgR4ulneNmLs80kWNFfTC4D94wpxjlqSBnsAWJLktCTHA5cAW9s7JDmh6QP4BLC9Ce9RY7cCa5v1tcBd4wrxilpHi9Me6rSqOphkHXAvMAfYVFWPJvlk038zcAZwW5JXgceAK0aNbQ59HXBnkiuAZ4GLx9WSqhlPm0iSjgCnPiSp4wxqSeo4g1o/I8niJE8nObHZntdsnzJizK1JPt7X9s4kf/oG6vhGkrNmOPaZJCfN9NxS1xjU+hlV9Rywgd4XHjSfG6vqB9M8zt6q+vj4PSWNY1BrkC8AZye5GvjHwA3TPUCSU5M80qz/0yRfTvLV5kE017f225BkR5JHk/ybIcdak+ThJI8k+dy4dulY4+15ep2qeiXJbwNfBT7cPKvgjVoGvBf4CbA7yX9ort7/dVW90DzEZluS91TVQ4cGJXkn8Dngl4C/BL6W5ALg/kHtVfVfDkOtUqd4Ra1hVgL7gDPH7ThF26rqxar6f/TuNz005/3rSXbS++ntP6L3kJu2Xwa+UVX/u6oOAl8Czh3RLh1zDGq9TpJlwPnA2cC/aH7m+kb9pLX+KnBcktOA3wLOax4TeTfwc/3lDCvzMNQkvSkY1PoZzfMKNgBXV9WzwL8HPj9Lp3sH8H+AF5tHQ64csM93gV9NclIzPbIG+OaIdumYY1Cr328Az1bVfc32fwTeneRXmyeEAZDkD/tun/uDJJPN8u2pnKiqvk9vyuNRYBPw5wP22Qf8DvB1eo+U3FlVdw1rn+bfKr0p+BNySeo4r6glqeMMaknqOINakjrOoJakjjOoJanjDGpJ6jiDWpI67v8Dw3SfE59k4I0AAAAASUVORK5CYII=",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "corr_matrix = y_test.corr()\n",
    "sns.heatmap(corr_matrix, annot=True, cmap='coolwarm', center=0)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
