{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn import preprocessing\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.neural_network import MLPRegressor\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "from sklearn.metrics import r2_score\n",
    "from scipy.stats import pearsonr\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.feature_selection import SelectFromModel\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compiling complete dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_rf = pd.read_csv(\"df_guai_tfidf.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['index',\n",
       " 'tfidf_0',\n",
       " 'tfidf_1',\n",
       " 'tfidf_2',\n",
       " 'tfidf_3',\n",
       " 'tfidf_4',\n",
       " 'tfidf_5',\n",
       " 'tfidf_6',\n",
       " 'tfidf_7',\n",
       " 'tfidf_8',\n",
       " 'tfidf_9',\n",
       " 'tfidf_10',\n",
       " 'tfidf_11',\n",
       " 'tfidf_12',\n",
       " 'tfidf_13',\n",
       " 'tfidf_14',\n",
       " 'tfidf_15',\n",
       " 'tfidf_16',\n",
       " 'tfidf_17',\n",
       " 'tfidf_18',\n",
       " 'tfidf_19',\n",
       " 'tfidf_20',\n",
       " 'tfidf_21',\n",
       " 'tfidf_22',\n",
       " 'tfidf_23',\n",
       " 'tfidf_24',\n",
       " 'tfidf_25',\n",
       " 'tfidf_26',\n",
       " 'tfidf_27',\n",
       " 'tfidf_28',\n",
       " 'tfidf_29',\n",
       " 'tfidf_30',\n",
       " 'tfidf_31',\n",
       " 'tfidf_32',\n",
       " 'tfidf_33',\n",
       " 'tfidf_34',\n",
       " 'tfidf_35',\n",
       " 'tfidf_36',\n",
       " 'tfidf_37',\n",
       " 'tfidf_38',\n",
       " 'tfidf_39',\n",
       " 'tfidf_40',\n",
       " 'tfidf_41',\n",
       " 'tfidf_42',\n",
       " 'tfidf_43',\n",
       " 'tfidf_44',\n",
       " 'tfidf_45',\n",
       " 'tfidf_46',\n",
       " 'tfidf_47',\n",
       " 'tfidf_48',\n",
       " 'tfidf_49',\n",
       " 'tfidf_50',\n",
       " 'tfidf_51',\n",
       " 'tfidf_52',\n",
       " 'tfidf_53',\n",
       " 'tfidf_54',\n",
       " 'tfidf_55',\n",
       " 'tfidf_56',\n",
       " 'tfidf_57',\n",
       " 'tfidf_58',\n",
       " 'tfidf_59',\n",
       " 'tfidf_60',\n",
       " 'tfidf_61',\n",
       " 'tfidf_62',\n",
       " 'tfidf_63',\n",
       " 'tfidf_64',\n",
       " 'tfidf_65',\n",
       " 'tfidf_66',\n",
       " 'tfidf_67',\n",
       " 'tfidf_68',\n",
       " 'tfidf_69',\n",
       " 'tfidf_70',\n",
       " 'tfidf_71',\n",
       " 'tfidf_72',\n",
       " 'tfidf_73',\n",
       " 'tfidf_74',\n",
       " 'tfidf_75',\n",
       " 'tfidf_76',\n",
       " 'tfidf_77',\n",
       " 'tfidf_78',\n",
       " 'tfidf_79',\n",
       " 'tfidf_80',\n",
       " 'tfidf_81',\n",
       " 'tfidf_82',\n",
       " 'tfidf_83',\n",
       " 'tfidf_84',\n",
       " 'tfidf_85',\n",
       " 'tfidf_86',\n",
       " 'tfidf_87',\n",
       " 'tfidf_88',\n",
       " 'tfidf_89',\n",
       " 'tfidf_90',\n",
       " 'tfidf_91',\n",
       " 'tfidf_92',\n",
       " 'tfidf_93',\n",
       " 'tfidf_94',\n",
       " 'tfidf_95',\n",
       " 'tfidf_96',\n",
       " 'tfidf_97',\n",
       " 'tfidf_98',\n",
       " 'tfidf_99',\n",
       " 'tfidf_100',\n",
       " 'tfidf_101',\n",
       " 'tfidf_102',\n",
       " 'tfidf_103',\n",
       " 'tfidf_104',\n",
       " 'tfidf_105',\n",
       " 'tfidf_106',\n",
       " 'tfidf_107',\n",
       " 'tfidf_108',\n",
       " 'tfidf_109',\n",
       " 'tfidf_110',\n",
       " 'tfidf_111',\n",
       " 'tfidf_112',\n",
       " 'tfidf_113',\n",
       " 'tfidf_114',\n",
       " 'tfidf_115',\n",
       " 'tfidf_116',\n",
       " 'tfidf_117',\n",
       " 'tfidf_118',\n",
       " 'tfidf_119',\n",
       " 'tfidf_120',\n",
       " 'tfidf_121',\n",
       " 'tfidf_122',\n",
       " 'tfidf_123',\n",
       " 'tfidf_124',\n",
       " 'tfidf_125',\n",
       " 'tfidf_126',\n",
       " 'tfidf_127',\n",
       " 'tfidf_128',\n",
       " 'tfidf_129',\n",
       " 'tfidf_130',\n",
       " 'tfidf_131',\n",
       " 'tfidf_132',\n",
       " 'tfidf_133',\n",
       " 'tfidf_134',\n",
       " 'tfidf_135',\n",
       " 'tfidf_136',\n",
       " 'tfidf_137',\n",
       " 'tfidf_138',\n",
       " 'tfidf_139',\n",
       " 'tfidf_140',\n",
       " 'tfidf_141',\n",
       " 'tfidf_142',\n",
       " 'tfidf_143',\n",
       " 'tfidf_144',\n",
       " 'tfidf_145',\n",
       " 'tfidf_146',\n",
       " 'tfidf_147',\n",
       " 'tfidf_148',\n",
       " 'tfidf_149',\n",
       " 'tfidf_150',\n",
       " 'tfidf_151',\n",
       " 'tfidf_152',\n",
       " 'tfidf_153',\n",
       " 'tfidf_154',\n",
       " 'tfidf_155',\n",
       " 'tfidf_156',\n",
       " 'tfidf_157',\n",
       " 'tfidf_158',\n",
       " 'tfidf_159',\n",
       " 'tfidf_160',\n",
       " 'tfidf_161',\n",
       " 'tfidf_162',\n",
       " 'tfidf_163',\n",
       " 'tfidf_164',\n",
       " 'tfidf_165',\n",
       " 'tfidf_166',\n",
       " 'tfidf_167',\n",
       " 'tfidf_168',\n",
       " 'tfidf_169',\n",
       " 'tfidf_170',\n",
       " 'tfidf_171',\n",
       " 'tfidf_172',\n",
       " 'tfidf_173',\n",
       " 'tfidf_174',\n",
       " 'tfidf_175',\n",
       " 'tfidf_176',\n",
       " 'tfidf_177',\n",
       " 'tfidf_178',\n",
       " 'tfidf_179',\n",
       " 'tfidf_180',\n",
       " 'tfidf_181',\n",
       " 'tfidf_182',\n",
       " 'tfidf_183',\n",
       " 'tfidf_184',\n",
       " 'tfidf_185',\n",
       " 'tfidf_186',\n",
       " 'tfidf_187',\n",
       " 'tfidf_188',\n",
       " 'tfidf_189',\n",
       " 'tfidf_190',\n",
       " 'tfidf_191',\n",
       " 'tfidf_192',\n",
       " 'tfidf_193',\n",
       " 'tfidf_194',\n",
       " 'tfidf_195',\n",
       " 'tfidf_196',\n",
       " 'tfidf_197',\n",
       " 'tfidf_198',\n",
       " 'tfidf_199',\n",
       " 'tfidf_200',\n",
       " 'tfidf_201',\n",
       " 'tfidf_202',\n",
       " 'tfidf_203',\n",
       " 'tfidf_204',\n",
       " 'tfidf_205',\n",
       " 'tfidf_206',\n",
       " 'tfidf_207',\n",
       " 'tfidf_208',\n",
       " 'tfidf_209',\n",
       " 'tfidf_210',\n",
       " 'tfidf_211',\n",
       " 'tfidf_212',\n",
       " 'tfidf_213',\n",
       " 'tfidf_214',\n",
       " 'tfidf_215',\n",
       " 'tfidf_216',\n",
       " 'tfidf_217',\n",
       " 'tfidf_218',\n",
       " 'tfidf_219',\n",
       " 'tfidf_220',\n",
       " 'tfidf_221',\n",
       " 'tfidf_222',\n",
       " 'tfidf_223',\n",
       " 'tfidf_224',\n",
       " 'tfidf_225',\n",
       " 'tfidf_226',\n",
       " 'tfidf_227',\n",
       " 'tfidf_228',\n",
       " 'tfidf_229',\n",
       " 'tfidf_230',\n",
       " 'tfidf_231',\n",
       " 'tfidf_232',\n",
       " 'tfidf_233',\n",
       " 'tfidf_234',\n",
       " 'tfidf_235',\n",
       " 'tfidf_236',\n",
       " 'tfidf_237',\n",
       " 'tfidf_238',\n",
       " 'tfidf_239',\n",
       " 'tfidf_240',\n",
       " 'tfidf_241',\n",
       " 'tfidf_242',\n",
       " 'tfidf_243',\n",
       " 'tfidf_244',\n",
       " 'tfidf_245',\n",
       " 'tfidf_246',\n",
       " 'tfidf_247',\n",
       " 'tfidf_248',\n",
       " 'tfidf_249',\n",
       " 'tfidf_250',\n",
       " 'tfidf_251',\n",
       " 'tfidf_252',\n",
       " 'tfidf_253',\n",
       " 'tfidf_254',\n",
       " 'tfidf_255',\n",
       " 'tfidf_256',\n",
       " 'tfidf_257',\n",
       " 'tfidf_258',\n",
       " 'tfidf_259',\n",
       " 'tfidf_260',\n",
       " 'tfidf_261',\n",
       " 'tfidf_262',\n",
       " 'tfidf_263',\n",
       " 'tfidf_264',\n",
       " 'tfidf_265',\n",
       " 'tfidf_266',\n",
       " 'tfidf_267',\n",
       " 'tfidf_268',\n",
       " 'tfidf_269',\n",
       " 'tfidf_270',\n",
       " 'tfidf_271',\n",
       " 'tfidf_272',\n",
       " 'tfidf_273',\n",
       " 'tfidf_274',\n",
       " 'tfidf_275',\n",
       " 'tfidf_276',\n",
       " 'tfidf_277',\n",
       " 'tfidf_278',\n",
       " 'tfidf_279',\n",
       " 'tfidf_280',\n",
       " 'tfidf_281',\n",
       " 'tfidf_282',\n",
       " 'tfidf_283',\n",
       " 'tfidf_284',\n",
       " 'tfidf_285',\n",
       " 'tfidf_286',\n",
       " 'tfidf_287',\n",
       " 'tfidf_288',\n",
       " 'tfidf_289',\n",
       " 'tfidf_290',\n",
       " 'tfidf_291',\n",
       " 'tfidf_292',\n",
       " 'tfidf_293',\n",
       " 'tfidf_294',\n",
       " 'tfidf_295',\n",
       " 'tfidf_296',\n",
       " 'tfidf_297',\n",
       " 'tfidf_298',\n",
       " 'tfidf_299',\n",
       " 'tfidf_300',\n",
       " 'tfidf_301',\n",
       " 'tfidf_302',\n",
       " 'tfidf_303',\n",
       " 'tfidf_304',\n",
       " 'tfidf_305',\n",
       " 'tfidf_306',\n",
       " 'tfidf_307',\n",
       " 'tfidf_308',\n",
       " 'tfidf_309',\n",
       " 'tfidf_310',\n",
       " 'tfidf_311',\n",
       " 'tfidf_312',\n",
       " 'tfidf_313',\n",
       " 'tfidf_314',\n",
       " 'tfidf_315',\n",
       " 'tfidf_316',\n",
       " 'tfidf_317',\n",
       " 'tfidf_318',\n",
       " 'tfidf_319',\n",
       " 'tfidf_320',\n",
       " 'tfidf_321',\n",
       " 'tfidf_322',\n",
       " 'tfidf_323',\n",
       " 'tfidf_324',\n",
       " 'tfidf_325',\n",
       " 'tfidf_326',\n",
       " 'tfidf_327',\n",
       " 'tfidf_328',\n",
       " 'tfidf_329',\n",
       " 'tfidf_330',\n",
       " 'tfidf_331',\n",
       " 'tfidf_332',\n",
       " 'tfidf_333',\n",
       " 'tfidf_334',\n",
       " 'tfidf_335',\n",
       " 'tfidf_336',\n",
       " 'tfidf_337',\n",
       " 'tfidf_338',\n",
       " 'tfidf_339',\n",
       " 'tfidf_340',\n",
       " 'tfidf_341',\n",
       " 'tfidf_342',\n",
       " 'tfidf_343',\n",
       " 'tfidf_344',\n",
       " 'tfidf_345',\n",
       " 'tfidf_346',\n",
       " 'tfidf_347',\n",
       " 'tfidf_348',\n",
       " 'tfidf_349',\n",
       " 'tfidf_350',\n",
       " 'tfidf_351',\n",
       " 'tfidf_352',\n",
       " 'tfidf_353',\n",
       " 'tfidf_354',\n",
       " 'tfidf_355',\n",
       " 'tfidf_356',\n",
       " 'tfidf_357',\n",
       " 'tfidf_358',\n",
       " 'tfidf_359',\n",
       " 'tfidf_360',\n",
       " 'tfidf_361',\n",
       " 'tfidf_362',\n",
       " 'tfidf_363',\n",
       " 'tfidf_364',\n",
       " 'tfidf_365',\n",
       " 'tfidf_366',\n",
       " 'tfidf_367',\n",
       " 'tfidf_368',\n",
       " 'tfidf_369',\n",
       " 'tfidf_370',\n",
       " 'tfidf_371',\n",
       " 'tfidf_372',\n",
       " 'tfidf_373',\n",
       " 'tfidf_374',\n",
       " 'tfidf_375',\n",
       " 'tfidf_376',\n",
       " 'tfidf_377',\n",
       " 'tfidf_378',\n",
       " 'tfidf_379',\n",
       " 'tfidf_380',\n",
       " 'tfidf_381',\n",
       " 'tfidf_382',\n",
       " 'tfidf_383',\n",
       " 'tfidf_384',\n",
       " 'tfidf_385',\n",
       " 'tfidf_386',\n",
       " 'tfidf_387',\n",
       " 'hybrid',\n",
       " 'indica',\n",
       " 'sativa',\n",
       " 'anxiety',\n",
       " 'anxious',\n",
       " 'aroused',\n",
       " 'arthritis',\n",
       " 'creative',\n",
       " 'depression',\n",
       " 'dizzy',\n",
       " 'dry eyes',\n",
       " 'dry mouth',\n",
       " 'energetic',\n",
       " 'epilepsy',\n",
       " 'euphoric',\n",
       " 'eye pressure',\n",
       " 'fatigue',\n",
       " 'focused',\n",
       " 'giggly',\n",
       " 'happy',\n",
       " 'headache',\n",
       " 'hungry',\n",
       " 'migraines',\n",
       " 'pain',\n",
       " 'paranoid',\n",
       " 'relaxed',\n",
       " 'seizures',\n",
       " 'sleepy',\n",
       " 'spasticity',\n",
       " 'stress',\n",
       " 'talkative',\n",
       " 'tingly',\n",
       " 'uplifted',\n",
       " 'ammonia',\n",
       " 'apple',\n",
       " 'apricot',\n",
       " 'berry',\n",
       " 'blue cheese',\n",
       " 'blueberry',\n",
       " 'butter',\n",
       " 'cheese',\n",
       " 'chemical',\n",
       " 'chestnut',\n",
       " 'citrus',\n",
       " 'coffee',\n",
       " 'diesel',\n",
       " 'earthy',\n",
       " 'flowery',\n",
       " 'fruit',\n",
       " 'grape',\n",
       " 'grapefruit',\n",
       " 'honey',\n",
       " 'lavender',\n",
       " 'lemon',\n",
       " 'lime',\n",
       " 'mango',\n",
       " 'menthol',\n",
       " 'mint',\n",
       " 'nutty',\n",
       " 'orange',\n",
       " 'peach',\n",
       " 'pear',\n",
       " 'pepper',\n",
       " 'pine',\n",
       " 'pineapple',\n",
       " 'plum',\n",
       " 'pungent',\n",
       " 'rose',\n",
       " 'sage',\n",
       " 'skunk',\n",
       " 'spicy/herbal',\n",
       " 'strawberry',\n",
       " 'sweet',\n",
       " 'tar',\n",
       " 'tea',\n",
       " 'tobacco',\n",
       " 'tree',\n",
       " 'tropical',\n",
       " 'vanilla',\n",
       " 'violet',\n",
       " 'woody',\n",
       " 'X..Guaiol']"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_rf.columns.to_list()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Splitting dependent and independent variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df_rf.drop(['index', 'X..Guaiol'], axis = 1)\n",
    "y = df_rf[['X..Guaiol']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plotting histograms on target variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.44444444],\n",
       "       [0.44444444],\n",
       "       [0.44444444],\n",
       "       ...,\n",
       "       [0.22222222],\n",
       "       [0.22222222],\n",
       "       [0.22222222]])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_array = y.to_numpy()\n",
    "y_array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:ylabel='Count'>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "sns.histplot(y, bins = 10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train test split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=1, test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train1, X_val, y_train1, y_val = train_test_split(X_train, y_train, random_state=1, test_size=0.25)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "RF modeling (before Feature selection and Hyperparameter Tuning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/y1/pjvjlkjn5gl846rnyzr53p340000gn/T/ipykernel_10483/350139188.py:2: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  rfreg.fit(X_train1, y_train1)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;background-color: white;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>RandomForestRegressor()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">RandomForestRegressor</label><div class=\"sk-toggleable__content\"><pre>RandomForestRegressor()</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "RandomForestRegressor()"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rfreg = RandomForestRegressor()\n",
    "rfreg.fit(X_train1, y_train1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_rfreg = rfreg.predict(X_val)\n",
    "y_pred_rfreg_r2 = rfreg.predict(X_train1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.05062060317677853"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mean_absolute_error(y_val, y_pred_rfreg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.012122802940721678"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mean_squared_error(y_val, y_pred_rfreg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.11010360094348268"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mean_squared_error(y_val, y_pred_rfreg, squared = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9832583011562875"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#train\n",
    "r2_score(y_train1, y_pred_rfreg_r2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9138911955660742"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#val\n",
    "r2_score(y_val, y_pred_rfreg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Residual plots for each target variable"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Feature Selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_feat = pd.DataFrame({\n",
    "    \"features\": X_train1.columns,\n",
    "    \"score\": rfreg.feature_importances_\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>features</th>\n",
       "      <th>score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>tfidf_0</td>\n",
       "      <td>0.000572</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>tfidf_1</td>\n",
       "      <td>0.000752</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>tfidf_2</td>\n",
       "      <td>0.002560</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>tfidf_3</td>\n",
       "      <td>0.001291</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>tfidf_4</td>\n",
       "      <td>0.000619</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>464</th>\n",
       "      <td>tree</td>\n",
       "      <td>0.000181</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>465</th>\n",
       "      <td>tropical</td>\n",
       "      <td>0.000512</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>466</th>\n",
       "      <td>vanilla</td>\n",
       "      <td>0.001608</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>467</th>\n",
       "      <td>violet</td>\n",
       "      <td>0.000059</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>468</th>\n",
       "      <td>woody</td>\n",
       "      <td>0.000762</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>469 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     features     score\n",
       "0     tfidf_0  0.000572\n",
       "1     tfidf_1  0.000752\n",
       "2     tfidf_2  0.002560\n",
       "3     tfidf_3  0.001291\n",
       "4     tfidf_4  0.000619\n",
       "..        ...       ...\n",
       "464      tree  0.000181\n",
       "465  tropical  0.000512\n",
       "466   vanilla  0.001608\n",
       "467    violet  0.000059\n",
       "468     woody  0.000762\n",
       "\n",
       "[469 rows x 2 columns]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_feat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_feat_ranked = df_feat.sort_values(\"score\", ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>features</th>\n",
       "      <th>score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>390</th>\n",
       "      <td>sativa</td>\n",
       "      <td>3.532612e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>388</th>\n",
       "      <td>hybrid</td>\n",
       "      <td>3.872629e-02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>441</th>\n",
       "      <td>lemon</td>\n",
       "      <td>2.731643e-02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>426</th>\n",
       "      <td>blueberry</td>\n",
       "      <td>1.618039e-02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>168</th>\n",
       "      <td>tfidf_168</td>\n",
       "      <td>1.020139e-02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>329</th>\n",
       "      <td>tfidf_329</td>\n",
       "      <td>8.971756e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>405</th>\n",
       "      <td>focused</td>\n",
       "      <td>8.161648e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>434</th>\n",
       "      <td>earthy</td>\n",
       "      <td>8.031679e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>141</th>\n",
       "      <td>tfidf_141</td>\n",
       "      <td>7.971940e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>149</th>\n",
       "      <td>tfidf_149</td>\n",
       "      <td>7.801520e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>345</th>\n",
       "      <td>tfidf_345</td>\n",
       "      <td>7.603370e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>406</th>\n",
       "      <td>giggly</td>\n",
       "      <td>7.554087e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>433</th>\n",
       "      <td>diesel</td>\n",
       "      <td>7.444707e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>145</th>\n",
       "      <td>tfidf_145</td>\n",
       "      <td>7.242008e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>101</th>\n",
       "      <td>tfidf_101</td>\n",
       "      <td>7.003042e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>199</th>\n",
       "      <td>tfidf_199</td>\n",
       "      <td>6.292858e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>320</th>\n",
       "      <td>tfidf_320</td>\n",
       "      <td>6.242410e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>285</th>\n",
       "      <td>tfidf_285</td>\n",
       "      <td>5.654340e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>161</th>\n",
       "      <td>tfidf_161</td>\n",
       "      <td>5.155864e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>337</th>\n",
       "      <td>tfidf_337</td>\n",
       "      <td>5.062775e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>253</th>\n",
       "      <td>tfidf_253</td>\n",
       "      <td>4.721395e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>312</th>\n",
       "      <td>tfidf_312</td>\n",
       "      <td>4.698765e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>93</th>\n",
       "      <td>tfidf_93</td>\n",
       "      <td>4.648914e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>158</th>\n",
       "      <td>tfidf_158</td>\n",
       "      <td>4.622110e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>239</th>\n",
       "      <td>tfidf_239</td>\n",
       "      <td>4.516208e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>395</th>\n",
       "      <td>creative</td>\n",
       "      <td>4.340769e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>297</th>\n",
       "      <td>tfidf_297</td>\n",
       "      <td>4.268601e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>247</th>\n",
       "      <td>tfidf_247</td>\n",
       "      <td>4.235524e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>309</th>\n",
       "      <td>tfidf_309</td>\n",
       "      <td>4.230177e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>447</th>\n",
       "      <td>orange</td>\n",
       "      <td>4.200860e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>121</th>\n",
       "      <td>tfidf_121</td>\n",
       "      <td>4.101116e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>245</th>\n",
       "      <td>tfidf_245</td>\n",
       "      <td>4.019421e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>128</th>\n",
       "      <td>tfidf_128</td>\n",
       "      <td>3.982674e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>tfidf_7</td>\n",
       "      <td>3.978325e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>189</th>\n",
       "      <td>tfidf_189</td>\n",
       "      <td>3.807034e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>402</th>\n",
       "      <td>euphoric</td>\n",
       "      <td>3.731511e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>281</th>\n",
       "      <td>tfidf_281</td>\n",
       "      <td>3.663731e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>431</th>\n",
       "      <td>citrus</td>\n",
       "      <td>3.638310e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>167</th>\n",
       "      <td>tfidf_167</td>\n",
       "      <td>3.536833e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>tfidf_30</td>\n",
       "      <td>3.498166e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>78</th>\n",
       "      <td>tfidf_78</td>\n",
       "      <td>3.444414e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>207</th>\n",
       "      <td>tfidf_207</td>\n",
       "      <td>3.442978e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>74</th>\n",
       "      <td>tfidf_74</td>\n",
       "      <td>3.376286e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>437</th>\n",
       "      <td>grape</td>\n",
       "      <td>3.325421e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>399</th>\n",
       "      <td>dry mouth</td>\n",
       "      <td>3.270750e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>457</th>\n",
       "      <td>skunk</td>\n",
       "      <td>3.208146e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>210</th>\n",
       "      <td>tfidf_210</td>\n",
       "      <td>3.175185e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>tfidf_5</td>\n",
       "      <td>3.124873e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>366</th>\n",
       "      <td>tfidf_366</td>\n",
       "      <td>2.980227e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>73</th>\n",
       "      <td>tfidf_73</td>\n",
       "      <td>2.967993e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>tfidf_96</td>\n",
       "      <td>2.841265e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>tfidf_37</td>\n",
       "      <td>2.826482e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>119</th>\n",
       "      <td>tfidf_119</td>\n",
       "      <td>2.757345e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>361</th>\n",
       "      <td>tfidf_361</td>\n",
       "      <td>2.710959e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>400</th>\n",
       "      <td>energetic</td>\n",
       "      <td>2.707611e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>362</th>\n",
       "      <td>tfidf_362</td>\n",
       "      <td>2.705080e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>415</th>\n",
       "      <td>sleepy</td>\n",
       "      <td>2.698996e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>173</th>\n",
       "      <td>tfidf_173</td>\n",
       "      <td>2.657516e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>456</th>\n",
       "      <td>sage</td>\n",
       "      <td>2.619304e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>211</th>\n",
       "      <td>tfidf_211</td>\n",
       "      <td>2.616096e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>tfidf_2</td>\n",
       "      <td>2.560284e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>407</th>\n",
       "      <td>happy</td>\n",
       "      <td>2.559515e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>413</th>\n",
       "      <td>relaxed</td>\n",
       "      <td>2.556718e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>230</th>\n",
       "      <td>tfidf_230</td>\n",
       "      <td>2.530255e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>123</th>\n",
       "      <td>tfidf_123</td>\n",
       "      <td>2.495155e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>357</th>\n",
       "      <td>tfidf_357</td>\n",
       "      <td>2.485868e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>tfidf_43</td>\n",
       "      <td>2.483128e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>340</th>\n",
       "      <td>tfidf_340</td>\n",
       "      <td>2.458951e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>144</th>\n",
       "      <td>tfidf_144</td>\n",
       "      <td>2.403113e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>tfidf_11</td>\n",
       "      <td>2.365520e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>420</th>\n",
       "      <td>uplifted</td>\n",
       "      <td>2.345097e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>424</th>\n",
       "      <td>berry</td>\n",
       "      <td>2.337181e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>tfidf_26</td>\n",
       "      <td>2.308241e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>94</th>\n",
       "      <td>tfidf_94</td>\n",
       "      <td>2.298279e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>tfidf_32</td>\n",
       "      <td>2.270608e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>258</th>\n",
       "      <td>tfidf_258</td>\n",
       "      <td>2.253066e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>162</th>\n",
       "      <td>tfidf_162</td>\n",
       "      <td>2.209463e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>120</th>\n",
       "      <td>tfidf_120</td>\n",
       "      <td>2.183215e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>138</th>\n",
       "      <td>tfidf_138</td>\n",
       "      <td>2.174246e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75</th>\n",
       "      <td>tfidf_75</td>\n",
       "      <td>2.171860e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>240</th>\n",
       "      <td>tfidf_240</td>\n",
       "      <td>2.163710e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>314</th>\n",
       "      <td>tfidf_314</td>\n",
       "      <td>2.140143e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>257</th>\n",
       "      <td>tfidf_257</td>\n",
       "      <td>2.128645e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>419</th>\n",
       "      <td>tingly</td>\n",
       "      <td>2.103834e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>409</th>\n",
       "      <td>hungry</td>\n",
       "      <td>2.023729e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>222</th>\n",
       "      <td>tfidf_222</td>\n",
       "      <td>2.022883e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>267</th>\n",
       "      <td>tfidf_267</td>\n",
       "      <td>1.875038e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>124</th>\n",
       "      <td>tfidf_124</td>\n",
       "      <td>1.872749e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>260</th>\n",
       "      <td>tfidf_260</td>\n",
       "      <td>1.861959e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>126</th>\n",
       "      <td>tfidf_126</td>\n",
       "      <td>1.841177e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>215</th>\n",
       "      <td>tfidf_215</td>\n",
       "      <td>1.815959e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>303</th>\n",
       "      <td>tfidf_303</td>\n",
       "      <td>1.809373e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>130</th>\n",
       "      <td>tfidf_130</td>\n",
       "      <td>1.786140e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>tfidf_46</td>\n",
       "      <td>1.781080e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>tfidf_10</td>\n",
       "      <td>1.770708e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>342</th>\n",
       "      <td>tfidf_342</td>\n",
       "      <td>1.751120e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>237</th>\n",
       "      <td>tfidf_237</td>\n",
       "      <td>1.723749e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>382</th>\n",
       "      <td>tfidf_382</td>\n",
       "      <td>1.721062e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>378</th>\n",
       "      <td>tfidf_378</td>\n",
       "      <td>1.720020e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>203</th>\n",
       "      <td>tfidf_203</td>\n",
       "      <td>1.685016e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>343</th>\n",
       "      <td>tfidf_343</td>\n",
       "      <td>1.684649e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>163</th>\n",
       "      <td>tfidf_163</td>\n",
       "      <td>1.641318e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>374</th>\n",
       "      <td>tfidf_374</td>\n",
       "      <td>1.632618e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>460</th>\n",
       "      <td>sweet</td>\n",
       "      <td>1.628095e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>466</th>\n",
       "      <td>vanilla</td>\n",
       "      <td>1.607790e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>283</th>\n",
       "      <td>tfidf_283</td>\n",
       "      <td>1.602943e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>338</th>\n",
       "      <td>tfidf_338</td>\n",
       "      <td>1.582762e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>418</th>\n",
       "      <td>talkative</td>\n",
       "      <td>1.582171e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>348</th>\n",
       "      <td>tfidf_348</td>\n",
       "      <td>1.552105e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>454</th>\n",
       "      <td>pungent</td>\n",
       "      <td>1.542234e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>381</th>\n",
       "      <td>tfidf_381</td>\n",
       "      <td>1.530148e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>341</th>\n",
       "      <td>tfidf_341</td>\n",
       "      <td>1.527007e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>350</th>\n",
       "      <td>tfidf_350</td>\n",
       "      <td>1.489900e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>184</th>\n",
       "      <td>tfidf_184</td>\n",
       "      <td>1.479116e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>270</th>\n",
       "      <td>tfidf_270</td>\n",
       "      <td>1.478816e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>178</th>\n",
       "      <td>tfidf_178</td>\n",
       "      <td>1.478787e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>367</th>\n",
       "      <td>tfidf_367</td>\n",
       "      <td>1.473224e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>104</th>\n",
       "      <td>tfidf_104</td>\n",
       "      <td>1.461243e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>217</th>\n",
       "      <td>tfidf_217</td>\n",
       "      <td>1.461155e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>231</th>\n",
       "      <td>tfidf_231</td>\n",
       "      <td>1.448300e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>347</th>\n",
       "      <td>tfidf_347</td>\n",
       "      <td>1.419812e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>139</th>\n",
       "      <td>tfidf_139</td>\n",
       "      <td>1.413392e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>376</th>\n",
       "      <td>tfidf_376</td>\n",
       "      <td>1.396228e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>91</th>\n",
       "      <td>tfidf_91</td>\n",
       "      <td>1.392891e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>445</th>\n",
       "      <td>mint</td>\n",
       "      <td>1.368818e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>90</th>\n",
       "      <td>tfidf_90</td>\n",
       "      <td>1.364698e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>107</th>\n",
       "      <td>tfidf_107</td>\n",
       "      <td>1.311932e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>136</th>\n",
       "      <td>tfidf_136</td>\n",
       "      <td>1.310880e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>264</th>\n",
       "      <td>tfidf_264</td>\n",
       "      <td>1.308757e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>tfidf_28</td>\n",
       "      <td>1.305045e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54</th>\n",
       "      <td>tfidf_54</td>\n",
       "      <td>1.300491e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>tfidf_3</td>\n",
       "      <td>1.291291e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>259</th>\n",
       "      <td>tfidf_259</td>\n",
       "      <td>1.279059e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>tfidf_19</td>\n",
       "      <td>1.275336e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>153</th>\n",
       "      <td>tfidf_153</td>\n",
       "      <td>1.268296e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>79</th>\n",
       "      <td>tfidf_79</td>\n",
       "      <td>1.257717e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>305</th>\n",
       "      <td>tfidf_305</td>\n",
       "      <td>1.236294e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>321</th>\n",
       "      <td>tfidf_321</td>\n",
       "      <td>1.233882e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>325</th>\n",
       "      <td>tfidf_325</td>\n",
       "      <td>1.230703e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>190</th>\n",
       "      <td>tfidf_190</td>\n",
       "      <td>1.223580e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>198</th>\n",
       "      <td>tfidf_198</td>\n",
       "      <td>1.220861e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>360</th>\n",
       "      <td>tfidf_360</td>\n",
       "      <td>1.213372e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>318</th>\n",
       "      <td>tfidf_318</td>\n",
       "      <td>1.205794e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>tfidf_34</td>\n",
       "      <td>1.200935e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>152</th>\n",
       "      <td>tfidf_152</td>\n",
       "      <td>1.195067e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>166</th>\n",
       "      <td>tfidf_166</td>\n",
       "      <td>1.169701e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>183</th>\n",
       "      <td>tfidf_183</td>\n",
       "      <td>1.168572e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>151</th>\n",
       "      <td>tfidf_151</td>\n",
       "      <td>1.162352e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>tfidf_20</td>\n",
       "      <td>1.154771e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>287</th>\n",
       "      <td>tfidf_287</td>\n",
       "      <td>1.153397e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>393</th>\n",
       "      <td>aroused</td>\n",
       "      <td>1.140317e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>132</th>\n",
       "      <td>tfidf_132</td>\n",
       "      <td>1.125626e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>205</th>\n",
       "      <td>tfidf_205</td>\n",
       "      <td>1.121919e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>61</th>\n",
       "      <td>tfidf_61</td>\n",
       "      <td>1.111978e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>206</th>\n",
       "      <td>tfidf_206</td>\n",
       "      <td>1.106877e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>86</th>\n",
       "      <td>tfidf_86</td>\n",
       "      <td>1.095219e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>105</th>\n",
       "      <td>tfidf_105</td>\n",
       "      <td>1.086913e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>398</th>\n",
       "      <td>dry eyes</td>\n",
       "      <td>1.085941e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>428</th>\n",
       "      <td>cheese</td>\n",
       "      <td>1.076654e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>200</th>\n",
       "      <td>tfidf_200</td>\n",
       "      <td>1.073287e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>188</th>\n",
       "      <td>tfidf_188</td>\n",
       "      <td>1.060022e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>371</th>\n",
       "      <td>tfidf_371</td>\n",
       "      <td>1.055464e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>tfidf_48</td>\n",
       "      <td>1.052401e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>103</th>\n",
       "      <td>tfidf_103</td>\n",
       "      <td>1.022607e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>274</th>\n",
       "      <td>tfidf_274</td>\n",
       "      <td>1.021312e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>tfidf_97</td>\n",
       "      <td>1.018186e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>286</th>\n",
       "      <td>tfidf_286</td>\n",
       "      <td>1.015092e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>172</th>\n",
       "      <td>tfidf_172</td>\n",
       "      <td>1.007012e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>tfidf_49</td>\n",
       "      <td>1.001170e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>85</th>\n",
       "      <td>tfidf_85</td>\n",
       "      <td>9.823051e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>147</th>\n",
       "      <td>tfidf_147</td>\n",
       "      <td>9.730590e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>129</th>\n",
       "      <td>tfidf_129</td>\n",
       "      <td>9.623306e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>tfidf_21</td>\n",
       "      <td>9.606318e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>291</th>\n",
       "      <td>tfidf_291</td>\n",
       "      <td>9.515153e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>354</th>\n",
       "      <td>tfidf_354</td>\n",
       "      <td>9.462030e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>tfidf_98</td>\n",
       "      <td>9.410028e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>278</th>\n",
       "      <td>tfidf_278</td>\n",
       "      <td>9.330648e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>282</th>\n",
       "      <td>tfidf_282</td>\n",
       "      <td>9.191246e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>148</th>\n",
       "      <td>tfidf_148</td>\n",
       "      <td>9.157839e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>175</th>\n",
       "      <td>tfidf_175</td>\n",
       "      <td>9.016800e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>451</th>\n",
       "      <td>pine</td>\n",
       "      <td>8.997904e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>135</th>\n",
       "      <td>tfidf_135</td>\n",
       "      <td>8.969139e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>157</th>\n",
       "      <td>tfidf_157</td>\n",
       "      <td>8.948802e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>219</th>\n",
       "      <td>tfidf_219</td>\n",
       "      <td>8.854560e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>442</th>\n",
       "      <td>lime</td>\n",
       "      <td>8.788897e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>194</th>\n",
       "      <td>tfidf_194</td>\n",
       "      <td>8.721170e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>154</th>\n",
       "      <td>tfidf_154</td>\n",
       "      <td>8.714726e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>146</th>\n",
       "      <td>tfidf_146</td>\n",
       "      <td>8.589480e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>164</th>\n",
       "      <td>tfidf_164</td>\n",
       "      <td>8.563744e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>289</th>\n",
       "      <td>tfidf_289</td>\n",
       "      <td>8.529222e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>80</th>\n",
       "      <td>tfidf_80</td>\n",
       "      <td>8.497598e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>408</th>\n",
       "      <td>headache</td>\n",
       "      <td>8.486063e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>269</th>\n",
       "      <td>tfidf_269</td>\n",
       "      <td>8.468803e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>363</th>\n",
       "      <td>tfidf_363</td>\n",
       "      <td>8.377868e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>tfidf_45</td>\n",
       "      <td>8.273861e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>273</th>\n",
       "      <td>tfidf_273</td>\n",
       "      <td>8.235656e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>221</th>\n",
       "      <td>tfidf_221</td>\n",
       "      <td>8.220118e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>64</th>\n",
       "      <td>tfidf_64</td>\n",
       "      <td>8.209959e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>111</th>\n",
       "      <td>tfidf_111</td>\n",
       "      <td>8.188126e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>56</th>\n",
       "      <td>tfidf_56</td>\n",
       "      <td>8.187968e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53</th>\n",
       "      <td>tfidf_53</td>\n",
       "      <td>8.109691e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>272</th>\n",
       "      <td>tfidf_272</td>\n",
       "      <td>8.102629e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>383</th>\n",
       "      <td>tfidf_383</td>\n",
       "      <td>8.052657e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>170</th>\n",
       "      <td>tfidf_170</td>\n",
       "      <td>8.007115e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>397</th>\n",
       "      <td>dizzy</td>\n",
       "      <td>7.995144e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>280</th>\n",
       "      <td>tfidf_280</td>\n",
       "      <td>7.988256e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>193</th>\n",
       "      <td>tfidf_193</td>\n",
       "      <td>7.908202e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>tfidf_99</td>\n",
       "      <td>7.898150e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>380</th>\n",
       "      <td>tfidf_380</td>\n",
       "      <td>7.783989e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>248</th>\n",
       "      <td>tfidf_248</td>\n",
       "      <td>7.738084e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>125</th>\n",
       "      <td>tfidf_125</td>\n",
       "      <td>7.734099e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>tfidf_17</td>\n",
       "      <td>7.722731e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>386</th>\n",
       "      <td>tfidf_386</td>\n",
       "      <td>7.693513e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>468</th>\n",
       "      <td>woody</td>\n",
       "      <td>7.619451e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>tfidf_39</td>\n",
       "      <td>7.574695e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>tfidf_1</td>\n",
       "      <td>7.521473e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>255</th>\n",
       "      <td>tfidf_255</td>\n",
       "      <td>7.423782e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>228</th>\n",
       "      <td>tfidf_228</td>\n",
       "      <td>7.412211e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>71</th>\n",
       "      <td>tfidf_71</td>\n",
       "      <td>7.368539e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>tfidf_16</td>\n",
       "      <td>7.250803e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>262</th>\n",
       "      <td>tfidf_262</td>\n",
       "      <td>7.246141e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>377</th>\n",
       "      <td>tfidf_377</td>\n",
       "      <td>7.236278e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>tfidf_14</td>\n",
       "      <td>7.221192e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>110</th>\n",
       "      <td>tfidf_110</td>\n",
       "      <td>7.197252e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>353</th>\n",
       "      <td>tfidf_353</td>\n",
       "      <td>7.105887e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>159</th>\n",
       "      <td>tfidf_159</td>\n",
       "      <td>7.082528e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>tfidf_9</td>\n",
       "      <td>7.026187e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>373</th>\n",
       "      <td>tfidf_373</td>\n",
       "      <td>6.904115e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>181</th>\n",
       "      <td>tfidf_181</td>\n",
       "      <td>6.872377e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>435</th>\n",
       "      <td>flowery</td>\n",
       "      <td>6.821499e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>311</th>\n",
       "      <td>tfidf_311</td>\n",
       "      <td>6.795466e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>112</th>\n",
       "      <td>tfidf_112</td>\n",
       "      <td>6.786285e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>142</th>\n",
       "      <td>tfidf_142</td>\n",
       "      <td>6.765134e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>263</th>\n",
       "      <td>tfidf_263</td>\n",
       "      <td>6.752637e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>336</th>\n",
       "      <td>tfidf_336</td>\n",
       "      <td>6.734786e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>143</th>\n",
       "      <td>tfidf_143</td>\n",
       "      <td>6.677030e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>133</th>\n",
       "      <td>tfidf_133</td>\n",
       "      <td>6.664784e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>369</th>\n",
       "      <td>tfidf_369</td>\n",
       "      <td>6.660512e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>62</th>\n",
       "      <td>tfidf_62</td>\n",
       "      <td>6.631637e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>271</th>\n",
       "      <td>tfidf_271</td>\n",
       "      <td>6.593277e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>117</th>\n",
       "      <td>tfidf_117</td>\n",
       "      <td>6.544643e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>150</th>\n",
       "      <td>tfidf_150</td>\n",
       "      <td>6.460012e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>304</th>\n",
       "      <td>tfidf_304</td>\n",
       "      <td>6.429621e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>tfidf_22</td>\n",
       "      <td>6.404397e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>277</th>\n",
       "      <td>tfidf_277</td>\n",
       "      <td>6.389510e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>58</th>\n",
       "      <td>tfidf_58</td>\n",
       "      <td>6.325406e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>351</th>\n",
       "      <td>tfidf_351</td>\n",
       "      <td>6.308084e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>137</th>\n",
       "      <td>tfidf_137</td>\n",
       "      <td>6.245486e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>82</th>\n",
       "      <td>tfidf_82</td>\n",
       "      <td>6.221851e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>298</th>\n",
       "      <td>tfidf_298</td>\n",
       "      <td>6.217195e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>87</th>\n",
       "      <td>tfidf_87</td>\n",
       "      <td>6.190564e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>tfidf_4</td>\n",
       "      <td>6.186378e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>233</th>\n",
       "      <td>tfidf_233</td>\n",
       "      <td>6.176950e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>88</th>\n",
       "      <td>tfidf_88</td>\n",
       "      <td>6.122477e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>385</th>\n",
       "      <td>tfidf_385</td>\n",
       "      <td>6.115950e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>100</th>\n",
       "      <td>tfidf_100</td>\n",
       "      <td>6.110499e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>223</th>\n",
       "      <td>tfidf_223</td>\n",
       "      <td>6.097605e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>355</th>\n",
       "      <td>tfidf_355</td>\n",
       "      <td>6.074877e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>69</th>\n",
       "      <td>tfidf_69</td>\n",
       "      <td>6.066562e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>243</th>\n",
       "      <td>tfidf_243</td>\n",
       "      <td>6.026957e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>131</th>\n",
       "      <td>tfidf_131</td>\n",
       "      <td>6.026681e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>331</th>\n",
       "      <td>tfidf_331</td>\n",
       "      <td>6.026145e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>326</th>\n",
       "      <td>tfidf_326</td>\n",
       "      <td>5.998244e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>241</th>\n",
       "      <td>tfidf_241</td>\n",
       "      <td>5.837926e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51</th>\n",
       "      <td>tfidf_51</td>\n",
       "      <td>5.747415e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>229</th>\n",
       "      <td>tfidf_229</td>\n",
       "      <td>5.725061e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>tfidf_0</td>\n",
       "      <td>5.719354e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>307</th>\n",
       "      <td>tfidf_307</td>\n",
       "      <td>5.661959e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>208</th>\n",
       "      <td>tfidf_208</td>\n",
       "      <td>5.639122e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>70</th>\n",
       "      <td>tfidf_70</td>\n",
       "      <td>5.627022e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>81</th>\n",
       "      <td>tfidf_81</td>\n",
       "      <td>5.608634e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>tfidf_6</td>\n",
       "      <td>5.598728e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>202</th>\n",
       "      <td>tfidf_202</td>\n",
       "      <td>5.499627e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>294</th>\n",
       "      <td>tfidf_294</td>\n",
       "      <td>5.474968e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>392</th>\n",
       "      <td>anxious</td>\n",
       "      <td>5.456071e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>265</th>\n",
       "      <td>tfidf_265</td>\n",
       "      <td>5.305691e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>108</th>\n",
       "      <td>tfidf_108</td>\n",
       "      <td>5.237346e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>412</th>\n",
       "      <td>paranoid</td>\n",
       "      <td>5.170756e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>77</th>\n",
       "      <td>tfidf_77</td>\n",
       "      <td>5.126571e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>465</th>\n",
       "      <td>tropical</td>\n",
       "      <td>5.123884e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>313</th>\n",
       "      <td>tfidf_313</td>\n",
       "      <td>5.114425e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>254</th>\n",
       "      <td>tfidf_254</td>\n",
       "      <td>5.090481e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>266</th>\n",
       "      <td>tfidf_266</td>\n",
       "      <td>5.063111e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>387</th>\n",
       "      <td>tfidf_387</td>\n",
       "      <td>5.062696e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>72</th>\n",
       "      <td>tfidf_72</td>\n",
       "      <td>4.930936e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>335</th>\n",
       "      <td>tfidf_335</td>\n",
       "      <td>4.913720e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>436</th>\n",
       "      <td>fruit</td>\n",
       "      <td>4.911864e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>225</th>\n",
       "      <td>tfidf_225</td>\n",
       "      <td>4.857254e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>268</th>\n",
       "      <td>tfidf_268</td>\n",
       "      <td>4.852558e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>204</th>\n",
       "      <td>tfidf_204</td>\n",
       "      <td>4.841875e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>106</th>\n",
       "      <td>tfidf_106</td>\n",
       "      <td>4.822127e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>65</th>\n",
       "      <td>tfidf_65</td>\n",
       "      <td>4.805737e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>246</th>\n",
       "      <td>tfidf_246</td>\n",
       "      <td>4.757229e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>tfidf_18</td>\n",
       "      <td>4.753309e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>275</th>\n",
       "      <td>tfidf_275</td>\n",
       "      <td>4.747732e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>224</th>\n",
       "      <td>tfidf_224</td>\n",
       "      <td>4.716966e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>57</th>\n",
       "      <td>tfidf_57</td>\n",
       "      <td>4.692050e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>333</th>\n",
       "      <td>tfidf_333</td>\n",
       "      <td>4.658132e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>349</th>\n",
       "      <td>tfidf_349</td>\n",
       "      <td>4.630492e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>220</th>\n",
       "      <td>tfidf_220</td>\n",
       "      <td>4.596341e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>235</th>\n",
       "      <td>tfidf_235</td>\n",
       "      <td>4.580494e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>109</th>\n",
       "      <td>tfidf_109</td>\n",
       "      <td>4.553656e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>236</th>\n",
       "      <td>tfidf_236</td>\n",
       "      <td>4.536904e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>251</th>\n",
       "      <td>tfidf_251</td>\n",
       "      <td>4.485550e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>83</th>\n",
       "      <td>tfidf_83</td>\n",
       "      <td>4.474469e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>327</th>\n",
       "      <td>tfidf_327</td>\n",
       "      <td>4.454053e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>186</th>\n",
       "      <td>tfidf_186</td>\n",
       "      <td>4.449616e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>tfidf_44</td>\n",
       "      <td>4.396859e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>288</th>\n",
       "      <td>tfidf_288</td>\n",
       "      <td>4.358736e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>tfidf_29</td>\n",
       "      <td>4.328038e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>299</th>\n",
       "      <td>tfidf_299</td>\n",
       "      <td>4.278531e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>356</th>\n",
       "      <td>tfidf_356</td>\n",
       "      <td>4.270299e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>458</th>\n",
       "      <td>spicy/herbal</td>\n",
       "      <td>4.264255e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>344</th>\n",
       "      <td>tfidf_344</td>\n",
       "      <td>4.228614e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>249</th>\n",
       "      <td>tfidf_249</td>\n",
       "      <td>4.200350e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>375</th>\n",
       "      <td>tfidf_375</td>\n",
       "      <td>4.194308e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>84</th>\n",
       "      <td>tfidf_84</td>\n",
       "      <td>4.091399e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>368</th>\n",
       "      <td>tfidf_368</td>\n",
       "      <td>4.085251e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>443</th>\n",
       "      <td>mango</td>\n",
       "      <td>4.082927e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>372</th>\n",
       "      <td>tfidf_372</td>\n",
       "      <td>4.064506e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>292</th>\n",
       "      <td>tfidf_292</td>\n",
       "      <td>4.037178e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>tfidf_33</td>\n",
       "      <td>4.033277e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>276</th>\n",
       "      <td>tfidf_276</td>\n",
       "      <td>3.995724e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>323</th>\n",
       "      <td>tfidf_323</td>\n",
       "      <td>3.972489e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>296</th>\n",
       "      <td>tfidf_296</td>\n",
       "      <td>3.947463e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>370</th>\n",
       "      <td>tfidf_370</td>\n",
       "      <td>3.939247e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>122</th>\n",
       "      <td>tfidf_122</td>\n",
       "      <td>3.876744e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>116</th>\n",
       "      <td>tfidf_116</td>\n",
       "      <td>3.855142e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>310</th>\n",
       "      <td>tfidf_310</td>\n",
       "      <td>3.817366e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>160</th>\n",
       "      <td>tfidf_160</td>\n",
       "      <td>3.772223e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>238</th>\n",
       "      <td>tfidf_238</td>\n",
       "      <td>3.737234e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>317</th>\n",
       "      <td>tfidf_317</td>\n",
       "      <td>3.726775e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>185</th>\n",
       "      <td>tfidf_185</td>\n",
       "      <td>3.725562e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>155</th>\n",
       "      <td>tfidf_155</td>\n",
       "      <td>3.688229e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>102</th>\n",
       "      <td>tfidf_102</td>\n",
       "      <td>3.672659e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>232</th>\n",
       "      <td>tfidf_232</td>\n",
       "      <td>3.650489e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>364</th>\n",
       "      <td>tfidf_364</td>\n",
       "      <td>3.612885e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>421</th>\n",
       "      <td>ammonia</td>\n",
       "      <td>3.607854e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>334</th>\n",
       "      <td>tfidf_334</td>\n",
       "      <td>3.601296e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>176</th>\n",
       "      <td>tfidf_176</td>\n",
       "      <td>3.579265e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>171</th>\n",
       "      <td>tfidf_171</td>\n",
       "      <td>3.554907e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>179</th>\n",
       "      <td>tfidf_179</td>\n",
       "      <td>3.524860e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>tfidf_47</td>\n",
       "      <td>3.493677e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>tfidf_27</td>\n",
       "      <td>3.486201e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>tfidf_23</td>\n",
       "      <td>3.468623e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>301</th>\n",
       "      <td>tfidf_301</td>\n",
       "      <td>3.427086e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>tfidf_41</td>\n",
       "      <td>3.378899e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>358</th>\n",
       "      <td>tfidf_358</td>\n",
       "      <td>3.373951e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>209</th>\n",
       "      <td>tfidf_209</td>\n",
       "      <td>3.350037e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>212</th>\n",
       "      <td>tfidf_212</td>\n",
       "      <td>3.333557e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>339</th>\n",
       "      <td>tfidf_339</td>\n",
       "      <td>3.277901e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>302</th>\n",
       "      <td>tfidf_302</td>\n",
       "      <td>3.228229e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52</th>\n",
       "      <td>tfidf_52</td>\n",
       "      <td>3.168330e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>140</th>\n",
       "      <td>tfidf_140</td>\n",
       "      <td>3.157688e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>322</th>\n",
       "      <td>tfidf_322</td>\n",
       "      <td>3.155230e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>319</th>\n",
       "      <td>tfidf_319</td>\n",
       "      <td>3.145825e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>180</th>\n",
       "      <td>tfidf_180</td>\n",
       "      <td>3.108803e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>113</th>\n",
       "      <td>tfidf_113</td>\n",
       "      <td>3.099103e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>tfidf_40</td>\n",
       "      <td>3.073770e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>tfidf_42</td>\n",
       "      <td>3.068706e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>tfidf_31</td>\n",
       "      <td>3.036914e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>328</th>\n",
       "      <td>tfidf_328</td>\n",
       "      <td>3.028489e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>216</th>\n",
       "      <td>tfidf_216</td>\n",
       "      <td>3.019284e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>384</th>\n",
       "      <td>tfidf_384</td>\n",
       "      <td>3.018373e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>252</th>\n",
       "      <td>tfidf_252</td>\n",
       "      <td>2.985181e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>295</th>\n",
       "      <td>tfidf_295</td>\n",
       "      <td>2.981534e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>352</th>\n",
       "      <td>tfidf_352</td>\n",
       "      <td>2.963958e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>227</th>\n",
       "      <td>tfidf_227</td>\n",
       "      <td>2.957743e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>92</th>\n",
       "      <td>tfidf_92</td>\n",
       "      <td>2.948081e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>192</th>\n",
       "      <td>tfidf_192</td>\n",
       "      <td>2.935691e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>234</th>\n",
       "      <td>tfidf_234</td>\n",
       "      <td>2.924540e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>tfidf_95</td>\n",
       "      <td>2.908771e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>316</th>\n",
       "      <td>tfidf_316</td>\n",
       "      <td>2.873934e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>tfidf_8</td>\n",
       "      <td>2.861328e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>191</th>\n",
       "      <td>tfidf_191</td>\n",
       "      <td>2.825593e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>455</th>\n",
       "      <td>rose</td>\n",
       "      <td>2.783265e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>182</th>\n",
       "      <td>tfidf_182</td>\n",
       "      <td>2.756969e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>306</th>\n",
       "      <td>tfidf_306</td>\n",
       "      <td>2.717348e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>177</th>\n",
       "      <td>tfidf_177</td>\n",
       "      <td>2.667368e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>187</th>\n",
       "      <td>tfidf_187</td>\n",
       "      <td>2.661541e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>67</th>\n",
       "      <td>tfidf_67</td>\n",
       "      <td>2.653813e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>tfidf_24</td>\n",
       "      <td>2.605686e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>226</th>\n",
       "      <td>tfidf_226</td>\n",
       "      <td>2.604394e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>214</th>\n",
       "      <td>tfidf_214</td>\n",
       "      <td>2.600843e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>300</th>\n",
       "      <td>tfidf_300</td>\n",
       "      <td>2.580932e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>430</th>\n",
       "      <td>chestnut</td>\n",
       "      <td>2.575190e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>76</th>\n",
       "      <td>tfidf_76</td>\n",
       "      <td>2.553749e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>63</th>\n",
       "      <td>tfidf_63</td>\n",
       "      <td>2.534789e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>tfidf_12</td>\n",
       "      <td>2.509737e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>315</th>\n",
       "      <td>tfidf_315</td>\n",
       "      <td>2.500888e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>55</th>\n",
       "      <td>tfidf_55</td>\n",
       "      <td>2.485292e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>118</th>\n",
       "      <td>tfidf_118</td>\n",
       "      <td>2.484497e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>432</th>\n",
       "      <td>coffee</td>\n",
       "      <td>2.391186e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>196</th>\n",
       "      <td>tfidf_196</td>\n",
       "      <td>2.355547e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>156</th>\n",
       "      <td>tfidf_156</td>\n",
       "      <td>2.354628e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>308</th>\n",
       "      <td>tfidf_308</td>\n",
       "      <td>2.346568e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>66</th>\n",
       "      <td>tfidf_66</td>\n",
       "      <td>2.294154e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>115</th>\n",
       "      <td>tfidf_115</td>\n",
       "      <td>2.278695e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>462</th>\n",
       "      <td>tea</td>\n",
       "      <td>2.242697e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>201</th>\n",
       "      <td>tfidf_201</td>\n",
       "      <td>2.242471e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>290</th>\n",
       "      <td>tfidf_290</td>\n",
       "      <td>2.198760e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>169</th>\n",
       "      <td>tfidf_169</td>\n",
       "      <td>2.195554e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>332</th>\n",
       "      <td>tfidf_332</td>\n",
       "      <td>2.169385e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>365</th>\n",
       "      <td>tfidf_365</td>\n",
       "      <td>2.166050e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>346</th>\n",
       "      <td>tfidf_346</td>\n",
       "      <td>2.157644e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>127</th>\n",
       "      <td>tfidf_127</td>\n",
       "      <td>2.109588e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>68</th>\n",
       "      <td>tfidf_68</td>\n",
       "      <td>2.103680e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>444</th>\n",
       "      <td>menthol</td>\n",
       "      <td>2.080134e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>tfidf_15</td>\n",
       "      <td>2.058098e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>242</th>\n",
       "      <td>tfidf_242</td>\n",
       "      <td>2.040006e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>213</th>\n",
       "      <td>tfidf_213</td>\n",
       "      <td>1.965500e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>359</th>\n",
       "      <td>tfidf_359</td>\n",
       "      <td>1.960081e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>448</th>\n",
       "      <td>peach</td>\n",
       "      <td>1.907717e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>279</th>\n",
       "      <td>tfidf_279</td>\n",
       "      <td>1.886101e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>244</th>\n",
       "      <td>tfidf_244</td>\n",
       "      <td>1.880105e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50</th>\n",
       "      <td>tfidf_50</td>\n",
       "      <td>1.863309e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59</th>\n",
       "      <td>tfidf_59</td>\n",
       "      <td>1.836629e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>197</th>\n",
       "      <td>tfidf_197</td>\n",
       "      <td>1.816967e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>464</th>\n",
       "      <td>tree</td>\n",
       "      <td>1.808052e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>165</th>\n",
       "      <td>tfidf_165</td>\n",
       "      <td>1.797430e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>114</th>\n",
       "      <td>tfidf_114</td>\n",
       "      <td>1.756575e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>324</th>\n",
       "      <td>tfidf_324</td>\n",
       "      <td>1.752082e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>261</th>\n",
       "      <td>tfidf_261</td>\n",
       "      <td>1.730431e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>450</th>\n",
       "      <td>pepper</td>\n",
       "      <td>1.703667e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>330</th>\n",
       "      <td>tfidf_330</td>\n",
       "      <td>1.632247e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>446</th>\n",
       "      <td>nutty</td>\n",
       "      <td>1.630789e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>256</th>\n",
       "      <td>tfidf_256</td>\n",
       "      <td>1.603968e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>tfidf_38</td>\n",
       "      <td>1.603444e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>218</th>\n",
       "      <td>tfidf_218</td>\n",
       "      <td>1.584423e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>tfidf_25</td>\n",
       "      <td>1.575324e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>459</th>\n",
       "      <td>strawberry</td>\n",
       "      <td>1.572067e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>195</th>\n",
       "      <td>tfidf_195</td>\n",
       "      <td>1.554430e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>tfidf_35</td>\n",
       "      <td>1.551291e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>439</th>\n",
       "      <td>honey</td>\n",
       "      <td>1.521728e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>134</th>\n",
       "      <td>tfidf_134</td>\n",
       "      <td>1.460612e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>60</th>\n",
       "      <td>tfidf_60</td>\n",
       "      <td>1.450848e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>tfidf_13</td>\n",
       "      <td>1.377022e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>89</th>\n",
       "      <td>tfidf_89</td>\n",
       "      <td>1.334318e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>174</th>\n",
       "      <td>tfidf_174</td>\n",
       "      <td>1.250101e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>293</th>\n",
       "      <td>tfidf_293</td>\n",
       "      <td>1.229717e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>449</th>\n",
       "      <td>pear</td>\n",
       "      <td>1.208057e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>284</th>\n",
       "      <td>tfidf_284</td>\n",
       "      <td>1.124416e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>429</th>\n",
       "      <td>chemical</td>\n",
       "      <td>1.104422e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>452</th>\n",
       "      <td>pineapple</td>\n",
       "      <td>1.093674e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>379</th>\n",
       "      <td>tfidf_379</td>\n",
       "      <td>9.732620e-05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>438</th>\n",
       "      <td>grapefruit</td>\n",
       "      <td>8.599476e-05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>461</th>\n",
       "      <td>tar</td>\n",
       "      <td>8.050076e-05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>463</th>\n",
       "      <td>tobacco</td>\n",
       "      <td>7.406212e-05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>440</th>\n",
       "      <td>lavender</td>\n",
       "      <td>7.227291e-05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>250</th>\n",
       "      <td>tfidf_250</td>\n",
       "      <td>6.098705e-05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>467</th>\n",
       "      <td>violet</td>\n",
       "      <td>5.883638e-05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>453</th>\n",
       "      <td>plum</td>\n",
       "      <td>5.485279e-05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>tfidf_36</td>\n",
       "      <td>5.475444e-05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>427</th>\n",
       "      <td>butter</td>\n",
       "      <td>5.411046e-05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>425</th>\n",
       "      <td>blue cheese</td>\n",
       "      <td>3.324199e-05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>391</th>\n",
       "      <td>anxiety</td>\n",
       "      <td>3.275466e-05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>410</th>\n",
       "      <td>migraines</td>\n",
       "      <td>3.252261e-05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>423</th>\n",
       "      <td>apricot</td>\n",
       "      <td>2.935471e-05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>396</th>\n",
       "      <td>depression</td>\n",
       "      <td>2.754968e-05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>422</th>\n",
       "      <td>apple</td>\n",
       "      <td>2.183774e-05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>404</th>\n",
       "      <td>fatigue</td>\n",
       "      <td>3.040739e-08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>414</th>\n",
       "      <td>seizures</td>\n",
       "      <td>3.911011e-10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>394</th>\n",
       "      <td>arthritis</td>\n",
       "      <td>3.028354e-10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>411</th>\n",
       "      <td>pain</td>\n",
       "      <td>1.456504e-10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>401</th>\n",
       "      <td>epilepsy</td>\n",
       "      <td>1.415702e-10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>416</th>\n",
       "      <td>spasticity</td>\n",
       "      <td>0.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>389</th>\n",
       "      <td>indica</td>\n",
       "      <td>0.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>417</th>\n",
       "      <td>stress</td>\n",
       "      <td>0.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>403</th>\n",
       "      <td>eye pressure</td>\n",
       "      <td>0.000000e+00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         features         score\n",
       "390        sativa  3.532612e-01\n",
       "388        hybrid  3.872629e-02\n",
       "441         lemon  2.731643e-02\n",
       "426     blueberry  1.618039e-02\n",
       "168     tfidf_168  1.020139e-02\n",
       "329     tfidf_329  8.971756e-03\n",
       "405       focused  8.161648e-03\n",
       "434        earthy  8.031679e-03\n",
       "141     tfidf_141  7.971940e-03\n",
       "149     tfidf_149  7.801520e-03\n",
       "345     tfidf_345  7.603370e-03\n",
       "406        giggly  7.554087e-03\n",
       "433        diesel  7.444707e-03\n",
       "145     tfidf_145  7.242008e-03\n",
       "101     tfidf_101  7.003042e-03\n",
       "199     tfidf_199  6.292858e-03\n",
       "320     tfidf_320  6.242410e-03\n",
       "285     tfidf_285  5.654340e-03\n",
       "161     tfidf_161  5.155864e-03\n",
       "337     tfidf_337  5.062775e-03\n",
       "253     tfidf_253  4.721395e-03\n",
       "312     tfidf_312  4.698765e-03\n",
       "93       tfidf_93  4.648914e-03\n",
       "158     tfidf_158  4.622110e-03\n",
       "239     tfidf_239  4.516208e-03\n",
       "395      creative  4.340769e-03\n",
       "297     tfidf_297  4.268601e-03\n",
       "247     tfidf_247  4.235524e-03\n",
       "309     tfidf_309  4.230177e-03\n",
       "447        orange  4.200860e-03\n",
       "121     tfidf_121  4.101116e-03\n",
       "245     tfidf_245  4.019421e-03\n",
       "128     tfidf_128  3.982674e-03\n",
       "7         tfidf_7  3.978325e-03\n",
       "189     tfidf_189  3.807034e-03\n",
       "402      euphoric  3.731511e-03\n",
       "281     tfidf_281  3.663731e-03\n",
       "431        citrus  3.638310e-03\n",
       "167     tfidf_167  3.536833e-03\n",
       "30       tfidf_30  3.498166e-03\n",
       "78       tfidf_78  3.444414e-03\n",
       "207     tfidf_207  3.442978e-03\n",
       "74       tfidf_74  3.376286e-03\n",
       "437         grape  3.325421e-03\n",
       "399     dry mouth  3.270750e-03\n",
       "457         skunk  3.208146e-03\n",
       "210     tfidf_210  3.175185e-03\n",
       "5         tfidf_5  3.124873e-03\n",
       "366     tfidf_366  2.980227e-03\n",
       "73       tfidf_73  2.967993e-03\n",
       "96       tfidf_96  2.841265e-03\n",
       "37       tfidf_37  2.826482e-03\n",
       "119     tfidf_119  2.757345e-03\n",
       "361     tfidf_361  2.710959e-03\n",
       "400     energetic  2.707611e-03\n",
       "362     tfidf_362  2.705080e-03\n",
       "415        sleepy  2.698996e-03\n",
       "173     tfidf_173  2.657516e-03\n",
       "456          sage  2.619304e-03\n",
       "211     tfidf_211  2.616096e-03\n",
       "2         tfidf_2  2.560284e-03\n",
       "407         happy  2.559515e-03\n",
       "413       relaxed  2.556718e-03\n",
       "230     tfidf_230  2.530255e-03\n",
       "123     tfidf_123  2.495155e-03\n",
       "357     tfidf_357  2.485868e-03\n",
       "43       tfidf_43  2.483128e-03\n",
       "340     tfidf_340  2.458951e-03\n",
       "144     tfidf_144  2.403113e-03\n",
       "11       tfidf_11  2.365520e-03\n",
       "420      uplifted  2.345097e-03\n",
       "424         berry  2.337181e-03\n",
       "26       tfidf_26  2.308241e-03\n",
       "94       tfidf_94  2.298279e-03\n",
       "32       tfidf_32  2.270608e-03\n",
       "258     tfidf_258  2.253066e-03\n",
       "162     tfidf_162  2.209463e-03\n",
       "120     tfidf_120  2.183215e-03\n",
       "138     tfidf_138  2.174246e-03\n",
       "75       tfidf_75  2.171860e-03\n",
       "240     tfidf_240  2.163710e-03\n",
       "314     tfidf_314  2.140143e-03\n",
       "257     tfidf_257  2.128645e-03\n",
       "419        tingly  2.103834e-03\n",
       "409        hungry  2.023729e-03\n",
       "222     tfidf_222  2.022883e-03\n",
       "267     tfidf_267  1.875038e-03\n",
       "124     tfidf_124  1.872749e-03\n",
       "260     tfidf_260  1.861959e-03\n",
       "126     tfidf_126  1.841177e-03\n",
       "215     tfidf_215  1.815959e-03\n",
       "303     tfidf_303  1.809373e-03\n",
       "130     tfidf_130  1.786140e-03\n",
       "46       tfidf_46  1.781080e-03\n",
       "10       tfidf_10  1.770708e-03\n",
       "342     tfidf_342  1.751120e-03\n",
       "237     tfidf_237  1.723749e-03\n",
       "382     tfidf_382  1.721062e-03\n",
       "378     tfidf_378  1.720020e-03\n",
       "203     tfidf_203  1.685016e-03\n",
       "343     tfidf_343  1.684649e-03\n",
       "163     tfidf_163  1.641318e-03\n",
       "374     tfidf_374  1.632618e-03\n",
       "460         sweet  1.628095e-03\n",
       "466       vanilla  1.607790e-03\n",
       "283     tfidf_283  1.602943e-03\n",
       "338     tfidf_338  1.582762e-03\n",
       "418     talkative  1.582171e-03\n",
       "348     tfidf_348  1.552105e-03\n",
       "454       pungent  1.542234e-03\n",
       "381     tfidf_381  1.530148e-03\n",
       "341     tfidf_341  1.527007e-03\n",
       "350     tfidf_350  1.489900e-03\n",
       "184     tfidf_184  1.479116e-03\n",
       "270     tfidf_270  1.478816e-03\n",
       "178     tfidf_178  1.478787e-03\n",
       "367     tfidf_367  1.473224e-03\n",
       "104     tfidf_104  1.461243e-03\n",
       "217     tfidf_217  1.461155e-03\n",
       "231     tfidf_231  1.448300e-03\n",
       "347     tfidf_347  1.419812e-03\n",
       "139     tfidf_139  1.413392e-03\n",
       "376     tfidf_376  1.396228e-03\n",
       "91       tfidf_91  1.392891e-03\n",
       "445          mint  1.368818e-03\n",
       "90       tfidf_90  1.364698e-03\n",
       "107     tfidf_107  1.311932e-03\n",
       "136     tfidf_136  1.310880e-03\n",
       "264     tfidf_264  1.308757e-03\n",
       "28       tfidf_28  1.305045e-03\n",
       "54       tfidf_54  1.300491e-03\n",
       "3         tfidf_3  1.291291e-03\n",
       "259     tfidf_259  1.279059e-03\n",
       "19       tfidf_19  1.275336e-03\n",
       "153     tfidf_153  1.268296e-03\n",
       "79       tfidf_79  1.257717e-03\n",
       "305     tfidf_305  1.236294e-03\n",
       "321     tfidf_321  1.233882e-03\n",
       "325     tfidf_325  1.230703e-03\n",
       "190     tfidf_190  1.223580e-03\n",
       "198     tfidf_198  1.220861e-03\n",
       "360     tfidf_360  1.213372e-03\n",
       "318     tfidf_318  1.205794e-03\n",
       "34       tfidf_34  1.200935e-03\n",
       "152     tfidf_152  1.195067e-03\n",
       "166     tfidf_166  1.169701e-03\n",
       "183     tfidf_183  1.168572e-03\n",
       "151     tfidf_151  1.162352e-03\n",
       "20       tfidf_20  1.154771e-03\n",
       "287     tfidf_287  1.153397e-03\n",
       "393       aroused  1.140317e-03\n",
       "132     tfidf_132  1.125626e-03\n",
       "205     tfidf_205  1.121919e-03\n",
       "61       tfidf_61  1.111978e-03\n",
       "206     tfidf_206  1.106877e-03\n",
       "86       tfidf_86  1.095219e-03\n",
       "105     tfidf_105  1.086913e-03\n",
       "398      dry eyes  1.085941e-03\n",
       "428        cheese  1.076654e-03\n",
       "200     tfidf_200  1.073287e-03\n",
       "188     tfidf_188  1.060022e-03\n",
       "371     tfidf_371  1.055464e-03\n",
       "48       tfidf_48  1.052401e-03\n",
       "103     tfidf_103  1.022607e-03\n",
       "274     tfidf_274  1.021312e-03\n",
       "97       tfidf_97  1.018186e-03\n",
       "286     tfidf_286  1.015092e-03\n",
       "172     tfidf_172  1.007012e-03\n",
       "49       tfidf_49  1.001170e-03\n",
       "85       tfidf_85  9.823051e-04\n",
       "147     tfidf_147  9.730590e-04\n",
       "129     tfidf_129  9.623306e-04\n",
       "21       tfidf_21  9.606318e-04\n",
       "291     tfidf_291  9.515153e-04\n",
       "354     tfidf_354  9.462030e-04\n",
       "98       tfidf_98  9.410028e-04\n",
       "278     tfidf_278  9.330648e-04\n",
       "282     tfidf_282  9.191246e-04\n",
       "148     tfidf_148  9.157839e-04\n",
       "175     tfidf_175  9.016800e-04\n",
       "451          pine  8.997904e-04\n",
       "135     tfidf_135  8.969139e-04\n",
       "157     tfidf_157  8.948802e-04\n",
       "219     tfidf_219  8.854560e-04\n",
       "442          lime  8.788897e-04\n",
       "194     tfidf_194  8.721170e-04\n",
       "154     tfidf_154  8.714726e-04\n",
       "146     tfidf_146  8.589480e-04\n",
       "164     tfidf_164  8.563744e-04\n",
       "289     tfidf_289  8.529222e-04\n",
       "80       tfidf_80  8.497598e-04\n",
       "408      headache  8.486063e-04\n",
       "269     tfidf_269  8.468803e-04\n",
       "363     tfidf_363  8.377868e-04\n",
       "45       tfidf_45  8.273861e-04\n",
       "273     tfidf_273  8.235656e-04\n",
       "221     tfidf_221  8.220118e-04\n",
       "64       tfidf_64  8.209959e-04\n",
       "111     tfidf_111  8.188126e-04\n",
       "56       tfidf_56  8.187968e-04\n",
       "53       tfidf_53  8.109691e-04\n",
       "272     tfidf_272  8.102629e-04\n",
       "383     tfidf_383  8.052657e-04\n",
       "170     tfidf_170  8.007115e-04\n",
       "397         dizzy  7.995144e-04\n",
       "280     tfidf_280  7.988256e-04\n",
       "193     tfidf_193  7.908202e-04\n",
       "99       tfidf_99  7.898150e-04\n",
       "380     tfidf_380  7.783989e-04\n",
       "248     tfidf_248  7.738084e-04\n",
       "125     tfidf_125  7.734099e-04\n",
       "17       tfidf_17  7.722731e-04\n",
       "386     tfidf_386  7.693513e-04\n",
       "468         woody  7.619451e-04\n",
       "39       tfidf_39  7.574695e-04\n",
       "1         tfidf_1  7.521473e-04\n",
       "255     tfidf_255  7.423782e-04\n",
       "228     tfidf_228  7.412211e-04\n",
       "71       tfidf_71  7.368539e-04\n",
       "16       tfidf_16  7.250803e-04\n",
       "262     tfidf_262  7.246141e-04\n",
       "377     tfidf_377  7.236278e-04\n",
       "14       tfidf_14  7.221192e-04\n",
       "110     tfidf_110  7.197252e-04\n",
       "353     tfidf_353  7.105887e-04\n",
       "159     tfidf_159  7.082528e-04\n",
       "9         tfidf_9  7.026187e-04\n",
       "373     tfidf_373  6.904115e-04\n",
       "181     tfidf_181  6.872377e-04\n",
       "435       flowery  6.821499e-04\n",
       "311     tfidf_311  6.795466e-04\n",
       "112     tfidf_112  6.786285e-04\n",
       "142     tfidf_142  6.765134e-04\n",
       "263     tfidf_263  6.752637e-04\n",
       "336     tfidf_336  6.734786e-04\n",
       "143     tfidf_143  6.677030e-04\n",
       "133     tfidf_133  6.664784e-04\n",
       "369     tfidf_369  6.660512e-04\n",
       "62       tfidf_62  6.631637e-04\n",
       "271     tfidf_271  6.593277e-04\n",
       "117     tfidf_117  6.544643e-04\n",
       "150     tfidf_150  6.460012e-04\n",
       "304     tfidf_304  6.429621e-04\n",
       "22       tfidf_22  6.404397e-04\n",
       "277     tfidf_277  6.389510e-04\n",
       "58       tfidf_58  6.325406e-04\n",
       "351     tfidf_351  6.308084e-04\n",
       "137     tfidf_137  6.245486e-04\n",
       "82       tfidf_82  6.221851e-04\n",
       "298     tfidf_298  6.217195e-04\n",
       "87       tfidf_87  6.190564e-04\n",
       "4         tfidf_4  6.186378e-04\n",
       "233     tfidf_233  6.176950e-04\n",
       "88       tfidf_88  6.122477e-04\n",
       "385     tfidf_385  6.115950e-04\n",
       "100     tfidf_100  6.110499e-04\n",
       "223     tfidf_223  6.097605e-04\n",
       "355     tfidf_355  6.074877e-04\n",
       "69       tfidf_69  6.066562e-04\n",
       "243     tfidf_243  6.026957e-04\n",
       "131     tfidf_131  6.026681e-04\n",
       "331     tfidf_331  6.026145e-04\n",
       "326     tfidf_326  5.998244e-04\n",
       "241     tfidf_241  5.837926e-04\n",
       "51       tfidf_51  5.747415e-04\n",
       "229     tfidf_229  5.725061e-04\n",
       "0         tfidf_0  5.719354e-04\n",
       "307     tfidf_307  5.661959e-04\n",
       "208     tfidf_208  5.639122e-04\n",
       "70       tfidf_70  5.627022e-04\n",
       "81       tfidf_81  5.608634e-04\n",
       "6         tfidf_6  5.598728e-04\n",
       "202     tfidf_202  5.499627e-04\n",
       "294     tfidf_294  5.474968e-04\n",
       "392       anxious  5.456071e-04\n",
       "265     tfidf_265  5.305691e-04\n",
       "108     tfidf_108  5.237346e-04\n",
       "412      paranoid  5.170756e-04\n",
       "77       tfidf_77  5.126571e-04\n",
       "465      tropical  5.123884e-04\n",
       "313     tfidf_313  5.114425e-04\n",
       "254     tfidf_254  5.090481e-04\n",
       "266     tfidf_266  5.063111e-04\n",
       "387     tfidf_387  5.062696e-04\n",
       "72       tfidf_72  4.930936e-04\n",
       "335     tfidf_335  4.913720e-04\n",
       "436         fruit  4.911864e-04\n",
       "225     tfidf_225  4.857254e-04\n",
       "268     tfidf_268  4.852558e-04\n",
       "204     tfidf_204  4.841875e-04\n",
       "106     tfidf_106  4.822127e-04\n",
       "65       tfidf_65  4.805737e-04\n",
       "246     tfidf_246  4.757229e-04\n",
       "18       tfidf_18  4.753309e-04\n",
       "275     tfidf_275  4.747732e-04\n",
       "224     tfidf_224  4.716966e-04\n",
       "57       tfidf_57  4.692050e-04\n",
       "333     tfidf_333  4.658132e-04\n",
       "349     tfidf_349  4.630492e-04\n",
       "220     tfidf_220  4.596341e-04\n",
       "235     tfidf_235  4.580494e-04\n",
       "109     tfidf_109  4.553656e-04\n",
       "236     tfidf_236  4.536904e-04\n",
       "251     tfidf_251  4.485550e-04\n",
       "83       tfidf_83  4.474469e-04\n",
       "327     tfidf_327  4.454053e-04\n",
       "186     tfidf_186  4.449616e-04\n",
       "44       tfidf_44  4.396859e-04\n",
       "288     tfidf_288  4.358736e-04\n",
       "29       tfidf_29  4.328038e-04\n",
       "299     tfidf_299  4.278531e-04\n",
       "356     tfidf_356  4.270299e-04\n",
       "458  spicy/herbal  4.264255e-04\n",
       "344     tfidf_344  4.228614e-04\n",
       "249     tfidf_249  4.200350e-04\n",
       "375     tfidf_375  4.194308e-04\n",
       "84       tfidf_84  4.091399e-04\n",
       "368     tfidf_368  4.085251e-04\n",
       "443         mango  4.082927e-04\n",
       "372     tfidf_372  4.064506e-04\n",
       "292     tfidf_292  4.037178e-04\n",
       "33       tfidf_33  4.033277e-04\n",
       "276     tfidf_276  3.995724e-04\n",
       "323     tfidf_323  3.972489e-04\n",
       "296     tfidf_296  3.947463e-04\n",
       "370     tfidf_370  3.939247e-04\n",
       "122     tfidf_122  3.876744e-04\n",
       "116     tfidf_116  3.855142e-04\n",
       "310     tfidf_310  3.817366e-04\n",
       "160     tfidf_160  3.772223e-04\n",
       "238     tfidf_238  3.737234e-04\n",
       "317     tfidf_317  3.726775e-04\n",
       "185     tfidf_185  3.725562e-04\n",
       "155     tfidf_155  3.688229e-04\n",
       "102     tfidf_102  3.672659e-04\n",
       "232     tfidf_232  3.650489e-04\n",
       "364     tfidf_364  3.612885e-04\n",
       "421       ammonia  3.607854e-04\n",
       "334     tfidf_334  3.601296e-04\n",
       "176     tfidf_176  3.579265e-04\n",
       "171     tfidf_171  3.554907e-04\n",
       "179     tfidf_179  3.524860e-04\n",
       "47       tfidf_47  3.493677e-04\n",
       "27       tfidf_27  3.486201e-04\n",
       "23       tfidf_23  3.468623e-04\n",
       "301     tfidf_301  3.427086e-04\n",
       "41       tfidf_41  3.378899e-04\n",
       "358     tfidf_358  3.373951e-04\n",
       "209     tfidf_209  3.350037e-04\n",
       "212     tfidf_212  3.333557e-04\n",
       "339     tfidf_339  3.277901e-04\n",
       "302     tfidf_302  3.228229e-04\n",
       "52       tfidf_52  3.168330e-04\n",
       "140     tfidf_140  3.157688e-04\n",
       "322     tfidf_322  3.155230e-04\n",
       "319     tfidf_319  3.145825e-04\n",
       "180     tfidf_180  3.108803e-04\n",
       "113     tfidf_113  3.099103e-04\n",
       "40       tfidf_40  3.073770e-04\n",
       "42       tfidf_42  3.068706e-04\n",
       "31       tfidf_31  3.036914e-04\n",
       "328     tfidf_328  3.028489e-04\n",
       "216     tfidf_216  3.019284e-04\n",
       "384     tfidf_384  3.018373e-04\n",
       "252     tfidf_252  2.985181e-04\n",
       "295     tfidf_295  2.981534e-04\n",
       "352     tfidf_352  2.963958e-04\n",
       "227     tfidf_227  2.957743e-04\n",
       "92       tfidf_92  2.948081e-04\n",
       "192     tfidf_192  2.935691e-04\n",
       "234     tfidf_234  2.924540e-04\n",
       "95       tfidf_95  2.908771e-04\n",
       "316     tfidf_316  2.873934e-04\n",
       "8         tfidf_8  2.861328e-04\n",
       "191     tfidf_191  2.825593e-04\n",
       "455          rose  2.783265e-04\n",
       "182     tfidf_182  2.756969e-04\n",
       "306     tfidf_306  2.717348e-04\n",
       "177     tfidf_177  2.667368e-04\n",
       "187     tfidf_187  2.661541e-04\n",
       "67       tfidf_67  2.653813e-04\n",
       "24       tfidf_24  2.605686e-04\n",
       "226     tfidf_226  2.604394e-04\n",
       "214     tfidf_214  2.600843e-04\n",
       "300     tfidf_300  2.580932e-04\n",
       "430      chestnut  2.575190e-04\n",
       "76       tfidf_76  2.553749e-04\n",
       "63       tfidf_63  2.534789e-04\n",
       "12       tfidf_12  2.509737e-04\n",
       "315     tfidf_315  2.500888e-04\n",
       "55       tfidf_55  2.485292e-04\n",
       "118     tfidf_118  2.484497e-04\n",
       "432        coffee  2.391186e-04\n",
       "196     tfidf_196  2.355547e-04\n",
       "156     tfidf_156  2.354628e-04\n",
       "308     tfidf_308  2.346568e-04\n",
       "66       tfidf_66  2.294154e-04\n",
       "115     tfidf_115  2.278695e-04\n",
       "462           tea  2.242697e-04\n",
       "201     tfidf_201  2.242471e-04\n",
       "290     tfidf_290  2.198760e-04\n",
       "169     tfidf_169  2.195554e-04\n",
       "332     tfidf_332  2.169385e-04\n",
       "365     tfidf_365  2.166050e-04\n",
       "346     tfidf_346  2.157644e-04\n",
       "127     tfidf_127  2.109588e-04\n",
       "68       tfidf_68  2.103680e-04\n",
       "444       menthol  2.080134e-04\n",
       "15       tfidf_15  2.058098e-04\n",
       "242     tfidf_242  2.040006e-04\n",
       "213     tfidf_213  1.965500e-04\n",
       "359     tfidf_359  1.960081e-04\n",
       "448         peach  1.907717e-04\n",
       "279     tfidf_279  1.886101e-04\n",
       "244     tfidf_244  1.880105e-04\n",
       "50       tfidf_50  1.863309e-04\n",
       "59       tfidf_59  1.836629e-04\n",
       "197     tfidf_197  1.816967e-04\n",
       "464          tree  1.808052e-04\n",
       "165     tfidf_165  1.797430e-04\n",
       "114     tfidf_114  1.756575e-04\n",
       "324     tfidf_324  1.752082e-04\n",
       "261     tfidf_261  1.730431e-04\n",
       "450        pepper  1.703667e-04\n",
       "330     tfidf_330  1.632247e-04\n",
       "446         nutty  1.630789e-04\n",
       "256     tfidf_256  1.603968e-04\n",
       "38       tfidf_38  1.603444e-04\n",
       "218     tfidf_218  1.584423e-04\n",
       "25       tfidf_25  1.575324e-04\n",
       "459    strawberry  1.572067e-04\n",
       "195     tfidf_195  1.554430e-04\n",
       "35       tfidf_35  1.551291e-04\n",
       "439         honey  1.521728e-04\n",
       "134     tfidf_134  1.460612e-04\n",
       "60       tfidf_60  1.450848e-04\n",
       "13       tfidf_13  1.377022e-04\n",
       "89       tfidf_89  1.334318e-04\n",
       "174     tfidf_174  1.250101e-04\n",
       "293     tfidf_293  1.229717e-04\n",
       "449          pear  1.208057e-04\n",
       "284     tfidf_284  1.124416e-04\n",
       "429      chemical  1.104422e-04\n",
       "452     pineapple  1.093674e-04\n",
       "379     tfidf_379  9.732620e-05\n",
       "438    grapefruit  8.599476e-05\n",
       "461           tar  8.050076e-05\n",
       "463       tobacco  7.406212e-05\n",
       "440      lavender  7.227291e-05\n",
       "250     tfidf_250  6.098705e-05\n",
       "467        violet  5.883638e-05\n",
       "453          plum  5.485279e-05\n",
       "36       tfidf_36  5.475444e-05\n",
       "427        butter  5.411046e-05\n",
       "425   blue cheese  3.324199e-05\n",
       "391       anxiety  3.275466e-05\n",
       "410     migraines  3.252261e-05\n",
       "423       apricot  2.935471e-05\n",
       "396    depression  2.754968e-05\n",
       "422         apple  2.183774e-05\n",
       "404       fatigue  3.040739e-08\n",
       "414      seizures  3.911011e-10\n",
       "394     arthritis  3.028354e-10\n",
       "411          pain  1.456504e-10\n",
       "401      epilepsy  1.415702e-10\n",
       "416    spasticity  0.000000e+00\n",
       "389        indica  0.000000e+00\n",
       "417        stress  0.000000e+00\n",
       "403  eye pressure  0.000000e+00"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.set_option('display.max_rows', df_feat_ranked.shape[0]+1)\n",
    "df_feat_ranked"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/andalanputra/opt/anaconda3/lib/python3.9/site-packages/sklearn/feature_selection/_from_model.py:357: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  self.estimator_.fit(X, y, **fit_params)\n"
     ]
    }
   ],
   "source": [
    "selector = SelectFromModel(rfreg).fit(X_train1, y_train1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([5.22349671e-04, 6.64641846e-04, 2.38623386e-03, 1.23573424e-03,\n",
       "       5.22375323e-04, 3.16436134e-03, 4.40631823e-04, 4.03635080e-03,\n",
       "       2.58646145e-04, 5.98887391e-04, 1.54925383e-03, 2.35905304e-03,\n",
       "       1.86645369e-04, 2.37924107e-04, 7.77571042e-04, 2.21860887e-04,\n",
       "       6.49848149e-04, 7.65578521e-04, 3.77434911e-04, 1.22777910e-03,\n",
       "       1.05996683e-03, 9.77855280e-04, 6.39199045e-04, 3.11313438e-04,\n",
       "       3.25396476e-04, 1.75622651e-04, 2.32800340e-03, 4.47391149e-04,\n",
       "       1.20137911e-03, 4.01360432e-04, 3.35801925e-03, 2.85216466e-04,\n",
       "       2.21915984e-03, 4.20003713e-04, 1.32662814e-03, 1.87804332e-04,\n",
       "       5.09668167e-05, 3.03293612e-03, 1.59459073e-04, 7.47935593e-04,\n",
       "       3.07470165e-04, 3.30479220e-04, 3.37981649e-04, 2.42820756e-03,\n",
       "       4.77133159e-04, 8.14774000e-04, 1.96110333e-03, 3.87047307e-04,\n",
       "       1.07847407e-03, 9.93520280e-04, 1.87624729e-04, 6.10569455e-04,\n",
       "       3.30212588e-04, 7.72300586e-04, 1.35465797e-03, 3.23077312e-04,\n",
       "       8.14421410e-04, 4.56379481e-04, 5.70154052e-04, 2.08764584e-04,\n",
       "       1.40278785e-04, 1.09389455e-03, 7.28777960e-04, 2.38673547e-04,\n",
       "       8.52679249e-04, 4.72949390e-04, 2.23974527e-04, 2.42329473e-04,\n",
       "       2.35322651e-04, 6.17393092e-04, 6.14439916e-04, 7.05465530e-04,\n",
       "       4.99537958e-04, 2.82895286e-03, 3.64525262e-03, 2.29307249e-03,\n",
       "       2.81481253e-04, 5.88650912e-04, 3.48985583e-03, 1.12742244e-03,\n",
       "       8.39445638e-04, 6.08256213e-04, 7.96754650e-04, 4.09022776e-04,\n",
       "       4.74489572e-04, 1.16886890e-03, 1.24494608e-03, 8.13278203e-04,\n",
       "       5.14760778e-04, 8.75405105e-05, 1.19693692e-03, 1.34219994e-03,\n",
       "       2.99809336e-04, 4.73515069e-03, 2.24390804e-03, 2.98013496e-04,\n",
       "       2.85089365e-03, 1.08213090e-03, 9.48431997e-04, 8.27553612e-04,\n",
       "       6.64552275e-04, 7.16139460e-03, 3.81991037e-04, 1.04093712e-03,\n",
       "       1.38945670e-03, 9.86993290e-04, 5.03201011e-04, 1.34773195e-03,\n",
       "       4.28625087e-04, 4.38231073e-04, 7.08600498e-04, 7.83888089e-04,\n",
       "       6.70778080e-04, 2.76497636e-04, 1.91227196e-04, 2.13801771e-04,\n",
       "       3.68695567e-04, 5.73824729e-04, 2.70432058e-04, 2.88745153e-03,\n",
       "       2.03447720e-03, 4.22253972e-03, 4.05105704e-04, 2.57677173e-03,\n",
       "       1.80526510e-03, 6.58277185e-04, 1.91539450e-03, 2.22744571e-04,\n",
       "       4.07331081e-03, 1.01039713e-03, 1.87528248e-03, 5.29603937e-04,\n",
       "       1.44786621e-03, 4.83894015e-04, 1.67309624e-04, 1.00732763e-03,\n",
       "       1.22892299e-03, 5.67917490e-04, 2.13657159e-03, 1.31457091e-03,\n",
       "       3.77329098e-04, 7.61407031e-03, 6.27029078e-04, 6.91645114e-04,\n",
       "       2.24111165e-03, 7.51440874e-03, 8.07625559e-04, 1.04709213e-03,\n",
       "       7.28007192e-04, 7.71912761e-03, 6.78500071e-04, 1.15080745e-03,\n",
       "       1.27069867e-03, 1.36100517e-03, 9.86836828e-04, 3.47723248e-04,\n",
       "       2.30078715e-04, 8.69798999e-04, 4.58290639e-03, 7.37767921e-04,\n",
       "       3.74811107e-04, 5.13382008e-03, 2.19870559e-03, 1.91725827e-03,\n",
       "       8.32081975e-04, 1.83115516e-04, 1.20139463e-03, 3.63285350e-03,\n",
       "       1.02008781e-02, 1.92836426e-04, 7.87481147e-04, 3.51968993e-04,\n",
       "       9.70416081e-04, 2.95487731e-03, 1.00008098e-04, 8.94596633e-04,\n",
       "       4.10678669e-04, 2.65222665e-04, 1.50968767e-03, 3.68194457e-04,\n",
       "       3.03009712e-04, 6.84609252e-04, 2.12907911e-04, 1.32739300e-03,\n",
       "       1.33017654e-03, 4.06469455e-04, 4.12176193e-04, 2.14181548e-04,\n",
       "       1.06192041e-03, 3.78893922e-03, 1.42662431e-03, 2.68264616e-04,\n",
       "       2.48059325e-04, 7.26285495e-04, 9.09208630e-04, 1.25908288e-04,\n",
       "       2.28007064e-04, 2.19387848e-04, 1.14099432e-03, 6.42877167e-03,\n",
       "       1.14988922e-03, 1.92196349e-04, 5.61502956e-04, 1.70145235e-03,\n",
       "       5.63053111e-04, 1.07827631e-03, 1.13390769e-03, 3.27968737e-03,\n",
       "       6.69381282e-04, 3.36188748e-04, 3.30644441e-03, 2.63935129e-03,\n",
       "       3.42282338e-04, 1.64371277e-04, 2.83183777e-04, 1.69403490e-03,\n",
       "       3.17020324e-04, 1.59296179e-03, 1.70845933e-04, 8.10887566e-04,\n",
       "       3.74060369e-04, 7.61073658e-04, 2.25461588e-03, 6.26039837e-04,\n",
       "       4.70225673e-04, 4.96584169e-04, 2.70782478e-04, 3.73308909e-04,\n",
       "       8.47892857e-04, 5.91533595e-04, 2.48994506e-03, 1.48204216e-03,\n",
       "       3.44538828e-04, 5.93675210e-04, 2.70791307e-04, 3.55966686e-04,\n",
       "       4.15773489e-04, 1.60594487e-03, 3.43318151e-04, 4.64965633e-03,\n",
       "       2.06248195e-03, 6.07772228e-04, 1.30516423e-04, 5.19782345e-04,\n",
       "       2.07813626e-04, 3.97996779e-03, 4.54760347e-04, 4.17529279e-03,\n",
       "       7.59534193e-04, 4.40545871e-04, 8.47106692e-05, 3.73388669e-04,\n",
       "       3.07773271e-04, 4.96391058e-03, 5.27882582e-04, 1.01387836e-03,\n",
       "       1.07416666e-04, 2.17359530e-03, 2.58304866e-03, 1.35004716e-03,\n",
       "       1.86042975e-03, 1.96659516e-04, 6.11132090e-04, 6.00665672e-04,\n",
       "       1.37410665e-03, 5.72919818e-04, 4.90420680e-04, 1.64379303e-03,\n",
       "       5.60645652e-04, 8.49957704e-04, 1.39958205e-03, 7.23027526e-04,\n",
       "       8.03782607e-04, 7.52195557e-04, 1.09740475e-03, 3.64726914e-04,\n",
       "       3.70268469e-04, 6.43091451e-04, 8.71704781e-04, 1.34241295e-04,\n",
       "       7.81151821e-04, 3.66660024e-03, 8.92235659e-04, 1.57455200e-03,\n",
       "       1.14046495e-04, 5.62691728e-03, 8.64431993e-04, 1.13082962e-03,\n",
       "       4.53948331e-04, 8.38760468e-04, 1.88117991e-04, 1.01457490e-03,\n",
       "       4.14887068e-04, 1.19142021e-04, 4.95200555e-04, 2.70667247e-04,\n",
       "       3.86071391e-04, 4.34077980e-03, 6.13407782e-04, 4.40831248e-04,\n",
       "       2.36033453e-04, 2.65659612e-04, 3.73605567e-04, 1.71839769e-03,\n",
       "       6.77951316e-04, 1.20759648e-03, 3.10971607e-04, 5.69310904e-04,\n",
       "       2.89314406e-04, 4.19896717e-03, 3.44786250e-04, 6.88790740e-04,\n",
       "       4.53843090e-03, 6.01836633e-04, 2.18265521e-03, 2.11504117e-04,\n",
       "       2.96867422e-04, 3.73439373e-04, 1.10894678e-03, 3.19032243e-04,\n",
       "       6.27045918e-03, 1.34498996e-03, 3.16613329e-04, 4.58191539e-04,\n",
       "       1.76828217e-04, 1.29492516e-03, 5.68685678e-04, 4.53719907e-04,\n",
       "       3.73651043e-04, 8.84523857e-03, 1.44005348e-04, 5.92185294e-04,\n",
       "       2.05922626e-04, 4.26630379e-04, 4.62654385e-04, 3.84871856e-04,\n",
       "       6.79975277e-04, 5.14821455e-03, 1.51941742e-03, 3.72833380e-04,\n",
       "       2.42699111e-03, 1.33954980e-03, 2.05692687e-03, 1.56665876e-03,\n",
       "       4.08757316e-04, 7.35663982e-03, 2.49893680e-04, 1.21437131e-03,\n",
       "       1.51210519e-03, 4.76914897e-04, 1.37879918e-03, 6.86974013e-04,\n",
       "       3.76180204e-04, 7.21635037e-04, 1.08276811e-03, 5.93571606e-04,\n",
       "       4.79066352e-04, 2.39242652e-03, 3.60733657e-04, 2.46261323e-04,\n",
       "       1.21793681e-03, 2.48558437e-03, 2.61474476e-03, 9.67959585e-04,\n",
       "       3.30076585e-04, 2.18595257e-04, 2.67734911e-03, 1.46558595e-03,\n",
       "       4.01397067e-04, 5.85809095e-04, 3.80552478e-04, 1.02186818e-03,\n",
       "       3.94538790e-04, 7.04753213e-04, 1.87976383e-03, 3.76422057e-04,\n",
       "       1.45268101e-03, 7.69414464e-04, 1.65094301e-03, 9.19649215e-05,\n",
       "       6.71308502e-04, 1.55990608e-03, 1.81985380e-03, 7.58505862e-04,\n",
       "       3.57920593e-04, 6.47278517e-04, 7.45618928e-04, 5.13853242e-04,\n",
       "       3.85817997e-02, 0.00000000e+00, 3.53482636e-01, 3.07640091e-05,\n",
       "       4.26702678e-04, 1.08343654e-03, 7.54720574e-08, 4.09439243e-03,\n",
       "       2.66920010e-05, 7.92068254e-04, 9.88087268e-04, 3.38826938e-03,\n",
       "       2.60905496e-03, 2.59516273e-10, 3.82016953e-03, 0.00000000e+00,\n",
       "       2.83992892e-08, 8.21185047e-03, 7.24723421e-03, 2.49269266e-03,\n",
       "       8.81031263e-04, 1.85032917e-03, 2.84527141e-05, 4.55256444e-10,\n",
       "       5.38654994e-04, 2.48398869e-03, 6.89844241e-21, 3.15812147e-03,\n",
       "       0.00000000e+00, 0.00000000e+00, 1.66923757e-03, 2.04724431e-03,\n",
       "       2.41428484e-03, 1.78851893e-04, 1.99220177e-05, 3.00967637e-05,\n",
       "       2.58941392e-03, 2.74537947e-05, 1.62056074e-02, 6.88222979e-05,\n",
       "       1.01871467e-03, 1.35611929e-04, 2.91570308e-04, 2.95999369e-03,\n",
       "       2.42887329e-04, 7.53969274e-03, 8.10452655e-03, 6.68101674e-04,\n",
       "       6.77868004e-04, 3.45954599e-03, 8.44257983e-05, 1.46246379e-04,\n",
       "       7.55440851e-05, 2.76602876e-02, 9.38369445e-04, 3.52339138e-04,\n",
       "       1.05052209e-04, 1.40345087e-03, 2.20572704e-04, 4.07214965e-03,\n",
       "       2.17841054e-04, 1.16910417e-04, 1.38535747e-04, 9.32300654e-04,\n",
       "       1.00602945e-04, 5.48507114e-05, 1.43163340e-03, 2.74786308e-04,\n",
       "       2.65852598e-03, 3.15157155e-03, 4.80746088e-04, 1.72713115e-04,\n",
       "       1.41008251e-03, 6.39406115e-05, 2.51645841e-04, 8.46529374e-05,\n",
       "       1.68029930e-04, 5.55439646e-04, 1.67725854e-03, 5.84934408e-05,\n",
       "       7.69238006e-04])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "selector.estimator_.feature_importances_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0021321961620469083"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "selector.threshold_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "mask = selector.get_support()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([False, False,  True, False, False,  True, False,  True, False,\n",
       "       False, False,  True, False, False, False, False, False, False,\n",
       "       False, False, False, False, False, False, False, False,  True,\n",
       "       False, False, False,  True, False,  True, False, False, False,\n",
       "       False,  True, False, False, False, False, False,  True, False,\n",
       "       False, False, False, False, False, False, False, False, False,\n",
       "       False, False, False, False, False, False, False, False, False,\n",
       "       False, False, False, False, False, False, False, False, False,\n",
       "       False,  True,  True,  True, False, False,  True, False, False,\n",
       "       False, False, False, False, False, False, False, False, False,\n",
       "       False, False, False,  True,  True, False,  True, False, False,\n",
       "       False, False,  True, False, False, False, False, False, False,\n",
       "       False, False, False, False, False, False, False, False, False,\n",
       "       False, False,  True, False,  True, False,  True, False, False,\n",
       "       False, False,  True, False, False, False, False, False, False,\n",
       "       False, False, False,  True, False, False,  True, False, False,\n",
       "        True,  True, False, False, False,  True, False, False, False,\n",
       "       False, False, False, False, False,  True, False, False,  True,\n",
       "        True, False, False, False, False,  True,  True, False, False,\n",
       "       False, False,  True, False, False, False, False, False, False,\n",
       "       False, False, False, False, False, False, False, False, False,\n",
       "        True, False, False, False, False, False, False, False, False,\n",
       "       False,  True, False, False, False, False, False, False, False,\n",
       "        True, False, False,  True,  True, False, False, False, False,\n",
       "       False, False, False, False, False, False,  True, False, False,\n",
       "       False, False, False, False, False,  True, False, False, False,\n",
       "       False, False, False, False, False,  True, False, False, False,\n",
       "       False, False,  True, False,  True, False, False, False, False,\n",
       "       False,  True, False, False, False,  True,  True, False, False,\n",
       "       False, False, False, False, False, False, False, False, False,\n",
       "       False, False, False, False, False, False, False, False, False,\n",
       "       False, False,  True, False, False, False,  True, False, False,\n",
       "       False, False, False, False, False, False, False, False, False,\n",
       "        True, False, False, False, False, False, False, False, False,\n",
       "       False, False, False,  True, False, False,  True, False,  True,\n",
       "       False, False, False, False, False,  True, False, False, False,\n",
       "       False, False, False, False, False,  True, False, False, False,\n",
       "       False, False, False, False,  True, False, False,  True, False,\n",
       "       False, False, False,  True, False, False, False, False, False,\n",
       "       False, False, False, False, False, False,  True, False, False,\n",
       "       False,  True,  True, False, False, False,  True, False, False,\n",
       "       False, False, False, False, False, False, False, False, False,\n",
       "       False, False, False, False, False, False, False, False, False,\n",
       "       False,  True, False,  True, False, False, False, False,  True,\n",
       "       False, False, False,  True,  True, False,  True, False, False,\n",
       "        True,  True,  True, False, False, False, False, False,  True,\n",
       "       False,  True, False, False, False, False,  True, False, False,\n",
       "       False,  True, False,  True, False, False, False, False,  True,\n",
       "       False,  True,  True, False, False,  True, False, False, False,\n",
       "        True, False, False, False, False, False,  True, False, False,\n",
       "       False, False, False, False, False, False,  True,  True, False,\n",
       "       False, False, False, False, False, False, False, False, False,\n",
       "       False])"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "selected_features = X.columns[mask]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tfidf_2</th>\n",
       "      <th>tfidf_5</th>\n",
       "      <th>tfidf_7</th>\n",
       "      <th>tfidf_11</th>\n",
       "      <th>tfidf_26</th>\n",
       "      <th>tfidf_30</th>\n",
       "      <th>tfidf_32</th>\n",
       "      <th>tfidf_37</th>\n",
       "      <th>tfidf_43</th>\n",
       "      <th>tfidf_73</th>\n",
       "      <th>...</th>\n",
       "      <th>berry</th>\n",
       "      <th>blueberry</th>\n",
       "      <th>citrus</th>\n",
       "      <th>diesel</th>\n",
       "      <th>earthy</th>\n",
       "      <th>grape</th>\n",
       "      <th>lemon</th>\n",
       "      <th>orange</th>\n",
       "      <th>sage</th>\n",
       "      <th>skunk</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.14162</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.14162</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.14162</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.198545</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.198545</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>74995</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>74996</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>74997</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>74998</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>74999</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>75000 rows × 82 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       tfidf_2  tfidf_5  tfidf_7  tfidf_11  tfidf_26  tfidf_30  tfidf_32  \\\n",
       "0          0.0      0.0      0.0       0.0       0.0       0.0       0.0   \n",
       "1          0.0      0.0      0.0       0.0       0.0       0.0       0.0   \n",
       "2          0.0      0.0      0.0       0.0       0.0       0.0       0.0   \n",
       "3          0.0      0.0      0.0       0.0       0.0       0.0       0.0   \n",
       "4          0.0      0.0      0.0       0.0       0.0       0.0       0.0   \n",
       "...        ...      ...      ...       ...       ...       ...       ...   \n",
       "74995      0.0      0.0      0.0       0.0       0.0       0.0       0.0   \n",
       "74996      0.0      0.0      0.0       0.0       0.0       0.0       0.0   \n",
       "74997      0.0      0.0      0.0       0.0       0.0       0.0       0.0   \n",
       "74998      0.0      0.0      0.0       0.0       0.0       0.0       0.0   \n",
       "74999      0.0      0.0      0.0       0.0       0.0       0.0       0.0   \n",
       "\n",
       "       tfidf_37  tfidf_43  tfidf_73  ...  berry  blueberry  citrus  diesel  \\\n",
       "0       0.14162  0.000000       0.0  ...      0          0       0       0   \n",
       "1       0.14162  0.000000       0.0  ...      0          0       0       0   \n",
       "2       0.14162  0.000000       0.0  ...      0          0       0       0   \n",
       "3       0.00000  0.198545       0.0  ...      1          0       0       0   \n",
       "4       0.00000  0.198545       0.0  ...      1          0       0       0   \n",
       "...         ...       ...       ...  ...    ...        ...     ...     ...   \n",
       "74995   0.00000  0.000000       0.0  ...      0          0       0       0   \n",
       "74996   0.00000  0.000000       0.0  ...      0          0       0       0   \n",
       "74997   0.00000  0.000000       0.0  ...      0          0       0       0   \n",
       "74998   0.00000  0.000000       0.0  ...      1          1       1       1   \n",
       "74999   0.00000  0.000000       0.0  ...      1          1       1       1   \n",
       "\n",
       "       earthy  grape  lemon  orange  sage  skunk  \n",
       "0           0      0      0       0     0      0  \n",
       "1           0      0      0       0     0      0  \n",
       "2           0      0      0       0     0      0  \n",
       "3           0      0      0       0     0      0  \n",
       "4           0      0      0       0     0      0  \n",
       "...       ...    ...    ...     ...   ...    ...  \n",
       "74995       0      0      0       0     0      0  \n",
       "74996       0      0      0       0     0      0  \n",
       "74997       0      0      0       0     0      0  \n",
       "74998       1      1      1       1     1      1  \n",
       "74999       1      1      1       1     1      1  \n",
       "\n",
       "[75000 rows x 82 columns]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "selected_X = df_rf[selected_features]\n",
    "selected_X"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train test split (after Feature Selection)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['selected_X_rf_tfidf_guai.pkl']"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import joblib\n",
    "\n",
    "joblib.dump(selector, \"selector_rf_tfidf_guai.pkl\")\n",
    "joblib.dump(selected_X, \"selected_X_rf_tfidf_guai.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(selected_X, y, random_state=1, test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train1, X_val, y_train1, y_val = train_test_split(X_train, y_train, random_state=1, test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/y1/pjvjlkjn5gl846rnyzr53p340000gn/T/ipykernel_10483/3758305.py:1: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  rfreg.fit(X_train1, y_train1)\n"
     ]
    }
   ],
   "source": [
    "rfreg.fit(X_train1, y_train1)\n",
    "y_pred_rfreg = rfreg.predict(X_val)\n",
    "y_pred_rfreg_r2 = rfreg.predict(X_train1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.05092552836654331"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mean_absolute_error(y_val, y_pred_rfreg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.01210120765835364"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mean_squared_error(y_val, y_pred_rfreg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.11000548921919143"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mean_squared_error(y_val, y_pred_rfreg, squared = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9780193268519342"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#train\n",
    "r2_score(y_train1, y_pred_rfreg_r2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.913936822681003"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#val\n",
    "r2_score(y_val, y_pred_rfreg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hyperparameter Tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "parameters = {'max_depth': [None, 10, 50, 100],\n",
    "              'max_features': ['auto', 'sqrt'],\n",
    "              'min_samples_leaf': [1, 2, 4],\n",
    "              'min_samples_split': [2, 5, 10],\n",
    "              'n_estimators': [100, 300, 500]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "rscv = RandomizedSearchCV(rfreg,  \n",
    "                     parameters,   \n",
    "                     cv=5, \n",
    "                     scoring='neg_mean_absolute_error',\n",
    "                     n_jobs = -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/andalanputra/opt/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/Users/andalanputra/opt/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/Users/andalanputra/opt/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/Users/andalanputra/opt/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/Users/andalanputra/opt/anaconda3/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
      "  warn(\n",
      "/Users/andalanputra/opt/anaconda3/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
      "  warn(\n",
      "/Users/andalanputra/opt/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/Users/andalanputra/opt/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/Users/andalanputra/opt/anaconda3/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
      "  warn(\n",
      "/Users/andalanputra/opt/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/Users/andalanputra/opt/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/Users/andalanputra/opt/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/Users/andalanputra/opt/anaconda3/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
      "  warn(\n",
      "/Users/andalanputra/opt/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/Users/andalanputra/opt/anaconda3/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
      "  warn(\n",
      "/Users/andalanputra/opt/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/Users/andalanputra/opt/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/Users/andalanputra/opt/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/Users/andalanputra/opt/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/Users/andalanputra/opt/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/Users/andalanputra/opt/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/Users/andalanputra/opt/anaconda3/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
      "  warn(\n",
      "/Users/andalanputra/opt/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/Users/andalanputra/opt/anaconda3/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
      "  warn(\n",
      "/Users/andalanputra/opt/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/Users/andalanputra/opt/anaconda3/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
      "  warn(\n",
      "/Users/andalanputra/opt/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/Users/andalanputra/opt/anaconda3/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
      "  warn(\n",
      "/Users/andalanputra/opt/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/Users/andalanputra/opt/anaconda3/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
      "  warn(\n",
      "/Users/andalanputra/opt/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/Users/andalanputra/opt/anaconda3/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
      "  warn(\n",
      "/Users/andalanputra/opt/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/Users/andalanputra/opt/anaconda3/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
      "  warn(\n",
      "/Users/andalanputra/opt/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/Users/andalanputra/opt/anaconda3/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
      "  warn(\n",
      "/Users/andalanputra/opt/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/Users/andalanputra/opt/anaconda3/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
      "  warn(\n",
      "/Users/andalanputra/opt/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/Users/andalanputra/opt/anaconda3/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
      "  warn(\n",
      "/Users/andalanputra/opt/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/Users/andalanputra/opt/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/Users/andalanputra/opt/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/Users/andalanputra/opt/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/Users/andalanputra/opt/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/Users/andalanputra/opt/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/Users/andalanputra/opt/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/Users/andalanputra/opt/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/Users/andalanputra/opt/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/Users/andalanputra/opt/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/Users/andalanputra/opt/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/Users/andalanputra/opt/anaconda3/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
      "  warn(\n",
      "/Users/andalanputra/opt/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/Users/andalanputra/opt/anaconda3/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
      "  warn(\n",
      "/Users/andalanputra/opt/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/Users/andalanputra/opt/anaconda3/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
      "  warn(\n",
      "/Users/andalanputra/opt/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/Users/andalanputra/opt/anaconda3/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
      "  warn(\n",
      "/Users/andalanputra/opt/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/Users/andalanputra/opt/anaconda3/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
      "  warn(\n",
      "/Users/andalanputra/opt/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/Users/andalanputra/opt/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/Users/andalanputra/opt/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/Users/andalanputra/opt/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/Users/andalanputra/opt/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/Users/andalanputra/opt/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/Users/andalanputra/opt/anaconda3/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
      "  warn(\n",
      "/Users/andalanputra/opt/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/Users/andalanputra/opt/anaconda3/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
      "  warn(\n",
      "/Users/andalanputra/opt/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/Users/andalanputra/opt/anaconda3/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
      "  warn(\n",
      "/Users/andalanputra/opt/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/Users/andalanputra/opt/anaconda3/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
      "  warn(\n",
      "/Users/andalanputra/opt/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/Users/andalanputra/opt/anaconda3/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
      "  warn(\n",
      "/Users/andalanputra/opt/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_search.py:909: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  self.best_estimator_.fit(X, y, **fit_params)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-2 {color: black;background-color: white;}#sk-container-id-2 pre{padding: 0;}#sk-container-id-2 div.sk-toggleable {background-color: white;}#sk-container-id-2 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-2 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-2 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-2 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-2 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-2 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-2 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-2 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-2 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-2 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-2 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-2 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-2 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-2 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-2 div.sk-item {position: relative;z-index: 1;}#sk-container-id-2 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-2 div.sk-item::before, #sk-container-id-2 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-2 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-2 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-2 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-2 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-2 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-2 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-2 div.sk-label-container {text-align: center;}#sk-container-id-2 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-2 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-2\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>RandomizedSearchCV(cv=5, estimator=RandomForestRegressor(), n_jobs=-1,\n",
       "                   param_distributions={&#x27;max_depth&#x27;: [None, 10, 50, 100],\n",
       "                                        &#x27;max_features&#x27;: [&#x27;auto&#x27;, &#x27;sqrt&#x27;],\n",
       "                                        &#x27;min_samples_leaf&#x27;: [1, 2, 4],\n",
       "                                        &#x27;min_samples_split&#x27;: [2, 5, 10],\n",
       "                                        &#x27;n_estimators&#x27;: [100, 300, 500]},\n",
       "                   scoring=&#x27;neg_mean_absolute_error&#x27;)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" ><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">RandomizedSearchCV</label><div class=\"sk-toggleable__content\"><pre>RandomizedSearchCV(cv=5, estimator=RandomForestRegressor(), n_jobs=-1,\n",
       "                   param_distributions={&#x27;max_depth&#x27;: [None, 10, 50, 100],\n",
       "                                        &#x27;max_features&#x27;: [&#x27;auto&#x27;, &#x27;sqrt&#x27;],\n",
       "                                        &#x27;min_samples_leaf&#x27;: [1, 2, 4],\n",
       "                                        &#x27;min_samples_split&#x27;: [2, 5, 10],\n",
       "                                        &#x27;n_estimators&#x27;: [100, 300, 500]},\n",
       "                   scoring=&#x27;neg_mean_absolute_error&#x27;)</pre></div></div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-3\" type=\"checkbox\" ><label for=\"sk-estimator-id-3\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">estimator: RandomForestRegressor</label><div class=\"sk-toggleable__content\"><pre>RandomForestRegressor()</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-4\" type=\"checkbox\" ><label for=\"sk-estimator-id-4\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">RandomForestRegressor</label><div class=\"sk-toggleable__content\"><pre>RandomForestRegressor()</pre></div></div></div></div></div></div></div></div></div></div>"
      ],
      "text/plain": [
       "RandomizedSearchCV(cv=5, estimator=RandomForestRegressor(), n_jobs=-1,\n",
       "                   param_distributions={'max_depth': [None, 10, 50, 100],\n",
       "                                        'max_features': ['auto', 'sqrt'],\n",
       "                                        'min_samples_leaf': [1, 2, 4],\n",
       "                                        'min_samples_split': [2, 5, 10],\n",
       "                                        'n_estimators': [100, 300, 500]},\n",
       "                   scoring='neg_mean_absolute_error')"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rscv.fit(X_train1, y_train1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'n_estimators': 500,\n",
       " 'min_samples_split': 10,\n",
       " 'min_samples_leaf': 1,\n",
       " 'max_features': 'sqrt',\n",
       " 'max_depth': None}"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rscv.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['rscv_rf_tfidf_best_params_guai.pkl']"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "joblib.dump(rscv, \"rscv_rf_tfidf_guai.pkl\")\n",
    "joblib.dump(rscv.best_params_, \"rscv_rf_tfidf_best_params_guai.pkl\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "RF (after Hyperparameter Tuning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/y1/pjvjlkjn5gl846rnyzr53p340000gn/T/ipykernel_10483/2401359886.py:2: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  rfreg_ht.fit(X_train1, y_train1)\n"
     ]
    }
   ],
   "source": [
    "rfreg_ht = RandomForestRegressor(n_estimators = 500, min_samples_split = 10, min_samples_leaf = 1, max_features = 'sqrt', max_depth = None)\n",
    "rfreg_ht.fit(X_train1, y_train1)\n",
    "y_pred_rfreg = rfreg_ht.predict(X_val)\n",
    "y_pred_rfreg_r2 = rfreg_ht.predict(X_train1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.06771851450494457"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mean_absolute_error(y_val, y_pred_rfreg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.013096077046736857"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mean_squared_error(y_val, y_pred_rfreg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.11443809263849541"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mean_squared_error(y_val, y_pred_rfreg, squared = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9587896396937998"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#train\n",
    "r2_score(y_train1, y_pred_rfreg_r2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9068613618675889"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#val\n",
    "r2_score(y_val, y_pred_rfreg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Residual plots after Hyperparameter Tuning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Predicting model on the test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_rfreg_test = rfreg_ht.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['y_test_rfreg_tfidf_guai.pkl']"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "joblib.dump(y_pred_rfreg_test, \"y_pred_rfreg_test_tfidf_guai.pkl\")\n",
    "joblib.dump(y_test, \"y_test_rfreg_tfidf_guai.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.06637703066982538"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mean_absolute_error(y_test, y_pred_rfreg_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.012907328842008842"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mean_squared_error(y_test, y_pred_rfreg_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.11361042576281827"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mean_squared_error(y_test, y_pred_rfreg_test, squared = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9103282989327511"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "r2_score(y_test, y_pred_rfreg_test)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Error analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAe0AAAF1CAYAAADFgbLVAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjQuMywgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/MnkTPAAAACXBIWXMAAAsTAAALEwEAmpwYAAAhHElEQVR4nO3df7xVdZ3v8dcnRLBRUxG9yNEBS5vAO2ES4piJmWnND2TKwpzwmg7m1bIezZ0k76Rzb4zOvWNOjuUMlYHTDyRzlNuoM0g4jobQoVAE08gfeJKBI2b+SBl+fO4fe6Fb2XA2nM05fM95PR+P/dhrf9Z3rf3d63F4vPmu9d1rR2YiSZJ2f2/o7Q5IkqTmGNqSJBXC0JYkqRCGtiRJhTC0JUkqhKEtSVIhDG1JLRMRt0fE2U20GxERGRF79ES/pL7C0JYKEhF7R8TjEfHRuto+EbEqIj7UxPZ7RsQXIuLhiHgxIn5ZBe37WtG/zHx/Zs5qxb4kbc3QlgqSmS8AU4EvR8TQqvx/gPbMvKmJXdwETASmAPsDI4EvA7+/C7orqcUMbakwmfmvwD8D10TEBODDwIVdbRcR7wVOASZm5qLM/M/qcUdmXlzXLiPiLXWvZ0bEF6vl/SPiBxHRGRG/qpbb6treFRHnVctviIj/GRFPRMTaiLghIt7UmqMg9U+GtlSmzwATqI2c/ywzVzexzXuBRZnZ0Y33fQPwTeC3gcOAl4Brt9H2v1WPk4DDgb2301ZSEwxtqUCZ+StgOfBG4OYmNzsQ+I8tLyLigIh4NiJ+HREvN/m+6zLz+5n5m8x8HpgOnLiN5mcBX8rMR6vT+tOAyU4+k3aeoS0VKCL+BBgB3An8dZObrQOGbXmRmc9k5n7AMcCgJt/3jRHxD9Up7+eAu4H9ImJAg+aHAE/UvX4C2AM4uMn+SnodQ1sqTEQcBFwN/ClwPvDhiHh3E5vOB95Zfw16G35DbQS/xX+pW/4s8Fbg2MzcF9jyvtFgP09RO42+xWHARmBNE32V1IChLZXnWuCWzFxQXcv+c+BrEbHd0XI1gW0BcEtEHFt9/WsgMP51TZcCH42IARFxGq89/b0PtevYz0bEAcBl23nL7wKfiYiREbE38FfAjZm5sfmPKqmeoS0VJCJOB94F/I8ttcz8OtABfCEiPh8Rt9e1vz0iPl+3iz8GfgB8C3gWeIzatefT6tpcDPxhtf4s4Ja6dX8L7AU8DdwH3LGd7l4P/CO1U+iPAS8Dn2zuk0pqJDKzt/sgSZKa4EhbkqRCGNqSJBXC0JYkqRCGtiRJhTC0JUkqxG5/O8EDDzwwR4wY0dvdkCSpRyxZsuTpzBzaaN1uH9ojRoygvb29t7shSVKPiIgntrXO0+OSJBXC0JYkqRCGtiRJhdjtr2lLkvqGDRs20NHRwcsvN/Xz7X3e4MGDaWtrY+DAgU1vY2hLknpER0cH++yzDyNGjCCi0a+59h+Zybp16+jo6GDkyJFNb+fpcUlSj3j55ZcZMmRIvw9sgIhgyJAhO3zWwdCWJPUYA/tVO3MsDG1JkgrhNW1JUq+4et4jLd3fZ045sqX7a5WZM2fS3t7Otdde2+19OdKWJGknbNq0qcff09CWJPULf/EXf8GXv/zlV15feumlXHPNNVu1u+uuu3j3u9/NpEmTGDVqFJ/4xCfYvHkzAHvvvTdf+MIXOPbYY1m4cCHf+ta3GDduHGPGjOH8889/Jci/+c1vcuSRR3LiiSdy7733tuwzGNqSpH7h3HPPZdasWQBs3ryZ2bNnc9ZZZzVsu3jxYq666iqWLVvGL37xC26++WYAXnzxRY466igWLVrEkCFDuPHGG7n33ntZunQpAwYM4Nvf/jarV6/msssu495772XevHmsWLGiZZ/Ba9qSpH5hxIgRDBkyhJ/+9KesWbOGo48+miFDhjRsO27cOA4//HAAzjzzTO655x4+9KEPMWDAAD74wQ8CMH/+fJYsWcI73/lOAF566SUOOuggFi1axIQJExg6tPZDXR/5yEd45JHWXL83tCVJ/cZ5553HzBlf4T/WrOXjH/0wPLd660YvriM2b3h13UvPEht+A8+tZvDgQQx4cS0A+dKznD35g1zxpb97zea33HLLLvtqm6fHJUn9xqRJk7jjzgX8+Cf3c+rJE7bZbvGSpTz2+Co2b97MjTfP5V3jx23V5uQTT+CmW/+ZtWtrIf7MM8/wxBNPcOyxx3LXXXexbt06NmzYwPe+972W9d+RtiSpV/TGV7T23HNPTjrhePZ7074MGDBgm+2Oe+cxXHL5dJat+Bnv/r3xTPrD92/VZtTvHMkX/+ef8773vY/NmzczcOBAvvKVrzB+/Hguv/xyjjvuOIYNG8Y73vGOls00N7QlSf3G5s2bua99Cd+bNWO77d74xr24ceY/bFV/4amVr3n9kQ9O5CPnfGKrdueccw7nnHNO9zrbgKfHJUn9wooVK3jLW97CySeewBFvPry3u7NTHGlLkvqFUaNG8eijj74ywWzZ8of42PmffE2bQXsOYtEP/5kJJ/xeb3SxS4a2JKlf+q+j38bSe+7s7W7sEE+PS5JUCENbkqRCGNqSJBXC0JYkqc7jTzzJd753c293oyEnokmSeseCK1q7v5OmtWQ3j696ku987xY+esYfb7Vu48aN7LFH70WnI21JUr+w1U9z/q8ruebvv75Vu0su/yv+feEixrzrvVz9lRnM/PaNnDFlKn/4kSm87/Qzuevff8QffHjKK+0vuugiZs6cCcCSJUs48cQTOeaYYzj11FNZvbrBvc27wdCWJPULW/005/dv5awPbz2avvLyz3PCccey9J47+cyFUwFY+OMlzLruy/zwB9u+j/iGDRv45Cc/yU033cSSJUv4+Mc/zqWXXtrSz9D0GD8iBgDtwC8z8w8i4gDgRmAE8Djw4cz8VdV2GnAusAn4VGb+S1U/BpgJ7AXcBlycmdmqDyNJ0ra88tOc9y9jTefTHP27RzHkgAOa2vaUk07ggAP2326bhx9+mAcffJBTTjkFgE2bNjFs2LBu97vejpyYvxh4CNi3en0JMD8zr4yIS6rXn4uIUcBkYDRwCHBnRByZmZuA64CpwH3UQvs04PaWfBJJkrpw3nnn8bV/nM2atZ18dPIZvLB+41ZtXtqwiY2bN7+y7uWNm9lz0F6vvP7PzbBh46ZX17/8MgCZyejRo1m4cOEu639Tp8cjog34faD+5P9EYFa1PAs4va4+OzPXZ+ZjwEpgXEQMA/bNzIXV6PqGum0kSdrlJk2axLwf/hs/+en9vPekExu22Xvv3+KFF17c5j4OO7SNnz3yc9avX8+vn3uO+fPnA/DWt76Vzs7OV0J7w4YNLF++vKX9b3ak/bfAnwP71NUOzszVAJm5OiIOqurDqY2kt+ioahuq5dfXJUnqEXvuuSfvPv443rSdn+Y8atTb2GOPARw34VTOmnwG++33ptesbxt+CJP+6PcZP+FU3nz4CI4++uhX9n3TTTfxqU99il//+tds3LiRT3/604wePbpl/e8ytCPiD4C1mbkkIiY0sc9oUMvt1Bu951Rqp9E57LDDmnhLSVJxWvQVrR2xefNmfrzkp9zwjeu22WbgwIH84PuzX1P7k8lnvOb1Fy+7lC9eVptktvfQQ1+pjxkzhrvvvruFPX6tZk6PHw/8UUQ8DswG3hMR3wLWVKe8qZ7XVu07gEPrtm8DnqrqbQ3qW8nMGZk5NjPHDh06dAc+jiRJjW35ac4TTzietxw+sre7s1O6HGln5jRgGkA10v6zzPyTiPi/wNnAldXzrdUmc4HvRMSXqE1EOwJYnJmbIuL5iBgPLAKmAH/X2o8jSVJjW36a84XOJwFYvuJn/OmFn35Nm0GD9mTBHXN7oXfN6c5tXa4E5kTEucAq4AyAzFweEXOAFcBG4MJq5jjABbz6la/bcea4JKmXjB71O/xowR293Y0dskOhnZl3AXdVy+uAk7fRbjowvUG9HThqRzspSeobMpOIRlOc+p+duU2Jd0STJPWIwYMHs27dup0Kq74mM1m3bh2DBw/eoe38wRBJUo9oa2ujo6ODzs7OXu3H+hd+1dL9DXr6hZ3abvDgwbS1tXXdsI6hLUnqEQMHDmTkyN6ftb3wG3/W0v2NOfdvWrq/7fH0uCRJhTC0JUkqhKEtSVIhDG1JkgphaEuSVAhDW5KkQhjakiQVwtCWJKkQhrYkSYUwtCVJKoShLUlSIQxtSZIKYWhLklQIQ1uSpEIY2pIkFcLQliSpEIa2JEmFMLQlSSqEoS1JUiEMbUmSCmFoS5JUCENbkqRCGNqSJBXC0JYkqRCGtiRJhegytCNicEQsjoj7I2J5RPxlVb88In4ZEUurxwfqtpkWESsj4uGIOLWufkxELKvWXRMRsWs+liRJfc8eTbRZD7wnM1+IiIHAPRFxe7Xu6sz8m/rGETEKmAyMBg4B7oyIIzNzE3AdMBW4D7gNOA24HUmS1KUuR9pZ80L1cmD1yO1sMhGYnZnrM/MxYCUwLiKGAftm5sLMTOAG4PRu9V6SpH6kqWvaETEgIpYCa4F5mbmoWnVRRDwQEddHxP5VbTjwZN3mHVVteLX8+nqj95saEe0R0d7Z2dn8p5EkqQ9rKrQzc1NmjgHaqI2aj6J2qvvNwBhgNXBV1bzRdercTr3R+83IzLGZOXbo0KHNdFGSpD5vh2aPZ+azwF3AaZm5pgrzzcDXgHFVsw7g0LrN2oCnqnpbg7okSWpCM7PHh0bEftXyXsB7gZ9V16i3mAQ8WC3PBSZHxKCIGAkcASzOzNXA8xExvpo1PgW4tXUfRZKkvq2Z2ePDgFkRMYBayM/JzB9ExD9GxBhqp7gfB84HyMzlETEHWAFsBC6sZo4DXADMBPaiNmvcmeOSJDWpy9DOzAeAoxvUP7adbaYD0xvU24GjdrCPkiQJ74gmSVIxDG1JkgphaEuSVAhDW5KkQhjakiQVwtCWJKkQhrYkSYUwtCVJKoShLUlSIQxtSZIKYWhLklQIQ1uSpEIY2pIkFcLQliSpEIa2JEmFMLQlSSqEoS1JUiEMbUmSCmFoS5JUCENbkqRCGNqSJBXC0JYkqRCGtiRJhTC0JUkqhKEtSVIhDG1JkgphaEuSVIguQzsiBkfE4oi4PyKWR8RfVvUDImJeRPy8et6/bptpEbEyIh6OiFPr6sdExLJq3TUREbvmY0mS1Pc0M9JeD7wnM98OjAFOi4jxwCXA/Mw8AphfvSYiRgGTgdHAacBXI2JAta/rgKnAEdXjtNZ9FEmS+rYuQztrXqheDqweCUwEZlX1WcDp1fJEYHZmrs/Mx4CVwLiIGAbsm5kLMzOBG+q2kSRJXWjqmnZEDIiIpcBaYF5mLgIOzszVANXzQVXz4cCTdZt3VLXh1fLr65IkqQlNhXZmbsrMMUAbtVHzUdtp3ug6dW6nvvUOIqZGRHtEtHd2djbTRUmS+rwdmj2emc8Cd1G7Fr2mOuVN9by2atYBHFq3WRvwVFVva1Bv9D4zMnNsZo4dOnTojnRRkqQ+q5nZ40MjYr9qeS/gvcDPgLnA2VWzs4Fbq+W5wOSIGBQRI6lNOFtcnUJ/PiLGV7PGp9RtI0mSurBHE22GAbOqGeBvAOZk5g8iYiEwJyLOBVYBZwBk5vKImAOsADYCF2bmpmpfFwAzgb2A26uHJElqQpehnZkPAEc3qK8DTt7GNtOB6Q3q7cD2rodLkqRt8I5okiQVwtCWJKkQhrYkSYUwtCVJKoShLUlSIZr5ylffsuCK1u7vpGmt3Z8kSdvgSFuSpEIY2pIkFcLQliSpEIa2JEmFMLQlSSqEoS1JUiEMbUmSCmFoS5JUCENbkqRCGNqSJBXC0JYkqRCGtiRJhTC0JUkqhKEtSVIhDG1JkgphaEuSVAhDW5KkQhjakiQVwtCWJKkQhrYkSYUwtCVJKoShLUlSIboM7Yg4NCIWRMRDEbE8Ii6u6pdHxC8jYmn1+EDdNtMiYmVEPBwRp9bVj4mIZdW6ayIids3HkiSp79mjiTYbgc9m5k8iYh9gSUTMq9ZdnZl/U984IkYBk4HRwCHAnRFxZGZuAq4DpgL3AbcBpwG3t+ajSJLUt3U50s7M1Zn5k2r5eeAhYPh2NpkIzM7M9Zn5GLASGBcRw4B9M3NhZiZwA3B6dz+AJEn9xQ5d046IEcDRwKKqdFFEPBAR10fE/lVtOPBk3WYdVW14tfz6uiRJakLToR0RewPfBz6dmc9RO9X9ZmAMsBq4akvTBpvnduqN3mtqRLRHRHtnZ2ezXZQkqU9rKrQjYiC1wP52Zt4MkJlrMnNTZm4GvgaMq5p3AIfWbd4GPFXV2xrUt5KZMzJzbGaOHTp06I58HkmS+qxmZo8H8A3gocz8Ul19WF2zScCD1fJcYHJEDIqIkcARwOLMXA08HxHjq31OAW5t0eeQJKnPa2b2+PHAx4BlEbG0qn0eODMixlA7xf04cD5AZi6PiDnACmozzy+sZo4DXADMBPaiNmvcmeOSJDWpy9DOzHtofD36tu1sMx2Y3qDeDhy1Ix2UJEk13hFNkqRCGNqSJBXC0JYkqRCGtiRJhTC0JUkqhKEtSVIhDG1JkgphaEuSVAhDW5KkQhjakiQVwtCWJKkQhrYkSYUwtCVJKoShLUlSIQxtSZIKYWhLklQIQ1uSpEIY2pIkFcLQliSpEIa2JEmFMLQlSSqEoS1JUiEMbUmSCmFoS5JUCENbkqRCGNqSJBXC0JYkqRCGtiRJhegytCPi0IhYEBEPRcTyiLi4qh8QEfMi4ufV8/5120yLiJUR8XBEnFpXPyYillXrromI2DUfS5KkvqeZkfZG4LOZ+TZgPHBhRIwCLgHmZ+YRwPzqNdW6ycBo4DTgqxExoNrXdcBU4IjqcVoLP4skSX1al6Gdmasz8yfV8vPAQ8BwYCIwq2o2Czi9Wp4IzM7M9Zn5GLASGBcRw4B9M3NhZiZwQ902kiSpCzt0TTsiRgBHA4uAgzNzNdSCHTioajYceLJus46qNrxafn290ftMjYj2iGjv7OzckS5KktRnNR3aEbE38H3g05n53PaaNqjldupbFzNnZObYzBw7dOjQZrsoSVKf1lRoR8RAaoH97cy8uSqvqU55Uz2vreodwKF1m7cBT1X1tgZ1SZLUhGZmjwfwDeChzPxS3aq5wNnV8tnArXX1yRExKCJGUptwtrg6hf58RIyv9jmlbhtJktSFPZpoczzwMWBZRCytap8HrgTmRMS5wCrgDIDMXB4Rc4AV1GaeX5iZm6rtLgBmAnsBt1cPSZLUhC5DOzPvofH1aICTt7HNdGB6g3o7cNSOdFCSJNV4RzRJkgphaEuSVAhDW5KkQhjakiQVwtCWJKkQhrYkSYUwtCVJKoShLUlSIQxtSZIKYWhLklQIQ1uSpEIY2pIkFcLQliSpEIa2JEmFMLQlSSqEoS1JUiEMbUmSCmFoS5JUCENbkqRCGNqSJBXC0JYkqRCGtiRJhTC0JUkqhKEtSVIhDG1JkgphaEuSVAhDW5KkQnQZ2hFxfUSsjYgH62qXR8QvI2Jp9fhA3bppEbEyIh6OiFPr6sdExLJq3TUREa3/OJIk9V3NjLRnAqc1qF+dmWOqx20AETEKmAyMrrb5akQMqNpfB0wFjqgejfYpSZK2ocvQzsy7gWea3N9EYHZmrs/Mx4CVwLiIGAbsm5kLMzOBG4DTd7LPkiT1S3t0Y9uLImIK0A58NjN/BQwH7qtr01HVNlTLr69L/dOCK1q/z5OmtX6f2r34d9Pv7exEtOuANwNjgNXAVVW90XXq3E69oYiYGhHtEdHe2dm5k12UJKlv2anQzsw1mbkpMzcDXwPGVas6gEPrmrYBT1X1tgb1be1/RmaOzcyxQ4cO3ZkuSpLU5+xUaFfXqLeYBGyZWT4XmBwRgyJiJLUJZ4szczXwfESMr2aNTwFu7Ua/JUnqd7q8ph0R3wUmAAdGRAdwGTAhIsZQO8X9OHA+QGYuj4g5wApgI3BhZm6qdnUBtZnoewG3Vw9JktSkLkM7M89sUP7GdtpPB6Y3qLcDR+1Q7yRJ0iu8I5okSYUwtCVJKoShLUlSIQxtSZIKYWhLklSI7tzGVP3c1fMeaen+PnPKkS3dnyT1NY60JUkqhKEtSVIhDG1JkgphaEuSVAhDW5KkQhjakiQVwtCWJKkQhrYkSYUwtCVJKoR3RNNuo9V3WAPvsiapb3GkLUlSIQxtSZIKYWhLklQIQ1uSpEIY2pIkFcLQliSpEIa2JEmFMLQlSSqEoS1JUiEMbUmSCmFoS5JUCO89vhtr9b24vQ+3JJWty5F2RFwfEWsj4sG62gERMS8ifl4971+3blpErIyIhyPi1Lr6MRGxrFp3TURE6z+OJEl9VzMj7ZnAtcANdbVLgPmZeWVEXFK9/lxEjAImA6OBQ4A7I+LIzNwEXAdMBe4DbgNOA25v1QdR13bFr2hJ6lkLH13X0v0dd1JLd6ddrMuRdmbeDTzzuvJEYFa1PAs4va4+OzPXZ+ZjwEpgXEQMA/bNzIWZmdT+A3A6kiSpaTs7Ee3gzFwNUD0fVNWHA0/WteuoasOr5dfXG4qIqRHRHhHtnZ2dO9lFSZL6llZPRGt0nTq3U28oM2cAMwDGjh27zXaS1FILrmjt/k6a1tr9qd/b2ZH2muqUN9Xz2qreARxa164NeKqqtzWoS5KkJu1saM8Fzq6WzwZuratPjohBETESOAJYXJ1Cfz4ixlezxqfUbSNJkprQ5enxiPguMAE4MCI6gMuAK4E5EXEusAo4AyAzl0fEHGAFsBG4sJo5DnABtZnoe1GbNe7McUmSdkCXoZ2ZZ25j1cnbaD8dmN6g3g4ctUO9kyRJr/A2ppIkFcLQliSpEIa2JEmFMLQlSSqEv/KlPs1fSpPUlzjSliSpEIa2JEmFMLQlSSqEoS1JUiEMbUmSCuHscWkHtGo2+vhV6wA47vAhLdmfpP7BkbYkSYUwtCVJKoSnx3dHC64AXj2F2l33HTa1JfuRJPUuR9qSJBXC0JYkqRCeHpd60cJHW3MJBOC+jY94b3Spj3OkLUlSIQxtSZIK4elx7bDxq2a0dH/Obpek5jjSliSpEIa2JEmFMLQlSSqE17TV61p9jRy8Tt5ftOoHXLYYv2qdP+Ki3ZojbUmSCuFIu4Va/bONkiTVc6QtSVIhDG1JkgrRrdCOiMcjYllELI2I9qp2QETMi4ifV8/717WfFhErI+LhiDi1u52XJKk/acU17ZMy8+m615cA8zPzyoi4pHr9uYgYBUwGRgOHAHdGxJGZuakFfZBew7u2SeqLdsVEtInAhGp5FnAX8LmqPjsz1wOPRcRKYBywcBf0QZJ2ir+8pt1Zd69pJ/CvEbEkIrYMRQ7OzNUA1fNBVX048GTdth1VbSsRMTUi2iOivbOzs5tdlCSpb+juSPv4zHwqIg4C5kXEz7bTNhrUslHDzJwBzAAYO3ZswzaSJPU33RppZ+ZT1fNa4J+one5eExHDAKrntVXzDuDQus3bgKe68/6SJPUnOx3aEfFbEbHPlmXgfcCDwFzg7KrZ2cCt1fJcYHJEDIqIkcARwOKdfX9Jkvqb7pwePxj4p4jYsp/vZOYdEfFjYE5EnAusAs4AyMzlETEHWAFsBC505rgkSc3b6dDOzEeBtzeorwNO3sY204HpO/uekiT1Z957XGrCrvglMknaUd7GVJKkQhjakiQVwtCWJKkQhrYkSYUwtCVJKoSzxyX1jAVXtHZ/J01r7f52kavnPdKyfY1f1bofM1GZHGlLklQIQ1uSpEIY2pIkFcLQliSpEIa2JEmFMLQlSSqEoS1JUiH8nrakMi24wu8t9wOt/J77FuNbvsee40hbkqRCGNqSJBWiX58eX/ho90+t3bex9aduJElqxJG2JEmFMLQlSSpEvz49LvU1rZ5p+5lTjmzp/lpxSUrqzwztbhq/akZvd0GS1E8Y2pK2yd+ClnYvXtOWJKkQjrSlPsJLNVLf50hbkqRCGNqSJBWix0M7Ik6LiIcjYmVEXNLT7y9JUql69Jp2RAwAvgKcAnQAP46IuZm5oif70d94rVOS+oaeHmmPA1Zm5qOZ+Z/AbGBiD/dBkqQi9XRoDweerHvdUdUkSVIXevorX9Gglls1ipgKTK1evhARD7ewDwcCT7dwf/2Rx7D7PIbdV8AxvKq3O9C1864q4Dju5lp/DH97Wyt6OrQ7gEPrXrcBT72+UWbOAHbJhdiIaM/Msbti3/2Fx7D7PIbd5zFsDY9j9/XkMezp0+M/Bo6IiJERsScwGZjbw32QJKlIPTrSzsyNEXER8C/AAOD6zFzek32QJKlUPX4b08y8Dbitp9+3jt9/6j6PYfd5DLvPY9gaHsfu67FjGJlbzQOTJEm7IW9jKklSIfpsaHd1u9SouaZa/0BEvKM3+rk7a+IYnlUduwci4kcR8fbe6OfurNnb9kbEOyNiU0R8qCf7V4JmjmFETIiIpRGxPCL+raf7uLtr4t/ymyLi/0XE/dUxPKc3+rk7i4jrI2JtRDy4jfU9kymZ2ece1Ca5/QI4HNgTuB8Y9bo2HwBup/bd8fHAot7u9+70aPIY/h6wf7X8fo/hjh/DunY/pDbX40O93e/d6dHk3+F+wArgsOr1Qb3d793p0eQx/Dzw19XyUOAZYM/e7vvu9ADeDbwDeHAb63skU/rqSLuZ26VOBG7ImvuA/SJiWE93dDfW5THMzB9l5q+ql/dR+969XtXsbXs/CXwfWNuTnStEM8fwo8DNmbkKIDM9jq/VzDFMYJ+ICGBvaqG9sWe7uXvLzLupHZdt6ZFM6auh3cztUr2l6vbt6PE5l9r/MvWqLo9hRAwHJgF/34P9Kkkzf4dHAvtHxF0RsSQipvRY78rQzDG8FngbtZtdLQMuzszNPdO9PqNHMqXHv/LVQ5q5XWpTt1Ttx5o+PhFxErXQftcu7VF5mjmGfwt8LjM31QY5ep1mjuEewDHAycBewMKIuC8zH9nVnStEM8fwVGAp8B7gzcC8iPj3zHxuF/etL+mRTOmrod3M7VKbuqVqP9bU8YmI3wW+Drw/M9f1UN9K0cwxHAvMrgL7QOADEbExM2/pkR7u/pr9t/x0Zr4IvBgRdwNvBwztmmaO4TnAlVm7OLsyIh4DfgdY3DNd7BN6JFP66unxZm6XOheYUs34Gw/8OjNX93RHd2NdHsOIOAy4GfiYo5qGujyGmTkyM0dk5gjgJuC/G9iv0cy/5VuBEyJij4h4I3As8FAP93N31swxXEXtTAURcTDwVuDRHu1l+XokU/rkSDu3cbvUiPhEtf7vqc3U/QCwEvgNtf9pqtLkMfwCMAT4ajVS3Jj+8MArmjyG2o5mjmFmPhQRdwAPAJuBr2dmw6/l9EdN/h3+b2BmRCyjdpr3c5npL3/ViYjvAhOAAyOiA7gMGAg9myneEU2SpEL01dPjkiT1OYa2JEmFMLQlSSqEoS1JUiEMbUmSCmFoS5JUCENbkqRCGNqSJBXi/wPf5blwbPVSrgAAAABJRU5ErkJggg==",
      "text/plain": [
       "<Figure size 576x432 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 432x288 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# assume y_pred is a numpy array and y_true is a pandas dataframe\n",
    "fig, ax = plt.subplots(figsize=(8, 6))\n",
    "\n",
    "column = \"X..Guaiol\"  # specify the target variable name\n",
    "ax.hist(y_pred_rfreg_test, alpha=0.5, label='y_pred', bins=20)\n",
    "ax.hist(y_test[column], alpha=0.5, label='y_true', bins=20)\n",
    "ax.legend(loc='upper right')\n",
    "ax.set_title(column)\n",
    "\n",
    "plt.show()\n",
    "plt.savefig('error_hist_knn_tfidf_guai.png')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pearson R"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pearson correlation coefficient: 0.957\n",
      "P-value: 0.000\n"
     ]
    }
   ],
   "source": [
    "corr_coef, p_value = pearsonr(y_pred_rfreg_test.flatten(), y_test.values.ravel())\n",
    "\n",
    "print(f\"Pearson correlation coefficient: {corr_coef:.3f}\")\n",
    "print(f\"P-value: {p_value:.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:>"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "corr_matrix = y_test.corr()\n",
    "sns.heatmap(corr_matrix, annot=True, cmap='coolwarm', center=0)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
